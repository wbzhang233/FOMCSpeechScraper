[
    {
        "speaker": "Daniel K. Tarullo",
        "position": "Governor",
        "date": "December 02, 2016",
        "title": "Financial Regulation Since the Crisis",
        "href": "https://www.federalreserve.gov/newsevents/speech/tarullo20161202a.htm",
        "content": "December 02, 2016\n\nGovernor Daniel K. Tarullo\n\nAt the Federal Reserve Bank of Cleveland and Office of Financial Research 2016 Financial Stability Conference, Washington, D.C.\n\nLast summer, when I accepted President Loretta Mester's invitation to speak at this conference, I thought it would be a good occasion to step back and assess where we stand in our post-crisis efforts to promote financial stability in the United States. This morning I will offer such an assessment. I will begin by reviewing what has been accomplished. Then I will suggest how to approach the work that remains--including both tackling continuing vulnerabilities to financial stability and rationalizing the measures that have already been taken.\n\nThe Crisis and Its Aftermath\nTo understand where we stand today, we should recall why we embarked on these efforts in the first place. There is little mistaking the motivation--it was the magnitude of the destruction wrought by the financial crisis and the Great Recession that followed it. The resulting losses in employment were on a scale not seen since the Great Depression. One model used by Federal Reserve staff1 estimates that cumulative loss in output relative to potential over the period was on the order of one quarter of a year's worth of economic output.2 While we cannot be certain that these losses were due solely to the financial crisis, losses of this magnitude appear broadly in line with estimates of the effects of prior financial crises.3 Moreover, the shortfalls in jobs and income relative to potential may understate the total losses, as many current estimates of potential output are significantly below levels expected prior to the Great Recession. This may be due to the declines in investment, business dynamism, and labor force attachment brought about by the shortfall in aggregate demand through hysteresis effects.4\n\nAs evidenced by a continuing stream of scholarship, many factors contributed to the unsustainability and fragility of the pre-crisis financial system. But the inadequacy of regulation and supervision was clearly among them. Large banking firms had insufficient levels of high-quality capital; excessive amounts of short-term, wholesale funding; too few high-quality, liquid assets; and inadequate risk measurement and management systems. Systemically important nonbank financial firms whose failure could threaten the stability of the financial system were effectively outside the regulatory perimeter. Governments did not have resolution regimes that could provide for an orderly resolution of a systemically important financial firm. Shadow banking--which was funding long-term assets with short-term wholesale liabilities--exposed the financial system to a systemwide liquidity run.\n\nAlthough we all lived through the fall of 2008, let me dwell for a moment on that frightening period. Six months had passed since the demise of Bear Stearns in March. Over that summer, it may have appeared as though the fallout from this episode had been contained. But by the fall, it became clear that other large, non-prudentially regulated financial firms threatened financial stability. American International Group (AIG) received direct government support. Two large freestanding investment banks converted themselves into bank holding companies to gain market confidence from the imprimatur of regulatory oversight by the Federal Reserve. Merrill Lynch and Bear Stearns itself ceased to exist as independent entities and were absorbed into existing bank holding companies, with some form of government benefit facilitating the acquisition.5 And, of course, as Fannie Mae and Freddie Mac teetered on the brink of failure, they were placed into government conservatorship, with accompanying full government guarantees of their liabilities. The absence of an option for orderly resolution was faced head-on in the case of Lehman Brothers, whose bankruptcy in September moved the financial crisis to its most acute phase.\n\nEven insured depository institutions such as Wachovia and Washington Mutual, for which special resolution procedures were available, were merged into existing banks with, again, government benefits to make the absorption of these failing banks worthwhile for the acquiring institutions.6 And a number of very large bank holding companies were under grave stress. Meanwhile, financial markets of all sorts had either ceased functioning or come dangerously close to it.\n\nUnlike in some bank crises of the past, direct connections among large financial firms were only part of the problem. At the heart of the crisis were contagion effects among firms holding similar assets--particularly, tradable assets--and the withdrawal of much of the short-term wholesale funding on which many large financial firms and the shadow banking system had come to rely. Needless to say, the larger the firm with lots of tradable assets and runnable funding, the greater the additional threat to the system.\n\nIf anyone harbored remaining doubts, it was clear by October that the nation's financial system faced not just severe liquidity problems, but a solvency crisis. In response, following enactment of the Troubled Asset Relief Program by Congress, Secretary Henry Paulson oversaw the injection of government capital into the nation's largest financial firms, as well as into many smaller banking firms. This first step toward stability was reinforced in early 2009 when Secretary Timothy Geithner initiated the stress test exercise to determine how much capital these firms needed to remain viable financial intermediaries and, perhaps as importantly, to share this information with markets. In the succeeding months, the Federal Reserve obliged the firms to raise enough private capital to replace the government capital and to meet the minimum capital levels established by the stress tests.\n\nBy the latter part of 2009, the U.S. financial system had been stabilized, but only with substantial injections of taxpayer capital and the complementary support of other guarantees and lending facilities variously provided by the Federal Reserve, the Treasury, and the Federal Deposit Insurance Corporation (FDIC)--both to banks and to non-bank financial actors. And the nation had meanwhile been plunged into the deepest economic downturn since the Great Depression.\n\nDemands were widespread, both in the country and the Congress, for a regulatory response to protect against the reemergence of the conditions that had led to the crisis. While there were different views on exactly what should be done, on how much new authority was needed for the regulators who had not fully exercised their existing powers, and on the degree to which regulators should be required--rather than just empowered--to take certain actions, there was agreement that action was needed. Throughout 2009, discussion and debate ensued not just between, but within, the political parties on how best to respond. If there was one powerful, widely held view that underlay the public debate, it was that the system needed to change to avoid a repeat of the taxpayer bailouts of so many large financial institutions.\n\nIt was only toward the end of the legislative exercise that resulted in the Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank Act) that the process took a more partisan turn. Indeed, the Dodd-Frank Act contains measures that commanded fairly wide consensus, such as the need for higher capital requirements for the largest banks. Furthermore, the origins of some features of the legislation rested as much or more with Republican than Democratic legislators, such as the section 165 requirement for resolution plans that will make systemically important firms resolvable in bankruptcy without requiring taxpayer support or resulting in major disorder in the financial system.\n\nThe Nature and Impact of the New Regulatory Regime\nNow let us fast forward to the present. Less than a decade after being the epicenter of a global financial crisis, today the United States has the strongest and most diverse financial system of any major economy in the world. Credit default swap (CDS) spreads and other market indicators suggest that investors have remained confident in the solvency of large U.S. banks through several recent episodes of global financial volatility.7 For example, during the market strains at the beginning of this year, the CDS spreads of U.S. banks increased only 25 to 50 basis points, and even so only briefly, while large banks in some other parts of the world saw their CDS spreads increase substantially more and for a longer period. The relative strength of, and resulting market confidence in, U.S. banks has allowed them to expand their lending, the growth of which has returned during the last couple of years to a pace similar to that in the pre-crisis, pre-bubble years.8\n\nWhat accounts for this dramatic change in the position of the U.S. financial system? First, the crisis response by U.S. authorities was fairly quick and complete. The resolute actions of the Bush Administration in late 2008 and the Obama Administration early in 2009 helped stabilize banks and begin their recovery in fairly short order. Recapitalization proceeded quickly, even as the stress test compelled an early reckoning with actual and potential losses. The forceful monetary policy response, the liquidity programs of the Federal Reserve, and the FDIC's guarantee of bank debt prevented the bottom from dropping out of the badly shaken financial system. The emergency fiscal stimulus of 2009 helped prevent a downward spiral in the real economy from a Great Recession to another depression.\n\nSecond, and of more relevance for the subject of this conference, was the regulatory reform program put in motion even before the crisis had ended. This program has steadily strengthened the capital, liquidity, and risk management positions of large banks, with progressively more stringent measures applied to the most systemically important institutions. The new regulatory regime for large banks serves two important, complementary goals. One is to ensure that the nation's large financial institutions are sufficiently strong to continue to function effectively as intermediaries, lending to creditworthy businesses and households even in a period of substantial financial and economic stress. If they cannot do so because, for example, their capital positions have been too weakened, the result could be a deepening of what may already be a serious recession. The other goal is to address the too-big-to-fail problem. When some combination of the size, functions, portfolios, and interconnectedness of a financial institution are such as to make authorities fear that its failure could endanger the entire financial system, they will be tempted to rescue the firm through direct capital injections or indirect measures to strengthen its solvency. Knowing this, other market actors will be willing to lend to that institution at a premium lower than its actual risks would suggest is warranted, an effect that is particularly apparent during periods of stress.\n\nTaking both these goals into account, the regulatory regime must aim for much greater resiliency in the large banks than in smaller ones, so that they can continue to function even under serious stress without solvency assistance from the government and, thus, avoid causing more harm to the economy. But the regime must also be able to contemplate failure by a very large bank--that is, to plan for the possibility that a larger bank may become insolvent notwithstanding much greater ex ante resiliency. The regime must promote market discipline and offset the moral hazard that comes if a bank and its creditors believe the government will have no real choice but to bail the bank out.\n\nMuch has been accomplished in the last six or seven years to build a regime that advances both these goals. I want to highlight four of its elements: capital, liquidity, risk management, and resolution planning. Capital is, of course, central to ensuring resiliency although, as I will explain shortly, the presence or absence of other regulatory requirements is relevant in setting minimum capital levels. Because no single capital measure can capture all possible sources of loss, U.S. banking regulation has for three decades required both a leverage ratio and a risk-based capital requirement. In responding to the crisis, we have applied a higher leverage ratio and stronger risk-based capital requirements, including a robust stress testing program to larger banks.\n\nThe risk-based capital regime that has been built since the crisis contains several distinct components: a minimum capital requirement, a buffer requirement, and a surcharge on systemically important banks.9 Let me explain the rationale for each component. The minimum capital requirement represents the amount of capital that experience suggests a bank needs so as to retain the confidence of its customers and counterparties and thus function as an intermediary. Recognizing that a bank operating below its minimum capital will be vulnerable to a sudden loss of market confidence, the regulatory consequences of falling below the minimum are severe and intended to force such a bank to quickly take steps to raise its capital level back above the minimum. The buffer capital requirement is sized so that, if the economy suffers a severe recession that leads a bank to suffer a substantial loss, the bank will still be above its minimum capital level and thus able to continue operating and lending to support economic growth. The buffer is intended to be useable in times of stress, and the regulatory consequences of falling into the buffer are accordingly less severe than the consequences of falling below the minimum. The surcharge on systemically important banks requires systemically important firms to recognize, and hold capital against, the costs that their failure would impose on the broader economy.\n\nThe minimum and buffer requirements were calibrated using historical data on bank losses across a number of countries in a way that would be appropriate for all large banks across a range of countries, although we recognized at the time that these requirements might not reflect market circumstances in all situations. The surcharge for global systemically important banks (G-SIBs) was calibrated to provide a sufficient amount of additional capital to reduce sufficiently the chances of a G-SIB's failure so that the impact of its failure, discounted by the probability of that failure occurring, would approximately equal the impact of the failure of a large bank holding company that is not a G-SIB, discounted by the somewhat higher probability of its failure.10\n\nAs I explained recently, we will soon consider adopting a \"stress capital buffer\" to integrate the post-crisis capital regime with our supervisory stress test.11 In this approach, each firm would have a buffer requirement derived from our annual stress test, taking the place of the existing buffer requirement, which is the same for all firms. This change would make the capital regime more risk-sensitive by using firm-specific information on risks drawn from the stress test. Using the supervisory stress test to guide a risk-sensitive capital regime seems far preferable to reliance on a bank's internal models, which have proven problematic as a basis for risk-based capital requirements under Basel II.12\n\nThe progressive implementation of this capital regime has substantially increased the resiliency of the largest banks. Although there can be reasonable differences over just how to compute minimum requirements, the post-crisis regime differs from pre-crisis days precisely because there is now a well thought through rationale for those much higher minimum requirements. Because of this regime, banks subject to the annual supervisory stress test have to this point more than doubled their high-quality capital, while shedding many of their riskiest assets and activities.\n\nA second important feature of the post-crisis regulatory regime for large banks has been the introduction of quantitative liquidity regulations. The financial crisis was, in the first instance, as much about liquidity as solvency. What proved in retrospect to be excessive liquidity for some types of assets turned into scarcity nearly overnight, confirming the view that liquidity is most available when you need it least and least available when you need it most. The period was defined by runs, not on bank deposits (at least not insured bank deposits), but on short-term wholesale funding. Because of deep uncertainty about the condition of counterparties and the value of assets serving as collateral, investors refused to roll over existing repurchase agreements (or repos) and similar extensions of credit, much less to offer new lending. Many trading activities ground to a near halt, and dealers were forced into fire sales of the assets on their balance sheets that remained liquid. Indeed, it was difficult at times to distinguish between liquidity and solvency crises at particular firms.\n\nThe Liquidity Coverage Ratio (LCR) and Net Stable Funding Ratio (NSFR) have placed the funding of large banks on a firmer footing. The LCR requires a large bank to hold enough high-quality liquid assets to cover the net cash outflows the bank would expect to occur over a 30-day stress scenario. This requirement establishes a buffer against liquidity risk that reduces the bank's vulnerability to a run, such as materialized in the recent crisis. In the event a bank does encounter liquidity difficulties, the LCR's 30-day buffer will give the authorities time to assess the bank's condition and react as appropriate.\n\nThe NSFR complements the LCR by requiring an amount of stable funding that is tailored to the liquidity risk of a bank's assets and liabilities, based on a one-year time horizon. The NSFR creates an incentive for banks to extend the maturity of their funding, making them more resilient to market stress. To offset the risks of the short-term wholesale funding structures that proved so dangerous in the recent crisis, the NSFR requires more stable funding for short-term loans to financial firms.\n\nIt is important to note how liquidity requirements also affect the capital needed by a bank, as can be illustrated by a simple, if admittedly improbable, example. Assume two banks with exactly the same assets and the same amount of capital. One funds those assets entirely through insured (sticky) deposits and longer-term debt, while the other funds its assets entirely through short-term uninsured deposits and repo borrowing. Assume now that an external shock reduces the value of the assets dramatically, with lingering uncertainty as to whether the value will continue to drop. It is readily apparent that the two large banks face very different risks, since the second bank's funding will at best become more expensive and at worst decline or disappear. A sound regulatory regime will align the riskiness of the two banks more closely, by requiring the second bank to change its funding profile, increase its capital, or some combination of the two. In fact, the LCR and NSFR would require more stability in funding at my second hypothetical bank, while one of the factors used to calculate the capital surcharge applicable to the largest banks is its relative reliance on runnable funding.\n\nI will not go into detail in explaining a third key factor of our post-crisis regulatory regime--the requirement for rigorous risk management at large banks. But a brief example should make the point. During the height of the crisis in the winter of 2009, as we were conducting the first stress test, we found that some of the largest banks were literally unable to determine in any reasonable time their aggregate exposures to particular counterparties and business lines across their varied operations. That deficiency made it easier to understand how they could have gotten themselves in such trouble. Because of the supervisory expectations for risk management in our annual Comprehensive Capital Analysis and Review (CCAR) exercise, the information and risk management systems of all banks have improved substantially, though work remains to be done at some of the largest banks.\n\nA fourth key element of the post-crisis regulatory regime is to develop credible options for resolution so that even one of the largest financial firms could be allowed to fail without bringing the financial system down. Without such options, market discipline will remain lacking. Moral hazard will lurk in the background, since market actors will doubt that a large institution would be allowed to fail. Moreover, government officials must themselves have confidence in the viability of orderly resolution and bankruptcy procedures, or else during periods of high stress, they will be tempted to use some form of government help to keep the firm solvent.\n\nNext Steps\nWhile it is perhaps a bit soon for a full evaluation of the regulatory regime for large banks, several studies affirm its beneficial economic effects, particularly when the destructive impact of a financial crisis is taken into account.13 This assessment should obviously be adjusted as warranted by new studies and data. But even as this work proceeds, we should continue to ask two questions.\n\nFirst, are we reasonably confident that the largest U.S. banks could weather a period of stress, and, in the more remote event they could not, that they would no longer present the Hobson's choice of disorderly failure endangering the entire financial system or some form of solvency bailout? While they are strong relative to their peers in other major economies and have held up well during the few bouts of moderate financial stress we have experienced over the last several years, these firms have not yet faced a major financial challenge. Second, should we adjust statutory or regulatory provisions that are not needed for, or are less efficient means for achieving, financial stability? Let me offer some perspective on answering both questions, along with a handful of specific proposals.\n\nWith respect to the first question, there is certainly room for discussion over the most suitable minimum capital standards for the most systemically important financial firms. As I noted when we were deciding on the expected impact approach as the best available method for calibrating capital surcharges, there is no magic to that method.14 Indeed, even within that approach, we should be open to research that suggests new or improved ways to determine the relative systemic importance of firms. However, I think it is important to have a methodology that is clearly explained and is based on the research that has been done. Let me note in passing two points that can be drawn from that research. First, there is work subsequent to the formulation of the Basel III capital standards suggesting that the costs of higher capital requirements may be somewhat lower, and the benefits broader, than previously thought. Second, however, the reduction in the probability of a financial crisis associated with increasing capital levels will begin to level off at some point, thereby creating diminishing benefits for tighter capital standards.15\n\nMoreover, as important as capital is to promoting systemic stability, it is not the only relevant consideration. The relative presence or absence of other regulations that mitigate risk in banks should affect minimum capital levels. To my mind, the most important of these are regulations limiting dependence of financial firms on runnable funding sources.16 If a firm is not vulnerable to runs, it is far more likely to weather a financial storm without resorting to fire sales or cutting off customers from credit, and thus far less likely to wreak havoc on the financial system.\n\nIn short, I think it healthy that discussion continues over the right type and levels of capital requirements and, more generally, over whether we have the right mix of policies. To that end, here are a few relatively near-term steps that we at the Federal Reserve can take to further advance financial stability goals. First is to continue focused work on making the largest, most systemically important firms resolvable in order to minimize both moral hazard and any harm that may befall the economy if such a firm were to fail. This means continued work by the Federal Reserve and the FDIC to require these firms to develop their resolution plans and, more importantly, modify their organizational structures and day-to-day practices such as liquidity management so as to enable an orderly resolution, should it become necessary. Along these lines, I would hope that Congress will move forward with a set of changes to the bankruptcy code to facilitate the resolution of large financial firms and, thereby, limit the number of instances in which the government would need to use the Title II procedures of Dodd-Frank.\n\nIn the very short term, we will also finalize our rule requiring the most systemically important firms to hold a sizeable amount of long-term debt, which would be available to the FDIC or a bankruptcy judge for conversion into equity should the firm fail. Note that this requirement is intended to prepare for the possibility that the firm fails despite all the measures we have taken to strengthen resiliency. Having identifiable instruments for conversion that would survive the loss of most or all of the firm's equity is necessary for a private recapitalization of the firm to be successful.\n\nA second step is to determine if we can develop metrics that would reflect a firm's particular vulnerabilities to funding shocks, liquidity shocks, and fire sale dynamics in their needed capital as part of the annual stress test.17 These measures would directly take into account macroprudential concerns of financial system stability. They might well counsel increased capital requirements for some of the largest banks.\n\nA third step is to take another look at the capital and liquidity positions of large U.S. branches of some foreign banks. As has become apparent, the actual consolidated capital positions of some such banks can be difficult for us to discern when the bank uses internal models to compute its required regulatory capital. It is critical to ensure that large U.S. branches of foreign banks do not create financial instability in the United States if their parents' global positions come under stress.\n\nAlthough I have been focusing mostly on the risks to financial stability posed by the largest financial firms, I would not want to leave a discussion of future work without offering another reminder that they are not the only source of vulnerabilities. The kinds of \"shadow banking\" that grew up around the private-label mortgage backed securities markets have largely disappeared, but other forms of runnable liabilities remain outside prudentially regulated institutions. There is also good reason to believe that new forms of shadow banking will develop in the future and, as I have explained at some length elsewhere, continued attention to such activities will be needed.18\n\nTurning now to an agenda for rationalizing what has already been done, I will not attempt to lay out a list of appropriate measures so much as to suggest some key considerations in forming such an agenda.\n\nFirst, it is critical that we not forget our still quite recent history. Earlier in this talk I recounted the origins and effects of the financial crisis as a reminder as to why we now have the stronger capital requirements and other measures I have described. There is surely a need to review over time the changes that have been implemented to assess how much additional stability we have gained and at what cost. As we gain experience with the statutory and regulatory measures that have been implemented, we have begun assessments of the efficacy and efficiency of these measures. Thus, for example, we are proposing to remove the qualitative assessment exercise in CCAR for most firms with less than $250 billion in assets.19 As part of our continuing examination of changes in market liquidity in the post-crisis period, we are assessing whether refinements might usefully be made in any of the regulations that have generally had beneficial effects in containing excessive and unsustainable liquidity. And as part of our efforts to tailor our regulations according to the business models of firms, we are considering ways to address the special issues posed for the large custody banks by certain elements of our regulatory framework. But in considering these and other changes, we will not weaken the essential elements of the existing regime that guard against another financial crisis.\n\nSecond--and here is an affirmative argument for rationalization measures--we need to have a more explicit and thorough tiering of requirements within the prudential regulatory regime. The flip side of the observation that the largest banks need stricter and more wide-ranging regulation because of the special risks they pose is that the smaller and less interconnected a bank is, the less risk it presents and thus the less strict its regulatory requirements need be. The Dodd-Frank Act reflects this principle, not only in its mandate of progressively more stringent requirements as the systemic importance of a financial firm increases, but also in the asset-size thresholds it establishes for various new regulations. However, as I have noted in the past, I think these thresholds were set too low in places.20 For example, I would raise the threshold for enhanced prudential standards from its current $50 billion level, perhaps to $100 billion. And I would entirely exempt community banks--by which I mean those with less than $10 billion in assets--from some regulations, such as the Volcker rule and the incentive compensation rule.\n\nIt is worth noting that the burden of these rules for small banks is often less in the substantive constraints they impose on bank activities than in the compliance costs they impose. Even with efforts by banking agencies to streamline implementing regulations for smaller banks, the relatively scarce compliance resources of those banks must still be directed towards assuring that no changes in substantive activities are needed and possibly documenting their compliance. Indeed, I would generalize this point to suggest that the smaller the bank, the greater the likelihood that a potential disconnect between costs and benefits of regulation is rooted in the disproportionate costs of exams, audits, and reporting. So while I think it is worthwhile to continue, for example, efforts to simplify capital rules for small banks, the greater value for those banks may lie in efforts to streamline the number of rules that apply to them and to reduce the number of separate compliance exams and exercises to which they are subject. While especially applicable to small banks, this point has broader application, as in our earlier-mentioned proposal to exempt most banks with less than $250 billion in assets from the qualitative component of our annual CCAR exercise.\n\nMy third suggested consideration in rationalizing the regulatory regime is a caution against being excessively attracted to simple answers to a set of risks posed by complicated and diverse activities. There is no question, in my mind at least, that regulations can become excessively complicated. A prime example is the Basel II approach of basing banks' capital requirements on their internal models. It is exceedingly difficult and costly for supervisors to validate those models rigorously and, even so, the potential remains for intentional or unintentional mistakes that are hard to detect in a timely manner. But this example does not mean that the simplest possible regulation is always optimal.\n\nConsider, in this regard, the idea of substituting a somewhat higher leverage ratio requirement for all other capital standards and many other regulatory requirements. While this idea has a surface appeal, since the imposition of, say, a 10 percent leverage ratio on the current balance sheets of large banks would yield a very well-capitalized set of banks. But one needs to look at the dynamic effects of such a requirement. Since a higher leverage ratio would also make banks significantly less profitable, and with the constraints of risk-based capital and liquidity requirements lifted, they would be strongly incentivized to change the composition of their balance sheets dramatically, shedding safer assets like Treasuries in exchange for riskier but higher-yielding assets. After all, with a leverage ratio as the only significant constraint, the regulatory cost of a short-term Treasury bill is identical to that of a junk bond.\n\nThus, to truly assure the safety and soundness of the financial system, a leverage ratio serving as the sole or dominant form of prudential regulation would probably have to be set considerably higher, at a level where the impact on financial intermediation could be quite extensive, particularly in what are today regarded as relatively safe capital market activities. Using both a leverage ratio and a strong set of risk-based capital requirements best combines the goals of safety and soundness, on the one hand, and efficient economic intermediation on the other. We should remember that it was because of the limitations of a stand-alone leverage ratio that risk-based capital requirements were introduced in the 1980s.\n\nConclusion\nThis conference is a good moment to remember just how bad things can be when financial stability is not effectively safeguarded and a financial crisis ensues. It is, accordingly, also a good moment to caution against backsliding on the considerable progress that has been made toward a regulatory system that will provide just such a safeguard, particularly with respect to the largest, most systemically important banks. While other modes of reform might have been taken, the one we have followed has provided a strong foundation for financial stability. And, although I am sure some large banks would like to pare back our liquidity and risk management requirements or reduce required capital levels, both they and the economy have now largely adjusted to the new regime.\n\nAfter compelling banks in the depths of the crisis to raise capital sufficient to keep them at the minimum level necessary to function as effective intermediaries, we have since increased their resiliency through requirements to increase the quality and quantity of their capital. But we have done so with a long transition period that allowed them mostly to build capital through retained earnings. And we have generally left to the banks choices about reducing size or exiting activities in response to the incentives created by regulations calibrated with credit and funding risks in mind. Our stress test and CCAR exercises should ensure that the largest banks will not maintain distributions of capital to their shareholders in the face of rising financial stress, as they did in 2007 and 2008, which left them more vulnerable to the crisis.\n\nThere are surely refinements that can be made to the regulatory regime that has emerged, particularly--though not exclusively--with respect to smaller banks that pose neither systemic nor macroprudential risks. And, as I have suggested, there is surely a healthy debate to be had as to whether additional strengthening of resiliency measures is appropriate for the largest institutions. But I do not think there is a sound economic case for generally weakening the regulatory requirements applicable to the largest banks. And I certainly do not think the taxpayers should bear the risk that would be entailed by any such weakening.\n\n\n\n1. This estimate is from the FRB/US model, which is one model of the U.S. economy used by staff at the Federal Reserve Board. For a description of the model and access to the data, see www.federalreserve.gov/econresdata/frbus/us-models-package.htm. Return to text\n\n2. Losses attributable to the Great Recession have been estimated using different metrics and range widely. For example, one 2013 study suggests that total U.S. losses from the financial crisis could range from 40 to 90 percent of a year's worth of economic output, or $6 to $14 trillion. Tyler Atkinson, David Luttrell, and Harvey Rosenblum (2013), \"How Bad Was It? The Costs and Consequences of the 2007-09 Financial Crisis (PDF) ,\" Federal Reserve Bank of Dallas, Staff Papers, no. 20 (July). For an alternative view that finds lower effects of moderate crises, but that excludes the recent crisis, see Christina D. Romer and David H. Romer (2015), \"New Evidence on the Impact of Financial Crises in Advanced Countries (PDF) ,\" NBER Working Papers, no. 21021 (Cambridge, Mass.: National Bureau of Economic Research, March). Return to text\n\n3. For estimates that predate the recent crisis, see Stephen G. Cecchetti, Marion Kohler, and Christian Upper (2009), \"Financial Crises and Economic Activity,\" in Financial Stability and Macroeconomic Policy (Kansas City: Federal Reserve Bank of Kansas City), pp. 89-135. Return to text\n\n4. For a discussion of these effects, see Laurence M. Ball (2014), \"Long-Term Damage from the Great Recession in OECD Countries,\" European Journal of Economics and Economic Policies: Intervention, vol. 11, no. 2 (September), pp. 149-160; and Dave Reifschneider, William Wascher, and David Wilcox (2015), \"Aggregate Supply in the United States: Recent Developments and Implications for the Conduct of Monetary Policy,\" IMF Economic Review, vol. 63 (March), pp. 71-109. Return to text\n\n5. In the case of JPMorgan's acquisition of Bear Stearns, the Federal Reserve provided credit to support the transaction. In the case of Bank of America's acquisition of Merrill Lynch, Bank of America sought an arrangement that would ring fence any losses incurred by Merrill so as not to impose those losses on the parent company. The Federal Reserve publicly announced its willingness to negotiate such an arrangement. Although subsequent developments obviated the need for a ring fence arrangement, the public announcement was perceived as benefiting Bank of America during the period of extreme market uncertainty in late 2008. Return to text\n\n6. Wells Fargo benefited from a significant tax advantage in the Wachovia acquisition, while the Federal Deposit Insurance Corporation agreed to share some losses in the Washington Mutual portfolio in order to facilitate its acquisition by JPMorgan. Return to text\n\n7. Some have suggested that market-based measures of bank risk indicate that banks are not safer than before the crisis. For example, CDS spreads are well above their levels in early 2006. But this as likely suggests that investors were too sanguine in 2006 as that they believe there has been no change in bank safety since then. And, as reflected in the changes made by credit ratings agencies in their assessment of implied support for banks from the government, markets may rightly perceive that the government is less likely now to bail out a bank that gets in trouble. Moreover, equity prices may be down because some combination of economic conditions and regulation make profits likely to be lower than was expected and experienced in the unsustainable period leading up to the crisis. Return to text\n\n8. Core loans grew at an average annual rate of about 7 percent from 1995 to 2004. Core loan growth was 5.4 percent in 2014, 6.5 percent in 2015, and 7.1 percent thus far in 2016. Return to text\n\n9. In addition to increasing minimum capital ratios, post-crisis reforms also placed more emphasis on the quality of regulatory capital by introducing the common equity tier 1 capital ratio, which reflects the focus by bank investors and counterparties during the crisis on common equity. Return to text\n\n10. The reason why the non-G-SIB's probability of failure is higher is because its capital ratio requirement is lower without a surcharge. For an explanation of this \"expected impact\" methodology, see Board of Governors of the Federal Reserve System (2015), \"Calibrating the G-SIB Surcharge,\" white paper (Washington: Board of Governors of the Federal Reserve System, July 20). Return to text\n\n11. See Daniel K. Tarullo (2016), \"Next Steps in the Evolution of Stress Testing,\" speech delivered at the Yale University School of Management Leaders Forum, New Haven, CT, September 26. Return to text\n\n12. See Daniel K. Tarullo (2014), \"Rethinking the Aims of Prudential Regulation,\" speech delivered at the Federal Reserve Bank of Chicago Bank Structure Conference, Chicago, IL, May 8. Return to text\n\n13. Early assessments include Macroeconomic Assessment Group (2010), \"Assessing the Macroeconomic Impact of the Transition to Stronger Capital and Liquidity Requirements: Final Report (PDF) \" (Basel, Switzerland: Bank for International Settlements, December); and Basel Committee on Banking Supervision (2010), \"An Assessment of the Long-Term Economic Impact of Stronger Capital and Liquidity Requirements (PDF) \" (Basel, Switzerland: Bank for International Settlements, August). More recent assessments include William R. Cline (2016), \"Benefits and Costs of Higher Capital Requirements for Banks (PDF) ,\" Petersen Institute for International Economics Working Paper, no. 16-6 (March); and Ingo Fender and Ulf Lewrick (2016), \"Adding It All Up: The Macroeconomic Impact of Basel III and Outstanding Reform Issues (PDF) ,\" BIS Working Papers No. 591 (Basel, Switzerland: Bank for International Settlements, November). Return to text\n\n14. See Daniel K. Tarullo (2011), \"Regulating Systemically Important Financial Firms,\" speech delivered at the Peterson Institute for International Economics, Washington, DC, June 3. Return to text\n\n15. See, for example, Jihad Dagher, Giovanni Dell'Ariccia, Luc Laeven, Lev Ratnovski, and Hui Ton (2016), \"Benefits and Costs of Bank Capital,\" IMF Staff Discussion Note SND/16/04 (Washington: International Monetary Fund, March). Return to text\n\n16. For a discussion of the relationship between capital and liquidity standards, see Daniel K. Tarullo (2013), \"Evaluating Progress in Regulatory Reforms to Promote Financial Stability,\" speech delivered at the Peterson Institute for International Economics, Washington, DC, May 3. Return to text\n\n17. See Tarullo, \"Next Steps in the Evolution of Stress Testing.\" Return to text\n\n18. See, e.g., Daniel K. Tarullo (2016), opening remarks delivered at the Center for American Progress and Americans for Financial Reform Conference, Washington, DC, July 12, www.federalreserve.gov/newsevents/speech/tarullo20160712a.htm; and Daniel K. Tarullo (2015), \"Thinking Critically about Nonbank Financial Intermediation,\" speech delivered at the Brookings Institution, Washington, DC, November 17. Return to text\n\n19. See Amendments to the Capital Plan and Stress Test Rules, 81 Fed. Reg. 67,239-60 (September 30, 2016), www.gpo.gov/fdsys/pkg/FR-2016-09-30/pdf/2016-23629.pdf . Return to text\n\n20. See, for example, Daniel K. Tarullo, \"Rethinking the Aims of Prudential Regulation.\" Return to text"
    },
    {
        "speaker": "Lael Brainard",
        "position": "Governor",
        "date": "December 02, 2016",
        "title": "The Opportunities and Challenges of Fintech",
        "href": "https://www.federalreserve.gov/newsevents/speech/brainard20161202a.htm",
        "content": "December 02, 2016\n\nGovernor Lael Brainard\n\nAt the Conference on Financial Innovation at the Board of Governors of the Federal Reserve System, Washington, D.C.\n\nIntroduction\nOn behalf of the Board of Governors, I would like to welcome you to our conference on emerging financial technologies, or fintech. I'd like to begin by remembering our Federal Reserve colleague Teresa Curran--executive vice president and director of Supervision at the Federal Reserve Bank of San Francisco--who recently passed away after a long illness. Teresa's leadership on fintech was one of her many extraordinary contributions to the System. With her characteristic enthusiasm, Teresa helped us prioritize this topic early on and had a strong influence in helping shape our work program--with an emphasis on assessing the opportunities and challenges of fintech in a balanced way. We already miss her wise counsel here. I'm sure Teresa would have appreciated this conference's gathering of academics, industry participants, and policymakers to exchange information and discuss current research related to financial innovation.\n\nWhy Is Fintech Important?\nIn my remarks today, I'd like to share a few thoughts about emerging financial technologies and their relevance to our work.1 Fintech has the potential to transform the way that financial services are delivered and designed as well as the underlying processes of payments, clearing, and settlement.2 The past few years have seen a proliferation of new digitally enabled financial products and services, in addition to new processes and platforms. Just as smartphones revolutionized the way in which we interact with one another to communicate and share information, fintech may impact nearly every aspect of how we interact with each other financially, from payments and credit to savings and financial planning. In our continuously connected, on-demand world, consumers, businesses, and financial institutions are all eager to find new ways to engage in financial transactions that are more convenient, timely, secure, and efficient.\n\nIn many cases, fintech puts financial change at consumers' fingertips--literally. Today's consumers, particularly millennials, are accustomed to having a wide range of applications, options, and information immediately accessible to them. Almost every type of consumer transaction--ordering groceries, downloading a movie, buying furniture, or arranging childcare, to name a few--can be done on a mobile device, and there are often multiple different applications that consumers can choose for each of these tasks based on their preferences. It seems inevitable for this kind of convenience, immediacy, and customization to extend to financial services. Indeed, according to the Federal Reserve Board's most recent survey of mobile financial services, fully two-thirds of consumers between the ages of 18 and 29 having a mobile phone and a bank account use mobile banking.3\n\nNew fintech platforms are giving consumers and small businesses more real-time control over their finances. Once broad adoption is achieved, it is technologically quite simple to conduct cashless person-to-person fund transfers, enabling, among other things, the splitting of a check after a meal out with friends or the sending of remittances quickly and cheaply to friends or family in other countries. Financial management tools are automating savings decisions based on what consumers can afford, and they are helping consumers set financial goals and providing feedback on expenditures that are inconsistent with those goals. In some cases, fintech applications are automatically transferring spare account balances into savings, based on monthly spending and income patterns, effectively making savings the default choice. Other applications are providing consumers with more real-time access to earnings as they are accrued rather than waiting for their regular payday. This service may be particularly valuable to the nearly 50 percent of adults with extremely limited liquid savings.4 It is too early to know what the overall impact of these innovations will be, but they offer the potential to empower consumers to better manage cash flow to reduce the need for more expensive credit products to cover short-term cash needs.5\n\nOne particularly promising aspect of fintech is the potential to expand access to credit and other financial services for consumers and small businesses. By reducing loan processing and underwriting costs, online origination platforms may enable financial services providers to more cost effectively offer smaller-balance loans to households and small businesses than had previously been feasible.6 In addition, broader analysis of data may allow lenders to better assess the creditworthiness of potential borrowers, facilitating the responsible provision of loans to some individuals and firms that otherwise would not have access to such credit. In recent years, some innovative Community Development Financial Institutions (CDFIs) have developed partnerships with online alternative lenders, with the goal of expanding credit access to underserved small businesses.7\n\nThe challenge will be to foster socially beneficial innovation that responsibly expands access to credit for underserved consumers and small businesses, and those who otherwise would qualify only for high-cost alternatives. It would be a lost opportunity if, instead of expanding access in a socially beneficial way, some fintech products merely provided a vehicle to market high-cost loans to the underserved, or resulted in the digital equivalent of redlining, exacerbating rather than ameliorating financial access inequities.\n\nWe are also monitoring a growing fintech segment called \"regtech\" that aims to help banks achieve regulatory compliance more effectively. Regtech firms are designing new tools to assist banks and other financial institutions in addressing regulatory compliance issues ranging from onboarding new customers to consumer protection to payments and governance. Many of the current solutions are focused on Bank Secrecy Act (BSA) regulatory requirements, including know-your-customer (KYC) and suspicious activity reporting requirements. The solutions utilize new technologies and data-analytic techniques that may reduce the costs and time needed for banks to identify and assess customers' money-laundering and terrorist-financing risks. However, it is too early to tell the degree to which innovative approaches to customer due diligence, such as KYC utilities, will deliver efficiency gains such as those outlined in the recent Bank for International Settlements Committee on Payments and Market Infrastructures report on correspondent banking.8\n\nEnsuring Risks Are Managed and Consumers Are Protected\nWhile financial innovation holds promise, it is crucial that financial firms, customers, regulators, and other stakeholders understand and mitigate associated risks. There is a tension between the lightning pace of development of new products and services being brought to market--sometimes by firms that are new or have not historically specialized in consumer finance--and the duty to ensure that important risks around financial services and payments are addressed. Firms need to ensure that they are appropriately controlling and mitigating both risks that are unique to fintech as well as risks that exist independently of new technologies.\n\nFor example, some fintech firms are exploring the use of nontraditional data in underwriting and pricing credit products. While nontraditional data may have the potential to help evaluate consumers who lack credit histories, some data may raise consumer protection concerns. Nontraditional data, such as the level of education and social media usage, may not necessarily have a broadly agreed upon or empirically established nexus with creditworthiness and may be correlated with characteristics protected by fair lending laws. To the extent that the use of this type of data could result in unfairly disadvantaging some groups of consumers, it requires careful review to ensure legal compliance. In addition, while consumers generally have some sense of how their financial behavior affects their traditional credit scores, alternative credit scoring methods present new challenges that could raise questions of fairness and transparency. It may not always be readily apparent to consumers, or even to regulators, what specific information is utilized by certain alternative credit scoring systems, how such use impacts a consumer's ability to secure a loan or its pricing, and what behavioral changes consumers might take to improve their credit access and pricing.\n\nSimilarly, fintech innovations that rely on data sharing may create security, privacy, and data-ownership risks, even as they provide increased convenience to consumers. Recent examples of large-scale fraud and cybersecurity breaches have illustrated the significance of possible security risks. As the data sets that financial institutions utilize expand beyond traditional consumer credit histories, data privacy will become a growing concern, as will data ownership and whether or not the consumer has any say over how these data are used and shared or whether he or she can review it for accuracy. The Consumer Financial Protection Bureau recently issued a request for information to better understand the benefits and risks associated with new financial services that rely on access to consumer financial accounts and account-related information.9\n\nIn addition to the risks I have outlined that are specific to new financial technologies, firms also must control for risks that have always been present, even in brick-and-mortar financial institutions. For example, risks around the BSA and Anti-Money Laundering rules cut across all segments and all portfolios. Similarly, firms must monitor credit and liquidity risks of loans acquired or processed via fintech platforms, especially given that these products have not been tested over an economic cycle.\n\nFurthermore, as a general rule, the introduction of new products or services typically involves heightened risks as a financial institution enters into new areas with which it may not have experience or that may not be consistent with its overall business strategy and risk tolerance. Banks collaborating with fintech firms must control for the risks associated with the associated new products, services, and third-party relationships. When incorporating innovation that is consistent with a bank's goals and risk tolerance, bankers will need to consider which model of engagement is most appropriate in light of their business model and risk-management infrastructure, manage any outsourced relationships consistent with supervisory expectations,10 ensure that regulatory compliance considerations are included in the development of new products and services, and have strong fallback plans in place to limit the risks associated with products and partners that may not survive.\n\nWith the growing number of partnerships between banks and fintech companies, we often receive questions about the applicability of our vendor risk-management guidance. We are actively reviewing our guidance to determine whether any adjustments or clarifications may become appropriate in the context of these arrangements. We hear concerns from community bankers in particular about their internal capacity to undertake the requisite due diligence and ongoing vendor management on their own, especially with much larger vendors, and questions about whether the interagency service providers supervision program might be relevant in this context. We are thinking about whether changes brought about by fintech and fintech partnerships may warrant consideration of any changes to the interagency supervision program for service providers.\n\nRegulatory Engagement\nI believe that the Federal Reserve is well-positioned to help shape this innovation as it develops, and it is important that we be clear about our expectations and mindful of the possible effects of our actions. The policy, regulatory, and supervisory decisions made by the Federal Reserve and other financial regulators can impact the ways in which new financial technologies are developed and implemented, and ultimately how effective they are. It is critical that fintech firms and financial institutions comply with all applicable legal protections and obligations. At the same time, it is important that regulators and supervisors not impose undue burdens on financial innovations that would provide broad social benefits responsibly. An unduly rigid regulatory or supervisory posture could lead to unintended consequences, such as the movement of innovations outside of the regulated banking industry, potentially creating greater risks and less transparency.\n\nThe rapid pace of change and the large number of actors--both banks and nonbanks--in fintech raise questions about how to effectively conduct our regulatory and supervisory activities. In one sense, regulators' approach to fintech should be no different than for conventional financial products or services. The same basic principles regarding fairness and transparency should apply regardless of whether a consumer obtains a product through a brick-and-mortar bank branch or an online portal using a smartphone. Indeed, the same consumer laws and regulations that apply to products offered by banks generally apply to nonbank fintech firms as well, even though their business models may differ. However, the application of laws and regulations that were designed based on traditional financial products and delivery channels may give rise to complex or novel issues when applied to new products or new delivery channels. As a result, we are committed to regularly engage with firms and the technology to develop a shared understanding of these issues as they evolve.\n\nFundamentally, financial institutions themselves are responsible for providing innovative financial services safely. Financial services firms must pair technological know-how and innovative services with a strong compliance culture and a thorough knowledge of the important legal and compliance guardrails. While \"run fast and break things\" may be a popular mantra in the technology space, it is ill-suited to an arena that depends on trust and confidence. New entrants need to understand that the financial arena is a carefully regulated space with a compelling rationale underlying the various rules at play, even if these are likely to evolve over time. There is more at stake in the realm of financial services than in some other areas of technological innovation. There are more serious and lasting consequences for a consumer who gets, for instance, an unsustainable loan on his or her smartphone than for a consumer who downloads the wrong movie or listens to a bad podcast. At the same time, regulators may need to revisit processes designed for a brick-and-mortar world when approaching digital finance. To ensure that fintech realizes its positive potential, regulators and firms alike should take a long view, with thoughtful engagement on both sides.\n\nWhen we look back at times of financial crisis or missteps, we frequently find that a key cause was elevating short-term profitability over long-term sustainability and consumer welfare. It was not long ago that so-called exotic mortgages originally designed for niche borrowers became increasingly marketed to low- and moderate-income borrowers who could not sustain them, ultimately with disastrous results. In addition to the financial consequences for individual consumers, the drive for unsustainable profit can contribute to distrust in the financial system, which is detrimental to the broader economy. It is critical that firms providing financial services consider the long-term social benefit of the products and services they offer. Concerns regarding long-term sustainability are magnified in situations where banks may bear credit or other longer-term operational risks related to products delivered by a fintech firm. One useful question to ask is whether a product's success depends on consumers making ill-informed choices; if so, or if the product otherwise fails to provide sufficient value to consumers, it is not going to be seen as responsible and may not prove sustainable over time.\n\nThe key challenge for regulatory agencies is to create the right balance. Ultimately, regulators should be prepared to appropriately tailor regulatory or supervisory expectations, to the extent possible within our respective authorities, to facilitate fintech innovations that produce benefits for consumers, businesses, and the financial system. At the same time, any contemplated adjustments must also appropriately manage corresponding risks.\n\nFederal Reserve Fintech Engagement\nTo better understand technological changes in lending, payments, and other areas, the Federal Reserve has been engaging with a wide range of market participants to understand barriers to socially beneficial innovations. Our unique structure, with Board and Reserve Bank staff in over 30 locations, allows us to tap expertise in markets and innovation centers across the country to help establish channels of communication, including with nonbank participants with whom we may not otherwise have regular contact.\n\nThe Federal Reserve also engages in ongoing communication with other regulators to promote, to the greatest extent possible, consistency in approaches and alignment of supervisory requirements. Exchanging ideas and discussing fintech innovations with other regulators is critical to understanding and vetting risks and, where appropriate, reaching consistent views regarding the application of laws, regulations, or guidance.\n\nFinally, we recognize the value of technical expertise. With fintech, as with any other emerging financial product or service, the Federal Reserve is learning as much as we can to ensure that we have a robust understanding of the technologies and activities in which banks and other financial firms are engaging, and to inform the development of our policy and supervisory approaches. To that end, the Federal Reserve Board has established a multidisciplinary working group that is engaged in a 360-degree analysis of fintech innovation. We are bringing together the best thinking across the Federal Reserve System, spanning key areas of responsibility--from supervision to community development, from financial stability to payments--to assess the impact of technological development on the Federal Reserve's responsibilities. As part of this effort, Federal Reserve senior officials and staff have been closely watching developments in fintech, evaluating its impact on financial services delivery, and assessing the policy and supervisory implications in this arena.\n\nConclusion\nCurrent developments in the digitization of finance, including the establishment of new business models, are important and deserving of serious engagement on the part of policymakers and regulators. As policymakers, we want to facilitate innovation where it has the potential to yield broad social benefit, while ensuring that risks are thoroughly managed. In safeguarding the public interest, the first line of analysis and protection will always rest with the market participants closest to the new technologies and product innovations and to the organizations that consider adopting them. But regulators also should seek to analyze the implications of technology developments through constructive and timely engagement. We should be attentive to the potential social benefits of these new technologies, prepared to make the necessary regulatory adjustments if their safety and integrity are proven and their potential benefits found to be in the public interest, and vigilant to ensure risks are well understood and managed.\n\n\n\nI am grateful to Tracy Basinger, Carol Evans, Andrew Figura, Amy Henderson, and Marysol Weindorf for their assistance in preparing this text.\n\n1. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board. Return to text\n\n2. For a review of the potential of distributed ledger technologies to change payment, settlement, and clearance processes, see the forthcoming Federal Reserve Board Finance and Economics Discussion Series paper titled \"Distributed Ledger Technology in Payments, Clearing and Settlement.\" Return to text\n\n3. Board of Governors of the Federal Reserve, Consumers and Mobile Financial Services 2016 (PDF) (Washington: Board of Governors). Return to text\n\n4. The Federal Reserve Board's Survey of Household Economics and Decisionmaking finds that 46 percent of households report that they would need to borrow money or sell something in order to pay an unexpected expense of $400. The report of survey findings is available on the Board's website at https://www.federalreserve.gov/communitydev/shed.htm. Return to text\n\n5. Robo-advisors are making investing and retirement planning cheaper and more accessible, filling a particular need as the coverage of employer-provided retirement plans has declined. According to Insider Newsletter published by Willis Towers Watson (vol. 26, no. 2, February 2016), only 20 percent of Fortune 500 companies offered a defined-benefit plan to salaried new hires in 2015, down from 59 percent among the same employers in 1998. Return to text\n\n6. For more information on fintech and small business lending, see Karen Gordon Mills and Brayden McCarthy, “The State of Small Business Lending: Innovation and Technology and the Implications for Regulation (PDF) ,” Harvard Business School Working Paper (2016). Return to text\n\n7. Most recently, Regions Bank announced a partnership with Fundation, an online lender, and TruFund, a CDFI, to provide small-dollar loans to underserved small businesses (for more information, see http://ir.regions.com/releasedetail.cfm?ReleaseID=989068 ). In 2015, Lending Club and the Opportunity Fund, a California-based CDFI, announced a partnership intended to provide $10 million in loans over a period of five months to 400 small businesses in underserved areas of California (for more information, see www.opportunityfund.org/media/blog/clinton-announces-partnership-between-opportunity-fund-and-lending-club ). Return to text\n\n8. See www.bis.org/cpmi/publ/d147.pdf . Return to text\n\n9. See http://files.consumerfinance.gov/f/documents/112016_cfpb_Request_for_Information_Regarding_Consumer_Access_to_Financial_Records.pdf  The Consumer Financial Protection Bureau believes that \"consumers should be able to use their financial records and account information and securely share access in an electronic format.\" Return to text\n\n10. See Supervision and Regulation Letter 13-19/Consumer Affairs Letter 13-21, \"Guidance on Managing Outsourcing Risk.\" Return to text"
    },
    {
        "speaker": "Jerome H. Powell",
        "position": "Governor",
        "date": "November 30, 2016",
        "title": "A View from the Fed",
        "href": "https://www.federalreserve.gov/newsevents/speech/powell20161130a.htm",
        "content": "November 30, 2016\n\nGovernor Jerome H. Powell\n\nAt the \"Understanding Fedspeak\" event cosponsored by the Hutchins Center on Fiscal and Monetary Policy at the Brookings Institution and the Center for Financial Economics at Johns Hopkins University, Washington, D.C.\n\nWatch on-demand\n\nThanks to David Wessel and the Hutchins Center on Fiscal and Monetary Policy at the Brookings Institution for putting together this event.1 Today I will share my own views on the Federal Open Market Committee's (FOMC) public communications, which are designed to serve three important purposes. The first is to provide the transparency that enables the Congress and the public to hold the Committee accountable for its decisions on monetary policy. The second is to enhance the effectiveness of monetary policy. If the public understands the central bank's views on the economy and monetary policy, then households and businesses will take those views into account in making their spending and investment plans; policy will be more effective as a result. And the third is to show the full range of FOMC participants' views, even if doing so may sometimes make it difficult for the public to identify a consensus view. In my view, acknowledgment of this diversity of views is important in sustaining the public's support over time for the Federal Reserve as an institution--what Jon Faust refers to in his paper as our \"democratic legitimacy.\"2 In my comments, I will also react to Jon's thought-provoking and well-reasoned paper.\n\nThe Modern Era\nI will start with a brief tour of the modern era of FOMC communications, beginning with the issuance of the first postmeeting statement in February 1994.3 That statement contained four sentences and noted that the policy action was being announced immediately \"so as to avoid any misunderstanding of the Committee's purposes.\"4 The Committee took additional steps to enhance transparency over the next two decades by putting its target for the federal funds rate into the statement (July 1995); releasing statements after every meeting rather than only after meetings at which the Committee had changed its policy (May 1999); including voting information along with an explanation of dissents in the statement (March 2002); adding the first explicit forward-guidance language to the statement--the \"considerable period\" language (August 2003); and accelerating the release of the minutes after an FOMC meeting (December 2004).5\n\nThe pace of change accelerated notably after Ben Bernanke became Chairman in 2006. At that time, the Fed was said to be a bit of a communications laggard compared with some other central banks. Chairman Bernanke's agenda would move the FOMC to the forefront of transparency and accountability in modern central banking.\n\nIn October 2007, after extensive discussions and internal trial runs, the FOMC published its first Summary of Economic Projections (SEP), which built on the macroeconomic forecasts from the semiannual Monetary Policy Report to the Congress. Since then, SEP projections have been expanded to include longer-run values for real gross domestic product growth, the unemployment rate, headline PCE (personal consumption expenditures) price inflation, and the federal funds rate; assessments of uncertainty and risks to the economic outlook; and, of course, the federal funds rate projections, or \"dot plot,\" added in January 2012.6 An extensive write-up of the projections is included as an addendum to the meeting minutes. Finally, and perhaps most important, since April 2011, the Chair has held a quarterly press conference following the FOMC meetings at which SEP projections are collected.\n\nIn January 2012, the Committee first released its Statement on Longer-Run Goals and Monetary Policy Strategy, which is reaffirmed annually. This consensus statement serves as a quasi-constitutional document that clarifies that the Committee's inflation objective is 2 percent as measured by the annual change in the PCE price index, that this objective is symmetric, that the maximum level of employment is largely determined by nonmonetary factors affecting the structure and dynamics of the labor market, and that the Committee will take a balanced approach to promote its objectives of maximum employment and 2 percent inflation under circumstances in which the Committee judges that those objectives are not complementary.\n\nCompared with a decade ago, FOMC participants express their views more frequently through speeches and interviews, and our communications vehicles reveal a greater diversity of viewpoints. In FOMC meetings, as readers of our transcripts know, FOMC participants now speak longer than they did before 2006, and they typically make their remarks prior to hearing the policy views of the Chair. Since September 2010, the minutes have included paragraphs that reflect the views on monetary policy expressed by all meeting participants, not just those who vote on the policy decision. These changes, taken together with the SEP and the dot plot, have given greater emphasis to the diversity of views of Fed policymakers.\n\nDiscussion\nThe large size and unique structure of the FOMC have important implications for our communications. The Committee has seats for up to 19 participants, up to 12 of whom hold votes at any given time. Governors are appointed by the President and confirmed by the Senate. Reserve Bank Presidents are appointed by the Banks' private-sector board members who are not affiliated with commercial banks, subject to approval by the Board of Governors. This unique federated structure was designed to ensure a diversity of views, among other purposes. My strong view is that this institutionalized diversity of thinking is a strength of our System. My own experience is that the best outcomes are reached when opposing viewpoints are clearly and strongly presented before decisions are made. The Committee's diversity shows through most clearly at times such as these, when economic conditions have been particularly challenging and when there have been significant policy disagreements.\n\nOur communications are intended to enable the public to better understand how the Committee sees the economic situation and outlook, as well as what the Committee is likely to do if incoming data differ from that outlook--the Committee's \"reaction function.\" My sense is that market participants and other members of the public focus instead mainly on the timing of the next policy change or on how many policy moves will occur in a given year. It also seems that the public may not fully appreciate the uncertainty that surrounds the outlook. In addition, market participants often say that there are too many voices saying too many different things about policy--the cacophony problem. The dot plot has been a poor predictor of the Committee's actual policy path, and some have questioned its usefulness. However, markets do not appear to be unusually uncertain about FOMC decisions.7\n\nIn theory, our communications about monetary policy can be roughly divided into those that express the consensus and those that show the diversity of views. Today I will focus on the latter. Specifically, are communications that illustrate the diversity of views about the likely policy path--particularly the dot plot and public commentary by FOMC participants other than the Chair--currently serving us well? And if not, how can we make improvements?\n\nQuestions of how much to say about the likely path of policy were extensively debated in the public sphere in the years leading up to the Bernanke era, and by the FOMC while Ben was Chairman.8 The benefits of greater transparency are typically thought to include more efficient pricing of financial assets and a closer alignment between the market's views and those of the Committee.9 Transparency should allow asset prices to respond immediately to incoming economic data, which would foster progress toward the Committee's objectives. Those who supported the publication of some form of policy rate path generally saw it as part of a forecast-based approach to policymaking, in which policy plans depend in a complex way on policymakers' outlooks, risk assessments, and objectives.10 The whole forward interest rate curve matters for financial conditions, not just the overnight rate. Monetary policy was therefore thought to be made more effective by communication of the full expected path of policy, which could then be incorporated into private-sector expectations and longer-term interest rates. But all along, there have been other voices urging caution and asking, in effect, \"How much transparency is too much?\" As Don Kohn noted in 2005 remarks, \"more is not necessarily always better\" when it comes to Fed communication.11 Critics have often argued that too much discussion of the likely path of policy could be taken as a commitment to a particular path and timing and could ultimately constrain the Committee from pursuing what it views to be the optimal path. Indeed, to the extent that the Committee's talk about the path of policy is given weight, that talk may leave \"too little scope for private assessments of economic developments to show through\" in market prices.12\n\nJon notes in his paper that communications about monetary policy generally received high marks from 2008 through early 2013, and he focuses his analysis on the challenging period since mid-2013. I am also going to skip over the years 2013-14, which included the \"taper tantrum\" and the relatively uneventful taper itself. I will focus instead on the years 2015-16, which seem to me to be the most relevant to the challenges the Committee faces today. I will pay particular attention to the dot plot, the cacophony issue, and the need to do a better job of explaining uncertainty.\n\nThe Dot Plot\nThe dot plot is not a consensus forecast of the Committee. Rather, the dots represent each individual participant's assessment of the appropriate policy path. The Committee considered the use of a consensus forecast in 2012 but abandoned the effort after struggling to reach agreement on its parameters.13\n\nAs you can see from figure 1, the median dots have moved down from SEP to SEP. The December 2014 SEP median dots showed increases of 350 basis points over the years 2015-2017. In the event, there was one 25 basis point rate increase in 2015, and the September 2016 SEP median shows one more in 2016 and two in 2017--for a total of 100 basis points. Figures 2 and 3 display rate expectations derived from financial market prices and forecasts made by financial market participants, respectively. These market paths have also declined significantly over the period. And the path estimated from overnight index swaps (figure 2) has been substantially below the SEP median. It does not appear that markets have uncritically accepted the dots, let alone taken them as a commitment.14\n\nSome argue that the downward march of the dots has damaged the Committee's credibility. For me, the story is both more complicated and more interesting. Like Jon, I do not think of the dot plot as a useful predictor of near-term policy moves. But that is not to say that the dot plot is without value. Indeed, changes in the SEP and the dot plot over time have been quite revealing about the evolution of policymakers' views about the path of policy.\n\nIn recent years, FOMC participants have significantly revised their views about the values to which key economic variables will converge over the longer run. The same is true of many other economic forecasters. Since the beginning of 2012, participants' views about the longer-run annual growth potential of the economy have dropped from 2.45 percent to 1.85 percent (figure 4).15 Much of the downward revision in estimates of longer-run potential growth reflects the implications of demographic trends and the slowdown in productivity growth.16 These structural factors have also weighed on participants' assessments of the longer-run neutral federal funds rate--the rate that would be neither expansionary nor contractionary if the economy were operating near its potential.17 The median assessment of the longer-run neutral federal funds rate declined from 4.25 percent in 2012 to 2.90 percent in September of this year, with 60 basis points of that shift occurring just since September 2015 (figure 5). The persistence of low inflation despite faster-than-expected reductions in unemployment has also led participants to lower their estimates of the longer-run normal unemployment rate; the median estimate has declined from 5.60 percent in January 2012 to 4.85 percent in September 2016 (figure 6).\n\nTaken together, these revisions explain a good part of the downward movement of the dots. One way to see that is through the application of a policy rule, such as a Taylor rule.18 Simple policy rules, as they are sometimes called, incorporate key factors for monetary policy, including the natural rate of unemployment, the neutral rate of interest, and deviations of inflation and unemployment from their long-run values. As they prepare for FOMC meetings, FOMC participants routinely see policy recommendations from a variety of rules, including several Taylor rule variations. While these rules are useful as benchmarks, in my view they should not be excessively relied on for policy decisions.19\n\nThe red solid line in figure 7 shows the policy prescription using the original 1993 Taylor rule together with the September SEP dots for the federal funds rate.20 The Taylor rule prescription has been derived using the median value for core PCE price inflation, the unemployment rate, and the longer-run normal unemployment rate from the September 2016 SEP.\n\nThe intercept in this Taylor rule represents the longer-run real interest rate--or r*--which is set to 2 percent. If we replace that intercept with the median of the longer-run r* implied by the most recent SEP, which is 0.9 percent, we see that the rule prescribes much lower settings for policy interest rates than the unadjusted rule (the blue dashed line in figure 7). The lower intercept does not completely close the gap between the Taylor rule prescription and the dots. However, many observers believe that the neutral real interest rate is currently well below its longer-run value. The language that has appeared in the Committee's postmeeting statement since December 2015 that \"the federal funds rate is likely to remain, for some time, below levels that are expected to prevail in the longer run\" is consistent with this view.21\n\nWe can estimate a short-run, time-varying r* using a standard reduced-form IS (investment and saving) equation that relates the unemployment gap to its own lagged value and the lagged real interest rate gap. We use the median of FOMC participants' projections from the September SEP in this exercise. The IS specification employed here is similar to that used in Laubach-Williams (2003) and is shown in figure 8.22 Using these short-run, time-varying estimates of r* as intercepts in our Taylor rule gives us the purple dashed-dotted line in figure 9. This rule now tells us that the median dot remains slightly below the adjusted rule's prescription at the end of 2016 and 2017 but is back in line by the end of 2018.\n\nAs Don Kohn recently noted, \"We have been in uncharted waters with unreliable anchors.\"23 The downward march of the dots shows that policymakers have been learning, and our understanding of the economy has been evolving, as we navigate the treacherous shoals of the post-crisis economy. The revisions in the longer-run values and the short-run, time-varying r* estimates provide a framework for understanding policymakers' evolving views of the economy and of appropriate monetary policy. And the dots for 2016 and 2017 lie below the purple dashed-dotted line in figure 9, showing that FOMC participants see an even more gradual path of rate increases than suggested by the short-run r* estimates. This lower path may be related to global economic weakness and risk-management considerations at the effective lower bound. Of course, all of this would have happened in the absence of an SEP or a dot plot. The new communications tools have made the process more transparent to the public. In this sense, the dot plot is more messenger than message.\n\nCacophony\nI often hear that there are too many voices offering too much diversity of views about the likely path of policy--the cacophony problem. Reserve Bank Presidents and Governors are expected to publicly discuss their views on the economy and policy. Indeed, our policy on the external communications of FOMC participants states that \"the Committee's public accountability is strengthened by open discussion of Committee participants' views about the economic outlook as well as their judgments about the appropriate course of monetary policy.\"24 Central banking often comes across as obscure and complicated, and we try to help the public understand what we do. But there is more to it than that. Jon Faust's paper captures well the framers' vision of an institutionalized diversity of perspectives. In my view, the public expression of our diverse views helps sustain public support for the Federal Reserve as a public institution. Those members of the public who disagree with our policy should know that their concerns are given voice in our deliberations. But there is a tradeoff here that needs to be managed: On the one hand, the effectiveness of policy is thought to depend on the public's understanding of the Committee's consensus. On the other hand, the expression of diverse views may sometimes make it difficult for the public to see that consensus.\n\nJon sees this public discussion about policy as mainly a form of negotiation. In my view, motivations are simpler and more obvious. Many of us enjoy getting out of the office to speak to outside groups. We appear to enjoy talking to print journalists, and some of us like going on television. With the proliferation of media of all kinds, there is a need for content, and we have been willing suppliers. In my view, these public appearances are mostly not about gaining leverage in a negotiation. There is a single FOMC participant who has most of the leverage in our policy discussions. Observers would be well advised to listen carefully to what she says.\n\nI strongly agree with Jon that it is wise not to read too much about the path of policy into all of this communication. FOMC participants other than the Chair speak only for themselves and customarily make that clear at the beginning of their remarks. Their commentary is not intended to express the consensus or to predict its evolution.\n\nAs Jon notes, during the Greenspan era, there was very little discussion of the likely path for the policy rate by FOMC participants, including the Chairman. The proliferation of forward policy guidance during the crisis utterly broke that equilibrium. Many of us seem to be trained to a new habit, which is to offer one's views about the near-term path for policy, typically at the end of a speech on the outlook. While such communication can serve a useful purpose, I have come around to the view that focusing too much on the precise timing of policy moves may be adding to confusion and frustration about our communications. I am trying to avoid this problem in my own remarks.\n\nUncertainty\nAll economic forecasts are subject to considerable uncertainty. There is always a wide range of plausible outcomes for important economic variables, including the federal funds rate. In her remarks at Jackson Hole in August, Chair Yellen showed the median path for the federal funds rate from the June SEP surrounded by a 70 percent confidence interval based on the historical accuracy of private and government forecasts.25 I reproduce that figure here (figure 10), updated for the September 2016 SEP.26 Note that the tan confidence interval in the figure is much wider than the disparity of views as represented by the central tendency of the projections (the black dashed lines). This uncertainty is a fundamental aspect of our world, and it should probably feature more prominently in our communications.\n\nConclusion\nTo sum up, the FOMC and individual participants communicate a great deal these days--much more than in the past. Some of those communications are designed to express the consensus, and some are designed to show the diversity of views. In my view, communications should do more to emphasize the uncertainty that surrounds all economic forecasts, should downplay short-term tactical questions such as the timing of the next rate increase, and should focus the public's attention instead on the considerations that go into making policy across the range of plausible paths for the economy.\n\n\n\n1. The views I express here are my own. Return to text\n\n2. See Jon Faust (2016), \"Oh, What a Tangled Web We Weave: Monetary Policy Transparency in Divisive Times,\" paper prepared for \"Understanding Fedspeak,\" an event cosponsored by the Hutchins Center on Fiscal and Monetary Policy at the Brookings Institution and the Center for Financial Economics at Johns Hopkins University, held at the Brookings Institution, Washington, November 30. Return to text\n\n3. For a review FOMC communications, see Mark A. Wynne (2013), \"A Short History of FOMC Communication (PDF),\" Economic Letter, vol. 8 (Dallas: Federal Reserve Bank of Dallas, September). Return to text\n\n4. See Board of Governors of the Federal Reserve System (1994), FOMC statement, press release, February 4, paragraph 3. Return to text\n\n5. The expedited release shortened the lag between an FOMC meeting and the publication of the meeting minutes between two and five weeks. See Deborah J. Danker and Matthew M. Luecke (2005), \"Background on FOMC Meeting Minutes (PDF),\" Federal Reserve Bulletin, vol. 91 (Spring), pp. 175-79. Return to text\n\n6. The \"dot plot\" is a figure that provides individual policymaker assessments of appropriate monetary policy as defined by the value of the federal funds rate target or the midpoint of the federal funds rate target range at the end of each calendar year of the SEP forecast. Return to text\n\n7. See, for example, David Mericle (2016), US Daily: The Fed and the Markets: A Failure to Communicate? (New York: Goldman Sachs, September 20). Return to text\n\n8. See Alan S. Blinder, Michael Ehrmann, Marcel Fratzscher, Jakob De Haan, and David-Jan Jansen (2008), \"Central Bank Communication and Monetary Policy: A Survey of Theory and Evidence,\" Journal of Economic Literature, vol. 46 (December), pp. 910-45. Return to text\n\n9. See Ben S. Bernanke (2004), \"Central Bank Talk and Monetary Policy,\" speech delivered at the Japan Society Corporate Luncheon, New York, October 7. Return to text\n\n10. See Ben S. Bernanke (2004), \"The Logic of Monetary Policy,\" speech delivered at the National Economists Club, Washington, December 2. Return to text\n\n11. See Donald L. Kohn (2005), \"Central Bank Communication,\" speech delivered at the Annual Meeting of the American Economic Association, Philadelphia, January 9, paragraph 5. Return to text\n\n12. Quote taken from Kohn, \"Central Bank Communication,\" paragraph 12, in note 10. This point has been emphasized in work by Stephen Morris and Hyun Shin. See, for example, Jeffery D. Amato, Stephen Morris, and Hyun Song Shin (2002), \"Communication and Monetary Policy,\" Oxford Review of Economic Policy, vol. 18 (December), pp. 495-503. Return to text\n\n13. According to the minutes from the October 22-23, 2012, FOMC meeting, \"In their discussion, participants agreed that FOMC communications could be enhanced by clarifying the linkage between participants' economic forecasts, including the underlying policy assumptions, and the Committee's policy decision as expressed in the postmeeting statement. However, most participants judged that, given the diversity of their views about the economy's structure and dynamics, it would be difficult for the Committee to agree on a fully specified longer-term path for monetary policy to incorporate into a quantitative consensus forecast in a timely manner, especially under present conditions in which the policy decision comprises several elements.\" See Board of Governors of the Federal Reserve System (2012), \"Minutes of the Federal Open Market Committee, October 23-24, 2012,\" press release, November 14, paragraph 52. Return to text\n\n14. The expected policy rate paths shown in figures 1, 2, and 3 are not entirely comparable. The SEP paths are median values of the modal projections of individual participants for the end of the calendar year. The overnight index swap (OIS) paths are estimated using a spline approach; each line corresponds to the estimated path on the day before the release of SEP projections. OIS paths are mean forecasts of market participants and may be influenced by variations in risk premiums over time. The primary dealer survey paths are medians of modal forecasts, and the survey responses are collected about a week before the SEP projections are released. Return to text\n\n15. Other forecasters--for instance, Blue Chip and the Survey of Professional Forecasters--have also revised down their estimates for longer-run real gross domestic product (GDP) growth. See Jerome H. Powell (2016), \"Recent Economic Developments, the Productive Potential of the Economy, and Monetary Policy,\" speech delivered at the Peterson Institute for International Economics, Washington, May 26. In making these comparisons, I use the midpoint of the central tendency for real GDP growth and the unemployment rate. Return to text\n\n16. See John G. Fernald (2015), \"Productivity and Potential Output before, during, and after the Great Recession,\" in Jonathan A. Parker and Michael Woodford, eds., NBER Macroeconomics Annual 2014, vol. 29 (Chicago: University of Chicago Press), pp. 1-51; and Etienne Gagnon, Benjamin K. Johannsen, and David Lopez-Salido (2016), \"Understanding the New Normal: The Role of Demographics (PDF),\" Finance and Economics Discussion Series 2016-080 (Washington: Board of Governors of the Federal Reserve System, October). Return to text\n\n17. For further discussion of the neutral nominal federal funds rate, see Janet L. Yellen (2015), \"The Economic Outlook and Monetary Policy,\" speech delivered at the Economic Club of Washington, Washington, December 2. Return to text\n\n18. See Fernanda Nechio and Glenn D. Rudebusch (2016), \"Has the Fed Fallen behind the Curve This Year?  \" FRBSF Economic Letter 2016-33 (San Francisco: Federal Reserve Bank of San Francisco, November). Return to text\n\n19. For example, FRB/US simulations using the Taylor (1993) rule for the period 2010-15 show substantially higher unemployment and lower inflation than was actually realized. For more information about the Taylor (1993) rule, see John B. Taylor (1993), \"Discretion versus Policy Rules in Practice,\" Carnegie-Rochester Conference Series on Public Policy, vol. 39 (December), pp. 195-214. Return to text\n\n20. The SEP policy projections are for the midpoint of the federal funds rate target range at the end of a calendar year. The Taylor (1993) rule is defined as Rt = 2 + πt + 0.5(πt – 2) + 0.5Yt. In this expression, R is the federal funds rate, π is the percent change in the core PCE price index from four quarters earlier, and Y is the output gap. The rule used here is in terms of the unemployment gap instead of the output gap. The output gap is approximated using Okun's law; specifically, Yt = 2.0(U* – Ut), where U is the unemployment rate and U* is the non-accelerating inflation rate of unemployment, or NAIRU. Return to text\n\n21. See, for example, Board of Governors of the Federal Reserve System (2016), \"Federal Reserve Issues FOMC Statement,\" press release, November 2, paragraph 4. Return to text\n\n22. For a discussion of the short-run, time-varying estimates of r* using projections from the SEP, see Michelle Bongard and Benjamin K. Johannsen (2016), \"The Neutral Rate and the Summary of Economic Projections,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, November 28). These authors combine the IS specification used here with SEP projections to calculate implied values for r*. See also Thomas Laubach and John C. Williams (2003), \"Measuring the Natural Rate of Interest,\" Review of Economics and Statistics, vol. 85 (November), pp. 1063-70. Return to text\n\n23. See Donald Kohn (2016), \"How Should Central Bankers Talk about Future Monetary Policy? Lessons from the Crisis and Beyond (PDF) ,\" (Washington: Hutchins Center on Fiscal and Monetary Policy, Brookings Institution, November). Return to text\n\n24. The FOMC Policy on External Communications of Committee Participants was adopted in June 2011 and is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/files/FOMC_ExtCommunicationParticipants.pdf; for the quoted text, see p. 1. Return to text\n\n25. The reason for the confidence interval is that the economy is frequently buffeted by shocks and thus rarely evolves as predicted. See Janet L. Yellen (2016), \"The Federal Reserve's Monetary Policy Toolkit: Past, Present, and Future,\" speech delivered at \"Designing Resilient Monetary Policy Frameworks for the Future,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 26. Return to text\n\n26. The confidence interval equals the median SEP path for the federal funds rate plus or minus average root mean squared prediction errors of the three-month Treasury bill rate (subject to a lower bound of 12.5 basis points), for horizons from zero to three years ahead, based on forecast errors made over the past 20 years. For general information on the methodology used to construct confidence intervals using historical forecasting errors, see David Reifschneider and Peter Tulip (2007), \"Gauging the Uncertainty of the Economic Outlook from Historical Forecasting Errors ,\" Finance and Economics Discussion Series 2007-60 (Washington: Board of Governors of the Federal Reserve System, November). Return to text"
    },
    {
        "speaker": "Jerome H. Powell",
        "position": "Governor",
        "date": "November 29, 2016",
        "title": "Recent Economic Developments and Longer-Run Challenges",
        "href": "https://www.federalreserve.gov/newsevents/speech/powell20161129a.htm",
        "content": "November 29, 2016\n\nGovernor Jerome H. Powell\n\nAt the The Economic Club of Indiana, Indianapolis, Indiana\n\nThank you for the opportunity to speak here today. My plan is to discuss the U.S. economy from three different perspectives. I will start by taking stock of the current expansion--a business cycle point of view. Then I will shift the focus to some of the longer-term challenges we face in coming years. I will conclude with a discussion of monetary policy. As always, the views I express here today are mine alone.\n\nThe Current State of the Economy\nAs you know, the Congress has tasked the Federal Reserve with achieving stable prices and maximum employment--the dual mandate. Today, we are not far from achieving those goals.\n\nThe Federal Open Market Committee (FOMC) has an objective of 2 percent for inflation, as measured by the annual change in the price index for personal consumption expenditures. The Committee sees this objective as symmetrical, so that minor deviations above or below 2 percent are treated alike.1 Inflation has consistently run below 2 percent since 2011, and is now at 1.2 percent over the past 12 months (figure 1). This headline measure of inflation has recently been held down by falling energy and food prices. We also monitor core inflation, which excludes the volatile energy and food components because they often send a misleading signal about underlying inflation pressures. Core inflation is running at 1.7 percent over the past 12 months. Both measures have gradually moved upward toward 2 percent.\n\nU.S. inflation trended steadily lower after the Volcker disinflation of 1981 to 1982 and has been low and reasonably stable for many years. In fact, for the past several years inflation has run below policy targets in many parts of the world, including here in the United States. Many of us are old enough to remember when the only challenge was to keep inflation low. But too-low inflation can also be a serious problem. Below-target inflation increases the real value of debts owed by households and businesses and reduces the ability of central banks to respond to downturns.\n\nThe public's expectations about inflation are thought to be an important driver of actual inflation. Many measures of U.S. inflation expectations--both from surveys and from market-based readings--are still well below their pre-crisis levels, although some have moved up as of late. The only way to ensure that inflation expectations remain safely anchored near the FOMC's target is to keep inflation close to that target on a consistent basis. So, while the current shortfall may seem small, it is important that inflation continue to move up to 2 percent, as I expect it will.\n\nThe FOMC does not have a numerical goal for maximum employment because the long-run sustainable level of employment changes over time and is determined mainly by nonmonetary factors that are outside the Fed's control, such as evolving labor market practices, demographics, social change, and fiscal and regulatory policies. Nonetheless, four times each year FOMC participants write down their estimates of the longer-run normal level of the unemployment rate (the natural rate); at the September FOMC meeting the median estimate was 4.8 percent, very close to the current unemployment rate of 4.9 percent.\n\nOther labor market measures are also healthy, including payroll job creation and labor force participation. Employers have been adding roughly 180,000 jobs per month so far this year--a pace a little below that of the past several years but significantly higher than underlying growth in the labor force (figure 2). Despite these strong job gains, the unemployment rate has flattened out this year after several years of sharp declines, thanks to welcome developments in labor force participation (figure 3).\n\nThe labor force participation rate represents the percentage of adults aged 16 and over who are in the labor force, which is defined to include only those who are employed or actively looking for work. When people enter or reenter the labor force and begin to search for a job, that is generally a good thing even though at the margin their entry tends to increase the unemployment rate (or prevent it from declining). Beginning in the 1960s, labor force participation rose steadily as women entered the paid workforce (figure 4). That trend ran its course as participation peaked around 2000 and has declined steadily since then as a result of the aging of our population and other longer-run trends, notably the decline in participation by men in the heart of their working-age years. Going forward, many analysts expect labor force participation to decline at a trend rate of roughly 0.3 percent per year as a result of these factors. However, participation fell much more sharply than that after the financial crisis. Some of those who left the labor force went back to school, but others moved onto disability, took early retirement, or just became discouraged and stopped seeking work. The sharp drop raised fears that the crisis might leave behind permanent damage to our labor force. Fortunately, since late 2013, the participation rate has remained about flat and thus has gradually moved back close to its estimated longer-term trend.2 On net, people have been entering and remaining in the labor market as job prospects have brightened, offsetting the natural decline from population aging.\n\nSurveys of households and firms also suggest that we are near full employment (figure 5). For example, respondents are now more likely to say that jobs are plentiful than that they are hard to get--a response that has generally been seen when the economy is near full employment. Job vacancies are running at high levels, and firms report that it is getting harder to find employees to fill open positions. Moreover, wages are now rising faster than inflation, and faster than output per hour. Taken together, labor market indicators show an economy that is on solid footing and close to our mandate of maximum employment.\n\nIt is interesting to compare this expansion to past U.S. expansions, and also to recoveries of other countries since the end of the Global Financial Crisis. The picture is a mixed one. The current recovery has been under way since June 2009--nearly seven and a half years. It will soon be the third longest of the 20 recoveries since the founding of the Federal Reserve in 1913. GDP, or output, is now 11 percent higher than its pre-crisis peak. Employment is now 6.5 million higher than its pre-crisis peak.\n\nBut this expansion has also had the slowest pace of GDP growth of any postwar recovery (figure 6). Given steady but modest growth, we have seen surprisingly large gains in employment and, until this year, a rapid reduction in the unemployment rate. Even though GDP growth has been slow, job gains during this recovery have been stronger than those during the previous expansion--the so-called jobless recovery of the early 2000s. The combination of weak growth and strong hiring in this expansion implies small increases in output per hour, or productivity. In fact, productivity has been increasing at a dismal pace, compared with virtually any period in the postwar era. I will return to productivity and growth in a moment.\n\nMore positively, our current recovery compares fairly well with those of other advanced economies (figure 7). Output has increased faster, and unemployment has declined faster, in the United States than in other major advanced economies. And the Fed's challenges in getting inflation back up to 2 percent are similar to, but not as severe as, those faced by some other major monetary authorities.\n\nTurning to the near-term outlook, after a slow patch in the first half of this year, growth has clearly strengthened. I expect that the economy will continue on its path of the last few years, with real GDP growth of about 2 percent, strong job gains, a tightening labor market, and inflation moving up toward our 2 percent objective. The main risks I see to that outlook are from abroad. Growth and inflation are low around the world. With interest rates so low, we are not well positioned to respond to negative shocks, whatever the source.\n\nLonger-Run Challenges\nProductivity and Growth\n\nLet's turn to longer-run challenges, and start by asking why growth has been so slow, and how fast we are likely to grow going forward. This next slide shows the five-year trailing average annual real GDP growth rate (figure 8). By this measure, growth averaged about 3.2 percent annually through the 1970s, the 1980s, and the 1990s. But growth began to decline after 2000 and then nose-dived with the onset of the Global Financial Crisis in 2007 and the slow expansion that followed. Since the financial crisis ended in 2009, forecasters have gradually reduced their estimates of long-run trend growth from about 3 percent to about 2 percent--a seemingly small difference that would make a huge difference in living standards over time.3\n\nHow much of this decline is just a particularly bad business cycle, and how much represents a long-run downshift? To get at that question, let's take a deeper look at the growth slowdown. We can think of economic growth as coming from two sources: more hours worked (labor supply) or higher output per hour (productivity). Hours worked mainly depends on growth in the labor force, which has been slowing since the mid-2000s as the baby-boom generation ages. As you can see, the labor force is now growing at only about 0.5 percent per year (figure 9). Another way to see this is through the sustained increase in the ratio of people over 65 to those who are in their prime working years (figure 10). This long-expected demographic fact has now arrived, and it has challenging implications for our potential growth and also for our fiscal policy.4\n\nThe unexpected part of the growth slowdown reflects weak productivity growth rather than lower labor supply. Labor productivity has increased only 1/2 percent per year since 2010--the smallest five-year rate of increase since World War II and about one-fourth of the average postwar rate (figure 11). The slowdown in productivity has been worldwide and is evident even in countries that were little affected by the crisis (figure 12). Given the global nature of the phenomenon, it is unlikely that U.S.-specific factors are mainly responsible.\n\nA portion of the productivity slowdown is undoubtedly due to low levels of investment by businesses. The financial crisis and the Great Recession left firms with excess capacity, reducing incentives to invest. If businesses expect slower growth to continue, that will also hold down investment.\n\nThe other important factor is the decline in what economists call total factor productivity, or TFP, which is the part of productivity that is not explained by capital investment or increases in the skills of the labor force. TFP is thought to be mainly a function of technological innovation and efficiency gains.\n\nThere is no consensus about the future direction of productivity.5 The pessimists argue that the big paradigm-changing innovations, such as electrification or the advent of computers, are behind us. If that is so, then our standard of living will increase more slowly going forward. The optimists think that this slowdown is only a passing phase and that the age of robots and machine learning will transform our economy in coming decades. Still others argue that we are currently underestimating productivity and output because of the real difficulties we face in measuring GDP in a modern economy. For example, how do we measure the value-added of free digital services like Facebook or Twitter?6\n\nThe future is, as always, uncertain. But I would sum up the growth discussion as follows. Growth in the labor force has slowed, and we can estimate it with reasonable confidence to be only about 0.5 percent. Growth in productivity is both more important and much harder to predict. Productivity varies significantly over time, as figure 11 showed. If productivity growth returns to, say, 1.5 percent, then the U.S. economy could grow at about 2.0 percent over the long term. Actual growth may turn out to be weaker or stronger, and the choices we make as a society will have something to say about that.\n\nWhy Are Long-Term Interest Rates So Low?\n\nLet's turn to the related question of why long-term interest rates are so extraordinarily low in advanced economies around the world. The yield on our own benchmark 10-year U.S. Treasury security has increased lately, but at 2.3 percent it is still far below what was normal before the financial crisis. In fact, this next chart shows that, as growth and inflation have fallen, longer term interest rates have fallen as well over the past 35 years (figure 13).\n\nSo why are long-term interest rates so low? Many of you will no doubt be thinking, \"They are low because you people at the Fed set them low!\" While there is an element of truth there, that is not the whole story. The FOMC has considerable control over short-term interest rates. We have much less influence over long-term rates, which are set in the marketplace. Long-term interest rates represent the price that balances the supply of saving by lenders and demand for funds by borrowers, such as businesses needing to fund their capital expenditures. Lenders expect to receive a real return and to be compensated for inflation and for the risk of nonpayment. Meanwhile, borrowers adjust their demand for funds based on their changing assessment of the risks and expected returns of their investment projects. When desired saving rises or investment demand falls, then long-term interest rates will decline. Today's very low level of long-term rates suggests that both of these factors are at play.\n\nBoth expectations of slower growth and the aging of our population are having significant effects on desired saving and investment and are thus important causes of lower interest rates. If the economy is expanding more slowly, then the level of investment needed to meet demand will be lower. The lower path of growth reduces future income prospects of households, and they will tend to raise their saving. The pending retirement of baby boomers means higher saving, because people tend to save the most in the years just before their retirement. In addition, the lower rate of return on capital owing to lower productivity growth will lead to less investment and lower interest rates.\n\nAs with productivity, the factors behind the fall in U.S. interest rates include an important global component, as rates are low around the world. Indeed, although our rates are near historical lows, U.S. Treasury rates are among the highest among the major advanced economy sovereigns (figure 14).\n\nIs This the New Normal?\n\nWhat can we do to prevent low growth, low inflation, and low interest rates from becoming the new normal? We need to focus on ways to increase our long-term growth and spread that prosperity as broadly as possible. I hasten to add that these policies are, for the most part, outside the purview of the Federal Reserve. We need policies that support productivity growth, business hiring and investment, labor force participation, and the development of skills. We need effective fiscal and regulatory policies that inspire public confidence. Increased spending on public infrastructure may raise private-sector productivity over time, particularly with the growth of the stock of public infrastructure near an all-time low.7 Greater support for public and private research and development, and policies that improve product and labor market dynamism may also be fruitful.8 Monetary policy can contribute by supporting a strong and durable expansion in a context of price stability.\n\nMonetary Policy\nThe low interest rate environment presents special challenges for monetary policy. In setting our target for the federal funds rate, a good place to start is to identify the rate that would prevail if the economy were at 2 percent inflation and full employment--the so-called neutral rate. \"Neutral\" in this context means that the rate is neither contractionary nor expansionary. If the fed funds rate is lower than the neutral rate, then policy is stimulative or accommodative, which will tend to raise growth and inflation. If the fed funds rate is higher than the neutral rate, then policy is tight and will tend to slow growth and reduce inflation.\n\nBut we can only estimate the neutral rate, and those estimates are subject to substantial uncertainty. Before the crisis, the long-run neutral rate was generally thought to be roughly stable at around 4.25 percent. Since the crisis, estimates have steadily declined, and the median estimate by FOMC participants stood at 2.9 percent in September. Many analysts believe that the neutral rate is even lower than that today and will only return to its long-run value over time.9 The low level of the neutral interest rate has several important implications. First, today's low rates are not as stimulative as they seem--consider that, despite historically low rates, inflation has run consistently below target and housing construction remains far below pre-crisis levels. Second, with rates so low, central banks are not well positioned to counteract a renewed bout of weakness. Third, persistently low interest rates can raise financial stability concerns. A long period of very low interest rates could lead to excessive risk-taking and, over time, to unsustainably high asset prices and credit growth. These are risks that we monitor carefully. Higher growth would increase the neutral rate and help address these issues.\n\nTurning to the outlook for monetary policy, incoming data show an economy that is growing at a healthy pace, with solid payroll job gains and inflation gradually moving up to 2 percent. In my view, the case for an increase in the federal funds rate has clearly strengthened since our previous meeting earlier this month. Of course, the path of rates will depend on the path of the economy. With inflation below target, relatively slow growth, and some slack remaining in the economy, the Committee has been patient about raising rates. That patience has paid dividends. But moving too slowly could eventually mean that the Committee would have to tighten policy abruptly to avoid overshooting our goals.\n\nConclusion\nTo wrap up, since the end of the Great Recession in 2009, our economy has recovered slowly but steadily. Today, we are reasonably close to achieving full employment and our 2 percent inflation objective. But we face real challenges over the medium and longer terms. Our aging population will mean slower growth, all else held equal. If living standards are to continue to rise, we need policies that will support productivity and allow our dynamic economy to generate widespread gains in prosperity.\n\n1. See the FOMC's \"Statement on Longer-Run Goals and Monetary Policy Strategy (PDF),\" FOMC, January 26, 2016. Return to text\n\n2. The current participation rate is within the range of estimates cited in Stephanie Aaronson, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014), \"Labor Force Participation: Recent Developments and Future Prospects (PDF) ,\" Brookings Papers on Economic Activity, Fall, pp. 197-275. Return to text\n\n3. See Jerome H. Powell (2016), \"Recent Economic Developments, the Productive Potential of the Economy, and Monetary Policy,\" speech delivered at the Peterson Institute for International Economics, Washington, D.C., May 26. Return to text\n\n4. Congressional Budget Office (2016), The 2016 Long-Term Budget Outlook (PDF) , (Washington: CBO, July). Return to text\n\n5. On the pessimistic end of the spectrum are analysts such as Robert Gordon, The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War (Princeton University Press, 2016). Among the optimists are Erik Brynjolfsson and Andrew McAfee, The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies (W. W. Norton & Company, 2014). Return to text\n\n6. See David M. Byrne, John G. Fernald, and Marshall B. Reinsdorf (2016), \"Does the United States Have a Productivity Slowdown or Measurement Problem? \" Brookings Papers on Economic Activity, March 4. Return to text\n\n7. See, for example, Abdul Abiad, Davide Furceri, and Petia Topalova (2014), \"IMF Survey: The Time Is Right for an Infrastructure Push ,\" World Economic Outlook (Washington: International Monetary Fund, October). Return to text\n\n8. See, for example, International Monetary Fund (2016), \"Acting Now, Acting Together ,\" Fiscal Monitor (Washington: IMF, April); Ryan A. Decker, John Haltiwanger, Ron S. Jarmin, and Javier Miranda (2016), \"Declining Business Dynamism: What We Know and the Way Forward ,\" American Economic Review, vol. 106 (May), pp. 203-07; Steven Davis and John Haltiwanger (2014), \"Labor Market Fluidity and Economic Performance,\" NBER Working Paper Series 20479 (Cambridge, Mass: National Bureau of Economic Research, September); The Department of the Treasury Office of Economic Policy, the Council of Economic Advisers, and the Department of Labor (2015), \"Occupational Licensing: A Framework for Policymakers (PDF) \" (Washington: The White House, July). Return to text\n\n9. See, for example, Kathryn Holston, Thomas Laubach, and John Williams (2016), \"Measuring the Natural Rate of Interest: International Trends and Determinants (PDF) ,\" Federal Reserve Bank of San Francisco Working Paper 2016-11 (August); Benjamin K. Johannsen and Elmar Mertens (2016), \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound ,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, February 9), http://dx.doi.org/10.17016/2380-7172.1703. Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "November 21, 2016",
        "title": "Longer-Term Challenges for the U.S. Economy",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20161121a.htm",
        "content": "November 21, 2016\n\nVice Chairman Stanley Fischer\n\nAt \"A Conversation with Stanley Fischer,\" sponsored by the Council on Foreign Relations, New York, New York\n\nWatch live: http://www.cfr.org/monetary-policy/conversation-stanley-fischer/p38477\n\nNotwithstanding a number of shocks over the past year, the U.S. economy is performing reasonably well. Job gains have been robust in recent years, and the unemployment rate has declined to 4.9 percent, likely close to its long-run sustainable level. After running at a subdued pace during the first half of the year, gross domestic product growth has picked up in the most recent data, and inflation has been firming toward the Federal Open Market Committee's 2 percent target.1\n\nAlthough the economy has moved back to the vicinity of the Committee's employment and inflation targets--suggesting that the cyclical drag on the economy has been greatly reduced, if not largely eliminated--along some dimensions this has not been a happy recovery. Unease with the economy reflects a number of longer-term challenges, challenges that will require a different set of policy tools than those used to address nearer-term cyclical shortfalls in growth. Prominent among these challenges are low equilibrium interest rates and sluggish productivity growth in the United States and abroad. I will first touch on low interest rates before turning to productivity. The federal funds rate and policy rates in other advanced economies remain very low or even negative. Longer-term rates are also low by historical standards, even taking into account the increase of the past two weeks.\n\nSuch low interest rates, together with only tepid growth, suggest that the equilibrium interest rate--that is, the rate that neither boosts nor slows the economy--has fallen. Why does this matter? Importantly, low interest rates make the economy more vulnerable to adverse shocks by constraining the ability of monetary policy to combat recessions using conventional interest rate policy--because the effective lower bound on the interest rate means that monetary policy has less room to reduce the interest rate when that becomes necessary. Also, low equilibrium rates could threaten financial stability by encouraging a reach for yield and compressing net interest margins, although it is important to point out that so far we have not seen evidence that low rates have notably increased financial vulnerabilities in the U.S. financial system. More fundamentally, low equilibrium real rates could signal that the economy’s long-run growth prospects are dim.\n\nWhy are interest rates so low?2 In a speech last month, I identified a number of factors that have worked to boost saving, depress investment, or both. Among the factors holding down interest rates is the sluggishness of foreign economic growth. Another is demographics, with saving being higher as a result of an increase in the average age of the U.S. population. Also, investment recently has been weaker than might otherwise be expected, perhaps reflecting uncertainty about longer-run growth prospects, as well as the decline in investment in the energy sector as a result of the fall in the price of oil. Finally, and most important, weak productivity growth has likely pushed down interest rates both by lowering investment, as firms lower their expectations for the marginal return on investment, and by increasing saving, as consumers lower their expectations for income growth and borrow less and/or save more as a consequence.\n\nUnderstanding the recent weakness of productivity growth is central to addressing the longer-run challenges confronting the economy. Productivity growth over the past decade has been lackluster by post-World War II standards. Output per hour increased only 1-1/4 percent per year, on average, from 2006 to 2015, compared with its long-run average of 2-1/2 percent from 1949 to 2005. This halving of productivity growth, if it were to persist, would have wide-ranging consequences for living standards, wage growth, and economic policy more broadly. A number of explanations have been offered for the decline in productivity growth, including mismeasurement in the official statistics, depressed capital investment, and a falloff in business dynamism, with reality likely reflecting some combination of all of these factors and more.\n\nWe should also consider the possibility that weak demand has played a role in holding back productivity growth, although standard economic textbooks generally trace a path from productivity growth to demand rather than vice versa. Chair Yellen recently spoke on the influence of demand on aggregate supply.3 In her speech, she reviewed a body of literature that suggests that demand conditions can have persistent effects on supply.4 In most of the literature, these effects are thought to occur through hysteresis in labor markets. But there are likely also some channels through which low aggregate demand could affect productivity, perhaps by lowering research-and-development spending or decreasing the pace of firm formation and innovation. I believe that the relationship between productivity growth and the strength of aggregate demand is an area where further research is required.\n\nI will conclude by reiterating one aspect of the low interest rate and low productivity growth problems that I have mentioned previously--the fact that, for several years, the Fed has been close to being \"the only game in town,\" as Mohamed El-Erian described it in his recent book.5 But macroeconomic policy does not have to be confined to monetary policy. Certain fiscal policies, particularly those that increase productivity, can increase the potential of the economy and help confront some of our longer-term economic challenges. While there is disagreement about what the most effective policies would be, some combination of improved public infrastructure, better education, more encouragement for private investment, and more effective regulation all likely have a role to play in promoting faster growth of productivity and living standards. By raising equilibrium interest rates, such policies may also reduce the probability that the economy, and the Federal Reserve, will have to contend more than is necessary with the effective lower bound on interest rates.\n\n1. Views expressed are mine and are not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See Stanley Fischer (2016), \"Why Are Interest Rates So Low? Causes and Implications,\" speech delivered at the Economic Club of New York, New York, October 17. Return to text\n\n3. See Janet L. Yellen (2016), \"Macroeconomic Research after the Crisis,\" speech delivered at \"The Elusive 'Great' Recovery: Causes and Implications for Future Business Cycle Dynamics,\" 60th annual economic conference, held at the Federal Reserve Bank of Boston, Boston, October 14. Return to text\n\n4. See, for example, Olivier Blanchard, Eugenio Cerutti, and Lawrence Summers (2015), \"Inflation and Activity--Two Explorations and Their Monetary Policy Implications (PDF),\"  IMF Working Paper WP/15/230 (Washington: International Monetary Fund, November); and Dave Reifschneider, William Wascher, and David Wilcox (2015), \"Aggregate Supply in the United States: Recent Developments and Implications for the Conduct of Monetary Policy,\" IMF Economic Review, vol. 63 (March), pp. 71-109. Return to text\n\n5. See Mohamed A. El-Erian (2016), The Only Game in Town: Central Banks, Instability, and Avoiding the Next Collapse (New York: Random House). Return to text"
    },
    {
        "speaker": "Jerome H. Powell",
        "position": "Governor",
        "date": "November 18, 2016",
        "title": "The Global Trade Slowdown and Its Implications for Emerging Asia",
        "href": "https://www.federalreserve.gov/newsevents/speech/powell20161118a.htm",
        "content": "November 18, 2016\n\nGovernor Jerome H. Powell\n\nAt \"CPBS 2016 Pacific Basin Research Conference,\" sponsored by the Center for Pacific Basin Studies at the Federal Reserve Bank of San Francisco, San Francisco, California\n\nIt is a pleasure for me to return to the Center for Pacific Basin Studies here at the San Francisco Fed. The global economy is at a critical juncture today. According to the International Monetary Fund's latest World Economic Outlook, global gross domestic product (GDP) is set to grow at only 3.1 percent this year, the lowest rate of growth since the Global Financial Crisis. Investment and productivity remain subdued, despite extremely low and even negative interest rates in many economies.1 One key aspect of global weakness that is of particular relevance to emerging Asian economies is the sharp slowdown in global trade. This slowdown represents a notable departure from the \"normal\" times of the past few decades, and is the subject of my remarks today.2\n\nMore specifically, I will discuss four topics. First, I will review the main features of the global trade slowdown and summarize the evidence on its potential causes. Second, I will examine the special role that structural changes in China appear to be playing in the trade slowdown. Third, I will turn to the implications of this slowdown for economic growth in the region. And, finally, I will offer some views on how Asian economies can respond to the slowdown by rethinking their \"export-led growth\" paradigm.\n\nDocumenting the Global Trade Slowdown and Its Likely Causes\nTo set the scene, I will review the main features of the recent global trade slowdown. As you can see on the first slide, growth in world trade rebounded after the Great Recession but has slowed substantially since 2011. On a real inflation-adjusted basis, world imports have grown at an average annual rate of less than 3-1/2 percent since 2011, about half the 7 percent pace seen in the eight years prior to the Global Financial Crisis.3 As illustrated in the next slide, trade is no longer outpacing GDP growth. The share of real world imports in world GDP has been flat at just under 30 percent since 2011 after nearly doubling between 1985 and 2007.4 This sustained slowing of real trade relative to GDP is quite unusual: Since 1870, trade has generally grown faster than production, outside of wartime and recessionary periods.\n\nTrade has been sluggish almost everywhere. Real trade growth has been lower over the 2011-15 period compared with the 2000-07 period for every G-20 country outside of Japan, where trade growth was constant. The third slide shows that the fall in real import growth in emerging Asia has been particularly pronounced from over 10 percent in the first period to just about 3 percent in the second. But import growth has declined in Latin America and the advanced economies as well.\n\nThe next slide shows the differential between real import growth and real GDP growth for the same two periods. For emerging Asia, the differential went from positive to substantially negative, indicating that real import growth slowed to well below real GDP growth. In advanced foreign economies, the differential was just about zero in the more recent period, indicating that real import growth barely kept pace with GDP growth. Trade relative to GDP has held up better, though, in the United States and Latin America.\n\nIs the trade slowdown just another manifestation of slow growth, or is it an independent concern? That depends on the reasons for the slowdown. Weak global growth is surely part of the explanation, as emphasized by several recent empirical studies, including a special chapter on the topic in the latest IMF World Economic Outlook.5 As can be seen in slide 5, global GDP growth has fallen from an average of 3.5 percent before the Global Financial Crisis to about 2.5 percent since its end.\n\nBut weak global growth alone does not explain why trade has slowed to about the same pace as GDP after growing faster than GDP for decades. Part of the reason could be that the particular expenditure categories in which international trade flows are concentrated have become especially weak. A stark case in point is the Global Financial Crisis, when plummeting demand for investment and durable goods--two highly traded expenditure categories--contributed to the sharp 4 percentage point fall in the ratio of world trade to GDP. The special weakness in some components of demand has persisted beyond the crisis and could also explain some of the recent sluggishness in trade relative to GDP. In particular, as you can see from the middle two bars of slide 5, the slowdown in world investment growth--from about 4.5 percent growth before the Global Financial Crisis to only about 3 percent growth since 2011--has been more pronounced than the slowdown in world GDP growth or in world consumption. But the differences are not huge, suggesting that this explanation can go only so far.\n\nIndeed, research suggests that other factors are also important in accounting for the slowdown in world trade.6 One such factor is the deceleration in the pace of trade liberalization policies. From the early 1990s through the mid-2000s, trade barriers were coming down rapidly, including the signing of the North American Free Trade Agreement in 1994, the 2001 entry of China into the World Trade Organization, and the 2005 expiration of the multifibre agreement restricting textile imports to the United States and European Union. These changes resulted in the most rapid increases in the trade-to-GDP ratio since 1870. As the pace of trade liberalization has slowed in recent years, perhaps reflecting limits to further gains from trade agreements, it is only natural that the trade-to-GDP ratio should flatten out as well.\n\nAnother related factor is the maturation of global value chains. Increased fragmentation of production across international borders--a natural outgrowth of the gains from specialization--meant more trade for any given value of final production, thus adding to the major expansion in gross trade flows in the 1990s and 2000s. As shown in the next slide, global value chain participation, as measured by the share of foreign value added in world exports, increased substantially during this period. It is quite plausible that the process of increased fragmentation of production across borders is subject to \"diminishing returns\" and has its natural limits. Consistent with this notion, the trend toward greater product fragmentation has slowed in recent years.\n\nFinally, of course, China looms large in any discussion of the global trade slowdown. Not only is China's trade being affected by all of the factors just discussed, but on-going structural changes within the Chinese economy, including rebalancing toward domestic demand, are exerting an independent effect on world trade flows. So, let's look next at China in more detail.7\n\nChina\nAfter years of rapid export-led growth, China is now among the world's leaders in both exports and imports. China's exports now account for 14 percent of the world's total, compared with only 4 percent 15 years ago. At the same time, China's industrialization and export model has greatly increased its own demand for imports of raw materials, intermediate inputs, and parts and components. In recent years, however, growth in both Chinese imports and Chinese exports has slowed markedly. These developments have had a significant effect on global trade. One simple way to measure that effect is to consider what would have happened if China's trade had not decelerated. As shown in slide 7, under a counterfactual in which China's trade growth had not slowed relative to its GDP since 2011, global trade would still be growing as a share of GDP.8\n\nChina has, of course, been subject to many of the forces I have already discussed. One notable trend, shown by the black line in slide 8, is that Chinese processing exports--that is, re-exports from assembled imported parts and components--as a share of China's total exports have been falling steadily for several years. This trend in part reflects weak global demand, as weaker demand for final goods and services from the advanced economies should have led Chinese processing exports to fall disproportionately. It is also consistent with the deceleration of global supply chain formation.\n\nAlthough global factors have undoubtedly played a role, however, the evidence suggests that a substantial part of the slowdown in Chinese trade reflects developments that are specific to the Chinese economy and that are likely to exert a lasting imprint on global trade.9 First, the rapid expansion of China's manufacturing base over the past 15 years--made possible by vast reserves of cheap, rural labor--may simply be reaching its natural limit. Accordingly, we would expect China's manufacturing exports to slow.\n\nSecond, China is moving up the sophistication ladder by producing some higher value-added parts and components itself, instead of importing them. One manifestation of this phenomenon is the higher domestic value-added in Chinese exports in recent years, shown by the gray bars in this slide, relative to the period before the Global Financial Crisis. Another manifestation can be seen in slide 9, which shows the decline in the share of parts and components in China's total manufactured imports from about 65 percent in 2005 to under 50 percent in 2014.10 These two pieces of evidence suggest that the shift away from parts and components in Chinese imports is not just due to lower orders tied to weak import demand in the advanced economies, but also due to the rising productivity and sophistication of the Chinese labor force, which is enabling China to move to higher value-added exports.\n\nAs China moves up the sophistication ladder, you would also expect other countries to take a greater role in the lower steps of the ladder. We do have evidence that some other countries with cheaper labor, such as Vietnam and Bangladesh, are playing more of a role as exporters in the low-value added parts of the Asian supply chain. Anecdotal evidence suggests, though, that some of this shift is also taking place within China, as low-value-added production shifts to low-wage areas in China's interior.11\n\nThe third important structural change affecting Chinese trade is the progress China is making in moving away from its export-led model of economic growth and rebalancing its economy toward domestic demand. As shown in slide 10, investment, which in much of the pre‑crisis period was supporting high exports, has been falling as a share of the economy in recent years while the consumption share has been rising. Note, though, that the consumption share remains well below its value in the early 2000s. In addition, as can be seen in slide 11, as part of its rebalancing, Chinese production has been shifting away from manufacturing to services. Thanks in part to these developments, China's current account surplus (not shown here) has fallen sharply as a share of its GDP over the past several years.12\n\nThese are welcome developments as China's huge trade surplus created an unsustainable situation, contributing both to internal imbalances within the Chinese economy and to global imbalances. But the rebalancing toward domestic demand will likely put a damper on China's trade for some time as resources shift away from trade-intensive manufacturing. In principle, this drag on China's trade could be partly or even completely offset by stronger imports by Chinese consumers. Evidence of a shift toward imports of consumer goods, however, is limited thus far, and further substantial progress depends on the Chinese authorities' ability to remove distortions that currently depress consumption and boost saving. It may well be, however, that the rising power of the Chinese consumer will in time propel another long round of rapid increases in world trade.\n\nImplications for Growth in the Region\nHaving examined developments in world and Chinese trade, let me turn to the implications of these trends for economic growth in the emerging Asia region.\n\nThere is little doubt that for many years China and other emerging Asian economies have benefited from rapid expansion of trade.13 Greater trade can provide a host of economic benefits, including enabling the pursuit of comparative advantage, fostering more competition (which leads to more efficiency), generating technological and knowledge spillovers, and facilitating import of key capital goods. These factors enhance productivity and growth and result in the availability of a greater variety of goods to consumers at lower prices. It is safe to say that over the years, the Asian economies have benefited from their high degree of export orientation through all of these transmission mechanisms.14 A number of academic studies have found a causal link between openness and growth.15 A simple scatter plot of economic growth across countries over the period from 2000 to 2007 against their export orientation, presented in slide 12, is telling: More trade-intensive economies have grown significantly faster over this period, and the fast-growing emerging Asian economies shown by the red dots have generally been among the most export-oriented.\n\nHow did greater focus on trade develop in Asia? At first, increased export orientation in Asia was achieved by taking advantage of low-cost, low-skilled labor to produce low value-added products for foreign markets. Over time, countries such as Japan and South Korea moved up to higher value-added exports, in part through technological and knowledge spillovers. Later, with the rise of China, many emerging Asian economies became integrated into global supply chains, with China acting as the endpoint of a giant Asian assembly line.\n\nGiven that trade benefited the Asian economies on the way up, it seems natural that the slowdown in global trade, whatever its causes, could lead to some loss of dynamism and growth in the region. For China, the shift away from trade dependence is partly a reflection of policy choice, with rebalancing seen as a way to sustain growth in the face of some exhaustion of the heavy export/investment model. But many other Asian economies' fortunes are tied to those of China, so developments in China will have important implications for growth in these economies.\n\nOne natural question is how the rise in domestic content of Chinese exports is affecting countries that rely heavily on supplying parts and components to China. To document this reliance, your next slide shows that the share of parts and components in other Asian economies' exports to China (the middle green bars) is much greater than their share in exports to the rest of the world (the right blue bars). Over time, this share has fallen from about 70 percent in 2005 to 60 percent in 2014, without the share of parts and components in exports to the rest of the world increasing. This evidence, combined with the evidence I presented earlier on trends in Chinese processing exports, suggests that other economies in Asia are being adversely affected both by less final global demand for Chinese exports and by less use of imported parts and components by China in the production of any given amount of final goods exports.\n\nAnd the effects of these shifts in supply chains are being offset only very slowly and to only a very limited extent by China importing more goods for domestic consumption.16 Accordingly, it is doubtful that, at least so far, China is fully replacing advanced-economy demand as an engine of growth for the rest of emerging Asia. One way to look more concretely at this issue is to estimate an equation for the growth for emerging Asia ex. China that separately controls for the effects of Chinese growth and advanced-economy growth. This approach lets us see the direct contribution of Chinese growth to that of its neighbors at the margin, apart from the indirect effect due to China's exports to advanced economies.\n\nThe results of such an exercise, based on 10-year rolling regressions, are presented in slide 14. Note that in the first half of the 2000s, the effect of advanced-economy growth on emerging Asia ex. China (shown on the left) steadily rises from near zero to a one-to-one effect by 2005, whereas the coefficient on Chinese growth (on the right) hovers around 0.25 and is statistically insignificant. These results suggest that the effect of the rise in China on the rest of emerging Asia in the 2000s mainly reflected China's role as a \"conduit\" for trade with the advanced economies. However, after the Global Financial Crisis, we see the coefficient on advanced-economy growth move down some, whereas the coefficient on China's growth rises to 0.5 and becomes statistically significant. But the direct effect of advanced-economy growth is still larger than the direct effect of Chinese growth, consistent with the idea that it is still early days for the rebalancing of China's economy and that China will only slowly supplant the role of advanced economies as drivers of emerging Asian growth.\n\nRethinking the \"Export-Led Growth\" Paradigm\nThat brings me to the final topic of my remarks today, which is how emerging Asia can respond to the global trade slowdown and the structural changes taking place in China. Some of the structural changes I have discussed suggest that the recent deceleration of trade relative to GDP will likely persist and that we may expect global trade to grow perhaps about as fast as, but not substantially faster than, global GDP growth for the foreseeable future. Under these circumstances, emerging Asian countries may not be able to look to their export sectors as the key source of dynamism for their economies.\n\nSo what's an Asian economy to do? I would argue that, instead of trying to restore growth through enhancing external surpluses, under the circumstances it makes more sense for emerging Asia to focus on domestic demand as an engine of its growth, and to allow their trade and current account surpluses to shrink. When looking at these economies in aggregate, as shown in your next slide, current account surpluses narrowed greatly after the Global Financial Crisis but rebounded substantially thereafter.17 However, as you can see in slide 16, we have seen some narrowing of current account balances as a share of GDP in several emerging Asian economies, although in some others, such as South Korea, Taiwan, and Thailand, the surpluses have increased. Encouraging domestic demand and allowing for downward adjustment of these surpluses in emerging Asia, with more balances turning into deficits, would provide a much-needed injection of demand into the global economy and also support economic growth in the region by providing another source of growth in place of the lessened impetus from external demand.\n\nA shift toward external deficits in Asia would be advantageous, considering the low level of external financing costs at present. Many observers are raising the possibility of a \"new normal\" for the global economy, in which moderate global demand, low productivity growth, and slow trade may persist for some time, keeping interest rates in the advanced economies \"low for long.\" To be sure, bond yields have moved up recently, but they remain quite low by historical standards. Accordingly, the cost of external finance to Asian economies has fallen, which should support strong private capital flows to emerging markets. Normally, we would worry about volatility of these flows and how they might exacerbate risks of financial instability, particularly as U.S. monetary policy normalizes. But we should also bear in mind that many emerging market economies (EMEs), particularly in Asia, have improved their macroeconomic fundamentals over the past two decades; that they have built an adequate war chest of reserves, with no pending need to further reserve accumulation for precautionary purposes; and that their currencies are much more flexible, which acts as an adjustment mechanism to shocks and also lessens the possibility of fluctuations in reserves due to currency intervention. These factors have made the emerging Asian economies much less vulnerable.\n\nGiven all this, dare we imagine a world in which private capital inflows to EMEs could prove self-sustaining, are not offset by reverse flows of official capital, and would finance long-term profitable investment that would help support growth in these economies while also supporting global growth? In essence, these capital inflows would finance the shift from export-led growth to domestic-led growth required by the slowdown in global trade. And, with little or no official outflows, EMEs would have total capital net inflows as well, consistent with running current account deficits instead of current account surpluses. As pointed out recently by former Fed Chairman Ben Bernanke, the availability of profitable capital investments in one part of the world can help defeat secular stagnation in another part.18\n\nOf course, these developments may take time. The point is that at this current juncture of the global economy, it is all the more important for emerging Asian economies--and, indeed, emerging market economies more broadly--to enhance domestic demand while pursuing prudent policies. It would be good to do this for the sake of the global economy, but emerging Asian economies should do this for their own sakes as well.\n\n(Thank you.I would be happy to take a few questions.)\n\nReferences\nAthukorala, Prema-Chandra, and Nobuaki Yamashita (2006). \"Production Fragmentation and Trade Integration: East Asia in a Global Context,\" North American Journal of Economics and Finance, vol. 17 (3), pp. 233-56.\n\nBaldwin, Robert E. (2004). \"Openness and Growth: What's the Empirical Relationship? (PDF)\"  in Robert E. Baldwin and L. Alan Winers, eds., Challenges to Globalization: Analyzing the Economics. Chicago: University of Chicago Press, February, pp. 499-525.\n\nBernanke, Ben (2015). \"Why Are Interest Rates So Low, Part 2: Secular Stagnation,\"  Brookings Institute, March 31.\n\nThe Economist (2015). \"A Tightening Grip: Rising Chinese Wages Will Only Strengthen Asia's Hold on Manufacturing,\" The Economist, March 14, www.economist.com/news/briefing/21646180-rising-chinese-wages-will-only-strengthen-asias-hold-manufacturing-tightening-grip.\n\nEuropean Central Bank (2016). \"Understanding the Weakness in Global Trade. What is the New Normal? (PDF)\"  European Central Bank Occasional Paper Series No. 178, September.\n\nFrankel, Jeffrey, and David Romer (1999). \"Does Trade Cause Growth?\" American Economic Review, vol. 89 (June), pp. 379-99.\n\nGaulier, Guillaume, Walter Steingress, and Soledad Zignago (2016). \"The Role of China in the Trade Slowdown,\" Rue de la Banque, Banque de France, No. 30 (September).\n\nGlick, Reuven, and Ramon Moreno (1997). \"The East Asian Miracle: Growth because of Government Intervention and Protectionism or in Spite of It?\" Business Economics, vol. 32 (April), pp. 20-5.\n\nHaltmaier, Jane T., Shaghil Ahmed, Brahima Coulibaly, Ross Knippenberg, Sylvain Leduc, Mario Marazzi, and Beth Anne Wilson. (2007). \"The Role of China in Asia: Engine, Conduit, or Steamroller? (PDF)\" International Finance Discussion Papers 904. Board of Governors of the Federal Reserve System, September.\n\nHoekman, Bernard, ed. (2015). The Global Trade Slowdown: A New Normal? (PDF)  VoxEU.org eBook. London: Centre for Economic Policy Research, June.\n\nInternational Monetary Fund (2016a). World Economic Outlook, chapter 2: Global Trade: What's behind the Slowdown?  Washington, D.C.: IMF, October.\n\n------ (2016b). World Economic Outlook, chapter 4: Spillovers from China's Transition and from Migration.  Washington, D.C.: IMF, October.\n\nLewis, Logan, and Ryan Monarch (2016). \"Causes of the Global Trade Slowdown,\" IFDP Notes (Washington: Board of Governors of the Federal Reserve System, November).\n\nLui, Silvia, Rebecca Riley, Dawn Holland, Ali Orazgani, and Pawel Paluchowski (2013). \"Long Run Income Elasticities of Import Demand (PDF),\"  BIS Research Paper No. 144. London: National Institute of Economic and Social Research.\n\nOrganisation for Economic Co-operation and Development (2016). \"Cardiac Arrest or Dizzy Spell: Why Is World Trade So Weak and What Can Policy Do about It? (PDF)\"  OECD Economic Policy Papers, No. 18. Washington, D.C.: OECD, September.\n\nPage, John (1994). \"The East Asian Miracle: Four Lessons for Development Policy,\" in Stanley Fischer and Julio Rotemberg, eds., NBER Macroeconomic Annual, vol. 9 (January), pp. 219-82.\n\nSetser, Brad (2016). \"The Return of the East Asian Savings Glut,\"  CFR Discussion Paper. Council on Foreign Relations, October.\n\nWorld Bank (1993). The East Asian Miracle: Economic Growth and Public Policy. New York: Oxford University Press.\n\n1. The World Economic Outlook's headline growth numbers aggregate global growth, using PPP-based GDP weights. They also compute growth using GDP weights based on market exchange rates, according to which global growth this year is projected to be even lower, at 2.4 percent. Return to text\n\n2. The views I express here are my own. Return to text\n\n3. In principle, data on either world exports or world imports could be used to study global trade, though the two differ in practice. My remarks here focus on import data, which are generally regarded as more reliable at the country level. Return to text\n\n4. The share of nominal world imports to nominal GDP has actually been declining since 2011, with a particularly sharp drop in 2015, reflecting steep declines in commodity prices. Return to text\n\n5. International Monetary Fund (2016a); see also Organization for Economic Co-operation and Development (2016), European Central Bank (2016), and Hoekman (2015). Return to text\n\n6. See, for example, European Central Bank (2016), Hoekman (2015), Organization for Economic Co-operation and Development (2016), and Lewis and Monarch (2016). Return to text\n\n7. Another explanation that has been put forward for much of the decline in world trade relative to world GDP is an increased weight of EMEs in the contribution to global growth together with the property that EMEs have lower income elasticities of trade than advanced economies do. (See European Central Bank, 2016.) However, more broadly, the literature does not seem to suggest that income elasticities are significantly lower for EMEs (for example, Lui and others, 2013). Also, while trade financing constraints--another potential explanation--played some role during the severe trade slowdown during the Global Financial Crisis, trade financing does not appear to have become more difficult since 2011 and likely has not been a significant factor in the slowdown in recent years. Return to text\n\n8. See Lewis and Monarch (2016) for more details. Return to text\n\n9. A recent note from the Banque du France--Gaullier, Steingress, and Zignago (2016)--argues that the long run elasticity of world trade to income is unity, and that structural changes in China go a long way in explaining both the sharp rise in the elasticity in the years before the Global Financial Crisis and the subsequent decline in the post-crisis years as China rebalances toward domestic demand. Return to text\n\n10. This share has been computed by updating the methodology followed in Haltmaier and others (2007), which, in turn, extended the methodology of Athukorala and Yamashita (2006). Return to text\n\n11. See, for example, The Economist (2015). Return to text\n\n12. Over the past couple of years, though, China's current account surplus has turned up again, especially as a share of world GDP. Return to text\n\n13. See, for example, Glick and Moreno (1997), Page (1994), and World Bank (1993). Return to text\n\n14. Some--Page (1994), for example--have argued that industrial policies favoring certain export industries have also played an important role in Asia's success, but it seems to be generally agreed that industrial support was only maintained conditional on successful performance on world markets. Return to text\n\n15. See, for example, Frankel and Romer (1999) and Baldwin (2004). Return to text\n\n16. The arguments laid out here are consistent with the findings in the chapter on spillovers from China's transition presented in the latest IMF World Economic Outlook (2016b). This chapter concludes that for many countries the effect of China's transition and rebalancing toward a more sustainable growth model will entail short-run negative spillovers, but there will be potential gains to the global economy over the longer term. Return to text\n\n17. See Setster (2016) for a detailed discussion of the return of the East Asian savings glut. Return to text\n\n18. See Bernanke (2015). Return to text"
    },
    {
        "speaker": "Lael Brainard",
        "position": "Governor",
        "date": "November 17, 2016",
        "title": "The \"Gig\" Economy: Implications of the Growth of Contingent Work",
        "href": "https://www.federalreserve.gov/newsevents/speech/brainard20161117a.htm",
        "content": "November 17, 2016\n\nGovernor Lael Brainard\n\nAt \"Evolution of Work,\" a convening cosponsored by the Board of Governors of the Federal Reserve System, the Federal Reserve Bank of New York, and the Freelancers Union, New York, New York\n\nWatch live at https://www.facebook.com/newyorkfed/\n\nI would like to thank Bill Dudley and Sara Horowitz for inviting me to participate in today's conference. The subject we are tackling today--the evolution of work--is a particular interest of mine and is a matter of great importance to the Federal Reserve. The Congress has mandated the Federal Reserve to implement monetary policy so as to promote maximum employment and stable prices. Our dual mandate recognizes the importance of work in enabling people to contribute to the financial security of their family and the prosperity of their community and the country overall. Moreover, there is a long-standing recognition that secure and dignified work provides a key sense of purpose and worth. Understanding the changing nature of employment in today's economy is not only central to the mission of the Federal Reserve, but also goes to the core of who we are as providers for our families and productive members of society.1\n\nIn contrast to traditional work arrangements, in which an employee has a durable employment relationship with a single primary employer, a large and growing proportion of the workforce is working through contracting, temporary arrangements, on-call arrangements, or as freelancers being hired for episodic \"gigs.\" Broadly speaking, contingent arrangements are more transitory than traditional arrangements, in the extreme consisting of a single transaction or gig. They often provide considerably greater flexibility than long-term employment contracts, allowing workers and employers to move in and out of work relationships easily. Depending on the nature of the employment relationship, this enhanced flexibility could have benefits and costs that accrue to workers and employers very differently.\n\nAlthough they have always been a feature of the American economic landscape, there has been a sharp increase in the prevalence of contingent working arrangements over the past decade, and it is too early to tell how much of this acceleration is a cyclical phenomenon associated with the Great Recession or reflects a structural trend. The growing share and variety of contingent work has important implications for policy and puts a premium on data and research exploring this topic. For monetary policy, the growth of contingent work affects the way we assess maximum employment and the way we interpret important labor market outcomes, such as the level of part-time employment and aggregate hours worked. Depending on the contractual arrangements, it may also have important implications for economic security and the behavior of households as consumers and savers. Richer and timely data and analysis could help guide employers, workers, and public officials toward outcomes where benefits and risks are better understood and managed.\n\nWhat Do We Know about Contingent Work?\nOfficial measures of the changing nature of work have not kept pace with the evolution of the economy. But thanks to some cutting-edge researchers, several of whom are present today, there is a growing foundation of analysis.\n\nLast year, Larry Katz and Alan Krueger conducted a version of the Contingent Worker Survey (CWS) to track alternative and nonstandard work arrangements using the RAND American Life Panel.2 Their findings are striking: Over the past decade, contingent workers have increased by roughly one-half and now make up 16 percent of the workforce. This rapid increase is in marked contrast to the preceding decade, when contingent workers remained at a relatively stable 10 percent of the workforce, according to the Bureau of Labor Statistics' (BLS) CWS.3 They conclude that all of the net growth in aggregate employment in the decade leading up to 2015 can be accounted for by contingent work arrangements, which means there has been no net employment growth in traditional work arrangements. Given that this period spanned the Great Recession and the first five years of a slow recovery, it naturally raises the question of how much of the large recent shift toward contingent work is attributable to cyclical factors, as opposed to structural forces that may be here to stay.4\n\nLong before the advent of firms such as Uber and TaskRabbit, many individuals worked in contingent arrangements, such as freelancing and contracting, and it is these groups that have increased their share of the workforce most notably over the past decade. The largest increase in contingent work over this time has been among workers whose services are contracted out by another company, which rose from 0.6 percent to 3.1 percent of the workforce. There was also a large increase in workers who are independent contractors, consultants, or freelancers, whose share grew from 6.9 percent in 2005 to 8.4 percent in 2015. On-call workers expanded from 1.7 percent to 2.6 percent of the workforce.5\n\nOver this same period, technological platforms have emerged that are transforming the way people identify, schedule, and engage in contingent work and are also helping people to monetize their assets to generate income. These developments, under the rubric of the \"gig,\" \"on-demand,\" \"platform,\" or \"sharing\" economy, have the potential to be transformative. Although the data are still relatively sparse, it appears that the number of workers using online platforms to secure gigs is still small but is growing quickly.6 Katz and Krueger found that workers who provide services through three online intermediaries accounted for only 0.5 percent of all workers in 2015. Diana Farrell and Fiona Greig (2016) reach a similar conclusion, using a unique and rich data set.7\n\nThe Federal Reserve Board fielded a survey to better understand the many ways adults are generating income, regardless of their employment status and the frequency of these activities. The survey uses an expansive concept of contingent work, capturing all of the activity individuals are undertaking to generate income. The Enterprising and Informal Work Activity survey, or EIWA, suggests that more than a third--36 percent--of the adult population undertook informal paid work activity either as a complement to, or as a substitute for, more traditional and formal work arrangements.8 Similarly, a survey undertaken by Upwork and the Freelancers Union that also uses an expansive definition of contingent work finds that 35 percent of the labor force engages in freelance work.9\n\nThe Upwork survey provides further insight by subdividing the 35 percent of the labor force who have done some form of informal work over the past 12 months into five categories. In the categories most comparable with the Katz and Krueger CWS categories, roughly 12 percent of the workforce identify as independent contractors who do not have an employer and engage in project-by-project work, whereas between 2 and 3 percent are traditional contract or temporary workers who have a single employer or project at a time and whose work status is temporary. By contrast, roughly half of the Upwork respondents do informal work in addition to traditional employment relationships; almost 10 percent derive their income from multiple different types of arrangements, including both traditional employment relationships and freelancing, while about 9 percent report having a full-time traditional job and \"moonlighting\" to gain additional income on top of that. The group that derives income from multiple different types of jobs has evidenced the fastest growth over the last few years covered by the survey. In addition, 2.5 percent identify as business owners.\n\nFinally, the EIWA survey provides valuable insights into the use of recent technologies in informal work. The EIWA survey suggests that over the previous six months, roughly 11 percent of adults in the United States have engaged in paid services using an online platform, such as arranging transportation activities with companies such as Uber, arranging work opportunities on sites like Care.com, Amazon Mechanical Turk, or TaskRabbit, generating projects through companies such as Fiverr, selling goods and crafts on sites such as eBay and Etsy, and renting rooms or homes through services like Airbnb, among others.10 This figure is much larger than the Katz and Krueger finding of 0.5 percent, partly because the EIWA survey was fielded to all adults regardless of their formal employment status, asked about all online paid services, and used a six-month look-back period, rather than the past week.\n\nWho Is Engaging in Contingent Work and Why?\nTogether, these recent surveys of informal work paint a varied picture of the universe of informal work arrangements, along with participants' motivations for engaging in them. Nineteen percent of informal workers in the EIWA survey, for example, were engaged in three or more online and/or offline informal paid work activities in the prior six months, and 25 percent indicated that informal and contingent work activities have been \"very much\" or \"somewhat\" a regular and consistent source of their monthly income.\n\nResults regarding the ages of workers attracted to nontraditional work vary: Katz and Krueger find that the share of contingent work arrangements increases with age, while the Upwork study finds that freelancing is more prevalent among the young. The earnings experiences of contingent workers appear to span a wide range. Katz and Krueger find that those engaged in contingent work tend to be concentrated in the highest income quintiles. But while independent contractors and contract workers earn relatively high wages, on-call and temporary-help work tends to occur among workers in lower wage quintiles.\n\nOne common theme that emerges is the desire to earn extra money, which is a primary motivation for 74 percent of part-time, and 68 percent of full-time, freelancers in the Upwork survey. Similarly, in the EIWA survey, 65 percent of informal workers reported that earning income was their main reason for engaging in informal and contingent work, and the EIWA provides many examples that corroborate this result.11 A full-time restaurant cook in his 50s, reports that he does yard work and sells items both online and offline to earn extra income and to help family members. He averages 60 hours per month from side and gig work and reported that these earnings constitute 75 percent of his household's monthly earnings. Similarly, a respondent in her 20s works part time as a dental hygienist and supplements this employment with about 8 hours per month of additional gig work. She said that the gig work somewhat mitigated the effect of the Great Recession, which found her working fewer hours, with stagnant wages and a loss of benefits.\n\nFor others, work-life balance considerations seem to play a significant role in choosing contingent work arrangements. For example, a mother in her 20s reported spending 12 hours per month selling self-crafted items online, babysitting, and completing online tasks, collectively providing about 20 percent of her family's income. She reported that her main reason for participating in the gig economy is to be home with her daughter.\n\nMany others find themselves in highly variable work arrangements not by preference but because of the requirements of their employers. As employers have outsourced noncore tasks to contract firms and moved to technologically enabled \"just-in-time\" scheduling of employees, contract workers and on-call workers have had to adjust to variable and sometimes unpredictable hours.\n\nAs these stories indicate, there are a variety of reasons workers engage in alternative and nonstandard work arrangements. Many individuals use the flexibility and enhanced connectivity of new technology-enabled platforms to pursue expanded opportunities. While some supplement their traditional job, using their free time to earn extra income, others cobble together contingent work arrangements or gigs to generate necessary income in the absence of traditional work opportunities. Still others move into contingent work arrangements due to their employers' work requirements. While some workers seem to appreciate the greater opportunities contingent work arrangements provide, others engage in this work out of necessity because they appear unable to obtain a full-time traditional work arrangement that meets their needs. Overall, the Upwork study finds that 63 percent of freelancers say they are pursuing this type of work by choice, while 37 percent do it out of necessity. It is unclear whether this outcome would hold true of the more tightly defined population in the Katz and Krueger survey.\n\nImplications of a Growing Gig Economy\nIf market forces and technology are driving the growing prevalence of gig work, these trends will likely continue, and policymakers must better understand these changes. A natural starting point is measurement. There is some good news on this front, as the BLS is preparing to field a CWS in May 2017 for the first time since 2005.\n\nBetter data should help deepen our understanding of how the growth of contingent work is changing the behavior of workers and employers and what these developments imply for the overall economy and household welfare. From a macroeconomic perspective, we should be attuned to the possibility that the growth in flexible work arrangements may alter the natural rate of employment and how the labor market reacts to shocks as we assess the cyclical behavior of important aggregates--such as labor force participation, employment, hours worked, and underemployment.\n\nOne possibility is that new technologies, by lowering the barriers to workforce entry, could raise employment and labor force participation. Because there are fixed costs to obtaining and maintaining a job--such as searching for the job, learning about the job, and traveling to the job site every workday--the traditional work arrangement embeds incentives for individuals to work only one job, thus minimizing these fixed costs. And for those individuals who desire to work relatively few hours, these fixed costs in the past may have led to a decision to remain out of the labor force. But if technology makes it less costly for individuals to find work, manage multiple work relationships, and flexibly work more or fewer hours as their schedule permits, this could significantly increase workers' options and have important effects on labor market behavior. Importantly, any such increases in participation and employment would likely be structural, not cyclical, enabling the economy to run at a sustainably higher level.\n\nNew technologies could also make it easier for individuals' actual hours to match their desired hours of work in a day or a week. Instead of seeing hours per week bunched around 40, we may see greater variation in the hours that individuals work. Lower barriers to workforce entry may make it more attractive for more individuals to work only a few hours a week if they desire--and can afford--to do so. At the same time, by making it easier to find additional work, new technologies may lead to more individuals working greater-than-full-time hours every week. In addition, we may see individuals changing the number of hours they work more frequently, as these changes become less costly. Both the EIWA and Upwork surveys confirm that gig work does, indeed, lower barriers to workforce entry and increase hours and flexibility for some individuals.\n\nThe increasing prevalence of gig work may also affect the unemployment rate and productivity. To the extent that gigs provide an easy entryway to employment, unemployment may decrease. However, if gig work is less stable, it may increase job loss. The net effect on unemployment is, thus, unclear. Regarding productivity, gig work could lower aggregate productivity to the extent that it requires less human capital or specialized knowledge than traditional jobs, or if it primarily increases hours worked by lower-skilled individuals. That said, gig work, especially when enabled by new technologies, may allow hours to respond more flexibly to changes in demand and individuals to more easily connect with many different clients or employers. As a result, workers' downtime and the time required to acquire new clients and manage existing clients may decrease, in which case resource utilization and productivity may increase.\n\nIt is also possible that the increasing prevalence of gig work will cause the cyclical behavior of unemployment, participation, and the workweek to change, with implications for how we assess the amount of slack. We know that contingent work increases when the economy worsens. If new technologies make it easier to find gig work, then we could see unemployment rise less in recessions, to the extent that gig workers are counted as employed. However, it could be that individuals who are able to avoid unemployment through contingent work would still be underemployed if it is difficult to cobble together enough gigs to achieve full-time employment. This would likely show up as lower average workweeks and higher levels of involuntary part-time employment during downturns. As a result, cyclical changes in resource utilization could be reflected less in movements in the unemployment rate and more in variation in hours per worker.\n\nBeyond the behavior of macroeconomic variables, it is unclear how the growth of different types of gig work affects the welfare of workers. Welfare should increase in cases where gig work meets the needs of workers by providing a low-barrier means of accessing employment and by allowing workers to better match actual hours worked with desired hours of work, especially if the gig work is available at times and in places where traditional work opportunities are in short supply.\n\nThere is some evidence that this has, indeed, been the case. For example, 24 percent of informal workers in the EIWA survey indicated that contingent work had offset their spells of unemployment, loss of working hours, loss of benefits, or frozen wages in their formal employment \"very much\" or \"somewhat.\" In addition, three-fourths of Uber drivers say that the greater control over their work schedules that Uber allows has made their lives better.12\n\nHowever, there are likely many workers who would prefer regular full-time traditional work to contingent work, particularly if much of the power in determining hours worked in alternative work arrangements belongs to the employer. Technological advances have enabled firms to use just-in-time strategies for their employees, making them in effect on-call workers. This is a rising trend in industries such as retail and food preparation. Several recent articles describe the challenges faced by these just-in-time workers, who must conform their hours to the daily and even hourly ebbs and flows of business, often not knowing whether they will have work on a given day until they call in that morning to inquire.13 These arrangements can leave workers scrambling to patch together child care, elder care, and transportation to meet the often unpredictable demands of their workplace, while making it difficult to engage in regularly scheduled activities to enhance their income and opportunities, such as a second job or career training. While such workers often are not given full-time work, they often must make themselves available to work full-time hours. According to one survey, 71 percent of retail workers in New York stated that their hours fluctuated from week to week, while half said their employers could change their hours at will.14 It is also notable that the increase in contingent work over the past decade has coincided with an increase of one-third in the share of employees working part time but who would prefer to work full time from 3 percent prior to the Great Recession to close to 4 percent today.\n\nIn addition, contingent workers may receive lower wages, less training, and fewer benefits than their counterparts with traditional jobs. Typically, the wages of low-skilled employees within a company are boosted by social norms regarding pay equity, and nonpecuniary benefits are often equalized across a company's employees, in certain cases as mandated by law.15 However, the wages that contractors receive are unlikely to reflect the same equity considerations. Moreover, contingent work generally does not offer employer-based benefits and workplace protections that come with traditional employment opportunities, like overtime compensation, minimum wage protections, health insurance, family leave, employer-sponsored retirement plans, workers' compensation, and paid sick leave.\n\nAs a result, for some, contingent work may entail greater risks than in traditional full-time employment, with more variable and less predictable hours and earnings. The Upwork study notes that one of freelancers' biggest concerns is managing income variability and benefits. For lower-income workers, unpredictable fluctuations in income can lead to severe hardship. The Federal Reserve Board's Survey of Household Economics and Decisionmaking, for example, finds that 46 percent of households report that they would need to borrow money or sell something in order to pay an unexpected expense of $400.16\n\nThese findings suggest that employers, policymakers, and workers should seek ways to help individuals better manage the risks inherent in most forms of contingent work. For example, we may need to enhance social safety net programs, such as unemployment and disability insurance, to better support some types of contingent work. Another possibility is to make benefits, such as health insurance and retirement saving, portable across different employers. We may also want to encourage the additional saving that many contingent workers need to ensure that their basic consumption needs are not sacrificed when demand for their work declines, perhaps by providing monetary or other types of incentives.\n\nClosing Thoughts\nThe apparent trend toward contingent work has recently coincided with new advances in technology that can potentially amplify this trend and push it in new directions. We are still at an early stage in these developments, and it is too soon to say how these changes will play out. But the effects on the labor market could be long lasting and significant. Taking into account the potentially varied effects of the rising prevalence of gig work on household welfare, public policy should strive to maximize the benefits of the greater flexibility and lower entry barriers provided by advances in technology, while addressing the risks that currently accompany many forms of gig employment. Going forward, better data will be necessary, along with detailed research and analysis, in order to enable workers, employers, and policymakers to guide these changes in the labor market in a direction that ensures the benefits are broadly shared and the risks are well understood and well managed.\n\nReferences\nAnsel, Bridget (2015). \"The Pitfalls of Just-in-Time Scheduling,\" Washington Center for Equitable Growth, January 27.\n\nBracha, Anat, and Mary A. Burke (2014). \"Informal Work Activity in the United States: Evidence from Survey Responses (PDF),\" Current Policy Perspectives 14-13. Boston: Federal Reserve Bank of Boston, December.\n\nBracha, Anat, Mary A. Burke, and Arman Khachiyan (January 2015). \"Changing Patterns in Informal Work Participation in the United States 2013-2015 (PDF),\" Current Policy Perspectives 15-10. Boston: Federal Reserve Bank of Boston, October.\n\nCarrillo, Dani, Kristen Harknett, Allison Logan, Sigrid Luhr, and Daniel Schneider (2016). \"On-Call Job, On-Call Family: The Necessity of Family Support among Retail Workers with Unstable Work Schedules (PDF),\" Working Paper 2016-11. Washington: Washington Center for Equitable Growth, November.\n\nFarrell, Diana, and Fiona Greig (2016). Paychecks, Paydays, and the Online Platform Economy: Big Data on Income Volatility. New York: JPMorgan Chase Institute, February, https://www.jpmorganchase.com/corporate/institute/document/jpmc-institute-volatility-2-report.pdf.\n\nHall, Jonathan V., and Alan B. Krueger (2015). \"An Analysis of the Labor Market for Uber's Driver-Partners in the United States (PDF),\" Working Paper 587. Princeton, N.J.: Princeton University, Industrial Relations Section, January.\n\nHarris, Seth D., and Alan B. Krueger (2015). \"A Proposal for Modernizing Labor Laws for Twenty-First-Century Work: The 'Independent Worker (PDF),' \" Discussion Paper 2015-10. Washington: Hamilton Project, Brookings Institution, December.\n\nKatz, Lawrence F., and Alan B. Krueger (2016). \"The Rise and Nature of Alternative Work Arrangements in the United States, 1995-2015 (PDF),\" working paper, March.\n\nManyika, James, Susan Lund, Jacques Bughin, Kelsey Robinson, Jan Mischke, and Deepa Mahajan (2016). Independent Work: Choice, Necessity, and the Gig Economy. San Francisco: McKinsey Global Institute, October, available at http://www.mckinsey.com/global-themes/employment-and-growth/independent-work-choice-necessity-and-the-gig-economy.\n\nRobles, Barbara J., and Marysol McGee (2016). \"Exploring Online and Offline Informal Work: Findings from the Enterprising and Informal Work Activities (EIWA) Survey (PDF),\" Finance and Economics Discussion Series 2016-089. Washington: Board of Governors of the Federal Reserve System, November.\n\nUpwork and Freelancers Union (2016). \"Freelancing in America: 2016,\" survey results, October 6, available at https://www.upwork.com/i/freelancing-in-america/2016.\n\nU.S. Government Accountability Office (2015). Contingent Workforce: Size, Characteristics, Earnings, and Benefits. Washington: GAO, April, available at http://www.gao.gov/products/GAO-15-168R.\n\nWessler, Seth Freed (2014). \"Shift Change: 'Just-in-Time' Scheduling Creates Chaos for Workers,\" NBC News, May 10, http://www.nbcnews.com/feature/in-plain-sight/shift-change-just-time-scheduling-creates-chaos-workers-n95881.\n\n\n\nI am grateful to Stephanie Aaronson, Dave Buchholz, Andrew Figura, Joseph Firschein, Arturo Gonzalez, Barbara Lipman, Barbara Robles, Marysol Weindorf, and Alison Weingarden for their assistance in preparing this text.\n\n1. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. The Contingent Worker Survey is the main survey used by the Bureau of Labor Statistics for tracking alternative and nonstandard work. The survey was last fielded in 2005. Return to text\n\n3. See Katz and Krueger (2016). Return to text\n\n4. The U.S. Government Accountability Office (GAO) study of the contingent workforce shows an increase of 5 percentage points in the share of contingent work arrangements, although this shift took place from 2006 to 2010. The GAO's definition of contingent work covers a much larger share of the workforce, 40.4 percent in 2010, than the CWS. See U.S. Government Accountability Office (2015).\n\nIn the same vein, a 2014 survey by the Federal Reserve Bank of Boston found that roughly 44 percent of its survey's respondents participated in some informal paid work activity during the previous two years. See Bracha and Burke (2014). Return to text\n\n5. See Katz and Krueger (2016). Return to text\n\n6. See Harris and Krueger (2015). Return to text\n\n7. By contrast, studies conducted by the Federal Reserve Bank of Boston in 2013 and 2015 found that approximately one in four respondents--or more than half of informal work participants--say they earned money through informal work activities conducted online. See Bracha, Burke, and Khachiyan (2015). Return to text\n\n8. See Robles and McGee (2016).\n\nSome informal workers in the EIWA would not meet the definition of employment in the Current Population Survey (CPS) either because they did not do work in the CPS reference week (the EIWA asks about activities over the past six months, not during the reference week) or because they would not categorize the covered activities (such as the occasional selling of goods or renting of property) as work. Return to text\n\n9. The Upwork survey encompasses an expansive set of contingent work arrangements, even if only intermittent, over the past 12 months, and the EIWA encompasses a similar scope over the past 6 months, while Katz and Krueger confine their focus to the Current Population Survey reference week, similar to the BLS CWS. In addition, the Upwork definition is similar to the EIWA in counting as informal workers those individuals with traditional full- or part-time work who also engage in some informal work, in contrast to Katz and Krueger and the BLS CWS, which try to differentiate those workers who predominantly engage in contingent work. Return to text\n\n10. A study by the McKinsey Global Institute suggests that 15 percent of independent workers in the United States and the European Union participate in online informal work activities. See Manyika and others (2016). Return to text\n\n11. The responses to the survey were anonymous and confidential. Return to text\n\n12. See Hall and Krueger (2015). Return to text\n\n13. See Ansel (2015) and Carrillo and others (2016). Return to text\n\n14. The 2011 survey was conducted by the Retail Action Project, cited in Wessler (2014). Return to text\n\n15. Regulations stipulated by the Employee Retirement Income Security Act and the Affordable Care Act generally mandate equal benefits provision of pension and health insurance plans across employees. Return to text\n\n16. The survey is available on the Board's website at https://www.federalreserve.gov/communitydev/shed.htm. Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "November 15, 2016",
        "title": "Is There a Liquidity Problem Post-Crisis?",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20161115a.htm",
        "content": "November 15, 2016\n\nVice Chairman Stanley Fischer\n\nAt \"Do We Have a Liquidity Problem Post-Crisis?\", a conference sponsored by the Initiative on Business and Public Policy at the Brookings Institution, Washington, D.C.\n\nWatch live: https://www.brookings.edu/events/do-we-have-a-liquidity-problem-post-crisis/\n\nMarket liquidity is the ability to rapidly execute sizable securities transactions at a low cost and with a limited price impact.1 The high degree of liquidity in U.S. capital markets historically has contributed to the efficient allocation of capital through lower costs and a mix of bank- and market-based finance that supports the flexibility of these markets.2 Regulatory changes may have altered financial institutions' incentive to provide liquidity, raising concerns brought into sharp relief by several \"flash events\" over the past few years. At the same time, any changes in observed liquidity are also likely accompanied by other related changes--such as in technology--and a more complete assessment of these shifts is important when we think about the effects on liquidity of changes in financial regulations that were induced by the global financial crisis.3\n\nThis afternoon, I will first review some of the concerns raised by market participants and others about market liquidity as well as highlight the challenges associated with finding clear evidence that substantiates these concerns. I will then discuss whether potential impairment of liquidity might exacerbate problems related to fire sales and leverage. Finally, I will make the case that any changes in market liquidity resulting from regulatory changes should be analyzed in the broader context of the overall safety of the financial system. This perspective naturally emphasizes potential tradeoffs between the possibly adverse effect regulations may have on market liquidity and their positive effect on the stability of the financial system.\n\nMarket Participants' Concerns\n\n1. Decline in dealers' inventory\nMarket participants have cited a decline in dealers' inventories as a possible source of decreased liquidity. Figure 1 shows that primary dealers' inventories of fixed-income securities, which are predominantly used for market making, declined sharply after the Lehman Brothers failure, from about $1.3 trillion to about $800 billion, and have since fallen further to about $700 billion. The recent decline might be due in part to regulations, such as the Volcker rule and the Supplementary Leverage Ratio, aimed at making the financial system safer and sounder, as well as to changes firms may have made on their own, perhaps in reaction to the experience of the financial crisis. Regardless of the causes of the change, market participants have expressed a concern that the decline in inventories reflects in part a reduced willingness or capacity of the primary dealers to make markets--which may in turn lead to lower liquidity. However, whether markets are in fact less liquid depends on both the degree to which the decrease in primary dealers' inventories affects their willingness to provide liquidity and the extent to which nonbank firms such as hedge funds and insurance companies fill any lost market-making capacity.4\n\n2. Decline in trade size and turnover\nMarket participants also often cite the decline in average trade size and turnover--the volume of trades relative to the total amount of bonds outstanding--as evidence of reduced liquidity. Figure 2 shows that average trade size in the corporate bond market has indeed declined since 2006 but has been relatively stable in the past four years. Nevertheless, this decrease may reflect a number of factors, including changes in technology or the types and preferences of institutions engaged in trades, so it may not indicate a reduction in market liquidity. Certainly, the length of this trend, roughly a decade, seems on its face more consistent with a secular trend such as technological change. Turnover in the corporate bond market has declined as well, though this evidence is also not a definitive sign of reduced market liquidity. The decline in turnover is not driven by a reduction in trading volume, but it is the result of a robust growth of the denominator, debt outstanding.\n\n3. Liquidity during times of stress\nMarket participants further express concern about the potential for market liquidity to become less resilient during times of stress, when it is needed the most. However, evidence on this front is difficult to gather. Some argue that market liquidity is resilient because financial markets appear to have functioned fairly well during recent episodes of high market volatility, such as following the Brexit vote or earlier this year, when oil prices were low and stock market volatility was high. Others argue that it is not. According to a recent study, the cost of trading distressed corporate bonds appears to be higher now than in the recent past.5 Specifically, the authors find that, before the crisis, the cost of a $1 million bond transaction increased about 0.7 percent following a downgrade, but--after the Volcker rule--the cost following a downgrade rose 2.4 percent. This analysis, however, is limited to episodes of distressed borrowers rather than a systemwide stress.\n\n4. Flash events\nIn addition, recent flash events--such as the sharp movement in Treasury prices on October 15, 2014; the rapid rise and decline of the euro-dollar exchange rate on March 18, 2015; 6 and the swing in sterling on October 7, 2016--have led some to assert that market liquidity has become less resilient. Researchers at the Federal Reserve Bank of New York have argued that spikes in volatility and sudden declines in liquidity have become more frequent in both Treasury and equity markets.7 The Commodity Futures Trading Commission also points out that flash events are more common now.8 Market participants suggest that the rapid growth in high-frequency trading in equity, foreign exchange, and U.S. Treasury markets, along with broader concerns about less resilient liquidity, potentially explains these flash events. Nevertheless, a report on the October 15, 2014 event by the staff of the Treasury Department, Federal Reserve, and market regulatory agencies found no single factor that caused the sharp swing in prices.9\n\nA Broader Review of the Evidence\n\n1. Trading costs are low\nEven though flash events appear to be more common, it is certainly too soon to declare that a broad reduction in market liquidity has occurred. Figure 3 plots realized bid-ask spreads for investment-grade corporate bonds over time (the black dashed line) and speculative-grade corporate bonds (the red solid line). Prior to the financial crisis, the cost of trading corporate bonds was low--on average, bid-ask spreads were about 1 percent of the price of the bond for investment-grade bonds and about 2 percent for speculative-grade bonds. This measure of trading costs skyrocketed during the financial crisis but has returned to the range seen in the few years prior to the crisis. Alternative measures of trading costs, such as price impact measures, which attempt to capture the effect of transactions on market prices, follow a similar pattern.\n\nTransaction costs seem to suggest liquidity has improved. One caveat, however, is that measures of aggregate transaction costs in the corporate bond market may underestimate embedded liquidity costs. In preliminary work, Choi and Huh suggest that transactions in which dealers act simply as brokers, rather than as intermediaries that hold assets on their balance sheets, could reflect price concessions that dealers make to entice counterparties into the other side of a trade so that the dealers will not need to hold the traded assets.10 Price concessions, in turn, lower traditional measures of trading costs, making trading seem inexpensive, when in reality these concessions are fees the dealers pay to some investors for providing liquidity. Moreover, as dealer inventories have declined over the past few years, this downward distortion to aggregate trading cost measures may have increased. To address this problem, Choi and Huh try to isolate transactions in which corporate bond investors are looking for liquidity (in other words, are looking to trade) and then construct measures of transaction costs for only such trades. The paper's results are preliminary but appear to suggest transaction costs have increased somewhat in recent years.\n\n2. Trading volume is high\nAnother commonly used measure of liquidity is trading volume. Figure 4 shows trading volume in the corporate bond market. This measure is important because low trading volumes may indicate that high transaction costs have deterred investors from making trades, a phenomenon that transaction cost measures would clearly miss because they are calculated from actual trades. The trading volumes depicted in the figure show no obvious signs of a current problem with market liquidity. In 2006, investors traded an average of $12 billion a day. During the height of the financial crisis, trading volume decreased to $8 billion a day, but, by 2009, volumes appeared to have fully recovered. Today trading volumes are at about $19 billion a day. On balance, the evidence presented in these two figures seems to suggest that market liquidity has not deteriorated in recent years--subject, of course, to the caveat I just discussed about the possibility that our measures of bid-ask spreads could be distorted by the increasing role of investors as suppliers rather than demanders of liquidity.11\n\nAs an aside, the market liquidity figures shown are only for the corporate bond market, but we see similar patterns in the equity and Treasury markets.12 That is, we do not find convincing evidence that liquidity has markedly declined in those markets.\n\nPolicy Issues Related to Market Liquidity\nWhile the evidence for changes in market liquidity does not point clearly to a reduction, I have highlighted some recent research that indicates the possibility that market liquidity has fallen. To date, observed changes in liquidity do not suggest that shifts in liquidity are having a notable effect on the cost of trading. Nonetheless, the potential for liquidity to evaporate in times of stress deserves careful scrutiny--along with broader risks to financial stability associated with changes in markets.\n\nOne area where policy concerns have arisen is related to the potential for fire sales in bond markets, which could compound the risks associated with leverage in the financial sector. Bond markets have grown considerably, and market-based finance has intensified over the past years, making market liquidity even more important.13 In addition, mutual funds that offer daily redemption rights have grown relative to the size of corporate bond markets. As shown in figure 5, assets under management in investment-grade and high-yield corporate bond mutual funds (the solid blue area) have hovered around 25 to 30 percent of the amount of outstanding corporate bonds in recent years, up from about 15 percent before the crisis.i\n\nReduced market liquidity might exacerbate fire sale risks from leverage at financial institutions or from first-mover advantage at mutual funds. Leveraged institutions are more sensitive to changes in asset prices. Adverse movements in asset prices, margin calls, and higher haircuts may force them to sell assets to obtain cash and delever, affecting other market participants through declining asset prices and increased margin calls.\n\nIn addition, leverage may closely interact with liquidity risk at mutual funds. Open-end mutual funds are characterized by the so-called first-mover advantage: Investors can redeem daily from the funds that hold assets that are less liquid, while liquidation costs are borne by investors remaining in the fund. If a decline in bond prices leads to sizable fund withdrawals, the first-mover advantage could accelerate redemptions and second-round price declines. In addition, investors may perceive leveraged funds that experience stress as riskier, possibly becoming more inclined to redeem from these funds. This situation could be worse than in the past if market liquidity deteriorates and dealers are less willing to buy and hold bonds in inventory to cushion the price decline induced by fire sales. However, thanks to recent regulation and supervisory changes, including higher capital requirements and stress tests, leverage at the largest intermediaries is much reduced relative to pre-crisis norms--and, as a result, vulnerabilities from potential fire sale risks are less significant. From this perspective, a small reduction in liquidity from regulatory changes--even if present, which is not obvious--may be a reasonable price to pay for greater safety. I will now place changes in liquidity into the broader context of financial stability.\n\nTradeoff between Liquidity and Regulations to Achieve a Safer Financial System\nIt is possible that regulations aimed at correcting vulnerabilities in the financial system--like the Supplementary Leverage Ratio, together with other factors--have altered the business model of dealer firms and, thus, liquidity. While the evidence for a reduction in market liquidity is far from clear, let us for the moment accept this possibility and consider the potential effects on financial stability.\n\nRegulatory changes, even those that may have reduced market liquidity, likely have enhanced financial stability on balance. Recent evidence indeed points in favor of enhanced financial stability. Regulatory capital ratios for banks and insurance companies remain high, which, as previously mentioned, would mitigate fire sales and their effect on the solvency and functioning of these institutions. Leverage at intermediaries is much reduced relative to pre-crisis norms, and gross leverage at hedge funds, based on the partial information available, has not changed much in recent years. Research from economists at the Federal Reserve Bank of New York shows that the decline in leverage, among other factors, has substantially reduced potential fire sale externalities in the banking and broker-dealer sectors.14 Thus, the regulatory changes appear to be having a positive effect on financial system stability, and these benefits may outweigh the potential costs of a possible reduction in liquidity.\n\nRegulatory changes are in train for the asset management industry, whose vulnerabilities have been under examination by the Financial Stability Oversight Council and the Financial Stability Board.15 The Securities and Exchange Commission (SEC) has recently approved rules to modernize and enhance the reporting and disclosure of information by registered investment companies and to enhance liquidity risk management by open-end funds, including mutual funds and certain exchange-traded funds.16 The SEC has also proposed rules that would put new limits on registered funds' gross notional derivative exposures, enhance the requirements for asset segregation in derivatives transactions, and include new risk-management requirements for the use of derivatives.17\n\nConclusion\nOverall, liquidity is adequate by most measures, in most markets, and most of the time.18 Bid-ask spreads and price-impact measures point toward liquidity that is good by historical standards, and we have not observed declines in market liquidity in recent episodes of high market volatility. Nevertheless, the market structure is changing, and trades in certain situations and in certain market segments might have become more costly. Also, flash events may be more frequent today, and the dynamics of a system with frequent flash events are likely to become complicated. Moreover, some regulatory changes are only now being phased in. In light of these changes and the evolving structure of financial markets, it will be important to monitor and continue to analyze the state of market liquidity. As we monitor, we should continue to emphasize how the evolution of market liquidity interacts with broader changes to affect the efficient allocation of capital and financial stability. And we should always bear in mind the possibility that new financial developments could change the dynamics of market responses to unanticipated economic developments.\n\nReferences\nAdrian, Tobias, Michael Fleming, Daniel Stackman, and Erik Vogt (2015). \"Has Liquidity Risk in the Treasury and Equity Markets Increased?\"  Federal Reserve Bank of New York, Liberty Street Economics (blog), October 6.\n\nBao, Jack, Maureen O'Hara, and Xing (Alex) Zhou (2016). \"The Volcker Rule and Market-Making in Times of Stress,\" working paper, September.\n\nBessembinder, Hendrik, Stacey Jacobsen, William Maxwell, and Kumar Venkataraman (2016). \"Capital Commitment and Illiquidity in Corporate Bonds,\" working paper, July.\n\nChoi, Jaewon, and Yesol Huh (2016). \"Customer Liquidity Provision in Corporate Bond Markets,\" working paper, September.\n\nDuarte, Fernando, and Thomas M. Eisenbach (2013). \"Fire-Sale Spillovers and Systemic Risk (PDF),\"  Federal Reserve Bank of New York Staff Reports 645. New York: Federal Reserve Bank of New York, October (revised February 2015).\n\nDuffie, Darrell (2012). Market Making under the Proposed Volcker Rule (PDF), report to the Securities Industry and Financial Markets Association and submission to the Office of the Comptroller of the Currency, the Board of Governors of the Federal Reserve System, the Federal Deposit Insurance Corporation, and the Securities and Exchange Commission. Stanford, Calif.: Graduate School of Business, Stanford University, January.\n\nFinancial Stability Board (2016). Proposed Policy Recommendations to Address Structural Vulnerabilities from Asset Management Activities (PDF),  consultative document. Basel, Switzerland: FSB, June.\n\nFinancial Stability Oversight Council (2016). Update on Review of Asset Management Products and Activities (PDF). Washington: FSOC, April.\n\nMassad, Timothy (2015). \"Remarks of Chairman Timothy Massad before the Conference on the Evolving Structure of the U.S. Treasury Market,\" speech delivered at the Federal Reserve Bank of New York, New York, October 21.\n\nPowell, Jerome H. (2015). \"Structure and Liquidity in Treasury Markets,\" speech delivered at the Brookings Institution, Washington, August 3.\n\nTrebbi, Francesco, and Kairong Xiao (2015). \"Regulation and Market Liquidity,\" NBER Working Paper Series 21739. Cambridge, Mass.: National Bureau of Economic Research.\n\nU.S. Department of the Treasury, Board of Governors of the Federal Reserve System, Federal Reserve Bank of New York, U.S. Securities and Exchange Commission, and U.S. Commodity Futures Trading Commission (2015). Joint Staff Report: The U.S. Treasury Market on October 15, 2014 (PDF). Washington: Treasury, Board of Governors, FRBNY, SEC, and CFTC, July.\n\nU.S. Securities and Exchange Commission (2015a). \"Open-End Fund Liquidity Risk Management Programs; Swing Pricing; Re-Opening of Comment Period for Investment Company Reporting Modernization Release (PDF),\" proposed rule and re-opening of comment period, releases 33-9922 and IC-31835, files S7-16-15 and S7-08-15. Washington: SEC, October.\n\n-------- (2015b). \"Use of Derivatives by Registered Investment Companies and Business Development Companies (PDF),\" proposed rule, release IC-31933, file S7-24-15. Washington: SEC, December.\n\n1. This is the definition of market liquidity presented in chapter 2 of the IMF's Global Financial Stability Report, September 2015, p. 50. Return to text\n\n2. In this speech, I am discussing market liquidity, not funding liquidity. Return to text\n\n3. I am grateful to Chiara Scotti and Clara Vega of the Federal Reserve Board staff for their assistance. Views expressed are mine and are not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n4. Bessembinder, Jacobsen, Maxwell, and Venkataraman (2016) find that bank dealers are less willing to provide liquidity now than in the recent past, while nonbank dealers are more willing. Duffie (2012) argues that the negative effect the Volcker rule may have on market liquidity in the short run may disappear in the long run as nonbanks step in to provide liquidity. Duffie (2012) also mentions that the migration of liquidity provision from banks to nonbanks, which are not regulated, may have potentially important adverse consequences for financial stability. Return to text\n\n5. See Bao, O'Hara, and Zhou (2016). Return to text\n\n6. See Powell (2015) for a discussion of recent flash events and other changes in the behavior of bond prices. Return to text\n\n7. See Adrian and others (2015). Return to text\n\n8. See Massad (2015). Return to text\n\n9. See U.S. Treasury and others (2015). Return to text\n\n10. See Choi and Huh (2016). Return to text\n\n11. Trebbi and Xiao (2015) analyze multiple corporate bond liquidity measures and conclude that there is no evidence of deterioration in liquidity due to regulation. Return to text\n\n12. Secured funding spreads have increased, suggesting higher intermediation costs in the repo (repurchase agreement) market. Return to text\n\n13. A market-based system is one where securities markets share center stage with banks in allocating capital, in contrast to a bank-based system, where banks play a leading role. Return to text\n\n14. See Duarte and Eisenbach (2013). Return to text\n\n15. See Financial Stability Oversight Council (2016) and Financial Stability Board (2016). Return to text\n\n16. The SEC approved the proposed rule on October 13, 2016. See U.S. Securities and Exchange Commission (2015a). Return to text\n\n17. See U.S. Securities and Exchange Commission (2015b). Return to text\n\n18. I thank Jerome Powell for this statement. Return to text\n\n\n\ni. Note: Update December 21, 2016:  The original version of this speech, referring to figure 5, stated that “In addition, mutual funds that offer daily redemption rights hold a greater share of bonds than investors who buy and hold. As shown in figure 5, the share of investment-grade and high-yield corporate bonds held at mutual funds (the solid blue area) has hovered around 25 to 30 percent in recent years, up from about 15 percent before the crisis.”  The figure shows assets under management by corporate bond mutual funds, not such funds’ holdings of corporate bonds, relative to outstanding corporate bonds.  The text has been revised to correctly describe the figure. Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "November 11, 2016",
        "title": "U.S. Monetary Policy from an International Perspective",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20161111a.htm",
        "content": "November 11, 2016\n\nVice Chairman Stanley Fischer\n\nAt the 20th Annual Conference of the Central Bank of Chile, Santiago, Chile (via videoconference)\n\nI am grateful for the invitation to speak to you today about how U.S. monetary policy affects the global economy and how foreign economic events affect U.S. monetary policy. Given the importance of the United States in international trade and in the global financial system, the monetary policy actions of the Federal Reserve influence the global economy through a wide range of trade and financial channels. As I will discuss, each foreign economy may be affected quite differently by U.S. monetary policy actions, and each may view spillovers from U.S. monetary policy as desirable or undesirable. Even so, I am reasonably confident that the spillovers from ongoing U.S. monetary policy normalization will generally prove manageable for foreign economies.1\n\nWhile most of my discussion will focus on monetary policy spillovers, I will begin by underscoring a different aspect of the interconnectedness of the U.S. economy--namely, how foreign developments have an important influence on U.S. output and inflation, and hence on the conduct of U.S. monetary policy.\n\nHow Foreign Developments Influence U.S. Monetary Policy\nThe U.S. economy is affected significantly by foreign developments through both trade and financial channels. Given that about one-eighth of the goods and services produced in the United States are exported, a sizable component of U.S. aggregate demand depends on foreign consumption and investment decisions, and hence ultimately on the economic health of foreign economies. The high degree of interconnectedness between domestic and foreign financial intermediaries--banks, the nonbank financial sector, and insurers, among others--means that developments in foreign financial markets tend to reverberate quickly back to the United States, including through changes in asset prices and risk tolerance. The pronounced tightening of U.S. financial conditions during the euro-area sovereign debt crisis that occurred from 2011 to 2012 illustrated the strength of these financial ties.\n\nDuring the past couple of years, foreign developments have at times been a substantial headwind for the U.S. economy. Although financial conditions have improved markedly in the advanced foreign economies and their monetary policy has been highly accommodative, these economies have yet to break out from the tepid growth they have experienced since the global financial crisis. Growth in the emerging market economies has also been disappointingly slow. For example, gross domestic product (GDP) growth in Latin America declined to zero last year, far below the 3 to 4 percent growth rates achieved in the first few years of this decade.2 The emerging market economies (EMEs) have weathered several bouts of financial market turbulence, including earlier this year, due to market concerns about economic growth in China and about its exchange rate system. With foreign growth relatively weak, the prospect of a gradual normalization of U.S. monetary policy contributed to a large appreciation of the dollar since mid-2014, with the real effective exchange value of the dollar rising around 17 percent.\n\nThese global developments materially slowed progress toward the Federal Reserve's employment and inflation objectives. The sizable appreciation of the dollar has been a substantial drag on U.S. exports over the past two years, and hence subtracted from economic growth. The stronger dollar, in concert with lower oil and other commodity prices, has also markedly reduced import price inflation and has been a factor keeping inflation well below the Federal Open Market Committee's (FOMC) 2 percent goal.3 These developments have influenced the FOMC's decisions to maintain a very accommodative monetary policy longer than members of the FOMC had expected in 2014 and through the end of 2015.\n\nFinancial market conditions have generally improved relative to earlier in the year, with even the initial market turbulence following the Brexit vote appearing fairly short lived. I am cautiously optimistic that the drag on the U.S. economy and inflation from past dollar appreciation may have mostly worked itself out, and that foreign economies are on a somewhat more secure footing that poses smaller downside risks to the U.S. economy. It is also possible that foreign economies may outperform forecasts, which would provide a boost to U.S. employment prospects and also to inflation. While forecasts are inherently uncertain, we will, as always, pay close attention to foreign developments, given their significant consequences for the U.S. economy, and take such developments into account in determining the appropriate stance of U.S. monetary policy.\n\nKey Channels through Which U.S. Monetary Policy Affects Foreign Economies\nI have focused thus far on the effects of global developments on the U.S. economy and financial markets and argued that these developments may have an important influence on U.S. monetary policy actions. I will next consider how U.S. monetary policy actions tend to affect foreign economies. Spillovers from the policy actions of major central banks, including especially those of the Federal Reserve, have been the focus of analysis and debate for decades and have attracted considerable attention since the global financial crisis.4 Foreign economies were affected when the Fed engaged in unconventional monetary policy stimulus and will likely experience some effects of the Fed's ongoing normalization of policy.\n\nThe Federal Reserve's focus on supporting domestic objectives for inflation and employment has sometimes been criticized as having potentially undesirable effects on the global economy. The unconventional policies that the Federal Reserve implemented following the global financial crisis, and particularly our large-scale asset purchases, have been characterized by some observers as supporting the U.S. economy by putting downward pressure on the dollar and thus hurting our trading partners.5\n\nMy reading of the evidence is that, overall, Federal Reserve policies during that period probably boosted foreign economic output. It is indeed likely that the depreciation of the dollar that accompanied U.S. asset purchases and forward guidance reduced foreign net exports and thus weighed on foreign GDP through the exchange rate channel. However, our accommodative policies also increased U.S. domestic demand, a second key channel of transmission that operated to boost the net exports of our foreign trading partners. Empirical estimates suggest that these countervailing effects roughly canceled each other out, on average, for our trading partners so that their net exports were not very much affected.6 Moreover, insofar as our unconventional policies reduced global interest rates and boosted asset prices--a third channel that tended to expand foreign as well as domestic demand--these actions were probably mildly stimulative for the global economy.\n\nIt may be helpful to provide some ballpark numerical estimates of how these different channels are likely to play out in determining the overall spillovers to foreign GDP by drawing on the research of my Federal Reserve colleagues.7 Specifically, they considered the spillovers from a hypothetical easing of Fed policy scaled to cause the yield on a 10-year U.S. Treasury note to fall 25 basis points.8 This easing by the Fed raises U.S. GDP about 0.5 percent, and--based on event-study analysis--causes the U.S. dollar to depreciate by about 1 percent or perhaps a bit less. While foreign exports are hurt due to the implied appreciation of foreign currencies--reducing foreign GDP about 0.15 percent, according to their estimates--foreign exports are boosted by nearly the same amount due to the policy-induced expansion of U.S. domestic demand. Thus, the overall effect on foreign GDP arising through these two trade channels is negligible. However, given that the fall in U.S. interest rates tends to reduce foreign interest rates--at least on average--by around half as much, my colleagues concluded that U.S. monetary stimulus likely has noticeable positive spillovers to foreign economies.\n\nOf course, there is considerable variation in how Fed policy actions--whether easing or tightening--affect the output of different foreign economies. Economies with more open capital accounts and that keep their exchange rate relatively stable against the dollar experience larger positive effects on their GDP of an expansionary Fed monetary policy action. The larger positive spillovers reflect the fact that their own interest rates move more in lockstep with U.S. interest rates, while the effects on their traded goods sector from the exchange rate channel are smaller. For example, Hong Kong, which has pegged its currency to the U.S. dollar at a fixed exchange rate since 1983, is an extreme illustration of an economy in which Fed actions pass through almost one to one to domestic interest rates. Conversely, spillovers from U.S. policy actions tend to be smaller to economies that have flexible exchange rates and adjust their policy rates based on domestic conditions; or, alternatively, to economies with less open capital accounts such as China.\n\nMost of the advanced foreign economies eventually welcomed the positive spillovers to their domestic output that were due to U.S. unconventional monetary policy easing. Because these economies generally experienced slower recoveries than the United States as well as undesirably low inflation, their central banks also wanted to pursue highly accommodative policies and took complementary actions--including forward guidance and large-scale asset purchases--to spur economic recovery.\n\nBy contrast, the Fed's monetary easing presented the EMEs with more difficult tradeoffs. Output in many EMEs expanded rapidly during the recovery from the global financial crisis, fueled by strong capital inflows and a boom in oil and commodity prices. Given that the Fed's easing raised equity prices and strengthened the demand for risky assets around the globe, it probably contributed to the growing resource pressures in some of these economies. EMEs had to choose between an accommodative monetary policy that was more in line with the United States and other advanced economies versus a tighter policy stance likely to cause their exchange rates to appreciate markedly and possibly cause a relatively sharp contraction in the tradable sectors of their economies. While the more accommodative stance had the attractive feature that it would lessen the hurt to the export sector, the downside was that it was more likely to lead to overheating and high inflation that could be costly to correct.\n\nMy sense is that most EME central banks had considerable latitude to keep inflation near target and output near potential through maintaining a relatively tight policy, and thus to limit spillovers from easing by the advanced economies. But while I think that there is a strong case for focusing on a limited set of objectives, including to ensure that inflation expectations remain firmly anchored, it is also important to recognize the tough tradeoffs faced by EME central banks given their understandable desire to avoid causing a sharp slowdown in exports. The tradeoff faced by EME central bankers helps illustrate some of the challenges posed by monetary policy divergence between the United States and other economies closely tied to it through economic and financial channels.\n\nNotwithstanding these challenges, I should underscore that the Federal Reserve's aggressive monetary easing contributed to a faster stabilization and recovery of the U.S. economy. This benefited the global economy by mitigating a major source of downside risk, thus improving global risk sentiment and confidence. Moreover, the Fed's monetary policy actions were reinforced by many steps to help safeguard the U.S. financial system and increase its resilience to shocks. These efforts included strengthening the banking system's capital buffers, implementing stress tests, reforming short-term wholesale funding markets, and developing swap lines with foreign central banks to help alleviate shortages of dollar liquidity during periods of financial stress. While ultimately aimed at the well-being of U.S. households and firms in pursuit of our domestic objectives, these efforts to improve U.S. financial stability also had favorable externalities for the global financial system and thus helped the global recovery.\n\nU.S. Monetary Policy Going Forward: Prospective Divergence\nPolicy divergence remains a familiar theme today, but the focus has obviously shifted to the consequences of a tightening in U.S. monetary policy on the rest of the global economy. In my view, the Fed appears reasonably close to achieving both the inflation and employment components of its mandate. Accordingly, the case for removing accommodation gradually is quite strong, keeping in mind that the future is uncertain and that monetary policy is not on a preset course. By contrast, the major foreign economies--including the advanced foreign economies and many EMEs--are at a different state of their business cycle and likely to maintain a high level of accommodation for some time or even ease further. So there is likely to be considerable policy rate divergence for some time. What are the likely consequences of this divergence for the foreign economies?\n\nThe \"taper tantrum\" that occurred in the middle of 2013 is interpreted by many observers as illustrating how monetary tightening by the Federal Reserve can exert a strong contractionary effect on our foreign trading partners through its effect on global financial conditions, just as the high level of Fed accommodation after the financial crisis provided a net boost to the global economy. Indeed, the large rise in U.S. bond yields during this episode precipitated a nearly commensurate rise in interest rates in many foreign economies and caused the prices of risky assets to fall globally. EMEs with weak fundamentals experienced sharp capital outflows, an abrupt tightening of financial conditions, and large exchange rate depreciations.9 The EME experience in 2013 seemed reminiscent of past episodes of U.S. tightening--including in the 1980s and again in the mid-1990s--that had sizable adverse spillovers to EMEs, particularly in Latin America.\n\nI am reasonably optimistic that the spillovers from ongoing U.S. normalization will be manageable for the foreign economies, including the EMEs. While there will almost inevitably be some bumps along the road, there are a number of reasons why I think that that policy normalization will not cause sizable disruptions for our trading partners:\n\nWhile there are good grounds to expect that spillovers from U.S. monetary policy actions will be manageable for most of our trading partners, events may unfold differently than expected. To illustrate, a noticeably faster U.S. recovery would require a more rapid removal of U.S. accommodation and could exert noticeably larger spillovers abroad by putting more upward pressure on foreign interest rates and by inducing larger depreciations of foreign currencies. Despite greater policy divergence, many of our trading partners would receive a net boost to their GDP provided that the stimulus to their exports--from stronger U.S. demand and a weaker domestic currency--was sufficient to offset possible tightening in their financial conditions. But other economies might be hurt as a weaker currency could lead to balance sheet deterioration and rising risk spreads, especially if their central banks were called on to tighten monetary policy to keep inflation at bay.\n\nWhile such uncertainty is a constant feature of the landscape we confront as policymakers, both the U.S. and global economies will be served best if we keep our own houses in order and ensure that policy rates are adjusted as appropriate to achieve our inflation and employment objectives. In my view, the prospects of a continued steady expansion in the U.S. economy are maximized to the extent that we proceed with a gradual removal of accommodation. Such a gradual approach to tightening policy will also help mitigate the risk of undesirable spillovers abroad--including by reducing the risk of having to tighten more abruptly later on--and in turn promote a stronger global economy.\n\nReferences\nAmmer, John, Michiel De Pooter, Christopher Erceg, and Steven Kamin (2016). \"International Spillovers of Monetary Policy,\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System, February 8.\n\nBasu, Kaushik, Barry Eichengreen, and Poonam Gupta (2014). \"From Tapering to Tightening: The Impact of the Fed's Exit on India,\" Policy Research Working Paper Series 7071. Washington: World Bank Group, October.\n\nBernanke, Ben (2015). \"Federal Reserve Policy in an International Context (PDF),\" Mundell-Fleming lecture presented at the 16th Jacques Polak Annual Research Conference, International Monetary Fund, Washington, November 5.\n\nCoulibaly, Brahima (2012). \"Monetary Policy in Emerging Market Economies: What Lessons from the Global Financial Crisis? (PDF)\" International Finance Discussion Papers 1042. Washington: Board of Governors of the Federal Reserve System February.\n\nFischer, Stanley (2015). \"The Transmission of Exchange Rate Changes to Output and Inflation,\" speech delivered at \"Monetary Policy Implementation and Transmission in the Post-Crisis Period,\" a research conference sponsored by the Board of Governors of the Federal Reserve System, Washington, November 12.\n\nFleming, J. Marcus (1962). \"Domestic Financial Policies under Fixed and under Floating Exchange Rates,\" International Monetary Fund Staff Papers, vol. 9 (November), pp. 369-80.\n\nFratzscher, Marcel, Marco Lo Duca, and Roland Straub (2013). \"On the International Spillovers of U.S. Quantitative Easing (PDF),\" Working Paper Series 1557. Frankfurt: European Central Bank (June).\n\nGruber, Joseph, Andrew McCallum, and Robert Vigfusson (2016). \"The Dollar in the U.S. International Transactions (USIT) Model,\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System, February 8.\n\nInternational Monetary Fund (2016). World Economic Outlook: Subdued Demand: Symptoms and Remedies (PDF) . Washington: IMF, October.\n\nIrwin, Douglas A. (2012). \"The French Gold Sink and the Great Deflation of 1929-32,\" Cato Papers on Public Policy, vol. 2. Washington: Cato Institute.\n\nMundell, Robert A. (1963). \"Capital Mobility and Stabilization Policy under Fixed and Flexible Exchange Rates,\" Canadian Journal of Economic and Political Science, vol. 29 (November), pp. 475-85.\n\nNeely, Christopher J. (2015). \"Unconventional Monetary Policy Had Large International Effects,\" Journal of Banking and Finance, vol. 52 (March), pp. 101-11.\n\nRogers, John H., Chiara Scotti, and Jonathan H. Wright (2014). \"Evaluating Asset-Market Effects of Unconventional Monetary Policy: A Multi-Country Review,\" Economic Policy, vol. 29 (October), pp. 749-99.\n\nSahay, Ratna, Vivek Arora, Thanos Arvanitis, Hamid Faruqee, Papa N'Diaye, Tommaso Mancini-Griffoli, and an IMF Team (2014). \"Emerging Market Volatility: Lessons from the Taper Tantrum (PDF),\" IMF Staff Discussion Note SDN/14/09. Washington: International Monetary Fund, September.\n\n1. I am grateful to Christopher Erceg of the Federal Reserve Board staff for his assistance. Views expressed are mine and are not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. These estimates are taken from table A1 of the Statistical Appendix of the October 2016 World Economic Outlook and report GDP growth for Latin America and the Caribbean. Return to text\n\n3. My 2015 speech \"The Transmission of Exchange Rate Changes to Output and Inflation\" provides some quantitative assessment of how changes in the dollar affect U.S. output and inflation, including estimates from the staff's empirical model of U.S. trade described in a recent IFDP Notes article by Gruber, McCallum, and Vigfusson (2016). Return to text\n\n4. Exchange rate issues leading up to the Great Depression were prominent, particularly vis-à-vis the French franc, which was returned to the gold standard at what was seen at the time as a highly favorable rate (Irwin, 2012). The pioneering analysis of Mundell (1963) and Fleming (1962) provides the standard framework for post-World War II analysis of the channels through which monetary policy actions are transmitted abroad. In recent years, there has been a rapidly expanding empirical literature assessing spillovers from Federal Reserve policy actions, including those from unconventional policies such as large-scale asset purchases--for example, Fratzscher, DeLuca, and Straub (2013); Rogers, Scotti, and Wright (2014); and Neely (2015). Return to text\n\n5. Bernanke (2015) discusses some of these critiques of Fed policy in the context of a more general analysis of how Fed policies have affected the global economy since the financial crisis. Return to text\n\n6. See Ammer and others (2016) for both a detailed discussion of these channels and estimates of the effects of U.S. monetary policy actions on foreign economies. Return to text\n\n7. See the discussion in section II of Ammer and others (2016). Return to text\n\n8. The policy rate would have to decline by much more than 25 basis points in order to induce the yield on a 10-year U.S. Treasury note to fall by this amount. Return to text\n\n9. See Sahay and others (2014). Return to text\n\n10. Basu, Eichengreen, and Gupta (2014) describe how India's economy and financial markets were affected by the taper tantrum. Return to text\n\n11. Coulibaly (2012) draws on a large cross-country data set to investigate empirically the factors that have allowed EMEs greater scope to pursue countercyclical monetary policies, and it highlights the importance of both inflation targeting and financial reforms that enhance transparency. Return to text\n\n12. The median assessment of FOMC participants in the September 2016 Summary of Economic Projections puts the longer-run level of the nominal federal funds rate at a bit under 3 percent. Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "November 04, 2016",
        "title": "The Economic Outlook",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20161104a.htm",
        "content": "November 04, 2016\n\nVice Chairman Stanley Fischer\n\nAt the 17th Jacques Polak Annual Research Conference, sponsored by the International Monetary Fund, Washington, D.C.\n\nWatch Live\n\nWith today's data in the news, I will first say a few words about labor market conditions before moving on to discuss the economic outlook and monetary policy.1\n\nThe labor market has, by and large, had a pretty good year. Including this morning's release for October, payrolls have increased an average of 181,000 per month this year, a slower pace than last year but enough to keep the unemployment rate flat at about 5 percent. The unchanged unemployment rate reflects a positive, though perhaps transitory, development--mainly a pickup in labor force participation. The rise in participation may reflect the effects of the modest pickup in wages we are now seeing, with the rate of increase in the employment cost index having risen from an annual rate of about 2 percent last year to 2-1/4 percent so far this year.\n\nOver the course of the past two years, a variety of negative shocks have affected the U.S. economy, but employment has resumed robust growth after each temporary slowdown: This recovery has been and continues to be powerful in terms of one of our two main targets--employment--and it is my view that the labor market is close to full employment.\n\nIt is nonetheless interesting to ask what level of payroll gains would maintain an unemployment rate of roughly 5 percent. Unsurprisingly, the level of payroll gains consistent with an unchanged unemployment rate is highly dependent on developments in labor force participation. If labor force participation was to remain flat, job gains in the range of 125,000 to 175,000 would likely be needed to prevent unemployment from creeping up. However, if labor force participation was to decline, as might be expected given demographic trends, the neutral rate of payroll gains would be lower. If we assumed a downward trend in participation of about 0.3 percentage point per year, in line with estimates of the likely drag from demographics, job gains in the range of 65,000 to 115,000 would likely be sufficient to maintain full employment.\n\nLast week we received some encouraging news on output growth. After a slow first half, real gross domestic product (GDP) increased almost 3 percent in the third quarter. However, the details were a little less exciting than the headline number. Household spending growth slowed, and residential investment declined. Business investment in equipment fell for the fourth consecutive quarter. A surge in exports supported growth; however, much of the increase was in shipments of soybeans, while exports of other goods remained tepid. Growth was also supported by a buildup in inventories, breaking a streak of five quarters in which inventories contributed negatively to growth, the longest such run in more than 50 years. Overall, I expect GDP growth to continue at a moderate pace, supported by household spending, renewed business investment, and the waning effects of past dollar appreciation on export growth.\n\nI will now turn to inflation. Headline PCE (personal consumption expenditures) inflation has moved up this year, with the 12-month change reaching 1.2 percent in September. As the transitory effects of the earlier fall in oil prices and rise in the dollar fade, PCE inflation can be expected to rise further toward our 2 percent target, supported by higher core PCE inflation, which ran at a 1.7 percent pace in September.\n\nAs you know, earlier this week, we decided to keep the target range for the federal funds rate at 1/4 to 1/2 percent. As was noted in the Federal Open Market Committee's statement, our assessment is that the most recent data have further strengthened the case for increasing the target range for the federal funds rate.2 The markets put a probability of above 70 percent on the rate being increased in December.\n\nSo far I've been discussing our near-term economic prospects. But the more interesting and important questions relate to the next few years rather than the next few months. They relate in large part to the secular stagnation arguments that were laid out yesterday in Larry Summers' Mundell-Fleming lecture--in particular the behavior of the rate of productivity growth. The statement that the problem we face is largely one of demand--and we do face that problem--seems to imply either that productivity growth is called forth by aggregate demand, or a Say's Law of productivity growth, namely that productivity growth produces its own demand.\n\nThat is not an issue that can be answered purely by theorizing. Rather, it will be answered by the behavior of output and inflation as we approach and perhaps to some extent exceed our employment and inflation targets.\n\n1. Views expressed are mine and are not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. Board of Governors of the Federal Reserve System (2016), \"Federal Reserve Issues FOMC Statement,\" press release, November 2. Return to text"
    },
    {
        "speaker": "Jerome H. Powell",
        "position": "Governor",
        "date": "October 24, 2016",
        "title": "Opening Remarks on Government Securities Settlement",
        "href": "https://www.federalreserve.gov/newsevents/speech/powell20161024.htm",
        "content": "October 24, 2016\n\nGovernor Jerome H. Powell\n\nAt The Evolving Structure of the U.S. Treasury Market: Second Annual Conference, Federal Reserve Bank of New York, New York, New York\n\nWatch live\n\nThis panel will focus on the settlement infrastructure for U.S. government securities--a vital component of the Treasury market and one that is undergoing an important transition. This segment of the industry has been in a period of slow but steady consolidation for several decades now. Thirty years ago, there were six banks providing a full suite of settlement services for U.S. government securities. Due to mergers and exits, two firms, Bank of New York Mellon (BNYM) and J.P. Morgan Chase (JPMC), have been the two dominant providers of these services since the 1990s. And soon there will be just one, given JPMC's planned exit.\n\nGiven the importance of these services, the official sector has had a long involvement as the market structure has evolved. After the terrorist attacks of September 11, 2001, the Federal Reserve convened the private-sector Working Group on Government Securities Clearance and Settlement to recommend steps to mitigate risks to the financial system from a disruption to these services. That work led to the \"NewBank\" proposal.1 Although the proposal was ultimately put aside, NewBank would have been a dormant financial institution that could spring into action in the event of potential disruptions from an exit from this business by either of the clearing banks. Some of today's panelists were actively involved in that work. Of course, at that time, the business was roughly evenly split between the two providers. Today's situation is very different--BNYM now has over 80 percent market share, due mainly to consolidation among end users.\n\nThe Federal Reserve has been working closely with the Department of the Treasury to ensure a smooth transition as JPMC prepares to exit. JPMC has said that it recognizes the need for, and its own interest in, ensuring that its exit does not disrupt the market. Indeed, JPMC will itself need to rely on these services going forward. The timeline set for a gradual transition over the next two years should be sufficient to avoid significant dislocations; however, if unexpected complications arise, that timeline may need to be adjusted.\n\nIn the near term, this exit will leave BNYM as the sole provider of U.S. government securities settlement and triparty repo services for broker-dealers. We have been working intensively with BNYM in anticipation of this transition. We have long recognized that any disruptions to these critical market services could have serious consequences for financial stability, and have calibrated our supervisory expectations accordingly. To ensure financial stability, we expect the provision of U.S. government securities settlement services to be robust in nearly all contingencies.\n\nAs BNYM becomes the sole provider, we will raise our expectations even higher. The bank has anticipated and welcomed this higher bar. BNYM is one of 8 U.S.-based systemically important banks. The bank is therefore subject to heightened capital and liquidity requirements and a resolution process that explicitly requires planning to ensure the continuity of critical services even in the event of a default.\n\nBNYM is unique in that it also plays the dominant--and soon the sole--role in government securities settlement and in the triparty repo market. These activities are comparable in their importance to those of the financial market utilities that have been designated as systemically important by the FSOC. Thus, BNYM will continue to be held to the high standards to which all U.S. bank SIFIs are held. And it will also be expected to operate in a manner that provides confidence that it is as resilient and robust as a systemically important financial market utility (FMU). Such FMUs are, of course, held to the Principles for Financial Market Infrastructures (PFMIs).2 The PFMIs overlap with our banking regulation in many areas; for example, both emphasize the need for sound risk management and the importance of resilience and recovery. The PFMIs also emphasize a strong governance role in support of financial stability and the interests of market functioning, and this has been a focus of our work with Bank of New York Mellon regarding the transition.\n\nAlthough our current task is to establish appropriate expectations for Bank of New York Mellon as a sole operator, that focus should not be taken as an indication that the Federal Reserve or other public authorities have pre-judged what the longer-term landscape for government securities settlement should look like. In fact, we do not have a specific market design end state in mind. Rather, we recognize the systemic importance of these activities and the need to ensure their continued availability in nearly all states of the world, regardless of the firms that offer them or the specific market structure.\n\nThe industry as a whole should play an important role in shaping the evolution of the settlement infrastructure. Other firms may seek to enter this market. There have also been discussions over time of a settlement utility, and the Depository Trust & Clearing Corporation is currently considering a new variant of such a model. Our focus is on the quality of the services offered--their safety, resilience, and support of the market--and not on the particular mechanism for offering them. If new proposals come forward that are consistent with our goals of a safe and resilient settlement system, then they will receive fair consideration.\n\n1. Report to the Federal Reserve Board by the Working Group on NewBank Implementation (PDF), December 2005. Return to text\n\n2. See Committee on Payment and Settlement Systems and the International Organization of Securities Commissions (2012), Principles for Financial Market Infrastructures , report (Basel, Switzerland: Bank for International Settlements, April).  Return to text"
    },
    {
        "speaker": "Daniel K. Tarullo",
        "position": "Governor",
        "date": "October 21, 2016",
        "title": "Pedagogy and Scholarship in a Post-Crisis World",
        "href": "https://www.federalreserve.gov/newsevents/speech/tarullo20161021a.htm",
        "content": "October 21, 2016\n\nGovernor Daniel K. Tarullo\n\nAt the Conference on the New Pedagogy of Financial Regulation, Columbia Law School, New York, New York\n\nLet me begin with the most prosaic of observations: The events of 2007-09 will be remembered not as a banking crisis, but as a financial crisis. Neither the origins nor the transmission of stress were limited to the traditional banking system of commercial banks and thrifts. While Wachovia and Washington Mutual failed, and other large depository institutions survived only because of government support, the more spectacular failures were those of nonbank financial firms--including American International Group (AIG), Bear Stearns, Lehman Brothers, and the government-sponsored enterprises Fannie Mae and Freddie Mac. Repurchase agreement (repo) and commercial paper markets depended on government liquidity to continue operating, as did money market funds.\n\nIt is thus unsurprising that, in approaching regulatory reform after the crisis, both the official sector and academics have focused more on the financial system as a whole. The shift is apparent in the very diction of post-crisis regulatory initiatives. The Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank Act) refers dozens of times to \"financial stability\" and \"systemic risk.\" A special regulatory structure has been developed for \"G-SIBs\"--that is, banks of global systemic importance--and a new category of designated systemically important nonbank financial companies has been created. This shift is also reflected in the titles and intellectual approaches of the two books that were discussed at this conference earlier this morning--that is, financial regulation. The authors of both books have eschewed the traditional concentration on banking or securities law alone, and have even moved beyond the more innovative pre-crisis casebooks that focused on the differential regulation of various forms of financial institutions.1\n\nThis broader category of \"financial regulation\" as the relevant delineation of an academic subject area seems right to me. For one thing, different forms of financial intermediation are--if not equally attractive for the preferences of specific investors and users of capital--at least significantly overlapping in the roles they can play. Beginning in the 1970s these overlaps multiplied, as the traditional separation of lending and capital market activities--which had been reinforced by the Glass-Steagall Act--began to break down under the weight of macroeconomic turbulence, technological and business innovation, and competition. In the 30 years that followed, these activities were progressively integrated further, both within bank holding companies and beyond, ultimately producing the explosive growth of money market, securitization, and derivative instruments.\n\nMore fundamentally, the broader category of \"financial regulation\" reflects the importance of a macroprudential, or systemic, perspective on the financial system. This means taking account of the relationships among the circumstances and activities of significant financial actors through such channels as funding dependencies and correlated assets. The financial crisis has made what was formerly a minority view--the need to incorporate systemic considerations into the regulatory regime--into something approaching a consensus.\n\nBut this shift of perspective--whether in pedagogy or in policy--raises as many questions as it answers. My remarks this morning will detail some of the questions that have recurred in regulatory deliberations in recent years, which I believe to be salient for policy, scholarship, and pedagogy. Then, more briefly, I will make a few observations about teaching and scholarship from the broadened perspective of financial regulation. I should note at the outset that, in the interest of time, I will confine myself to the prudential aspects of financial regulation.\n\nThinking Through a More Integrated Approach to Financial Regulation\nIt is only moderately reductionist to say that, from the New Deal through the crisis, the nature and scope of regulation was determined by the categorization of financial actors. If an entity was classified as a bank or a broker-dealer or an investment company, it was subject to a regulatory regime fashioned to deal with the risks associated with that form of intermediation or, perhaps more precisely, the risks that were perceived to be so associated. Such an approach always provided for some interesting legal discussions, since forms of intermediation that served similar purposes and carried broadly similar risks might be subject to quite different regulatory constraints.\n\nBut when, as noted earlier, nonbank forms of intermediation began to threaten traditional bank intermediation and when, in what was at least partly an effort to maintain the franchise value of commercial banks, strictures on bank activities and affiliations were significantly relaxed, the foundation of the New Deal regime was substantially eroded. With the notable exception of an increased emphasis on capital, which itself was decidedly microprudential in focus, the prudential regime was not shored up or extended to other kinds of intermediaries, much less replaced--a signal failure that contributed to the severity of the crisis. This may be a good point at which to note in passing that the pre-crisis failures were not limited to the underappreciation of systemic or macroprudential risks. Even from a purely microprudential perspective, for example, the Basel II changes to the capital requirements for large banks were ill-conceived.2\n\nA natural reaction to this legacy might be to shift from a regime based predominantly on the form of an intermediary to one built predominantly on its functions. As a practical matter, though, much post-crisis regulatory reform has been directed at strengthening the traditional form-based foundation, though perhaps to a somewhat greater degree in the United States than in some other financially important jurisdictions. And, at a conceptual level, some features of particular forms of intermediaries--such as being an insured depository institution rather than a money market fund--remain rightly important for regulatory purposes. So we will probably continue to build on a form-based regulatory regime, though the potential range of complementary function-based measures could be quite extensive. And, at the very least, analyses based on function rather than form can be valuable heuristic exercises for identifying inconsistencies and lacunae in the financial regulatory system.\n\nA first set of questions follows from just such an identification of gaps in the regulatory system, which are arguably most troubling when they relate to systemic considerations--that is, when a financial intermediary or activity may contribute to risk in the financial system because of the related positions or activities of others. Two critical gaps highlighted by the crisis were the inadequate prudential regulation of the most systemically important financial institutions (SIFIs) and the sometimes nonexistent prudential regulation of the many activities now denominated as \"shadow banking.\"\n\nThe SIFI issue has received the most public attention, often in the context of too-big-to-fail concerns. It was at the center of some of the most notable provisions of the Dodd-Frank Act, many of which follow from the important principle enunciated in section 165 that prudential regulation should become increasingly stringent for institutions of greater systemic importance. Precisely because a satisfactory treatment of this topic would require at least one lengthy speech on its own, it seems reasonably clear that teaching and scholarship should highlight the SIFI problem, appraise the regulatory approach toward such institutions since the crisis, and consider alternatives.\n\nAn appraisal of whether more or, as some would have it, fewer measures are needed under the approach taken in the Dodd-Frank Act and related regulatory actions will, I admit, be a little challenging. Some measures--including stress testing, capital requirements, and resolution planning--are still in train, and others may be forthcoming as a result of the research program the Federal Reserve is launching to consider the potential for additional explicitly macroprudential features in capital and liquidity stress testing.3 Still, I think it is feasible to teach and assess the general approach of using multiple regulatory tools that impose requirements that force systemically important firms to internalize the costs their distress or failure would impose on the financial system, and then leaving the regulated firms to make decisions as to how to alter their size and activities in order to make themselves most profitable within the stricter regulatory constraints. This approach can be usefully compared to structural or other approaches to the SIFI issue, such as caps on overall size or reimposition of the Glass-Steagall separation of commercial and investment banking.\n\nIn addressing this topic, I have found it useful to try to specify as clearly as possible the adverse systemic consequences that may be feared by public authorities confronting the possible failure of a systemically important institution. This exercise helps identify the regulatory measures that would be most effective in promoting the resiliency and orderly resolvability of such institutions. On virtually any short list of concerns would be reliance on short-term wholesale funding sources, which may dry up quickly under stressed conditions. A firm with inadequate sources of liquidity may then be forced into responses with systemic implications, such as fire sales of assets and termination of credit extensions to their own counterparties.\n\nThe other major vulnerability revealed by the financial crisis was systemic risk that may be created through so-called shadow banking activities--that is, credit intermediation outside the prudentially regulated banking system. Here is where the integration of traditional lending and capital markets is most clearly in evidence, albeit in quite different ways. In truth, many shadow banking channels passed through prudentially regulated institutions, as with the notorious structured investment vehicles and asset-backed commercial paper conduits. Changes in accounting and in bank capital and liquidity requirements have done a great deal to guard against a recurrence of such patterns in the future, though continued monitoring will be needed to prevent the development of other forms of support that elude these regulatory measures.\n\nOf greater interest for financial regulation going forward will be the constantly changing, and largely unrelated, set of intermediation activities pursued by very different types of financial market actors. While the extent of shadow banking has significantly diminished since the crisis, there is good reason to believe that it will grow in the future. Indeed, the very rigor of new regulations applicable to firms within the prudential perimeter may well incentivize more innovation outside that perimeter. It will be essential to disaggregate all the activities that might be characterized as shadow banking in order to regulate those that pose risks to the financial system while not unduly burdening forms of credit extension that may more or less benignly help meet the savings and investment needs of households and businesses. This task is perhaps summed up by the fact that activities which in one context are called \"shadow banking\" are in other contexts called \"market-based financing.\"\n\nOne might fairly characterize the current regulatory approach to shadow banking as one that examines, in turn, significant forms of credit intermediation outside the banking system and determines whether some type of prudential regulation is needed. In the terms I introduced a moment ago, regulators look at a particular form, such as money market funds. If no significant risks to financial stability are identified, or if some regulation to counteract those risks is implemented, the form of intermediation may then be thought of as relatively safe (at least from a systemic perspective) market-based finance. The virtue of this approach is that it allows for a very tailored regulatory response. But, as you can imagine, this approach necessarily involves a good bit of active oversight on an ongoing basis, both of measures previously taken and of new channels of nonbank intermediation as they arise.\n\nAn alternative approach would be to define shadow banking in broadly applicable terms, with specified regulatory consequences that ensue more or less automatically, regardless of whether the entity conducting the shadow banking is otherwise subject to prudential regulation. To date, the attempts I have seen along these lines look likely to entail substantial overinclusion, substantial underinclusion, or regulatory consequences that are inappropriately uniform. And, in the United States and other jurisdictions, it is not clear that authority exists to take this approach, either by an individual regulatory agency or even collectively. But, as with hypothesizing a functionally-based regulatory system more generally, hypothesizing a broadly applicable regulatory definition can usefully inform the direction of the current regulatory approach of activity-by-activity scrutiny.\n\nOf course, while the current approach allows for an ad hoc consideration of the particulars of each activity, it still requires at least a general filter for identifying sources of systemic risk. My own sense is that the greatest risks to financial stability lie in activities with vulnerability to funding runs and asset fire sales. These may be associated either with some of the same kinds of short-term funding found in systemically important banking organizations or in the potential for rapid and substantial investor redemptions of their holdings in certain investment funds. Where substantial leverage--either nominal or synthetic--is also present, the risks are only greater. Efforts to calibrate these, and possibly other, risks will remain an important feature of shadow banking regulation, along with refining ways in which such risks may be mitigated.\n\nBefore turning to another, though related, set of questions, let me digress a bit to note another implication of a regime in which regulation is developed with a view to risks to the financial system as a whole. The motivation both for more stringent regulation of systemically important firms and for regulation of shadow banking arises in large part from the potential contribution of each to systemwide contagion. A complementary motivation for some macroprudential measures is the importance of maintaining effective financial intermediation even during a period of severe recession or financial stress. But this reasoning should, I think, move us toward less regulatory stringency for some parts of the financial system, as well as greater stringency in other parts. For example, as banking regulation is strengthened to take account of the progressively more systemic significance of larger or more complicated institutions, there is a good argument for a less demanding regime for smaller institutions whose contribution to systemic contagion would almost surely be somewhere between modest and inconsequential. This observation raises the issue, which I have discussed previously, as to whether even within a particular form-based area of financial regulation we should be moving toward quite different regimes.4\n\nThe next set of questions raised by a systemwide perspective on financial regulation can be described much more briefly. It pertains to the appropriate target once a need for regulation has been established. The selection among, and mix of targets for, systemically-motivated regulation will be an important determinant of the character of financial regulation in the years ahead.\n\nThe relevant choices here are frequently identified in binary terms--that is, the regulation may be directed either at financial institutions or financial activities. This leads to confusion because, for example, what has been described as an \"activities-based\" approach to dealing with the potential risks posed by certain asset management activities actually involves regulation of the firms involved in those activities, such as through liquidity and risk management requirements. I suspect this confusion has arisen because, in the minds of some, \"institution-based\" regulation has become close to synonymous with banking regulation. Thus those opposed to, say, capital requirements for a particular kind of intermediary will advocate for activities-based regulation.\n\nMy own sense is that it is useful to distinguish three possible targets of regulation--specific financial institutions, financial business models, and financial transactions. Most financial regulation, historically and contemporaneously, falls within what I would describe as business model regulation. So, for example, any entity engaged in the \"business of banking\" is subject to the panoply of requirements found in Title 12 of the U.S. Code. Similarly, the requirements imposed on money market funds by the Securities and Exchange Commission (SEC), and being considered for application to asset management activities, are also targeted at a business model, even though the kind of regulation is quite different from that applicable to insured depository institutions.\n\nIn contrast, my taxonomy would categorize regulation as targeted at a specific institution when it applies because of the particular characteristics of that institution, not simply because of its business model (or models). Thus, the designation of a nonbanking firm as systemically important by the Financial Stability Oversight Council (FSOC) under the authority of the Dodd-Frank Act is made because the size, portfolios, activities, and other characteristics of the specific firm are found on an individualized basis to meet the statutory standard of nonbank systemic importance. Similarly, the determination of the capital surcharge applicable to SIFIs is made on the basis of the particular \"systemic footprint\" of the firm.\n\nFinally, a transaction-based requirement is one that would be binding on anyone involved in such a transaction (with perhaps some de minimis exceptions), regardless of their status as a particular kind of financial intermediary. An example would be the minimum margining requirements on securities financing transactions that have been agreed to at the Financial Stability Board (FSB), which the Federal Reserve will be proposing through a rulemaking next year.\n\nOf course, a particular firm may be a target under two, or possibly all three, approaches. But it is important to identify clearly why a regulation is deemed necessary and, accordingly, how it should be targeted. In the framework I have set forth, for example, institution-specific measures may be thought of as those needed to protect financial stability even though a firm is already subject to business model regulation. And a transaction-based measure may be thought of as one needed to protect financial stability regardless of whether all entities that might engage in such a transaction need to be regulated because of the risks associated with their business models.\n\nMy third set of questions pertains to the scope and allocation of government authority for financial regulation. With some relatively modest exceptions, authority in the New Deal regime was determined based on the distinct regulatory aims established for different kinds of financial intermediaries, the oversight of which was assigned to different agencies. The allocation basically followed the Glass-Steagall Act's separation of commercial and investment banking. But, over time, both markets and regulatory change complicated this fairly simple picture: markets complicated this as both banks and broker-dealers invented new ways of doing business that allowed each to take on risks previously reserved for the other, and regulatory changes saw shifts in the relationship of the Federal Reserve's authority as holding company regulator and that of the SEC or Commodity Futures Trading Commission as primary regulator of important nonbank holding company subsidiaries.\n\nThe additional regulatory authorities and mandates in the Dodd-Frank Act have created a quite different landscape from the pre-crisis regulatory terrain. Many of these authorities and mandates are explicitly tied to financial stability goals--a sharp departure from pre-crisis circumstances. Many must be exercised jointly by two or more agencies--in rulemakings, implementation, or both. And, of course, the Dodd-Frank Act created the FSOC--an unusual entity in U.S. administrative law.\n\nAppreciating this new configuration of authorities is important as a positive matter for understanding how regulation will be shaped over time and identifying possible remaining gaps in regulatory authority. It is also important as a normative matter in considering whether the allocation of authorities proves optimal over time. Here one would want to look at factors of efficacy, expertise, and excessive concentrations of authority, among others. In this regard, I would suggest that a comparison of the reconfigured financial regulatory system in the United Kingdom serves as an instructive counterpoint to the U.S. system.\n\nSome Thoughts on Post-Crisis Scholarship Topics and Pedagogy\nScholarship\nInsofar as I have succeeded in identifying questions that will be central to the further development and refinement of a regulatory system that takes account of the financial system as a whole, all of what I have already said should be fertile ground for legal and economic scholarship. However, not every important topic for research fits neatly into one of these cross-cutting issues, so let me mention some policy issues that may especially benefit from academic work.\n\nFirst is the issue of measures and standards for evaluating systemic risk. Numerous financial economists have done very useful work in creating metrics for the systemic importance of financial institutions--a literature that has already informed regulatory efforts to designate and categorize such institutions and, as it develops further, will surely continue to do so.5 But there are also specific legal standards, such as the financial stability factor now mandated in the review of proposed bank and holding company mergers, that could also benefit from academic work.6\n\nSecond is the set of issues associated with corporate governance in a prudentially regulated institution. John Armour, Lucien Bebchuk, Jeff Gordon, Jon Macey, and others have already tackled some of these issues--such as incentive compensation arrangements, the appropriate duties for boards of directors in such institutions, and the appropriate scope of supervisory expectations for boards.7 These issues remain worthy of discussion. The preceding questions and others, such as the advisability of a requirement for a non-executive chair of the board, have only grown in significance since I spoke to this topic a couple of years ago.8\n\nThird is the subject of overseeing the regulators, which includes such matters as the advisability of publicly releasing some or all supervisory ratings and informal enforcement actions. You may recall that our decision in 2009 to release the results of our stress test--a practice that we have continued in subsequent years--was quite controversial, but has proven to be enormously helpful both for giving investors in the firms and the public a better sense for how the Federal Reserve is conducting its capital regulation policies.\n\nFourth is the rather broad topic of the implications of technological innovation for financial services regulation and, indeed, for the competitive position of insured depository institutions. Many innovations now promising dramatic change in the way that credit is extended will probably end up having considerably less impact. But some could prove significant. I suspect that innovations in payments systems are quite likely to have far-reaching effects, including the growth of what might be termed the \"shadow payment system\" at the retail level. Here, by the way, I am departing a bit from my self-limitation to prudential issues, since consumer protection issues around alternative payments systems may be quite significant.\n\nFifth is the organization of the international system for financial regulation. The issues here are in some sense familiar from pre-crisis days: To what degree can host countries responsibly rely on home jurisdiction consolidated regulation and supervision of large and internationally active financial institutions? How should international cooperative efforts to set minimum prudential standards be brought together with domestic legal processes for financial regulation? These familiar questions have taken on new significance in light of the post-crisis emphasis on the financial system as a whole, including the varieties of shadow banking. So too the differing circumstances and legal systems of notable financial jurisdictions, which raise anew the question of how much international harmonization is ultimately desirable. The creation of the FSB, and greater emphasis on international standards in the International Organization of Securities Commissions and the International Association of Insurance Supervisors have substantially changed the relevant international organization chart from the days when only the Basel Committee on Banking Supervision produced such standards.\n\nPedagogy\nHaving not taught financial regulation since the interesting months of the fall 2008 semester, I am probably at a comparative disadvantage to most of this audience in reflecting on the new pedagogy of financial regulation. However, that will not stop me from making a couple of comments--though only a couple--on the core topic of this conference.\n\nFirst, I would urge everyone teaching in this area to place much more emphasis on the liability side of the balance sheets of financial institutions. Traditional banking law casebooks gave some treatment to deposits and deposit insurance, which provided a good point in a course to engage students on the subject of moral hazard. But the whole concept of runnable liabilities--whether uninsured deposits, repo, commercial paper, or other forms--was left largely untouched, even for commercial banks, much less for broker-dealers like Lehman Brothers or insurance holding companies like AIG. And, of course, in the pre-crisis period there was no quantitative liquidity regulation to include in a casebook.\n\nYet the financial crisis was, at least in its more virulent periods, as much a funding crisis as it was a solvency crisis. Indeed, the very fact that it may be difficult to distinguish clearly between the two is indicative of the primacy of funding to the crisis. Particularly in the context of systemic risk, funding and liquidity issues accordingly deserve something close to the attention devoted to capital if students are to understand the origins of the crisis, the regulatory response, and the challenges of regulation going forward. A focus on liabilities will help students understand why, for example, the Federal Reserve plans on setting capital standards differently for traditional insurance companies (that is, not the pre-crisis AIG) than for bank holding companies and their affiliates. An emphasis on runnable funding will help them see why systemic concerns extend beyond SIFIs as such. It also provides a good occasion for introducing students to the role of a lender of last resort, now perhaps more of a contested concept than had previously been assumed.\n\nI have considerably less conviction regarding my second comment, but I offer it anyway, perhaps to contribute to the pedagogical discussions that will be bred by this conference. Let me preface the observation by noting that were I to teach financial regulation again, the course would have to differ markedly from that fall 2008 version. Still, I wonder whether students will acquire a strong enough foundation for understanding how a financial regulatory system works in a course that is taught essentially as a survey of financial regulatory issues, without some point of reference to which they can return as they proceed through the course (or, more probably, as they cram for the exam). I was always struck by how much of a conceptual anchor for a banking law course was provided by the famous Corrigan/Aspinwall debate on whether banks were \"special.\"9 One could note, for example, that Aspinwall's observation that banks were becoming less special might have suggested that other forms of intermediaries should be more regulated, rather than the implication that banks should be less regulated. Indeed, my rereading of the companion pieces suggests that despite--or maybe because of--the fact that the debate is now more than 30 years old, it might profitably introduce a course that ventures well beyond traditional banking regulation, by its invitation to consider why we regulate in the first place.\n\nConclusion\nI began teaching in this area just as the Gramm-Leach-Bliley Act was culminating three decades of bank deregulation. At the time, I suggested to students that the regulation of banking organizations was in an unstable equilibrium. While I initially meant the adjective mostly to refer to doctrine, it became progressively more applicable to the financial system itself. The implementation of the regulatory aims established after the crisis, along with the inevitable refinements of what has already been done, will continue to play out for some time. The upshot, I think, is both an unusually important time to be researching and writing in this area and an unusually challenging time to be teaching it. This conference has been an excellent occasion for helping to shape both a research agenda and a new pedagogy.\n\n\n\n1. Howell E. Jackson and Edward J. Symons, Jr. (1999), Regulation of Financial Institutions (St. Paul, MN: West Group). Return to text\n\n2. See Daniel K. Tarullo (2008), Banking on Basel: The Future of International Financial Regulation (Washington, DC: Peter G. Peterson Institute for International Economics), pp. 178-82. Return to text\n\n3. See Daniel K. Tarullo (2016), \"Next Steps in the Evolution of Stress Testing,\" speech delivered at the Yale University School of Management Leaders Forum, New Haven, CT, September 26. Return to text\n\n4. See, e.g., Daniel K. Tarullo (2014), \"Rethinking the Aims of Prudential Regulation,\" speech delivered at the Federal Reserve Bank of Chicago Bank Structure Conference, Chicago, IL, May 8. Return to text\n\n5. Tobias Adrian and Markus K. Brunnermeier (2016), \"CoVaR,\"  American Economic Review, vol. 106 (July), pp. 1705-41; Fernando Duarte and Thomas M. Eisenback (2013; revised 2015), \"Fire-Sale Spillovers and Systemic Risk,\"  Federal Reserve Bank of New York Staff Report, no. 645; and Christian T. Brownlees and Robert F. Engle (2016), \"SRISK: A Conditional Capital Shortfall Measure of Systemic Risk,\" available at https://ssrn.com/abstract=1611229  or http://dx.doi.org/10.2139/ssrn.1611229 . Return to text\n\n6. Daniel K. Tarullo (2012), \"Financial Stability Regulation,\" speech given at the University of Pennsylvania School of Law Distinguished Jurist Lecture, Philadelphia, PA, October 10. Return to text\n\n7. See, e.g., John Armour and Jeffrey Gordon (2014), \"Systemic Harms and Shareholder Value,\" Journal of Legal Analysis, vol. 6, no. 1 (Spring), pp. 35-85; Lucian A. Bebchuk and Holger Spamann (2010), \"Regulating Bankers' Pay,\" Georgetown Law Journal, vol. 98, no. 2, pp. 247-87; Jonathan Macey and Maureen O'Hara (2016), \"Bank Corporate Governance: A Proposal for the Post-Crisis World,\"  Federal Reserve Bank of New York, Economic Policy Review, vol. 22, no. 1 (August), pp. 85-105. Return to text\n\n8. Daniel K. Tarullo (2014), \"Corporate Governance and Prudential Regulation,\" speech given at the Association of American Law Schools 2014 Midyear Meeting, Washington, DC, June 9. Return to text\n\n9. See E. Gerald Corrigan (1982), \"Are Banks Special?\" Federal Reserve Bank of Minneapolis Annual Report, available at www.minneapolisfed.org/publications/annual-reports/are-banks-special; and Richard Aspinwall (1983), \"On the 'Specialness' of Banking,\" Issues in Banking Regulation, vol. 7 (Autumn), pp. 16-22. Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "October 17, 2016",
        "title": "Why Are Interest Rates So Low? Causes and Implications",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20161017a.htm",
        "content": "October 17, 2016\n\nVice Chairman Stanley Fischer\n\nAt the Economic Club of New York, New York, New York\n\nI am grateful to the Economic Club of New York for inviting me to speak today. My subject is the historically low level of interest rates, a topic not far from the minds of many in this audience and of many others in the United States and all over the world.1\n\nNotwithstanding the increase in the federal funds rate last December, the federal funds rate remains at a very low level. Policy rates of many other major central banks are lower still--even negative in some cases, even in countries long famous for their conservative monetary policies. Long-term interest rates in many countries are also remarkably low, suggesting that participants in financial markets expect policy rates to remain depressed for years to come. My main objective today will be to present a quantitative assessment of some possible factors behind low interest rates--and also of factors that could contribute to higher interest rates in the future.\n\nNow, I am sure that the reaction of many of you may be, \"Well, if you and your Fed colleagues dislike low interest rates, why not just go ahead and raise them? You are the Federal Reserve, after all.\" One of my goals today is to convince you that it is not that simple, and that changes in factors over which the Federal Reserve has little influence--such as technological innovation and demographics--are important factors contributing to both short- and long-term interest rates being so low at present.\n\nThere are at least three reasons why we should be concerned about such low interest rates. First, and most worrying, is the possibility that low long-term interest rates are a signal that the economy's long-run growth prospects are dim. Later, I will go into more detail on the link between economic growth and interest rates. One theme that will emerge is that depressed long-term growth prospects put sustained downward pressure on interest rates. To the extent that low long-term interest rates tell us that the outlook for economic growth is poor, all of us should be very concerned, for--as we all know--economic growth lies at the heart of our nation's, and the world's, future prosperity.\n\nA second concern is that low interest rates make the economy more vulnerable to adverse shocks that can put it in a recession. That is the problem of what used to be called the zero lower bound on interest rates. In light of several countries currently operating with negative interest rates, we now refer not to the zero lower bound, but to the effective lower bound, a number that is close to zero but negative. Operating close to the effective lower bound limits the room for central banks to combat recessions using their conventional interest rate tool--that is, by cutting the policy interest rate. And while unconventional monetary policies--such as asset purchases, balance sheet policies, and forward guidance--can provide additional accommodation, it is reasonable to think these alternatives are not perfect substitutes for conventional policy. The limitation on monetary policy imposed by low trend interest rates could therefore lead to longer and deeper recessions when the economy is hit by negative shocks.\n\nAnd the third concern is that low interest rates may also threaten financial stability as some investors reach for yield and compressed net interest margins make it harder for some financial institutions to build up capital buffers. I should say that while this is a reason for concern and bears continual monitoring, the evidence so far does not suggest a heightened threat of financial instability in the post-financial-crisis United States stemming from ultralow interest rates. However, I note that a year ago the Fed did issue warnings--successful warnings--about the dangers of excessive leveraged lending, and concerns about financial stability are clearly on the minds of some members of the Federal Open Market Committee, FOMC.\n\nThose are three powerful reasons to prefer interest rates that are higher than current rates. But, of course, Fed interest rates are kept very low at the moment because of the need to maintain aggregate demand at levels that will support the attainment of our dual policy goals of maximum sustainable employment and price stability, defined as the rate of inflation in the price level of personal consumption expenditures (or PCE) being at our target level of 2 percent.\n\nThat the actual federal funds rate has to be so low for the Fed to meet its objectives suggests that the equilibrium interest rate--that is, the federal funds rate that will prevail in the longer run, once cyclical and other transitory factors have played out--has fallen.2 Let me turn now to my main focus, namely an assessment of why the equilibrium interest rate is so low.\n\nTo frame this discussion, it is useful to think about the real interest rate as the price that equilibrates the economy's supply of saving with the economy's demand for investment. To explain why interest rates are low, we look for factors that are boosting saving, depressing investment, or both.3 For those of you lucky enough to remember the economics you learned many years ago, we are looking at a point that is on the IS curve--the investment-equals-saving curve. And because we are considering the long-run equilibrium interest rate, we are looking at the interest rate that equilibrates investment and saving when the economy is at full employment, as it is assumed to be in the long run.\n\nI will look at four major forces that have affected the balance between saving and investment in recent years and then consider some that may be amenable to the influence of economic policy.\n\nThe economy's growth prospects must be at the top of the list. Among the factors affecting economic growth, gains in productivity and growth of the labor force are particularly important. Second, an increase in the average age of the population is likely pushing up household saving in the U.S. economy. Third, investment has been weak in recent years, especially given the low levels of interest rates. Fourth and finally, developments abroad, notably a slowing in the trend pace of foreign economic growth, may be affecting U.S. interest rates.\n\nTo assess the empirical importance of these factors in explaining low long-run equilibrium interest rates, I will rely heavily on simulations that the Board of Governors' staff have run with one of our main econometric models, the FRB/US model. This model, which is used extensively in policy analyses at the Fed, has many advantages, including its firm empirical grounding, and the fact that it is detailed enough to make it possible to consider a wide range of factors within its structure.\n\nGoing through the four major forces I just mentioned, I will look first at the effect that slower trend economic growth, both on account of the decline in productivity growth as well as lower labor force growth, may be having on interest rates. Starting with productivity, gains in labor productivity have been meager in recent years. One broad measure of business-sector productivity has risen only 1-1/4 percent per year over the past 10 years in the United States and only 1/2 percent, on average, over the past 5 years. By contrast, over the 30 years from 1976 to 2005, productivity rose a bit more than 2 percent per year. Although the jury is still out on what is behind the latest slowdown in productivity gains, prominent scholars such as Robert Gordon and John Fernald suggest that smaller increases in productivity are the result of a slowdown in innovation that is likely to persist for some time.4\n\nLower long-run trend productivity growth, and thus lower trend output growth, affects the balance between saving and investment through a variety of channels. A slower pace of innovation means that there will be fewer profitable opportunities in which to invest, which will tend to push down investment demand. Lower productivity growth also reduces the future income prospects of households, lowering their consumption spending today and boosting their demand for savings. Thus, slower productivity growth implies both lower investment and higher savings, both of which tend to push down interest rates.5\n\nIn addition to a slower pace of innovation, it is also likely that demographic changes will weigh on U.S. economic growth in the years ahead, as they have in the recent past. In particular, a rising fraction of the population is entering retirement. According to some estimates, the effects of this population aging will trim about 1/4 percentage point from labor force growth in coming years.6\n\nLower trend increases in productivity and slower labor force growth imply lower overall economic growth in the years ahead. This view is consistent with the most recent Summary of Economic Projections of the FOMC, in which the median value for the rate of growth in real gross domestic product (GDP) in the longer run is just 1-3/4 percent, compared with an average growth rate from 1990 to 2005 of around 3 percent.7\n\nWe can use simulations of the FRB/US model to infer the consequences of such a slowdown in longer-run GDP growth for the equilibrium federal funds rate. Those simulations suggest that the slowdown to the 1-3/4 percent pace anticipated in the Summary of Economic Projections would eventually trim about 120 basis points from the longer-run equilibrium federal funds rate.8\n\nLet me move now to the second major development on my list. In addition to its effects on labor force growth, the aging of the population is likely to boost aggregate household saving. This increase is because the ranks of those approaching retirement in the United States (and in other advanced economies) are growing, and that group typically has above-average saving rates.9 One recent study by Federal Reserve economists suggests that population aging--through its effects on saving--could be pushing down the longer-run equilibrium federal funds rate relative to its level in the 1980s by as much as 75 basis points.10\n\nIn addition to slower growth and demographic changes, a third factor that may be pushing down interest rates in the United States is weak investment. Analysis with the FRB/US model suggests that, given how low interest rates have been in recent years, investment should have been considerably higher in the past couple of years. According to the model, this shortfall in investment has depressed the long-run equilibrium federal funds rate by about 60 basis points.\n\nInvestment may be low for a number of reasons. One is that greater perceived uncertainty could also make firms more hesitant to invest. Another possibility is that the economy is simply less capital intensive than it was in earlier decades.11\n\nFourth on my list are developments abroad: Many of the factors depressing U.S. interest rates have also been working to lower foreign interest rates. To take just one example, many advanced foreign economies face a slowdown in longer-term growth prospects that is similar to that in the United States, with similar implications for equilibrium interest rates in the longer run. In the FRB/US model, lower interest rates abroad put upward pressure on the foreign exchange value of the dollar and thus lower net exports. FRB/US simulations suggest that a reduction in the equilibrium federal funds rate of about 30 basis points would be required to offset the effects in the United States of a reduction in foreign growth prospects similar to what we have seen in the United States.\n\nThe first figure shows the effects of these four factors. You will see that each factor is considered separately; there is no attempt to add them together. That is because the broad factors we are considering here could well overlap--particularly the link between slower growth and the remaining three factors. Still, the comparison gives us a notion of the relative importance of some of the leading explanations for the decline in interest rates.\n\nI started by noting the costs of low interest rates, including the limits on the ability of monetary policy to respond to recessions, and possible risks to financial stability. Now that we have some notion of where lower interest rates might be coming from, I want to turn to the question of what might contribute to raising longer-run equilibrium interest rates.12\n\nOne development that would boost the equilibrium interest rate would be a further waning in the investor precaution that seems to have been holding back investment--in Keynesian terms, an improvement in animal spirits. The first bar in the second slide illustrates the effects on the longer-run equilibrium federal funds rate of an increase in business-sector investment equal to 1 percent of GDP. As can be seen, such a rebound in investment would raise the equilibrium funds rate by 30 basis points, according to the FRB/US model. In addition, higher investment would improve the longer-run growth prospects of the U.S. economy, although the effects in this particular case are fairly small, with real GDP growth about 0.1 percentage point higher on account of the higher investment.\n\nOver the years, many economists--some of them textbook authors--have noted that expansionary fiscal policy could raise equilibrium interest rates.13 To illustrate this possibility, the next two bars on the slide show the estimated effect on interest rates of two possible expansionary fiscal policies, one that boosts government spending by 1 percent of GDP and another that cuts taxes by a similar amount. According to the FRB/US model, both policies, if sustained, would lead to a substantial increase in the equilibrium federal funds rate. Higher spending of this amount would raise equilibrium interest rates by about 50 basis points; lower taxes would raise equilibrium rates by 40 basis points. I should note that the FRB/US model does not contain a great deal of detail about taxes and government spending. These are thus the effects of very broad changes in income taxes and government spending, and not those of any specific, detailed, policy measures.\n\nIt is important to emphasize that these estimates are from just one model and other models may give different results. Still, I think these implications of fiscal policy measures are qualitatively correct--they are a standard result in many models, including the simplest textbook IS-LM model.\n\nStimulative fiscal policies such as these could be beneficial if the economy confronted a recession. Of course, it would be important to ensure that any fiscal policy changes during a recession did not compromise long-run fiscal sustainability.\n\nGovernment policies that boost the economy's long-run growth rate would be an even better means of raising the equilibrium interest rate. This is a point I have also made in the past.14 While there is disagreement about what the most effective policies would be, some combination of more encouragement for private investment, improved public infrastructure, better education, and more effective regulation is likely to promote faster growth of productivity and living standards--and also to reduce the probability that the economy and, particularly, the central bank will in the future have to contend with the effective lower bound.\n\nIn summary, a variety of factors have been holding down interest rates and may continue to do so for some time. But economic policy can help offset the forces driving down longer-run equilibrium interest rates. Some of these policies may also help boost the economy's growth potential.\n\n\n\n\n\n\n\nReferences\nAaronson, Stephanie, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014), \"Labor Force Participation: Recent Developments and Future Prospects (PDF),\"  Brookings Papers on Economic Activity (Fall), pp. 197-255.\n\n\n\nBoard of Governors of the Federal Reserve System (2016), \"Federal Reserve Board and Federal Open Market Committee Release Economic Projections from the September 20-21 FOMC Meeting,\" press release, September 21.\n\n\n\nCarvalho, Carlos, Andrea Ferrero, and Fernanda Nechio (2016). \"Demographics and Real Interest Rates: Inspecting the Mechanism (PDF),\"  Working Paper Series 2016-05. San Francisco: Federal Reserve Bank of San Francisco, April.\n\n\n\nFernald, John, and Bing Wang (2015). \"The Recent Rise and Fall of Rapid Productivity Growth (PDF),\"  FRBSF Economic Letter 2015-04. San Francisco: Federal Reserve Bank of San Francisco, February.\n\n\n\nFischer, Stanley (2016). \"Remarks on the U.S. Economy,\" speech delivered at \"Program on the World Economy,\" a conference sponsored by The Aspen Institute, Aspen, Colo., August 21.\n\n\n\nGagnon, Etienne, Benjamin K. Johannsen, and David Lopez-Salido (2016). \"Understanding the New Normal: The Role of Demographics (PDF),\" Finance and Economics Discussion Series 2016-080. Washington: Board of Governors of the Federal Reserve System, October.\n\n\n\nGordon, Robert J. (2016). The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War. Princeton, N.J.: Princeton University Press.\n\n\n\nHamilton, James D., Ethan S. Harris, Jan Hatzius, and Kenneth D. West (2015). \"The Equilibrium Real Funds Rate: Past, Present, and Future (PDF)\"  NBER Working Paper no. 21476 (August).\n\n\n\nHilsenrath, Jon and Bob Davis (2016). \"Tech Boom Creates Too Few Jobs,\" Wall Street Journal, vol. 168, no. 88 (October 13, 2016), p. 1.\n\n\n\nHolston, Kathryn, Thomas Laubach, and John C. Williams (forthcoming). \"Measuring the Natural Rate of Interest: International Trends and Determinants,\" in Richard Clarida and Lucrezia Reichlin, organizers, NBER International Seminar on Macroeconomics 2016. Amsterdam: Journal of International Economics (Elsevier).\n\n\n\nJohannsen, Benjamin K., and Elmar Mertens (2016). \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, February 9.\n\n\n\nKiley, Michael T. (2015). \"What Can the Data Tell Us about the Equilibrium Real Interest Rate? (PDF)\" Finance and Economics Discussion Series 2015-077. Washington: Board of Governors of the Federal Reserve System, September.\n\n\n\nKocherlakota, Narayana (2015). \"Public Debt and the Long-Run Neutral Real Interest Rate,\"  speech delivered at Northwestern University, Evanston, Ill., September 8.\n\n\n\n-------- (2016). \"Write Your Congressperson! (If You Want Higher Interest Rates),\" Kocherlakota's Thoughts on Policy (blog), January 19, https://sites.google.com/site/kocherlakota009/home/policy/thoughts-on-policy/1-19-16.\n\n\n\nLaubach, Thomas, and John C. Williams (2003). \"Measuring the Natural Rate of Interest,\"  Review of Economics and Statistics, vol. 85 (November), pp. 1063-70.\n\n\n\nRachel, Lukasz, and Thomas D. Smith (2015). \"Secular Drivers of the Global Real Interest Rate (PDF),\"  Staff Working Paper 571. London: Bank of England, December.\n\n\n\nSummers, Lawrence H. (2014). \"U.S. Economic Prospects: Secular Stagnation, Hysteresis, and the Zero Lower Bound,\" Business Economics, vol. 49 (April), pp. 65-73.\n\n\n\n-------- (2015). \"Demand Side Secular Stagnation,\" American Economic Review, vol. 105 (May), pp 60-65.\n\n\n\n-------- (2016). \"The Age of Secular Stagnation: What It Is and What to Do about It,\" Foreign Affairs, vol. 95 (March/April), pp. 2-9, https://www.foreignaffairs.com/articles/united-states/2016-02-15/age-secular-stagnation.\n\n\n\n\n\n1. I am grateful to John Roberts and Robert Tetlow of the Federal Reserve Board staff for their assistance. Views expressed are mine and are not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. More formally, my Federal Reserve colleagues Thomas Laubach and John Williams (2003) have developed a statistical procedure that decomposes the movement in interest rates into the contribution of long-run and short-run factors. They conclude that the long-run component of the level of the real federal funds rate is currently very low--around 1/4 percent--compared with a pre-2000 average of 2-1/2 percent. Other assessments have reached similar conclusions. See Holston, Laubach, and Williams (forthcoming); Johannsen and Mertens (2016); and Kiley (2015). However, it is important to note that there is a great deal of statistical uncertainty around all of these estimates. Return to text\n\n3. While the analysis that follows relates to interest rates in the long run, these factors are also important determinants of interest rates in the short run. Return to text\n\n4. See Gordon (2016) and Fernald and Wang (2015). Return to text\n\n5. These effects are what we would expect from our textbook models; they are also at work in the FRB/US model being used here. The empirical evidence on the link between trend growth and long-run equilibrium interest rates is mixed. Laubach and Williams (2003) find evidence of a link that is consistent with the predictions of models such as FRB/US. However, in their well-known paper, Hamilton et al. (2016) conclude that while \"the theoretical presumption that there is a link between aggregate growth and real rates is very strong,\" the empirical link between the real equilibrium interest rate and real GDP growth is weak. As stressed by Hamilton et al. there a great deal of uncertainty over the relationship between growth and interest rates, likely, in part because of the multitude of shocks to which the economy is subject. A structural model, such as FRB/US, provides one method of estimating the link between growth and interest rates by examining the reaction of the interest rate to a clearly defined shock to the trend growth rate. However, this reaction occurs within the model economy, and is therefore subject to the particular structure and assumptions of the FRB/US model. Return to text\n\n\n\n6. See, for example, Aaronson et al (2014). Return to text\n\n7. See Board of Governors of the Federal Reserve System (2016). Return to text\n\n8. Details of the simulations are included in an Appendix to the speech. Return to text\n\n9. See Gagnon, Johannsen, and Lopez-Salido (2016); Rachel and Smith (2015); and Carvalho, Ferrero, and Necchio (2016). Return to text\n\n10. See Gagnon, Johannsen, and Lopez-Salido (2016), figure 12. Return to text\n\n11. See Summers (2014, 2015, 2016). See also Hilsenrath and Davis (2016). Return to text\n\n12. By emphasizing \"longer-run equilibrium\" interest rates, I am excluding monetary policy (which is unlikely to have major effects on the equilibrium real interest rate), and thereby also relating to concerns about monetary policy being the only game in town. Return to text\n\n13. See, for example, Kocherlakota (2015, 2016) and Summers (2016). Return to text\n\n14. For instance, in Fischer, 2016. Return to text\n\n\n\nAppendix\n\nHere we review the simulations that underlie the estimates of the effects of various economic disturbances for their implications for the long-run equilibrium real federal funds rate, using simulations of the staff's FRB/US model. We first provide background on the methodology we use. We then review the nature of the shocks that are discussed in the speech and show the effects of those shocks on the long-run federal funds rate. Finally, we provide details about the results shown in the figures.\n\n1. Background\n\nOur point of departure is a definition of the equilibrium interest rate that corresponds with the neutral rate of interest. In particular, we use the definition of the neutral rate of interest that Chair Yellen used in a 2015 speech: \"the real rate consistent with the economy achieving maximum employment and price stability over the medium term,\" which, in an elaboration in a footnote, is said to be \"usually thought of as independent of the cyclical disturbances that routinely buffet the economy...[that] fade away after a few years.\"1 The sort of disturbances being captured under the rubric of shifts in r* are thus rarer and more persistent than the usual business cycle phenomena and are associated with the \"various adjustment processes that are unusually drawn out by historical standards...[and have] slow-moving influences on both aggregate demand and supply.\"2 This definition corresponds reasonably closely with the (possibly time-varying) intercept of a Taylor-type rule in that the standard arguments of the Taylor (1999) rule--the output gap and the deviation of inflation from target--can be thought of as capturing the influence of the drivers of monetary policy at business cycle frequencies, with the longer-lasting (lower-frequency) determinants of the level of the policy rate being subsumed into movements in r*.3\n\nUsing this definition of r*, we identify several economic disturbances that have long-lasting consequences for the savings-investment balance of the U.S. economy. We shock the FRB/US model with each of these disturbances and compute what long-lasting (but not necessarily permanent) shift in the intercept of the Taylor (1999) rule is the best perturbation to the rule.\n\nThe thought experiment behind the simulations is as follows. We assume that the public views the Taylor (1999) rule as a good approximation of the conduct of monetary policy, and, accordingly, they price assets and formulate expenditure decisions on the expectation that this policy will prevail. Then policymakers identify that the economy is encountering a shock with durable implications for the savings-investment balance of the economy. At this point, policymakers communicate to the public a long-lasting shift to the intercept of the rule. Private-sector agents are assumed to understand this communication, and find it credible, and thus adjust their expectations accordingly.\n\n2. The shocks\n\nAll simulations were carried out using the database from the public release of the FRB/US model, starting in 2036:Q1, at which time the economy is in steady state.4 Accordingly, the effective lower bound on nominal interest rates is never a binding constraint under these circumstances. Consistent with the definition of a steady state, at the start of the simulations, the output gap is closed, the unemployment rate is equal to its natural rate of 4.8 percent, inflation is 2 percent, the nominal federal funds rate is 3 percent, the 10-year Treasury bond rate is 3.5 percent, and potential output growth is 2 percent. Except as otherwise noted, tax rates are held fixed at their baseline levels for four years, after which fiscal policy is allowed to respond by gradually adjusting the federal personal income tax rate to stabilize the ratio of federal government fiscal deficits to gross domestic product (GDP) at its assumed baseline target level. In all instances, monetary policy is assumed to be governed by the (non-inertial) Taylor (1999) rule, with an intercept shift where applicable.\n\nTable A.1 summarizes the effects of several shocks on the long-run equilibrium real federal funds rate in the FRB/US model. The details of how these shocks were implemented follow.\n\nLabor force. The growth rate of the U.S. population (variable N16 in the FRB/US model) is assumed to climb over the course of a year to a pace that is 1 percentage point faster than in the baseline, with commensurate effects on the labor force, employment, potential output, and actual output. The elevated pace of population growth lasts for 20years before returning to baseline rates over the succeeding 5 years.\n\nProductivity. The growth rate of total factor productivity (HMFPT) is increased 0.7 percentage point, which implies an acceleration in labor productivity (output per worker hour) of 1.0 percentage point. The shock lasts for 40 years before fading out at a moderate pace.\n\nInvestment. Sequences of shocks to the FRB/US model's three equations for business fixed investment--producer durables (EPD), intellectual property (EPI), and nonresidential structures (EPS)--are constructed such that the total increase in gross fixed capital investment equals 1 percent of GDP for 25 years. Thereafter, the shocks fade at a moderate rate over time. The shocks are scaled such that the split between the three components is about equal to their relative shares of GDP since 2001.\n\nCost of capital. Relative to its average over the period from 2000 to 2007, the financial cost of capital (RPD) has declined by about two percentage points, according to the FRB/US model database. That should have produced a boom in investment, which seems not to have happened. This shock computes the magnitude of this \"missing effect\" by simulating the effect of an increase in the financial cost of capital. RPD affects the user cost of capital for the model's four investment categories: equipment, intellectual property, nonresidential structures and inventories. Those, in turn, influence target rates of investment, all else equal. The shock lasts for 20 years before fading out at a moderate pace.\n\nForeign interest rates. The equilibrium real interest rate in (trade-weighted) foreign economies (FRSTAR) is assumed to decline by 1 percentage point for an indefinite period. This decline has the effect of reducing both foreign long- and short-term interest rates by a comparable amount.\n\nGovernment spending. An increase in the level of federal expenditures on goods (EGFO) equal to 1 percent of GDP is sustained for 25 years and then phased out at a moderate pace thereafter. All other components of government spending are held at their baseline levels. The federal personal income tax rate is held at baseline for 10 years, and then the model's fiscal policy reaction function is allowed to adjust the tax rate so as to return the ratio of federal deficits to GDP to its previous target level. The government-debt-to-GDP ratio is therefore allowed to permanently increase.\n\nTax cut. The model's fiscal policy reaction function is suspended for 10 years, similar to the case of the government spending shock described previously. A sequence of shocks to the FRB/US model's equation for the average federal personal income tax rate (TRFP) is constructed such that the resulting decrease in taxes increases the federal budget deficit very similarly to the government spending shock described previously, in order to make the two simulations of comparable magnitude. After 10 years, the personal federal tax rate is allowed to adjust to bring the ratio of government deficits to GDP back to the baseline target level. The government-debt-to-GDP ratio is permanently increased.\n\n* In the current context, rr* is defined as the intercept of the Taylor (1999) rule.\n\n3. Calculations for figures\n\nFigure 1: Effects on the long-run equilibrium federal funds rate\n\nSlower growth. The slower growth of 1-1/4 percentage points in this scenario assumes that labor force growth is 1/4 percentage point lower and that labor productivity growth is 1 percentage point lower. According to table A.1, an increase of 1 percentage point in labor force growth would raise the equilibrium real federal funds rate by 1.15 percentage points. The contribution of the slower labor force growth to the equilibrium federal funds rate is therefore negative 0.25 x 1.15, or negative 30 basis points. Similarly, the contribution of slower productivity growth is negative 1.00 x 0.85 = negative 85 basis points, for a total effect of negative 115 basis points.\n\nDemographics. As explained in the text, the effect of demographics on the equilibrium federal funds rate is based on the study of Gagnon, Johannsen, and Lopez-Salido (2016), who emphasize that demographic changes since the 1980s would imply a reduction of 125 basis points in the equilibrium federal funds rate. However, this number includes the effects of demographics on the labor force, which have already been included in the growth effect. As suggested by figure 12 of Gagnon, Johannsen, and Lopez-Salido (2016), adjusting for the effects of employment would trim about 50 basis points from the total effect (the distance between the solid-blue and dashed-green lines as of 2015). Thus, in Gagnon, Johannsen, and Lopez-Salido (2016), the effects excluding those via labor force growth are about negative 75 basis points.\n\nLower investment. This experiment corresponds to the cost of capital shock discussed in section 2, with the sign reversed. As can be seen in line 4 of table A.1, the \"missing effects\" of a 2 percentage point decrease in the financial cost of capital would have lowered the equilibrium real funds rate by 63 basis points.\n\nSlower foreign growth. Here, we assume that foreign trend GDP growth has fallen as much as U.S. trend GDP growth and thus has had a similar effect on interest rates--namely, 115 basis points. That assumption would imply a reduction in the (U.S.) equilibrium federal funds rate of negative 1.15 x 0.27, or negative 30 basis points.\n\nFigure 2: Long-run effects of animal spirits and fiscal policy on interest rates\n\nThis figure shows the effects of shocks that lead to 1 percentage point shifts in each of the variables indicated. These simulations can be found directly in table A.1. Thus, the animal spirits shock in figure 2 corresponds to the investment shock shown in line 3 of table A.1. And the government spending and tax cut simulations shown in figure 2 line up with the simulations shown in lines 6 and 7 of table A.1.\n\nReferences\n\nBoard of Governors of the Federal Reserve System (2016). \"FRB/US Model,\" webpage, Board of Governors.\n\nGagnon, Etienne, Benjamin K. Johannsen, and David Lopez-Salido (2016). \"Understanding the New Normal: The Role of Demographics (PDF),\" Finance and Economics Discussion Series 2016-080. Washington: Board of Governors of the Federal Reserve System, October.\n\nTaylor, John B. (1999). \"A Historical Analysis of Monetary Policy Rules,\" in John B. Taylor, ed., Monetary Policy Rules. Chicago: University of Chicago Press, pp. 319-41.\n\nWilliams, John C. (2016). \"Monetary Policy in a Low R-Star World,\" FRBSF Economic Letter 2016-23. San Francisco: Federal Reserve Bank of San Francisco, August.\n\nYellen, Janet L. (2015a). \"Normalizing Monetary Policy: Prospects and Perspectives,\" speech delivered at \"The New Normal Monetary Policy,\" a research conference sponsored by the Federal Reserve Bank of San Francisco, San Francisco, March 27.\n\n-------- (2015b). \"Inflation Dynamics and Monetary Policy,\" speech delivered at the Philip Gamble Memorial Lecture, University of Massachusetts, Amherst, Mass., September 24.\n\n-------- (2015c). \"The Economic Outlook and Monetary Policy,\" speech delivered at the Economic Club of Washington, Washington, December 2.\n\n-------- (2016). \"Current Conditions and the Outlook for the U.S. Economy,\" speech delivered at the World Affairs Council of Philadelphia, Philadelphia, June 6.\n\n\n\n1. See Yellen (2015a), paragraph 15 and footnote 4. Return to text\n\n2. See Yellen (2015a), footnote 4. Other definitions of the neutral rate used by the Chair in her public communications include the short-term real interest rate \"that would be neither expansionary nor contractionary if the economy was operating near potential\" (Yellen, 2015c, 2016) and the short-term real interest rate \"that would be consistent with real GDP expanding in line with potential\" (Yellen, 2015b). There may be circumstances in which the nuances of these definitions would matter, but, for our purposes, we can take them as one and the same. Return to text\n\n3. Williams (2016) defines the natural rate of interest as the short-term real rate \"that balances monetary policy so that it is neither accommodative nor contractionary in terms of growth and inflation.\" This description is close to that of the neutral rate (but not the natural rate) in the main text and in note 2 but adds a reference to inflation, which does not appear in definitions of the neutral rate. Return to text\n\n4. See Board of Governors (2016). Return to text"
    },
    {
        "speaker": "Janet L. Yellen",
        "position": "Chair",
        "date": "October 14, 2016",
        "title": "Macroeconomic Research After the Crisis",
        "href": "https://www.federalreserve.gov/newsevents/speech/yellen20161014a.htm",
        "content": "October 14, 2016\n\nChair Janet L. Yellen\n\nAt \"The Elusive 'Great' Recovery: Causes and Implications for Future Business Cycle Dynamics\" 60th annual economic conference sponsored by the Federal Reserve Bank of Boston, Boston, Massachusetts\n\nWatch live: https://www.bostonfed.org/live\n\nExtreme economic events have often challenged existing views of how the economy works and exposed shortcomings in the collective knowledge of economists. To give two well-known examples, both the Great Depression and the stagflation of the 1970s motivated new ways of thinking about economic phenomena. More recently, the financial crisis and its aftermath might well prove to be a similar sort of turning point. Today I would like to reflect on some ways in which the events of the past few years have revealed limits in economists' understanding of the economy and suggest several important questions I hope the profession will try to answer. Some of these questions are not new, though recent events have made them more urgent. Appropriately, some are addressed by the papers prepared for this conference. Pursuing answers to these questions is vital to the work of Federal Reserve and other economic policymakers, and the Fed is likewise engaged in ongoing research to seek answers.\n\nThe Influence of Demand on Aggregate Supply\nThe first question I would like to pose concerns the distinction between aggregate supply and aggregate demand: Are there circumstances in which changes in aggregate demand can have an appreciable, persistent effect on aggregate supply?\n\nPrior to the Great Recession, most economists would probably have answered this question with a qualified \"no.\" They would have broadly agreed with Robert Solow that economic output over the longer term is primarily driven by supply--the amount of output of goods and services the economy is capable of producing, given its labor and capital resources and existing technologies. Aggregate demand, in contrast, was seen as explaining shorter-term fluctuations around the mostly exogenous supply-determined longer-run trend.1 This conclusion deserves to be reconsidered in light of the failure of the level of economic activity to return to its pre-recession trend in most advanced economies. This post-crisis experience suggests that changes in aggregate demand may have an appreciable, persistent effect on aggregate supply--that is, on potential output.2\n\nThe idea that persistent shortfalls in aggregate demand could adversely affect the supply side of the economy--an effect commonly referred to as hysteresis--is not new; for example, the possibility was discussed back in the mid-1980s with regard to the performance of European labor markets.3 But interest in the topic has increased in light of the persistent slowdown in economic growth seen in many developed economies since the crisis. Several recent studies present cross-country evidence indicating that severe and persistent recessions have historically had these sorts of long-term effects, even for downturns that appear to have resulted largely or entirely from a shock to aggregate demand.4 With regard to the U.S. experience, one study estimates that the level of potential output is now 7 percent below what would have been expected based on its pre-crisis trajectory, and it argues that much of this supply-side damage is attributable to several developments that likely occurred as a result of the deep recession and slow recovery.5 In particular, the study finds that in the wake of the crisis, the United States experienced a modest reduction in labor supply as a result of reduced immigration and a fall in labor force participation beyond what can be explained by cyclical conditions and demographic factors, as well as a marked slowdown in the estimated trend growth rate of labor productivity. The latter likely reflects an unusually slow pace of business capital accumulation since the crisis and, more conjecturally, the sharp decline in spending on research and development and the very slow pace of new firm formation in recent years.6\n\nIf we assume that hysteresis is in fact present to some degree after deep recessions, the natural next question is to ask whether it might be possible to reverse these adverse supply-side effects by temporarily running a \"high-pressure economy,\" with robust aggregate demand and a tight labor market. One can certainly identify plausible ways in which this might occur. Increased business sales would almost certainly raise the productive capacity of the economy by encouraging additional capital spending, especially if accompanied by reduced uncertainty about future prospects. In addition, a tight labor market might draw in potential workers who would otherwise sit on the sidelines and encourage job-to-job transitions that could also lead to more-efficient--and, hence, more-productive--job matches.7 Finally, albeit more speculatively, strong demand could potentially yield significant productivity gains by, among other things, prompting higher levels of research and development spending and increasing the incentives to start new, innovative businesses.\n\nHysteresis effects--and the possibility they might be reversed--could have important implications for the conduct of monetary and fiscal policy. For example, hysteresis would seem to make it even more important for policymakers to act quickly and aggressively in response to a recession, because doing so would help to reduce the depth and persistence of the downturn, thereby limiting the supply-side damage that might otherwise ensue. In addition, if strong economic conditions can partially reverse supply-side damage after it has occurred, then policymakers may want to aim at being more accommodative during recoveries than would be called for under the traditional view that supply is largely independent of demand.\n\nMore research is needed, however, to better understand the influence of movements in aggregate demand on aggregate supply.8 From a policy perspective, we of course need to bear in mind that an accommodative monetary stance, if maintained too long, could have costs that exceed the benefits by increasing the risk of financial instability or undermining price stability. More generally, the benefits and potential costs of pursuing such a strategy remain hard to quantify, and other policies might be better suited to address damage to the supply side of the economy.\n\nHeterogeneity\nMy second question asks whether individual differences within broad groups of actors in the economy can influence aggregate economic outcomes--in particular, what effect does such heterogeneity have on aggregate demand?\n\nMany macroeconomists work with models where groups of individual actors, such as households or firms, are treated as a single \"representative\" agent whose behavior stands in for that of the group as a whole. For example, rather than explicitly modeling and then adding up the separate actions of a large number of different households, a macro model might instead assume that the behavior of a single \"average\" household can describe the aggregate behavior of all households.\n\nPrior to the financial crisis, these so-called representative-agent models were the dominant paradigm for analyzing many macroeconomic questions. However, a disaggregated approach seems needed to understand some key aspects of the Great Recession. To give one example, consider the effects of negative housing equity on consumption. Although households typically reduce their spending in response to wealth declines, the many households whose equity positions in their homes were actually driven negative by the reduction in house prices may have curtailed their spending even more sharply because of a markedly reduced ability to borrow. Such a development, in turn, would shift the relationship between housing equity (which remained solidly positive in the aggregate) and consumer spending for the economy as a whole. Such a shift in an aggregate relationship would be difficult to understand or predict without using disaggregated data and models.\n\nMore generally, studying the effects of household and firm heterogeneity might help us better account for the severity of the recession and the slow recovery. At the household level, recent research finds that heterogeneity can amplify the effects of adverse shocks, a result that is largely driven by households with very little net worth that sharply increase their savings in a recession.9 At the firm level, there is evidence that financial constraints had a particularly large adverse effect on employment at small firms and the start-up of new firms, factors that may be part of the explanation for the Great Recession's long duration and the subsequent slow recovery.10 More generally, if larger firms seeking to expand have better access to credit than smaller ones, overall growth in investment and employment could depend in part on the distribution of sales across different types of businesses. Modeling any of these issues quantitatively will likely require the use of a heterogeneous-agent framework.\n\nEconomists' understanding of how changes in fiscal and monetary policy affect the economy might also benefit from the recognition that households and firms are heterogeneous. For example, in simple textbook models of the monetary transmission mechanism, central banks operate largely through the effect of real interest rates on consumption and investment. Once heterogeneity is taken into account, other important channels emerge. For example, spending by many households and firms appears to be quite sensitive to changes in labor income, business sales, or the value of collateral that in turn affects their access to credit--conditions that monetary policy affects only indirectly. Studying monetary models with heterogeneous agents more closely could help us shed new light on these aspects of the monetary transmission mechanism.\n\nWhile the economics profession has long been aware that these issues matter, their effects had been incorporated into macro models only to a very limited extent prior to the financial crisis.11 I am glad to now see a greater emphasis on the possible macroeconomic consequences of heterogeneity, including in work by economists at the Federal Reserve.12 Nevertheless, the various linkages between heterogeneity and aggregate demand are not yet well understood, either empirically or theoretically. More broadly, even though the tools of monetary policy are generally not well suited to achieve distributional objectives, it is important for policymakers to understand and monitor the effects of macroeconomic developments on different groups within society.\n\nFinancial Linkages to the Real Economy\nMy third question concerns a key issue for monetary policy and macroeconomics that is less directly addressed by this conference: How does the financial sector interact with the broader economy?\n\nIn light of the housing bubble and subsequent events, policymakers clearly need to better understand what kinds of developments contribute to financial crises. What is the relationship between the buildup of excessive leverage and the value of real estate and other types of collateral, and what factors impede or facilitate the deleveraging process that follows? Does the economic fallout from a financial crisis depend on the particulars of the crisis, such as whether it involves widespread damage to household balance sheets? How does the nature and degree of the interconnections between financial firms affect the propagation and amplification of stress through the financial system and overall economy? Finally--and most importantly--what can monetary policy and financial oversight do to reduce the frequency and severity of future crises?\n\nAlthough the scope of these questions extends beyond the themes of this conference, it does include issues that are closely related. Consider the influence of balance sheet conditions and noninterest credit terms on spending and overall activity--an area where it is important to take account of differences across individual households and firms, as I just noted. Research on this topic has, of course, been ongoing for some time, and it has expanded greatly in the wake of the financial crisis.13 But I believe we have a lot more to learn about the ways in which changes in underwriting standards and other determinants of credit availability interact with interest rates to affect such things as consumer spending, housing demand and home prices, business investment (especially for small firms), and the formation of new firms.14 For example, is the persistent increase in the personal saving rate that we have observed since the collapse of the housing bubble primarily a result of a sustained shift toward more prudent underwriting standards by lenders? Is it something that will ultimately prove transitory once householdsfinish repairing their balance sheets or become more confident about their future prospects for employment and income?15 The answer to thislatter question could have significant implications for the longer-run normal, or neutral, level of interest rates and thus for the conduct of monetary policy.\n\nInflation Dynamics\nMy fourth question goes to the heart of monetary policy: What determines inflation?\n\nFrom my perspective, the standard framework for thinking about inflation dynamics used by central bank economists and others prior to the financial crisis remains conceptually useful today. A simple description of this framework might go something like this:16 Inflation is characterized by an underlying trend that has been essentially constant since the mid-1990s; previously, this trend seemed to drift over time, influenced by actual past inflation or other economic conditions. Theory and evidence suggest that this trend is strongly influenced by inflation expectations that, in turn, depend on monetary policy. In particular, the remarkable stability of various measures of expected inflation in recent years presumably represents the fruits of the Federal Reserve's sustained efforts since the early 1980s to bring down and then stabilize inflation at a low level. The anchoring of inflation expectations that has resulted from this policy does not, however, prevent actual inflation from fluctuating from year to year in response to the temporary influence of movements in energy prices and other disturbances. In addition, inflation will tend to run above or below its underlying trend to the extent that resource utilization--which may serve as an indicator of firms' marginal costs--is persistently high or low.17\n\nWhile this general framework for thinking about the inflation process remains useful, questions about some of its quantitative features have arisen in the wake of the Great Recession and the subsequent slow recovery. For example, the influence of labor market conditions on inflation in recent years seems to be weaker than had been commonly thought prior to the financial crisis. Although inflation fell during the recession, the decline was quite modest given how high unemployment rose; likewise, wages and prices rose comparatively little as the labor market gradually recovered. Whether this reduction in sensitivity was somehow caused by the recession or instead pre-dated it and was merely revealed under extreme conditions is unclear.18 Either way, the underlying cause is unknown. Does the reduced sensitivity reflect structural changes, such as globalization or a greater role for intangible capital in production that have reduced the importance of cyclical swings in domestic activity for firms' marginal costs and pricing power? Or does it perhaps reflect the well-documented reluctance--or, alternatively, limited ability--of firms to cut the nominal wages of their employees, which could help to explain the relatively moderate movements in inflation we saw during and after the recession?19\n\nAnother gap in our knowledge about the nature of the inflation process concerns expectations. Although many theoretical models suggest that actual inflation should be most closely related to short-run inflation expectations, as an empirical matter, measures of long-run expectations appear to explain the data better.20 Yet another unresolved issue concerns whose expectations--those of consumers, firms, or investors--are most relevant for wage and price setting, a point on which theory provides no clear-cut guidance. More generally, the precise manner in which expectations influence inflation deserves further study.21\n\nPerhaps most importantly, we need to know more about the manner in which inflation expectations are formed and how monetary policy influences them. Ultimately, both actual and expected inflation are tied to the central bank's inflation target, whether that target is explicit or implicit.22 But how does this anchoring process occur? Does a central bank have to keep actual inflation near the target rate for many years before inflation expectations completely conform? Can policymakers instead materially influence inflation expectations directly and quickly by simply announcing their intention to pursue a particular inflation goal in the future? Or does the truth lie somewhere in between, with a change in expectations requiring some combination of clear communications about policymakers' inflation goal, concrete policy actions to demonstrate their commitment to that goal, and at least some success in moving actual inflation toward its desired level in order to demonstrate the feasibility of the strategy? Although historical experience suggests that changing the public's inflation expectations would be neither quick nor easy, it is not clear which of these possibilities is correct.23\n\nWith nominal short-term interest rates at or close to their effective lower bound in many countries, the broader question of how expectations are formed has taken on heightened importance. Under such circumstances, many central banks have sought additional ways to stimulate their economies, including adopting policies that are directly aimed at influencing expectations of future interest rates and inflation. The unusually explicit and extended guidance about the likely future path of the federal funds rate that was provided by the FOMC from 2011 through 2014 is an example of such a policy, as is the Bank of Japan's upward revision to its official inflation objective in 2013. Moreover, these and other expectational strategies may be needed again in the future, given the likelihood that the global economy may continue to experience historically low interest rates, thereby making it unlikely that reductions in short-term interest rates alone would be an adequate response to a future recession.24\n\nFor all of these reasons, I hope that researchers will strive to improve our understanding of inflation dynamics and its interactions with monetary policy.\n\nInternational Linkages\nBefore closing, let me mention one additional area where more study is needed--the effects of changes in U.S. monetary policy on financial and economic conditions in the rest of the world and the ways in which those foreign effects can feed back to influence conditions here at home. Of course, cross-country monetary policy spillovers have been the subject of scholarly debate since the Great Depression, and much of the formal analysis of this topic dates back to the early 1960s.25 But this issue has received renewed interest with the advent of unconventional monetary policies after the Great Recession and, more recently, the divergence of monetary policies among major advanced-economy central banks.\n\nBroadly speaking, monetary policy actions in one country spill over to other economies through three main channels: changes in exchange rates; changes in domestic demand, which alter the economy's imports; and changes in domestic financial conditions--such as interest rates and asset prices--that, through portfolio balance and other channels, affect financial conditions abroad. Research by Federal Reserve staff suggests that, all told, U.S. monetary policy spillovers to other economies are positive--that is, policies designed to provide stimulus to the U.S. economy also boost activity abroad, as negative effects of dollar depreciation are offset by positive effects of higher U.S. imports and easier foreign financial conditions.26 However, this issue is far from settled, as are a host of other related questions, including the following: Do U.S. monetary policy actions affect advanced and emerging market countries differently? Do conventional and unconventional monetary policies spill over to other countries differently? And to what extent are U.S. interest rates and financial conditions influenced by easing measures abroad?\n\nConclusion\nIn closing, I would like to commend the Federal Reserve Bank of Boston for organizing this conference and fostering research and debate on questions vital to our understanding of the economy. Answering these questions will help the Federal Reserve's efforts to promote a healthy economy, and I am grateful for the opportunity to speak to you today and be part of this important discussion.\n\nReferences\nAgnello, Luca, and Ludger Schuknecht (2011). \"Booms and Busts in Housing Markets: Determinants and Implications,\" Journal of Housing Economics, vol. 20 (September), pp. 171-90.\n\nAkerlof, George A., William T. Dickens, and George L. Perry (1996). \"The Macroeconomics of Low Inflation (PDF),\" Brookings Papers on Economic Activity, no. 1, pp. 1-76.\n\nAkerlof, George A., Andrew K. Rose, and Janet L. Yellen (1988). \"Job Switching and Job Satisfaction in the U.S. Labor Market (PDF),\" Brookings Papers on Economic Activity, no. 2, pp. 495-594.\n\nAmmer, John, Michiel De Pooter, Christopher Erceg, and Steven Kamin (2016). \"International Spillovers of Monetary Policy,\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System, February 8.\n\nAuclert, Adrien (2016). \"Monetary Policy and the Redistribution Channel (PDF),\" unpublished paper, Stanford University, Department of Economics, January.\n\nBernanke, Ben S., and Mark Gertler (1989). \"Agency Costs, Net Worth, and Business Fluctuations,\" American Economic Review, vol. 79 (March), pp. 14-31.\n\nBernanke, Ben S., Mark Gertler, and Simon Gilchrist (1999a). \"The Financial Accelerator in a Quantitative Business Cycle Framework,\" in John B. Taylor and Michael Woodford, eds., Handbook of Macroeconomics, vol. 1C. Amsterdam: Elsevier, pp. 1341-93.\n\nBernanke, Ben S., Thomas Laubach, Frederic S. Mishkin, and Adam S. Posen (1999b). Inflation Targeting: Lessons from the International Experience. Princeton, N.J.: Princeton University Press.\n\nBlanchard, Olivier (2016). \"The Phillips Curve: Back to the '60s?\" American Economic Review, vol. 106 (May), pp. 31-34.\n\nBlanchard, Olivier, Eugenio Cerutti, and Lawrence Summers (2015). \"Inflation and Activity--Two Explorations and Their Monetary Policy Implications (PDF),\" IMF Working Paper WP/15/230. Washington: International Monetary Fund, November.\n\nBlanchard, Olivier J., and Lawrence H. Summers (1986). \"Hysteresis and the European Unemployment Problem,\" in Stanley Fischer, ed., NBER Macroeconomics Annual 1986, vol. 1. Cambridge, Mass.: MIT Press, pp. 15-90.\n\nBlinder, Alan S., and Janet L. Yellen (2001). The Fabulous Decade: Macroeconomic Lessons from the 1990s. New York: Century Foundation Press.\n\nCerra, Valerie, and Sweta Chaman Saxena (2008). \"Growth Dynamics: The Myth of Economic Recovery,\" American Economic Review, vol. 98 (March), pp. 439-57.\n\nChaney, Thomas, David Sraer, and David Thesmar (2012). \"The Collateral Channel: How Real Estate Shocks Affect Corporate Investment,\" American Economic Review, vol. 102 (October), pp. 2381-409.\n\nChodorow-Reich, Gabriel (2014). \"The Employment Effects of Credit Market Disruptions: Firm-Level Evidence from the 2008-9 Financial Crisis,\" Quarterly Journal of Economics, vol. 129 (February), pp. 1-59.\n\nClark, Todd E., and Troy Davig (2008). \"An Empirical Assessment of the Relationships among Inflation and Short- and Long-Term Expectations (PDF),\" Research Working Paper RWP 08-05. Kansas City: Federal Reserve Bank of Kansas City, November.\n\nClementi, Gian Luca, and Berardino Palazzo (2016). \"Entry, Exit, Firm Dynamics, and Aggregate Fluctuations,\" American Economic Journal: Macroeconomics, vol. 8 (July), pp. 1-41.\n\nDaly, Mary C., and Bart Hobijn (2014). \"Downward Nominal Rigidities Bend the Phillips Curve,\" Journal of Money, Credit and Banking, vol. 46 (October), pp. 51‑93.\n\nDel Negro, Marco, Marc P. Giannoni, and Frank Schorfheide (2015). \"Inflation in the Great Recession and New Keynesian Models,\" American Economic Journal: Macroeconomics, vol. 7 (January), pp. 168-96.\n\nDokko, Jane, Brian M. Doyle, Michael T. Kiley, Jinill Kim, Shane Sherlund, Jae Sim, and Skander Van Den Heuvel (2011). \"Monetary Policy and the Global Housing Bubble,\" Economic Policy, vol. 26 (April), pp. 237-87.\n\nDuygan-Bump, Burcu, Alexey Levkov, and Judit Montoriol-Garriga (2015). \"Financing Constraints and Unemployment: Evidence from the Great Recession,\" Journal of Monetary Economics, vol. 75 (October), pp. 89-105.\n\nFair, Ray C. (2004). Estimating How the Macroeconomy Works. Cambridge, Mass.: Harvard University Press.\n\nFallick, Bruce C., Michael Lettau, and William L. Wascher (2016). \"Downward Nominal Wage Rigidity in the United States during and after the Great Recession (PDF),\" Finance and Economics Discussion Series 2016-001. Washington: Board of Governors of the Federal Reserve System, January.\n\nFaust, Jon, and Jonathan H. Wright (2013). \"Forecasting Inflation,\" in Graham Elliott and Allan Timmermann, eds., Handbook of Economic Forecasting, vol. 2A. Amsterdam: Elsevier, pp. 3-56.\n\nFernald, John G. (2015). \"Productivity and Potential Output before, during, and after the Great Recession,\" in Jonathan A. Parker and Michael Woodford, eds., NBER Macroeconomics Annual 2014, vol. 29. Chicago: University of Chicago Press, pp. 1-51.\n\nFleming, J. Marcus (1962). \"Domestic Financial Policies under Fixed and under Floating Exchange Rates,\" International Monetary Fund Staff Papers, vol. 9 (November), pp. 369-80.\n\nFukuda, Yoshiyuki, Yuki Kimura, Nao Sudo, and Hiroshi Ugai (2013). \"Cross-Country Transmission Effect of the U.S. Monetary Shock under Global Integration (PDF),\" Bank of Japan Working Paper Series 13-E-16. Tokyo: BOJ, November.\n\nGeorgiadis, Georgios (2015). \"Determinants of Global Spillovers from U.S. Monetary Policy (PDF),\" ECB Working Paper Series 1854. Frankfurt am Main, Germany: European Central Bank, September.\n\nGertler, Mark, and Peter Karadi (2015). \"Monetary Policy Surprises, Credit Costs, and Economic Activity,\" American Economic Journal: Macroeconomics, vol. 7 (January), pp. 44-76.\n\nGlick, Reuven, and Sylvain Leduc (2015). \"Unconventional Monetary Policy and the Dollar: Conventional Signs, Unconventional Magnitudes (PDF),\" Working Paper Series 2015-18. San Francisco: Federal Reserve Bank of San Francisco, November.\n\nGordon, Robert J. (2013). \"The Phillips Curve Is Alive and Well: Inflation and the NAIRU during the Slow Recovery (PDF),\" NBER Working Paper Series 19390. Cambridge, Mass.: National Bureau of Economic Research, August.\n\nGornemann, Nils, Keith Kuester, and Makoto Nakajima (2016). \"Doves for the Rich, Hawks for the Poor? Distributional Consequences of Monetary Policy (PDF),\" International Finance Discussion Papers 1167. Washington: Board of Governors of the Federal Reserve System.\n\nGourio, Francois, Todd Messer, and Michael Siemer (2016). \"Firm Entry and Macroeconomic Dynamics: A State-Level Analysis,\" American Economic Review, vol. 106 (May), pp. 214-18.\n\nGuvenen, Fatih (2011). \"Macroeconomics with Heterogeneity: A Practical Guide (PDF),\" Federal Reserve Bank of Richmond, Economic Quarterly, vol. 97 (Third Quarter), pp. 255-326.\n\nHolzer, Harry J., Steven Raphael, and Michael A. Stoll (2006). \"Employers in the Boom: How Did the Hiring of Less-Skilled Workers Change during the 1990s?\" Review of Economics and Statistics, vol. 88 (May), pp. 283-99.\n\nHoward, Greg, Robert Martin, and Beth Anne Wilson (2011). \"Are Recoveries from Banking and Financial Crises Really So Different? (PDF)\" International Finance Discussion Papers 1037. Washington: Board of Governors of the Federal Reserve System, November.\n\nIlzetski, Ethan, and Keyu Jin (2013). \"The Puzzling Change in the International Transmission of U.S. Macroeconomic Policy Shocks (PDF),\" working paper. London: London School of Economics, February.\n\nJustiniano, Alejandro, Giorgio Primiceri, and Andrea Tambalotti (2015). \"Household Leveraging and Deleveraging,\" Review of Economic Dynamics, vol. 18 (January), pp. 3-20.\n\nKaplan, Greg, Benjamin Moll, and Giovanni L. Violante (2016). \"Monetary Policy According to HANK,\" NBER Working Paper Series 21897. Cambridge, Mass.: National Bureau of Economic Research, January.\n\nKashyap, Anil K., and Jeremy C. Stein (2000). \"What Do a Million Observations on Banks Say about the Transmission of Monetary Policy?\" American Economic Review, vol. 90 (June), pp. 407-28.\n\nKatz, Lawrence F., and Alan B. Krueger (1999). \"The High-Pressure U.S. Labor Market of the 1990s (PDF),\" Brookings Papers on Economic Activity, no. 1, pp. 1-87.\n\nKhan, Aubhik, and Julia K. Thomas (2013). \"Credit Shocks and Aggregate Fluctuations in an Economy with Production Heterogeneity,\" Journal of Political Economy, vol. 121 (December), pp. 1055-107.\n\nKiley, Michael T. (2008). \"Monetary Policy Actions and Long-Run Inflation Expectations (PDF),\" Finance and Economics Discussion Series 2008-03. Washington: Board of Governors of the Federal Reserve System, February.\n\nKrueger, Dirk, Kurt Mitman, and Fabrizio Perri (2016). \"Macroeconomics and Household Heterogeneity,\" CEPR Discussion Paper 11038. London: Centre for Economic Policy Research, June.\n\nKrusell, Per, and Anthony A. Smith, Jr. (1998). \"Income and Wealth Heterogeneity in the Macroeconomy,\" Journal of Political Economy, vol. 106 (October), pp. 867-96.\n\nMartin, Robert F., Teyanna Munyan, and Beth Anne Wilson (2015). \"Potential Output and Recessions: Are We Fooling Ourselves? (PDF)\" International Finance Discussion Papers 1145. Washington: Board of Governors of the Federal Reserve System, September.\n\nMavroeidis, Sophocles, Mikkel Plagborg-Moller, and James H. Stock (2014). \"Empirical Evidence on Inflation Expectations in the New Keynesian Phillips Curve,\" Journal of Economic Literature, vol. 52 (March), pp. 124-88.\n\nMian, Atif, Kamalesh Rao, and Amir Sufi (2013). \"Household Balance Sheets, Consumption, and the Economic Slump,\" Quarterly Journal of Economics, vol. 128 (November), pp. 1687-726.\n\nMundell, Robert A. (1963). \"Capital Mobility and Stabilization Policy under Fixed and Flexible Exchange Rates,\" Canadian Journal of Economics and Political Science, vol. 29 (November), pp. 475-85.\n\nOkun, Arthur M. (1973). \"Upward Mobility in a High-Pressure Economy,\" Brookings Papers on Economic Activity, no. 1, pp. 207-52.\n\nParker, Jonathan A., Nicholas S. Souleles, David S. Johnson, and Robert McClelland (2013). \"Consumer Spending and the Economic Stimulus Payments of 2008,\" American Economic Review, vol. 103 (October), pp. 2530-53.\n\nPeek, Joe, and Eric S. Rosengren (2013). \"The Role of Banks in the Transmission of Monetary Policy,\" Public Policy Discussion Papers 13-5. Boston: Federal Reserve Bank of Boston, September.\n\nPeek, Joe, Eric S. Rosengren, and Geoffrey M.B. Tootell (2003). \"Identifying the Macroeconomic Effects of Loan Supply Shocks,\" Journal of Money, Credit and Banking, vol. 35 (December), pp. 931-46.\n\nQuadrini, Vincenzo, and Jose-Víctor Rios-Rull (2015). \"Inequality in Macroeconomics,\" in Anthony B. Atkinson and Francois Bourguignon, eds., Handbook of Income Distribution, vol. 2B. Amsterdam: Elsevier, pp. 1229-302.\n\nReifschneider, Dave, William Wascher, and David W. Wilcox (2015). \"Aggregate Supply in the United States: Recent Developments and Implications for the Conduct of Monetary Policy,\" IMF Economic Review, vol. 63 (May), pp. 71-109.\n\nSiemer, Michael (2014). \"Firm Entry and Employment Dynamics in the Great Recession (PDF),\" Finance and Economics Discussion Series 2014-56. Washington: Board of Governors of the Federal Reserve System, August.\n\nSolow, Robert M. (1997). \"Is There a Core of Usable Macroeconomics We Should All Believe In?\" American Economic Review, vol. 87 (May), pp. 230-32.\n\nSterk, Vincent, and Silvana Tenreyro (2016). \"The Transmission of Monetary Policy through Redistributions and Durable Purchases (PDF),\" CEP Working Paper 2016/1. Zurich: Council on Economic Policies, January.\n\nSummers, Laurence H. (2014). \"Reflections on the ‘New Secular Stagnation Hypothesis,'\" in Coen Teulings and Richard Baldwin, eds., Secular Stagnation: Facts, Causes, and Cures. London: Centre for Economic Policy Research, pp. 27-38.\n\nYellen, Janet L. (2015). \"Inflation Dynamics and Monetary Policy,\" speech delivered at the Philip Gamble Memorial Lecture, University of Massachusetts at Amherst, Amherst, Mass., September 24.\n\nYellen, Janet L. (2016). \"The Federal Reserve's Monetary Policy Toolkit: Past, Present and Future,\" speech delivered at \"Designing Resilient Monetary Policy Frameworks for the Future,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyoming, August 26.\n\n1. See Solow (1997). Return to text\n\n2. Or, as Summers (2014) asked in a pithy inversion of Say's law, is it true that \"lack of demand creates lack of supply?\" (p. 37). Return to text\n\n3. As Blanchard and Summers (1986) discuss, the question at the time was whether the long-run equilibrium, or \"natural,\" rate of unemployment in European economies had been permanently raised by previous periods of high actual unemployment. Return to text\n\n4. For example, see Cerra and Saxena (2008); Howard, Martin, and Wilson (2011); Martin, Nunyan, and Wilson (2014); and Blanchard, Cerutti, and Summers (2015). Return to text\n\n5. See Reifschneider, Wascher, and Wilcox (2015). Return to text\n\n6. Fernald (2015), however, argues that much of the apparent slowdown in U.S. potential GDP growth began prior to the 2007-09 recession. Return to text\n\n7. See Okun (1973) for an early discussion of the benefits of a high-pressure economy. Importantly, not all of these benefits might show up as measured output, but they would nonetheless be welfare improving--for example, higher job satisfaction from better matches between workers and employers, as noted by Akerlof, Rose, and Yellen (1988). Return to text\n\n8. For example, the experience of the 1990s might seem to provide a natural case study of whether reverse hysteresis is possible. Unfortunately, most studies of the labor market during this period do not directly speak to this issue, although Holzer, Raphael, and Stoll (2006) investigate changes in employers' willingness to hire less-skilled workers during these years, while Katz and Krueger (1999) and my own study with Blinder (2001) explore the somewhat related question of how the U.S. economy was able to simultaneously experience rapid growth, low unemployment, and low inflation in the late 1990s. Return to text\n\n9. See Krueger, Mitman, and Perri (2016). Return to text\n\n10. On the role of financing constraints for firm employment, see Siemer (2014); Chodorow-Reich (2014); and Duygan-Bump, Levkov, and Montoriol-Garriga (2015). A general-equilibrium model with heterogeneity among firms and credit frictions is studied in Khan and Thomas (2013). For the role of entry and exit in macroeconomic dynamics, see Clementi and Palazzo (2016) as well as Gourio, Messer, and Siemer (2016). Return to text\n\n11. For early quantitative work on the relationship between income and wealth heterogeneity and the macroeconomy, see Krusell and Smith (1998). Return to text\n\n12. Guvenen (2011) reviews several issues related to macroeconomics with heterogeneity. For an overview of the interactions between distribution and aggregate outcomes, see the work by Quadrini and Rios-Rull (2015). For recent work on the effects of monetary policy in models with heterogeneous agents, see Kaplan, Moll, and Violante (2016); Gornemann, Kuester, and Nakajima (2016); Auclert (2016); and Sterk and Tenreyro (2016). Return to text\n\n13. For an example of early research on this topic, see Bernanke and Gertler (1989). Other important pre-crisis studies include the development of the financial accelerato­r model by Bernanke and others (1999a) and work by Kashyap and Stein (2000) and Peek, Rosengren, and Tootell (2003) on the bank balance sheet channel and the effects of bank loan supply shocks. For a more recent summary of the role of banks in the monetary transmission mechanism, see Peek and Rosengren (2013). Chaney, Sraer, and Thesmer (2012) provide evidence for the collateral channel of real estate for corporate investment, while Mian, Rao, and Sufi (2013) examine the influence of household balance sheets on consumption. Return to text\n\n14. More empirical work would be useful to disentangle the spending effects that result from changes in credit conditions from those that result from movements in interest rates, as estimates of the latter likely often inadvertently incorporate the former. Most empirical models of the overall economy do not explicitly control for the influence of noninterest credit factors on consumption and investment; as a result, estimated interest rate effects will partially reflect the influence of these factors to the extent these factors are correlated with interest rates. There are many reasons to suspect that this is the case. Movements in interest rates influence a firm's cash flow and the value of its collateral, all else being equal. Higher interest rates also adversely affect consumer spending and especially residential investment, both by forcing households to devote a greater portion of their income to debt service and by making it more difficult to qualify for a loan because of maximum payment-to-income rules. Evidence for these effects is provided by Gertler and Karadi (2015), who show that relatively small changes in short-term interest rates are correlated with large movements in credit costs. Such correlations and interactions may explain why some types of spending appear to be more correlated with movements in nominal interest rates than with real interest rates; see Fair (2004, ch. 3) for evidence on this point. Finally, the relative contributions of relaxed lending standards, low interest rates, and other factors to housing bubbles, both in the United States and abroad, remains an open and unsettled topic; Agnello and Shucknecht (2011) present cross-country evidence that monetary policy plays an important role, while Dokko and others (2011) argue that monetary policy was a minor influence in the most recent episode. Return to text\n\n15. See Mian, Rao, and Sufi (2013) for an assessment of the role of leverage and housing wealth shocks in driving consumption during the Great Recession. Work by Justiniano, Primiceri, and Tambalotti (2015) suggests that debt overhang alone cannot explain the slow recovery from the Great Recession. Return to text\n\n16. See Yellen (2015) for a more extensive discussion. Return to text\n\n17. In the economic literature, this general description of the inflation process is referred to as the expectations-augmented Phillips curve. In its simplest form, the Phillips curve relates inflation to expected inflation and the intensity of resource utilization in the economy. In practice, however, empirical specifications also typically include measures of supply shocks, such as changes in the relative prices of energy or imported goods, as additional determinants. Two well-known variants of the Phillips curve are the traditional \"accelerationist\" specification and the so-called New Keynesian Phillips curve; the former approximates inflation expectations using a moving average of past inflation, while the latter assumes that inflation expectations are \"rational\" and consistent with the predictions of a structural model of the entire economy. Some adherents of either type of Phillips curve argue that their preferred model can explain the behavior of inflation during and after the financial crisis. For example, Gordon (2013) presents evidence in favor of an accelerationist model, while Del Negro, Giannoni, and Schorfheide (2015) make this claim for a New Keynesian model. Return to text\n\n18. See Blanchard (2016) for evidence on how the responsiveness of inflation to resource utilization has changed over time. Interestingly, research suggests that this sensitivity began declining well before the crisis. Return to text\n\n19. For an early discussion of the potential macroeconomic effects of downward nominal wage rigidity, see Akerlof, Dickens, and Perry (1996). More recently, Daly and Hobijn (2014) develop a model in which the reluctance or inability of firms to cut nominal wages (or both) creates important nonlinearities in the relationship between labor utilization and wage inflation. Finally, Fallick, Lettau, and Wascher (2015) review the evidence for downward nominal wage rigidity in recent years and explore the ways in which it has interacted with labor market stress over time. Return to text\n\n20. Specifically, survey measures of long-run inflation expectations are broadly correlated with estimates of inflation's longer-term trend. See Clark and Davig (2008); see also Faust and Wright (2013, who make a related point in the context of inflation forecasting. Return to text\n\n21. As Mavroeidis, Plagborg-Moller, and Stock (2014) conclude from their exhaustive survey, empirical estimates of the New Keynesian inflation equation are \"unable to pin down the role of expectations in the inflation process sufficiently accurately for the results to be useful for policy analysis\" (p. 172). Return to text\n\n22. For a discussion of the theoretical and empirical influence of monetary policy on inflation in the context of a formal inflation-targeting regime, see Bernanke and others (1999b). Return to text\n\n23. See Kiley (2008) for a discussion of the relationship between U.S. monetary policy and survey measures of long-run inflation expectations; his results suggest that it took many years for the Federal Reserve to succeed in anchoring long-run expectations at a low level. In a similar vein, Bernanke and others (1999b) conclude that inflation expectations \"respond only after a lag following declines in [actual] inflation\" (p. 298) based on their study of the effects of adopting inflation targeting in different countries. Return to text\n\n24. I discussed this likelihood in a recent speech (Yellen, 2016). Return to text\n\n25. See Mundell (1963) and Fleming (1962). Return to text\n\n26. See Ammer, De Pooter, Erceg, and Kamin (2016). Other recent research on this topic includes Fukuda, Kimura, Sudo, and Ugai (2013); Georgiadis (2015); Glick and Leduc (2015); and Ilzetski and Jin (2013). Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "October 09, 2016",
        "title": "The U.S. Economy and Monetary Policy",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20161009a.htm",
        "content": "October 09, 2016\n\nVice Chairman Stanley Fischer\n\nAt the 31st Annual Group of Thirty International Banking Seminar, Washington, D.C.\n\nWith Friday morning's labor market data prominently in the news, I will start with the labor market and end with a discussion of monetary policy.1\n\nRecent reports pertaining to the labor market, including Friday's release, have been solid, showing continued improvement. So far this year, payrolls are reported to have increased by 180,000 per month. That is down from last year's gains of 230,000 per month but well above what is needed to provide jobs for new entrants into the labor force. Despite the strong job growth, the unemployment rate, at 5 percent in September, has essentially moved sideways this year as individuals have come back into the labor market in response to better employment opportunities and higher wages. As a consequence, the labor force participation rate has edged up against a backdrop of a declining longer-run trend owing to aging of the population. This increase is a very welcome development.\n\nAll told, with the unemployment rate not far from levels that most Federal Open Market Committee (FOMC) participants view as normal in the longer run and the rise in the participation rate, I see the U.S. economy as close to full employment, with some further improvement expected.\n\nReal gross domestic product (GDP) rose at a subdued 1 percent pace during the first half of the year and only 1-1/4 percent over the past four quarters. This pace likely underestimates the momentum in aggregate demand because it includes a sizable inventory correction that began early last year. It is likely that this correction has by now run its course, and most analysts are expecting inventories to make a positive contribution to demand over the second half of the year and for GDP to increase in the neighborhood of 2-3/4 percent.2\n\nHousehold spending has been the main contributor to real GDP growth over the past four quarters, and, with solid gains in employment and household income and upbeat consumer sentiment, this sector should continue to support growth over the second half of the year. In contrast, residential construction has cooled this year despite rising home prices and low interest rates. Housing starts have been moving sideways, suggesting little pickup in construction over the near term.\n\nIn addition, business investment spending has been weak, held down in part by declining activity in the energy sector, which has obviously been hard hit by the steep drop in oil prices. The recent stabilization of rig counts in the United States suggests that this source of restraint on business investment may be coming to an end. That said, business investment outside of the energy sector has been unusually soft for the past three quarters, and this weakness will bear close watching. Perhaps investment is being held down as firms respond to the flat trajectories for manufacturing and exports, reflecting subdued foreign demand and the appreciation of the dollar since mid-2014. Another possibility could be that firms are reassessing the prospects for growth and profitability in an environment of weak productivity growth and are accordingly scaling back investment plans. Notwithstanding these downside possibilities, I expect that business investment will pick up in the second half of the year as the drag from the oil sector wanes and as firms expand capacity to meet rising demand.\n\nThe combination of strong job gains and lackluster GDP growth over the past four quarters reflects exceptionally poor labor productivity growth. Indeed, productivity declined 1/2 percent over the most recent four quarters and has increased only about 1/4 percent per year, on average, since 2011. While improving labor market conditions have led to higher household incomes in recent years, the key to improved living standards over the long haul will be a revival in productivity growth--at least to more normal levels, possibly in the range of 1-1/2 percent per annum.\n\nForeign economies have been growing at a moderate pace, even in the face of numerous shocks, including concerns about China's exchange regime at the start of the year and Brexit over the summer. The economic effects of the steep appreciation of the dollar that began in mid-2014 have begun to fade, and U.S. exports have returned to growth following a weak 2015.\n\nTurning to inflation, I believe that transitory effects of the fall in oil prices and the rise in the dollar are the primary reason that inflation has fallen short of the FOMC's 2 percent goal. Total personal consumption expenditures (PCE) inflation was 1 percent in August on a 12-month basis, held down by earlier declines in gasoline prices, but core PCE inflation has moved up somewhat, and its 12-month change stood at 1.7 percent in August. As oil prices and the dollar stabilize, the drag on consumer price inflation from these sources ought to dissipate, and inflation will likely move closer to 2 percent. This projection, however, depends critically on expectations for future inflation remaining reasonably well anchored; as the FOMC has noted, low readings for some indicators of expected inflation deserve close watching.\n\nLet me now turn to the monetary policy outlook. As you know, at our September meeting, the FOMC decided to keep the target range for the federal funds rate at 1/4 to 1/2 percent. As we noted in the statement, the recent pickup in economic growth and continued progress in the labor market have strengthened the case for an increase in the federal funds rate.3 Indeed, in our individual economic projections prepared in advance of the September meeting, nearly all FOMC participants anticipated an increase in the target range for the federal funds rate by the end of this year. Moreover, as economic growth has picked up and some of the earlier concerns about the global outlook have receded, the Committee judged the risks to the U.S. economic outlook to be roughly balanced.\n\nGiven that generally positive view of the economic outlook, one might ask, why did we not raise the federal funds rate at our September meeting? Our decision was a close call, and leaving the target range for the federal funds rate unchanged did not reflect a lack of confidence in the economy. Conditions in the labor market are strengthening, and we expect that to continue. And while inflation remains low, we expect it to rise to our 2 percent objective over time. But with labor market slack being taken up at a somewhat slower pace than in previous years, scope for some further improvement in the labor market remaining, and inflation continuing to run below our 2 percent target, we chose to wait for further evidence of continued progress toward our objectives.\n\nAs we noted in our statement, we continue to expect that the evolution of the economy will warrant some gradual increases in the federal funds rate over time to achieve and maintain our objectives. That assessment is based on our view that the neutral nominal federal funds rate--that is, the interest rate that is neither expansionary nor contractionary and keeps the economy operating on an even keel--is currently low by historical standards. With the federal funds rate modestly below the neutral rate, the current stance of monetary policy should be viewed as modestly accommodative, which is appropriate to foster further progress toward our objectives. But since monetary policy is only modestly accommodative, there appears little risk of falling behind the curve in the near future, and gradual increases in the federal funds rate will likely be sufficient to get monetary policy to a neutral stance over the next few years.\n\nThis view is consistent with the projections of appropriate monetary policy prepared by FOMC participants in connection with our September meeting.4 The median projection for the federal funds rate rises only gradually to 1.1 percent at the end of next year, 1.9 percent at the end of 2018, and 2.6 percent by the end of 2019. Most participants also marked down their estimate of the longer-run normal federal funds rate, with the median now at 2.9 percent.\n\nHowever, as we have noted on many previous occasions, policy is not on a preset course. The economic outlook is inherently uncertain, and our assessment of the appropriate path for the federal funds rate will change in response to changes to the economic outlook and associated risks.\n\n1. I am grateful to James Clouse and Glenn Follette of the Federal Reserve Board staff for their assistance. Views expressed are mine and are not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. The September Blue Chip forecast projects real GDP to increase at an annual rate of 2.9 percent in the third quarter and 2.4 percent in the fourth quarter. Return to text\n\n3. See Board of Governors of the Federal Reserve System (2016), \"Federal Reserve Issues FOMC Statement,\" press release, September 21. Return to text\n\n4. See Board of Governors of the Federal Reserve System (2016), \"Federal Reserve Board and Federal Open Market Committee Release Economic Projections from the September 20-21 FOMC Meeting,\" press release,\" September 21. Return to text"
    },
    {
        "speaker": "Lael Brainard",
        "position": "Governor",
        "date": "October 07, 2016",
        "title": "Distributed Ledger Technology: Implications for Payments, Clearing, and Settlement",
        "href": "https://www.federalreserve.gov/newsevents/speech/brainard20161007a.htm",
        "content": "October 07, 2016\n\nGovernor Lael Brainard\n\nAt the Institute of International Finance Annual Meeting Panel on Blockchain, Washington, D.C.\n\nWe recognize the potential of distributed ledger technology, or blockchain, to transform the way financial market participants transfer, store, and maintain ownership records of digitized assets. The genuinely innovative aspect of distributed ledger technology combines a number of core elements that can be used to support the transfer process and distributed recordkeeping for digital assets and digital representations of assets. These elements include peer-to-peer networking and distributed data records, which provide broadly shared access to a single ledger across participants in the system, so that all participants maintain a shared, accurate history of all transactions in the system. In addition, cryptography provides a secure way to initiate a valid transaction as well as to securely transmit and store data. And consensus algorithms provide a process for transactions to be confirmed and added to the single ledger, which is an important feature when more than one participant has permission to propose updates to the ledger. We are paying close attention to distributed ledger technology, or blockchain, recognizing this may represent the most significant development in many years in payments, clearing, and settlement.1\n\nThe Federal Reserve Board has established a working group that is engaged in a 360-degree analysis of financial innovation across the broad range of our responsibilities, drawing on engagement with industry stakeholders and on expertise from across the Federal Reserve System, including in supervision, consumer protection, financial stability and information technology. One important area of oversight is the payments system, where technology changes are viewed through the prism of our responsibilities for promoting the safety and efficiency of the payments and settlements systems; supervising financial institutions engaged in payments, clearing and settlement; and safeguarding financial stability. We want to maintain public confidence in the payments system, while supporting innovation that provides broadly shared benefits to the public over time, including through the reduction of unnecessary frictions, costs, and delays.\n\nIllustrative Use Cases\nLet me briefly mention a few of the use cases that we have explored in our discussions with industry stakeholders in order to illustrate the potential of distributed ledger technologies to improve payments, clearing, and settlement, as well as the considerations that are important to us in our assessment of benefits and risks.\n\nIn cross-border payments and trade finance, significantly faster processing and reduced costs relative to the long and opaque intermediation chains associated with current methods of correspondent banking are promising potential benefits of the technology. Reducing intermediation steps in cross-border payments may help decrease time, costs, and counterparty risks and may materially diminish opacity, for instance by enabling small businesses or households remitting payments across borders to see the associated transfer costs and processing times up front. In trade finance, where document-intensive processes are not fully automated, distributed ledger technology may be able to reduce significant costs and speed up processing associated with issuing and tracking letters of credit and associated documents. To see the full potential of this technology realized for cross-border payments, it will be important to identify and track identities associated with the transactions, which in itself may be facilitated by the use of distributed ledgers, depending on their design.\n\nIn securities markets, the industry is exploring activities ranging from the issuance of securities on a distributed ledger, to the clearing and settlement of trades, to tracking and administering corporate actions. For securities clearing and settlement in particular, the potential shift to one master record shared \"simultaneously\" among users of a distributed ledger-based system could be compelling. Sharing one immutable record may have the potential to reduce or even eliminate the need for the reconciliation of multiple records linked to a single trade among and between dealers and other organizations. In concept, such technology could lead to greater transparency, reduced costs, and faster settlement. Likewise, distributed ledgers may improve collateral management by improving the tracking of ownership and transactions. Nonetheless, as is frequently true in the complex arena of payments, clearing, and settlement, we can also expect that practical details covering a host of technical, business, and market issues will have an important role in determining how new technologies ultimately perform.\n\nFor commodities and derivatives, there are projects to streamline some of the more antiquated corners of the markets. In markets that are heavily paper-based and lack any central means for coordination, distributed ledger technology could potentially be leveraged to provide coordination that facilitates exchange, clearing, and settlement of obligations.\n\nA related development is the potential coupling of distributed ledger protocols with self-execution and possibly self-enforcement of contractual clauses, using so-called \"smart contracts.\" To take a familiar example, for a corporate bond with a specified par value, tenor, and coupon payment stream, a smart contract would automatically execute payments on the specified schedule to the assigned owner over the life of the bond. Although the idea of automating certain aspects of contracts is not new, and banks do some of this today, the potential introduction of smart contracts does raise several issues for consideration. For example, what is the legal status of a smart contract, which is written in code? Would consumers and businesses rely on smart contracts to perform certain services traditionally done by their banks or other intermediaries? Could the widespread automated interaction of multiple counterparties lead to any unwanted dynamics for financial markets? These and other considerations will be important factors in determining the extent of the application of smart contracts.\n\nRegardless of the application, much of the industry is at a \"proof of concept\" stage of development. These proofs of concept are often simple, experimental uses of the technology on a small scale that help stakeholders understand the potential and limitations of the technology for a specific purpose, which in turn typically lead to refinements and more developed proofs of concept. As such, many potential applications are in their infancy, and the industry may still be several years away from an application that is ready to be fully implemented. Even so, the industry seems to be making announcements daily on new proofs of concept and progress that may lead to pilots, so that timeline could accelerate. In some cases, there have been announcements the technology will be used within the next year or two in actual production environments. The initial relatively simple proofs of concept must be followed by much more complex demonstrations in real-world situations before these technologies can be safely deployed in today's highly interconnected, synchronized, and far-reaching financial markets.\n\nAlthough many private and inward-facing projects are being explored, the industry has also recognized the need to collaborate at early stages of development. An important positive development is that industry participants are actively engaging with each other to look for common approaches. Some groups are creating standards that facilitate common platforms to enable greater interoperability of often proprietary applications that are built on them and interoperate through application program interfaces, or APIs.\n\nIn coming months and years, innovators, investors, and financial practitioners will no doubt make important strides in addressing key challenges such as adopting common standards, achieving interoperability between and among legacy systems and evolving distributed ledgers, improving scalability and computational throughput, and improving cryptographic security. These are positive developments that we will monitor closely.\n\nManaging Risks\nAll of this activity demonstrates that we are in a very innovative period. The industry is eager to get on with adopting the various possibilities that distributed ledger technology may bring. However, established players and, increasingly, new entrants understand that there are important guardrails that have been carefully developed over many years in the arena of payments, clearing, and settlement. The safety and soundness of financial institutions, safety and efficiency of the payment system, and broader financial stability are critical to a healthy financial environment that fosters innovation with broad public benefits over the long run. We expect the private sector to bear important responsibility for developing and deploying new financial technologies in a safe and sound manner, even as we all seek an innovative and efficient payment system over the long run. The deployment of any new financial technology must be undertaken with a thorough understanding and management of risks.\n\nLike many new financial technologies, distributed ledgers could ameliorate or exacerbate traditional financial risks. What matters to us as policymakers and regulators is not only whether the migration to a new technological platform increases or reduces risks, but also whether risks are rendered more or less opaque, and how they are distributed among and between financial intermediaries and end users. In the payments, clearing, and settlement arena, some important risk areas for consideration include settlement, operations, and cybersecurity, as well as money laundering and terrorist financing. In managing risks, important considerations include system resiliency and governance as well as the role of licensing in ensuring proper oversight.\n\nIn securities settlements, for example, a difference in timing between the delivery of securities and the delivery of funds introduces settlement risk between counterparties and other institutions involved in this process. To the extent that distributed ledger technologies are designed to supplant the traditional reliance on trusted intermediaries to ensure settlement, they will need to reliably demonstrate their ability to mitigate or even eliminate settlement risk, especially in cases where the delivery of the securities and the associated payment take place on different platforms.\n\nTraditional payment, clearing, and settlement are subject to operational risk, and it is critically important that new technologies operate reliably, securely, and with integrity. The daily operation of markets and their clearing and settlement functions are built on trust and confidence. Market participants trust that clearing and settlement functions and institutions will work properly every day. Confidence has built over time that when market participants trade, accurate and timely clearing and settlement will follow.\n\nThus, robust security is an important element of any system. The distributed nature of this new technology, combined with the fact that many connected participants can update the shared ledger, means that end-point security is another critical component of any successful implementation of the technology. Adverse actors that can take over a participant's access to the ledger remains a key security concern, as thefts of cryptographic keys in Bitcoin continue to demonstrate. Thus, advances in cryptography will remain a key priority to enable widespread adoption of distributed ledger technologies, along with systems for securing private keys, the management of access to private keys, and differentiated permissions for participants in the system to read and write to the ledger. Recent episodes have illustrated the importance of having protocols agreed at the outset to determine whether and under what circumstances to reverse transactions once they have been recorded in a distributed master ledger.\n\nFinally, it will be important that users and administrators of distributed ledger technologies can meet their responsibilities to combat money laundering, terrorist financing, and other key law enforcement concerns. Some of the new technologies would potentially allow authorized access to certain data records in a much more efficient manner than has previously been possible. For example, distributed ledgers could be developed to collect personally identifiable information and country identifiers that enable banks to identify and report on suspicious activity. It will be important that these new technological developments and their implementation perform in a safe and sound manner that is transparent and satisfies regulatory requirements.\n\nWhile prevention will remain the preferred approach, realistically, resiliency and recovery will also need to be high-priorities. Indeed, many firms have suggested that the distributed data storage concept has the potential to increase the level of resiliency and data integrity. The basic idea is it should be harder to corrupt multiple copies of the same data simultaneously such that digital ledgers could reduce the vulnerability associated with a single point of failure. We must press firms and experts to identify the strengths and vulnerabilities of this concept, even as we all look for ways to make databases more secure and resilient. In an interesting development, some financial institutions have also begun to consider using distributed ledgers to back up critical databases and enable quick recovery from potentially virulent cyberattacks. We will be interested in whether such techniques can make new contributions to cybersecurity.\n\nOverall, the public needs to have confidence that any system employing distributed ledgers will operate properly, particularly in stressed conditions, and know that when adverse scenarios do occur, there will be robust management and governance to respond effectively. Recent events, such as thefts from accounts on distributed ledger platforms, highlight the challenge that distributed ledgers may have when adverse scenarios occur and there is uncertainty around what an appropriate response would be. Such uncertainty around management and governance can raise doubts about the integrity of a system employing distributed ledgers.\n\nTraditionally, financial regulators in the United States have been given licensing authority as a key way of ensuring that responsibility for managing risks is transparently assigned with appropriate oversight. The development of new business models associated with evolving financial technologies has raised questions about the applicability of existing licenses and their adequacy to new business models. For instance, the Monetary Authority of Singapore recently issued a consultation paper that proposes an activity-based payments framework as a way to address the introduction of non-traditional payment providers.2 The United States has seen several noteworthy recent developments, including the New York State Department of Financial Services' BitLicense, a distributed ledger company, securing Federal Reserve Bank of New York approval for participation in the National Settlement Service, and, most recently, discussion by the OCC of a limited-purpose charter.\n\nOngoing Engagement\nBecause of the notable potential of distributed ledger technology, financial authorities, both domestic and international, will follow these developments with keen interest. At the Federal Reserve, we expect to publish a research paper later this year that summarizes some of the key findings from our industry engagement so far. Going forward, we will continue to deepen our engagement with a range of financial institutions, technologists, multi-stakeholder consortia, and academic experts to refine our understanding of the new technologies, along with their possibilities and limitations, with a particular focus on our responsibilities for the payments system, as well as our oversight of financial market intermediaries. We will also continue to discuss these issues with other central banks and authorities around the world. We will work together to foster socially beneficial innovation, while insisting that risks are thoroughly understood, managed, and controlled.\n\nI am grateful to David Mills for his assistance in preparing this text.\n\n1. See http://www.federalreserve.gov/newsevents/speech/brainard20160414a.htm. Also, see the forthcoming Feds working paper, \"Staff Study on Distributed Ledger Technology in Payments, Clearing, and Settlement,\" 2016. Return to text\n\n2. See www.mas.gov.sg/~/media/resource/publications/consult_papers/2016/Proposed Activity Based Payments Framework and Establishment of a National Payments Council.pdf . Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "October 05, 2016",
        "title": "Low Interest Rates",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20161005a.htm",
        "content": "October 05, 2016\n\nVice Chairman Stanley Fischer\n\nAt the 40th Annual Central Banking Seminar, sponsored by the Federal Reserve Bank of New York, New York, New York\n\nI would like to thank the Federal Reserve Bank of New York for establishing this seminar 40 years ago and for maintaining it since then. This event has always been a useful forum for sharing knowledge and experiences among the world's central banks, something that has become especially valuable in the years since the Great Recession. This seminar has also fostered a stronger sense of community among central banks, whose interactions undergird the global financial system.1\n\nI will talk today about an issue that currently confronts almost all central banks: historically low interest rates. Indeed--as shown in figure 1--in an increasing number of countries, they have even dipped below zero. Ultralow interest rates have not been limited to the short end of the yield curve, which is most directly affected by monetary policy. Figure 2 shows that longer-term interest rates--which embed market participants' expectations of where real short-term rates and inflation are likely to be in the future--have also been exceptionally low.\n\nThe low interest rate environment presents us with four key questions: (1) Are ultralow interest rates part of the so-called new normal for the global economy, or are they mostly transitory? (2) How concerned should we be, if at all, about the current interest rate environment? (3) What determines the level of interest rates over the longer run? (4) What can policymakers do about chronically low interest rates?\n\nThe fact that interest rates have remained so low in the United States over the past eight years--well into the recovery from the severe strains of the Great Recession--suggests that ultralow rates may reflect more than just cyclical forces. Here is a simple observation that illustrates this point: The unemployment rate in the United States has dropped from a peak of 10 percent in the aftermath of the Great Recession to just 4.9 percent today. Yet, over the same period, yields on nominal and inflation-indexed 10-year U.S. Treasury securities have fallen around 180 basis points and 140 basis points, respectively. This observation suggests that perhaps structural factors are pulling down what economists often refer to as the longer-run equilibrium or natural rate of interest.\n\nKnut Wicksell, the great Swedish economist, emphasized the concept of an equilibrium level of interest rates in his influential work. In his 1898 book, Interest and Prices, he wrote that \"there is a certain level of the average rate of interest which is such that the general level of prices has no tendency to move either upwards or downwards.\"2 In modern language, this level of the interest rate is usually referred to as the natural rate of interest. Applying Wicksell's insights to the circumstances we face today, the fact that both inflation and interest rates have remained very low over the past several years suggests that our current interest rate environment may well reflect, at least in part, a very low level of the natural rate of interest.\n\nIf we knew the natural rate precisely, conducting monetary policy would be relatively straightforward. Central bankers could easily assess their policy stance--which could be measured, for instance, as the difference between actual and natural interest rates--and adjust it as needed. If only life were that simple! In reality, given that the natural rate of interest cannot be directly observed, Wicksell proposed that the central bank follow a simple interest rate rule. Given that he believed that the sole function of monetary policy should be to pursue price stability, a modern interpretation of Wicksell's rule would suggest that the central bank should raise the interest rate if inflation is above target and reduce the interest rate if inflation is below target.3 When inflation stabilized, the central bank would know that the interest rate was at its natural level. In principle, this method could be extended to a reaction function that included both an inflation and a maximum-employment objective for the central bank, as is the case for the Federal Reserve.\n\nBut there is another way of measuring the natural rate of interest. Instead of backing out the value of the natural rate of interest by following Wicksell's rule-based approach, one could try to estimate the natural rate directly with the help of an economic model. One prominent example of this approach is the work of my Federal Reserve colleagues Thomas Laubach and John Williams.4\n\nLaubach and Williams estimated the natural rate in a small-scale Keynesian model where inflation responds to the gap between actual and potential gross domestic product (GDP) and economic activity is determined by a simple equation that links deviations of actual from potential GDP to the gap between actual and natural interest rates. In their model, as in Wicksell's framework, inflation generally will rise if the interest rate is low relative to the natural rate and fall if the interest rate is high relative to the natural rate. Their empirical results point to the growth rate of potential GDP as an important determinant of the natural rate of interest, a topic that I will discuss shortly.\n\nIn a recent update to their work--cowritten with another Federal Reserve colleague, Kathryn Holston--Laubach and Williams report that, for the United States as well as other advanced economies, estimates of the natural rate have fallen since the late 1990s, with particularly large declines following the global financial crisis.5 Their results--summarized in figure 3 --support the informal assessment that chronically low interest rates could well be, at least in part, the result of very low natural interest rates and not just a consequence of the cyclical state of the economy.\n\nNow, to our second big question: Having concluded that the natural rate appears to have fallen, how concerned should we be, if at all? We should be concerned because a low natural interest rate can have major economic significance. Let me start elaborating on this point by making two simple observations: First, nothing dictates that the natural rate of interest should be positive; indeed, the natural rate has no effective lower bound. Second, there is an effective lower bound for nominal interest rates (and, consequently, for the actual real rate). Why? Because currency is a government obligation that pays a nominal interest rate of zero and, instead of buying government bills or bonds at a negative interest rate, one can always hold currency.6\n\nTo see why these two simple observations can be so consequential, we need only go back to the work of another great economist from the past. In John Maynard Keynes's General Theory, this contrast between equilibrium and actual interest rates was at the heart of the so-called liquidity trap, a situation where the equilibrium interest rate is so low that even a zero (or slightly negative) nominal interest rate is not low enough to stimulate economic activity.7 Keynes's bottom line was that, when the economy falls into the liquidity trap, traditional monetary policy loses its effectiveness and fiscal policy has to be used for countercyclical stabilization. And here lies the first reason why we should be concerned about chronically low interest rates: When the equilibrium interest rate is very low, the economy is more likely to fall into the liquidity trap; it becomes more vulnerable to adverse shocks that might render conventional monetary policy ineffective.\n\nOf course, as we have all learned over the past several years, unconventional monetary policy tools developed and used since the Great Recession--such as large-scale asset purchases and extended forward guidance--have significantly mitigated concerns about the liquidity trap.8 Nonetheless, the question of whether unconventional tools are perfect substitutes for cutting short-term interest rates remains a topic of active research.9\n\nLet me briefly mention a second reason for worrying about ultralow interest rates: The transition to a world with a very low natural rate of interest may hurt financial stability by causing investors to reach for yield, and some financial institutions will find it harder to be profitable. On the whole, however, the evidence to date does not point to notable risks to financial stability stemming from ultralow interest rates. For instance, the financial sector has appeared resilient to recent episodes of market stress, supported by strong capital and liquidity positions.\n\nLast but definitely not least, a very low natural rate of interest is worrisome because it may reflect more deep-seated economic problems. For instance, economic theory--along with some empirical evidence--suggests that real interest rates and the growth of real GDP tend to move together over the long run.10 Thus, a decline in longer-run equilibrium real rates--as suggested by my observations today and by the careful work of Laubach and Williams--could be yet another indication that the economy's growth potential may have dimmed considerably. This deeply concerning conjecture--which suggests that the slowdown of productivity growth that we have experienced in recent years could be long lasting--has played an important role in Larry Summers's revival of the \"secular stagnation\" hypothesis.11\n\nGiven what a fall in the natural rate of interest might mean for economic performance for years to come, we should reflect on the forces that may have caused that decline--my third question--and on what, if anything, can be done to reverse them--my fourth and last question.\n\nUltimately, the level of the natural interest rate reflects businesses', households', and governments' saving and investment decisions over the medium to longer run. Indeed, the saving-investment channel provides a useful framework for thinking about the relationship between the natural rate and the growth rate of potential GDP. For instance, a lasting slowing in the pace of technological innovation--a key determinant of potential growth--may result in fewer profitable opportunities for businesses, which could dampen their propensity to invest in physical capital.12 At the same time, households might see the slower pace of technological innovation as reducing their future income prospects, which could increase their propensity to save. If persistent, this slowing in the growth rate of potential GDP--and the resulting combination of lower investment and higher saving propensities--would put downward pressure on the natural rate of interest.\n\nMore generally, any persistent factors that affect saving and investment decisions will also affect the natural rate. Recent studies point to trends that may have had a sizable and lasting effect on the balance between saving and investment at the macro level.13 Some of these trends may have worked more directly on the demand for investment goods, whereas others may have had a more direct bearing on saving. Potential factors that others have mentioned as having contributed to reduced investment in physical capital include heightened economic uncertainty in the aftermath of the Great Recession and the lower physical capital needs of many of today's growing firms, particularly information technology firms.14 On the saving side, some researchers have noted that high saving rates in some emerging market countries, combined with a lack of suitable domestic investment opportunities in those countries, may have put downward pressure on interest rates in advanced economies.15 Others have raised the possibility that the trauma associated with the Great Recession may have contributed to a persistent increase in precautionary saving and greater demand for safe and liquid assets.16\n\nThus, both increased saving and reduced investment have potentially driven the sizable decline in the natural rate of interest. If some of the forces behind these shifts prove to be quite persistent, then we could be stuck in a new longer-run equilibrium characterized by sluggish growth and recurrent reliance on unconventional monetary policy.\n\nNonetheless, there is a silver lining. Monetary and fiscal policies could ameliorate some, though not all, of the potential causes of ultralow rates--such as excessive precautionary saving and weak demand for physical capital. In other words, ultralow interest rates are not necessarily here to stay, especially if the right policies are put in place to address at least some of their root causes.\n\nWhat are some of these policies? First, transparent and sound monetary policies here and abroad have helped mitigate downside risks and improve economic conditions, likely boosting confidence in the sustainability of the recovery. Without them, we probably would have had a more pronounced increase in precautionary saving and a deeper decline in fixed investment, which together would have put additional downward pressure on the natural rate of interest and, more important, further damaged the economy's growth potential.\n\nBut, second, the virtues of sound monetary policy notwithstanding, we must not forget, as former Fed Chairman Ben Bernanke reminded us on numerous occasions, that \"monetary policy is not a panacea.\"17 For instance, as I mentioned recently elsewhere, policies to boost productivity growth and the longer-run potential of the economy are more likely to be found in effective fiscal and regulatory measures than in central bank actions.18 Some combination of improved public infrastructure, better education, more encouragement for private investment, and more-effective regulation is likely to promote faster growth, which would increase the natural rate of interest and, thus, reduce the probability that we may find ourselves again struggling to avoid Keynes's infamous liquidity trap. If the natural rate can be lifted by appropriate policies, the economic near-stagnation that many countries have experienced in recent years may well turn out not to be that secular after all.\n\nReferences\n\nBean, Charles, Christian Broda, Takatoshi Ito, and Randall Kroszner (2015). Low for Long? Causes and Consequences of Persistently Low Interest Rates (PDF) , Geneva Reports on the World Economy 17. Geneva and London: International Center for Monetary and Banking Studies and Centre for Economic Policy Research.\n\nBernanke, Ben S. (2005). \"The Global Saving Glut and the U.S. Current Account Deficit ,\" speech delivered at the Homer Jones Lecture, St. Louis, April 14.\n\n-------- (2012). \"U.S. Monetary Policy and International Implications,\" speech delivered at \"Challenges of the Global Financial System: Risks and Governance under Evolving Globalization,\" a seminar sponsored by Bank of Japan-International Monetary Fund, Tokyo, October 14.\n\nCaballero, Ricardo J., Emmanuel Farhi, and Pierre-Olivier Gourinchas (2008). \"An Equilibrium Model of 'Global Imbalances' and Low Interest Rates,\" American Economic Review, vol. 98 (March), pp. 358-93.\n\nCarvalho, Carlos, Andrea Ferrero, and Fernanda Nechio (2016). \"Demographics and Real Interest Rates: Inspecting the Mechanism (PDF) ,\" Working Paper Series 2016-05. San Francisco: Federal Reserve Bank of San Francisco, April.\n\nD'Amico, Stefania, William English, David Lopez-Salido, and Edward Nelson (2012). \"The Federal Reserve's Large-Scale Asset Purchase Programs: Rationale and Effects (PDF),\" Finance and Economics Discussion Series 2012-85. Washington: Board of Governors of the Federal Reserve System, October.\n\nEngen, Eric M., Thomas Laubach, and David Reifschneider (2015). \"The Macroeconomic Effects of the Federal Reserve's Unconventional Monetary Policies (PDF),\" Finance and Economics Discussion Series 2015-005. Washington: Board of Governors of the Federal Reserve System, January.\n\nFernald, John, and Bing Wang (2015). \"The Recent Rise and Fall of Rapid Productivity Growth (PDF) ,\" FRBSF Economic Letter 2015-04. San Francisco: Federal Reserve Bank of San Francisco, February.\n\nFischer, Stanley (2016). \"Remarks on the U.S. Economy,\" speech delivered at \"Program on the World Economy,\" a conference sponsored by The Aspen Institute, Aspen, Colo., August 21.\n\nGagnon, Etienne, Benjamin K. Johannsen, and David Lopez-Salido (2016). \"Understanding the New Normal: The Role of Demographics (PDF),\" Finance and Economics Discussion Series 2016-080. Washington: Board of Governors of the Federal Reserve System, October.\n\nGordon, Robert J. (2016). The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War. Princeton, N.J.: Princeton University Press.\n\nHaldane, Andy (2015). \"Stuck (PDF) ,\" speech delivered at Open University, London, June 30.\n\nHolston, Kathryn, Thomas Laubach, and John C. Williams (forthcoming). \"Measuring the Natural Rate of Interest: International Trends and Determinants,\" in Richard Clarida and Lucrezia Reichlin, organizers, NBER International Seminar on Macroeconomics 2016. Amsterdam: Journal of International Economics (Elsevier).\n\nJohannsen, Benjamin K., and Elmar Mertens (2016). \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, February 9.\n\nKeynes, John Maynard (1936). The General Theory of Employment, Interest and Money. London: Macmillan.\n\nKrishnamurthy, Arvind, and Annette Vissing-Jorgensen (2011). \"The Effects of Quantitative Easing on Interest Rates: Channels and Implications for Policy,\" NBER Working Paper Series 17555. Cambridge, Mass.: National Bureau of Economic Research, October.\n\nLaubach, Thomas, and John C. Williams (2003). \"Measuring the Natural Rate of Interest ,\" Review of Economics and Statistics, vol. 85 (November), pp. 1063-70.\n\nLo, Stephanie, and Kenneth Rogoff (2015). \"Secular Stagnation, Debt Overhang and Other Rationales for Sluggish Growth, Six Years On (PDF) ,\" BIS Working Papers 482. Basel, Switzerland: Bank for International Settlements, January.\n\nMeaning, Jack, and Feng Zhu (2011). \"The Impact of Recent Central Bank Asset Purchase Progammes (PDF) ,\" BIS Quarterly Review, December, pp. 73-83.\n\nMendoza, Enrique G., Vincenzo Quadrini, and Jose-Victor Rios-Rull (2009). \"Financial Integration, Financial Development, and Global Imbalances,\" Journal of Political Economy, vol. 117 (June), pp. 371-416.\n\nRachel, Lukasz, and Thomas D. Smith (2015). \"Secular Drivers of the Global Real Interest Rate (PDF) ,\" Staff Working Paper 571. London: Bank of England, December.\n\nSummers, Lawrence H. (2014). \"U.S. Economic Prospects: Secular Stagnation, Hysteresis, and the Zero Lower Bound,\" Business Economics, vol. 49 (April), pp. 65-73.\n\n-------- (2015). \"Demand Side Secular Stagnation,\" American Economic Review, vol. 105 (May), pp 60-65.\n\nWicksell, Knut (1936). Interest and Prices (Geldzins und Güterpreise): A Study of the Causes Regulating the Value of Money, trans. R.F. Kahn. London: Macmillan.\n\nWoodford, Michael (2012). \"Methods of Policy Accommodation at the Interest-Rate Lower Bound,\" paper presented at \"The Changing Policy Landscape,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., Aug. 30-Sept. 1, pp. 185-288, available at https://www.kansascityfed.org/publications/research/escp/symposiums/escp-2012 .\n\n\n\n1. I am grateful to Antulio Bomfim of the Federal Reserve Board staff for his assistance. Views expressed are mine and are not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. Wicksell's Interest and Prices, published in German in 1898 as Geldzins und Güterpreise by Gustav Fischer (Jena), was first published in English in 1936--see Wicksell (1936). Return to text\n\n3. Wicksell's proposed rule was based on the price level rather than inflation: \"So long as prices remain unaltered the banks' rate of interest is to be raised; and if prices fall, the rate of interest is to be lowered; and the rate of interest is henceforth to be maintained at its new level until a further movement of prices calls for a further change in one direction or the other\" (Wicksell, 1936, p. 189). Return to text\n\n4. See Laubach and Williams (2003). See also Gagnon, Johannsen, and Lopez-Salido (2016) and Johannsen and Mertens (2016). Return to text\n\n5. See Holston, Laubach, and Williams (forthcoming). Return to text\n\n6. It has turned out in practice that nominal interest rates can dip (and have dipped) into negative territory. In part, that is because anyone who wants to hold a substantial amount of wealth in currency will have to pay for storage, safeguarding, and insurance of their currency holdings. This fact means that the lower bound on the nominal interest rate is below zero to an extent that depends on the full costs of holding wealth in the form of currency. In addition, investors appear to be willing to pay for the safety and liquidity of certain government securities. Hence, the term we now use in the Federal Reserve is not the zero lower bound on nominal interest rates, but rather the effective lower bound, which may well be less than zero. By how much? We do not know, but probably not that far from zero. The lowest nominal policy rate among the central banks with negative rates today can be found in Denmark and Switzerland--currently negative 0.75 percent. Return to text\n\n7. See Keynes (1936). Return to text\n\n8. See Engen, Laubach, and Reifschneider (2015). Return to text\n\n9. See, for instance, D'Amico and others (2012); Meaning and Zhu (2011); Krishnamurthy and Vissing-Jorgensen (2011); and Woodford (2012). Return to text\n\n10. See Laubach and Williams (2003). Return to text\n\n11. See, for instance, Fernald and Wang (2015), Gordon (2016), and Summers (2014, 2015). Return to text\n\n12. A lasting slowing in the pace of technological innovation may also help explain the significant decline in the past 10 years in the growth rate of total factor productivity (TFP), the portion of productivity that is not accounted for by measurable inputs to production--see Fischer (2016). The available data suggest that, compared with reduced business investment, the decline in TFP growth accounts for a larger share of the slowing in the growth rate of potential GDP in recent years and, thus, may also be an important factor behind the decline in the natural rate of interest. Return to text\n\n13. See, for instance, Bean and others (2015) and Carvalho, Ferrero, and Nechio (2016). Return to text\n\n14. See Summers (2014) and Rachel and Smith (2015). Return to text\n\n15. See Bernanke (2005); Caballero, Farhi, and Gourinchas (2008); and Mendoza, Quadrini, and Rios-Rull (2009). Return to text\n\n16. See Haldane (2015) and Lo and Rogoff (2015). Return to text\n\n17. See, for instance, Bernanke (2012). Return to text\n\n18. See Fischer (2016). Return to text"
    },
    {
        "speaker": "Janet L. Yellen",
        "position": "Chair",
        "date": "September 29, 2016",
        "title": "Brief Remarks",
        "href": "https://www.federalreserve.gov/newsevents/speech/yellen20160929a.htm",
        "content": "September 29, 2016\n\nChair Janet L. Yellen\n\nAt the \"Banking and the Economy: A Forum for Minority Bankers,\" sponsored by the Federal Reserve Bank of Kansas City, Kansas City, Missouri (via videoconference)\n\nWatch live\n\nThank you, and I also would like to thank the organizers of this forum for arranging for me to be part of your conversation, on a day when other business unfortunately prevents me from travelling to Kansas City.\n\nAnd I am really looking forward to hearing from all of you on what I expect will be a range of topics, but I thought I might start with a few remarks about something of considerable interest to me, which is diversity and inclusion.\n\nI think the Kansas City Fed is an excellent place to discuss this issue because of the recognition it has received for promoting diversity and inclusion, both among businesses and other organizations in the 10th District and in its own ranks. I know that the Bank is continuing to hold Diversity Summits with firms and community groups, the most recent of which was last month. In various ways, it is also promoting diversity among its own staff and senior leaders through recruiting, hiring and promotions, and is closely tracking progress. The Greater Kansas City Chamber of Commerce singled out the Bank this year for its diversity efforts from among 20 organizations and businesses.\n\nI believe these efforts reflect a commitment to diversity that is found throughout the Federal Reserve System, and I would like to talk a bit about the basis for that commitment, starting with why it is that diversity, in its different forms, is so important.\n\nOne reason that the Fed organizes conferences such as this one is to facilitate communication. In this case, we want to communicate with you, as leaders of institutions we oversee and are otherwise affected by our decisions. We want to understand your views and try to explain what we are trying to accomplish. Such communication would not be effective if only one or just a few banks in the 10th District were part of the conversation. Today's forum includes bankers from smaller community banks, regional banks, and large banks because the roles of your institutions in your communities differ, and hearing your different views provides a fuller picture of the industry's views. Similarly, it is important to include in the conversation bankers of diverse backgrounds, which is why it is important that we hear from minority bankers.\n\nIn these examples, diversity in its various forms is a source of strength, which is something that we as financial regulators understand very well. The Federal Reserve supports an ongoing role for community banks in part because diversity among financial institutions promotes a stable and healthy financial system, spurring competition and ensuring that customers of all types have access to a wide variety of services. The Federal Reserve supports the Partnership for Progress, which assists and advises minority-owned financial institutions, because we believe that those institutions are likewise a source of diversity that contributes to a healthy financial system.\n\nI expect it is not news, either, to bankers, that diversity is a source of strength. Every day, in serving customers, bankers can see the strength that comes from diversity--the wisdom of diversification in investment decisions, in diverse product lines for the businesses you lend to, and especially in the strength of diverse communities.\n\nDiversity also strengthens organizations by making it possible to have a wide variety of views available. It helps ensure that individuals within those organizations have the opportunity to shine and employ their talents to the fullest and that their best ideas are heard and acted on. The banks you serve are better able to reach new customers, especially groups of customers who have historically been underbanked, when they show that serving those customers is a top priority. And one of the most effective ways of showing a commitment to a diverse customer base is showing a commitment to a diverse workforce. Demographic trends indicate that minorities will be an increasing share of the population in the years and decades ahead, and thus an increasing share of new customers for your institutions.\n\nMy organization, the Federal Reserve, is also committed to a diverse workforce and to diversity in our senior leadership. The Federal Reserve is pursuing this goal not only for all of the practical reasons I have cited to seek diversity, but also because it is the right thing to do. I want to be clear to all of you that I am committed to improving diversity throughout our organization, including at the upper ranks. Diversity is also important on the boards of directors and advisory councils of Reserve Banks. I hope, in fact, that in this room today there are individuals who one day may serve as an advisor, director or even a Reserve Bank President or member of the Board of Governors.\n\nImproving diversity requires effort and constant focus. We will continue working hard to achieve this goal. I believe it is as vital to the Federal Reserve as it is to your employers, and to every employer, to improve diversity and extend opportunity to everyone."
    },
    {
        "speaker": "Jerome H. Powell",
        "position": "Governor",
        "date": "September 29, 2016",
        "title": "Trends in Community Bank Performance over the Past 20 Years",
        "href": "https://www.federalreserve.gov/newsevents/speech/powell20160929a.htm",
        "content": "September 29, 2016\n\nGovernor Jerome H. Powell\n\nAt the \"Community Banking in the 21st Century\" Fourth Annual Community Banking Research and Policy Conference, sponsored by the Federal Reserve System and the Conference of State Bank Supervisors, St. Louis, Missouri\n\nWatch live\n\nWelcome to Day 2 of the conference. I am grateful to the organizing committee for inviting me to be part of this important event once again. This is the third time that I have had the privilege of addressing this unique audience, which brings together bankers, bank supervisors, and banking researchers to share their thoughts regarding the current and future state of community banking. The interactions that occur at these annual gatherings are incredibly valuable and stimulate innovative thinking on the part of all three groups of participants.\n\nAs usual, the organizers have put together a highly relevant agenda. I was particularly struck by the way in which this year's program spans generations, from last night's keynote speaker, Gene Rainbolt, who began his career in banking more than 50 years ago, to the winners of the case study competition, who are just preparing to embark on their careers. I hope that these impressive and accomplished young men and women will enjoy long and successful careers in banking that they will be able to reflect back on during the 54th annual community banking conference in 2066. I have already penciled in the date on my calendar, and I look forward to hearing what they will have to say.\n\nWhile the keynote addresses, case study competition, and networking opportunities all contribute to the appeal of this event, it is the research sessions that form the core of the conference. In the first research session yesterday, we heard about the importance of community banks to the Missouri economy, the viability of the traditional banking model, what is special about community banks, and the changing characteristics of the communities served by minority depository institutions. In the second session, we heard about the relationship between bank size and performance from three quite different perspectives. Both of these sessions provided cause for optimism about the future relevance and importance of community banks while simultaneously raising concerns about the viability of the very smallest banking organizations.\n\nIn my remarks today, I would like to explore this mixed message a bit further and ask what the observed trends in the data imply for today's community bankers and the communities they serve. In doing so, I will look at changes in the community banking sector at a national level and will also look at geographic patterns of community bank growth and decline. For purposes of these remarks, I will define community banks as those with less than $10 billion in assets, although my conclusions would be the same if I used a lower cutoff, such as $1 billion in assets, or a more detailed definition of community banks, such as that developed by the Federal Deposit Insurance Corporation (FDIC) a few years ago.1 As always, the views I express here today are my own.\n\nI will start by discussing figures showing the number of community banks operating in the United States over the past 20 years. Figure 1 shows the number of community banks for each year from 1995 to 2015. It shows a steady decline in the number of such banks over time. The rate of decline is considerably steeper in the late 1990s than in the period from 2000 to 2010. In the past five years, the rate of decrease has accelerated somewhat but remains slower than that experienced in the late 1990s.\n\nBreaking the universe of community banks down into subgroups based on size, we can see that the decline in community bank numbers is far from uniform.2 The number of banks with between $1 billion and $10 billion in assets has doubled since 1995 (figure 2), although such banks still make up a small percentage of all community banks. I should note that the growth in this \"large community bank\" category is greater than that among banks with more than $10 billion in assets, in terms of both the number of banks added to the category and the percentage growth rate. Banks ranging in size from $300 million to $1 billion have also roughly doubled in number over these past 20 years (figure 3). And the number of banks in the size range from $100 million to $300 million in assets has declined by only a very modest percentage since 1995 (figure 4).\n\nHowever, the picture for banks with less than $100 million in assets is very different from the picture for larger banks. As can be seen in figure 5, the number of such banking organizations has declined by more than two-thirds since 1995. As with the pattern for all community banks, the decline in the number of these small community banks was steeper in the late 1990s than in later years.\n\nWe can identify four factors that help to account for the decrease in the number of banks with under $100 million in assets. Some of this decline reflects the growth of small banks (often de novo banks) out of the smallest size range into larger size categories due to either organic growth or acquisition of another bank. Indeed, 90 percent of the large drop-off in the number of banks in this size range in 2014 and 2015 is due to banks moving up into a larger size category. A number of the smallest banking organizations also disappeared as a result of being merged with or acquired by other banking organizations. Some of the decline reflects the failures experienced in the Great Recession. And, finally, there have been few new bank formations in recent years.\n\nAs noted in a 2014 article by McCord and Prescott, a key difference between the past few years and the late 1990s is that the recent acceleration in the rate of decrease in the number of community banks is due in large part to a decline in new bank charters rather than an increase in the annual number of exits.3 This fact can be seen in figure 6, which shows the number of new charters each year (in blue, with squares to mark yearly values), the actual annual change in the number of community banks (in green, with triangles), and what the annual change in the number of banks would have been in the absence of new entry (in red, with circles), over the past 20 years. It is clear from this figure that in the absence of new entry, the annual decline in the number of community banks between 2000 and 2010 would have been quite similar to what it has been since 2010. Or, viewed from a different perspective, if entry had remained at more \"normal\" levels during the past 5 years, the rate of decline in the number of community banks would not have accelerated. And, since almost all new entrants have less than $100 million in assets, the decline in the number of banks in this smallest size category would have been much less steep during the past 5 years.\n\nResearch by Adams and Gramlich that was presented at the 2014 community banking conference and subsequently published in the Review of Industrial Organization considers the underlying causes of the virtual absence of new bank formation since 2009.4 This research suggests that slow economic growth and low interest rates in the post-crisis environment can explain about 75 percent of the decline in new bank charters. The authors were not able to isolate the effect of regulatory changes on the rate of new bank formation, but note that regulation may also play a role.\n\nThe sharp difference in trends for the number of banks with less than $100 million in assets compared with larger community banks naturally leads to the question of whether this difference is reflected in basic bank performance measures. I will begin with return on assets (ROA). Breaking down all community banks into the same size categories I used earlier, with the addition of a category for all banks larger than $10 billion in assets, we find striking differences in the patterns of bank profitability over time (figure 7). The largest community banks--those with $1 billion to $10 billion in assets (in green, with diamonds to mark yearly values)--followed a pattern similar to that of our largest banks (in black, with crosses), but with slightly worse results throughout the past 20 years. These large community banks had lower average levels of profitability than our largest banks prior to the recent recession, suffered worse losses in 2009, and have enjoyed lower levels of earnings since the crisis.\n\nBanks in the size range from $300 million to $1 billion in assets (in blue, with triangles) have been the most consistently profitable group among community banks, although their profit levels still lag those for the largest banks. These midsize community banks performed as well as banks with $1 billion to $10 billion in assets before the recent recession and remained profitable, on average, even in 2009.\n\nThe story is much the same for banks in the size class from $100 million to $300 million in assets (in red, with squares). Their profit levels were slightly lower than those for larger community banks prior to the crisis, but they performed similarly until 2015, when banks of this size showed a decline in profits not experienced by any other size grouping of community banks. Time will tell whether this is an anomaly or the beginning of a pattern.\n\nLooking at the smallest community banks, those with less than $100 million in assets, gives some hints for why their numbers have declined. The average ROA for the smallest banks (in purple, with circles) has been consistently lower than that for the next-smallest class of banks since 1995. The already lower level of profits for the smallest banks began to decline further in 2006. Since 2009, profits for the smallest banks have increased slightly but remain below their levels of profitability prior to the recession and below the ROA levels for larger banks.5\n\nData on nonperforming loans (NPLs) show a mixed picture.6 A breakdown of community banks by size indicates that the ratio of NPLs to total loans peaked for every size category in 2010 (figure 8). Prior to 2007, the smallest community banks consistently had a higher ratio of NPLs than did larger community banks; but from 2007 until 2013, their NPL rate was below that of larger community banks. In the past two years, NPLs on the balance sheets of the smallest banks have declined more slowly than for larger banks so that banks with less than $100 million in assets once again have the highest NPL ratio.\n\nLet me turn now to consider changes in the number of community banks over the past 20 years at a more local level. For purposes of this discussion, I define local banking markets as counties in rural areas and as Metropolitan Statistical Areas in urban areas. Figure 9 shows those local banking markets in which the number of community banks decreased over the 20 years from 1995 to 2015 (in white) and those markets in which the number of community banks increased or stayed constant (in blue). As you can see, there are markets in every state where the number of community banks has declined. However, there also are markets in every state where community banks have maintained or increased their presence. In fact, the number of local markets that saw their population of community banks hold constant or increase between 1995 and 2015 was more than double the number of local markets that experienced a decline in the number of community banks over this period. And, perhaps surprisingly, the share of rural markets experiencing a decrease in the number of community banks (about 32 percent) was slightly lower than the share of urban markets facing such a decline (about 35 percent).\n\nAs we saw, the vast majority of the decline in the number of community banks involved banks with less than $100 million in assets. This next figure (figure 10) shows changes in the number of banks in this smallest size category together with changes in the number of all community banks. The local markets that are shaded in dark blue are those where both the number of banks with less than $100 million in assets and the number of all community banks declined between 1995 and 2015. The light-blue markets are those where the total number of community banks remained constant or increased despite a decline in the number of banks in the smallest size category. There are just over twice as many markets shaded in light blue as there are shaded in dark blue, indicating that in two-thirds of the markets where the number of very small community banks declined, the number of community banks overall did not decline. Markets in white are those where the number of banks in the smallest category increased or remained unchanged over the past 20 years.\n\nThis examination of the geographic patterns of changes in the population of community banks has shown that most markets in the United States have maintained or increased their numbers of community banks over the past 20 years. Those local markets that have lost community banks have not been concentrated in any particular section of the country, and urban markets have been slightly more likely to lose community banks over the past 20 years than rural areas.\n\nOne might ask, what factors have led some markets to lose community banks while others gained community banks or saw no change? Because of the importance of community banks as a source of small business lending and other retail services, we have explored this question but do not yet have any definitive answers. We considered the possibility that underlying demographic characteristics were driving the observed changes in the number of banks in a local market area. Perhaps the size of the labor force or the population density, the racial and ethnic mix of the population, or changes in any of these factors might explain the outcome. We also considered whether economic conditions such as the unemployment rate, the median household income, the number of business establishments, or changes in any of these measures might be useful in predicting which markets would lose community banks over time. Taking into account all of these variables in a regression framework did not yield much explanatory power.\n\nThis analysis has not led us to a clear story regarding the determinants of changes in the number of community banks serving a local market area, but we intend to continue our research efforts and hope that they will ultimately yield some valuable insights. We can take some comfort from the fact that the number of local markets that either maintained or increased the number of community banks serving their residents and small businesses is much larger than the number of markets that saw a decline in the number of community banks. That said, we recognize that the loss of community banks may have caused some communities to suffer adverse economic consequences.\n\nSo, what do we take away from this review of bank numbers and performance? First, the decline in the number of community banks is not a recent phenomenon--it has been a constant theme over at least the past 20 years. Second, it has occurred almost exclusively among the smallest community banks--those with less than $100 million in assets. However, I want to emphasize that the long-trending decline in the number of very small community banks does not mean that these banks do not play an important role in our financial system. Almost all newly chartered banks fall into this category, and many of these banks thrive and, ultimately, outgrow the smallest size category. Thus, banks with less than $100 million in assets should be viewed as a key source of dynamism and competition within the banking sector. Third, although the rate of decline has accelerated a bit during the past 5 years, that acceleration is largely due to a lack of entry rather than an increased rate of exit. Fourth, although the lack of entry may be due in part to increased regulatory burden, much of it can be explained by very low interest rates and a post-crisis expansion that has been slower than usual. Fifth, at a local level, about one-third of markets have seen a decline in the number of community banks over the past 20 years, but about two-thirds have seen no change or an increase in the number of community banks. It is unclear what factors explain observed changes in the number of community banks at a local market level. More research is needed on this question.\n\nI think the key question for policymakers is whether the recent acceleration in the rate of decline in the number of small banks is primarily a structural change attributable to increasing economies of scale--or, perhaps more accurately, diseconomies of very small scale--or whether recent efforts by the FDIC and others to encourage more chartering of new banks, combined with a return to higher interest rates and stronger economic growth, will mitigate the decline in numbers. At this point, I think it is too soon to say.\n\nThe Federal Reserve and the Conference of State Bank Supervisors began this conference three years ago in order to stimulate research on community banks, with the goal of improving our understanding of their condition and their important contributions to economic growth and prosperity. We plan to continue our own research efforts across the Federal Reserve System, as well as our efforts, through initiatives such as this conference, to encourage academics to focus their attention on community banks.\n\nOf course, the Federal Reserve's support for community banks goes well beyond research. One of the clearest lessons from our most recent recession is that, when it comes to bank regulation and supervision, one size does not fit all. As we seek to promote safety and soundness and ensure consumer compliance, we increasingly tailor rules and supervisory approaches to the differing risks posed by institutions of different size and complexity. This way, we can achieve our aims without creating undue regulatory burden. The Federal Reserve is committed to this approach to community bank oversight and to ensuring that new and existing regulations are not unduly burdensome for community banks. In addition to fulfilling this commitment, the Federal Reserve and other federal banking agencies have launched a review to identify banking regulations that are outdated, unnecessary, or unduly burdensome, as required by the Economic Growth and Regulatory Paperwork Reduction Act.\n\nThe Federal Reserve has taken some concrete steps to provide burden relief by publishing a streamlined Call Report for non-complex community banks, extending the examination cycle for banks with $1 billion or less in total assets, increasing the threshold for the Small Bank Holding Company Policy Statement to $1 billion and expanding the scope to include savings and loan holding companies. In addition, we have efforts underway to reduce burden associated with our real estate appraisal requirements, to simplify the regulatory capital requirement for community banks, to encourage resource sharing among community banks to help manage their BSA and AML obligations, and to use Call Report data and forward-looking risk analytics to identify high-risk community banks, which would allow us to focus our supervisory response on the areas of highest risk and reduce the regulatory burden on low-risk community banks. We will continue to work with bankers and the other banking regulators to ensure that we reduce burden and complexity in our regulations and guidance.\n\nAnother way that we further our understanding is by talking to the bankers themselves. The entire Board of Governors meets twice a year with the Community Depository Institutions Advisory Council, which includes representatives of community banks, thrifts, and credit unions in each of the 12 Federal Reserve Districts. Individual Governors also take advantage of opportunities to meet with community bankers from time to time. I speak regularly to bank executives, including those who run smaller institutions. I find these types of conversations--with people who live and work in the world outside the Capital Beltway and far from Wall Street--to be particularly enlightening. In addition, I hope that some of the conversations here today among researchers, bankers, and bank regulators will continue, leading to benefits to all in the form of more informative research, better design and implementation of regulatory policy, and enhanced community bank performance.\n\n\n\n1. The FDIC definition of community banks can be found at https://www.fdic.gov/regulations/resources/cbi/report/CBSI-1.pdf. Return to text\n\n2. All asset sizes are converted to 2005 dollars, so the changes in size distribution cannot be attributed to inflation. Return to text\n\n3. See Roisin McCord and Edward Simpson Prescott (2014), \"The Financial Crisis, the Collapse of Bank Entry, and Changes in the Size Distribution of Banks ,\" Federal Reserve Bank of Richmond, Economic Quarterly, vol. 100 (First Quarter), pp. 23-50. Return to text\n\n4. Robert M. Adams and Jacob Gramlich (2016), \"Where Are All the New Banks? The Role of Regulatory Burden in New Bank Formation,\" Review of Industrial Organization, vol. 48 (March), pp. 181-208. Return to text\n\n5. The patterns for return on equity (ROE) are similar to those for ROA, although community banks as a whole had negative ROE in both 2009 and 2010. The largest community banks, with $1 billion to $10 billion in assets, suffered much greater negative returns on equity in these years than did smaller community banks. Midsize community banks, with $300 million to $1 billion in assets, fared better than their larger and smaller counterparts.\n\nThe smallest community banks showed an unusual pattern in their ROEs. (It should be noted that, for banks of this size, ROE can be a questionable measure of profitability because such banks tend to be either privately held or very thinly traded.) These banks were in the only size category that did not show a negative ROE in 2009, but it was also the only class to show a negative ROE in 2013, and the ROE for these banks has been consistently below that for larger banks since the recession. Return to text\n\n6. NPLs are defined as nonaccrual loans plus loans that are 90-plus days past due and still accruing. Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "September 27, 2016",
        "title": "Why Study Economics?",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20160927a.htm",
        "content": "September 27, 2016\n\nVice Chairman Stanley Fischer\n\nAt the Convocation for the Department of Economics, Howard University, Washington, D.C.\n\nI am very pleased to visit today with the students and faculty of the Howard University Economics Department. First, a fact that you know but others may not: The Howard University Economics Department is the only producer of economics Ph.D.'s among the nation's historically black colleges and universities, and it has been teaching economics to undergraduates for nearly a century.1\n\nSpeaking as one economist to a group among whom I hope will be many future economists, let me start by saying that pursuing a degree in economics can bring many rewards. First, an economics degree provides many possible career paths. The discipline's logical, structured approach to problem solving is valued in many settings, including academia, banking, business, consulting, government, and law. Economics majors typically receive salaries that represent a good return on their educational investment. Second, in addition to career prospects and financial rewards, economics offers a means of engaging in many of society's most pressing issues. The study of economics provides a rigorous, analytic perspective on human behavior. It commands respect and has the ability to influence policies that address important issues. A degree in economics will help you understand and participate in these policy debates, putting you in a good position to change the world for the better.\n\nNext, I would like to discuss two current questions that economists are actively debating: First, why is participation in our nation's labor force declining? And, second, what can be done to improve economic mobility (the ability to climb the economic ladder) for children from all groups and from all areas of the country? By doing so, I hope to illustrate the relevance of economics to important, real-life issues.\n\nThe proportion of adults participating in the labor force--that is, either holding jobs or actively searching for employment--has declined substantially over the past decade. The decline has reflected, in part, the severe economic recession. Millions of people lost their jobs, and many of them experienced great difficulty finding new employment. Some of these people became discouraged and stopped looking for work. In other words, they dropped out of the labor force. However, much of the decline in labor force participation reflects factors that precede the recession.2 Most significantly, our population is aging, and older people participate in the labor market at lower rates than younger adults. In addition, the labor force participation of prime-age males--that is, individuals aged 25 through 54--has been declining since the mid-1960s, particularly among those with only a high school degree or less education, and has continued to decline in the years since the last recession.\n\nEconomists are examining a number of reasons why prime-age males are falling out of the labor force. Here there are differences among economists. Some economists have emphasized the role of public assistance programs, such as disability insurance. Some evidence suggests that public assistance income has likely played a role. Other economists have put more emphasis on the effects of the reduction over time in the demand for lower-skilled labor.3 Indeed, the wages of high school graduates have fallen sharply in comparison with the wages of college graduates over the past 40 years. Many economists believe that the decline in demand for lower-skilled workers reflects technological changes.4 For instance, the introduction of information technology such as desktop computers may have boosted the wages of highly skilled workers by more than the wages of workers with fewer skills. The slump in demand for lower-skilled labor likely also reflects the effects of globalization, including competition from goods produced and imported from abroad.5\n\nMy second current question concerns economic mobility: How likely is a child from a low-income family to move up to a higher income level as an adult? Over the past few years, economists have made important findings using newly available data. First, economic mobility varies substantially across the United States. For example, the odds of a child from the bottom quintile of the income distribution reaching the top quintile of income as an adult are 11 percent here in the Washington, D.C., area but only 4 percent in the Charlotte, North Carolina, region. Second, mobility is significantly lower in areas with greater residential segregation in terms of both race and income. Mobility is also lower in areas with greater income inequality, less family stability, and lower-quality schools.6 However, we need further study and analysis to understand whether these factors cause lower mobility or are merely correlated with it. Thus, despite the gains in our knowledge in recent years, significant gaps remain in our understanding of what factors help and hinder economic mobility.\n\nI will conclude by discussing diversity in the economics profession. Our profession currently is not very diverse, but it needs to be. Only about one-fourth of tenured and tenure-track faculty members in U.S. academic economics departments are women, and only around 5 percent are African American or Hispanic. Yet research conducted by economists as well as other social scientists suggests that a diversity of perspectives and ideas lead to better decisions and increased productivity.7 In my own experience, economic policy decisions are better when informed by a wide range of views and experiences. You all here today are crucial to the future of our profession.\n\nIndeed, I hope that by obtaining your degrees and working on economic problems, you will help change the field of economics itself. As in many other fields, economics undergoes continual redesign by its practitioners. We need--and by that I mean society as a whole needs--a more diverse set of practitioners in economics, practitioners who may perceive different questions to be important and different answers to be more persuasive. And so, by joining the profession you can acquire the power to change not only the field, but also the broad set of societal institutions that are influenced by the work of economists.\n\nEconomists tend to respond to the results of research. And the research shows the importance of diversity in decisionmaking. As a result, many organizations are working very seriously to become more diverse. At the Federal Reserve Board, these efforts include developing connections with the Economics Department here at Howard. Our economists have recently served as visiting faculty at Howard or have given guest lectures here. During the past spring semester, Board economists served as mentors to Howard master's degree and Ph.D. students. This fall, we are offering a class on statistical programming methods through the university. On October 25th, we will host an open house with the undergraduate economics association here at Howard for students who are interested in learning more about the Federal Reserve. I encourage you to attend. I would also like to make you aware that the Board offers internships to qualified students, including Howard students studying economics. Moreover, the Federal Reserve Board's Office of Diversity and Inclusion is coordinating an effort to increase the diversity of our staff.8 Everyone at the Board with responsibility for recruiting, hiring, management, and promotion is involved. But I want to emphasize that these are steps on what will be a long road.\n\nFinally, Board economists are also working to increase our understanding of the diverse economic experiences of different groups in the economy. For example, staff economists have recently been examining the disparities in wealth across families using our Survey of Consumer Finances. Wealth is an important measure of household well-being; it can be used to start a new business, cover expenses when household income unexpectedly falls, and provide an inheritance to children--all factors that influence opportunities for economic advancement. One study finds that factors such as educational attainment and inheritances almost entirely explain the gap between the wealth of white families and that of Hispanic families. Although these factors also explain most of the gap in wealth between white families and black families, a substantial portion of this gap cannot be explained by such factors.9 Additional research is required to fully explain the difference in wealth across white and African American households.\n\nThank you for inviting me to speak to you. It would be great to see some of you who are here today going on to influence the direction of the country on any number of issues. To put it in a nutshell, I firmly believe that a degree in economics will equip you for a personally productive and rewarding career, will position you to help make progress on some of society's toughest issues, and will change the field of economics itself.\n\nThank you for listening--and may you all both enjoy and succeed in your future careers, especially in economics.\n\n\n\n\n\n\n\n1. I am grateful to Andrew Cohen and Byron Lutz of the Federal Reserve Board staff for their assistance. Views expressed are mine and are not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See Stephanie Aaronson, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014), \"Labor Force Participation: Recent Developments and Future Prospects (PDF) ,\" Brookings Papers on Economic Activity (Fall), pp. 197-255. Return to text\n\n3. See John Bound, Stephan Lindner, and Timothy Waidmann (2014), \"Reconciling Findings on the Employment Effect of Disability Insurance ,\" IZA Journal of Labor Policy, vol. 3 (11), pp. 1-23. For an opposing view that concludes that disability insurance has significantly suppressed the labor force participation of the less skilled, see David H. Autor and Mark G. Duggan (2003), \"The Rise in the Disability Rolls and the Decline in Unemployment,\" Quarterly Journal of Economics, vol. 118 (February), pp. 157-205. Return to text\n\n4. See Daron Acemoglu (2002), \"Technical Change, Inequality, and the Labor Market,\" Journal of Economic Literature, vol. 40 (March), pp. 7-72. Return to text\n\n5. See David H. Autor, David Dorn, and Gordon H. Hanson (2013), \"The China Syndrome: Local Labor Market Effects of Import Competition in the United States,\" American Economic Review, vol. 103 (October), pp. 2121-68. Return to text\n\n6. See Raj Chetty, Nathaniel Hendren, Patrick Kline, and Emmanuel Saez (2014), \"Where Is the Land of Opportunity? The Geography of Intergenerational Mobility in the United States ,\" Quarterly Journal of Economics, vol. 129 (November), pp. 1553-1623. Return to text\n\n7. See, for example, Amanda Bayer and Cecilia Elena Rouse (forthcoming), \"Diversity in the Economics Profession: A New Attack on an Old Problem,\" Journal of Economic Perspectives. Return to text\n\n8. See Board of Governors of the Federal Reserve System (2015), Report to the Congress on the Office of Minority and Women Inclusion (PDF) (Washington: Board of Governors, March). Return to text\n\n9. See Jeffrey P. Thompson and Gustavo A. Suarez (2015), \"Exploring the Racial Wealth Gap Using the Survey of Consumer Finances (PDF),\" Finance and Economics Discussion Series 2015-076 (Washington: Board of Governors of the Federal Reserve System, September). Return to text"
    },
    {
        "speaker": "Daniel K. Tarullo",
        "position": "Governor",
        "date": "September 26, 2016",
        "title": "Next Steps in the Evolution of Stress Testing",
        "href": "https://www.federalreserve.gov/newsevents/speech/tarullo20160926a.htm",
        "content": "September 26, 2016\n\nGovernor Daniel K. Tarullo\n\nAt the Yale University School of Management Leaders Forum, New Haven, Connecticut\n\nWatch Live\n\nSupervisory stress testing has become a cornerstone of post-crisis prudential regulation. Stress testing, unlike traditional capital requirements, provides a forward-looking assessment of losses that would be suffered under adverse economic scenarios. The simultaneous testing of the largest firms lends a perspective on a large part of the banking system and facilitates identification of common exposures and risks.\n\nDuring the financial crisis, the success of an ad hoc stress test in assessing the capital needs of, and restoring confidence in, the nation's largest financial institutions encouraged Congress to make stress testing a required and regular feature of large firm prudential regulation.1 The Federal Reserve has, in the succeeding years, substantially refined its supervisory stress test. Moreover, the stress test has been integrated into our Comprehensive Capital Analysis and Review (CCAR), which both ties the results of the test into the banks' capital distribution practices and evaluates their risk management and capital planning capacities.\n\nToday I want to share with you the results of an extensive review of the statutory stress test and CCAR programs, which we began following the end of the 2015 cycle. Before turning to the reasons for that review and some ideas for changing these programs that have arisen from it, I will take a few moments to summarize the characteristics and purposes of the programs as they have evolved to this point.\n\nStress Testing and CCAR Today\nAs we have implemented the requirement mandated by the Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank Act) for stress testing--which the Federal Reserve denominates as the Dodd-Frank Act Stress Test (DFAST)--that exercise includes four main steps.2 (1) The firms subject to DFAST provide the Federal Reserve with detailed, significantly standardized data on their loans, securities holdings, trading positions, counterparty exposures, revenue, expenses, and balance sheets. (2) The Federal Reserve specifies hypothetical macroeconomic and financial market scenarios--including an \"adverse\" and a \"severely adverse\" scenario. (3) The Federal Reserve inputs the data from the firms into its own supervisory models to project each firm's losses, revenues, and capital over a nine-quarter planning horizon under the specified scenarios. (4) The results of the exercise, including the capital positions of the firms following the hypothesized stress scenarios, are disclosed to the public.\n\nAs DFAST has evolved, it has become an increasingly valuable tool for evaluating whether the largest financial firms are holding sufficient capital to continue providing credit in the event of significant macroeconomic and financial stress. However, in itself DFAST does not set any capital ratios or limit any capital actions by the firms. Those functions are implemented through the CCAR program, which was created through the regulatory process by the Federal Reserve.3 In CCAR, the Federal Reserve assesses the overall capital adequacy of the firms--including evaluations of whether each firm's capital provides an adequate buffer for the losses that would be incurred during the stress scenarios, whether its risk management and capital planning processes are appropriately well-developed and governed, and how its plans to distribute capital through dividends or share repurchases could affect its ability to remain a viable financial intermediary in the hypothesized scenarios. Given how central these considerations are to effective risk management and the soundness of these firms, we are progressively integrating the qualitative elements of CCAR into our year-round supervisory program for the largest banking organizations.\n\nUnder CCAR, the Federal Reserve may object to a firm's capital plan on either quantitative or qualitative grounds. A quantitative objection is made when the stress test reveals that a firm would not be able to maintain its post-stress capital ratios above the regulatory minimum levels over the planning horizon, taking into account its planned capital distributions. We have taken planned distributions into account because, as the run-up to the financial crisis revealed, firms may be reluctant to cut their distributions--particularly dividends--even in a period of growing stress. Thus, CCAR included what has been called a \"pre-funding\" requirement.\n\nThe Federal Reserve may object on qualitative grounds if it finds that the firm's capital planning processes are not sufficiently reliable. The qualitative assessment includes the assumptions and analyses underlying each firm's capital plan, its controls and governance processes, and whether previously identified weaknesses in management and operations have been corrected. If the Federal Reserve objects on quantitative or qualitative grounds, the firm may not make any capital distributions without our permission. In practice, in the case of a qualitative objection, we have generally permitted distributions at the previous year's level but no increases. This practice, however, has been in the context of distributions rising from generally low levels coming out of the crisis; there has been no guarantee that a similar practice would prevail as distributions continue rising.\n\nThe quantitative component of CCAR, based as it is on the DFAST stress tests, has contributed to the continued strengthening of the capital levels of the largest financial institutions that began after the original stress test in the winter of 2009.4 While, understandably, many focus on the quantitative side and its implications for capital distributions, the importance of the qualitative component has been perhaps underappreciated. We saw during the 2009 stress test that many large financial institutions were unable to marshal the data necessary to gauge their own exposures accurately or to project the adverse effects they would suffer in a tail event, as opposed to a more ordinary cyclical downturn. CCAR has required the firms to steadily improve their risk management and capital planning processes. Indeed, some of the firms--particularly the less complex banks within the CCAR cohort--are now meeting, or are close to meeting, our supervisory expectations across a range of risk management and capital planning processes.\n\nThe CCAR Review\nClearly, then, we regard the stress testing and CCAR programs to have made substantial contributions to protecting the safety and soundness of the nation's largest financial firms and to promoting the stability of the financial system as a whole. But, equally clearly, if a stress testing regime is to continue to play this role, it must be dynamic. The hypothesized scenarios must change to take account of new economic and financial risks. The supervisory model may, in some circumstances, need to be changed to take account of evolving economic conditions and bank portfolio characteristics. Additionally, we have been refining the stress testing and CCAR processes in what is, of course, still a relatively new regulatory and supervisory tool. Changes of all these kinds have been, and will continue to be, made from year to year.\n\nAfter five years of post-crisis stress testing, however, we believed it was important for us to conduct a more thorough assessment of the program. Taking advantage of the shift in timing of the annual stress tests following the 2015 cycle, we undertook an overall review.5 We knew there were several areas to which attention was needed. These included the imperfect alignment of CCAR with the regulatory capital requirements as they had evolved since we began stress testing, the desire for additional macroprudential elements in the stress test, and the qualitative component of CCAR as it applied to less complex firms.\n\nBut we also wanted to hear what others thought. Accordingly, we met with bank officials, debt and equity-side market analysts, public interest groups, and academics--both to solicit their views on the topics I noted a moment ago and to hear their overall evaluation of, and recommendations for, our stress testing and CCAR exercises. As you can imagine, we received a wide range of suggestions, at least some of which were inconsistent with one another. In the main, though, these discussions reflected strong support for stress testing, reinforced our going-in view of the key issues for consideration, and presented us with some other areas for possible change. Before describing the package of potential changes that is emerging from our review, let me explain a bit more about each of the key topics.\n\nFirst is the fact that CCAR has been adjusted to align with some, but not all, of the important changes made in our regulatory capital rules over the past six years.6 One might decide that the regulatory capital rules and CCAR should be different, complementary capital measures, roughly the way that a leverage ratio requirement and risk-weighted capital requirements are complementary. In some particulars, though, CCAR sits a bit uneasily alongside the ongoing capital requirements. The most notable example is that CCAR assumes that a firm will continue to make its planned capital distributions during a stress period even though the regulatory capital rules now include a capital conservation buffer to limit such distributions. Another is that, to this point, CCAR has not reflected the firm-specific capital surcharge we have adopted for global systemically important banks (GSIBs).\n\nOur second key topic was the macroprudential dimension of the stress testing and CCAR regimes. One of the most important lessons of the financial crisis was that prudential regulation, including capital regulation, had been dominantly microprudential in nature, even for the largest firms. That is, the regulation was designed and applied with a view mostly to the idiosyncratic risks faced by a bank in isolation, without regard to the interaction of the bank and the financial system as a whole. Thus, for example, capital regulation did not take account of fire sale effects--the reduction in portfolio values for one bank by other banks selling certain types of assets in order to enhance their own solvency or to counter a reduction in funding availability. Similarly, microprudential capital regulation allows a bank to meet its capital ratios by reducing lending--that is, by reducing the denominator of its ratio--as well as by increasing capital. If many banks were to follow this strategy, even creditworthy borrowers would be adversely affected, thereby exacerbating an economic downturn.\n\nOur stress testing and CCAR regimes do have some macroprudential elements, which have been modestly enhanced over the past few years. By conducting the stress tests for all large banks at the same time under common scenarios, we can evaluate the collective losses that may be borne by a major part of the industry in the stress scenario. We vary scenario design to take account of a variety of risks to the financial system and in a way that reduces procyclical effects.7 We vary the market shock over time to reduce the incentive for firms to correlate their asset holdings or adopt correlated hedging strategies that are treated relatively favorably under one particular market shock scenario. And we do not allow firms to plan on a reduction in their balance sheets as a way to meet capital ratio requirements under stress.\n\nStill, as currently conceived and implemented, our stress testing regime emphasizes the direct risks to bank capital from a severe recession and associated market dislocation via the usual channels of reduced operating revenues combined with credit, market, counterparty, and operational losses. However, as noted by some academics and policy analysts, a fully developed macroprudential dimension to stress testing would incorporate indirect risks to bank capital through channels such as market-wide funding and liquidity disruptions, fire sales, and so on.8 These amplification effects are obviously particularly important for firms that have relatively larger trading books or that rely relatively more on short-term funding, or both. Indeed, many of the academics with whom we discussed stress testing during our review emphasized the importance of building out the macroprudential elements of our stress testing program.\n\nThe third topic we had identified for review was the nature of the qualitative assessment as it applied to the relatively smaller, less complex firms within the CCAR exercise. While we had always explicitly differentiated our risk management and capital planning expectations for these firms, our supervisors had observed that many such firms seemed uncertain of whether they would nonetheless be held to the more stringent standards intended for the largest, most complex firms. In the course of our review, comments from these smaller, less complex firms confirmed this observation. Officials from these banks expressed the view that the CCAR qualitative assessment was unduly burdensome because it created pressure to develop complex processes, extensive documentation, and sophisticated stress test models that mirrored those in use at the largest, most complex firms, in order to avoid the possibility of a public objection to their capital plan. Since our intention had never been to create an incentive for firms with a relatively small systemic footprint to invest in stress testing processes appropriate only for larger or more complex firms, we knew we needed to address this problem.\n\nResults of the Review\nAfter more than a year of discussions and analysis, we have developed ideas for changes to the stress testing and CCAR regimes that would address these three key issues, along with some related matters that arose during the course of our review. Some of these changes would need to be pursued through rulemakings, including the usual notice-and-comment process. Others can be implemented through nonregulatory changes, though some will need further elaboration in moving from idea to concrete practice. Thus, there is a necessarily provisional character to the package set forth here. Except for the relief from the qualitative requirements for smaller, less complex CCAR firms--which I will describe a bit later--we do not contemplate proposing regulations to implement these ideas until early next year. Thus, any such changes would not apply to the coming 2017 DFAST/CCAR cycle.\n\nBetter Alignment of CCAR with the new regulatory capital rules\nAs I noted earlier, there have been significant additions to regulatory capital requirements since the first CCAR exercise began in late 2010. While some--such as revised risk-weighted asset calculation methodologies and definitions of capital--have been integrated into the stress testing program, other important additions have not. Most significant are the various capital buffer requirements that sit atop the regulatory minimum levels. These include a uniform 2.5-percent capital conservation buffer (CCB), the GSIB surcharge, and a countercyclical buffer that can expand the CCB for a broad range of firms in times of increasing financial vulnerabilities.9 Firms that do not hold capital sufficient to meet or exceed this combined buffer level are subject to restrictions on their capital distributions and bonus payments to executives, which become progressively stricter as their capital level falls deeper into the buffer.\n\nTo better align CCAR with the regulatory capital rules as they now stand, we will be considering adoption of a \"stress capital buffer\" (SCB) approach to setting post-stress capital requirements that would further integrate our capital rules with our stress test and CCAR frameworks. The simplest way to describe it is that the SCB would replace the existing 2.5 percent CCB as a component in each CCAR firm's point-in-time capital requirements. The SCB would be risk-sensitive and vary across firms, based on the results of the annual stress test. Specifically, it would be set equal to the maximum decline in a firm's common equity tier 1 capital ratio under the severely adverse scenario of the supervisory stress test before the inclusion of the firm's planned capital distributions, a simplification from the current practice of calculating the capital positions of the firm separately for each quarter in the scenario horizon.\n\nAs is now the case with the CCB and other applicable capital buffers, a firm would be subject to restrictions on its capital distributions whenever its capital levels fall below the combined regulatory minima and buffers. Although it is likely that the stress test losses will continue to exceed 2.5 percent of risk-weighted assets for most GSIBs, the SCB would have a specified floor at this current CCB level to avoid any reduction in the stringency of the regulatory capital rules. A firm's buffer requirement would be recalculated after each year's stress test, and its capital plan would not be approved in CCAR if the plan indicated that the firm would fall into the buffer under the stress test's baseline projections.\n\nLet me use a hypothetical example to illustrate how the SCB would work. Assuming that a firm's common equity tier 1 capital ratio declines in CCAR's severely adverse scenario from 13 percent to 8 percent, that firm's SCB would be the greater of 2.5 percent or the 5 percent decline--thus, 5 percent. Assuming further that this firm is a GSIB with a surcharge of 3 percent and that the countercyclical buffer is not in effect, the firm would be constrained in making capital distributions that would bring its common equity tier 1 capital ratio under 12.5 percent. The 12.5 percent figure is the sum of the 4.5 percent minimum common equity tier 1 risk-weighted capital requirement, the 3 percent surcharge, and the 5 percent stress loss as calculated in annual stress test.10\n\nBecause the GSIB capital surcharge already exists as an additional buffer requirement in the regulatory capital rules, the stress capital buffer approach would effectively add the GSIB capital surcharge to our estimates of the amount of capital needed under stress. This would generally result in a significant increase in capital requirements applicable to the GSIBs, for most of which CCAR has been their binding capital constraint. But having both the stress loss buffer and the capital surcharge included in our capital requirements is wholly consistent with the reasons for having a capital surcharge in the first place. Indeed, not having the two together has actually been an anomaly that arose from the sequencing of the various capital strengthening measures we have undertaken.\n\nThe Board adopted the GSIB surcharge requirement as part of its implementation of section 165 of the Dodd-Frank Act, which established the important macroprudential principle that financial firms should be subject to increasingly stringent regulation as their systemic importance increases. As explained in more detail in the white paper that accompanied the Board's final GSIB risk-based capital surcharge rule,11 the material distress or failure of a GSIB would have an adverse impact on the financial system as a whole that is far greater than the impact on the financial system of the distress or failure of a non-GSIB banking firm. Accordingly, GSIBs should face capital surcharges to compel internalization of those external costs. This should reduce the probability of a GSIB's failure enough below that of a non-GSIB that the expected impact on the system of a GSIB and a non-GSIB failure are more comparable.\n\nBecause the difference in the external costs of the distress or failure of a GSIB as compared to a non-GSIB is likely to be at least as high during times of macroeconomic and financial market stress as during ordinary times, there is no reason why the GSIB surcharge should not be a part of the post-stress capital regime. A complementary point is that the extra buffer required by the GSIB surcharge also reflects the fact that even the best-conceived annual stress scenarios cannot capture all tail risks in the financial system. The integration of capital rules and the stress test thus advances our second aim in initiating our CCAR review--the incorporation of more macroprudential elements.\n\nAs some of you may know, Chair Yellen and I have, on a number of occasions over the past year or so, indicated publicly that we would be considering the effective incorporation of the surcharge into post-stress capital expectations. Some industry representatives have subsequently argued that this step is not warranted. While we will of course address these and other comments as our rulemaking process moves forward, I want to comment now on a couple of arguments, since they seem to reflect a misunderstanding of our stress testing program or of the regulatory structure established by the Dodd-Frank Act.\n\nOne such argument is that it is duplicative to include both the anticipated losses under stress and the GSIB surcharge in a firm's capital requirement because two elements of our current stress test, the global market shock and the counterparty default shock, only apply to GSIB firms. However, these additional scenario components capture direct losses to which any firm engaged in material trading activity is exposed. The market shock measures the trading mark-to-market losses associated with sudden changes in asset prices. The large counterparty default measures the losses associated with repricing counterparty exposures based on the market shock, and then assuming the default of the counterparty that represents the largest net exposure. These components of the stress test do not capture the adverse impact of a GSIB failure on the financial system as a whole--the risks that are the basis for the GSIB surcharge.\n\nThese components of our stress test currently apply only to GSIBs because GSIBs are the only firms currently in CCAR for which these exposures are material. Non-GSIBs currently do not have material trading activities and so would suffer only small direct trading losses as a result of severely stressed market conditions or the failure of a major derivatives or repurchase agreement (repo) counterparty. As the U.S. intermediate holding companies of foreign banks with more material trading businesses in their U.S. operations are added to CCAR, we intend to revisit whether the global market shock and counterparty default component should be applied to firms beyond the U.S. GSIBs.\n\nAnother argument offered against inclusion of the surcharge as an element of post-stress capital expectations is that the material distress or failure of a GSIB no longer poses a significant threat to financial stability due to the regulations and supervisory programs that are designed to improve GSIB resolvability. These measures include, among others, the proposed total loss absorbing capacity (TLAC) rule, the proposed qualifying financial contracts early termination rule and related International Swap and Derivatives Association (ISDA) protocols, and efforts to ensure firms engage in strong recovery and resolution planning.\n\nIt is true that these efforts have improved GSIB resolvability in recent years. But these efforts are ongoing, rather than complete. More importantly, while there is certainly a relationship between the goals of strengthening the resiliency of the most systemically important firms and making them more readily resolvable should they nonetheless fail, those are still separate regulatory aims. The demise of a very large financial institution would cause substantial damage to the economy and the financial system even if it was not so disorderly as to threaten the system entirely. Note, in this regard, that the Dodd-Frank Act requires both more stringent prudential standards for systemically important firms and a process for promoting the orderly resolution of these same firms. While the complementarity of these and other elements of a regulatory program always warrant consideration, and while adjustments in all aspects of the program should be made as conditions and practices evolve, current work on orderly resolution is surely no argument against the promotion of systemic stability and macroprudential aims by integrating the surcharge requirement with CCAR.\n\nChanges to the treatment of planned dividends and share repurchases\nThe shift to a stress capital buffer approach would provide a mechanism for addressing two issues related to capital distribution limitations under CCAR. The first is the arguable inconsistency between, on the one hand, the existing CCAR assumption that all planned dividends and share repurchases would proceed during the two-year planning horizon, regardless of how much stress the bank was under and, on the other, the concept of a capital conservation buffer above minimum capital requirements as it has been added to the capital rules. The second is a soft limitation on dividends put in place by the Board at the inception of CCAR. Both of these features of CCAR reflected supervisory concerns with the fact that, even as the financial crisis was clearly unfolding, some of the largest banks continued to repurchase shares and pay dividends to shareholders and, thereby, depleted capital that proved to be needed later.12\n\nThe SCB approach addresses the first of these issues by providing a continuous constraint on any planned distributions that would bring capital levels below the sum of the minimum 4.5 percent of risk-weighted assets plus the firm-specific SCB, plus any applicable GSIB surcharge.13 However, because declines in observed and reported capital levels usually occur with a lag, and the historical evidence that dividends are less likely to be curtailed than share repurchases,14 we would assume a firm will maintain its dividends for one year while reducing its repurchases. This would have the effect of requiring a firm to hold capital to meet its stress losses and fund its planned dividends over the next year.\n\nThe switch to an SCB approach would also give us an opportunity to address a second issue, the soft limit on dividends in CCAR. Since its inception, our policy statements on CCAR have indicated that a capital plan with a planned dividend payout ratio above 30 percent would be subjected to particularly close scrutiny. When this policy was adopted in late 2010, we expected that it would be a useful guideline during a period when most of the CCAR banks would need to continue increasing capital levels for some time but also recognized that at some point we would need to revisit it.\n\nSince the new approach of adding one year's planned dividends to a firm's capital buffer should act as a disincentive for imprudent or unsustainable levels of dividends, the notion of extra scrutiny on planned dividends may no longer be useful. And we would, in any case, be reluctant to substitute a higher payout ratio for the original 30 percent ratio because it may end up being an implicit target for banks to try to reach. However, firms planning higher dividends should be aware that the operation of the SCB is such that, if a firm planned to pay out all of its earnings in the form of dividends and things did not go as well as expected for the firm, it could end up having to cut its dividend.\n\nBalance sheet and risk-weighted asset assumptions\nBeyond requiring that large banks have the resiliency to weather a period of serious financial stress, an important macroprudential aim of stress testing is to ensure that they can provide credit to households and businesses that remain creditworthy even in such a period. If banks maintain their capital ratios under stress by reducing their balance sheets through asset sales, or reductions in new lending, this crucial intermediation function will be compromised across the economy. The result could be a credit crunch, likely resulting in a more severe or longer-lasting recession. In the first few years of CCAR, we used the banks' own projections where many banks planned on balance sheet declines as part of their strategy for remaining sufficiently capitalized.15 In the 2014 CCAR cycle, we replaced banks' projections with our own model, adding a requirement that banks would not restrict the supply of loans during the severely adverse scenario.\n\nTo date, the model has actually operated to project an increase in the balance sheets of the CCAR banks during the severely adverse scenario, with varying impacts on different portfolios. This assumption, and its somewhat complicated implementation, was designed to be fairly conservative, in a manner not dissimilar to the assumptions about capital distributions. Numerous banks have attempted to show why some of these portfolios or business lines would not be increasing under any reasonable assumptions, and thus that even macroprudential goals do not justify ignoring the likelihood that those portfolios would decline. During our review of CCAR, some banks proposed ways to distinguish among business lines so as to relax what they argued to be an unrealistic assumption, even one with a macroprudential purpose.\n\nThe complexities of trying to differentiate across idiosyncratic business lines seem to us considerable. We are instead considering replacing this feature of our model with a simple assumption that balance sheets and risk-weighted assets remain constant over the severely adverse scenario horizon. Given that some decline in demand by creditworthy borrowers for loans is inevitable in a serious recession, this simpler assumption would still achieve the macroprudential policy objective that any such decline in lending during a recession is attributable to the impact of the recession, rather than to capital constraints at the large banks. This change would also make the treatment of balance sheets and risk-weighted assets simpler and more transparent.\n\nToward a more macroprudential stress testing regime\nThe second major objective in our stress testing review was to integrate more macroprudential elements into the program. Of course, combining the GSIB surcharge with the SCB approach promotes an important macroprudential aim, since the surcharges are calibrated to force large, interconnected banks to internalize the additional costs their distress would impose on the financial system. The surcharges are thus at least a partial surrogate for inclusion of various macroprudential features in the stress test.\n\nWe are also considering a couple of relatively modest revisions we are considering to the Board's \"Policy Statement on the Scenario Design Framework for Stress Testing\"16 that are motivated by the macroprudential consideration of reducing procyclicality. The first would be to make the severity of the change in the unemployment rate less severe during downturns. The second would be to replace the current judgmental approach to setting the hypothesized path of house prices by tying this variable to disposable personal income. The result would be a more countercyclical path of house prices and increased transparency into how we determine the severity of this very important element of the scenario.\n\nBeyond these steps, we heard many ideas during our review on how we might pursue our macroprudential objective by adding new features to the stress test, especially from official sector representatives and academics. We also reviewed the growing academic literature on this topic. We concluded that, to this point, even the most conceptually promising of the ideas are a good ways from being realized in specific and well-supported elements of our economic models. Many macroprudential risks involve the spread of stress from one firm or market to others. As such, macroprudential elements of stress tests often must estimate not just first-round losses, but also the knock-on effects, which depend significantly on the vulnerabilities and responses of all other major actors in the financial system, including many that we do not regulate. Modelling these effects requires information about the behavior of those actors that may not be observable either to a firm or to us.\n\nNotwithstanding these and other practical challenges, many of the suggestions we received have focused on important potential risks that bear further inquiry by regulators. Hence we will be undertaking a research program to pursue these ideas in order to better understand the quantitative consequences of new risks and business activities, potential amplification channels such as fire sales by which stress could migrate from the large banks to the rest of the financial system, and important dynamics between capital and liquidity positions. At a minimum, this research should inform scenario design and the overall regulatory and financial stability functions of the Board. And at least some of the ideas might eventually be translated into features of the stress testing regime. Over the medium term we view three related areas as the highest priorities: funding shocks, liquidity shocks, and spillovers from the default of common counterparties.\n\nFunding shocks\nFunding stresses are a natural starting point. As banks incur losses and their capital base erodes, some of their creditors will demand additional compensation and bank funding costs will increase. This kind of \"direct\" funding shock is really microprudential because the resulting losses depend largely on the bank's own decisions about its capital base, asset risk, and reliance on short-term wholesale funding. As such, it should be more straightforward to integrate direct funding shocks into our main stress testing framework than to integrate systemwide effects, and we will consider whether, and how, to do so in the relatively near term.\n\nIn a \"systemic\" funding shock, by contrast, each bank's cost of funds depends on the capital position of the system as a whole. By taking the overall solvency of the system into account, this element captures a key amplification channel evident during the last financial crisis. As the banking system experienced capital losses, the cost of funding increased and some wholesale funding markets shut down even for relatively healthy banks. The potential for this kind of funding shock means that the presence of a poorly capitalized bank might increase funding costs for all banks--a classic kind of macroprudential concern.\n\nLiquidity shocks and fire sale dynamics\nAs we saw during the last financial crisis, repo and other funding markets can simply close to distressed institutions, which are then unable to access certain kinds of funds at any price. Such a firm may then be forced to make up the funding shortfall by turning to market sources of liquidity by selling assets--both high-quality liquid assets like Treasury securities and less liquid assets. During the financial crisis, distressed firms sold large amounts of securities as quickly as possible. The fire sale price discounts required for such rapid execution in turn imposed mark-to-market losses on other firms with similar holdings. To understand better this channel of financial contagion, we intend to continue our work on the ability of markets to handle large quantities of asset sales under stress, the capacity and willingness of firms to tap their buffers of high-quality assets, and the susceptibility of bank capital to mark-to-market losses from fire sales.\n\nMany commentators have drawn attention to these concerns, and some have advocated an integrated approach to capital and liquidity stress testing. We may or may not be able to achieve this end point. At a minimum, though, research in this area will allow us to move in this direction, perhaps by using the conclusions reached in the annual stress test as a starting point for our annual Comprehensive Liquidity Analysis and Review (CLAR), or vice versa. The results could also shed light on the current calibration of our liquidity rules.\n\nDefault of a common counterparty and the reaction of central counterparties\nCurrently, the annual stress test incorporates a counterparty default scenario component for the eight G-SIBs that measures direct credit loss. However, this component does not consider the potentially large second-round effects of the default of a major financial institution, including an increase in the probability of default of other counterparties as a result of the initial default and requirements for larger margins from derivatives counterparties. Of particular interest is the role of central counterparties (CCPs) in alleviating or transmitting stress from the default of one of their members. By regulatory design, CCPs have increased in prominence in the post-crisis environment because they can lead to greater efficiency and transparency in trading. But this increased role makes it important to understand the impact they may have in stressed conditions. For example, CCPs collect prefunded resources that can mitigate the impact of a default, but also can call on surviving clearing members for additional financial resources if those pre-funded resources are exhausted.\n\nPromoting transparency\nTransparency has played an important role in making stress testing such a key part of post-crisis prudential regulation. Transparency of the scenarios and results gives investors and analysts valuable information about the condition of the tested banks, thereby contributing to market discipline. It also allows the public to evaluate the job that the Federal Reserve is doing. For example, analysts can compare our loss estimates for specified portfolios under specified stress conditions with their own evaluations--an exercise that can inform both the analysts and us.\n\nThere are three areas in which transparency considerations need to be applied. First is the set of scenarios applied in the annual exercise. We release essentially all details of the scenarios and, further, have published a policy statement exploring the aims and factors relevant to development of the scenarios.18\n\nSecond is the set of results of the DFAST and CCAR exercises themselves. Right from the start--during the Supervisory Capital Assessment Program (SCAP) in 2009--we adopted what was then the controversial practice of publishing post-stress capital ratio results for each participating firm, along with a breakdown of the projected losses by loan type. Since then, we have substantially increased the breadth of the disclosed results, including a summary of the reasons for any qualitative objection or conditional non-objection to firms' capital plans. During the course of our review, suggestions were made for more granular disclosures, such as providing more details on different components of projected net revenues. We will make this change, and possibly a few others, over the course of the next cycle or two of stress testing.19\n\nThe third area for transparency involves the supervisory models used in the stress tests. Banks involved in DFAST/CCAR have regularly requested more disclosures so that they can better understand the likely impact on their firms. One argument has been that banks will have a difficult time in their capital planning if they cannot predict how loss functions and other model features will affect their stress losses. In part to remove the possibility that a bank would receive a quantitative objection to its capital plan because of a large gap between their loss estimates and those produced by the supervisory model, a few years ago we began allowing banks to revise their capital distribution requests following receipt of their DFAST results. Under the SCB approach, a bank could also adjust its planned capital distributions after receiving the stress test results to avoid having its baseline capital distribution projections fall into the buffer.\n\nWe have already taken a number of steps to respond to these requests. We currently publish descriptions of all models used in the stress test, including the key risk drivers and scenario variables for each key modeling area. We host an annual conference about modelling practices. We disclose a description of the most material changes to stress test models before each stress test. We are considering further steps, such as disclosing descriptions of changes well in advance of the stress test, and phasing in the most material model changes over two years, so as to smooth somewhat the effects of the changes on projected losses or revenues. Finally, and a bit more tentatively, we are assessing the feasibility of publishing data that represent typical bank portfolios of loans and securities with the losses we would project for those portfolios under various stress scenarios. This kind of information could also help the public trace how changes in risk drivers alter loss projections.\n\nHaving said all this, let me now say that we do not intend to publish the full computer code in the supervisory model that is used to project revenues and losses. Full disclosure would permit firms to game the system--that is, to optimize portfolio characteristics based on the parameters of the model and take risks in areas not well-captured by the stress test just to minimize the estimated stress losses. In part for this reason, full disclosure could promote a \"model monoculture\" in which both supervisors and firms use the same models to evaluate risks. A critical part of the DFAST/CCAR process is that firms use their own models to assess their risks. We do not want them simply to copy the supervisory model and thereby increase the vulnerability of the financial system to the inevitable blind spots in even the best models.\n\nIn short, this is not like using a model to develop a regulation that, for example, limits emissions of polluting substances. In such a case, adherence to the precise model output would itself achieve the regulatory purpose. Here, by contrast, the very purpose of the regulatory regime would be undermined. Remember, this is a stress test. The shifts in activities of banks and in the economy create a dynamic set of risks. Effective prudential regulation must be equally dynamic and should try to avoid pushing major financial firms toward measuring all of their risk positions in exactly the same way.\n\nThere is, however, one additional consideration. Because the stress tests would be undermined by giving the models to the banks, there are of course limited opportunities for external parties to assess the models. To promote the integrity of the models in these circumstances, we established a Model Validation Group, which is composed of modelling experts who are not involved in the design and application of the stress test models. They make regular assessments and offer suggestions for improvement. We expect to be providing the public greater information on our internal validation processes.\n\nEliminating the qualitative CCAR exercise for smaller firms\nAs you can already tell, our responses to the need for better alignment of the stress test with our capital rules and to the desirability of more macroprudential emphasis each required a good bit of explanation. In contrast, our response to the issue of the unnecessary burden on smaller, less complex CCAR firms is both simply stated and simply achieved.\n\nIn a notice of proposed rulemaking that the Board is releasing today we are proposing that banks with less than $250 billion in assets that do not have significant international or nonbank activity would no longer be included in the annual CCAR qualitative review. As noted earlier, many of these firms have already met supervisory expectations. We do not intend for less complex firms to invest in stress testing capabilities on par with the most complex firms and, given their profile, we feel these firms can maintain the progress they have made through the normal supervisory process, supplemented with targeted horizontal reviews of discrete aspects of capital planning.\n\nThis shift will reduce the intensity of supervision of their capital planning processes, remove any uncertainty as to supervisory expectations for their firms relative to the largest firms, and eliminate the possibility of a public objection to their capital plans on qualitative grounds. They would still be included in the quantitative side of the stress test and the proposed stress capital buffer. But we are also proposing to reduce the amount of data these firms are required to submit for the purpose of running the stress test, on what we call the Y-14 regulatory reports. Unlike the other substantial changes we are contemplating to CCAR and our stress test, we are proposing that these changes would be effective next year, for CCAR 2017.\n\nConclusion\nThis set of changes we are considering for our stress testing regime has been motivated by somewhat different considerations, against the backdrop of what we intend to remain a dynamic regulatory instrument whose procedures will be regularly refined and whose substance will be regularly adapted to changing economic conditions and industry practices. Still, in pulling this package of modifications together, we have consciously shaped them in accordance with the principle that financial regulation should be progressively more stringent for firms of greater importance, and thus potential risk, to the financial system. Two features of the package reflect this principle.\n\nFirst, of course, is the elimination of the qualitative portion of CCAR for nearly all the firms with less than $250 billion in assets, along with some record keeping and reporting requirements.\n\nThe second key feature is the differential impact the better alignment of CCAR with our capital regulations will have on the roughly 30 firms that are covered. Let me note at the outset that the precise effects on the capital requirements of individual firms cannot be determined because of the very nature of the stress test regime. The scenarios vary from year to year, and the resulting projected effects on losses and revenues may also vary materially depending on the composition of a firm's balance sheet and activities. However, to provide some idea of what the impact may be, we assessed how the various changes I have mentioned would have affected capital requirements in the two most recent CCAR cycles. On average for the eight GSIBs, integration of the surcharge with the post-stress requirements would have been somewhat less than half offset by the simplifying changes in the prefunding of capital distributions and balance sheet assumptions. The impact on capital requirements will likely be greater for firms with larger GSIB surcharges.\n\nFor the other CCAR firms, for which there are no capital surcharges, these simplifying assumptions will result in some reduction of post-stress capital requirements. We estimate that the aggregate impact of these changes for the CCAR firms as a whole should be a modest increase in the total amount of required capital. But this increase will be totally due to the impact on the eight GSIB firms, whose increased capital requirements will more than offset the reductions for the other firms.\n\nIn short, the GSIBs will see their capital requirements rise. All other CCAR firms will see some reduction in their capital requirements. And firms that have less than $250 billion in assets and do not have extensive international or nontraditional banking activities will also transition to a more tailored set of capital planning expectations outside the CCAR process.\n\n\n\n1. Dodd-Frank Act §165(i), 12 U.S.C. §5365(i). Return to text\n\n2. For a more complete description of the Federal Reserve's DFAST and CCAR programs, see www.federalreserve.gov/bankinforeg/stress-tests-capital-planning.htm. As a formal matter, DFAST was implemented beginning in 2013. However, in 2011 and 2012, the Federal Reserve conducted supervisory stress tests as part of its CCAR program, as explained later in the text. Return to text\n\n3. 12 CFR 225.8. Return to text\n\n4. The common equity capital ratio--which compares high-quality capital to risk-weighted assets--of the 33 bank holding companies in the 2016 CCAR has more than doubled from 5.5 percent in the first quarter of 2009 to 12.2 percent in the first quarter of 2016. This reflects an increase of more than $700 billion in common equity capital to a total of $1.2 trillion during the same period. www.federalreserve.gov/newsevents/press/bcreg/20160629a.htm. Return to text\n\n5. The 2016 CCAR cycle started one quarter later than past years' CCAR cycles. Return to text\n\n6. For example, our regulatory capital rules now include a minimum requirement based on common equity, reflecting the fact that common equity provides the best buffer against losses. As a result, the similar common equity requirement that had been included in the early years of CCAR, to meet an additional post-stress target ratio of tier 1 common equity, was removed after CCAR 2015. Other changes that have been integrated into the stress test include modification of the risk-weighted asset calculation methodologies and revised definitions of capital. Return to text\n\n7. Daniel K. Tarullo (2013), \"Macroprudential Regulation,\" speech delivered at the Yale Law School Conference on Challenges in Global Financial Services, New Haven, CT, September 20. Return to text\n\n8. See, for example, David Greenlaw, Anil Kashyap, Kermit Schoenholtz, and Hyun Song Shin (2012), \"Stressed Out: Macroprudential Principles for Stress Testing.\"  Chicago Booth Research Paper No. 12-08, Fama-Miller Working Paper (Chicago: University of Chicago Booth School of Business, February 13). Return to text\n\n9. The countercyclical buffer applies to banking organizations with more than $250 billion in assets or $10 billion in on-balance-sheet foreign exposures and to any depository institution subsidiary of such organizations. See 12 CFR Part 217, Appendix A. Return to text\n\n10. Figure 1 further illustrates the stress capital buffer. Return to text\n\n11. Board of Governors of the Federal Reserve System (2015), \"Calibrating the G-SIB Surcharge,\" white paper (Washington: Board of Governors of the Federal Reserve System, July 20). Return to text\n\n12. See Beverly Hirtle (2014), \"Bank Holding Company Dividends and Repurchases during the Financial Crisis (PDF),\"  Staff Report No. 666 (New York: Federal Reserve Bank of New York, March). Return to text\n\n13. Were a countercyclical capital buffer to be imposed, it would be added to the buffers above the 4.5 percent minimum capital requirement. Return to text\n\n14. During the financial crisis, firms began to curtail share repurchases beginning in 2007 but generally did not cut dividends until late 2008. See Hirtle (2014). Return to text\n\n15. The original stress test undertaken during the crisis did not allow this assumption, precisely because of our aim that the large banks as a group be well-positioned to meet the needs of creditworthy borrowers at that time of great stress. Return to text\n\n16. See 12 CFR part 252, appendix A. Return to text\n\n17. See 12 CFR Part 252, Appendix A. Return to text\n\n18. See 12 CFR 252, appendix A; Board of Governors of the Federal Reserve System (2013), \"Policy Statement on the Scenario Design Framework for Stress Testing (PDF),\" Final Rule; Policy Statement, November 29. Return to text\n\n19. Quite recently some banks have also suggested disclosing some version of the supervisory letters we send following the annual CCAR to each participating firm detailing our assessment of their capital planning processes. These banks believe that analysts and investors could benefit from knowing more detail on the concerns of the supervisors. We had already been considering how to increase the information provided around qualitative objections or conditional non-objections and will factor these latest observations into this decision. Return to text"
    },
    {
        "speaker": "Lael Brainard",
        "position": "Governor",
        "date": "September 12, 2016",
        "title": "The \"New Normal\" and What It Means for Monetary Policy",
        "href": "https://www.federalreserve.gov/newsevents/speech/brainard20160912a.htm",
        "content": "September 12, 2016\n\nGovernor Lael Brainard\n\nAt the Chicago Council on Global Affairs, Chicago, Illinois\n\nWatch live: https://www.thechicagocouncil.org/event/economic-outlook-and-monetary-policy-implications\n\nIn the months ahead, my colleagues and I will continue to assess what policy path will best promote the sustained attainment of our goals. With that in mind, I would like to start by describing the contours of today's economy that will be particularly important in shaping the appropriate path of policy before reviewing recent developments. These contours represent noteworthy departures from the \"old normal\" that prevailed in the decades prior to the financial crisis. I would argue that policy today must rely less on the old normal as a guidepost and instead be sensitive to the contours that shape today's \"new normal.\"1\n\nKey Features of the \"New Normal\"\nBecause monetary policy is forward looking, policymakers must assess how key features of the economic environment are most likely to influence the future path of the economy and shape policy accordingly. At a time when our assessment of the economy is evolving, several features of the \"new normal\"--some of which are interrelated--appear particularly noteworthy for our policy deliberations:\n\n1. Inflation Has Been Undershooting, and the Phillips Curve Has Flattened\nFirst, for the past several decades, policymakers relied on the empirical relationship between unemployment and inflation embodied in the Phillips curve as a key guidepost for monetary policy. The Phillips curve implied that as labor market slack diminished and the economy approached full employment, upward pressure on inflation would result. However, since 2012, inflation has tended to change relatively little--both absolutely and relative to earlier decades--as the unemployment rate has fallen considerably.2 At a time when the unemployment rate has fallen from 8.2 percent to 4.9 percent, inflation has undershot our 2 percent target now for 51 straight months.3 In other words, the Phillips curve appears to be flatter today than it was previously.\n\nWith the Phillips curve appearing to be a less reliable guidepost than it has been in the past, the anchoring role of inflation expectations remains critically important. On expected, similar to realized, inflation, recent developments suggest some reasons to be concerned more about undershooting than overshooting. Although some survey measures have remained well anchored at 2 percent, consumer surveys have moved to the lower end of their historical ranges and have not risen sustainably.4 Meanwhile, market‑based measures of inflation compensation have declined noticeably over the past two years at longer-term horizons, and have shown little improvement despite the recent stabilization in the price of oil and the exchange rate. Thus, we cannot rule out that the sustained period of undershooting the inflation target along with global disinflationary pressures are weighing on inflation expectations.\n\nRecognition of these developments is reflected in the evolution of the forecasts of Federal Open Market Committee (FOMC) participants in the Summary of Economic Projections (SEP) from June 2012 to June 2016. The SEP forecasts have shown repeated mark downs of the central tendency of the projection for core PCE (personal consumption expenditures) inflation, and the attainment of 2 percent at the upper end of the range has been pushed out repeatedly from 2012 initially to 2017 most recently.\n\nThe apparent flatness of the Phillips curve together with evidence that inflation expectations may have softened on the downside and the persistent undershooting of inflation relative to our target should be important considerations in our policy deliberations. In particular, to the extent that the effect on inflation of further gradual tightening in labor market conditions is likely to be moderate and gradual, the case to tighten policy preemptively is less compelling.\n\n2. Labor Market Slack Has Been Greater than Anticipated\nSecond, and related, although we have seen important progress on employment, this improvement has been accompanied by evidence of greater slack than previously anticipated. This uncertainty about the true state of the economy suggests we should be open to the possibility of material further progress in the labor market. Indeed, with payroll employment growth averaging 180,000 per month this year, many observers would have expected the unemployment rate to drop noticeably rather than moving sideways, as it has done. It is true that today's unemployment rate of 4.9 percent is only 0.1 percentage point from the median SEP participant's estimate of the longer-run level of unemployment. However, the natural rate of unemployment is uncertain and can vary over time. Indeed, in the SEP, the central tendency of the projection for the longer-run natural rate of unemployment has come down significantly, from a range of 5.2 to 6.0 percent in June 2012 to 4.7 to 5.0 percent in June 2016--a reduction of 1/2 to 1 percentage point.5 We cannot rule out that estimates of the natural unemployment rate may move even lower.\n\nIn addition, the unemployment rate is not the only gauge of labor market slack, and other measures have been suggesting there is some room to go. The share of employees working part time for economic reasons, for example, has remained noticeably above its pre-crisis level. Of particular significance, the prime-age labor force participation rate, despite improvement this year, remains about 1‑1/2 percentage points below its pre-crisis level, suggesting room for further gains. While it is possible that the current low level of prime-age participation reflects ongoing pre-crisis trends, we cannot rule out that it reflects a lagged and still incomplete response to a very slow recovery in job opportunities and wages.6\n\nThis possibility is reinforced by the continued muted recovery in wage growth. Although wage growth has picked up to about a 2-1/2 percent pace in recent quarters, this pace is only modestly above that which prevailed over much of the recovery and well below growth rates seen prior to the financial crisis.7\n\nMy main point here is that in the presence of uncertainty and the absence of accelerating inflationary pressures, it would be unwise for policy to foreclose on the possibility of making further gains in the labor market.\n\n3. Foreign Markets Matter, Especially because Financial Transmission is Strong\nThird, disinflation pressure and weak demand from abroad will likely weigh on the U.S. outlook for some time, and fragility in global markets could again pose risks here at home.8 In Europe, recovery continues, but growth is slow and inflation is very low. Low growth and a flat yield curve are contributing to reduced profitability and a higher cost of equity financing for banks, which in turn could impair bank lending, one of the main transmission channels of monetary policy in the euro area's bank-centric financial system. A low growth, low inflation environment also makes progress on fiscal sustainability difficult and leaves countries with high debt-to-gross domestic product (GDP) ratios vulnerable to adverse demand shocks. Against this backdrop, uncertainty about Britain's future relationship with the European Union could damp business sentiment and investment in Europe.\n\nJapan remains greatly challenged by weak growth and low inflation. Indeed, it is striking that despite active and creative monetary policies in both the euro area and Japan, inflation remains below target levels. The experiences of these economies highlight the risk of becoming trapped in a low-growth, low-inflation, low-inflation-expectations environment and suggest that policy should be oriented toward minimizing the risk of the U.S. economy slipping into such a situation.\n\nDownside risks are also present in emerging market economies, where growth has slowed rapidly in recent years.9 Most importantly, China is undergoing a challenging transition from a growth model based on investment, exports, and debt-fueled state-owned enterprises to one driven by consumption, services, and dynamic private businesses. Because of the adjustment costs along this transition path and demographic trends, Chinese growth will likely continue to slow. Given that China has experienced very high growth in corporate debt, this downshift could pose risks. Importantly, Chinese authorities have made some progress on clarifying their policy stance, and capital outflows have slowed in recent months. Nonetheless, considerable uncertainty remains, and further volatility cannot be ruled out. The importance of Chinese growth and stability to many emerging market economies and to global markets more broadly implies that these risks have global implications.\n\nHeadwinds from abroad should matter to U.S. policymakers because recent experience suggests global financial markets are tightly integrated, such that disturbances emanating from Chinese or euro-area financial markets quickly spill over to U.S. financial markets. The fallout from adverse foreign shocks appears to be more powerfully transmitted to the U.S. than previously. Indeed, recent research suggests that changes in expectations regarding the path of policy in the United States relative to other major economies lead to exchange rate movements that appear to be several times bigger than they were several years ago.10 The fact that many advanced economies are suffering from deficient demand and have policy rates at or near the zero bound and that the U.S. dollar is a favored safe-haven asset may imply that adverse foreign demand shocks have a particularly strong effect on the value of the dollar, effectively transmitting the weakness to the U.S. economy.11\n\nIn turn, U.S. activity and inflation appear to be importantly influenced by these exchange rate movements. In particular, estimates from the FRB/US model suggest that the nearly 20 percent appreciation of the dollar from June 2014 to January of this year could be having an effect on U.S. economic activity roughly equivalent to a 200 basis point increase in the federal funds rate. Interestingly, it appears that this effect showed through in decreased business investment activity and stagnant manufacturing output, while the anticipated effect on net exports may have been somewhat dampened by depressed demand for imports of capital goods, among other factors.\n\n4. The Neutral Rate Is Likely to Remain Very Low for Some Time\nFourth, perhaps most salient for monetary policy, it appears increasingly clear that the neutral rate of interest remains considerably and persistently lower than it was before the crisis. Over the current expansion, with a federal funds rate at, or near, zero and the additional support provided by asset purchases and reinvestment, GDP growth has averaged a very modest rate upward of 2 percent, and inflation has averaged only 1‑1/2 percent. Ten years ago, based on the underlying economic relationships that prevailed at the time, it would have seemed inconceivable that real activity and inflation would be so subdued given the stance of monetary policy. To reconcile these developments, it is difficult not to conclude that the current level of the federal funds rate is less accommodative today than it would have been 10 years ago. Put differently, the amount of aggregate demand associated with a given level of the interest rate is now much lower than before the crisis.\n\nIn the early stages of the recovery, most observers thought that the cyclical headwinds restraining demand and lowering the neutral rate would dissipate, and that the neutral rate would move gradually back to the pre-crisis norm of 2 percent. But seven years into the expansion and with little sign of a significant acceleration in activity, the low neutral rate looks likely to persist. Indeed, developments over the past year confirm that the underlying causes will be with us for some time.12 Foreign consumption and investment are weak, while foreign demand for savings is high, along with an elevated demand for safe assets. Productivity growth, which increased at an average annual rate of nearly 2-1/2 percent from 1950 to 2000, has increased only 1/2 percent on average over the past five years, and demographics also suggest a persistent slowing of the labor force.\n\nRecognition of the reduction in the long-run neutral federal funds rate is perhaps the most consequential change in the SEP forecasts. In the four years between June 2012 and June 2016, the estimate of the long-run federal funds rate has declined from 4.25 percent to 3.0 percent--nearly one-third. Over one-third of that adjustment has occurred between December 2015 and June 2016. It is notable that this recent step-down in the SEP estimate has coincided with a period of easing in financial conditions and a stabilization in the exchange rate as market participants have taken into account changes in the perceived FOMC policy reaction function.\n\nSeveral econometric models and estimates from market participants suggest the current real neutral rate is at or close to zero, and any increase is likely to be shallow and slow.13 These estimates imply that it may require a relatively more modest adjustment in the policy rate to return to neutral over time than previously anticipated.\n\n5. Policy Options Are Asymmetric\nThe four features just discussed that define the new normal make it likely that we will continue to grapple with a fifth new reality for some time: the ability of monetary policy to respond to shocks is asymmetric. With policy rates near the zero lower bound and likely to return there more frequently even if the economy only experiences shocks similar in magnitude to those experienced pre-crisis, due to the low level of the neutral rate, there is an asymmetry in the policy tools available to respond to adverse developments. Conventional changes in the federal funds rate, our most tested and best understood tool, cannot be used as readily to respond to downside shocks to aggregate demand as it can to upside shocks. While there are, of course, other policy options, these alternatives have constraints and uncertainties that are not present with conventional policy.14 From a risk-management perspective, therefore, the asymmetry in the conventional policy toolkit would lead me to expect policy to be tilted somewhat in favor of guarding against downside risks relative to preemptively raising rates to guard against upside risks.\n\nBecause a persistently low neutral rate implies less room for conventional monetary policy to adjust to adverse developments, it will be important to assess whether our current policy tools are adequate to respond to negative shocks and, if not, what adjustments would be most appropriate. There is a growing literature on such policy alternatives, such as raising the inflation target, moving to a nominal income target, or deploying negative interest rates.15 These options merit further assessment. However, they are largely untested and would take some time to assess and prepare. For the time being, the most effective way to address these concerns is to ensure that our policy actions align with our commitment to achieving the existing inflation target, which the Committee has recently clarified is symmetric around 2 percent--and not a ceiling--along with maximum employment.\n\nRecent Developments Suggest Gradual Progress\nAgainst the backdrop of these five features of the new normal that are most salient for conditioning policy, I will briefly summarize my take on recent economic developments and their implications for policy. The economy has seen welcome progress on some fronts in recent months, supported by the cautious approach taken by the Committee and a corresponding easing in financial conditions: The labor market has continued to improve, consumer confidence has remained high, and we have navigated past near-term risks from abroad.\n\nOverall, the recent data on the labor market and aggregate spending suggest that we are continuing to move toward full employment, but that progress has been, and likely will be, somewhat gradual. This year, monthly job gains have averaged 180,000, below last year's pace but still sufficient to reduce labor market slack. The slowing pace of job gains has been associated with a flattening out in the unemployment rate over the past year, along with a heartening 1/2 percentage point increase in the prime-age labor force participation rate. These developments suggest that an improving job market has made joining, or remaining in, the labor force increasingly attractive, and may imply that the labor market has room for further improvement.\n\nRecent spending data suggest a pickup in third-quarter growth. In particular, real consumer spending increased at nearly a 4 percent annual pace over the three months ending in July, driven by continued job growth, buoyant consumer sentiment, and rising household wealth. Nonetheless, spending in other sectors has been disappointing. Weak foreign growth and the net appreciation of the dollar over the past two years have weighed heavily on net exports, corporate profitability, business investment, and manufacturing production. Business investment has declined in each of the past three quarters, and the latest data on housing permits suggest that residential investment slowed noticeably in the middle of this year. As a result, economic activity over the past three quarters has been disappointing, with growth in GDP and gross domestic income each averaging less than 1 percent, a significant step-down from the same period in 2015.\n\nLooking ahead, the stabilization of the dollar and oil prices suggests that growth in these components should move higher over the second half of the year. Indeed, exports, which have declined since the end of 2014, moved slightly higher last quarter, and the number of oil drilling rigs in operation has begun to edge up after sharp declines over the past two years, a positive sign for business investment. In addition, inventory investment, which edged lower last quarter, should step up over the second half of the year to a level more in line with continued moderate increases in final sales.\n\nWe have also seen signs of progress on our inflation mandate. In July, the 12‑month change in core PCE prices was 1.6 percent, higher than a year ago, but still noticeably below our 2 percent target. The stabilization of the dollar and oil prices should lead inflation to move back toward our target in coming quarters. Non-oil import prices, which fell steadily from the end of 2014 through the first quarter of this year, edged up in the second quarter and, if the dollar remains steady, should continue to rise going forward. Continued progress in inflation will also depend on inflation expectations remaining well anchored and not drifting lower. The evidence here is mixed, as I noted earlier.\n\nPolicy Implications\nThe five features of the current economic landscape that I have highlighted lean roughly in the same direction: In today's new normal, the costs to the economy of greater-than-expected strength in demand are likely to be lower than the costs of significant unexpected weakness. In the case of unexpected strength, we have well-tried and tested tools and ample policy space in which to react. Moreover, because of Phillips curve flattening, the possibility of remaining labor market slack, the likely substantial response of the exchange rate and its depressing effect on inflation, the low neutral rate, and the fact that inflation expectations are well anchored to the upside, the response of inflation to unexpected strength in demand will likely be modest and gradual, requiring a correspondingly moderate policy response and implying relatively slight costs to the economy. In the face of an adverse shock, however, our conventional policy toolkit is more limited, and thus the risk of being unable to adequately respond to unexpected weakness is greater. The experience of the Japanese and euro-area economies suggest that prolonged weakness in demand is very difficult to correct, leading to economic costs that can be considerable.\n\nThis asymmetry in risk management in today's new normal counsels prudence in the removal of policy accommodation. I believe this approach has served us well in recent months, helping to support continued gains in employment and progress on inflation. I look forward to assessing the evolution of the data in the months ahead for signs of further progress toward our goals, bearing in mind these considerations.\n\nReferences\nAaronson, Stephanie, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014). \"Labor Force Participation: Recent Developments and Future Prospects (PDF),\" Brookings Papers on Economic Activity, Fall, pp. 197-275.\n\nBall, Laurence (2014). \"The Case for a Long-Run Inflation Target of Four Percent (PDF),\" IMF Working Paper WP/14/92. Washington: International Monetary Fund, June.\n\nBernanke, Ben S. (2015). \"Monetary Policy in the Future,\" speech delivered at the \"Rethinking Macro Policy III\" conference sponsored by the International Monetary Fund, Washington, April 15.\n\nBlanchard, Olivier (2016). \"The U.S. Phillips Curve: Back to the 60s? (PDF)\" Policy Brief 16‑1. Washington: Peterson Institute of International Economics, January.\n\nBlanchard, Olivier, Giovanni Dell'Ariccia, and Paolo Mauro (2010). \"Rethinking Macroeconomic Policy (PDF),\" IMF Staff Position Note 10/03. Washington: International Monetary Fund, February 12.\n\nBrainard, Lael (2015a). \"Economic Outlook and Monetary Policy,\" speech delivered at \"North America's Place in a Changing World Economy,\" 57th National Association for Business Economics Annual Meeting, Washington, October 12.\n\n--------- (2015b). \"Normalizing Monetary Policy When the Neutral Interest Rate Is Low,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford, Calif., December 1.\n\nCaballero, Ricardo J., Emmanuel Farhi, and Pierre-Olivier Gourinchas (2015). \"Global Imbalances and Currency Wars at the ZLB,\" NBER Working Paper Series 21670. Cambridge, Mass.: National Bureau of Economic Research, October.\n\nCouncil of Economic Advisers (2016). The Long-Term Decline in Prime-Age Male Labor Force Participation (PDF). Washington: Executive Office of the President of the United States, June.\n\nCurcuru, Stephanie (forthcoming). \"The Sensitivity of the USD Exchange Rate to Changes in Monetary Policy Expectations,\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System.\n\nCúrdia, Vasco (2015). \"Why So Slow? A Gradual Return for Interest Rates,\" Federal Reserve Bank of San Francisco, FRBSF Economic Letter 2015-32. San Francisco: FRBSF, October 12.\n\nDel Negro, Marco, Marc Giannoni, and Micah Smith (2016). \"The Macro Effects of the Recent Swing in Financial Conditions,\" Federal Reserve Bank of New York, Liberty Street Economics (blog), May 25.\n\nErceg, Christopher J., and Andrew T. Levin (2014). \"Labor Force Participation and Monetary Policy in the Wake of the Great Recession,\" Journal of Money, Credit and Banking, vol. 46 (S2, October), pp. 3-49.\n\nGoodfriend, Marvin (2016). \"The Case for Unencumbering Interest Rate Policy at the Zero Bound (PDF),\" speech delivered at \"Designing Resilient Monetary Policy Frameworks for the Future,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, Jackson Hole, Wyo., Aug. 26-27.\n\nHaldane, Andrew (2015). \"How Low Can You Go?\" speech delivered at the Portadown Chamber of Commerce, Northern Ireland, September 18.\n\nJohannsen, Benjamin K., and Elmar Mertens (2016). \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, February 9.\n\nKiley, Michael T. (2015a). \"What Can the Data Tell Us about the Equilibrium Real Interest Rate?\" Finance and Economics Discussion Series 2015-077. Washington: Board of Governors of the Federal Reserve System, August.\n\n--------- (2015b). \"Low Inflation in the United States: A Summary of Recent Research,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, November 23.\n\nLaubach, Thomas, and John C. Williams (2015). \"Measuring the Natural Rate of Interest Redux (PDF),\" Working Paper Series 2015-16. San Francisco: Federal Reserve Bank of San Francisco, October.\n\nLubik, Thomas A., and Christian Matthes (2015). \"Calculating the Natural Rate of Interest: A Comparison of Two Alternative Approaches (PDF),\" Economic Brief 15-10. Richmond, Va.: Federal Reserve Bank of Richmond, October.\n\nReifschneider, David (2016). \"Gauging the Ability of the FOMC to Respond to Future Recessions (PDF),\" Finance and Economics Discussion Series 2016-068. Washington: Board of Governors of the Federal Reserve System.\n\nRomer, Christina D. (2011). \"Dear Ben: It's Time for Your Volcker Moment,\" New York Times, October 29, www.nytimes.com/2011/10/30/business/economy/ben-bernanke-needs-a-volcker-moment.html?_r=0.\n\nI am grateful to Andrew Figura for his assistance in preparing this text.\n\n1. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See Blanchard (2016), Kiley (2015b), and Brainard (2015a), Return to text\n\n3. The inflation information refers to core PCE (personal consumption expenditures) inflation measured on a 12-month average basis. Return to text\n\n4. For example, over the past 12 months, median 5-to-10 year-ahead inflation expectations from the University of Michigan Surveys of Consumers were 1/4 percentage point below the average over the prior 10 years. Return to text\n\n5. For information from current and previous SEPs, see https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm. Return to text\n\n6. For analyses of the determinants of labor force participation, see Aaronson and others (2014), Erceg and Levin (2014), and Council of Economic Advisers (2016). Return to text\n\n7. Over the 12 months ending in August 2016, average hourly earnings increased 2.4 percent. Over the 12 months ending in June, the employment cost index for private-sector workers also increased 2.4 percent. The more volatile compensation per hour measure for the business sector has increased at an annual rate of 2.6 percent over the past eight quarters. From the fourth quarter of 2009 to the fourth quarter of 2014, these measures all increased at an average annual rate of around 2 percent. From the fourth quarter of 2003 to the fourth quarter of 2007, the compensation per hour and employment cost index measures increased at an average annual rate of around 3-1/2 percent. Average hourly earnings for all workers were not available for this period. Return to text\n\n8. The International Monetary Fund (IMF) has repeatedly marked down its forecast of world economic growth in recent years. From April 2014 to July of this year, for example, the IMF revised down 2015 growth from 3.9 percent to 3.1 percent. And from April 2015 to July of this year, the IMF revised down 2016 growth from 3.8 percent to 3.1 percent. See the IMF's World Economic Outlook at http://www.imf.org/external/ns/cs.aspx?id=29 . Return to text\n\n9. Emerging market growth, as weighted by a country's share of U.S. exports, has decreased from an average pace of 5-1/4 percent from the fourth quarter of 2009 to the fourth quarter of 2012 to a little over 2 percent last year. Return to text\n\n10. See Curcuru (forthcoming). The confidence intervals around the estimated effects are quite large. Return to text\n\n11. See Caballero, Farhi, and Gourinchas (2015). Return to text\n\n12. For a fuller description of the likely contributors to a persistent low neutral rate, see Brainard (2015b) and Goodfriend (2016). Return to text\n\n13. See, for example, Laubach and Williams (2015); Del Negro, Giannoni, and Smith (2016); Cúrdia (2015); Lubik and Matthes (2015); Kiley (2015a); and Johannsen and Mertens (2016) for econometric estimates of the neutral rate, or the closely related concept of the natural rate of interest. See the Federal Reserve Bank of New York's most recent Survey of Market Participants and Survey of Primary Dealers for forecasters' estimates of the current neutral rate. Return to text\n\n14. See Reifschneider (2016). Return to text\n\n15. See Romer (2011), Blanchard, Dell'Ariccia and Mauro (2010), Ball (2014), Haldane (2015), Bernanke (2015), and Goodfriend (2016). Return to text"
    },
    {
        "speaker": "Janet L. Yellen",
        "position": "Chair",
        "date": "August 26, 2016",
        "title": "The Federal Reserve's Monetary Policy Toolkit: Past, Present, and Future",
        "href": "https://www.federalreserve.gov/newsevents/speech/yellen20160826a.htm",
        "content": "August 26, 2016\n\nChair Janet L. Yellen\n\nAt \"Designing Resilient Monetary Policy Frameworks for the Future,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, Jackson Hole, Wyoming\n\nThe Global Financial Crisis and Great Recession posed daunting new challenges for central banks around the world and spurred innovations in the design, implementation, and communication of monetary policy. With the U.S. economy now nearing the Federal Reserve's statutory goals of maximum employment and price stability, this conference provides a timely opportunity to consider how the lessons we learned are likely to influence the conduct of monetary policy in the future.\n\nThe theme of the conference, \"Designing Resilient Monetary Policy Frameworks for the Future,\" encompasses many aspects of monetary policy, from the nitty-gritty details of implementing policy in financial markets to broader questions about how policy affects the economy. Within the operational realm, key choices include the selection of policy instruments, the specific markets in which the central bank participates, and the size and structure of the central bank's balance sheet. These topics are of great importance to the Federal Reserve. As noted in the minutes of last month's Federal Open Market Committee (FOMC) meeting, we are studying many issues related to policy implementation, research which ultimately will inform the FOMC's views on how to most effectively conduct monetary policy in the years ahead. I expect that the work discussed at this conference will make valuable contributions to the understanding of many of these important issues.\n\nMy focus today will be the policy tools that are needed to ensure that we have a resilient monetary policy framework. In particular, I will focus on whether our existing tools are adequate to respond to future economic downturns. As I will argue, one lesson from the crisis is that our pre-crisis toolkit was inadequate to address the range of economic circumstances that we faced. Looking ahead, we will likely need to retain many of the monetary policy tools that were developed to promote recovery from the crisis. In addition, policymakers inside and outside the Fed may wish at some point to consider additional options to secure a strong and resilient economy. But before I turn to these longer-run issues, I would like to offer a few remarks on the near-term outlook for the U.S. economy and the potential implications for monetary policy.\n\nCurrent Economic Situation and Outlook\nU.S. economic activity continues to expand, led by solid growth in household spending. But business investment remains soft and subdued foreign demand and the appreciation of the dollar since mid-2014 continue to restrain exports. While economic growth has not been rapid, it has been sufficient to generate further improvement in the labor market. Smoothing through the monthly ups and downs, job gains averaged 190,000 per month over the past three months. Although the unemployment rate has remained fairly steady this year, near 5 percent, broader measures of labor utilization have improved. Inflation has continued to run below the FOMC's objective of 2 percent, reflecting in part the transitory effects of earlier declines in energy and import prices.\n\nLooking ahead, the FOMC expects moderate growth in real gross domestic product (GDP), additional strengthening in the labor market, and inflation rising to 2 percent over the next few years. Based on this economic outlook, the FOMC continues to anticipate that gradual increases in the federal funds rate will be appropriate over time to achieve and sustain employment and inflation near our statutory objectives. Indeed, in light of the continued solid performance of the labor market and our outlook for economic activity and inflation, I believe the case for an increase in the federal funds rate has strengthened in recent months. Of course, our decisions always depend on the degree to which incoming data continues to confirm the Committee's outlook.\n\nAnd, as ever, the economic outlook is uncertain, and so monetary policy is not on a preset course. Our ability to predict how the federal funds rate will evolve over time is quite limited because monetary policy will need to respond to whatever disturbances may buffet the economy. In addition, the level of short-term interest rates consistent with the dual mandate varies over time in response to shifts in underlying economic conditions that are often evident only in hindsight. For these reasons, the range of reasonably likely outcomes for the federal funds rate is quite wide--a point illustrated by figure 1 in your handout. The line in the center is the median path for the federal funds rate based on the FOMC's Summary of Economic Projections in June.1 The shaded region, which is based on the historical accuracy of private and government forecasters, shows a 70 percent probability that the federal funds rate will be between 0 and 3-1/4 percent at the end of next year and between 0 and 4-1/2 percent at the end of 2018.2 The reason for the wide range is that the economy is frequently buffeted by shocks and thus rarely evolves as predicted. When shocks occur and the economic outlook changes, monetary policy needs to adjust. What we do know, however, is that we want a policy toolkit that will allow us to respond to a wide range of possible conditions.\n\nThe Pre-Crisis Toolkit\nPrior to the financial crisis, the Federal Reserve's monetary policy toolkit was simple but effective in the circumstances that then prevailed. Our main tool consisted of open market operations to manage the amount of reserve balances available to the banking sector.3 These operations, in turn, influenced the interest rate in the federal funds market, where banks experiencing reserve shortfalls could borrow from banks with excess reserves. Before the onset of the crisis, the volume of reserves was generally small--only about $45 billion or so.4 Thus, even small open market operations could have a significant effect on the federal funds rate. Changes in the federal funds rate would then be transmitted to other short-term interest rates, affecting longer-term interest rates and overall financial conditions and hence inflation and economic activity. This simple, light-touch system allowed the Federal Reserve to operate with a relatively small balance sheet--less than $1 trillion before the crisis--the size of which was largely determined by the need to supply enough U.S. currency to meet demand.5\n\nThe global financial crisis revealed two main shortcomings of this simple toolkit. The first was an inability to control the federal funds rate once reserves were no longer relatively scarce. Starting in late 2007, faced with acute financial market distress, the Federal Reserve created programs to keep credit flowing to households and businesses.6 The loans extended under those programs helped stabilize the financial system. But the additional reserves created by these programs, if left unchecked, would have pushed down the federal funds rate, driving it well below the FOMC's target. To prevent such an outcome, the Federal Reserve took several steps to offset (or sterilize) the effect of its liquidity and credit operations on reserves.7 By the fall of 2008, however, the reserve effects of our liquidity and credit programs threatened to become too large to sterilize via asset sales and other existing tools. Without sufficient sterilization capacity, the quantity of reserves increased to a point that the Federal Reserve had difficulty maintaining effective control over the federal funds rate.\n\nOf course, by the end of 2008, stabilizing the federal funds rate at a level materially above zero was not an immediate concern because the economy clearly needed very low short-term interest rates. Faced with a steep rise in unemployment and declining inflation, the FOMC lowered its target for the federal funds rate to near zero, a reduction of roughly 5 percentage points over the previous year and a half. Nonetheless, a variety of policy benchmarks would, at least in hindsight, have called for pushing the federal funds rate well below zero during the economic downturn.8 That doing so was impossible highlights the second serious limitation of our pre-crisis policy toolkit: its inability to generate substantially more accommodation than could be provided by a near-zero federal funds rate.\n\nOur Expanded Toolkit\nTo address the challenges posed by the financial crisis and the subsequent severe recession and slow recovery, the Federal Reserve significantly expanded its monetary policy toolkit. In 2006, the Congress had approved plans to allow the Fed, beginning in 2011, to pay interest on banks' reserve balances.9 In the fall of 2008, the Congress moved up the effective date of this authority to October 2008. That authority was essential. Paying interest on reserve balances enables the Fed to break the strong link between the quantity of reserves and the level of the federal funds rate and, in turn, allows the Federal Reserve to control short-term interest rates when reserves are plentiful. In particular, once economic conditions warrant a higher level for market interest rates, the Federal Reserve could raise the interest rate paid on excess reserves--the IOER rate. A higher IOER rate encourages banks to raise the interest rates they charge, putting upward pressure on market interest rates regardless of the level of reserves in the banking sector.\n\nWhile adjusting the IOER rate is an effective way to move market interest rates when reserves are plentiful, federal funds have generally traded below this rate. This relative softness of the federal funds rate reflects, in part, the fact that only depository institutions can earn the IOER rate. To put a more effective floor under short-term interest rates, the Federal Reserve created supplementary tools to be used as needed. For instance, the overnight reverse repurchase agreement (ON RRP) facility is available to a variety of counterparties, including eligible money market funds, government-sponsored enterprises, broker-dealers, and depository institutions. Through it, eligible counterparties may invest funds overnight with the Federal Reserve at a rate determined by the FOMC. Similar to the payment of IOER, the ON RRP facility discourages participating institutions from lending at a rate substantially below that offered by the Fed.10\n\nOur current toolkit proved effective last December. In an environment of superabundant reserves, the FOMC raised the effective federal funds rate--that is, the weighted average rate on federal funds transactions among participants in that market--by the desired amount, and we have since maintained the federal funds rate in its target range.\n\nTwo other major additions to the Fed's toolkit were large-scale asset purchases and increasingly explicit forward guidance.11 Both were used to provide additional monetary policy accommodation after short-term interest rates fell close to zero. Our purchases of Treasury and mortgage-related securities in the open market pushed down longer-term borrowing rates for millions of American families and businesses. Extended forward rate guidance--announcing that we intended to keep short-term interest rates lower for longer than might have otherwise been expected--also put significant downward pressure on longer-term borrowing rates, as did guidance regarding the size and scope of our asset purchases.\n\nIn light of the slowness of the economic recovery, some have questioned the effectiveness of asset purchases and extended forward rate guidance. But this criticism fails to consider the unusual headwinds the economy faced after the crisis. Those headwinds included substantial household and business deleveraging, unfavorable demand shocks from abroad, a period of contractionary fiscal policy, and unusually tight credit, especially for housing. Studies have found that our asset purchases and extended forward rate guidance put appreciable downward pressure on long-term interest rates and, as a result, helped spur growth in demand for goods and services, lower the unemployment rate, and prevent inflation from falling further below our 2 percent objective.12\n\nTwo of the Fed's most important new tools--our authority to pay interest on excess reserves and our asset purchases--interacted importantly. Without IOER authority, the Federal Reserve would have been reluctant to buy as many assets as it did because of the longer-run implications for controlling the stance of monetary policy. While we were buying assets aggressively to help bring the U.S. economy out of a severe recession, we also had to keep in mind whether and how we would be able to remove monetary policy accommodation when appropriate. That issue was particularly relevant because we fund our asset purchases through the creation of reserves, and those additional reserves would have made it ever more difficult for the pre-crisis toolkit to raise short-term interest rates when needed.\n\nThe FOMC considered removing accommodation by first reducing our asset holdings (including through asset sales) and raising the federal funds rate only after our balance sheet had contracted substantially. But we decided against this approach because our ability to predict the effects of changes in the balance sheet on the economy is less than that associated with changes in the federal funds rate. Excessive inflationary pressures could arise if assets were sold too slowly. Conversely, financial markets and the economy could potentially be destabilized if assets were sold too aggressively. Indeed, the so-called taper tantrum of 2013 illustrates the difficulty of predicting financial market reactions to announcements about the balance sheet. Given the uncertainty and potential costs associated with large-scale asset sales, the FOMC instead decided to begin removing monetary policy accommodation primarily by adjusting short-term interest rates rather than by actively managing its asset holdings.13 That strategy--raising short-term interest rates once the recovery was sufficiently advanced while maintaining a relatively large balance sheet and plentiful bank reserves--depended on our ability to pay interest on excess reserves.\n\nWhere Do We Go from Here?\nWhat does the future hold for the Fed's toolkit? For starters, our ability to use interest on reserves is likely to play a key role for years to come. In part, this reflects the outlook for our balance sheet over the next few years. As the FOMC has noted in its recent statements, at some point after the process of raising the federal funds rate is well under way, we will cease or phase out reinvesting repayments of principal from our securities holdings. Once we stop reinvestment, it should take several years for our asset holdings--and the bank reserves used to finance them--to passively decline to a more normal level. But even after the volume of reserves falls substantially, IOER will still be important as a contingency tool, because we may need to purchase assets during future recessions to supplement conventional interest rate reductions.14 Forecasts now show the federal funds rate settling at about 3 percent in the longer run.15 In contrast, the federal funds rate averaged more than 7 percent between 1965 and 2000. Thus, we expect to have less scope for interest rate cuts than we have had historically.\n\nIn part, current expectations for a low future federal funds rate reflect the FOMC's success in stabilizing inflation at around 2 percent--a rate much lower than rates that prevailed during the 1970s and 1980s. Another key factor is the marked decline over the past decade, both here and abroad, in the long-run neutral real rate of interest--that is, the inflation-adjusted short-term interest rate consistent with keeping output at its potential on average over time.16 Several developments could have contributed to this apparent decline, including slower growth in the working-age populations of many countries, smaller productivity gains in the advanced economies, a decreased propensity to spend in the wake of the financial crises around the world since the late 1990s, and perhaps a paucity of attractive capital projects worldwide.17 Although these factors may help explain why bond yields have fallen to such low levels here and abroad, our understanding of the forces driving long-run trends in interest rates is nevertheless limited, and thus all predictions in this area are highly uncertain.18\n\nWould an average federal funds rate of about 3 percent impair the Fed's ability to fight recessions? Based on the FOMC's behavior in past recessions, one might think that such a low interest rate could substantially impair policy effectiveness. As shown in the first column of the table in the handout, during the past nine recessions, the FOMC cut the federal funds rate by amounts ranging from about 3 percentage points to more than 10 percentage points. On average, the FOMC reduced rates by about 5-1/2 percentage points, which seems to suggest that the FOMC would face a shortfall of about 2-1/2 percentage points for dealing with an average-sized recession. But this simple comparison exaggerates the limitations on policy created by the zero lower bound. As shown in the second column, the federal funds rate at the start of the past seven recessions was appreciably above the level consistent with the economy operating at potential in the longer run. In most cases, this tighter-than-normal stance of policy before the recession appears to have reflected some combination of initially higher-than-normal labor utilization and elevated inflation pressures. As a result, a large portion of the rate cuts that subsequently occurred during these recessions represented the undoing of the earlier tight stance of monetary policy. Of course, this situation could occur again in the future. But if it did, the federal funds rate at the onset of the recession would be well above its normal level, and the FOMC would be able to cut short-term interest rates by substantially more than 3 percentage points.\n\nA recent paper takes a different approach to assessing the FOMC's ability to respond to future recessions by using simulations of the FRB/US model.19 This analysis begins by asking how the economy would respond to a set of highly adverse shocks if policymakers followed a fairly aggressive policy rule, hypothetically assuming that they can cut the federal funds rate without limit.20 It then imposes the zero lower bound and asks whether some combination of forward guidance and asset purchases would be sufficient to generate economic conditions at least as good as those that occur under the hypothetical unconstrained policy. In general, the study concludes that, even if the average level of the federal funds rate in the future is only 3 percent, these new tools should be sufficient unless the recession were to be unusually severe and persistent.\n\nFigure 2 in your handout illustrates this point. It shows simulated paths for interest rates, the unemployment rate, and inflation under three different monetary policy responses--the aggressive rule in the absence of the zero lower bound constraint, the constrained aggressive rule, and the constrained aggressive rule combined with $2 trillion in asset purchases and guidance that the federal funds rate will depart from the rule by staying lower for longer.21 As the red dashed line shows, the federal funds rate would fall far below zero if policy were unconstrained, thereby causing long-term interest rates to fall sharply.i But despite the lower bound, asset purchases and forward guidance can push long-term interest rates even lower on average than in the unconstrained case (especially when adjusted for inflation) by reducing term premiums and increasing the downward pressure on the expected average value of future short-term interest rates. Thus, the use of such tools could result in even better outcomes for unemployment and inflation on average.\n\nOf course, this analysis could be too optimistic. For one, the FRB/US simulations may overstate the effectiveness of forward guidance and asset purchases, particularly in an environment where long-term interest rates are also likely to be unusually low.22 In addition, policymakers could have less ability to cut short-term interest rates in the future than the simulations assume. By some calculations, the real neutral rate is currently close to zero, and it could remain at this low level if we were to continue to see slow productivity growth and high global saving.23 If so, then the average level of the nominal federal funds rate down the road might turn out to be only 2 percent, implying that asset purchases and forward guidance might have to be pushed to extremes to compensate.24 Moreover, relying too heavily on these nontraditional tools could have unintended consequences. For example, if future policymakers responded to a severe recession by announcing their intention to keep the federal funds rate near zero for a very long time after the economy had substantially recovered and followed through on that guidance, then they might inadvertently encourage excessive risk-taking and so undermine financial stability.\n\nFinally, the simulation analysis certainly overstates the FOMC's current ability to respond to a recession, given that there is little scope to cut the federal funds rate at the moment. But that does not mean that the Federal Reserve would be unable to provide appreciable accommodation should the ongoing expansion falter in the near term. In addition to taking the federal funds rate back down to nearly zero, the FOMC could resume asset purchases and announce its intention to keep the federal funds rate at this level until conditions had improved markedly--although with long-term interest rates already quite low, the net stimulus that would result might be somewhat reduced.\n\nDespite these caveats, I expect that forward guidance and asset purchases will remain important components of the Fed's policy toolkit. In addition, it is critical that the Federal Reserve and other supervisory agencies continue to do all they can to ensure a strong and resilient financial system. That said, these tools are not a panacea, and future policymakers could find that they are not adequate to deal with deep and prolonged economic downturns. For these reasons, policymakers and society more broadly may want to explore additional options for helping to foster a strong economy.\n\nOn the monetary policy side, future policymakers might choose to consider some additional tools that have been employed by other central banks, though adding them to our toolkit would require a very careful weighing of costs and benefits and, in some cases, could require legislation. For example, future policymakers may wish to explore the possibility of purchasing a broader range of assets. Beyond that, some observers have suggested raising the FOMC's 2 percent inflation objective or implementing policy through alternative monetary policy frameworks, such as price-level or nominal GDP targeting. I should stress, however, that the FOMC is not actively considering these additional tools and policy frameworks, although they are important subjects for research.\n\nBeyond monetary policy, fiscal policy has traditionally played an important role in dealing with severe economic downturns. A wide range of possible fiscal policy tools and approaches could enhance the cyclical stability of the economy.25 For example, steps could be taken to increase the effectiveness of the automatic stabilizers, and some economists have proposed that greater fiscal support could be usefully provided to state and local governments during recessions. As always, it would be important to ensure that any fiscal policy changes did not compromise long-run fiscal sustainability.\n\nFinally, and most ambitiously, as a society we should explore ways to raise productivity growth. Stronger productivity growth would tend to raise the average level of interest rates and therefore would provide the Federal Reserve with greater scope to ease monetary policy in the event of a recession. But more importantly, stronger productivity growth would enhance Americans' living standards. Though outside the narrow field of monetary policy, many possibilities in this arena are worth considering, including improving our educational system and investing more in worker training; promoting capital investment and research spending, both private and public; and looking for ways to reduce regulatory burdens while protecting important economic, financial, and social goals.\n\nConclusion\nAlthough fiscal policies and structural reforms can play an important role in strengthening the U.S. economy, my primary message today is that I expect monetary policy will continue to play a vital part in promoting a stable and healthy economy. New policy tools, which helped the Federal Reserve respond to the financial crisis and Great Recession, are likely to remain useful in dealing with future downturns. Additional tools may be needed and will be the subject of research and debate. But even if average interest rates remain lower than in the past, I believe that monetary policy will, under most conditions, be able to respond effectively.\n\n\n\n1. The June 2016 Summary of Economic Projections (SEP) is an addendum to the minutes of the June 2016 FOMC meeting and is available on the Board's website at www.federalreserve.gov/monetarypolicy/files/fomcminutes20160615.pdf. Return to text\n\n2. The confidence interval equals (subject to a lower bound of 12.5 basis points) the median SEP path for the federal funds rate plus or minus average root mean squared prediction errors (RMSPEs) of the three-month Treasury bill rate, for horizons from zero to nine quarters ahead, based on forecast errors made over the past 20 years. Average RMSPEs are calculated as the mean of the RMSPEs of the following forecasters, subject to availability for the horizon in question: the Federal Reserve Board staff (Greenbook/Tealbook), the Administration, the Congressional Budget Office, the Blue Chip consensus forecast, and the Survey of Professional Forecasters. Differences in predictive accuracy among these forecasters are not statistically significant. For more information on the general methodology used to construct confidence intervals using historical forecasting errors, see David Reifschneider and Peter Tulip (2007), \"Gauging the Uncertainty of the Economic Outlook from Historical Forecasting Errors (PDF),\" Finance and Economics Discussion Series 2007-60 (Washington: Board of Governors of the Federal Reserve System, November). Return to text\n\n3. Open market operations at the time were primarily repurchase agreements based on Treasury securities, with primary dealers as counterparties. Return to text\n\n4. Reserves of depository institutions include vault cash and balances maintained with Federal Reserve Banks. Excess reserves are the reserves held over and above required reserves. See the Board's webpage \"Reserve Requirements\" at www.federalreserve.gov/monetarypolicy/reservereq.htm. Return to text\n\n5. Prior to the financial crisis, the size of the Fed's balance sheet was about $900 billion. Assets consisted almost entirely of Treasury securities. Liabilities included currency held by the public and a relatively small volume of reserve balances. For more on the Fed's balance sheet, see www.federalreserve.gov/monetarypolicy/bst_fedsbalancesheet.htm. Return to text\n\n6. For information on the Federal Reserve's credit and liquidity programs that were implemented in response to the financial crisis, see www.federalreserve.gov/monetarypolicy/bst_crisisresponse.htm on the Board's website. Return to text\n\n7. Reserves were initially taken out of the banking system by not reinvesting principal payments from maturing securities and later by selling portions of securities holdings. In September 2008, the Department of the Treasury announced the temporary Supplementary Financing Program, in which the proceeds of a series of Treasury bill auctions, separate from Treasury's routine borrowing, were maintained in an account at the Federal Reserve Bank of New York. The funds in this account served to drain reserves from the banking system. Return to text\n\n8. Consider the following policy rule: R(t) = R* + p(t) + 0.5[p(t)-p*]-2.0[U(t)-U*], where R is the federal funds rate, R* is the longer-run normal value of the federal funds rate adjusted for inflation, π is the four-quarter moving average of core PCE inflation, π* is the FOMC's target for inflation (2 percent), U is the unemployment rate, and U* is the longer-run normal rate of unemployment. Based on the medians of FOMC participants' latest longer-run projections, R* is approximately 1 percent and U* is about 4.8 percent. Accordingly, with the unemployment rate climbing to 10 percent and core PCE inflation falling to 1 percent in 2009, this rule would have prescribed lowering the federal funds rate to minus 9 percent at the depths of the recession. In contrast, the standard Taylor rule, which is half as responsive to movements in resource utilization, would have prescribed lowering the federal funds rate to minus 3-3/4 percent using the same estimates for R* and U*. The more aggressive rule does a reasonably good job of accounting for movements in the federal funds rate in the decade prior to its falling to its effective lower bound in late 2008, see David Reifschneider (2016), \"Gauging the Ability of the FOMC to Respond to Future Recessions (PDF),\" Finance and Economics Discussion Series 2016-068 (Washington: Board of Governors of the Federal Reserve System, August). For more information on the standard Taylor rule, see John B. Taylor (1993), \"Discretion versus Policy Rules in Practice,\" Carnegie-Rochester Conference Series on Public Policy, vol. 39 (December), pp. 195-214. Return to text\n\n9. Paying interest on reserves is a tool commonly used by central banks, including the Bank of England, the Bank of Japan, and the European Central Bank. Return to text\n\n10. Other tools that could help strengthen the floor under short-term interest rates but are not currently in use include the Term Deposit Facility and term reverse repurchase agreements. Return to text\n\n11. Prior to the crisis, the Fed occasionally used forward guidance pertaining to the likely future path of interest rates, but that guidance was usually confined to a relatively short time frame. Return to text\n\n12. See, for instance, Joseph Gagnon, Matthew Raskin, Julie Remache, and Brian Sack (2011), \"The Financial Market Effects of the Federal Reserve's Large-Scale Asset Purchases,\"  International Journal of Central Banking, vol. 7 (March), pp. 3-43; and Stefania D'Amico, William English, David López-Salido, and Edward Nelson (2012), \"The Federal Reserve's Large-Scale Asset Purchase Programmes: Rationale and Effects,\" Economic Journal, vol. 122 (November), pp. F415-46. Moreover, the Federal Reserve's forward guidance and asset purchase policies have been estimated to have helped lower unemployment and boost inflation; see Eric M. Engen, Thomas Laubach, and David Reifschneider (2015), \"The Macroeconomic Effects of the Federal Reserve's Unconventional Monetary Policies,\" Finance and Economics Discussion Series 2015-005 (Washington: Board of Governors of the Federal Reserve System, January). Return to text\n\n13. The FOMC's \"Policy Normalization Principles and Plans\" call for reducing the Federal Reserve's securities holdings in a \"gradual and predictable manner primarily by ceasing to reinvest repayments of principal on securities held in the [System Open Market Account]\" (Board of Governors of the Federal Reserve System (2014), \"Federal Reserve Issues FOMC Statement on Policy Normalization Principles and Plans,\" press release, September 17, second bullet). Consistent with those plans, the Federal Open Market Committee anticipates that it will maintain its current reinvestment strategy \"until normalization of the level of the federal funds rate is well under way\" (for instance, see Board of Governors of the Federal Reserve System (2015), \"Federal Reserve Issues FOMC Statement,\" press release, December 16, paragraph 5. Return to text\n\n14. If the FOMC were to again increase the size of the balance sheet markedly in response to a future recession, then the ability to pay interest on reserves could be critical during the subsequent recovery period to help control short-term interest rates while the balance sheet remains elevated. Beyond this motivation for retaining IOER, the ability to pay interest on reserves could also be important to the operation of any special liquidity and credit facilities that might be created to deal with systemic disruptions to the financial system during a future emergency. In particular, such facilities could significantly expand the supply of reserves, which would be problematic if the FOMC wished to keep short-term interest rates from falling to zero. Return to text\n\n15. In the Blue Chip Financial Indicators survey released on June 1, 2016, the consensus forecast for the longer-run level of the federal funds rate was 3.2 percent. FOMC participants in June 2016 generally anticipated a slightly lower longer-run level, in that the median of their individual forecasts was 3 percent (see table 1 of the June 2016 SEP, available at www.federalreserve.gov/monetarypolicy/fomcminutes20160615ep.htm). The latest long-run forecast from the Administration (www.whitehouse.gov/sites/default/files/omb/budget/fy2016/assets/16msr.pdf) is also close to 3 percent, as was the projection made by the Congressional Budget Office earlier in the year (see www.cbo.gov/about/products/budget_economic_data). Return to text\n\n16. Updated estimates from the model developed by Laubach and Williams (2003) indicate that the real long-run neutral or \"equilibrium\" short-term interest rate in the United States is currently about 2-1/2 percentage points lower than it was on average in the 1980s and 1990s (see Thomas Laubach and John C. Williams (2003), \"Measuring the Natural Rate of Interest,\" Review of Economics and Statistics, vol. 85 (November), pp. 1063-70; updated estimates are available at www.frbsf.org/economic-research/economists/john-williams/Laubach_Williams_updated_estimates.xlsx.)  In addition, Holston, Laubach, and Williams (2016) find significant but somewhat smaller declines in equilibrium rates for the euro area, Canada, and the United Kingdom (see Kathryn Holston, Thomas Laubach, and John C. Williams (2016), \"Measuring the Natural Rate of Interest: International Trends and Determinants,\" Working Paper 2016-11 (San Francisco: Federal Reserve Bank of San Francisco, June), www.frbsf.org/economic-research/files/wp2016-11.pdf).  Return to text\n\n17. For a discussion of the possible role played by these factors in explaining the current low level of interest rates in the United States and other advanced economies, see Lawrence H. Summers (2014), \"U.S. Economic Prospects: Secular Stagnation, Hysteresis, and the Zero Lower Bound,\" Business Economics, vol. 49 (April), pp. 65-73; Robert J. Gordon (2014), \"The Demise of U.S. Economic Growth: Restatement, Rebuttal, and Reflections,\"  NBER Working Paper 19895 (Cambridge, Mass.: National Bureau of Economic Research, February); and Ben S. Bernanke (2015), \"Why Are Interest Rates So Low, Part 2: Secular Stagnation,\"  Ben Bernanke's Blog, blog post (Washington: Brookings Institution, March 31). Return to text\n\n18. For example, see James D. Hamilton, Ethan S. Harris, Jan Hatzius, and Kenneth D. West (2015), \"The Equilibrium Real Funds Rate: Past, Present, and Future,\"  NBER Working Paper 21476 (Cambridge, Mass.: National Bureau of Economic Research, August); and Olivier Blanchard (2016), \"Three Remarks on the U.S. Treasury Yield Curve,\"  Realtime Economic Issues Watch (Washington: Peterson Institute for International Economics, June 22). Return to text\n\n19. FRB/US model simulations have several advantages for analyzing this issue. For one, the model's structure allows the public's expectations for interest rates, inflation, and other factors to take full account of the implications of the effective lower bound on nominal interest rates, changes in future monetary policy as signaled by forward guidance, and asset purchases. In addition, the model incorporates the low responsiveness of inflation to movements in resource utilization seen in recent years as well as the effects of asset purchases on term premiums, and thus a variety of longer-term interest rates, equity prices, and the foreign exchange value of the dollar. For a further discussion about the advantages (and possible disadvantages) of using the FRB/US model to study this issue, see Reifschneider, \"Gauging the Ability of the FOMC to Respond to Future Recessions,\" in note 8. Return to text\n\n20. The aggressive rule is R(t) = 1.0 + p(t) + 0.5 [p(t)-2] - 2.0 [U(t)-4.8], where R is the federal funds rate, π is the four-quarter moving average of core PCE inflation, and U is the unemployment rate [Note: On August 30, 2016, a typo in the equation for the aggressive rule was corrected to change \"[4.8 - U(t)]\" to \"[U(t) - 4.8]\"]. Note that baseline values of the equilibrium real rate, the natural rate of unemployment, and the target rate of inflation used in the simulation analysis--1.0 percent, 4.8 percent, and 2.0 percent, respectively--are consistent with the medians of the latest long-run projections of individual FOMC participants. As discussed by Taylor (1999), this rule appears to do a good job in stabilizing real activity and inflation in a wide range of economic models (see John B. Taylor (1999), \"Introduction,\" in John B. Taylor, ed., Monetary Policy Rules (Chicago: University of Chicago Press), pp. 1-14). Return to text\n\n21. The forward guidance is provided at the start of the recession and has three components. First, the federal funds rate will be lowered to zero more quickly than prescribed by the rule. Second, the federal funds rate will remain at zero as long as the unemployment rate is greater than 5 percent. And, finally, that after the initial increase in the federal funds rate, policymakers will proceed gradually in returning to the prescriptions of the policy rule. Return to text\n\n22. As shown in figure 2, the 10-year Treasury yield in the simulation starts out at just over 4 percent, well below its level pre-crisis, suggesting that there may be less room to push down long-term interest rates in the future than in the past. Another potential source of overstatement could be the FRB/US assumption that changes in long-term interest rates, whether driven by shifts in term premiums or shifts in the expected path of short-term interest rates, have the same influence on real activity, as there is some empirical evidence that the estimated sensitivity of spending to movements in term premiums alone may be relatively small; see Michael T. Kiley (2014), \"The Aggregate Demand Effects of Short- and Long-Term Interest Rates,\"  International Journal of Central Banking, vol. 10 (December), pp. 69-104. On the other hand, the effectiveness of forward guidance in the FRB/US model is materially less than it is in some other models, implying that the FRB/US simulation results could potentially understate the stimulus provided by the announcement of a lower-for-longer policy. See Hess Chung (2015), \"The Effects of Forward Guidance in Three Macro Models,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, February 26). Return to text\n\n23. In principle, the federal funds rate in the longer run could also turn out to be lower than currently predicted if inflation were to remain persistently below 2 percent. However, because a higher rate of inflation can arguably be achieved over time through a sufficiently tight labor market, this risk seems low to me as long as the Federal Reserve is committed to achieving its inflation objective. Return to text\n\n24. In the simulations reported by Reifschneider, \"Gauging the Ability of the FOMC to Respond to Future Recessions,\" in note 8, overcoming the effects of the zero lower bound during a severe recession would require about $4 trillion in asset purchases and pledging to stay low for even longer if the average future level of the federal funds rate is only 2 percent. Return to text\n\n25. For further discussion of ways to enhance the effectiveness of fiscal policy in stabilizing the economy, see Xavier Debrun and Radhicka Kapoor (2010), \"Fiscal Policy and Macroeconomic Stability: Automatic Stabilizers Work, Always and Everywhere (PDF),\"  IMF Working Paper WP/10/111 (Washington: International Monetary Fund, May); Antonio Fatás and Ilian Mihov (2012), \"Fiscal Policy as a Stabilization Tool,\" B.E. Journal of Macroeconomics, vol. 12 (October), pp. 1-66; International Monetary Fund (2015), \"Can Fiscal Policy Stabilize Output? (PDF)\"  chapter 2 in Fiscal Monitor (Washington: IMF, April), pp. 21-48; and Alisdair McKay and Ricardo Reis (2016), \"The Role of Automatic Stabilizers in the U.S. Business Cycle,\" Econometrica, vol. 84 (January), pp. 141-94. Return to text\n\ni. Note: On August 29, 2016, a typo was corrected to change the line color cited from “blue” to “red” in the following sentence: “As the red dashed line shows, the federal funds rate would fall far below zero if policy were unconstrained, thereby causing long-term interest rates to fall sharply.” Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "August 21, 2016",
        "title": "Remarks on the U.S. Economy",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20160821a.htm",
        "content": "August 21, 2016\n\nVice Chairman Stanley Fischer\n\nAt the \"Program on the World Economy\" a conference sponsored by The Aspen Institute, Aspen, Colorado\n\nThe Fed's dual mandate aims for maximum sustainable employment and an inflation rate of 2 percent, as measured by the price index for personal consumption expenditures (PCE). Employment has increased impressively over the past six years since its low point in early 2010, and the unemployment rate has hovered near 5 percent since August of last year, close to most estimates of the full-employment rate of unemployment. The economy has done less well in reaching the 2 percent inflation rate. Although total PCE inflation was less than 1 percent over the 12 months ending in June, core PCE inflation, at 1.6 percent, is within hailing distance of 2 percent--and the core consumer price index inflation rate is currently above 2 percent.1\n\nSo we are close to our targets. Not only that, the behavior of employment has been remarkably resilient. During the past two years we have been concerned at various stages by the possible negative effects on the U.S. economy of the Greek debt crisis, by the 20 percent appreciation of the trade-weighted dollar, by the Chinese growth slowdown and accompanying exchange rate uncertainties, by the financial market turbulence during the first six weeks of this year, by the dismaying pothole in job growth this May, and by Brexit--among other shocks. Yet, even amid these shocks, the labor market continued to improve: Employment has continued to increase, and the unemployment rate is currently close to most estimates of the natural rate.\n\nDuring that period, the decline in the price of oil changed from being regarded as a simple reduction in the cost of living of almost all households--and thus an unmitigated blessing--to also being a source of concern, as it was understood that the decline in investment in the production and installation of drilling equipment mitigated the blessing, as did the decline in U.S. oil production.\n\nAnd there have been other issues of concern to those particularly interested in monetary and macroeconomic policy, though probably of less explicit concern to the public: The decline in estimates of r*--the neutral interest rate that neither boosts nor slows the economy--which is related to the fear that we are facing a prolonged period of secular stagnation; the associated concerns that (a) the short-term interest rate will be constrained by its effective lower bound a greater percentage of time in the future than in the past, and (b) that the U.S. economy could find itself having to contend at some point with negative interest rates--something that the Fed has no plans to introduce; the fear that very low interest rates present a threat to financial stability; and concerns that low rates of real wage growth are increasing inequality in the distribution of income.\n\nPrimarily, I believe it is a remarkable, and perhaps underappreciated, achievement that the economy has returned to near-full employment in a relatively short time after the Great Recession, given the historical experience following a financial crisis.2 To be sure, it was a slow and difficult time for many, in part because growth in real gross domestic product (GDP) has been slow by historical standards. As can be seen in table 1, part of the slower output growth was due to smaller increases in aggregate hours worked, primarily reflecting demographic factors such as the aging of the baby-boom generation. But, as shown in table 2, there was also a major decline in the rate of productivity growth--to which I will return shortly.\n\nTurning briefly to recent developments, the pattern of high employment growth and low productivity growth that we have seen in recent years has continued this year. So far in 2016, nonfarm payroll gains have averaged about 185,000 per month--down from last year's pace of 230,000, but still more than enough to represent a continued improvement in labor market conditions. Estimates of monthly job gains needed to keep the unemployment rate steady range widely, from around 75,000 per month to 150,000 per month, depending on what happens to labor force participation among other things.\n\nOutput growth has been much less impressive. Over the four quarters ending this spring, real GDP is now estimated to have increased only 1-1/4 percent. This pace likely understates the underlying momentum in aggregate demand, in part because of a sizable inventory correction that began early last year; even so, GDP growth has been mediocre at best.\n\nThe combination of strong job gains and mediocre GDP growth has resulted in exceptionally slow labor productivity growth. Most recently, business-sector productivity is reported to have declined for the past three quarters, its worst performance since 1979. Granted, productivity growth is often quite volatile from quarter to quarter, both because of difficulties in measuring output and hours and because other transitory factors may affect productivity. But looking at the past decade, productivity growth has been lackluster by post-World War II standards. Output per hour increased only 1-1/4 percent per year on average from 2006 to 2015, compared with its long-run average of 2-1/2 percent from 1949 to 2005. A 1-1/4 percentage point slowdown in productivity growth is a massive change, one that, if it were to persist, would have wide-ranging consequences for employment, wage growth, and economic policy more broadly. For example, the frustratingly slow pace of real wage gains seen during the recent expansion likely partly reflects the slow growth in productivity.3\n\nLet me highlight a few topics from the growing volume of research on this topic. The first is that the productivity slowdown reflects mismeasurement, because the official statistics have failed to capture new and better products or properly account for changes in prices over time.4 Given how often we meet new technologies in our daily activities, even in classes of products that have been in operation for many years--from driving an automobile, to flying, to medicines and medical equipment, to our communications, and far more--it is easy to persuade ourselves that technological advances play a major part in improving our lives. However, some of these gains are conceptually outside the scope of GDP, and most recent research suggests that mismeasurement of output cannot account for much of the productivity slowdown.5\n\nAnother explanation is that business investment has been relatively modest during the current expansion, and so increases in capital per worker have been smaller than in previous decades. Part of the modest pace of investment is likely because the effective labor force that will use this new capital has been expanding much less rapidly than in previous decades, but it is also possible that investment has been restrained by the subdued outlook for growth and profits, thereby generating less demand for expanding productive capacity.6\n\nHowever the slow growth in capital per worker has been quantitatively less important--accounting for only one-fourth of the slowdown in productivity compared with its long-run average--than the decline in the growth rate of total factor productivity (TFP), the portion of productivity that is not accounted for by measurable inputs to production. Indeed, TFP growth has averaged less than 1/2 percent per year in the past 10 years, well below its long-run average of 1-1/4 percent. Pinning down the exact causes of this slowdown is difficult, and there are many possibilities. For instance, it may reflect a slowdown in technological innovations, which may be persistent, as some have argued, or may be a temporary phenomenon, as I am inclined to believe.7\n\nLow-to-middling TFP growth might also reflect the downward trend in business dynamism, as evidenced by a notable slowdown in gross job creation and destruction. Diminished dynamism has been linked to a marked slowdown in the reallocation of labor and capital from low-productivity establishments and firms to high-productivity ones, especially in innovative sectors like high tech.8 Both phenomena are closely related to the declining trend in new business creation.9\n\nAre we doomed to slow productivity growth for the foreseeable future? We don't know.10 On the encouraging side, the technological frontier appears to be advancing rapidly in some sectors, and there are hints that the firm start-up rate is improving.11 On the more discouraging side, investment continues to disappoint--and so the current capital stock is smaller and embodies fewer frontier technologies than might otherwise be the case--and the productivity slowdown is a global phenomenon, suggesting that it may not be easily or quickly remedied.\n\nLet me conclude by mentioning briefly one aspect of the low interest rate and low productivity growth problems--the fact that the Fed has been close to being \"the only game in town,\" as Mohamed El-Erian and others have described it.12 At least one part of the solution can be found in the observation that overall macroeconomic policy does not have to be confined solely to monetary policy. In particular, monetary policy is not well equipped to address long-term issues like the slowdown in productivity growth. Rather, the key to boosting productivity growth, and the long-run potential of the economy, is more likely to be found in effective fiscal and regulatory policies.13 While there is disagreement about what the most effective policies would be, some combination of improved public infrastructure, better education, more encouragement for private investment, and more-effective regulation all likely have a role to play in promoting faster growth of productivity and living standards--and also in reducing the probability that the economy and particularly the central bank will in the future have to contend more than is necessary with the zero lower bound.\n\n\n\n1. I am grateful to Christopher Nekarda, Joseph Gruber, David Lebow, and Stacey Tevlin of the Federal Reserve Board staff for their assistance. Views expressed are mine and are not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See Carmen M. Reinhart and Kenneth S. Rogoff (2009), This Time Is Different: Eight Centuries of Financial Folly (Princeton, N.J.: Princeton University Press). Return to text\n\n3. An alternative explanation is that productivity growth has been slow because wage growth has been slow; that is, faced with only tepid rises in labor costs, firms have had less incentive to invest in labor-saving technologies. Return to text\n\n4. See, for example, David Byrne and Carol Corrado (2016), \"ICT Prices and ICT Services: What Do They Tell Us about Productivity and Technology? (PDF)\"  Economics Program Working Paper Series 16-05 (New York: Conference Board, May; revised July 2016); and David Byrne and Eugenio Pinto (2015), \"The Recent Slowdown in High-Tech Equipment Price Declines and Some Implications for Business Investment and Labor Productivity,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, March 26). Return to text\n\n5. See, for example, Chad Syverson (2016), \"Challenges to Mismeasurement Explanations for the U.S. Productivity Slowdown,\"  NBER Working Paper Series 21974 (Cambridge, Mass.: National Bureau of Economic Research, February); and David M. Byrne, John G. Fernald, and Marshall B. Reinsdorf (2016), \"Does the United States Have a Productivity Slowdown or a Measurement Problem? (PDF)\"  Brookings Papers on Economic Activity, Spring, pp. 109-82. Return to text\n\n6. Eugenio Pinto and Stacey Tevlin (2014), \"Perspectives on the Recent Weakness in Investment,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, May 21). Return to text\n\n7. For example, Robert Gordon (2016) argues forcefully in his recent book, The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War (Princeton, N.J.: Princeton University Press), that slow productivity growth is likely to persist. Return to text\n\n8. See Ryan A. Decker, John Haltiwanger, Ron S. Jarmin, and Javier Miranda (2016), \"Changing Business Dynamism: Volatility of Shocks vs. Responsiveness to Shocks? (PDF)\"  unpublished paper, April. Return to text\n\n9. See Ryan A. Decker, John Haltiwanger, Ron S. Jarmin, and Javier Miranda (2016), \"Declining Business Dynamism: Implications for Productivity?\" unpublished paper, August; and Francois Gourio, Todd Messer, and Michael Siemer (2016), \"Firm Entry and Macroeconomic Dynamics: A State-Level Analysis (PDF),\" Finance and Economics Discussion Series 2016-043 (Washington: Board of Governors of the Federal Reserve System, February). Return to text\n\n10. There is no shortage of views on this issue among economists, but the views to some extent appear to depend on whether the economist making the prediction is an optimist or a pessimist. For the record, I note (a) that looking ahead, I expect GDP growth to pick up in coming quarters, as investment recovers from a surprisingly weak patch and the drag from past dollar appreciation diminishes, and (b) that I am an optimist. Return to text\n\n11. See Dan Andrews, Chiara Criscuolo, and Peter N. Gal (2015), \"Frontier Firms, Technology Diffusion and Public Policy: Micro Evidence from OECD Countries (PDF),\"  OECD Productivity Working Papers Series 2015-02 (Paris: Organisation for Economic Co-operation and Development, November). Return to text\n\n12. See Mohamed El-Erian (2016), The Only Game in Town: Central Banks, Instability, and Avoiding the Next Collapse (New York: Random House).\n\nDavid Mericle and Avisha Thakkar (2016) recently noted that, in the seven years since the Great Recession and Global Financial Crisis, U.S. monetary policy was somewhat more supportive--and fiscal policy less supportive--compared with the average policy response in previous large advanced-economy financial crises (see \"The Crisis and Its Aftermath: Back to the Future,\" Goldman Sachs, Economics Research, U.S. Economics Analyst, August 12). Return to text\n\n13. One related hypothesis, identified with Mancur Olson, is that, absent major shakeups of the institutional structure of the economy, the gradual accretion of the barnacles produced by the political process slows the vitality of the economy until eventually the public is willing to face the difficulties attending the structural reforms needed to restore that vitality. Return to text"
    },
    {
        "speaker": "Daniel K. Tarullo",
        "position": "Governor",
        "date": "July 12, 2016",
        "title": "Opening Remarks",
        "href": "https://www.federalreserve.gov/newsevents/speech/tarullo20160712a.htm",
        "content": "July 12, 2016\n\nGovernor Daniel K. Tarullo\n\nAt the Center for American Progress and Americans for Financial Reform Conference, Washington, D.C.\n\nHaving been given the privilege of opening this conference, let me start at the very beginning with the term \"shadow banking.\" The very phrase evokes the sense of something hidden, furtive even--a sort of film noir backdrop for extending credit, in contrast to the well-lit setting of the local insured depository institution. In the pre-crisis years, there did indeed develop modes of financial intermediation in which certain features of a counterparty relationship were, if not quite obscured, then at least ambiguous, and thus \"shadowy.\" Most notable were arrangements in which guarantees of capital preservation or liquidity provision were understood to exist and to have been previously honored, even in the absence of contractual obligations for those guarantees. But as asset values were falling to points unknown, the withdrawal of many of these implicit guarantees by financial entities that were themselves under stress amplified the growing liquidity crunch.\n\nDamaging as these arrangements were, however, they do not define the range of issues associated with the term shadow banking. A broader definition would embrace all forms of lending outside of prudentially regulated institutions. While such a definition might be a useful starting point for purposes of consumer protection, for example, it seems both over- and under-inclusive for purposes of regulation to protect financial stability and the resilience of the economy as a whole. There are certainly forms of nonbank lending that do not raise prudential concerns. On the other hand, financial stability concerns can arise where credit extension is only indirectly involved, as might be the case with certain bond funds, or where credit is not involved at all, as might be the case with firms writing large amounts of variable annuities with minimum return guarantees.\n\nRather than dwell on definitions, much less attempt to develop a taxonomy of shadow banking, I think it more productive to focus on the characteristics of shadow banking-related financial activities and institutions that are most likely to pose risks to financial stability and to the economy more generally.1 Front and center among these risks is that of runnable liabilities.2 As has been frequently observed, the recent financial crisis began, like most banking crises, with a run on short-term liabilities by investors who had come to doubt the value of the assets they were funding through various kinds of financial intermediaries. The difference, of course, was that the run was not principally on depository institutions, as in the 1930s, but on asset-backed commercial paper programs, broker-dealers, money market funds, and other intermediaries that were heavily dependent on short-term wholesale funding.\n\nLacking enough liquidity to repay all the counterparties who declined to roll over their investments, these intermediaries were forced into fire sales that further depressed asset prices, thereby reducing the values of assets held by many other intermediaries, raising margin calls, and leading to still more asset sales. Those financial market actors who did have excess liquidity tended to horde it, in light of their uncertainty as to whether their balance sheets might come under greater stress and their reluctance to catch the proverbial falling knife by purchasing assets whose prices were plummeting with no obvious floor.\n\nRuns and panics are the defining characteristic of a financial crisis, transforming debt problems that might themselves have produced a drag on the economy into a classic adverse feedback loop with more devastating consequences. It is important to note that the short-term funding or immediately redeemable investments that can run when a shock hits are likely to have contributed to the vulnerability of relevant asset classes to those shocks. The very short-term nature of the transaction reduces the incentives of counterparties to evaluate carefully the loan or investment they are making. If you can refuse to roll over your repo tomorrow, why be too concerned about whether the underlying collateral may prove to be overvalued a few months later? Consequently, funds may flow into asset classes with less sensitivity to information relevant to the value of the assets, driving asset values up and lending standards down, until the moment at which negative information becomes so powerful that everyone wants out at once.\n\nThus, in deciding where--from a prudential viewpoint--to concentrate analysis and policy initiatives within the broad universe of activities that can be described by the term shadow banking, it seems to me that the presence of runnable funding is the key, though perhaps not the only consideration.3 To be sure, this kind of funding remains at levels well below those prevailing before the crisis, as many of the more damaging mechanisms of that period--such as the infamous structured investment vehicles (SIVs)--have disappeared. Moreover, the largest broker-dealers, both domestic and foreign, that were so dependent on short-term funding in the pre-crisis period have now either converted to, or been absorbed into, bank holding companies subject to prudential capital and liquidity regulation. New regulatory requirements have placed some constraints on the relationships between shadow banking and prudentially regulated banking organizations. The Securities and Exchange Commission has taken some steps to strengthen its regulation of money market funds and other asset managers whose business models involve substantial amounts of liquidity transformation.\n\nBut just because the levels of runnable funding are significantly lower than before the crisis does not necessarily mean they are at safe or optimal levels. And it seems quite reasonable to expect that new forms of financial intermediation based substantially on runnable funding could develop in the future. As liquidity standards, stress testing, and resolution planning evolve, regulators will continue to work on this issue with prudentially regulated firms. But the conditions for destructive runs that threaten financial stability could exist even where no institutions that might be perceived as too-big-to-fail are immediately involved. So I continue to believe that the post-crisis work to create a solid regime to protect financial stability cannot be deemed complete without a well-considered approach to regulating runnable funding outside, as well as inside, the regulatory perimeter.\n\nAgain, taking advantage of my spot at the opening of the conference, let me note some key questions to be answered in fashioning such an approach.\n\nFirst, to what degree will it rely on uniform regulation of users of runnable funding no matter what the characteristics of the market actors and business models involved in the funding relationship? The alternative would be continued reliance on a regulatory response tailored to different forms of financial intermediation and, perhaps, the relative market significance of the various actors. The advantages of the former are that it minimizes at least one kind of regulatory arbitrage and the need for extensive and perhaps constant elaboration. The advantages of the latter are that it might allow more innovation in financial markets, particularly by non-established actors, and could well be more efficient.\n\nSecond, what agency or agencies would be the appropriate regulators? The answer to this question would obviously be related to the answer to the first, though some different considerations do apply. The choice of a single agency versus multiple agencies involves the well-known tradeoff between relative coherence of approach and linkage with other agency functions and expertise, on the one hand, versus involvement of multiple agency perspectives and avoidance of too much concentration of authority in a single agency, on the other.\n\nThird, what form or forms would the regulation take? A non-exhaustive list of possibilities includes outright prohibition, minimum margining requirements and practices, capital requirements, and taxation. Again, the answer to this question may both affect, and be affected by, the considerations implicated by the first two.\n\nMy fourth and fifth questions are quite different from the first three, and I will defer for a moment actually stating them, in order to provide some context. To this point, my remarks have reflected the familiar perspective that identifies a set of market practices carrying significant risk of negative externalities--in this case, with some collective action problems thrown in--and then asks how to fashion an appropriate regulatory response. An additional, important consideration here is that at least some of the short-term funding instruments implicated in this analysis respond not just to the desire of their creators for funding that is cheaper than equity or longer-term debt, but also to the demand of many entities--from other financial firms to pension funds to foreign sovereigns--for \"safe\" assets. As the term implies, these assets must be reliable stores of value that are readily available for use--features sometimes characterized as \"money-like.\"\n\nObvious forms of safe assets include currency itself (though that has its well-known limitations for large-value transacting), government-insured demand deposits, and obligations of highly creditworthy sovereigns such as U.S. Treasuries. But numerous commentators have observed that, for a variety of reasons, demand for safe assets in recent decades has been growing substantially faster than the supply of these most obvious and truly safe forms of government-backed assets.4 In these circumstances, they note, the demand for privately created safe assets has increased. One problem, of course, is that the privately created assets may be treated as safe in normal times but, as seen in 2008, not in periods of high stress. Hence the phenomenon of runs. Another consideration is that the private creation of putatively safe assets is, at least to some degree, the creation of money outside of the operations of central banks or of depository institutions subject to reserve requirements and other regulations.\n\nWith that background, here are my last two questions. Fourth, as a factual matter, to what extent is the supply of short-term funding a response to a persistent demand for more safe assets? If the answer is \"considerable,\" then further constraints on the creation of currently used safe assets might result in further financial engineering in search of assets that approximate the attributes of truly safe assets even less well, but are the best the demanders of these assets can do.\n\nAnd so, fifth, to what extent does a comprehensive regulatory approach to shadow banking need to include mechanisms--involving the government directly or indirectly--for the creation of more genuinely safe assets, as well as limitations on the runnable varieties that can precipitate or exacerbate financial stress? This is clearly a big question that runs well beyond the scope of even the most far-reaching financial regulatory debates and initiatives of the post-crisis period. It implicates some elements of monetary policy, as well as moral hazard issues and other recurring factors in financial regulation.\n\nConsideration of the question of whether government policy should seek to create, or create the conditions for private creation of, safe assets has already produced numerous interesting analyses and proposals. Some of these ideas move in quite different directions, perhaps an indication that it is not realistic to think we will have an answer in the near term that can command a working agreement among policymakers.5 But, even if that is so, the implications of these questions must be confronted when devising policy responses to the very real risks of runnable liabilities.\n\nThere are the questions. Now I bring the opening of the conference to a close, and look forward to hearing what answers emerge during the rest of the day.\n\n1. Some of the issues mentioned in these brief opening remarks are addressed at greater length in Daniel K. Tarullo (2015), \"Thinking Critically about Nonbank Financial Intermediaries,\" remarks at the Brookings Institution, Washington, November 17. Return to text\n\n2. A working definition of runnable liabilities is provided by Jack Bao, Josh David, and Song Han in \"The Runnables,\" FEDS Notes, September 3, 2015, www.federalreserve.gov/econresdata/notes/feds-notes/2015/the-runnables-20150903.html:\n\n\n\n3. Funding considerations are most relevant where funding is needed for an intermediary's existing balance sheet of longer-term assets, since forced sales are the most likely alternative. But they may also be useful in thinking about forms of non-bank credit in which the intermediary has only a small balance sheet of its own and essentially relies on external funding either to buy the loans directly or to fund them until they can be sold to other investors. The potential fragility of such a business model in recessionary periods could be of concern if it had come to occupy a large part of the market for certain forms of lending. In these circumstances, the withdrawal of these kinds of lenders could leave a hole that insured depository institutions--with their stickier funding sources and required capital levels--might not be able to fill completely. The result could be the unavailability of credit for borrowers that were creditworthy even in less favorable economic times. Return to text\n\n4. For some of the factors involved in this increased demand, see Daniel K. Tarullo (2012), \"Shadow Banking after the Financial Crisis,\" remarks delivered at the Federal Reserve Bank of San Francisco Conference on Challenges in Global Finance, San Francisco, June 12. Return to text\n\n5. For examples see Mark Carlson, Burcu Duygan-Bump, Fabio Natalucci, Bill Nelson, Marcelo Ochoa, Jeremy Stein, and Skander Van den Heuvel (forthcoming), \"The Demand for Short-Term, Safe Assets and Financial Stability: Some Evidence and Implications for Central Bank Policies\"  International Journal of Central Banking; Morgan Ricks (2016), The Money Problem (Chicago: University of Chicago Press); Jeremy Stein (2012) \"Monetary Policy as Financial Stability Regulation,\" Quarterly Journal of Economics 127, pp. 57-95; Perry Mehrling (2011), The New Lombard Street (Princeton:, NJ: Princeton University Press); and Gary Gorton and Andrew Metrick (2010), \"Regulating the Shadow Banking System,\" Brookings Papers on Economic Activity (Washington: Brookings Institution, Fall), pp. 261-97. Return to text"
    },
    {
        "speaker": "Jerome H. Powell",
        "position": "Governor",
        "date": "June 28, 2016",
        "title": "Recent Economic Developments, Monetary Policy Considerations and Longer-term Prospects",
        "href": "https://www.federalreserve.gov/newsevents/speech/powell20160628a.htm",
        "content": "June 28, 2016\n\nGovernor Jerome H. Powell\n\nAt the Chicago Council on Global Affairs, Chicago, Illinois\n\nWatch live\n\nThank you for this opportunity to speak here today. The Chicago Council on Global Affairs has been a thought leader for nearly a century, encouraging public discourse, education, and research on important global issues. The Council's global focus is particularly important for understanding the challenges facing the U.S. economy today, as shown by last week's referendum on the United Kingdom's status in the European Union. In my remarks, I will review recent economic developments and the outlook for the economy. I will also discuss the economy's longer-term productive potential. As always, the view I express here today are my own.\n\nThe Dual Mandate and State of the Economy\nAs you know, the Federal Reserve, through the Federal Open Market Committee (FOMC), is charged by the Congress with achieving maximum employment and stable prices--the dual mandate. For price stability, the FOMC has adopted a goal of 2 percent for inflation, as measured by the annual change in the price index for personal consumption expenditures. Many other central banks in developed economies have adopted inflation goals centered around 2 percent.\n\nThe FOMC has not set a numerical goal for maximum employment, because the long-run sustainable level of employment is determined mainly by non-monetary factors that are outside the Fed's control, such as demographics, social change, and fiscal and regulatory policies. Nonetheless, four times a year, FOMC participants write down their estimates of the longer-run sustainable level of the unemployment rate (which many interpret as the \"natural rate\"); at the recent June FOMC meeting the median estimate of that rate was 4.8 percent.\n\nHow should we evaluate our current performance against the dual mandate? I would say that we have made substantial progress toward maximum employment, although there is still some room for improvement. We have more work to do to assure that inflation moves back up to our 2 percent goal.\n\nLet's start with the employment mandate. After several years of strong job growth, employment is now over 5 million higher than the pre-crisis peak in 2007. The unemployment rate has fallen from 10 percent in 2009 to 4.7 percent in May, essentially at the level that many observers identify as the natural rate. This rate is very far from a bright line--it cannot be observed directly, and estimates of its level are subject to great uncertainty.1 So we look to a wide range of labor market indicators to assess the overall health of the labor market. Many of those indicators suggest that the labor market is strong. To mention a few of these, job openings are at an all-time high by some measures. The \"quits\" rate--the rate at which employees voluntarily leave their jobs--is about at pre-crisis levels. Surveys of individuals and businesses suggest that the ease of finding and filling jobs is similar to that experienced in the mid-2000s.\n\nEven though we are near the natural rate of unemployment, there is still room for improvement on several margins. Important among these is the labor force participation rate. If someone leaves the labor force for any reason, even temporarily, that person is not counted as unemployed. So the labor force participation rate is also a key determinant of the unemployment rate. Labor force participation is influenced by many factors, including the age structure of the population and individuals' perceptions of the availability of jobs.\n\nParticipation rose steadily from the 1970s through the 1990s as increasing numbers of women entered the formal workforce. That process ran its course, and, around the year 2000, participation began a gradual decline because of population aging and the continuation of other long-term trends, particularly the decline in participation among prime age males. From 2008 through 2013, participation dropped sharply by 3 percentage points, but has remained about flat, on net, since late 2013 in a context of strong job growth and declining unemployment. Economists estimate that, as the population ages, participation will naturally tend to decline at a trend rate of about 0.2 percentage point per year, so this period of flat participation actually represents an improvement against the post-crisis cyclical drop. Today, participation is near its longer-run trend as estimated by a group of Fed economists whose work is widely cited on these issues.2 Some other estimates suggest that there is still a shortfall in participation, and, of course, estimates of the trend participation rate are surrounded by fairly wide bands of uncertainty. I am inclined to believe that there are potential workers at the margins of the labor market who will return as the recovery continues, the labor market tightens further and wages increase. The U.S. participation rate for workers in the 25-54 age group is now below those of most other advanced economies, including the U.K., France and Germany, for example.\n\nThe number of part-time workers who want full time work remains above pre-crisis levels, which suggests that there may be some remaining slack there as well. In addition, we should expect to see stronger wage increases as the labor market tightens. There are welcome signs of a firming in wages, seen most clearly in the data on average hourly earnings, which are rising faster than the sum of inflation and productivity growth.\n\nAfter several years of improving labor market conditions, recent data have been sending mixed signals on the level of momentum in the economy. Business investment has weakened, even outside the energy sector. Growth in gross domestic product (GDP) is estimated to have slowed to a rate of only 1-1/4 percent on an annualized basis over the fourth quarter of last year and the first quarter of this year. Incoming data do point to a rebound. For example, the Atlanta Fed's GDPNow model, which bases its projection on a range of incoming monthly data, estimates growth of 2.6 percent in the second quarter. In contrast, the labor market data, especially the monthly increase in payroll jobs, after displaying considerable strength for several years right through the first quarter of 2016, weakened significantly in April and May. While I would not want to make too much of two monthly observations, the strength of the labor market has been a key feature of the recovery, allowing us to look through quarterly fluctuations in GDP growth. So the possible loss of momentum in job growth is worrisome.\n\nTurning to the inflation part of the mandate, the Fed's preferred measure of inflation has consistently run below our 2 percent objective since the end of the financial crisis, with the exception of the \"Arab Spring\" period in 2011, when oil prices temporarily spiked. For the 12 months ending in April, total inflation was only 1 percent, while core inflation (excluding food and energy prices) was 1-1/2 percent. Core inflation has been held down by falling import prices, owing in large part to the rise in the dollar, as well as the indirect effects of lower oil prices. If the dollar and oil prices remain broadly stable going forward, inflation should move up over time to our 2 percent objective.\n\nWhen I was first exposed to macroeconomics in college, more than four decades ago, the view was that inflation was strongly influenced by the amount of slack in the economy. But the relationship between slack and inflation has weakened substantially over the years. In addition, inflation depends importantly on the inflation expectations of workers and firms. A widely shared view among economists today is that, unlike during the 1970s, expectations are no longer heavily influenced by fluctuations in inflation, but are fairly constant, or anchored. For both these reasons, inflation has become less responsive to cyclical changes in the economy. We measure inflation expectations through surveys of forecasters and the general public, and also through market readings on inflation swaps and \"breakevens,\" which represent inflation compensation as measured by the difference between the return offered by nominal Treasury securities and that offered by TIPS. Since mid-2014, these market-based measures have declined significantly to historically low levels. Some of this decline probably represents lower risk of high inflation, or an elevated liquidity preference for much more heavily traded nominal Treasury securities, rather than expectations of lower inflation. Some survey measures of inflation expectations have also trended down. Given the importance of expectations for determining inflation, these developments deserve, and receive, careful attention. While inflation expectations seem to me to remain reasonably well anchored, it is essential that they remain so. The only way to assure that anchoring is to achieve actual inflation of 2 percent, and I am strongly committed to that objective.\n\nLooking Ahead\nMy baseline expectation has been that our economy is likely to continue on its path of growth at around 2 percent. I have also expected the ongoing healing in labor markets to continue, with healthy wage increases and job creation. As the economy tightens, I have expected that inflation will move up over time to the Committee's 2 percent objective.\n\nFor some time, the principal risks to that outlook have been from abroad. Global economic and financial conditions are particularly important for the U.S. economy at the moment. Weakness in economic activity around the world and related bouts of financial volatility have weighed on the performance of our economy. Given the stronger performance of the U.S. economy, the trade-weighted value of the dollar has risen roughly 20 percent since 2014. Such a large appreciation of the dollar means that we will \"export\" some of our strength to our trading partners and \"import\" some of their weakness.\n\nGrowth and inflation remain stubbornly low for most of our major trading partners. European and Japanese authorities have limited scope to respond, with daunting longer-run fiscal challenges and policy rates already set below zero. In China, stimulus measures should support growth in the near term, but may also slow China's necessary transition away from its export- and investment-led business model. Emerging market nations such as Brazil, Russia and Venezuela face challenging conditions.\n\nThese global risks have now shifted even further to the downside, with last week's referendum on the United Kingdom's status in the European Union. The Brexit vote has the potential to create new headwinds for economies around the world, including our own. The risks to the global outlook were somewhat elevated even prior to the referendum, and the vote has introduced new uncertainties. We have said that the Federal Reserve is carefully monitoring developments in global financial markets, in cooperation with other central banks. We are prepared to provide dollar liquidity through our existing swap lines with central banks, as necessary, to address pressures in global funding markets, which could have adverse implications for our economy. Although financial conditions have tightened since the vote, markets have been functioning in an orderly manner. And the U.S. financial sector is strong and resilient. As our recent stress tests show, our largest financial institutions continue to build their capital and strengthen their balance sheets.\n\nIt is far too early to judge the effects of the Brexit vote. As the global outlook evolves, it will be important to assess the implications for the U.S. economy, and for the stance of policy appropriate to foster continued progress toward our objectives of maximum employment and price stability.\n\nI am often asked why rates remain so low now that we are near full employment. A big part of the answer is that, at least for the time being, the appropriate level of rates is simply lower than it was before the crisis. As a result, policy is not as stimulative as it might appear to be. Estimates of the real interest rate needed to keep the economy on an even keel if it were operating at 2 percent inflation and full employment--the \"neutral rate\" of interest--are currently around zero. Today, the real short term interest rate is about negative 1-1/4 percent, so policy is actually only moderately stimulative. I anticipate that the neutral rate will move up over time, as some of the headwinds that have weighed on economic growth ease.\n\nLonger-term Considerations: Potential output, productivity, labor market fluidity, and business dynamism\nI would like to take a step back from the current context and explore an issue that ought to receive more attention--the longer-run potential growth rate of our economy. One reason for the low neutral rate of interest is that potential growth appears to have slowed. Since the crisis ended, forecasters have broadly reduced their estimates of longer run growth by a full percentage point--from about 3 percent to about 2 percent.3 This seemingly modest reduction implies dramatically smaller increases in living standards over time. A growing body of research shows that deep recessions accompanied by severe financial crises often leave behind permanent damage.4 One recent analysis suggests that in about one-third of such cases there is no permanent damage; one-third of the time there is a permanent reduction in the level of potential output but not its subsequent growth rate; and one third of the time there is a reduction in both the level of potential output and in the growth rate.5 Unfortunately, many economies are currently in danger of falling into the third category, including the U.S. economy.\n\nOutput growth can be broken down into increases in hours worked and changes in output per hour, or productivity. Most of the decline in estimated potential U.S. growth appears to be from lower productivity. Labor productivity growth began to slow around 2005--before the crisis--and been only 1/2 percent annually since 2011--the slowest five year period since World War II. The productivity slowdown has been worldwide, and has been seen in countries that were not as strongly affected by the crisis, so U.S. specific factors are probably not the main cause.6\n\nIncreasing productivity is necessary if living standards are to continue to rise over generations. So two important questions arise: Why has productivity growth been so slow? And what does the future look like?\n\nWe have tentative answers to the first question. Labor productivity is a function of three things. The first two are the skills of the labor force, and the tools they have, particularly equipment, software and the like. These are inputs to production and are driven by private and public investment. The third determinant is called \"total factor productivity,\" or TFP, which refers to the ability of firms to produce more efficiently given the first two inputs. For example, as businesses learned how to incorporate advances in information technology into their production processes, there was a surge of productivity growth from roughly 1995 to 2005.\n\nThe weak performance of productivity since the crisis appears to stem mainly from weak business investment and low TFP growth. Weak business investment has resulted from weak demand and uncertainty about the pace of the recovery. TFP is equally important and has generally accounted for most of the variation in productivity over time, but is less well understood and so more difficult to forecast.\n\nThe second question--what will happen with productivity going forward--is the subject of intense debate. The range of forecasts is wide, and the historical record provides ample ground for humility. This summer, many will be carrying Robert Gordon's massive The Rise and Fall of American Growth to the beach (or perhaps to the lake, here in the Midwest), which argues the pessimistic view.7 For balance, maybe bring along Brynjolfsson and McAfee's The Second Machine Age, which take a more optimistic view and is a great deal shorter.8\n\nOne factor that may contribute to low productivity growth is the notable decline in recent decades in measures of the dynamism of our economy. Entrepreneurs start new firms; most of them fail, but a few of them succeed, grow very rapidly, and account for significant amounts of job formation. Older firms shrink or go out of business if they fail to keep up with innovation and advances in productivity. Workers change jobs and move around the country (or the world) as their careers evolve and as companies grow and shrink. These processes can be painful and messy for both workers and firms, but they are essential to the allocation of resources to their highest, most productive uses. The high levels of innovation and fluidity of our economy have long been thought to be among the principal reasons for our high and rising living standards.\n\nThe slowdown in essentially all of these processes is seen in declining rates of creation and destruction of both firms and jobs.\n\nStart-ups: Start-ups are a key driver of productivity growth. Although it may feel that we are living in an age of disruption, the birthrate of startups has actually been in decline since the 1970s.9 New firms can be loosely grouped into two categories: those started by \"lifestyle entrepreneurs\" who want to be their own boss, but who have little prospect or desire for high growth; and those founded by transformational entrepreneurs who start businesses that aspire to grow dramatically and change their industry. Before 2000, the decline in new firm entry was mainly in the first sort; since 2000, it is also found among the so-called transformational firms. While the drop in the formation of lifestyle-type firms could be neutral or even a positive for productivity, as in the case of the U.S. retail sector, the reduction in the creation of high-performance new firms suggests that lower dynamism could be associated with slower productivity growth.10\n\nLabor Market Dynamism: While changing jobs can be painful, job changes in the aggregate are associated with higher compensation, implying higher productivity. But the rewards to job change may have declined. Fewer start-ups has meant lower \"job flows,\" as measured by job creation and destruction, and fewer opportunities for workers to find better jobs. And labor market dynamism across many dimensions has declined by more than can be explained by the reduction in startups. Workers have become less likely to leave their jobs, change jobs, or move geographically to take new jobs.11\n\nDynamism is a relatively new field of inquiry, and there is no consensus yet on the reasons for, or implications of, these developments. Some plausible sources of these changes are benign, while others are more negative and suggest that the reduction in dynamism may be a factor behind the slower increases in productivity. For example, historically there has been a robust correlation at the firm level between productivity and growth, with high productivity levels being correlated with faster growth and low productivity levels being associated with contraction or exit. This relationship has weakened since 2000, particularly in the high-tech sector.12 High productivity firms are not growing as quickly, and low productivity firms are shrinking or exiting at a slower pace.\n\nIt may be that some government policies, while well intended, have contributed to these trends. One example that may explain a small portion of the reduction in dynamism is the substantial increase in occupational licensing.13 By some estimates, the fraction of workers who are required to hold a government issued license or certification to perform their jobs has risen from 5 percent in the 1950s to close to 40 percent.14 Like many policies, licensing has benefits and costs. Among the costs are that it tends to reduce job switching and employment opportunities for excluded workers, and may restrict competition and thus increase prices faced by consumers. Among the benefits may be higher quality products and services and improved health and safety standards. Some researchers have advanced the view that licensing requirements have become overly burdensome and may have contributed to the secular decline in job and worker reallocation.15\n\nDynamism is a fast-developing field of research, and it will be important that public policy react appropriately as this work continues. It goes without saying that economic policymakers should use all available information and tools to create a supportive environment for growth. We need policies that support labor force participation and the development of skills, business hiring and investment, and productivity growth. For the most part, these policies are outside the remit of the Federal Reserve, but monetary policy can contribute by supporting a strong and durable expansion, in a context of price stability.\n\nConclusion\nHow should we think about the performance of our economy since the Crisis? The picture is mixed, and that question will no doubt be debated in the decades ahead. But here are some facts. Since 2011, job growth has been stronger and unemployment has declined faster than most forecasts. On the other hand, economic growth has been consistently lower than almost all private- and public-sector forecasts, including those of FOMC participants. Growth has been slower in this recovery than in many previous recoveries; a growing body of research shows that weak recoveries are the norm after deep recessions and those associated with severe financial crises. Finally, our recovery has also been stronger than those of many other advanced economies following this crisis.\n\nI expect our economy to continue to make progress. Monetary policy will need to remain supportive of growth, as we work through the challenging global environment. As always, it will be important to carefully monitor economic developments in order to assess the stance of policy appropriate to foster continued progress toward our objectives of maximum employment and price stability.\n\n1. Confidence intervals around statistical estimates of the natural rate are routinely estimated to be quite wide, reflecting both uncertainty about the correct model specification as well as uncertainty about the parameter estimates given the model. The canonical paper by Douglas Staiger, James H. Stock and Mark W. Watson (1997), \"How Precise are Estimates of the Natural Rate of Unemployment?,\" in Christina D. Romer and David H. Romer, eds., Reducing Inflation: Motivation and Strategy (Chicago: University of Chicago Press) puts the 95 percent confidence interval at 1-1/2 percentage points on either side of the point estimate. Return to text\n\n2. See Stephanie Aaronson, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014), \"Labor Force Participation: Recent Developments and Future Prospects (PDF),\"  Brookings Papers on Economic Activity, Fall, pp. 197-275. Return to text\n\n3. The long-range consensus U.S. economic projections for real GDP growth reported by Blue Chip Economic Indicators moved down from 2.9 percent in March 2007 to 2.1 percent in March 2016. Return to text\n\n4. See Robert F. Martin, Teyanna Munyan, and Beth Anne Wilson (2014), \"Potential Output and Recessions: Are We Fooling Ourselves?\" IFDP Notes (Washington: Board of Governors of the Federal Reserve System, November 12). Return to text\n\n5. See Olivier Blanchard, Eugenio Cerutti and Lawrence Summers (2015), \"Inflation and Activity -- Two Explorations and Their Monetary Policy Implications,\" IMF Working Paper WP/15/230, 2015 (Washington: International Monetary Fund). Return to text\n\n6. See, for example, \"New OECD indicators trace productivity growth slowdown pre- and post-crisis.\"   Return to text\n\n7. See Robert J. Gordon (2016), The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War (Princeton, N.J.: Princeton University Press). Return to text\n\n8. See Erik Brynjolfsson and Andrew McAfee (2014), The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies (New York: W.W. Norton). Return to text\n\n9. See Ryan A. Decker, John Haltiwanger, Ron S. Jarmin and Javier Miranda (2016), \"Declining Business Dynamism: What We Know and the Way Forward,\" Amercian Economic Review, vol. 106 (May), pp 203-07; Ryan Decker, John C. Haltiwanger, Ron Jarmin, and Javier Miranda (forthcoming), \"Where Has all the Skewness Gone? The Decline of High-Growth (Young) Firms in the U.S.\" European Economic Review; and Jorge Guzman and Scott Stern (2016), \"The State of American Entrepreneurship: New Estimates of the Quantity and Quality of Entrepreneurship for 15 US States, 1988-2014,\" NBER Working Paper Series 22095 (Cambridge, Mass: National Bureau of Economic Research, March). Return to text\n\n10. See Lucia Foster, John Haltiwaner and C. J. Krizan (2001) \"Aggregate Productivity Growth: Lessons from Microeconomic Evidence\" in New Developments in Productivity Analysis, Charles Hulten, Ediwn Dean and Michael Harper, eds. (Cambridge, Mass: National Bureau of Economic Research, March). Return to text\n\n11. See Steven Davis and John Haltiwanger (2014) \"Labor Market Fluidity and Economic Performance,\" NBER Working Paper Series 20479, (Cambridge, Mass: National Bureau of Economic Research, September); Raven Malloy, Christopher Smith, Riccardo Trezzi and Abigail Wozniak (2016), \"Understanding Declining Fluidity in the Labor Market,\"  Brookings Papers on Economic Activity, March 3; and Henry Hyatt and James Spletzer (2013) \"The Recent Decline in Employment Dynamics.\"  Return to text\n\n12. See Decker and others, \"Declining Business Dynamism,\" in note 5. Return to text\n\n13. Licensing restrictions increase the costs of switching occupations and potentially reduces interstate mobility. The evidence linking licensing to labor market fluidity is inconclusive, with some researchers finding a linkage and others not. Return to text\n\n14. Davis and Haltiwanger (2014). Return to text\n\n15. See, for example, The Department of the Treasury Office of Economic Policy, the Council of Economic Advisers, and the Department of Labor (2015), \"Occupational Licensing: A Framework for Policymakers (PDF),\" (Washington: The White House, July). Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "June 22, 2016",
        "title": "Comments on the Resolution Framework for Banks and Bank Holding Companies in the United States",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20160622a.htm",
        "content": "June 22, 2016\n\nVice Chairman Stanley Fischer\n\nAt the Panel Discussion on Resolution Riksbank Macroprudential Conference, Stockholm, Sweden\n\nI'm grateful to the organizers for inviting me to participate in this conference. I would like briefly to describe the legal frameworks that exist for resolving banking organizations in the United States, the steps that the Federal Reserve and other U.S. regulators have taken to make global systemically important banking organizations (GSIBs) in the United States more resolvable, and a few of the criticisms of U.S. regulatory actions in this area, together with my responses to them.1\n\nU.S. law provides several legal frameworks for resolving failed financial firms. In the United States, a failed depository institution is resolved by the Federal Deposit Insurance Corporation (FDIC) using a framework created by the Federal Deposit Insurance Act. The FDIC has acted as receiver for several thousand failed banks since 1934, including 465 from 2008 through 2012. Most of these failed banks were relatively small community banks, and all were considerably smaller than the most systemically important firms active today.2\n\nWhile the Federal Deposit Insurance Act creates a special resolution framework for failed banks, a failed U.S. bank holding company--that is, a corporate entity that controls one or more banks--would generally be resolved under the same provisions of the U.S. Bankruptcy Code as would apply to other corporate debtors, such as industrial firms, in a proceeding overseen by a federal judge. During the recent crisis, fears about the systemic consequences that would follow from the bankruptcies of systemically important financial firms motivated extraordinary government actions to prevent such firms from failing. Unfortunately, the fears proved well founded: The bankruptcy of Lehman Brothers Holdings--the largest bankruptcy filing in American history--significantly exacerbated the crisis.3\n\nTo increase the viability of the Bankruptcy Code as a framework for resolving failed financial firms without major systemic consequences, section 165(d) of the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010 (Dodd-Frank Act) requires large banking organizations to produce resolution plans, also known as living wills, demonstrating how they could be resolved under the Bankruptcy Code in an orderly fashion in the event of failure.\n\nAlthough the Bankruptcy Code provides the default legal framework for the resolution of a failed bank holding company, Title II of the Dodd-Frank Act creates a backup resolution framework, called the orderly liquidation authority, to be used if the resolution of a failed financial company under the Bankruptcy Code would have serious adverse effects on U.S. financial stability. If that criterion and several others are met, Title II allows the Secretary of the Treasury to appoint the FDIC as receiver for the failed financial company as an alternative to a bankruptcy resolution overseen by a judge. The orderly liquidation authority has several features that could reduce the systemic effect of a financial company's failure relative to a bankruptcy resolution, including an orderly liquidation fund to provide government liquidity support for the failed firm and provisions to prevent the unwinding of the failed firm's derivatives and other qualified financial contracts while they are transferred to a solvent firm.\n\nThe Federal Reserve Board has recently proposed important new rules to increase the prospects for the orderly resolution of a GSIB with minimal effect on financial stability. Last October, the Board proposed a rule to subject the eight U.S. GSIBs to total loss-absorbing capacity (TLAC) and long-term debt requirements, building on the international TLAC standard established by the Financial Stability Board.4 The proposal would require these systemically important firms to maintain outstanding a large quantity of long-term debt that could be used to absorb losses and recapitalize the firm in an orderly resolution under either the Bankruptcy Code or the orderly liquidation authority.5\n\nThe proposal would also apply internal TLAC and long-term debt requirements to the U.S. intermediate holding companies of foreign GSIBs in order to facilitate the recapitalization of a failed foreign GSIB's U.S. operations. Finally, the proposal would restrict the operations of GSIB holding companies (as distinct from their operating subsidiaries) so that those legal entities could go through a resolution proceeding without setting off short-term wholesale funding runs or otherwise jeopardizing financial stability.\n\nIn May of this year, the Board issued another proposal to make GSIBs more resolvable. This second proposed rule would impose restrictions on GSIBs' qualified financial contracts--including derivatives and repo agreements--to guard against the mass unwinding of those contracts during the resolution of a GSIB.6 The proposed restrictions are a key step toward GSIB resolvability because the rapid unwinding of a GSIB's qualified financial contracts could destabilize the financial system by causing asset fire sales and toppling other firms.\n\nActing in conjunction with the FDIC, the Federal Reserve Board has also sought to increase GSIB resolvability through its review of the firms' living wills. In April this year, the Board and the FDIC announced the results of their review of the eight U.S. GSIBs' 2015 resolution plans, which evaluated the plans based on the firms' capital, liquidity, governance mechanisms, operational capabilities, legal entity rationalization, derivatives and trading activities, and responsiveness to prior agency feedback.7\n\nThe agencies found that five of the GSIBs' plans fell short of the Dodd-Frank Act's standard and required those firms to fix the deficiencies in their plans by October of this year or potentially face more stringent prudential requirements. The agencies also identified less-severe shortcomings in the plans of all eight GSIBs, which the GSIBs are expected to address in their next round of resolution plan submissions, due in July 2017. The deficiencies and shortcomings identified by the agencies touched on most of the categories I have just listed, especially liquidity, governance mechanisms, operational capabilities, and legal entity rationalization.\n\nI want to end by briefly addressing several criticisms that have been made of the Dodd-Frank Act's orderly liquidation authority and the Board's TLAC proposal. One criticism is that there is no need for the backup orderly liquidation authority because the Bankruptcy Code provides an adequate framework for the resolution of any financial company. As Title II of the Dodd-Frank Act recognizes, however, the Bankruptcy Code may not be adequate to minimize the systemic impact of the resolution of a systemically important financial firm. The Bankruptcy Code does not direct the judge to take financial stability into account in making decisions, and it does not provide other important stabilizing features of the orderly liquidation authority, such as government liquidity support and stay-and-transfer treatment for qualified financial contracts.\n\nA related line of criticism holds that the orderly liquidation authority enshrines \"too big to fail\" and provides for taxpayer bailouts of systemically important firms through the orderly liquidation fund. However, under the Board's proposed TLAC rule, a failed GSIB would be recapitalized by its private-sector long-term creditors (whose debt claims would be converted into equity), not by the government. The orderly liquidation fund would be used only to provide liquidity support, not to inject capital, and in the unlikely event that the fund does incur losses, the Dodd-Frank Act provides that these losses would be covered by assessments on major financial companies and would not be passed on to taxpayers. I also note that credit rating agencies have recognized public-sector efforts to end the too-big-to-fail phenomenon. The rating agencies no longer assume that the U.S. government will take extraordinary actions to prevent the failure of systemically important U.S. financial firms.\n\nFinally, one criticism that has been leveled at our TLAC proposal is that imposing long-term debt requirements on GSIBs will lead those firms to increase their leverage and thereby raise their probability of failure, and that they should instead be required to hold higher levels of equity capital. I agree that equity capital plays a key role in preventing financial firm failures, and we have raised equity capital requirements for banking organizations--especially GSIBs--substantially since the crisis. But to protect financial stability, we must reduce not only the probability that a GSIB will fail, but also the damage that its failure could do if it were to occur. At the point of failure, a banking firm's equity capital is likely to be zero or negative, so to improve GSIB resolvability, our proposal requires GSIBs to have a thick tranche of gone-concern loss-absorbing capacity to ensure that resolution authorities will have the necessary raw material to manufacture fresh equity and recapitalize and stabilize the firm.8 That is the role played by the proposal's long-term debt requirements. And we expect that firms would generally come into compliance with the proposed requirements by replacing existing ineligible liabilities with eligible long-term debt rather than by increasing their leverage. At any rate, even if a firm were to come into compliance in part by increasing the size of its balance sheet, it would remain subject to our robust equity capital requirements and leverage limits, which are designed to ensure a very low probability of failure. Finally, the existence of a thick tranche of loss-absorbing long‑term debt should reduce a GSIB's probability of failure by reducing its short-term creditors' incentives to run at the first sign of distress.\n\nIn short, we and other U.S. regulators are working hard to address the too-big-to-fail problem by improving the prospects for the orderly resolution of a GSIB in the United States. The Dodd-Frank Act gave us tools to reduce the probability of failure of our largest and most complex banking firms and to significantly reduce the damage that the failure of such a firm would do to the U.S. financial system and the broader economy. We have made a lot of progress toward accomplishing these goals, leaving the U.S. banking system fundamentally safer and stronger, and our work in this area will continue.\n\nThank you.\n\n1. I am grateful to Mark Van Der Weide, Barbara Bouchard and Mark Savignac of the Federal Reserve Board for their assistance in the preparation of these comments. Return to text\n\n2. The average (per bank) assets of the 465 banks resolved by the FDIC between 2008 and 2012 was roughly $1.5 billion, with a total of $680.3 billion. The largest depository institution ever resolved by the FDIC was Washington Mutual, which was resolved in 2008 and had total assets of $307 billion prior to failure. Return to text\n\n3. Lehman's pre-bankruptcy total assets were $691 billion. The second-largest bankruptcy in American history was the bankruptcy of Washington Mutual, Inc., the savings and loan holding company that owned Washington Mutual; its pre-failure total assets were nearly $328 billion. Both Lehman and Washington Mutual filed for bankruptcy in September 2008. Return to text\n\n4. Board of Governors of the Federal Reserve System (2015), \"Federal Reserve Board Proposes New Rule to Strengthen the Ability of Largest Domestic and Foreign Banks Operating in the United States to Be Resolved without Extraordinary Government Support or Taxpayer Assistance,\" press release, October 30. Return to text\n\n5. Under the proposal, a U.S. GSIB would be required to hold at a minimum (i) a long-term debt amount of the greater of 6 percent plus its GSIB surcharge of risk-weighted assets and 4.5 percent of total leverage exposure and (ii) a TLAC amount of the greater of 18 percent of risk-weighted assets and 9.5 percent of total leverage exposure. See Board of Governors of the Federal Reserve System (2015), \"Total Loss-Absorbing Capacity, Long-Term Debt, and Clean Holding Company Requirements for Systemically Important U.S. Bank Holding Companies and Intermediate Holding Companies of Systemically Important Foreign Banking Organizations; Regulatory Capital Deduction for Investments in Certain Unsecured Debt of Systemically Important U.S. Bank Holding Companies,\" notice of proposed rulemaking (Docket No. R‑1523), Federal Register, vol. 80 (November 30), pp. 74931-32. The GSIB has to satisfy both constraints. TLAC encompasses both equity capital and eligible long-term debt. Return to text\n\n6. See Board of Governors of the Federal Reserve System (2016), \"Federal Reserve Board Proposes Rule to Support U.S. Financial Stability by Enhancing the Resolvability of Very Large and Complex Financial Firms,\" press release, May 3. Return to text\n\n7. See Board of Governors of the Federal Reserve System and Federal Deposit Insurance Corporation (2016), \"Agencies Announce Determinations and Provide Feedback on Resolution Plans of Eight Systemically Important, Domestic Banking Institutions,\" joint press release, April 13. Return to text\n\n8. See Board of Governors (2015), \"Total Loss-Absorbing Capacity, Long-Term Debt, and Clean Holding Company Requirements,\" in note 5. Under the proposal, a U.S. GSIB would be subject to external long-term debt requirements of 6 percent of risk-weighted assets plus the amount of the risk-based capital surcharge applicable to the GSIB under the Board's GSIB surcharge rule and 4.5 percent of total leverage exposure. Return to text"
    },
    {
        "speaker": "Jerome H. Powell",
        "position": "Governor",
        "date": "June 21, 2016",
        "title": "Introductory Comments",
        "href": "https://www.federalreserve.gov/newsevents/speech/powell20160621a.htm",
        "content": "June 21, 2016\n\nGovernor Jerome H. Powell\n\nAt the Roundtable on the Interim Report of the Alternative Reference Rates Committee sponsored by the Federal Reserve Board and the Federal Reserve Bank of New York, New York, New York\n\nI want to thank you all for coming today, and I also want to thank the Alternative Reference Rates Committee (ARRC) for all its work in developing its interim report. This report marks a new stage in reference rate reform.1 Reference benchmarks are a key part of the financial infrastructure. About $300 trillion dollars in contracts reference LIBOR alone. But benchmarks were not given much consideration prior to the recent scandals involving attempts to manipulate them. Since then, the official sector has thought seriously about financial benchmarks, conducting a number of investigations into charges of manipulation, publishing the International Organization of Securities Commission's (IOSCO) Principles for Financial Benchmarks and, through the Financial Stability Board (FSB), sponsoring major reform efforts of both interest rate and foreign exchange benchmarks.2 The institutions represented on the ARRC have also had to think seriously about these issues as they have developed this interim report. Now, we need end users to begin to think more seriously about how they use benchmarks and the risks they are taking on by relying so heavily on a reference rate--in this case U.S. dollar LIBOR--that is less resilient than it needs to be.\n\nIn saying this, I want to make it clear that LIBOR has been significantly improved. ICE Benchmark Administration is in the process of making important changes to its methodology, and submissions to LIBOR are now regulated by the United Kingdom's Financial Conduct Authority. However, the term money market borrowing by banks that underlies U.S. dollar LIBOR has experienced a secular decline. As a result, the majority of U.S. dollar LIBOR submissions must still rely on expert judgement, and even those submissions that are transaction-based may be based on relatively few actual trades. This calls into question whether LIBOR can ultimately satisfy IOSCO Principle 7 regarding data sufficiency, which requires that a benchmark be based on an active market. That Principle is a particularly important one, as it is difficult to ask banks to submit rates at which they believe they could borrow on a daily basis if they do not actually borrow very often.\n\nThat basic fact poses the risk that LIBOR could eventually be forced to stop publication entirely. Ongoing regulatory reforms and changing market structures raise questions about whether the transactions underlying LIBOR will become even scarcer in the future, particularly in periods of stress, and banks might feel little incentive to contribute to U.S. dollar LIBOR panels if transactions become less frequent. Market participants are not used to thinking about this possibility, but benchmarks sometimes come to a halt. The sudden cessation of a benchmark as heavily used as LIBOR would present significant systemic risks. It could entail substantial losses and would create substantial uncertainty, potential legal challenges, and payments disruptions for the market participants that have relied on LIBOR. These disruptions would be even greater if there were no viable alternative to U.S. dollar LIBOR that market participants could quickly move to.\n\nThese concerns led the FSB and Financial Stability Oversight Council to call for the promotion of alternatives to LIBOR, and led the Federal Reserve to convene the ARRC in cooperation with the U.S. Treasury Department, U.S. Commodity Futures Trading Commission, and Office of Financial Research. LIBOR is currently the dominant reference rate in the market because of its liquidity. We are not under any illusions that moving a significant portion of trading to an alternative rate will be simple or easy. But I believe the ARRC has provided a workable and credible plan for creating liquidity in a new rate and beginning the process of moving trading to it.\n\nWe need input from end users and others to finalize the ARRC's plans, and I look forward to hearing the views of those in attendance. Successful implementation will require a coordinated effort from a broad set of market participants. This effort will certainly entail costs, but continued reliance on U.S. dollar LIBOR on the current scale could entail much higher costs if unsecured short-term borrowing declines further and submitting banks choose to leave the LIBOR panels, especially if there were no viable alternative rate. Simply put, this effort is something that needs to happen, and if the ARRC members, the official sector, and end users and other market participants all jointly coordinate in finalizing these plans, then a successful transition can be made with the least disruption to the market, leaving everyone in a better place.\n\n1. See Alternative Reference Rates Committee (2016), Interim Report and Consultation (PDF) (New York: ARRC, May). Return to text\n\n2. For more information on the IOSCO principles, see Board of the International Organization of Securities Commissions (2013), Principles for Financial Benchmarks: Final Report (PDF) (Madrid: IOSCO, July). Return to text"
    },
    {
        "speaker": "Janet L. Yellen",
        "position": "Chair",
        "date": "June 06, 2016",
        "title": "Current Conditions and the Outlook for the U.S. Economy",
        "href": "https://www.federalreserve.gov/newsevents/speech/yellen20160606a.htm",
        "content": "June 06, 2016\n\nChair Janet L. Yellen\n\nAt The World Affairs Council of Philadelphia, Philadelphia, Pennsylvania\n\nI am delighted to be with you today. I will discuss recent economic developments, the outlook, and their implications for monetary policy. My message will be largely favorable, although recent developments have been mixed. Most importantly, the economy has registered considerable progress over the past several years toward the Federal Reserve's goals of maximum employment and price stability, and, as I will explain, there are good reasons to expect that we will advance further toward those goals. The news from the labor market over the past year has been generally good, with significant job gains, the unemployment rate declining below 5 percent, rising household incomes, and tentative signs of faster wage growth. At the same time, recent signs of a slowdown in job creation bear close watching. Inflation has been lower than our objective of 2 percent, but I expect it to move up over time for reasons that I will describe. If incoming data are consistent with labor market conditions strengthening and inflation making progress toward our 2 percent objective, as I expect, further gradual increases in the federal funds rate are likely to be appropriate and most conducive to meeting and maintaining those objectives. However, I will emphasize that monetary policy is not on a preset course and significant shifts in the outlook for the economy would necessitate corresponding shifts in the appropriate path of policy.\n\nIn particular, an important theme of my remarks today will be the inevitable uncertainty surrounding the outlook for the economy. Unfortunately, all economic projections are certain to turn out to be inaccurate in some respects, and possibly significantly so. Will the economic situation in Europe or China take a turn for the worse or exceed expectations? Will U.S. productivity growth pick up and allow stronger growth of gross domestic product (GDP) and incomes or instead continue to stagnate? What will happen with the price of oil? The uncertainties are sizable, and progress toward our goals and, by implication, the appropriate stance of monetary policy will depend on how these uncertainties evolve. Indeed, the policy path that my colleagues and I judge most likely to achieve and maintain maximum employment and price stability has evolved and will continue to evolve in response to developments that alter our economic outlook and the associated risks to that outlook.\n\nThe Current Economic Situation\nThe economic expansion following the Great Recession has now been under way for seven years. The recovery has not always been smooth, but overall, the gains have been impressive. In particular, the job market has strengthened substantially, and I believe we are now close to eliminating the slack that has weighed on the labor market since the recession.\n\nI will turn to this past Friday's labor market report in a moment, but let me begin with some background: The economy added 2.7 million jobs last year, an average of about 230,000 a month. In the first three months of this year, payrolls were growing only modestly slower, at a little less than a 200,000 monthly pace. The unemployment rate had fallen to 5 percent, down from a peak of 10 percent in 2009. In addition, the Bureau of Labor Statistics' measure of the job openings rate was at a record high in March, and the quits rate--the share of employees voluntarily leaving their jobs--has moved up and in March stood close to its pre-recession levels.1 The increase in the quits rate is a sign that workers are feeling more confident about the job market and are likely receiving more job offers.\n\nSo the overall labor market situation has been quite positive. In that context, this past Friday's labor market report was disappointing. Payroll gains were reported to have been much smaller in April and May than earlier in the year, averaging only about 80,000 per month.2 And while the unemployment rate was reported to have fallen further in May, that decline occurred not because more people had jobs but because fewer people reported that they were actively seeking work. A broader measure of labor market slack that includes workers marginally attached to the workforce and those working part-time who would prefer full-time work was unchanged. An encouraging aspect of the report, however, was that average hourly earnings for all employees in the nonfarm private sector increased 2-1/2 percent over the past 12 months--a bit faster than in recent years and a welcome indication that wage growth may finally be picking up.3\n\nAlthough this recent labor market report was, on balance, concerning, let me emphasize that one should never attach too much significance to any single monthly report. Other timely indicators from the labor market have been more positive. For example, the number of people filing new claims for unemployment insurance--which can be a good early indicator of changes in labor market conditions--remains quite low, and the public's perceptions of the health of the labor market, as reported in various consumer surveys, remain positive. That said, the monthly labor market report is an important economic indicator, and so we will need to watch labor market developments carefully.\n\nEconomic conditions here in the Philadelphia metropolitan area have improved broadly in line with national trends. During the downturn, the Philadelphia area and the city itself saw unemployment rise by less than it did for the nation as a whole, but unemployment took longer to recover thereafter.4 In the City of Philadelphia, in particular, unemployment was still running above 10 percent as recently as 2013. But unemployment here has fallen appreciably since then, helped by a revival in residential and commercial construction that is evident around the city.\n\nWhile the general picture of the labor market is largely positive, some people are still struggling. Unemployment rates rose more during the recession for African Americans and Hispanics than for the nation overall, and even though those rates have also come down by more during the economic expansion, unemployment remains higher for these groups. Unfortunately, those gaps have not narrowed noticeably relative to where they were before the recession. Unemployment rates for young African American and Hispanic men without a college degree remain especially high, and one important benefit from further improvement in the labor market would be increased job opportunities for these men and other groups that currently still experience high unemployment. To be sure, many of the factors that contribute to the labor market outcomes of minority groups are not amenable to monetary policy, and measures beyond the scope of monetary policy should be considered to alleviate the economic challenges that these and other Americans face. Education and training, of course, are vital. Later today, I will visit one program that helps workers in West Philadelphia learn new skills and then connects them with potential employers, an initiative in which government, businesses, and local institutions are working together successfully.\n\nWhile the economy has made great strides toward the FOMC's objective of maximum employment, somewhat less progress has been made toward our inflation objective. Inflation has run persistently below the Fed's goal of 2 percent over the past several years even as the labor market strengthened significantly.5 Over the 12 months through April, the price index for personal consumption expenditures rose only about 1 percent. But I remain optimistic, because two factors that have been holding down inflation will likely prove only temporary. First, the sharp drop in crude oil prices since the middle of 2014 has lowered prices of gasoline and other energy products, significantly restraining overall inflation. At about the same time, the foreign exchange value of the dollar strengthened, holding down prices of imported goods. But oil prices have stopped declining and indeed have risen from their low point earlier this year. And, since the beginning of the year, the dollar has been roughly unchanged against a broad basket of currencies. As the downward pressure on prices from these two forces dissipates and as the labor market strengthens further, I expect inflation to move back to 2 percent.\n\nThe Economic Outlook\nLet me now turn to the outlook for the economy. GDP growth was reported to have been relatively weak early this year, but this measure of growth in economic activity can vary significantly from quarter to quarter. Indeed, while spending data for the second quarter are limited at present, recent data on retail sales and motor vehicle sales point to a significant step-up in consumer spending and GDP growth this quarter.6\n\nStepping back from near-term indicators, I would like to focus more broadly on the factors likely to affect economic performance over the coming years. Next week, concurrent with our policy meeting, the FOMC participants will release a new set of economic projections. Those could, of course, differ from the previous set of such projections in March. But speaking for myself, although the economy recently has been affected by a mix of countervailing forces, I see good reasons to expect that the positive forces supporting employment growth and higher inflation will continue to outweigh the negative ones. As a result, I expect the economic expansion to continue, with the labor market improving further and GDP growing moderately. And as I just noted, I expect to see inflation moving up to 2 percent over the next couple of years.\n\nLet me start with the positive. The increase in employment over the past several years has contributed to higher household incomes and strengthening consumer confidence. If the May labor report was an aberration or reflects a temporary slowdown resulting from the weakness in economic activity at the start of the year, then job growth should pick up and support further gains in income. In addition, rising equity and house prices have helped restore households' wealth. The fall in oil prices has supported household purchasing power as well. Simple calculations suggest that the average household has gained some $1,300 in purchasing power since mid-2014 from the fall in gasoline prices.7 With continuing gains in disposable income and wealth, I expect consumer spending to grow at a solid rate. I also expect the housing sector to make further progress. Both home sales and construction have been gradually improving, and residential investment made a noticeable contribution to GDP growth over the past year. Housing has been supported by low mortgage rates, and while mortgage credit is still difficult to obtain for households with low credit scores or hard-to-document income, those with good credit histories are generally able to borrow at very favorable terms.8 And fiscal policy at the combined national, state, and local levels, which subtracted from GDP growth for much of recovery, is now a small positive.\n\nEconomists often say, \"on the other hand.\" So, in keeping with that tradition, I'll now turn to the less-positive. Economic developments abroad have significantly restrained growth in the United States over the past year, although I am cautiously optimistic that these headwinds are now fading. Concerns about slowing growth in China and falling commodity prices, which afflicted global financial markets early this year and thus likely weighed on demand, appear to have eased somewhat. Indicators suggest that foreign economies are growing, if still at only a moderate pace, and foreign financial markets have recovered and stabilized. That said, net exports have been a drag on U.S. GDP growth over the past year and are likely to continue to weigh on growth over the medium term. This drag, in part, reflects the prolonged effects of the significant increase in the foreign exchange value of the dollar since the middle of 2014, a development that has been particularly challenging for U.S. manufacturers and other firms competing with foreign producers.\n\nAlthough lower oil prices have likely been a positive influence on the U.S. economy overall, they also have had a negative side, given the sizable U.S. energy industry. New drilling and energy-sector employment have plunged, and the effects have spilled over to businesses serving the energy production sector. But the largest declines in drilling activity are likely now behind us, and with oil prices having recovered somewhat, I expect that oil prices will become less of a factor.\n\nBusiness investment has been weak in the past six months or so, even beyond the energy sector, and investment in capital equipment is reported to have declined in the last quarter of 2015 and first quarter of this year. I suspect there is a transitory element to this weak investment performance, and I expect investment to rebound. But the latest labor market data raise the less favorable possibility that firms may instead have decided to expand their operations more slowly, and I intend to continue to pay close attention to developments in this area.\n\nAs I said, the positive economic forces have outweighed the negative, and despite the challenges that the economy continues to face, I continue to expect further progress toward our employment and inflation objectives.\n\nSome Important Uncertainties\nTo be sure, there is considerable uncertainty about the economic outlook that I have been discussing, and, as I have already noted, we should expect to be surprised in the future just as we have been surprised in the past. Four areas of uncertainty seem particularly salient at present.\n\nThe first involves the thrust and resilience of domestic demand. The U.S. economy has performed better than many others around the globe, and that performance has relied chiefly on the resilience of domestic sources of demand, consumer spending in particular. So an important question is whether the U.S. economy could continue to make progress amid fairly considerable global bumpiness. I continue to think that the answer to that question is yes, but the weak investment performance in recent months is concerning, and Friday's employment report provides another reminder that the question is still relevant.\n\nThe second uncertainty pertains to the economic situation abroad. Even though the financial stresses that had emanated from abroad at the start of this year have eased, global risks require continued attention. Much of the turmoil early this year appeared to be associated with concern over the outlook for Chinese growth, which in turn has broad implications for commodity prices and global economic growth. Recently, the renminbi has moved in a more predictable fashion and Chinese capital outflows have abated. However, it is widely acknowledged that China faces considerable challenges as it continues to rebalance its economy toward domestic demand and consumption.\n\nMore generally, in the current environment of sluggish growth, low inflation, and already very accommodative monetary policy in many advanced economies, investor perceptions of and appetite for risk can change abruptly. One development that could shift investor sentiment is the upcoming referendum in the United Kingdom. A U.K. vote to exit the European Union could have significant economic repercussions.\n\nA third key uncertainty for the U.S. economy is the outlook for productivity growth--that is, increases in the amount of output produced per hour worked. While the job market has strengthened significantly, GDP increases have been less impressive. That combination of solid labor market gains and moderate GDP growth reflects the fact that labor productivity growth has been unusually weak in recent years, averaging less than 1/2 percent per year since 2010.9\n\nOver time, productivity growth is the key determinant of improvements in living standards, supporting higher pay for workers without increased costs for employers. Recent weak productivity growth likely helps account for the disappointing pace of wage gains during this economic expansion. Therefore, understanding whether, and by how much, productivity growth will pick up is a crucial part of the economic outlook. But this is a very difficult question, and economists are divided. Some are relatively optimistic, pointing to the ongoing pace of innovations that promise revolutionary technologies, from genetically tailored medical therapies to self-driving cars. Others believe that the low-hanging fruit of innovation largely has been picked and that there is simply less scope for further gains.10\n\nMy position has been, and remains, cautiously optimistic. There is some evidence that the deep recession had a long-lasting effect in depressing investment, research and development spending, and the start-up of new firms, and that these factors have, in turn, lowered productivity growth. With time, I expect this effect to ease in a stronger economy.11 I also see no obvious slowdown in the pace or the potential benefits of innovation in America, which likewise may bear fruit more readily in a stronger economy. In the meantime, it would be helpful to adopt public policies designed to boost productivity. Strengthening education and promoting innovation and investment, public and private, will support longer-term growth in productivity and greater gains in living standards.\n\nA fourth important uncertainty for the economic outlook involves how quickly inflation will move back to 2 percent. As long as oil prices do not resume their earlier declines and the dollar does not rise substantially further, my expectation is that inflation will move up to 2 percent over the next one to two years. But oil prices and the dollar can move unpredictably. In addition, a further strengthening of labor market conditions would typically be estimated to exert modest upward pressure on inflation over the next couple of years; but such estimates are inherently imprecise, and the effect on inflation could turn out to be significantly different, either upward or downward, than I expect.\n\nUncertainty concerning the outlook for inflation also reflects, in part, uncertainty about the behavior of those inflation expectations that are relevant to price setting. For two decades, inflation has been relatively stable, reacting less persistently than before to temporary factors like a recession or a swing in oil prices. The most convincing explanation for this stability, in my view, is that longer-term inflation expectations have remained quite stable.12 So it bears noting that some survey measures of longer-term inflation expectations have moved a little lower over the past couple of years, while proxies for these expectations inferred from financial market instruments like inflation-protected securities have moved down more noticeably. It is unclear whether these indicators point to a true decline in those inflation expectations that are relevant for price setting; for example, the financial market measures may reflect changing attitudes toward inflation risk more than actual inflation expectations. But the indicators have moved enough to get my close attention. If inflation expectations really are moving lower, that could call into question whether inflation will move back to 2 percent as quickly as I expect.\n\nPolicy Implications\nLet me now turn to the implications of the economic outlook, as well as the uncertainties associated with that outlook, for monetary policy. My overall assessment is that the current stance of monetary policy is generally appropriate, in that it is providing support to the economy by encouraging further labor market improvement that will help return inflation to 2 percent. At the same time, I continue to think that the federal funds rate will probably need to rise gradually over time to ensure price stability and maximum sustainable employment in the longer run.\n\nSeveral considerations lead me to this conclusion. First, the current stance of monetary policy is stimulative, although perhaps not as stimulative as might appear at first glance. One useful measure of the stance of policy is the deviation of the federal funds rate from a \"neutral\" value, defined as the level of the federal funds rate that would be neither expansionary nor contractionary if the economy was operating near potential. This neutral rate changes over time, and, at any given date, it depends on a constellation of underlying forces affecting the economy. At present, many estimates show the neutral rate to be quite low by historical standards--indeed, close to zero when measured in real, or inflation-adjusted, terms.13 The current actual value of the federal funds rate, also measured in real terms, is even lower, somewhere around minus 1 percent. With the actual real federal funds rate modestly below the relatively low neutral real rate, the stance of monetary policy at present should be viewed as modestly accommodative.14\n\nAlthough the economy is now fairly close to the FOMC's goal of maximum employment, I view our modestly accommodative stance of policy as appropriate for several reasons. First, with inflation continuing to run below our objective, a mild undershooting of the unemployment rate considered to be normal in the longer run could help move inflation back up to 2 percent more quickly. Second, a stronger job market could also support labor market improvement along other dimensions, including greater labor force participation. A third reason relates to the risks associated with the constraint on conventional monetary policy when the federal funds rate is near zero. If inflation were to move persistently above 2 percent or the economy were to become notably overheated, the Committee could readily increase the target range for the federal funds rate. However, if inflation were to remain persistently low or the expansion were to falter, the FOMC would be able to provide only a limited amount of additional stimulus through conventional means.15\n\nThese motivations notwithstanding, I continue to believe that it will be appropriate to gradually reduce the degree of monetary policy accommodation, provided that labor market conditions strengthen further and inflation continues to make progress toward our 2 percent objective. Because monetary policy affects the economy with a lag, steps to withdraw this monetary accommodation ought to be initiated before the FOMC's goals are fully reached. And if the headwinds that have lingered since the crisis slowly abate as I anticipate, this would mean that the neutral rate of interest itself will move up, providing further impetus to gradually increase the federal funds rate. But I stress that the economic outlook, including the pace at which the neutral rate may shift over time, is uncertain, so monetary policy cannot proceed on any preset path.16\n\nThis point is well illustrated by events so far this year. For a time in January and early February, financial markets here and abroad became turbulent and financial conditions tightened, reflecting and reinforcing concerns about downside risks to the global economy. In addition, data received during the winter suggested that U.S. growth had weakened even as progress in the labor market remained solid. Because the implications of these developments for the economic outlook were unclear, the FOMC decided at its January, March, and April meetings that it would be prudent to maintain the existing target range for the federal funds rate.\n\nOver the past few months, financial conditions have recovered significantly and many of the risks from abroad have diminished, although some risks remain. In addition, consumer spending appears to have rebounded, providing some reassurance that overall growth has indeed picked up as expected. Unfortunately, as I noted earlier, new questions about the economic outlook have been raised by the recent labor market data. Is the markedly reduced pace of hiring in April and May a harbinger of a persistent slowdown in the broader economy? Or will monthly payroll gains move up toward the solid pace they maintained earlier this year and in 2015? Does the latest reading on the unemployment rate indicate that we are essentially back to full employment, or does relatively subdued wage growth signal that more slack remains? My colleagues and I will be wrestling with these and other related questions going forward.\n\nConclusion\nTo summarize, I have explained why I expect the U.S. economy will continue to improve and why I expect that further gradual increases in the federal funds rate will probably be appropriate to best promote the FOMC's goals of maximum employment and price stability. I have also laid out the considerable and unavoidable uncertainties that apply to both this outlook for the economy and to the appropriate path of the federal funds rate. My colleagues and I will make our policy decisions based on what incoming information implies for the economic outlook and the risks to that outlook. What is certain is that monetary policy is not on a preset course, and that the Committee will respond to new data and reassess risks so as to best achieve our goals.\n\nReferences\nBrynjolfsson, Erik, and Andrew McAfee (2014). The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies. New York: W.W. Norton & Company.\n\nByrne, David M., John G. Fernald, and Marshall B. Reinsdorf (2016). \"Does the United States Have a Productivity Slowdown or a Measurement Problem? \" Brookings Papers on Economic Activity, March 4.\n\nCowen, Tyler (2011). The Great Stagnation: How America Ate All the Low-Hanging Fruit of Modern History, Got Sick, and Will (Eventually) Feel Better. New York: Dutton.\n\nFernald, John G. (2015). \"Productivity and Potential Output before, during, and after the Great Recession,\" in Jonathan A. Parker and Michael Woodford, eds., NBER Macroeconomics Annual 2014, vol. 29. Chicago: University of Chicago Press, pp. 1-51.\n\nGordon, Robert J. (2016). The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War. Princeton, N.J.: Princeton University Press.\n\nJohannsen, Benjamin K., and Elmar Mertens (2016). \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, February 9.\n\nLaubach, Thomas, and John C. Williams (2016). \"Measuring the Natural Rate of Interest Redux (PDF),\" Finance and Economics Discussion Series 2016-011. Washington: Board of Governors of the Federal Reserve System, February.\n\nLubik, Thomas A., and Christian Matthes (2015). \"Calculating the Natural Rate of Interest: A Comparison of Two Alternative Approaches (PDF) ,\" Economic Brief 15-10. Richmond: Federal Reserve Bank of Richmond, October.\n\nMokyr, Joel (2014). \"Secular Stagnation? Not in Your Life (PDF) ,\" in Coen Teulings and Richard Baldwin, eds., Secular Stagnation: Facts, Causes and Cures. London: CEPR Press, pp. 83-89.\n\nReifschneider, Dave, William Wascher, and David Wilcox (2015). \"Aggregate Supply in the United States: Recent Developments and Implications for the Conduct of Monetary Policy,\" IMF Economic Review, vol. 63 (April), pp. 71-109.\n\nYellen, Janet L. (2015a). \"Inflation Dynamics and Monetary Policy,\" speech delivered at the Philip Gamble Memorial Lecture, University of Massachusetts, Amherst, Amherst, Mass., September 24.\n\nYellen, Janet L. (2015b). \"The Economic Outlook and Monetary Policy,\" speech delivered at the Economic Club of Washington, Washington, December 2.\n\n\n\n1. Note, however, that the help-wanted index published by the Conference Board suggests that the rate of job openings has been about flat over the past year. Return to text\n\n2. Payroll employment is now reported to have increased 123,000 in April and 38,000 in May. According to the Bureau of Labor Statistics, payrolls in May were held down about 35,000 by workers on strike at Verizon; thus, the strike can account for a relatively small portion of the slowdown in payroll growth in May. The Verizon workers are now back on the job and should be included in the June payroll counts. Return to text\n\n3. Hourly compensation in the business sector (a measure that includes benefit costs as well as wages) is now reported to have increased about 3 percent over the year ended in the first quarter of 2016, somewhat above the average increase in this series over the preceding several years. In addition, according to the Federal Reserve Bank of Atlanta's \"wage growth tracker,\" wage gains for continuously employed full-time workers have been gradually trending higher in recent years and were 3-1/2 percent over the 12 months through April. However, the employment cost index, another broad measure of labor compensation costs, has remained quite soft, rising only 1-3/4 percent over the year ended in March. Return to text\n\n4. The discussion refers to data for the Philadelphia-Camden-Wilmington, PA-NJ-DE-MD Metropolitan Statistical Area. Since 1990, the area's unemployment rate has averaged about 1/4 percentage point lower than the national rate. By contrast, in the City of Philadelphia itself, the unemployment rate has generally run about 2 percentage points higher than for the broader metropolitan area. Return to text\n\n5. The notion that inflation can be too low sounds strange to many people, but very low inflation typically means very low nominal interest rates, leaving little room for monetary policy to push rates down to offset adverse shocks to the economy, thereby increasing the chances that recessions and the associated job losses would be more severe and persistent. In addition, persistent and unexpectedly low inflation may significantly raise the real cost of making mortgage and other loan payments if accompanied by (as is typically the case) smaller-than-anticipated nominal income gains. Return to text\n\n6. On a seasonally adjusted basis, sales of light motor vehicles fell to an annual rate of 16.5 million units in March but then rebounded to a pace of 17.3 million units in April and 17.4 million units in May. Return to text\n\n7. In 2013, according to the Energy Information Agency, households purchased about 730 gallons per household on average. Applying the drop in gasoline prices since the first half of 2014, savings per household averaged about $110 in the second half of 2014, $780 in 2015, and another $420 through May of this year, implying a cumulative overall gain of more than $1,300 per household on average. Return to text\n\n8. Housing could receive another boost if there were a continued revival in the rate of new household formation, which has been depressed since the recession as young adults have delayed moving out of their parents' homes. Return to text\n\n9. The figures measure output per hour worked in the business sector. From 2007:Q4 through 2016:Q1, productivity growth averaged about 1 percent per year. By comparison, business-sector productivity growth averaged 1-1/2 percent per year over the two decades from the mid-1970s to the mid-1990s, and then it averaged 2-3/4 percent per year over the next dozen years until the latest recession began. Return to text\n\n10. On the relatively optimistic side, see Mokyr (2014) or Brynjolfsson and McAfee (2014). For a less optimistic perspective, see Gordon (2016) or Cowen (2011). Similarly, Fernald (2014) dates the most recent slowdown in measured productivity growth to before the great recession, in 2005. For evidence that the recent slowdown cannot be fully explained by measurement difficulties, see Byrne, Fernald, and Reinsdorf (2016). Return to text\n\n11. See Reifschneider, Wascher, and Wilcox (2015). Return to text\n\n12. For a more detailed discussion, see Yellen (2015a). Return to text\n\n13. The neutral rate is not directly observable and must instead be inferred from economic data, and estimates will vary depending on the methodology employed. However, we know that the neutral rate must have been well below its historical norm in recent years, because with the actual real interest having been as low as it has been lately, the economy would have otherwise expanded much more than has been the case. In recent years, the neutral rate has likely been held down below normal levels because of the factors I discussed earlier, including persistently weak growth abroad, the high exchange value of the dollar, low rates of household formation, and weak productivity growth. As I have noted before (see Yellen, 2015b), there is empirical evidence to support the conclusion that the neutral rate is currently not far from zero. See, in particular, Lubik and Matthes (2015), Laubach and Williams (2016), and Johanssen and Mertens (2016). Return to text\n\n14. The targeted federal funds rate, currently 0.37 percent, less the 12-month core inflation rate for personal consumption expenditures through April, equals about negative 1.2 percent. Return to text\n\n15. There are unconventional policy tools that could be employed to provide further support to aggregate demand, if necessary, and the efficacy and costs of using those tools would be weighed by the FOMC, as appropriate. However, so long as these tools are considered imperfect substitutes for the federal funds rate as an instrument of policy, the argument that the effective lower bound on nominal interest rates represents a source of asymmetric risk remains valid. Return to text\n\n16. Uncertainty about where the target range for the federal funds rate will be in the long run provides another reason why increases in policy rates cannot be on a preset path. I view the median value of 3-1/4 percent from the March SEP as being a reasonable guess for the longer-run normal rate. But FOMC participants have lowered their estimates of the longer-run normal rate over time, and as new evidence comes in and we see how economic conditions evolve, further changes, in either direction, are likely. Return to text"
    },
    {
        "speaker": "Lael Brainard",
        "position": "Governor",
        "date": "June 03, 2016",
        "title": "The Economic Outlook and Implications for Monetary Policy",
        "href": "https://www.federalreserve.gov/newsevents/speech/brainard20160603a.htm",
        "content": "June 03, 2016\n\nGovernor Lael Brainard\n\nAt the Council on Foreign Relations, Washington, D.C.\n\nIn recent months, financial conditions have eased, and there are encouraging signs that consumption has regained momentum. On the other hand, there are tentative signs of slowing in the labor market and risks remain.1 We cannot take the resilience of our recovery for granted.\n\nRecent Developments\nAs we consider the appropriate posture of policy going forward, the most immediate question is whether the data provide confidence that domestic economic activity has strengthened notably following two disappointing quarters. This is critical for making progress on the Committee's dual mandate objectives of full employment and 2 percent inflation. The data in today's labor market report on balance suggest that the labor market has slowed. Nonfarm payroll employment increased at an average monthly pace of 116,000 over the last three months--well below the 220,000 per month average pace over the preceding twelve months. The unemployment rate moved lower, reaching 4.7 percent, a new low in the current recovery, but involuntary part-time employment increased and the labor force participation rate declined.\n\nEven so, there are reasons to expect that the labor supply still has room to respond if labor demand increases. Importantly, the employment to population ratio for prime-age workers still remains 1-3/4 percentage points below pre-crisis levels. The recent data on wage inflation suggest a similar conclusion. Although there have been some signs of increasing wage growth recently, the step-up has been modest, and growth in the broad measures of wages remains quite low. For example, the average change over the past year across the three most commonly cited wage measures was about 2-1/2 percent, compared with an average change from the end of 2009 to the end of 2014 of 2 percent.2\n\nThe recent news on inflation--the second leg of our dual mandate--has also been mixed. The price of oil has rebounded significantly from the lows reached earlier in the year on expectations that supply and demand are likely to come into better alignment. Over the same period, the dollar has receded a bit, on net, from its peak in January, though it is still about 15 percent above the level in mid-2014 in inflation-adjusted trade-weighted terms. As a result, non-oil import prices look likely to stabilize this quarter after a year and a half of declines. Still, it should be noted that these developments coincided with the easing in financial conditions since mid-February and are likely due, at least in part, to expectations of more gradual U.S. monetary policy tightening. If those expectations were to shift materially, the conditions supporting higher inflation could diminish.\n\nWhile there are thus signs that inflation will move higher over the medium term, measures of core inflation have yet to convincingly exceed the low levels that have prevailed over much of the recovery. The 12-month change in core personal consumption expenditure (PCE) prices, a reasonable proxy for the underlying trend in inflation, was only 1.6 percent in April. This is still noticeably below our target and is roughly equal to the average change in core and total PCE inflation from the end of 2009 to the end of 2014.\n\nWe cannot rule out that stubbornly low inflation may be having an effect on inflation expectations. Market-based measures of inflation compensation--which reflect inflation risk and liquidity premiums, as well as inflation expectations--remain extremely low. For example, inflation compensation at the five-year, five-year-ahead horizon is currently around 1.5 percent, 1-1/4 percentage points below levels prevailing prior to mid-2014. Some survey-based measures of inflation expectations are also somewhat below historical norms. Median 5- to 10-year inflation expectations in the University of Michigan Surveys of Consumers, for example, over the past year have been on average about 1/4 percentage point below the average over the 10 years from 2005 to 2014.\n\nThus, although some signs point to a firming of inflation going forward, I view the persistently low level of inflation during the recovery together with some signs of a deterioration in inflation expectations as suggesting that the risks to the return of inflation to our 2 percent target over the medium term are weighted to the downside.\n\nProgress toward our goals of full employment and 2 percent inflation will depend importantly on solid growth in aggregate demand. Following disappointing gross domestic product (GDP) growth in the fourth quarter of last year and the first quarter of this year that averaged only 1.1 percent, I have been very attentive to incoming data, especially on consumption, which point to a pick-up in growth this quarter.3 In particular, consumer expenditures rose a strong 0.6 percent in April, and auto sales edged higher in May. These are encouraging signs, but the data relevant for second-quarter growth are still relatively sparse.\n\nIn general, demand growth in recent quarters has benefited from a relatively strong household sector--buoyed by a recovering labor market, reduced oil prices, and low interest rates--and has been pulled down by weak business investment and net exports. Indeed, consumption and housing investment can more than account for the 2 percent increase in GDP over the past four quarters. By contrast, business investment and net exports together subtracted 1/4 percentage point. The rise in the dollar and decline in foreign growth reduced demand for American exports, as well as profits and investment at U.S. firms, which were also adversely affected by declines in the price of oil. Over the twelve months ending in April, manufacturing output increased only 0.4 percent, while total industrial production, which also includes the drilling for, and extraction of, oil and gas, fell 1.1 percent. Although the most recent indicators suggest that weakness in investment and net exports has persisted into the current quarter, if the easing in financial conditions since mid-February and the recent firmness in oil prices were to continue, along with stabilization of the dollar, business investment and exporters would benefit.\n\nRisks to the Outlook\nOf course, there are risks to the projection that future GDP growth will be strong enough to deliver progress on inflation and employment. Most immediately, there is important uncertainty surrounding the United Kingdom's June 23 \"Brexit\" referendum on whether to leave the European Union (EU). The International Monetary Fund has noted that a vote in favor of Brexit could unsettle financial markets and create a period of uncertainty while the relationship between the United Kingdom and the EU is renegotiated. Although the economic effects of this uncertainty and the costs of adjusting to altered trade and financial ties are difficult to quantify, we cannot rule out a significant adverse reaction to such an outcome in the near term, such as a substantial jump in financial risk premiums. Because international financial markets are tightly linked, an adverse reaction in European financial markets could affect U.S. financial markets, and, through them, real activity in the United States.\n\nIn addition, we should not dismiss the possible reemergence of risks surrounding China and emerging market economies (EMEs) more broadly. In recent months, capital outflows in China have moderated as pressures on the exchange rate have eased. Should exchange rate pressures reemerge, we cannot rule out a recurrence of financial stress, which would affect not only China but also other emerging markets that are linked to China via supply chains or commodity exports and, ultimately, conditions here. China is making a challenging transition from export- to domestic demand-led growth, and the cost of reallocating resources from excess capacity sectors to more dynamic sectors could further impair growth in the near term. While China has taken policy steps to limit the extent of the slowdown, there is an evident tension in policy between reform and stimulus, and the effect of the stimulus may already be waning. Vulnerabilities--such as excess capacity, elevated corporate debt, and risks in the shadow banking sector--appear to be building, and could pose continued risks over the medium term.\n\nThe fragility of the global economic environment is unlikely to resolve any time soon. Growth in the advanced economies remains dependent on extraordinary unconventional monetary policy accommodation, while conventional policy continues to be constrained by the zero lower bound. Conventional policy, whose efficacy is more tested and better understood than unconventional policies, can respond readily to upside surprises to demand, but presently would be constrained in adjusting to downside surprises. This asymmetry in the capability of policy effectively skews risks to the outlook to the downside.\n\nIt also may amplify the sensitivity of exchange rates. Indeed, the evidence suggests that over the past year, dollar exchange rate movements have become considerably greater in response to U.S. monetary policy surprises than previously.4 The evidence that the sensitivity of exchange rate movements has been elevated lately is consistent with recent research suggesting that cross border financial transmission is likely to be amplified at near-zero interest rates where the ability to provide additional support through domestic channels in response to negative shocks may be viewed as limited.5\n\nIn this environment, markets have become quite sensitive to the possibility of a prolonged period of low growth, low inflation, and economic underperformance. One possible example of this sensitivity is the current negative term premium for 10-year Treasury notes, or the difference between the yield on the 10-year Treasury and expected risk-free short rates over the next 10 years. Prior to the Great Recession, the term premium was positive, as bond investors seem to have been most concerned about the risk that inflation would be higher than expected. But since the Great Recession, the term premium has been persistently negative, suggesting that investors have instead been focused on the risk of prolonged lower-than-expected inflation in the context of low growth and underperformance.6\n\nThus, while the easing in financial conditions since mid-February is very welcome, it is important to recognize that some of the conditions underlying recent bouts of turmoil largely remain in place, and an important reason for the fading of this turbulence was the expectation of more gradual U.S. monetary policy tightening.7 Should an event trigger renewed fears about global growth or a reassessment of the policy reaction function in the United States, turbulence could well return.\n\nPolicy Implications\nOn balance, recent developments have signaled continued progress toward our goals. While signs of weakness in business investment and global demand remain, consumption and residential investment have held firm, and the labor market has moved closer to full employment. At the same time, the relative stabilization in the dollar and oil prices in recent months has boosted somewhat the likelihood of a return to 2 percent inflation over the medium term. However, the data on progress toward our inflation objective are equivocal. Measures of underlying inflation have yet to convincingly signal a move back to 2 percent, and inflation expectations appear low, as I noted earlier.\n\nI want to emphasize that monetary policy is data dependent and is not on a preset course. In this regard, I look forward to hearing the deliberations of the Committee. Recognizing the data we have on hand for the second quarter is quite mixed and still limited, and there is important near-term uncertainty, there would appear to be an advantage to waiting until developments provide greater confidence. Prudent risk-management would suggest the risks from waiting until the totality of the data provides greater confidence in a rebound in domestic activity, and there is greater certainty regarding the \"Brexit\" vote, seem lower than the risks associated with moving ahead of these developments. This is especially true since the feedback loop through exchange rate and financial market channels appears to be elevated. In light of this amplified feedback loop, when conditions are appropriate for a policy move, it will be important that it be understood that any subsequent moves would be conditioned on further evidence confirming continued progress toward our objectives and not as inevitable steps on a preset course.\n\nIndeed, several factors suggest that the appropriate path to return monetary policy to a neutral stance could turn out to be quite shallow and gradual in the medium term. In particular, it appears likely that the medium-term neutral rate, or the real federal funds rate consistent with the economy remaining at full employment and 2 percent inflation, may be quite low. With productivity running very low, substantial overcapacity and disinflationary pressures abroad, and less favorable demographics, the neutral rate may be lower and today's federal funds rate closer to neutral than previously anticipated. Although we cannot observe the neutral rate directly, a variety of models suggests that it is currently very low relative to historical norms. Earlier in the recovery it seemed likely that the low level of the neutral rate was largely due to temporary factors, such as tight credit, weak consumer confidence, and the loss in household wealth following the crisis. However, with the recovery well into its seventh full year, credit in many markets is widely available, while consumer confidence and household net worth are at high levels. As a result, it appears more likely that much of the decline in the neutral rate is likely to prove persistent, consistent with a variety of estimates.8\n\nOne likely explanation for this persistence is the sharp drop-off in potential output growth since the Great Recession. From 1953 to 2003, potential output growth varied between 3 and 4-1/2 percent, with one brief exception, according to the Congressional Budget Office. Over the recovery, it has averaged only 1-1/4 percent. One contributor to this decline has been a reduction in the labor force participation rate due to population aging. Another has been a marked slowing in productivity growth. Over the six years from the end of 2009 to the end of 2015, productivity grew only a little over 1/2 percent per year, compared with average growth of 2-1/4 percent over the 50 years prior to the Great Recession.9\n\nThe reasons for such a dramatic slowing in productivity growth are not clear. Possible explanations include the fading of a one-time boost to productivity from information technology in the late 1990s and early 2000s; the reduced movement of resources from the least productive to the most productive firms, including new businesses, perhaps due to greater financial constraints for new and small businesses; and a delay between the introduction of new technologies, such as robotics, genetic sequencing, and artificial intelligence, and their effect on new production processes and products.10\n\nTo conclude, recent economic developments have been mixed, and important downside risks remain. In this environment, prudent risk management implies there is a benefit to waiting for additional data to provide confidence that domestic activity has rebounded strongly and reassurance that near-term international events will not derail progress toward our goals. In addition, because the depressed level of the neutral rate of interest reflects forces that are likely to persist, the appropriate path of policy is likely to remain shallow for several years.\n\nReferences\nBaily, Martin Neil, James Manyika, and Shalabh Gupta (2013). \"U.S. Productivity Growth: An Optimistic Perspective,\" International Productivity Monitor, no. 25, pp. 3-12.\n\nByrne, David M., John G. Fernald, and Marshall B. Reinsdorf (2016). \"Does the United States Have a Productivity Slowdown or a Measurement Problem? (PDF)\" Brookings Papers on Economic Activity, BPEA Conference Draft, March 10-11.\n\nCaballero, Ricardo J., Emmanuel Farhi, and Pierre-Olivier Gourinchas (2015). \"Global Imbalances and Currency Wars at the ZLB,\" NBER Working Paper Series 21670. Cambridge, Mass.: National Bureau of Economic Research, October.\n\nChen, Andrew, Eric Engstrom, and Olesya Grishchenko (2016). \"Has the Inflation Risk Premium Fallen? Is It Now Negative?\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, April 4.\n\nDecker, Ryan A., John Haltiwanger, Ron Jarmin, and Javier Miranda (2016). \"The Decline of High-Growth Entrepreneurship,\" VoxEU.org. London: Centre for Economic Policy Research, March 19.\n\n-------- (2014). \"The Role of Entrepreneurship in U.S. Job Creation and Economic Dynamism,\" Journal of Economic Perspectives, vol. 28 (Summer), pp. 3-24.\n\nDel Negro, Marco, Marc Giannoni, and Micah Smith (2016). \"The Macro Effects of the Recent Swing in Financial Conditions,\" Federal Reserve Bank of New York, Liberty Street Economics (blog), May 25.\n\nFederal Reserve Bank of New York, Markets Group (2016). Responses to Survey of Market Participants, April (PDF).\n\nFernald, John (2014). \"Productivity and Potential Output before, during, and after the Great Recession,\" NBER Working Paper Series 20248. Cambridge, Mass.: National Bureau of Economic Research, June.\n\nJohannsen, Benjamin K., and Elmar Mertens (2016). \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, February 9.\n\nLaubach, Thomas, and John C. Williams (2015). \"Measuring the Natural Rate of Interest Redux (PDF),\" Working Paper Series 2015-16. San Francisco: Federal Reserve Bank of San Francisco, October.\n\nSyverson, Chad (2016). \"Challenges to Mismeasurement Explanations for the U.S. Productivity Slowdown ,\" NBER Working Paper Series 21974. Cambridge, Mass.: National Bureau of Economic Research, February.\n\nYellen, Janet (2015). \"The Economic Outlook and Monetary Policy,\" speech delivered at the Economic Club of Washington, Washington, December 2.\n\nZarutskie, Rebecca, and Tiantian Yang (forthcoming). \"How Did Young Firms Fare during the Great Recession? Evidence from the Kauffman Firm Survey,\" in John Haltiwanger, Erik Hurst, Javier Miranda, and Antoinette Schoar, eds., Measuring Entrepreneurial Businesses: Current Knowledge and Challenges. NBER Book Series Studies in Income and Wealth. Chicago: University of Chicago Press.\n\nI am grateful to Andrew Figura for his assistance in preparing this text.\n\n1. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. The three commonly cited measures of wages are the private-industry employment cost index, compensation per hour in the business sector, and average hourly earnings. Return to text\n\n3. Growth in gross domestic income (GDI) has not slowed as much as GDP growth recently. However, the average of GDP and GDI growth has still slowed recently from an average annual rate of 2-1/2 percent from the third quarter of 2013 to the third quarter of 2015 to an average of 1-1/2 percent in the past two quarters. Return to text\n\n4. Recent research by Federal Reserve staff suggests that over the past year, a surprise of 25 basis points in the Federal Funds rate following FOMC announcements has triggered dollar appreciation of over 5 percent, although the confidence interval is extremely large, and the coefficient has varied substantially over time, including intervals when the relationship has been negative. Return to text\n\n5. See Caballero, Farhi, and Gourinchas (2015). Return to text\n\n6. See Chen, Engstrom, Grishchenko (2016). Another factor affecting the term premium is Federal Reserve asset purchases. In addition, some have suggested the low term premium could reflect an \"insurance\" value that investors attach to Treasury securities because the price of Treasuries would be expected to rise if there are adverse shocks to the global economy. Return to text\n\n7. For an estimate of the role of U.S. monetary policy in offsetting the recent tightening in financial conditions, see Del Negro, Giannoni, and Smith (2016). Return to text\n\n8. See, for example, Laubach and Williams (2015); the estimates from the dynamic stochastic general equilibrium models cited in Yellen (2015); the median estimated neutral rate from the Federal Reserve Bank of New York's most recent Survey of Market Participants (Federal Reserve Bank of New York, 2016); and Johannsen and Mertens (2016). Return to text\n\n9. Since the end of 2007, the average annual gain in productivity has been 1.1 percent. Return to text\n\n10. For more on the recent slowing in productivity growth and its possible causes, see Fernald (2014), Decker and others (2014, 2016), and Zarutskie and Yang (forthcoming). For an investigation into whether mismeasurement may be responsible for some of the slowing in productivity growth, see Byrne, Fernald, and Reinsdorf (2016) and Syverson (2016). For an optimistic outlook on future productivity growth, see Baily, Manyika, and Gupta (2013). Return to text"
    },
    {
        "speaker": "Jerome H. Powell",
        "position": "Governor",
        "date": "May 26, 2016",
        "title": "Recent Economic Developments, the Productive Potential of the Economy, and Monetary Policy",
        "href": "https://www.federalreserve.gov/newsevents/speech/powell20160526a.htm",
        "content": "May 26, 2016\n\nGovernor Jerome H. Powell\n\nAt the Peterson Institute for International Economics, Washington, D.C.\n\nThank you for the opportunity to speak here today. I will begin by reviewing recent economic developments and then turn to supply-side considerations, such as the level of potential output and the potential growth of our economy. I will conclude with a discussion of monetary policy. As always, the views I express here today are mine alone.\n\nRecent Developments and the State of the Economy\nThe U.S. economy has improved steadily since the recovery began seven years ago. Our economy is now 10 percent larger than at its previous peak in 2007. Employment has surpassed its 2008 peak by 5 million workers, and the unemployment rate has fallen from 10 percent to 5 percent, close to the level that many observers associate with full employment.\n\nLabor market developments remain healthy, with employers adding roughly 200,000 jobs per month so far this year--a pace similar to that of the past several years (figure 1). Job growth continues to be substantially faster than the underlying growth of the labor force, so the labor market continues to tighten. Despite the strong job gains, the unemployment rate has flattened out at 5 percent over the past six months thanks to a welcome increase in the labor force participation rate. Meanwhile, there are tentative and encouraging signs of a firming in wages, seen most clearly in the data on average hourly earnings, which are rising faster than inflation and productivity. All told, labor market indicators show an economy on solid footing.\n\nRecent spending data have been less positive than the labor market data. Growth of personal consumption slowed noticeably in the first quarter. Business fixed investment has fallen for two consecutive quarters, mainly because of a steep decline in energy-related capital expenditures. As a result, gross domestic product (GDP) growth over the two quarters ending in March 2016 is estimated to have averaged only 1 percent on an annualized basis. This estimate may continue to move around as more data come in.1 And there are good reasons to think that underlying growth is stronger than these recent readings suggest. Labor market data generally provide a better real-time signal of the underlying pace of economic activity.2 In addition, retail sales surged in April, as did consumer confidence in May, suggesting that the pause in consumption may have been transitory. Moreover, stronger demand would be more consistent with an environment that remains quite supportive of growth, with low interest rates, low gasoline prices, solid real income gains, a high ratio of household wealth to income, healthy levels of business and household confidence, and continuing strong job creation. Indeed, current forecasts for second-quarter GDP growth are for a rebound to around 2-1/4 percent.3\n\nInflation remains below the 2 percent target of the Federal Open Market Committee (FOMC), with total inflation as measured by the price index for personal consumption expenditures at 3/4 percent over the 12 months ending in March and core inflation at 1-1/2 percent, both slightly higher than a year earlier. Core inflation has been held down by falling import prices, owing in large part to the rise in the dollar, as well as the indirect effects of lower oil prices on core prices. As the recent financial market tensions have eased, oil prices have increased and the dollar has weakened a bit on net. If oil prices and the dollar remain broadly stable, inflation should move up further over time to our 2 percent objective. Inflation expectations seem to be under some downward pressure. Some survey-based measures are at the low end of their recent historical ranges. Market-based measures of longer-term breakevens have declined significantly since mid-2014 and stand near all-time lows. While I see expectations as staying reasonably well anchored, it is essential that they remain so and that inflation return over time to the 2 percent objective.\n\nThe easing in global financial conditions since mid-February and the associated waning in downside risks are welcome, and in part reflect expectations that the FOMC would move more slowly in removing monetary accommodation. However, underlying risks will likely remain until global growth is on a stronger footing. Growth and inflation remain stubbornly low for most of our major trading partners. In China, stimulus measures should support growth in the near term but may also slow China's necessary transition away from its export- and investment-led business model. Meanwhile, the ongoing buildup of debt there is notable. There is also some remaining uncertainty about China's exchange rate policy. Elsewhere, risks are posed by the upcoming \"Brexit\" vote, ongoing pressures from refugee flows into Europe, and challenging conditions for emerging economies such as Brazil, Russia, and Venezuela.\n\nDespite these downside risks, I see U.S. demand growing at a moderate pace, the labor market continuing to heal, and inflation returning over time to the FOMC's 2 percent objective. The economy is on track to attain the Committee's dual mandate of stable prices and maximum employment.\n\nSupply-Side Considerations\nFor several years after the crisis, economic activity remained far below its potential, and the need for highly accommodative policy seemed clear. As the shortfall of output from potential has narrowed, supply-side considerations such as the level and growth rate of potential output naturally begin to matter more for policy. I will turn now to a discussion of these issues.\n\nThe tension between labor market and spending data is not a recent phenomenon. Throughout the recovery period, forecasters have consistently overestimated both actual and potential GDP growth while underestimating the rate of job creation and the pace of decline of the unemployment rate (table 1). For example, in 2007, the average expectation for long-run GDP growth from the Blue Chip survey of 50 forecasters was 2.9 percent (table 2). After successive reductions, the estimate now stands at 2.1 percent. Blue Chip forecasters also underestimated the decline in the unemployment rate. Other well-known forecasts followed this same pattern, including those of the Congressional Budget Office, the Survey of Professional Forecasters, and, yes, FOMC participants. The pattern suggests that forecasters have only gradually taken on board the decline in potential in the wake of the financial crisis.\n\nOutput growth can be decomposed into increases in hours worked and changes in output per hour, or productivity growth. For the United States, much of the post-crisis decline in estimates of potential output growth appears to reflect weak labor productivity growth rather than damage to labor supply. Labor productivity has increased only 1/2 percent per year since 2010--the slowest five-year growth rate since World War II and about one-fourth of the average postwar rate (figure 2). For further perspective, productivity growth averaged 1-1/2 percent during the so-called slow productivity period from 1974 to 1995 and 3 percent during the tech-boom decade from 1995 to 2005. The slowdown has been worldwide and is evident even in countries that were little affected by the crisis (figure 3). Given the global nature of the phenomenon, changes in factors specific to the United States are probably not the main drivers.\n\nOne factor holding back productivity in recent years has been the meager growth in the business sector's capital stock (figure 4). This weakness is consistent with the weak recovery in demand.4 Another important factor is the marked decline in total factor productivity (TFP) growth (figure 5). TFP is that part of productivity that is not explained by capital investment or labor quality; it is thought to be mainly a function of technological innovation.5 A broad decline in the dynamism in our economy may also be contributing to lower TFP.6 There is strong evidence that the slowdown in TFP growth in the United States preceded the financial crisis, particularly in sectors that produce or use information technologies.7\n\nThe range of opinions on the future path of productivity growth is wide, and the historical record provides ample grounds for humility.8 A middle-ground position that seems to underlie many current forecasts is that productivity is probably still being held down by cyclical factors and lingering effects of the crisis. As those factors dissipate, labor productivity growth should move up to 1-1/2 percent or so, the lower end of its longer-run range.\n\nIn addition to productivity, the other principal factor in potential output is labor supply, which is determined by the working-age population, the natural rate of unemployment, and the trend labor force participation rate. Both the natural rate of unemployment and labor force participation initially appeared to suffer crisis-related damage. But more recent data are a bit more encouraging.\n\nThe natural rate of unemployment reflects the matching of characteristics that employers are seeking with those of the unemployed. With the dramatic labor market dislocations of the crisis, it was not surprising to see measures of matching efficiency deteriorate, and many observers raised their estimates of the natural rate accordingly. But there are other factors, such as demographic change, that may have led to a decline in the natural rate of unemployment.9 Blue Chip forecasters' estimate of the natural rate have now returned to around 5 percent, about the same as before the crisis, suggesting that these factors are roughly offsetting. Of course, estimates of the natural rate are highly uncertain.10\n\nTrends in labor force participation add another element of uncertainty. Participation has been declining since about 2000 and is estimated to have a trend rate of decline of 20 to 30 basis points per year, driven by population aging and other longer-term trends such as the decline in participation by prime-age males. But the participation rate fell sharply after the crisis, faster than its apparent trend. It has been important to understand how much of the post-crisis decline is cyclical, and thus amenable to repair by supportive policies, and how much is secular, due either to longer-run trends or to irreversible crisis-related damage. It has been a relief to see the participation rate improve over the past two years relative to estimates of its trend; indeed, participation is now close to some such estimates.11 Still, despite this relative improvement, the performance of the U.S. economy on this dimension has been poor relative to that of most OECD (Organisation for Economic Co-operation and Development) countries. For example, in the prime-age group of 25 to 54, the United States experienced a 2 percentage point decline in labor force participation from 2007 to 2014, while most OECD countries saw an increase (figure 6). The United States now stands at the low end of labor force participation for both men and women in this age group--above Italy, but well below Germany, France, and Spain.12\n\nLower potential growth would likely translate into lower estimates of the level of interest rates necessary to sustain stable prices and full employment. Estimates of the long-run \"neutral\" federal funds rate have declined about 100 basis points since the end of the crisis. The real yield on the 10-year Treasury is currently close to zero, compared with around 2 percent in the mid-2000s. Some of the decline in longer-term rates is explained by lower estimates of potential growth, and some by other factors such as very low term premiums.\n\nTo sum up so far, estimates of long-run potential growth of the U.S. economy have dropped from about 3 percent to about 2 percent in the wake of the crisis, with much of the decline a function of slower productivity growth. The decline in realized productivity growth seems to be driven both by low capital investment that is well explained by weak demand and by lower TFP growth. Expectations of lower productivity growth going forward are more a function of slower gains in TFP. Lower potential output growth would mean that interest rates will remain below their pre-crisis levels even after the output gap is fully closed and inflation returns to 2 percent.\n\nOver time, our understanding of the relationship between recessions and supply-side factors has evolved.13 There is a growing body of work suggesting that recessions can leave behind lasting damage--especially severe recessions associated with a financial crisis. One recent analysis suggests that about one-third of the time, there is no permanent supply-side damage; about one-third of the time, there is a reduction in the level of potential output but not its subsequent growth rate; and about one-third of the time, there is a reduction both in the level of output and in the growth rate.14 Unfortunately, recent experience suggests that the United States is at risk of falling in the last category (figure 7).\n\nIt goes without saying that economic policymakers should use all available tools to minimize supply-side damage from the crisis. We need policies that support labor force participation and the development of skills, business hiring and investment, and productivity growth--policies that are, for the most part, outside the remit of the Federal Reserve. Monetary policy can contribute by continuing to support the expansion as long as inflation remains consistent with our 2 percent objective and inflation expectations remain stable.\n\nStrong labor markets do seem to be averting some of the damage that might otherwise have become permanent. Improved matching is reducing the natural rate of unemployment. Potential workers are being pulled into the labor force by rising real wages and the recognition that jobs are becoming easier to find. Over a longer period, stronger demand should support increased investment, driving productivity higher. Moreover, as the economy tightens, firms will have rising incentives to get more out of every dollar of capital and hour of work.\n\nReal-time estimates of potential output are highly uncertain; forecasts of potential growth even more so. We can estimate growth of the working-age population reasonably well. Future levels of labor force participation are less certain. Least certain of all are forecasts of TFP. If the optimists are right, then there will eventually be another wave of high productivity growth driven by the truly remarkable evolution of technology. That would mean higher potential growth, faster increases in living standards, and also a return to higher interest rates over time.\n\nWhat if the pessimists are right and productivity growth remains low for another decade, or indefinitely? The consequences would include lower potential growth and relatively lower living standards. Our longer-term fiscal challenges would be significantly greater.\n\nMonetary Policy\nThe implications for monetary policy of these supply-side issues have been limited, but they begin to matter more as we near full employment.\n\nFor the near term, my baseline expectation is that our economy will continue on its path of growth at around 2 percent. To confirm that expectation, it will be important to see a significant strengthening in growth in the second quarter after the apparent softness of the past two quarters. To support this growth narrative, I also expect the ongoing healing process in labor markets to continue, with strong job growth, further reductions in headline unemployment and other measures of slack, and increases in wage inflation. As the economy tightens, I expect that inflation will continue to move over time to the Committee's 2 percent objective.\n\nIf incoming data continue to support those expectations, I would see it as appropriate to continue to gradually raise the federal funds rate. Depending on the incoming data and the evolving risks, another rate increase may be appropriate fairly soon. Several factors suggest that the pace of rate increases should be gradual, including the asymmetry of risks at the zero lower bound, downside risks from weak global demand and geopolitical events, a lower long-run neutral federal funds rate, and the apparently elevated sensitivity of financial conditions to monetary policy. Uncertainty about the location of supply-side constraints provides another reason for gradualism.\n\nThere are potential concerns with such a gradual approach. It is possible that monetary policy could push resource utilization too high, and that inflation would move temporarily above target. In an era of anchored inflation expectations, undershooting the natural rate of unemployment should result in only a small and temporary increase in the inflation rate.15 But running the economy above its potential growth rate for an extended period could involve significant risks even if inflation does not move meaningfully above target. A long period of very low interest rates could lead to excessive risk-taking and, over time, to unsustainably high asset prices and credit growth. Macroprudential and other supervisory policies are designed to reduce both the likelihood of such an outcome and the severity of the consequences if it does occur. But it is not certain that these tools would prove adequate in a financial system in which much intermediation takes place outside the regulated banking sector. Thus, developments along these lines could ultimately present a difficult set of tradeoffs for monetary policy.16\n\nConclusion\nTo wrap up, with the support of monetary accommodation, our economy has made substantial progress. My view is that a continued gradual return to more normal monetary policy settings will give us the best chance to continue to make up lost ground.\n\n1. For example, according to the Bureau of Economic Analysis, a 70 percent confidence band around the estimate of first-quarter GDP would extend from negative 0.7 percent to 1.7 percent, which implies that the spending data should be taken with a grain of salt. Return to text\n\n2. Analysis by Board staff finds that lagged employment growth provides a better signal of current-quarter GDP or employment growth than does lagged GDP growth. Return to text\n\n3. For example, the May Blue Chip forecast for second-quarter real GDP growth was 2.3 percent, and the Federal Reserve Bank of Atlanta's GDPNow forecasting model predicted 2.5 percent, as of May 17. Return to text\n\n4. See Eugenio Pinto and Stacey Tevlin (2014), \"Perspectives on the Recent Weakness in Investment,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, November 21). Their analysis indicates that investment growth over the expansion has been consistent with a model using business output growth and the user cost of capital. In a second model, they show that the modest increases in the capital stock are consistent with the increase in labor supply and TFP. Return to text\n\n5. Over long periods of time total factor productivity is primarily driven by innovation, knowledge and the efficiency with which inputs are put to use owing to the evolution of business practices as well as the influences of public capital stock, government regulations and other factors. Over shorter periods of time TFP will also capture the variations in the intensity of utilization of inputs, such as capacity utilization and hours per worker. Disentangling TFP from capital deepening and hours worked can be challenging. Return to text\n\n6. See, for example, Ryan Decker, John Haltiwanger, Ron Jarmin, and Javier Miranda (2014), \"The Role of Entrepreneurship in U.S. Job Creation and Economic Dynamism,\" Journal of Economic Perspectives, vol. 28 (Summer), pp. 3-24. Return to text\n\n7. See John Fernald (2014), \"Productivity and Potential Output before, during, and after the Great Recession,\" NBER Macroeconomics Annual, vol. 29, no. 1 (Cambridge, Mass.: National Bureau of Economic Research). Some have argued that part of the TFP slowdown may actually be a measurement problem, owing to the difficulty in measuring the productivity of health care, information technology, and other services. Others see the evidence for that claim as weak. For example, a recent paper finds little evidence that the slowdown arises from growing mismeasurement in information-technology-related goods and services. See David M. Byrne, John G. Fernald, and Marshall B. Reinsdorf (2016), \"Does the United States Have a Productivity Slowdown or a Measurement Problem?\"  Brookings Papers on Economic Activity, March 4. Return to text\n\n8. On the pessimistic end of the spectrum are analysts such as Robert Gordon; among the optimists are Erik Brynjolfsson and Andrew McAfee. See Robert J. Gordon (2016), The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War (Princeton, N.J.: Princeton University Press); and Erik Brynjolfsson and Andrew McAfee (2014), The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies (New York: W.W. Norton). Return to text\n\n9. For example, older labor force cohorts have lower participation but also lower unemployment rates. Return to text\n\n10. Confidence intervals around statistical estimates of the natural rate are routinely estimated to be quite wide, reflecting both uncertainty about the correct model specification and uncertainty about the parameter estimates given the model. The canonical paper by Staiger, Stock, and Watson puts the 95 percent confidence interval at 1-1/2 percentage points on either side of the point estimate. See Douglas Staiger, James H. Stock, and Mark W. Watson (1997), \"How Precise Are Estimates of the Natural Rate of Unemployment?\" in Christina D. Romer and David H. Romer, eds., Reducing Inflation: Motivation and Strategy (Chicago: University of Chicago Press). Return to text\n\n11. For example, a paper by Stephanie Aaronson and others estimates a trend below the current participation rate, while the Congressional Budget Office's estimate is above the current rate. See Stephanie Aaronson, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014), \"Labor Force Participation: Recent Developments and Future Prospects,\"  Brookings Papers on Economic Activity, Fall, pp. 197-275; and Congressional Budget Office (2016), The Budget and Economic Outlook: 2016 to 2026  (Washington: CBO, January 25). For the argument that most of the decline is related to the severity of the recession and is likely reversible, see Christopher J. Erceg and Andrew T. Levin (2013), \"Labor Force Participation and Monetary Policy in the Wake of the Great Recession (PDF),\"  IMF Working Paper WP/13/245 (Washington: International Monetary Fund, July). Return to text\n\n12. Different countries use slightly different concepts for measuring labor force participation, and therefore cross-country comparisons may reflect some measurement issues. However, to the extent that these differences are constant over time, comparisons of the relative performances will be little affected. Accordingly, it is worth highlighting that the labor force participation rate in the 25-54 age group has declined somewhat in the U.S. since 2008, while it has been relatively steady or even increased some in other major advanced economies. Return to text\n\n13. See, for example, Robert F. Martin, Teyanna Munyan, and Beth Anne Wilson (2014), \"Potential Output and Recessions: Are We Fooling Ourselves?\" IFDP Notes (Washington: Board of Governors of the Federal Reserve System, November 12); and Olivier Blanchard, Eugenio Cerutti, and Lawrence Summers (2015), \"Inflation and Activity--Two Explorations and Their Monetary Policy Implications (PDF),\"  IMF Working Paper WP/15/230 (Washington: International Monetary Fund, November). Return to text\n\n14. See Blanchard, Cerutti, and Summers, \"Inflation and Activity,\" in note 13. The authors argue that damage from recessions may be caused by hysteresis or by supply shocks such as oil price spikes or financial crises. In some cases, the link between recessions and future growth may reflect \"reverse causation,\" whereby the recession is caused by the realization that future growth will be lower than had been expected. Return to text\n\n15. See, for example, Laurence Ball and Sandeep Mazumder (2011), \"The Evolution of Inflation Dynamics and the Great Recession,\"  Brookings Papers on Economic Activity, (Spring), pp. 337–381; Blanchard, Cerutti, and Summers, \"Inflation and Activity\", in note 13. Return to text\n\n16. See for example, Jeremy C. Stein (2013), \"Overheating in Credit Markets: Origins, Measurement, and Policy Responses.\" Tobias Adrian and Adam B. Ashcraft (2012), \"Shadow Banking Regulation\" FRBNY Staff Report No. 559, and Samuel G. Hanson, Anil K. Kashyap, and Jeremy C. Stein (2011), \"A Macroprudential Approach to Financial Regulation,\" Journal of Economic Perspectives vol. 25, no. 1, both note that macroprudential tools may not be sufficient to fully address risks rising outside of the regulated banking sector. Return to text"
    },
    {
        "speaker": "Daniel K. Tarullo",
        "position": "Governor",
        "date": "May 20, 2016",
        "title": "Insurance Companies and the Role of the Federal Reserve",
        "href": "https://www.federalreserve.gov/newsevents/speech/tarullo20160520a.htm",
        "content": "May 20, 2016\n\nGovernor Daniel K. Tarullo\n\nAt the National Association of Insurance Commissioner’s International Insurance Forum, Washington, D.C.\n\nIt is a pleasure to be here with you this morning to discuss the statutory role of the Federal Reserve in supervising and regulating insurance firms. Since we inherited from the Office of Thrift Supervision the oversight of savings and loan holding companies (SLHCs) that contain insurance companies, we have looked at our role as complementing the role you--as insurance regulators--play. We value the interaction we have had with state insurance commissioners on policy matters and are pleased with the growth of ongoing, regularized cooperation in supervising the firms over which we both have oversight authority. Personally, I have profited enormously from the assistance provided by the staff of the National Association of Insurance Commissioners (NAIC) as I delved into the history and practice of capital regulation of insurance companies.\n\nToday I would like to begin by describing how I view the Federal Reserve's role in insurance regulation and supervision--both what it is and what it is not. As I think you will find, we have tried to occupy that role in a way that is closely grounded in the duties that Congress has given us. Then I will present current thinking on a topic that I know has occasioned great interest--the Federal Reserve's plans for adopting capital requirements for the insurance firms over which we now have statutory responsibilities.\n\nThe Federal Reserve's Role in Insurance Regulation and Supervision\nThe U.S. insurance industry has historically been, and remains, a significant part of the U.S. economy. For the industry across all sectors, written premiums last year totaled nearly $2 trillion and earned premiums totaled nearly $1.8 trillion, representing increases from 2014 of approximately 6 percent and 4 percent, respectively.1 This represents over 7 percent of U.S. gross domestic product, as it has in recent years.2 The two largest sectors in the U.S. insurance industry, property/casualty and life/annuities, together wrote approximately $1 trillion of premiums in 2015, up nearly 3 percent from the year prior.3 Moreover, for the U.S. insurance industry as a whole, written and earned premium last year were the highest in five years.4\n\nThe Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank Act) gave the Federal Reserve regulatory responsibilities both for insurance holding companies that own a federally insured bank or thrift and for insurance companies designated as systemically important by the U.S. Financial Stability Oversight Council (FSOC). The insurance holding companies for which the Federal Reserve is the consolidated supervisor hold about $2 trillion in total assets, representing about one-quarter of U.S. insurance industry assets. These firms are highly diverse: they range in size from firms with total assets of approximately $3 billion to firms with total assets of over $700 billion. They engage in a wide variety of insurance and non-insurance activities. Some are fully domestic, while others have material international operations. Some are organized as mutual companies, while others are owned by public shareholders.\n\nThe approach of the Federal Reserve in regulating insurance holding companies is derived from its overall statutory responsibilities for financial regulation as those have evolved over the years, most recently through the changes made by the Dodd-Frank Act. First, as was the case prior to the enactment of the Dodd-Frank Act, we are responsible for protecting the safety and soundness of federally insured depository institutions affiliated with any kind of holding company. With the Dodd-Frank Act's transfer of SLHC oversight to the Federal Reserve, that statutory responsibility now includes insurance holding companies. While the particulars are somewhat different than for bank holding companies, the aim and many of the tools to achieve this aim are the same.\n\nSecond, the Dodd-Frank Act sharpened our statutory mandate to make clear that the Federal Reserve is to regulate and supervise holding companies with a view to the safety and soundness of not only the holding company itself, but also its functionally regulated subsidiaries, including affiliated insured depository institutions. Again, while the particulars differ, this mandate applies to SLHCs as well as to bank holding companies.5 The Gramm-Leach-Bliley Act of 1999 had, at the least, rendered ambiguous the question of whether the Federal Reserve could take supervisory measures that involved a functionally regulated subsidiary of a holding company unless a specific threat to an affiliated depository institution could be established. The financial crisis underscored the importance for safety and soundness of not waiting until problems in the holding company were manifestly affecting the depository institution.\n\nThird, the Dodd-Frank Act also changed our statutory mandate to require that we regulate holding companies so as to promote the stability of the financial system as a whole. This means paying attention to interconnections among financial firms, correlations of asset holdings, and other characteristics that could endanger the nation's financial stability during periods of stress. One of the most notable differences between the Dodd-Frank Act and other financial legislation over the preceding half century is the frequency with which the phrases \"financial stability\" and \"systemic risk\" occur, either as the specific goal of certain new provisions or as a consideration to be taken into account in administering general regulatory authorities. As I have explained elsewhere,6 this systemic or \"macroprudential\" regulatory aim does not apply equally to all holding companies or banks. Indeed, with respect to community banks, for example, it does not really apply at all. It is important that financial regulation be tiered so as to regulate for the kinds of risks various groups of financial institutions actually pose, rather than to regulate in a monolithic fashion.\n\nFourth, for all the broadening of our statutory mandate, one feature of the financial regulatory system that the Dodd-Frank Act preserved was the functional regulation of holding company affiliates based on the kind of financial intermediation in which they are engaged. Thus, even though we do apply consolidated capital and liquidity requirements at the holding company level, we do not specifically apply them to broker-dealer, commodities merchant, or investment company affiliates. Nor do we have any role in the investor protection and market functioning mandates in the regulatory regimes administered by the Securities and Exchange Commission (SEC) and the Commodity Futures Trading Commission. Similarly, we have no role in regulating the types of insurance offered by affiliates of the holding companies we supervise or the manner in which the insurance is provided. These matters are the province of state insurance regulators. In fact, because of the overall structure of insurance regulation as specified by Congress in the McCarran-Ferguson Act and elsewhere, the line here is arguably brighter than in other areas.\n\nIn pursuing what might be termed its dual regulatory mandate of protecting the safety and soundness of depository institutions and their holding companies and promoting financial stability, the Federal Reserve must develop regulatory and supervisory measures that are appropriate for a range of non-bank financial intermediaries. Consider, for example, the risks associated with bank holding companies containing large broker-dealer operations. Unlike traditional commercial banks whose activities are funded with retail deposits, these bank holding companies are typically heavily reliant on repurchase agreements (or repos) and other types of short-term wholesale funding. The events of 2007 to 2008 reminded us that, while this type of funding may be very stable during normal times, it can disappear overnight in periods of stress. Runs by providers of short-term wholesale funding may not only precipitate the failure of an individual firm by depleting that firm's capital and liquidity buffers, but also precipitate contagion that can imperil the rest of the financial system.\n\nAs a result of this very dynamic during the financial crisis, the five large, formerly freestanding broker-dealers have mostly been absorbed by, or converted into, bank holding companies. In our post-crisis development of liquidity requirements and stress testing, and in reforming capital requirements, we needed to pay particular heed to these critical funding differences between traditional commercial banks and broker-dealers. Similarly, in building out our regulation and supervision of insurance companies, we are paying particular attention to how their funding patterns differ from other forms of financial intermediaries.\n\nHere, though, the major relevant difference is that the funding structures of traditional insurers are generally much more stable than the funding structures of commercial banks, much less broker-dealers. A traditional insurance company's liabilities are largely composed of contingent claims based on the occurrence of specified events, such as the death of an insured person or the destruction of property. Because these claims generally cannot be accelerated, companies engaged in traditional insurance activities are less vulnerable to runs and, accordingly, to short-term pressures to sell assets into declining markets. This insulation from creditor runs in turn suggests that capital and liquidity requirements for insurance companies should be calibrated differently than capital and liquidity requirements for dealer banks. Because Congress modified the Collins Amendment in late 2014, we can now tailor capital requirements for insurance companies.\n\nHowever, it is important to add that the balance sheet of an insurance company can look quite different from the traditional picture I have just sketched. For example, a life insurer may offer investment and retirement products with account values that can be withdrawn at the discretion of policyholders, sometimes with little or no surrender penalty. The option to surrender creates the potential for increased claims that could strain the liquidity of the firm. Relatedly, the extensive involvement of an insurance firm in securities lending, repo, over-the-counter derivatives, and other capital markets activities can create a balance sheet with much tighter connections to the rest of the financial system and greater liquidity risk in times of financial market stress. As with other financial intermediaries, insurers then become subject to demands for posting additional collateral or closing out positions as unfavorable market conditions take hold. In addition, if the positions of the insurance company are large enough, it could become a potential vehicle for transmitting distress at the company to other parts of the financial system.\n\nThe foregoing considerations suggest that we should distinguish between insurance companies that we oversee solely because they own an insured depository institution and those that have been designated as systemically important by the FSOC. This is precisely the path we are taking with regard to our supervision of these firms. For the former group, our supervisory efforts to date have focused on ensuring that the companies have strong internal controls and effective corporate governance, as well as satisfactory risk identification, measurement, and management. For firms designated as systemically important, our supervision has additionally emphasized capital and liquidity planning and positions, management of core business lines, and recovery and resolution planning. Board staff meets with the primary state insurance departments that supervise the insurance companies for which we have consolidated supervisory responsibility and, together with lead state supervisors, we co-host supervisory colleges and crisis management groups for AIG (American International Group, Inc.) and Prudential. We continue to discuss supervisory plans and findings for the insurance firms, extend invitations for joint inspection activities, and discuss common areas of supervisory focus.\n\nAs you likely know, the Board is also working to develop a regulatory framework for its supervised insurance companies. The Dodd-Frank Act authorizes the Board to establish minimum capital requirements for both systemically important insurance companies and SLHCs and bank holding companies predominantly engaged in insurance activities. For systemically important insurance companies, the Dodd-Frank Act directs the Board to establish enhanced prudential standards in order to mitigate risks to U.S. financial stability that could arise from the material distress, failure, or ongoing activities of these companies. The enhanced prudential standards must include, among other things, enhanced capital requirements, liquidity requirements, corporate governance and risk-management standards, and resolution planning requirements. We have already established resolution planning requirements for the systemically important firms. At present, we have three major regulatory initiatives underway for our supervised insurance firms: first, reporting requirements for the systemically important firms; second, enhanced corporate governance, risk management, and liquidity standards for those same firms; and third, capital requirements for all supervised insurance firms. Let me say a few words about the first two and then spend the rest of my remarks on capital requirements, which I know are probably of the greatest interest.\n\nAbout a month ago, the Federal Reserve proposed new reporting requirements specifically for the systemically important insurance companies.7 These reporting requirements are designed, among other things, to keep us informed as to the financial condition and risk profile of these firms, as well as the extent to which their activities and operations could pose a threat to the financial stability of the United States. The proposed reporting requirements differ substantially from reporting requirements for bank holding companies, and from available U.S. Generally Accepted Accounting Principles (U.S. GAAP) financial information filed with the SEC. They are highly tailored to the assets, liabilities, and risks of insurance companies. We look forward to receiving public comment on the proposal.\n\nRegarding enhanced prudential standards, the Federal Reserve's enhanced corporate governance and risk-management standards for systemically important insurance companies will likely build on the core provisions of our consolidated supervisory framework for large domestic and foreign banking organizations, with appropriate adjustments to reflect these firms' predominantly insurance business model.8 The framework will mandate standards for the systemically important insurance companies to follow in managing risk and will identify the parties responsible for ensuring the integrity of a company's risk-management practices. Enhanced liquidity requirements will likely include internal control requirements, general comprehensive cash flow projections, contingency plans to manage liquidity stress events, and internal liquidity stress testing requirements. I expect that these proposed enhanced prudential standards for systemically important insurance companies will be considered by the Board in the coming weeks. Of course, we look forward to public comment on these standards, once proposed.\n\nCapital Requirements for Insurance Companies Supervised by the Federal Reserve\nIn formulating capital standards for the insurance companies we supervise, our goals should track our overall goals in financial regulation, as I described them a few moments ago. Thus we should aim, first, to protect depository institutions and, second, to promote financial stability in a manner that takes account of both the unique form of financial intermediation reflected in the traditional insurance business and the activities by a few firms that are much more closely connected to short-term financial markets and the rest of the financial system. As with some of the other measures I have mentioned, these factors argue for different approaches to capital requirements for the systemically important insurance companies, on the one hand, and for the rest of the insurance companies we supervise, on the other. That is, indeed, the direction in which I believe we are headed.\n\nThere are, as all of you know, a lot of ideas out there as to how we should construct the capital requirements we will apply to insurance companies. Some, such as variations on the Solvency II approach used in the European Union, strike us as unpromising. The valuation frameworks for insurance liabilities adopted in Solvency II differ starkly from U.S. GAAP and may introduce excessive volatility. Such an approach would also be inconsistent with our strong preference for building a predominantly standardized risk-based capital rule that enables comparisons across firms without excessive reliance on internal models. Finally, it appears that Solvency II could be quite pro-cyclical.\n\nOther ideas have some conceptual appeal, but strike us as impractical for the foreseeable future. Most prominent among these is an approach based on internal cash flow stress testing. The appeal of this idea lies in its melding of capital and liquidity considerations. The relationship between a firm's capital levels and liquidity profile is something that needs to be kept in mind when formulating regulatory regimes for all forms of financial intermediaries. However, as I noted earlier, we are reluctant to rely on internal models for basic regulatory capital requirements, which makes this idea less appealing to us. The novelty and untested nature of this idea as a basis for regulation would, in any case, necessitate extensive development, likely over a period of years. While we have consciously taken a good bit of time in considering a capital regime for our supervised insurance firms in order to make sure we get it right, we cannot wait years more, especially because there is no guarantee that even this investment of effort would produce a feasible internal models-based capital rule. However, I think it is worth continuing to explore internal cash flow stress testing as we build the supervisory stress testing program for systemically important insurance companies.\n\nAnother set of possibilities is raised by the work of the International Association of Insurance Supervisors (IAIS). As part of its effort to create a common framework for the supervision of internationally active insurance groups, the IAIS began work on a comprehensive insurance capital standard (ICS) in 2013, issued an initial consultative proposal on the ICS in late 2014, and will continue work on the ICS for at least the next few years. The ICS would be the first international, group‑wide capital standard broadly applicable to internationally active insurance groups and would incorporate internationally compatible valuation principles, definitions of capital resources, and risk‑based capital requirements for assets and insurance liabilities.\n\nProgress in developing such a global capital standard for internationally active insurance firms has been slow. I will mention some of the difficulties that have been encountered. First, there is considerable heterogeneity among the insurance products offered in different jurisdictions. As one example, annuities and other savings and retirement products tend to be offered less frequently in countries with relatively expansive government pension programs. In the context of developing capital requirements, a second factor has been jurisdictional variations in accounting and valuation standards on which global capital requirements for insurance companies can be built. A third factor has been significant disagreement on the extent to which capital standards for internationally active insurance companies should be built on internal models. These challenges and the protracted process they have occasioned have, as a practical matter, rendered the ICS insufficiently developed to be an option as the Federal Reserve moves forward with capital requirements applicable to the insurance companies we supervise.\n\nA second relevant initiative of the IAIS involves the design of an enhanced regulatory and supervisory framework for global systemically important insurers (G-SIIs). In 2014, the IAIS released the Basic Capital Requirement (BCR) for G-SIIs. It is the first international consolidated capital standard developed for the insurance industry. The IAIS developed the BCR in an effort to ensure the soundness of global insurance firms with the largest systemic footprints. In 2015, the IAIS supplemented the BCR with a Higher Loss Absorbency (HLA) capital standard for G-SIIs. But the IAIS will need to revisit the BCR after the first version of ICS is complete and will also need to revisit HLA after further refinement is made on its G‑SII identification methodology. This somewhat provisional character of the BCR, along with its reliance on a method of valuation not in use by U.S. companies and regulators, mean it does not really fit our need for an approach that can--as a practical matter--be developed and implemented in the relatively near term.\n\nThese are some of the paths we do not intend to take in formulating capital requirements for insurance firms. The approach we do intend to follow will be elaborated in what I anticipate will be an advance notice of proposed rulemaking (ANPR) to be issued in the coming weeks. As I suggested earlier, the ANPR will likely put forward two different methodologies--one for the insurance firms that we supervise solely because they own a bank or thrift and the other for the firms designated as systemically important.\n\nA. Insurance Companies Owning a Bank or Thrift: The Building Block Approach\nThe Federal Reserve has traditionally set capital requirements for holding companies on a consolidated basis. Among other things, a consolidated capital standard deters firms from moving assets around its affiliates in order to take advantage of lower requirements applied to different affiliates for particular assets. Insofar as publicly traded banking organizations are required by securities laws to file consolidated, U.S. GAAP-consistent financial statements, there is both a parallelism between accounting and capital regulation and a measure of economy in the compliance costs of a consolidated capital rule.\n\nIn contrast, most insurance firms subject to our regulation only because they own depository institutions do not produce consolidated financial statements. Furthermore, Congress has prohibited the Federal Reserve from requiring insurance firms that file only Statutory Accounting Principles (SAP) financial statements to produce U.S. GAAP consolidated financial statements.9 Given that these firms have not been designated systemically important and that the depository institutions they own tend to be relatively small parts of the total firm, the compliance costs of requiring a move to some non-U.S. GAAP form of consolidated approach may well not be worth the incremental safety and soundness benefits of doing so. Together, these considerations are leading us to what we refer to as the building block approach (BBA), which is likely the approach that we will put forth for comment in the ANPR for this group of firms.\n\nThe BBA would aggregate capital resources and capital requirements across the different legal entities in the group to calculate combined, group-level capital resources and requirements. A firm's aggregate capital requirements generally would be the sum of the capital requirements at each subsidiary. The capital requirement for each regulated insurance or depository institution subsidiary generally would be based on the regulatory capital rules of that subsidiary's lead regulator--whether a state or foreign insurance regulator or a federal banking regulator for depository institutions. The regulatory capital requirement for any non-insurance, non-banking subsidiaries--which at present are relatively minor parts of these firms--would probably be determined under the standardized risk-based capital rules applicable to affiliates of bank holding companies.\n\nShould we adopt this approach, we will need to develop a formula or scalar to put the different regulatory regimes on a comparable basis. With an eye towards the kind of issues that are usually addressed by a consolidated capital approach, we will also need to fashion standards for adjustments to address inter-company transactions and possibly some other exposures. An example of the latter would be potential adjustments to harmonize permitted accounting practices that vary across states.\n\nThe BBA would efficiently leverage existing legal-entity-level regulatory capital frameworks that already apply to the various units of the supervised insurance group. As such, it would involve relatively low regulatory burden for these entities, even as it produces regulatory capital requirements that are reasonably well tailored to the insurance-related risks for each distinct jurisdiction and business line of the group.\n\nB. Systemically Important Insurance Companies: The Consolidated Approach\nBy definition, the insurance companies designated by the FSOC are systemically important. For these firms, application of an aggregated approach like that of the BBA could pose significant risks to the Federal Reserve's statutory aims of safety and soundness and financial stability. The BBA, recall, would simply aggregate capital requirements that may not be founded upon financial stability considerations. A consolidated form of capital requirements is key to ensuring that risks to the financial system as a whole (as compared, say, to investor or policyholder protection) are accounted for.\n\nFor these firms, then, the ANPR is likely to seek comment on what we have internally been calling the consolidated approach (CA). Let me note at the outset that this is not the consolidated capital framework we apply to bank holding companies. As with our capital requirements for bank holding companies, the CA would categorize all of the consolidated insurance group's assets and insurance liabilities into risk segments, apply risk factors to the amounts in each segment, and then set a minimum ratio of required capital comparing the consolidated capital requirements to the group's consolidated capital resources. However, the CA would use risk weights or risk factors that are more appropriate for the longer-term nature of most insurance liabilities.\n\nLike the BCR of the IAIS, the CA would take a consolidated approach to capital requirements. However, unlike the BCR, the foundation of the CA would be consolidated financial information based on U.S. GAAP, with appropriate adjustments for regulatory purposes. Our current thought is that the CA would initially be relatively simple in design, with a relatively small number of risk categories. Thus there would be a broad risk segmentation of asset classes and insurance liabilities. However, as we gained experience with the CA, we would have the option of making it increasingly granular in order to achieve greater risk sensitivity.\n\nThe CA, as a consolidated capital framework, would help prevent intra-group regulatory arbitrage opportunities and the potential for double leverage.10 It would also be compatible with supervisory stress testing, which--as you all know--is now a central component of our supervisory program for making systemically important firms highly resilient, as well as for giving us a more complete picture of risks in the financial system as a whole. Obviously, the compliance costs associated with the CA will be higher than those of the BBA. But this enhanced regulation is justified by the increased risks to the financial system associated with these firms. Indeed, it is our obligation under the Dodd-Frank Act to impose stricter regulation on these firms. Even so, by constructing a separate consolidated approach to capital for systemically designated insurance firms, compliance costs for these firms should be considerably lower than if they had to conform to the bank holding company capital regime. Finally, I would note that adoption by the Federal Reserve of a fully consolidated capital requirement for systemically important insurance companies might also help advance the international development of appropriate and effective capital requirements for insurance firms of global systemic importance.\n\nConclusion\nAs noted earlier, the Board's prudential regulatory objectives pertaining to supervised insurance companies are to protect the safety and soundness of the consolidated company, to protect any subsidiary depository institutions of the company, and to mitigate any threats to financial stability that might be posed by the activities, material financial distress, or failure of the company. Just as we have done with other non-bank financial intermediaries for which we have been given regulatory responsibilities, we will fashion a regime that takes account of the particular characteristics and risks of those intermediaries. We have taken a good bit of time in arriving at some potential insurance regulatory capital frameworks precisely because we wanted to consider these issues thoroughly. Our tentative conclusion is that a bifurcated approach to a capital regime for insurance companies makes sense in light of these considerations. But we anticipate using the vehicle of an ANPR in order to give all interested parties an opportunity to comment on this approach before we turn to developing and proposing its details. In this process, we of course especially welcome the views of those of you on the front lines of insurance supervision.\n\nThank you very much.\n\n1. NAIC Financial Regulatory Services, \"P&C, Title, Life/A&H, Fraternal, and Health Industry Snapshots for the Period Ended December 31, 2015 (PDF) .\" Return to text\n\n2. Ibid.; Bureau of Economic Analysis (2016), \"Gross Domestic Product: First Quarter 2016 (Advance Estimate) (TXT),\" April 28, Table 9; Federal Insurance Office (2015), \"Annual Report on the Insurance Industry (PDF),\" September, p. 12. Return to text\n\n3. NAIC Financial Regulatory Services, \"P&C, Title, Life/A&H, Fraternal, and Health Industry Snapshots for the Period Ended December 31, 2015 (PDF) ,\" pp. 1, 4-5. Return to text\n\n4. Ibid. Return to text\n\n5. See 12 USC § 1467a(b)(4)(A). Return to text\n\n6. See Daniel K. Tarullo (2014), \"Rethinking the Aims of Prudential Regulation,\" speech delivered at the Federal Reserve Bank of Chicago Bank Structure Conference, Chicago, Illinois, May 8. Return to text\n\n7. See 81 Fed. Reg. 24097 (April 25, 2016). Return to text\n\n8. See Board of Governors of the Federal Reserve System, Division of Banking Supervision and Regulation (2012), \"Consolidated Supervision Framework for Large Financial Institutions,\" Supervision and Regulation Letter SR 12-17 (December 17). Return to text\n\n9. The SAP are a set of accounting rules for insurance companies established by the NAIC and used to prepare those companies' financial statements. Return to text\n\n10. \"Double leverage\" refers to a parent company's use of debt to fund an equity investment in a subsidiary. Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "May 19, 2016",
        "title": "(Money), Interest and Prices: Patinkin and Woodford",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20160519.htm",
        "content": "May 19, 2016\n\nVice Chairman Stanley Fischer\n\nAt \"A Conference in Honor of Michael Woodford’s Contributions to Economics\" cosponsored by the Federal Reserve Bank of New York, Columbia University Program for Economic Research, and Columbia University Department of Economics, New York, New York\n\nIt is an honor for me to speak at the opening of this conference in honor of Michael Woodford, whose contributions to the theory of economic policy are frequently a central part of the economic analysis that takes place in the policy discussions at the Federal Reserve.1\n\nThe main story I want to tell today is about the quality of Michael's major book, Interest and Prices (henceforth MWIP). I will start with his predecessors, beginning as Michael does in his Interest and Prices with Wicksell.2 3 I shall quote key points from and about Wicksell's Interest and Prices (henceforth KWIP), and following that, from Patinkin's Money, Interest, and Prices (second edition, 1965) (henceforth MIP), which are relevant to MWIP, Michael Woodford's Interest and Prices (2003).\n\n1. I am grateful to Hess Chung, Rochelle Edge, William English, Michael Kiley, Thomas Laubach, Matthias Paustian, David Reifschneider, Jeremy Rudd, and Stacey Tevlin of the Federal Reserve Board for their advice and assistance. Return to text\n\n2. Wicksell's Interest and Prices, published in German in 1898 as Geldzins und Guterpreise by Gustav Fischer (Jena), was first published in English (translated by R.F. Kahn) by Macmillan & Co. in 1936. It was published in the United States by Augustus Kelley in 1965 in the series Reprints of Economic Classics. Return to text\n\n3. See Torsten Gardlund (1958), The Life of Knut Wicksell, trans. Nancy Adler (Brookfield, Vt.: Edward Elgar). Wicksell was not only a superb economist but also a remarkably interesting man, whose major works in economics were published starting in the late 1890s, when he was nearing the age of 50 (he was born in 1851 and died in 1926). Much of his earlier work was on Malthus and Malthusianism. The last paragraph of the text of Gardlund's book (p. 330) is about Wicksell's funeral and reads \"Various associations and academic institutions sent the customary wreaths, but many of Wicksell's friends and disciples, honoring a request, instead sent their contributions to the Malthusian Advice Bureau.\" Return to text\n\n4. He gives several reasons that the assumptions have little relation to practice, including that there is \"a kind of collective holding of balances, arising out of the acceptance by banks of deposits.\" Return to text\n\n5. See Joseph E. Stiglitz, ed. (1966-2011), The Collected Scientific Papers of Paul Samuelson, vol. II (Cambridge, Mass.: MIT Press), pp. 1682-92. Return to text\n\n6. See Knut Wicksell (1935), Lectures in Political Economy, vol. I: General Theory and vol II: Money (London: George Routledge and Sons); reprinted in 1967 (Fairfield, N.J.: Augustus M. Kelley). Return to text\n\n7. The first edition of Money, Interest, and Prices was published in 1956 by Row, Peterson (Evanston, Ill.); the second edition in 1965 by Harper & Row (New York). Return to text\n\n8. See Stanley Fischer (1993), \"Money, Interest, and Prices\" in Haim Barkai, Stanley Fischer, and Nissan Liviatan, eds., Monetary Theory and Thought: Essays in Honour of Don Patinkin (London: Palgrave Macmillan). Return to text\n\n9. See Kenneth J. Arrow (1957), \"Review of Money, Interest, and Prices,\" Mathematical Reviews, vol. 18 (September). Return to text\n\n10. See Harry G. Johnson (1962), \"Monetary Theory and Policy,\" American Economic Review, vol. 52 (June), pp. 335-84. Return to text\n\n11. As noted in my 1993 article, I did not find that criticism compelling. Return to text\n\n12. See Robert Barro and Herschel Grossman (1976), Money, Employment and Inflation (New York: Cambridge University Press). Return to text\n\n13. These are equations (1.12), (1.13), and (1.14), respectively, in chapter 4, which appear on page 246 of MWIP, the derivation of which is discussed on pp. 243-45. Return to text\n\n14. It is worth noting that the money stock dropped out of many models in the 1980s because standard relationships between money and real variables became unstable and because money aggregates became difficult to control. Or, as Gerald Bouey, former governor of the Bank of Canada, once said to the House of Commons Standing Committee on Finance, Trade and Economic Affairs, \"We did not abandon M1, M1 abandoned us.\" Return to text\n\n15. See Michael Woodford (2012), \"Methods of Policy Accommodation at the Interest-Rate Lower Bound,\" in Proceedings--Economic Policy Symposium--Jackson Hole (Kansas City: Federal Reserve Bank of Kansas City), pp. 185-288. Return to text\n\n16. See Gauti B. Eggertsson and Michael Woodford (2003), \"The Zero Bound on Interest Rates and Optimal Monetary Policy,\" Brookings Papers on Economic Activity, no. 1, pp. 139-211. Return to text\n\n17. I am grateful to Hess Chung of the Federal Reserve Board for drawing to my attention the general point made in this paragraph. Return to text\n\n18. See Robert J. Barro (1974), \"Are Government Bonds Net Wealth?\" Journal of Political Economy, vol. 82 (November-December), pp. 1095-1117. Return to text\n\n19. See Joseph E. Gagnon (2016), \"Quantitative Easing: An Underappreciated Success ,\" Policy Brief 16-4 (Washington: Peterson Institute for International Economics, April). Return to text\n\n20. I draw here on notes provided by Michael Kiley of the Federal Reserve Board. Return to text\n\n21. In Woodford's and Wicksell's analyses, natural values are those that would prevail in the absence of nominal rigidities. Return to text\n\n22. See, for example, Katharine Neiss and Edward Nelson (2002), \"Inflation Dynamics, Marginal Cost, and the Output Gap: Evidence from Three Countries,\" unpublished paper, Bank of England, July; Rochelle Edge, Michael Kiley, and Jean-Philippe Laforte (2008), \"Natural Rate Measures in an estimated DSGE model of the U.S. economy,\" Journal of Economic Dynamics and Control, vol. 32, pp. 2512-35. Return to text\n\n23. See, for example, figure 1 in Janet Yellen (2015), \"The Economic Outlook and Monetary Policy,\" speech delivered at the Economic Club of Washington, Washington, D.C., December 2. Return to text\n\n24. See Thomas Laubach and John Williams (2003), \"Measuring the Natural Rate of Interest,\" Review of Economics and Statistics, vol. 85, pp. 305-25. Return to text"
    },
    {
        "speaker": "Lael Brainard",
        "position": "Governor",
        "date": "April 14, 2016",
        "title": "The Use of Distributed Ledger Technologies in Payment, Clearing, and Settlement",
        "href": "https://www.federalreserve.gov/newsevents/speech/brainard20160414a.htm",
        "content": "April 14, 2016\n\nGovernor Lael Brainard\n\nAt the Institute of International Finance Blockchain Roundtable, Washington, D.C.\n\nInnovation in digital finance, loosely referred to as fintech, is capturing imaginations from Silicon Valley to Chicago to Wall Street. We're seeing a steady stream of announcements of new startups and partnerships, and consumers are downloading fintech apps at an even faster pace.\n\nFinancial products, services, and transactions lend themselves to successive waves of technological disruption because they can readily be represented as streams of numerical information ripe for digitization. However, as technological tools used by the industry change over time, it is important to keep sight of their impact on the public, whether it be on families seeking to own their own home, seniors seeking financial security, young adults seeking to invest in education and training, or small businesses attempting to smooth through volatile revenues and expenses.\n\nCurrent developments in the digitization of finance are important and deserving of serious and sustained engagement on the part of policymakers and regulators. The Federal Reserve Board has established a multi-disciplinary working group that is engaged in a 360-degree analysis of fintech innovation. We are bringing together the best thinking across the Federal Reserve System, spanning key areas of responsibility, from supervision to community development, from financial stability to payments. As policymakers, we want to facilitate innovation where it has the potential to yield public benefit, while ensuring that risks are thoroughly understood and managed. That orientation may have different implications in the arena of consumer and small business finance, for instance, as compared with payment, clearing, and settlement in the wholesale financial markets.\n\nTechnological and Organizational Changes in Payment, Clearing, and Settlement \nToday, I will focus on newly emerging distributed ledger technologies and related protocols, which were inspired originally by Bitcoin, and their potentially important applications to payment, clearing, and settlement in the wholesale markets.\n\nSuccessive waves of technological advance have swept through payment, clearing, and settlement over the past two centuries. In the 19th century, railroads and the telegraph helped improve speed and logistics. In the second half of the 20th century, computers were introduced to deal with the clearing of overwhelming volumes of paper checks and stock certificates stimulated by post-war growth. Starting at about the same time and continuing through today, new electronic networks have been established to allow high-speed computerized financial communication. As automation has evolved, payment, clearing, and settlement systems have been developed for conducting and processing transactions within and between firms. However, many of these systems have historically operated in silos, which can be hard to streamline or replace. In some areas, business processes may still rely heavily on manual or semi-automated procedures.\n\nOver time, banks and other firms have organized various types of clearinghouses to coordinate clearing and settlement activities in order to reduce costs and risks. The adoption of multilateral clearing in the United States was a key organizational innovation that began with the founding of the New York Clearing House in the 1850s. This led to notable efficiencies and risk reduction in the clearing of checks. Multilateral clearing was also used early on to improve clearing in the securities and derivatives markets. By the 1970s, the United States turned to technologies based on the centralized custody and clearing of book-entry securities in order to respond to the paperwork crisis in the equities markets. Following the recent financial crisis, the United States--along with many other countries--expanded the scope of central clearing to help address problems in the bilateral clearing of derivatives contracts.\n\nToday, the possible development and application of distributed ledger technology has raised questions about potentially far reaching changes to multilateral clearinghouses and the roles of financial institutions as intermediaries in trading, clearing, and settlement for their clients. In the extreme, distributed ledger technologies are seen as enabling a much larger universe of financial actors to transact directly with other financial actors and to exchange assets versus funds (that is, to \"clear\" and settle the underlying transactions) virtually instantaneously without the help of intermediaries both within and across borders. This dramatic reduction in frictions would be facilitated by distributed ledgers shared across various networks of financial actors that would keep a complete and accurate record of all transactions, and meet appropriate goals for transparency, privacy, and security.\n\nAt this stage, such a sea-change may sound like a remote possibility, particularly for the high volume and highly regulated clearing and settlement functions of the wholesale financial markets. But profound disruptions are not unprecedented in this arena. In the early 1960s, the use of computerized book-entry securities systems to streamline custody, clearing, and settlement in the securities markets may have seemed like a technologist's pipe dream. But these technologies became an important part of industry-wide changes in the 1970s. Today we rely on these types of systems for the daily operation of the markets.\n\nGiven this backdrop, it is important to give promising technologies the serious consideration they merit, seek to understand their opportunities and risks, and actively engage in dialogue about their potential uses and evolution. At the Federal Reserve, we approach these issues from the perspective of policymakers safeguarding the public interest in safe and sound core banking institutions, financial stability, particularly as it pertains to the wholesale financial markets, and the security and efficiency of the payment system.\n\nDistributed ledger technology was introduced for the transfer and record-keeping of Bitcoin and other digital currencies. The essential advantage of the technology is that it provides a credible way to transfer an asset without the need for trust in intermediaries or counterparties, much like a physical cash transaction. To do that, a transfer process must be able to credibly confirm that a sender of an asset is the owner and has enough of the asset to make the transfer to the receiver. This requires a secure system or protocol to transfer assets (the rails), protection against assets being transferred twice (the so-called double spend problem), and an immutable record of asset ownership that can be automatically and securely updated (the ledger). The tokenization of digital assets can facilitate the transfer process.\n\nThe genuinely innovative aspect of the technology combines a number of different core elements that support the transfer process and recordkeeping:\n\nWhile Bitcoin was originally associated with the concept of a universally available, publicly shared digital ledger technology without any central authority, many of the use cases that are currently under development and discussion rely on \"permissioned\" ledgers in which only permitted, known participants can validate transactions. These in turn can be either public or private in terms of access to the ledger.\n\nThe resulting Internet of Value holds out the promise of addressing important frictions and reducing intermediation steps in the clearing and settlement process. For example, in cross-border payments, faster processing and reduced costs relative to current correspondent banking are cited as specific potential benefits. Reducing intermediation steps in cross-border payments may help reduce costs and counterparty risks and may additionally improve financial transparency.\n\nIn securities clearing and settlement, the potential shift to one master record shared among participants has some appeal. Having one immutable record may have the potential to reduce or even eliminate the need for reconciliation by avoiding duplicative records that have different details related to a transaction that is being cleared and settled. This also can lead to greater transparency, reduced costs, and faster securities settlement. Likewise, digital ledgers may improve collateral management by improving the tracking of ownership and transactions.\n\nFor derivatives, there is interest in the potential for digital ledger protocols to enable self-execution and possibly self-enforcement of contractual clauses, in the context of \"smart contracts.\"\n\nAs we engage with industry and stakeholders to assess the potential applications of digital ledger and related technologies in the payment, clearing, and settlement arena, we will be guided by the principles of efficiency, safety and integrity, and financial stability.\n\nEfficiency \nMany are excited about the potential for these new technologies to reduce costs and frictions, such as those associated with collateral management and custodial services, reduce settlement risk, enhance security, increase transparency, and offer new services. But there are also concerns about the costs and risks from the early adoption of rapidly evolving and uncertain technologies and technological hurdles in integrating new technologies into legacy systems and achieving interoperability across different ledgers and networks. There are questions about the need for substantial new investments to obtain capabilities like real-time processing where these capabilities already exist at some of the industry's core infrastructures. There are also cautions that realizing the full potential of distributed ledger technologies could take many years.\n\nMuch of the case for adopting distributed ledger technologies revolves around achieving greater efficiency and reducing time and risks to post-trade clearing and settlement. But first, important technological challenges will need to be addressed to permit widespread adoption and migration away from legacy systems and networks. These include the need for standardization, the development of protocols that will permit interoperability between other ledgers and networks, and the reduction of computational intensity and costs.\n\nMoreover, distributed ledgers will have to compete with other options and priorities of financial firms and clearinghouses in a highly regulated financial ecosystem. Thus, a major threshold question for the adoption of distributed ledger technology within and between groups of firms engaging in particular types of transactions is whether the advantages outweigh the costs of replacing legacy systems.\n\nIn some cases, where distributed ledger technology can be employed internally within a firm to automate and speed up business processes, traditional business case analysis would presumably lead to efficient technology choices. By contrast, where coordinated industry-level decisions would be needed to develop distributed ledgers shared by multiple firms, the case must be compelling for entire networks of market participants that will need to make the investments, as well as for the broader public interest.\n\nThis set of competing considerations suggests there are likely to be a spectrum of cases. At one end are the high-volume, heavily regulated markets that have made large investments in central clearing to provide safe and efficient clearing and settlement for the industry and the public. These markets must always actively consider technological and other enhancements to strengthen efficiency and safety. But as a practical matter, the large-scale adoption of wholly new clearing technologies to replace existing legacy technologies for major markets may face a significant hurdle initially, such that incremental change or delayed adoption until the technology has achieved greater maturity and standardization may be more likely.\n\nAt the other end of the spectrum, there appear to be some markets or segments where clearing practices are relatively cumbersome and outmoded, and the network hurdles to the adoption of new technologies are lower. Improvements in smaller markets would also provide an opportunity for market participants to gain operational and business experience with distributed ledger technologies that could help inform and strengthen the case for broader applications over time.\n\nA middle case would involve the application of distributed ledger technologies to bilateral clearing even where improvements have already been made since the financial crisis. A threshold issue will be the design and safety of new technologies and whether firms will want to share a distributed ledger to manage transactions with their different counterparties and customers. No doubt much will depend not only on cost but also on a host of business, technical, security, and other issues. Even so, change might hold promise for improving bilateral clearing, and might also help us think about the long-run trade-offs between bilateral and central clearing.\n\nAn assessment of the longer-term potential for deployment of distributed ledger technology naturally raises questions about whether it might ultimately impact the organizational structure for clearing and settlement. As multilateral clearing organizations have strengthened and spread across many of the major asset classes traded in the markets, they have enabled coordinated action on governance, rules, technology, and risk management. It is possible that new technologies could substantially change the way these functions are pursued, but it would be surprising if they would obviate the need for multilateral clearing in the major markets. Governance, in particular, is a core function that is inescapably necessary if multilateral activity, even activity dealing with distributed ledgers, is to operate effectively. Indeed, if new technologies could lower the costs of multilateral clearing relative to bilateral clearing in new market segments, multilateral clearing could even grow.\n\nToday's clearing houses will likely continue to play a central role in highly regulated markets and be well positioned to evaluate and implement new clearing technologies, while continuing to provide core governance functions in the market. Nonetheless, it is also possible that if distributed ledgers ultimately cross asset classes and even industries, traditional clearinghouses serving specific market segments might have to evolve or new organizations might develop to provide an optimal approach to implementation. Moreover, in principle, the use of distributed ledgers in new market segments may call for new clearing arrangements more in tune with new technologies. Similarly, organizations that can provide governance or other coordinating functions in bilaterally cleared markets may also require organizational structures somewhat different from traditional clearinghouses. We will be following these issues with interest.\n\nSafety, Integrity, and Financial Stability\nSafety and integrity in clearing and settlement is a critical, long-standing public policy objective of the Federal Reserve, and is critical for broader financial stability. Regardless of the technologies employed, if risks to clearing and settlement are not identified and addressed, then banks, dealers, and other firms will not be able to manage their obligations and market functioning may be impaired. This is a key reason why major clearing and settlement systems are highly regulated. Hence, the fundamental threshold test for new technologies will be whether they can be deployed and operated safely, with the requisite high degree of operational and financial integrity, security, and resilience across a wide range of adverse scenarios. Regulators and the public need to know that if adverse scenarios do occur, there will be robust management and governance to respond effectively.\n\nDigital ledger technologies will need to be able to address the range of issues revolving around the confidentiality and security of firm and client records and data on the one hand, as well as law enforcement requirements and issues on the other. New technologies must be robust in practice, not just in theory, to attacks on security, and must be able to maintain appropriate confidentiality for records and data.\n\nIn addition, it will be important that digital ledger technologies can meet the requirements of law enforcement and other regulators to address money laundering, terrorist financing, and other key law enforcement concerns. Indeed, there is some potential that the new technologies could enable improved authorized access to certain data records in a much more efficient and comprehensive manner than has previously been possible, thereby potentially reducing costs associated with complying with the Bank Secrecy Act.\n\nOverall we should be optimistic that a range of new technologies hold the promise of providing more robust security, resilience, and information. We cannot afford to assume that change necessarily equals greater risk. Of course, much will depend on the technology itself, its scalability, its level of maturity, the controls and environment surrounding it, the standardization and accessibility of transactions data, the quality of management and governance, and the policy environment in which it is deployed.\n\nKey Challenges Going Forward\nToday, many industry participants are experimenting with distributed ledger technology in controlled, permissioned environments. If some of these experiments bear fruit, it will be important to address the challenge of how they would scale and achieve diffusion. In addition, determining exactly how the different distributed ledger technologies interoperate with each other, and legacy systems, will be critical. New and highly fragmented \"shared systems\" may create unintended consequences even as they aim to address problems created by today's siloed operations. Since distributed ledgers often involve shared databases, it will also be important to effectively manage access rights as information flows back and forth through shared systems. There may well be a tradeoff between the privacy of trading partners and competitors on the one hand, and the ability to leverage shared transactions records for faster and cheaper settlement on the other hand. And of course, development of sound risk-management, resiliency, and recovery procedures will be necessary to address operational risks. The Federal Reserve will continue to engage actively with the industry, stakeholders, and our regulatory colleagues as the industry works through these challenges and the technology evolves.\n\nI want to close by remembering a simple point that central bankers and markets have learned through hard lessons over many years. The daily operation of markets and their clearing and settlement functions are built on trust and confidence. Market participants trust that clearing and settlement functions and institutions will work properly every day. Confidence has built over time that when market participants trade, accurate and timely clearing and settlement will follow. Any disruption to this confidence comes at great cost to market integrity and financial stability. This is a matter of fundamental public interest. In safeguarding the public interest, the first line of inquiry and protection will always rest with those closest to the technology innovations and to the organizations that consider adopting the technology. But regulators also should seek to analyze the implications of technology developments through constructive and timely engagement. We should be attentive to the potential benefits of these new technologies, and prepared to make the necessary regulatory adjustments if their safety and integrity is proven and their potential benefits found to be in the public interest.\n\nI am grateful to Andrew Figura, Jeff Marquardt, and David Mills for their assistance in preparing this text."
    },
    {
        "speaker": "Janet L. Yellen",
        "position": "Chair",
        "date": "March 29, 2016",
        "title": "The Outlook, Uncertainty, and Monetary Policy",
        "href": "https://www.federalreserve.gov/newsevents/speech/yellen20160329a.htm",
        "content": "March 29, 2016\n\nChair Janet L. Yellen\n\nAt the Economic Club of New York, New York, New York\n\nFor more than a century, the Economic Club of New York has served as one of the nation's leading nonpartisan forums for discussion of economic policy issues. It is an honor to appear before you today to speak about the Federal Reserve's pursuit of maximum employment and price stability.\n\nIn December, the Federal Open Market Committee (FOMC) raised the target range for the federal funds rate, the Federal Reserve's main policy rate, by 1/4 percentage point. This small step marked the end of an extraordinary seven-year period during which the federal funds rate was held near zero to support the recovery from the worst financial crisis and recession since the Great Depression. The Committee's action recognized the considerable progress that the U.S. economy had made in restoring the jobs and incomes of millions of Americans hurt by this downturn. It also reflected an expectation that the economy would continue to strengthen and that inflation, while low, would move up to the FOMC's 2 percent objective as the transitory influences of lower oil prices and a stronger dollar gradually dissipate and as the labor market improves further. In light of this expectation, the Committee stated in December, and reiterated at the two subsequent meetings, that it \"expects that economic conditions will evolve in a manner that will warrant only gradual increases in the federal funds rate.\"1\n\nIn my remarks today, I will explain why the Committee anticipates that only gradual increases in the federal funds rate are likely to be warranted in coming years, emphasizing that this guidance should be understood as a forecast for the trajectory of policy rates that the Committee anticipates will prove to be appropriate to achieve its objectives, conditional on the outlook for real economic activity and inflation. Importantly, this forecast is not a plan set in stone that will be carried out regardless of economic developments. Instead, monetary policy will, as always, respond to the economy's twists and turns so as to promote, as best as we can in an uncertain economic environment, the employment and inflation goals assigned to us by the Congress.\n\nThe proviso that policy will evolve as needed is especially pertinent today in light of global economic and financial developments since December, which at times have included significant changes in oil prices, interest rates, and stock values. So far, these developments have not materially altered the Committee's baseline--or most likely--outlook for economic activity and inflation over the medium term. Specifically, we continue to expect further labor market improvement and a return of inflation to our 2 percent objective over the next two or three years, consistent with data over recent months. But this is not to say that global developments since the turn of the year have been inconsequential. In part, the baseline outlook for real activity and inflation is little changed because investors responded to those developments by marking down their expectations for the future path of the federal funds rate, thereby putting downward pressure on longer-term interest rates and cushioning the adverse effects on economic activity. In addition, global developments have increased the risks associated with that outlook. In light of these considerations, the Committee decided to leave the stance of policy unchanged in both January and March.\n\nI will next describe the Committee's baseline economic outlook and the risks that cloud that outlook, emphasizing the FOMC's commitment to adjust monetary policy as needed to achieve our employment and inflation objectives.\n\nRecent Developments and the Baseline Outlook\nReadings on the U.S. economy since the turn of the year have been somewhat mixed. On the one hand, many indicators have been quite favorable. The labor market has added an average of almost 230,000 jobs a month over the past three months. In addition, the unemployment rate has edged down further, more people are joining the workforce as the prospects for finding jobs have improved, and the employment-to-population ratio has increased by almost 1/2 percentage point. Consumer spending appears to be expanding at a moderate pace, driven by solid income gains, improved household balance sheets, and the ongoing effects of the increases in wealth and declines in oil prices over the past few years. The housing market continues its gradual recovery, and fiscal policy at all levels of government is now modestly boosting economic activity after exerting a considerable drag in recent years.\n\nOn the other hand, manufacturing and net exports have continued to be hard hit by slow global growth and the significant appreciation of the dollar since 2014. These same global developments have also weighed on business investment by limiting firms' expected sales, thereby reducing their demand for capital goods; partly as a result, recent indicators of capital spending and business sentiment have been lackluster. In addition, business investment has been held down by the collapse in oil prices since late 2014, which is driving an ongoing steep decline in drilling activity. Low oil prices have also resulted in large-scale layoffs in the energy sector and adverse spillovers to output and employment in industries that support energy production.\n\nOn balance, overall employment has continued to grow at a solid pace so far this year, in part because domestic household spending has been sufficiently strong to offset the drag coming from abroad. Looking forward however, we have to take into account the potential fallout from recent global economic and financial developments, which have been marked by bouts of turbulence since the turn of the year. For a time, equity prices were down sharply, oil traded at less than $30 per barrel, and many currencies were depreciating against the dollar. Although prices in these markets have since largely returned to where they stood at the start of the year, in other respects economic and financial conditions remain less favorable than they did back at the time of the December FOMC meeting. In particular, foreign economic growth now seems likely to be weaker this year than previously expected, and earnings expectations have declined. By themselves, these developments would tend to restrain U.S. economic activity. But those effects have been at least partially offset by downward revisions to market expectations for the federal funds rate that in turn have put downward pressure on longer-term interest rates, including mortgage rates, thereby helping to support spending. For these reasons, I anticipate that the overall fallout for the U.S. economy from global market developments since the start of the year will most likely be limited, although this assessment is subject to considerable uncertainty.\n\nAll told, the Committee continues to expect moderate economic growth over the medium term accompanied by further labor market improvement. Consistent with this assessment, the medians of the individual projections for economic growth, unemployment, and inflation made by all of the FOMC participants for our March meeting are little changed from December.2 A key factor underlying such modest revisions is a judgment that monetary policy remains accommodative and will be adjusted at an appropriately gradual pace to achieve and maintain our dual objectives of maximum employment and 2 percent inflation. Reflecting global economic and financial developments since December, however, the pace of rate increases is now expected to be somewhat slower. For example, the median of FOMC participants' projections for the federal funds rate is now only 0.9 percent for the end of 2016 and 1.9 percent for the end of 2017, both 1/2 percentage point below the December medians.\n\nAs has been widely discussed, the level of inflation-adjusted or real interest rates needed to keep the economy near full employment appears to have fallen to a low level in recent years. Although estimates vary both quantitatively and conceptually, the evidence on balance indicates that the economy's \"neutral\" real rate--that is, the level of the real federal funds rate that would be neither expansionary nor contractionary if the economy was operating near its potential--is likely now close to zero.3 However, the current real federal funds rate is even lower, at roughly minus 1-1/4 percentage point, when measured using the 12-month change in the core price index for personal consumption expenditures (PCE), which excludes food and energy. Thus, the current stance of monetary policy appears to be consistent with actual economic growth modestly outpacing potential growth and further improvements in the labor market.4\n\nLooking beyond the near term, I anticipate that growth will also be supported by a lessening of some of the headwinds that continue to restrain the U.S. economy, which include weak foreign activity, dollar appreciation, a pace of household formation that has not kept up with population and income growth and so has depressed homebuilding, and productivity growth that has been running at a slow pace by historical standards since the end of the recession. If these headwinds gradually fade as I expect, the neutral federal funds rate will also rise, in which case it will, all else equal, be appropriate to gradually increase the federal funds rate more or less in tandem to achieve our dual objectives. Otherwise, monetary policy would eventually become overly accommodative as the economy strengthened.5\n\nImplicitly, this expectation of fading headwinds and a rising neutral rate is a key reason for the FOMC's assessment that gradual increases in the federal funds rate over time will likely be appropriate. That said, this assessment is only a forecast. The future path of the federal funds rate is necessarily uncertain because economic activity and inflation will likely evolve in unexpected ways. For example, no one can be certain about the pace at which economic headwinds will fade. More generally, the economy will inevitably be buffeted by shocks that cannot be foreseen. What is certain, however, is that the Committee will respond to changes in the outlook as needed to achieve its dual mandate.\n\nTurning to inflation, here too the baseline outlook is little changed. In December, the FOMC anticipated that inflation would remain low in the near term due to the drag from lower prices for energy and imports. But as those transitory effects faded, the Committee expected inflation to move up to 2 percent over the medium term, provided the labor market improves further and inflation expectations are stable. This assessment still seems to me to be broadly correct. PCE prices were up only 1 percent in February relative to a year earlier, held down by earlier declines in the price of oil. In contrast, core PCE inflation, which strips out volatile food and energy components, was up 1.7 percent in February on a 12 month basis, somewhat more than my expectation in December. But it is too early to tell if this recent faster pace will prove durable. Even when measured on a 12-month basis, core inflation can vary substantially from quarter to quarter and earlier dollar appreciation is still expected to weigh on consumer prices in the coming months. For these reasons, I continue to expect that overall PCE inflation for 2016 as a whole will come in well below 2 percent but will then move back to 2 percent over the course of 2017 and 2018, assuming no further swings in energy prices or the dollar. This projection, however, depends critically on expectations for future inflation remaining reasonably well anchored. It is still my judgment that inflation expectations are well anchored, but as I will shortly discuss, continued low readings for some indicators of expected inflation do concern me.\n\nRisks to the Outlook for Real Economic Activity\nAlthough the baseline outlook has changed little on balance since December, global developments pose ongoing risks. These risks appear to have contributed to the financial market volatility witnessed both last summer and in recent months.\n\nOne concern pertains to the pace of global growth, which is importantly influenced by developments in China. There is a consensus that China's economy will slow in the coming years as it transitions away from investment toward consumption and from exports toward domestic sources of growth. There is much uncertainty, however, about how smoothly this transition will proceed and about the policy framework in place to manage any financial disruptions that might accompany it. These uncertainties were heightened by market confusion earlier this year over China's exchange rate policy.\n\nA second concern relates to the prospects for commodity prices, particularly oil. For the United States, low oil prices, on net, likely will boost spending and economic activity over the next few years because we are still a major oil importer. But the apparent negative reaction of financial markets to recent declines in oil prices may in part reflect market concern that the price of oil was nearing a financial tipping point for some countries and energy firms. In the case of countries reliant on oil exports, the result might be a sharp cutback in government spending; for energy-related firms, it could entail significant financial strains and increased layoffs. In the event oil prices were to fall again, either development could have adverse spillover effects to the rest of the global economy.\n\nIf such downside risks to the outlook were to materialize, they would likely slow U.S. economic activity, at least to some extent, both directly and through financial market channels as investors respond by demanding higher returns to hold risky assets, causing financial conditions to tighten. But at the same time, we should not ignore the welcome possibility that economic conditions could turn out to be more favorable than we now expect. The improvement in the labor market in 2014 and 2015 was considerably faster than expected by either FOMC participants or private forecasters, and that experience could be repeated if, for example, the economic headwinds we face were to abate more quickly than anticipated. For these reasons, the FOMC must watch carefully for signs that the economy may be evolving in unexpected ways, good or bad.\n\nRisks to the Inflation Outlook\nThe inflation outlook has also become somewhat more uncertain since the turn of the year, in part for reasons related to risks to the outlook for economic growth. To the extent that recent financial market turbulence signals an increased chance of a further slowing of growth abroad, oil prices could resume falling, and the dollar could start rising again. And if foreign developments were to adversely affect the U.S. economy by more than I expect, then the pace of labor market improvement would probably be slower, which would also tend to restrain growth in both wages and prices. But even if such developments were to occur, they would, in my view, only delay the return of inflation to 2 percent, provided that inflation expectations remain anchored.\n\nUnfortunately, the stability of longer-run inflation expectations cannot be taken for granted. During the 1970s, inflation expectations rose markedly because the Federal Reserve allowed actual inflation to ratchet up persistently in response to economic disruptions--a development that made it more difficult to stabilize both inflation and employment. With considerable effort, however, the FOMC gradually succeeded in bringing inflation back down to a low and stable level over the course of the 1980s and early 1990s. Since this time, measures of longer-run inflation expectations derived from both surveys and financial markets have been remarkably stable, making it easier to keep actual inflation relatively close to 2 percent despite large movements in oil prices and pronounced swings in the unemployment rate.\n\nLately, however, there have been signs that inflation expectations may have drifted down. Market-based measures of longer-run inflation compensation have fallen markedly over the past year and half, although they have recently moved up modestly from their all-time lows. Similarly, the measure of longer-run inflation expectations reported in the University of Michigan Survey of Consumers has drifted down somewhat over the past few years and now stands at the lower end of the narrow range in which it has fluctuated since the late 1990s.\n\nThe shifts in these measures notwithstanding, the argument that inflation expectations have actually fallen is far from conclusive. Analysis carried out at the Fed and elsewhere suggests that the decline in market-based measures of inflation compensation has largely been driven by movements in inflation risk premiums and liquidity concerns rather than by shifts in inflation expectations.6 In addition, the longer-run measure of inflation expectations from the Michigan Survey has historically exhibited some sensitivity to fluctuations in current gasoline prices, which suggests that this measure may be an unreliable guide to movements in trend inflation under current circumstances.7 Moreover, measures of longer-run expected inflation gleaned from surveys of business and financial economists, such as those reported in the Survey of Professional Forecasters, the Blue Chip survey, and the Survey of Primary Dealers, have largely moved sideways in the past year or two. Taken together, these results suggest that my baseline assumption of stable expectations is still justified. Nevertheless, the decline in some indicators has heightened the risk that this judgment could be wrong. If so, the return to 2 percent inflation could take longer than expected and might require a more accommodative stance of monetary policy than would otherwise be appropriate.8\n\nDespite the declines in some indicators of expected inflation, we also need to consider the opposite risk that we are underestimating the speed at which inflation will return to our 2 percent objective. Economic growth here and abroad could turn out to be stronger than expected, and, as the past few weeks have demonstrated, oil prices can rise as well as fall. More generally, economists' understanding of inflation is far from perfect, and it would not be all that surprising if inflation was to rise more quickly than expected over the next several years. For these reasons, we must continue to monitor incoming wage and price data carefully.\n\nMonetary Policy Implications\nLet me now turn to the implications for monetary policy of this assessment of the baseline outlook and associated risks.\n\nThe FOMC left the target range for the federal funds rate unchanged in January and March, in large part reflecting the changes in baseline conditions that I noted earlier. In particular, developments abroad imply that meeting our objectives for employment and inflation will likely require a somewhat lower path for the federal funds rate than was anticipated in December.\n\nGiven the risks to the outlook, I consider it appropriate for the Committee to proceed cautiously in adjusting policy. This caution is especially warranted because, with the federal funds rate so low, the FOMC's ability to use conventional monetary policy to respond to economic disturbances is asymmetric. If economic conditions were to strengthen considerably more than currently expected, the FOMC could readily raise its target range for the federal funds rate to stabilize the economy. By contrast, if the expansion was to falter or if inflation was to remain stubbornly low, the FOMC would be able to provide only a modest degree of additional stimulus by cutting the federal funds rate back to near zero.9\n\nOne must be careful, however, not to overstate the asymmetries affecting monetary policy at the moment. Even if the federal funds rate were to return to near zero, the FOMC would still have considerable scope to provide additional accommodation. In particular, we could use the approaches that we and other central banks successfully employed in the wake of the financial crisis to put additional downward pressure on long-term interest rates and so support the economy--specifically, forward guidance about the future path of the federal funds rate and increases in the size or duration of our holdings of long-term securities.10 While these tools may entail some risks and costs that do not apply to the federal funds rate, we used them effectively to strengthen the recovery from the Great Recession, and we would do so again if needed.11\n\nOf course, economic conditions may evolve quite differently than anticipated in the baseline outlook, both in the near term and over the longer run. If so, as I emphasized earlier, the FOMC will adjust monetary policy as warranted. As our March decision and the latest revisions to the Summary of Economic Projections demonstrate, the Committee has not embarked on a preset course of tightening. Rather, our actions are data dependent, and the FOMC will adjust policy as needed to achieve its dual objectives.\n\nFinancial market participants appear to recognize the FOMC's data-dependent approach because incoming data surprises typically induce changes in market expectations about the likely future path of policy, resulting in movements in bond yields that act to buffer the economy from shocks. This mechanism serves as an important \"automatic stabilizer\" for the economy. As I have already noted, the decline in market expectations since December for the future path of the federal funds rate and accompanying downward pressure on long-term interest rates have helped to offset the contractionary effects of somewhat less favorable financial conditions and slower foreign growth. In addition, the public's expectation that the Fed will respond to economic disturbances in a predictable manner to reduce or offset their potential harmful effects means that the public is apt to react less adversely to such shocks--a response which serves to stabilize the expectations underpinning hiring and spending decisions.12\n\nSuch a stabilizing effect is one consequence of effective communication by the FOMC about its outlook for the economy and how, based on that outlook, policy is expected to evolve to achieve our economic objectives. I continue to strongly believe that monetary policy is most effective when the FOMC is forthcoming in addressing economic and financial developments such as those I have discussed in these remarks, and when we speak clearly about how such developments may affect the outlook and the expected path of policy. I have done my best to do so today, in the time you have kindly granted me.\n\nReferences\nAbrahams, Michael, Tobias Adrian, Richard K. Crump, and Emanuel Moench (2012). \"Decomposing Real and Nominal Yield Curves (PDF),\" Federal Reserve Bank of New York, Staff Reports No. 570. New York: FRBNY, September; revised February 2015.\n\nAdam, Klaus, and Roberto M. Billi (2007). \"Discretionary Monetary Policy and the Zero Lower Bound on Nominal Interest Rates (PDF),\"  Journal of Monetary Economics, vol.54 (April), pp.728-52. An earlier version of this article is available on the Federal Reserve Bank of Kansas City's website at http://www.kansascityfed.org/publicat/reswkpap/pdf/rwp05-08.pdf .\n\nBauer, Michael D., and Glenn D. Rudebusch (2015). \"Optimal Policy and Market-Based Expectations,\" Federal Reserve Bank of San Francisco, FRBSF Economic Letter 2015-12, San Francisco: FRBSF, April 13.\n\nBoard of Governors of the Federal Reserve System (2015), \"Federal Reserve Issues FOMC Statement,\" press release, December 16.\n\nBrayton, Flint, Thomas Laubach, and David Reifschneider (2014). \"The FRB/US Model: A Tool for Macroeconomic Policy Analysis,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, April.\n\nD'Amico, Stefania, Don H. Kim, and Min Wei (2014). \"Tips from TIPS: The Informational Content of Treasury Inflation-Protected Security Prices (PDF),\" Finance and Economics Discussion Series 2014-24. Washington: Board of Governors of the Federal Reserve System, January.\n\nEngen, Eric M., Thomas T. Laubach, and David Reifschneider (2015). \"The Macroeconomic Effects of the Federal Reserve's Unconventional Monetary Policies (PDF),\" Finance and Economics Discussion Series 2015-005. Washington: Board of Governors of the Federal Reserve System, February.\n\nEnglish, William B., J. David Lopez-Salido, and Robert J. Tetlow (2015). \"The Federal Reserve's Framework for Monetary Policy: Recent Changes and New Questions (PDF),\"  IMF Economic Review, vol. 63 (April), pp. 22-70. An earlier version of this article is available on the Federal Reserve Board's website at http://www.federalreserve.gov/pubs/feds/2013/201376/201376pap.pdf.\n\nEvans, Charles, Jonas Fisher, François Gourio, and Spencer Krane (2015). \"Risk Management for Monetary Policy Near the Zero Lower Bound (PDF),\" Brookings Papers on Economic Activity, BPEA Conference Draft. Washington: Brookings Institution, March.\n\nGust, Christopher J., Benjamin K. Johannsen, and David Lopez-Salido (2015). \"Monetary Policy, Incomplete Information, and the Zero Lower Bound (PDF),\" Finance and Economics Discussion Series 2015-099. Washington: Board of Governors of the Federal Reserve System, February.\n\nJohannsen, Benjamin K., and Elmar Mertens (2016). \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, February 9.\n\nLaubach, Thomas, and John C. Williams (2016). \"Measuring the Natural Rate of Interest Redux (PDF),\" Finance and Economics Discussion Series 2016-011. Washington: Board of Governors of the Federal Reserve System, February.\n\nLubik, Thomas A., and Christian Matthes (2015). \"Calculating the Natural Rate of Interest: A Comparison of Two Alternative Approaches (PDF),\" Economic Brief 15-10. Richmond: Federal Reserve Bank of Richmond, October.\n\nNakata, Taisuke (2012). \"Uncertainty at the Zero Lower Bound (PDF),\" Finance and Economics Discussion Series 2013-09. Washington: Board of Governors of the Federal Reserve System, December.\n\nYellen, Janet L. (2015). \"The Economic Outlook and Monetary Policy,\" speech delivered at the Economic Club of Washington, Washington, December 2.\n\n1. Board of Governors (2015), paragraph 4. Return to text\n\n2. Specifically, the median projections of real GDP growth in 2016 and 2017 revised down 0.2 percentage point and 0.1 percentage point, respectively; the median projections of real GDP growth in 2018 and the longer run were unrevised. The median projection for the unemployment rate in late 2016 was unrevised, while the projections for late 2017, late 2018, and the longer run were revised down slightly. Finally, although the median projection for overall inflation in 2016 was revised down 0.4 percentage point, median projections for subsequent years were unrevised; in addition, median projections for core inflation were almost unrevised for all years. For additional information on the Summary of Economic Projections to be released with the March 2016 FOMC minutes, see www.federalreserve.gov/monetarypolicy/fomcprojtabl20160316.htm. Return to text\n\n3. The neutral rate is not directly observable. However, we intuitively know that it must have run well below its historical norm in recent years because otherwise the economy would have expanded at a much more rapid pace with the nominal federal funds rate near zero. As discussed in my December 2, 2015, speech to the Economic Club of Washington (Yellen, 2015), empirical evidence supports this intuition. I showed that model-based estimates of the \"natural rate,\" when the natural rate is defined as the real short-term interest rate that would prevail in the absence of frictions that slow the adjustment of wages and prices to changes in the economy, are currently close to zero in four macroeconomic models used by Federal Reserve staff. Time series estimates of a different concept of the natural rate that is more similar to the neutral rate definition used in this speech, such as Laubach and Williams (2016) and Lubik and Matthes (2015), are near historical lows. See also Johannsen and Mertens (2016) for empirical evidence of a decline in the longer-run level of the natural rate, along with measures of the uncertainty attached to estimates of its current value. Return to text\n\n4. Assuming that the current gap between the actual federal funds rate and its neutral value is about 125basis points, simulations of the FRB/US model under vector-autoregression-based expectations suggest that maintaining this interest rate gap for the next couple of years would lower the unemployment rate 1/2percentage point or so below what it otherwise would be if the gap were instead immediately closed. Under rational expectations, the predicted effect would be smaller. For further information, see Brayton, Laubach, and Reifschneider (2014). Return to text\n\n5. Of course, any gap between the real federal funds rate and the neutral rate will eventually need to be closed in order to stabilize inflation at 2 percent, keep employment at its maximum level, and the economy growing in line with its potential rate. Return to text\n\n6. For related background discussions, see Bauer and Rudebusch (2015), Abrahams and others (2012 [rev. 2015), and D'Amico, Kim, and Wei (2014). Return to text\n\n7. Similarly, a monthly survey conducted by the Federal Reserve Bank of New York shows a noticeable decline over the past two years in household expectations for inflation three years ahead. However, these readings on shorter-term expectations may also be influenced by current gasoline prices. Moreover, readings from this survey are only available since 2013, making it difficult to determine the significance of these results. Return to text\n\n8. Another risk to the inflation forecast, although one that has not changed appreciably since the turn of the year, is that the Committee may have overestimated the longer-run rate of unemployment consistent with inflation stabilizing at 2 percent. Currently, the median of FOMC participants' estimates of this rate is 4.8 percent. However, this longer-run rate cannot be estimated precisely, and so it could be appreciably higher or lower--although given low readings on wages in recent years, I think the latter possibility is more likely than the former. If so, a lower level of unemployment might be needed to fully eliminate slack in the labor market, drive faster wage growth, and return inflation to our 2 percent objective. Return to text\n\n9. Research suggests that, all else being equal, increased uncertainty and greater downside risk in the vicinity of the effective lower bound on nominal interest rates call for greater gradualism under optimal policy than would be the case if short-term nominal interest rates were appreciably above zero. This phenomenon is known as \"policy attenuation\" in the economic literature. For a discussion, see, for example, Adam and Billi (2007), Nakata (2012), Evans and others (2015), and Gust, Johannsen, and Lopez-Salido (2015). Return to text\n\n10. With regard to the Federal Reserve's balance sheet, the FOMC could increase its size by resuming large-scale purchases of longer-term Treasury securities and agency mortgage-backed securities. Alternatively, the FOMC could increase the duration of the Federal Reserve's holdings without expanding the size of its portfolio by selling assets with relatively short residual maturities and buying equal amounts of assets with relatively long residual maturities. Studies suggest that either action would reduce the term premiums embedded in longer-term interest rates considerably. Return to text\n\n11. For an overview of the macroeconomic effects of the Federal Reserve's unconventional policies after the financial crisis, see Engen, Laubach, and Reifschneider (2015) and the references therein. For a discussion of the costs and benefits of these tools, see English, Lopez-Salido, and Tetlow (2015). Return to text\n\n12. That said, market expectations are not always well aligned with the Committee's baseline outlook for the federal funds rate. Market participants may hold different views about the economic outlook and the associated risks and at times may be confused about the FOMC's strategy. In such situations, the Committee must do what it believes is appropriate while clearly explaining the rationale for its actions. Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "March 07, 2016",
        "title": "Reflections on Macroeconomics Then and Now",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20160307a.htm",
        "content": "March 07, 2016\n\nVice Chairman Stanley Fischer\n\nAt the \"Policy Challenges in an Interconnected World\" 32nd Annual National Association for Business Economics Economic Policy Conference, Washington, D.C.\n\nI am grateful to the National Association for Business Economics (NABE) for conferring the fourth annual NABE Paul A. Volcker Lifetime Achievement Award for Economic Policy on me, thereby allowing me the honor of following in the footsteps of Paul Volcker, Jean-Claude Trichet, and Alice Rivlin.1 The honor of receiving the award is enhanced by its bearing the name of Paul Volcker, a model citizen and public servant, and a giant in every sense among central bankers.\n\nOne thinks of many things on an occasion such as this one. My mind goes back first to growing up in a very small town in Zambia, then Northern Rhodesia, and to the surprise and delight my parents would have felt at seeing me standing where I am now. They would have been even more delighted that my girlfriend, Rhoda, whom I met when my parents moved to a bigger town in Zimbabwe, and I have been happily married for 50 years. But that is not the story I will tell today. Rather, I want to talk about our field, macroeconomics, and some of the lessons we have learned in the course of the last 55 years--and I say 55 years, because in 1961, at the end of my school years, on the advice of a friend, I read Keynes's General Theory for the first time.\n\nDid I understand it? Certainly not. Was I captivated by it? Certainly, though \"captured\" is a more appropriate word than \"captivated.\" Does it remain relevant? Certainly. Just a week ago I took it off the bookshelf to read parts of chapter 23, \"Notes on Mercantilism, the Usury Laws, Stamped Money and Theories of Under-Consumption.\" Today that chapter would be headed \"Protectionism, the Zero Lower Bound, and Secular Stagnation,\" with the importance of usury laws having diminished since 1936.\n\nThere is an old joke about our field--not the one about the one-handed economist, nor the one about \"assume you have a can opener,\" nor the one that ends, \"If I were you, I wouldn't start from here.\" Rather it's the one about the Ph.D. economist who returns to his university for his class's 50th reunion. He asks if he can see the most recent Ph.D. generals exam. After a while it is brought to him. He reads it carefully, looking perplexed, and then says, \"But this is exactly the same as the exam I wrote over 50 years ago.\" \"Ah yes,\" says the professor. \"It is the same, but all the answers are different.\"\n\nIs that really the case? Not really, though it is true to some extent in the realm of policy. To discuss the question of whether the answers to the questions of how to deal with macroeconomic policy problems have changed markedly over the past half-century or so, I will start by briefly sketching the structure of a basic macro model. The building blocks of this model are similar to those used in many macro models, including FRB/US, the Fed staff's large-scale model, and a variety of DSGE (dynamic stochastic general equilibrium) models used at the Fed and other central banks and by academic researchers.\n\nThe structure of the model starts with the standard textbook equation for aggregate demand for domestically produced goods, namely:2\n\nWhen I was an undergraduate at the London School of Economics (LSE) between 1962 and 1965, we learned the IS-LM model, which combined the aggregate demand equation (1) with the money market equilibrium condition set out in (3). That was the basic understanding of the Keynesian model as crystallized by John Hicks, Franco Modigliani, and others, in which it was easy to add detail to the demand functions for private-sector consumption, C; for investment, I; for government spending, G; and for net exports. The Keynesian emphasis on aggregate demand and its determinants is one of the basic innovations of the Keynesian revolution, and one that makes it far easier to understand and explain what factors are determining output and employment.\n\nContinuing down the list, on price and wage dynamics, the Phillips curve has flattened somewhat since the 1950s and 1960s.3 Further, the role of expectations of inflation in the Phillips curve has been developed far beyond what was understood when A.W. Phillips--who was a New Zealander, an LSE faculty member, and a statistician and former engineer--discovered what later became the Phillips curve. The difference between the short- and long-run Phillips curves, which is now a staple of textbooks, was developed by Milton Friedman and Edmund Phelps, and the effect of making expectations rational or model consistent was emphasized by Robert Lucas, whose islands model provided an imperfect information reason for a nonvertical short-run Phillips curve. In Okun's law, the Okun coefficient--the coefficient specifying how much a change in the unemployment rate affects output--appears to have declined over time. So has the trend rate of productivity growth, which is a critical determinant of future levels of per capita income.\n\nIn (3), the monetary equilibrium condition, the monetary policy decision was typically represented by the money stock at the LSE and perhaps also at the Massachusetts Institute of Technology (MIT) after the Keynesian revolution (after all, \"L\" represents the liquidity preference function and \"M\" the supply of money); now the money supply rule is replaced by an interest-rate setting rule, for instance a reaction function of some form, or by a calculated \"optimal\" policy based on a loss function.\n\nThe development of the flexible inflation-targeting approach to monetary policy is one of the major achievements of modern macroeconomics. Flexible inflation targeting allows for flexibility in the speed with which the monetary authority plans on returning to the target inflation rate, and is thereby close to the dual mandate that the law assigns to the Fed.\n\nA great deal of progress has been made in developing the credit and financial intermediation block. As early as the 1960s, each of James Tobin, Milton Friedman, and Karl Brunner and Alan Meltzer wrote out models with more fully explicated financial sectors, based on demand functions for assets other than money. Later the demand functions were often replaced by pricing equations derived from the capital asset pricing model. Researchers at the Fed have been bold enough to add estimated term and risk premiums to the determination of the returns on some assets.4 They have concluded, inter alia, that the arguments we used to make about how easy it would be to measure expected inflation if the government would introduce inflation-indexed bonds failed to take into account that returns on bonds are affected by liquidity and risk premiums. This means that one of the major benefits that were expected from the introduction of inflation-indexed bonds (Treasury Inflation-Protected Securities, generally called TIPS), namely that they would provide a quick and reliable measure of inflation expectations, has not been borne out, and that we still have to struggle to get reasonable estimates of expected inflation.\n\nAs students, we included NX, net exports, in the aggregate demand equation, but we did not generally solve for the exchange rate, possibly because the exchange rate was typically fixed. Later, in 1976, Rudi Dornbusch inaugurated modern international macroeconomics--and here I'm quoting from a speech by Ken Rogoff--in his famous overshooting model.5 As globalization of both goods and asset markets intensified over the next 40 years, the international aspects of trade in goods and assets occupied an increasingly important role in the economies of virtually all countries, not least the United States, and in macroeconomics.\n\nAt the LSE, we took a course on the British economy from Frank Paish, whose lectures consisted of a series of charts, accompanied by narrative from the professor. He made a strong impression on me in a lecture in 1963, in which he said, \"You see, it (the balance of payments deficit) goes up and it goes down, and it is clear that we are moving toward a balance of payments crisis in 1964.\" I waited and I watched, and the crisis appeared on schedule, as predicted. But Paish also warned us that forecasting was difficult, and gave us the advice \"Never look back at your forecasts--you may lose your nerve.\" I pass that wisdom on to those of you who need it.\n\nI remember also my excitement at being told by a friend in a more senior class about the existence of econometric models of the entire economy. It was a wonderful moment. I understood that economic policy would from then on be easy: All that was necessary was to feed the data into the model and work out at what level to set the policy parameters. Unfortunately, it hasn't worked out that way. On the use of econometric models, I think often of something Paul Samuelson once said: \"I'd rather have Bob Solow's views than the predictions of a model. But I'd rather have Solow with a model than without one.\"\n\nWe learned a lot at the LSE. But wonderful as it was to be in London, and to meet people from all over the world for the first time, and to be able to travel to Europe and even to the Soviet Union with a student group, and to ski for the first time in my life in Austria, it gradually became clear to me that the center of the academic economics profession was not in London or Oxford or Cambridge, but in the United States.\n\nThere was then the delicate business of applying to graduate school. There was a strong Chicago tendency among many of the lecturers at the LSE, but I wanted to go to MIT. When asked why, I gave a simple answer: \"Samuelson and Solow.\" Fortunately, I got into MIT and had the opportunity of getting to know Samuelson and Solow and other great professors. And I also met the many outstanding students who were there at the time, among them Robert Merton. I took courses from Samuelson and Solow and other MIT stars, and I wrote my thesis under the guidance of Paul Samuelson and Frank Fisher. From there, my first job was at the University of Chicago--and I understood that I was very lucky to have been able to learn from the great economists at both MIT and Chicago. Among the many things I learned at Chicago was a Milton Friedman saying: \"Man may not be rational, but he's a great rationalizer,\" which is a quote that often comes to mind when listening to stock market analysts.\n\nAfter four years at Chicago, I returned to the MIT Department of Economics, and thought that I would never leave--even more so when MIT succeeded in persuading Rudi Dornbusch, whom I had met when he was a student at Chicago, to move to MIT--thus giving him too the benefit of having learned his economics at both Chicago and MIT, and giving MIT the pleasure and benefit of having added a superb economist and human being to the collection of such people already present.\n\nMIT was still heavily involved in developing growth theory at the time I was a Ph.D. student there, from 1966 to 1969. We students were made aware of Kaldor's stylized facts about the process of growth, presented in his 1957 article \"A Model of Economic Growth.\" They were:\n\nWell, that was then, and many of the problems we face in our economy now relate to the changes in the stylized facts about the behavior of the economy: Every one of Kaldor's stylized facts is no longer true, and unfortunately the changes are mostly in a direction that complicates the formulation of economic policy.6\n\nWhile the basic approach outlined so far remains valid, and can be used to address many macroeconomic policy issues, I would like briefly to take up several topics in more detail. Some of them are issues that have remained central to the macroeconomic agenda over the past 50 years, some have to my regret fallen off the agenda, and others are new to the agenda.\n\nConcluding Remarks\nWell, are the answers all different than they were 50 years ago? No. The basic framework we learned a half-century ago remains extremely useful. But also yes: Some of the answers are different because they were not on previous exams because the problems they deal with were not evident fifty years ago. So the advice to potential policymakers is simple: Learn as much as you can, for most of it will come in useful at some stage of your career; but never forget that identifying what is happening in the economy is essential to your ability to do your job, and for that you need to keep your eyes, your ears, and your mind open, and with regard to your mouth--to use it with caution.\n\nMany thanks again for this award and this opportunity to speak with you.\n\nReferences\nBernanke, Ben S. (2005). \"The Global Saving Glut and the U.S. Current Account Deficit,\" speech delivered at the Homer Jones Lecture, St. Louis, April 14.\n\nBlanchard, Olivier (2014). \"Where Danger Lurks: The Recent Financial Crisis Has Taught Us to Pay Attention to Dark Corners, Where the Economy Can Malfunction Badly,\" Finance and Development, vol. 51 (September), pp. 28-31.\n\n-------- (2016). \"The U.S. Phillips Curve: Back to the 60s? (PDF)\"  Policy Brief 16-1. Washington: Peterson Institute for International Economics, January.\n\nBlanchard, Olivier, Eugenio Cerutti, and Lawrence Summers (2015). \"Inflation and Activity--Two Explorations and Their Monetary Policy Implications (PDF),\"  IMF Working Paper WP/15/230. Washington: International Monetary Fund, November.\n\nBlanchard, Olivier, and John Simon (2001). \"The Long and Large Decline in U.S. Output Volatility (PDF),\"  Brookings Papers on Economic Activity, 1, pp. 135-74.\n\nBrunner, Karl, and Allan H. Meltzer (1972). \"Money, Debt, and Economic Activity,\" Journal of Political Economy, vol. 80 (September-October), pp.951-77.\n\nByrne, David M., John G. Fernald, and Marshall Reinsdorf (forthcoming). \"Does the United States Have a Productivity Problem or a Measurement Problem?\" Brookings Papers on Economic Activity.\n\nCaballero, Ricardo J., Emmanuel Farhi, and Pierre-Olivier Gourinchas (2008). \"An Equilibrium Model of 'Global Imbalances' and Low Interest Rates,\" American Economic Review, vol. 98 (1), pp. 358-93.\n\nDaly, Mary C., John G. Fernald, Òscar Jordà, and Fernanda Nechio (2014). \"Output and Unemployment Dynamics (PDF),\"  Working Paper Series 2013-32. San Francisco: Federal Reserve Bank of San Francisco, November.\n\n-------- (2014). \"Interpreting Deviations from Okun's Law,\"  FRBSF Economic Letter 2014-12. San Francisco: Federal Reserve Bank of San Francisco.\n\nD'Amico, Stefania, Don H. Kim, and Min Wei (2014). \"Tips from TIPS: The Informational Content of Treasury Inflation-Protected Security Prices (PDF),\" Finance and Economics Discussion Series 2014-24. Washington: Board of Governors of the Federal Reserve System, January.\n\nDornbusch, Rudiger (1976). \"Expectations and Exchange Rate Dynamics,\" Journal of Political Economy, vol. 84 (December), pp. 1161-76.\n\nDornbusch, Rudiger, Stanley Fischer, and Richard Startz (2014). Macroeconomics, 12th ed. New York: McGraw-Hill Education.\n\nFischer, Stanley (forthcoming). \"Monetary Policy, Financial Stability, and the Zero Lower Bound,\" American Economic Review (Papers and Proceedings).\n\nFriedman, Milton (1968). \"The Role of Monetary Policy,\" American Economic Review, vol. 58 (March), pp. 1-17.\n\nGordon, Robert J. (2014). \"The Demise of U.S. Economic Growth: Restatement, Rebuttal, and Reflections,\" NBER Working Paper Series 19895. Cambridge, Mass.: National Bureau of Economic Research, February.\n\n-------- (2016). The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War. Princeton, N.J.: Princeton University Press.\n\nHall, Robert E. (2014). \"Quantifying the Lasting Harm to the U.S. Economy from the Financial Crisis,\" in Jonathan Parker and Michael Woodford, eds., NBER Macroeconomics Annual 2014, vol. 29. Chicago: University of Chicago Press.\n\nHamilton, James D., Ethan S. Harris, Jan Hatzius, and Kenneth D. West (2015). \"The Equilibrium Real Funds Rate: Past, Present and Future,\" NBER Working Paper Series 21476. Cambridge, Mass.: National Bureau of Economic Research, August.\n\nHicks, John R. (1937). \"Mr. Keynes and the 'Classics': A Suggested Interpretation,\" Econometrica, vol. 5 (April), pp. 147-59.\n\nJohannsen, Benjamin K., and Elmar Mertens (2016). \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, February 9.\n\nJones, Charles I., and Paul M. Romer (2010). \"The New Kaldor Facts: Ideas, Institutions, Population, and Human Capital,\" American Economic Journal: Macroeconomics, vol. 2 (January), pp. 224-45.\n\nKaldor, Nicholas (1957). \"A Model of Economic Growth,\" Economic Journal, vol. 67 (December), pp. 591-624.\n\nKeynes, John Maynard (1936). The General Theory of Employment, Interest and Money. London: Macmillan.\n\nKiley, Michael T. (2015). \"What Can the Data Tell Us about the Equilibrium Real Interest Rate? (PDF)\" Finance and Economics Discussion Series 2015-077. Washington: Board of Governors of the Federal Reserve System, August.\n\nKnotek, Edward S., II (2007). \"How Useful Is Okun's Law? (PDF)\"  Federal Reserve Bank of Kansas City, Economic Review, Fourth Quarter, pp. 73-103.\n\nLaubach, Thomas, and John C. Williams (2003). \"Measuring the Natural Rate of Interest,\" Review of Economics and Statistics, vol. 85 (November), pp. 1063-70.\n\nLucas, Robert E., Jr. (1972). \"Expectations and the Neutrality of Money,\" Journal of Economic Theory, vol. 4 (April), pp. 103-24.\n\nMendoza, Enrique G., Vincenzo Quadrini, and José-Víctor Ríos-Rull (2009). \"Financial Integration, Financial Development, and Global Imbalances,\" Journal of Political Economy, vol. 117 (3), pp. 371-416.\n\nModigliani, Franco (1944). \"Liquidity Preference and the Theory of Interest and Money,\" Econometrica, vol. 12 (January), pp. 45-88.\n\nMokyr, Joel, Chris Vickers, and Nicolas L. Ziebarth (2015). \"The History of Techonological Anxiety and the Future of Economic Growth: Is This Time Different?\" Journal of Economic Perspectives, vol. 29 (Summer), pp. 31-50.\n\nObstfeld, Maurice, and Kenneth Rogoff (1996). Foundations of International Macroeconomics. Cambridge, Mass.: MIT Press.\n\nOkun, Arthur M. (1962). \"Potential GNP: Its Measurement and Significance,\" Proceedings of the Business and Economics Statistics Section of the American Statistical Association, pp. 98-104.\n\nPhelps, Edmund S. (1967). \"Phillips Curves, Expectations of Inflation and Optimal Unemployment over Time,\" Economica, vol. 34 (August), pp. 254-81.\n\nReifschneider, David, and John C. Williams (2000). \"Three Lessons for Monetary Policy in a Low-Inflation Era,\" Journal of Money, Credit, and Banking, vol. 32 (November), pp. 936-66.\n\nReinhart, Carmen M., and Kenneth S. Rogoff (2009). This Time Is Different: Eight Centuries of Financial Folly. Princeton, N.J.: Princeton University Press.\n\nRogoff, Kenneth (2001). \"Dornbusch's Overshooting Model after Twenty-Five Years (PDF),\" speech delivered at the Mundell-Fleming Lecture, Second Annual Research Conference, International Monetary Fund, Washington, November 30 (revised January 22, 2002).\n\nSolow, Robert M. (2004). \"Introduction: The Tobin Approach to Monetary Economics,\" Journal of Money, Credit, and Banking, vol. 36 (August), pp. 657-63.\n\nStock, James H., and Mark W. Watson (2003). \"Has the Business Cycle Changed and Why?\" NBER Macroeconomics Annual 2002, vol. 17 (January).\n\nTobin, James (1969). \"A General Equilibrium Approach to Monetary Theory (PDF),\"  Journal of Money, Credit, and Banking, vol. 1 (February), pp. 15-29.\n\nU.S. Executive Office of the President, Council of Economic Advisors (2015). Long-Term Interest Rates: A Survey (PDF). Washington: EOP.\n\nWilliams, John C. (2013). \"A Defense of Moderation in Monetary Policy (PDF),\" Working Paper Series 2013-15. San Francisco: Federal Reserve Bank of San Francisco, July.\n\nWoodford, Michael (2010). \"Financial Intermediation and Macroeconomic Analysis,\" Journal of Economic Perspectives, vol. 24 (Fall), pp. 21-44.\n\n1. I am grateful to David Lopez-Salido, Andrea Ajello, Elmar Mertens, Stacey Tevlin, and Bill English of the Federal Reserve Board for their assistance. Views expressed are mine, and are not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. A fuller description of the equations is contained in the appendix. Return to text\n\n3. See Blanchard (2016). Return to text\n\n4. See D'Amico, Kim, and Wei (2014). Return to text\n\n5. See Dornbusch (1976) and Rogoff (2001). Return to text\n\n6. See Jones and Romer (2010). Return to text\n\n7. See, for instance, Mokyr, Vickers, and Ziebarth (2015). Return to text\n\n8. See Byrne, Fernald, and Reinsdorf (forthcoming). Return to text\n\n9. Inside the Fed, the range of 0 to 1/4 percent is generally called the ELB, the effective lower bound. Return to text\n\n10. I am distinguishing in this section between secular stagnation as being caused by a deficiency of aggregate demand and another view, that output growth will be very slow in future because productivity growth will be very low. The view that future productivity growth will be very low has already been discussed, with the conclusion that we do not have a good basis for predictions of its future level, and that we simply do not know whether future productivity growth will be extremely low or higher than it has been recently. There is no shortage of views on this issue among economists, but the views to some extent appear to depend on whether the economist making the prediction is an optimist or a pessimist. Return to text\n\n11. This research includes recent work by Johannsen and Mertens (2015) and Kiley (2015) that uses extensions of the original Laubach and Williams (2003) framework. An international perspective on medium-to-long-run real interest rates is provided by U.S. Executive Office of the President (2015). Reinhart and Rogoff (2009) and Hall (2014) discuss the long-lived effects of financial crises on economic performance. See also Hamilton and others (2015). I have, in addition, drawn on Fischer (forthcoming). Return to text\n\n12. It is also a major factor explaining the phenomenon of the economy's impressive performance on the jobs front during a period of historically slow growth. Return to text\n\n13. See, for instance, Gordon (2014, 2016). Return to text\n\n14. See Bernanke (2005). See also the recent work by Caballero, Farhi, and Gourinchas (2008); and Mendoza, Quadrini, and Rios-Rull (2009). Return to text\n\n15. See, for instance, Reifschneider and Williams (2000), Blanchard and Simon (2001), and Stock and Watson (2003). Return to text\n\n16. For a discussion of various issues reviewed by the Federal Open Market Committee in late 2008 and 2009 regarding the complications of unconventional monetary policy at the ZLB, see the set of staff memos on the Board's website. Return to text\n\n17. See Williams (2013). Return to text\n\nAppendix\n\nThe following model includes a number of elements that play a central role in the analysis of economic fluctuations and in larger policy models as I have encountered them at the Federal Reserve and other institutions.\n\nAn aggregate demand relationship, in the form of the investment-saving (or IS) curve, characterizes the negative dependence of economic activity on the real borrowing rate,\ni\nB\n−\nπ\ne\n, and the positive dependence on expected output,\ny\ne\n; government spending,\nG\n; and net exports,\nNX\n, as a function of the exchange rate,\ne\n, and foreign output,\ny\nf\n:\n\nThe Phillips curve describes a relationship between inflation and labor market slack. Inflation responds negatively to the level of the unemployment gap,\nu\n^\n, and to changes in aggregate productivity,\nz\n(including shocks to commodity prices). Current inflation also responds positively to expected future inflation,\nπ\ne\n, and to the level of the borrowing rate and of the exchange rate,\nϕ(\ni\nB\n,e)\n(cost - push shocks):\n\nCurrent issues regarding the role of expectations, the size of the slope, and the pass-through from exchange rate movements to domestic prices and wages can be addressed in this context. Recent discussions can be found in Blanchard's (2016) reference to the back-to-the-1960s thinking about the Phillips curve and in Blanchard, Cerutti, and Summers's (2015) thoughts on hysteresis mechanisms underlying the inflation and unemployment dynamic.\n\nTo connect cyclical fluctuations in the level of aggregate activity with changes in employment, Okun's law has been proved useful as an empirical description of the relationship between the output gap and the unemployment gap,\nu\n^\n=\nu−\nu\n∗\nu\n∗\n(see Knotek (2007); and Daly, Fernald, Jordà, and Nechio (2013, 2014)):\n\nTo characterize monetary policy, it is nowadays useful to consider how the central bank affects the level of interest rates by setting the federal funds rate,\ni\n, in response to deviations of expected inflation from its target,\nπ\n^\n=\nπ\ne\n−\nπ\n∗\n(inflation gap), and percent deviations of output from its potential level,\ny\n^\n=\ny−\ny\n∗\ny\n∗\n(output gap):\n\nTo capture the role of credit and financial intermediation in the economy, consider a loan market equation, where the demand on the left-hand side depends negatively on the borrowing rate,\ni\nB\n, and the level of economic activity (higher income implies lower financing needs). The supply of loans depends negatively on the level of interest rates,\ni\n, and positively on the level of intermediation spreads,\nω\n, and income,\ny\n(to the extent that higher aggregate income increases deposits and banks' capitalization and hence the supplies of intermediated funds). This equation pins down the equilibrium level of the intermediation spread,\nω\n:\n\nThe borrowing rate,\ni\nB\n, is then equal to the sum of the risk-free rate set by the central bank,\ni\n, and the spread,\nω\n:\n\nThis analysis is in the spirit of James Tobin's approach to monetary economics as was recently described by Solow (2004) and extended by Woodford (2010) to describe the role for financial intermediation shocks. It also captures the work by B. Friedman, B. Bernanke, and A. Blinder in thinking about the role of credit and credit spreads in the transmission of monetary policy impulses.\n\nOpen economy aspects are captured by the following equations: The balance of payment is in equilibrium when net exports are compensated by capital flows of opposite sign. Capital flows depend on the difference between the domestic interest rate and the foreign rate adjusted for depreciation:\n\nFurthermore, the uncovered interest rate parity equates the rate of return on domestic assets,\ni\n, to the rate of return on foreign assets,\ni\nf\n, plus future expected changes in the exchange rate,\nde\ne\n, and a residual risk premium component,\nRP\n:\n\nFor a detailed description of these relationships, see Dornbusch, Fischer, and Startz (2014); and Obstfeld and Rogoff (1996).\n\n"
    },
    {
        "speaker": "Lael Brainard",
        "position": "Governor",
        "date": "March 07, 2016",
        "title": "An Update on the Outlook, Liquidity, and Resilience",
        "href": "https://www.federalreserve.gov/newsevents/speech/brainard20160307a.htm",
        "content": "March 07, 2016\n\nGovernor Lael Brainard\n\nAt the Institute of International Bankers Annual Washington Conference, Washington, D.C.\n\nThis is a fitting moment to take stock of economic and financial developments, following a volatile start to the year. I will begin by reviewing the outlook, then provide a brief recap of how financial market liquidity has fared, and finish by commenting on the resilience and resolvability of the large interconnected banks.1\n\nOutlook for the United States\nI am heartened by the continued strong progress on employment and the resilience of American consumers, which stand out against a considerably more challenging global backdrop. I am pleased with the continued strength in the U.S. labor market, which is drawing people back into the labor force. In February, the unemployment rate was 4.9 percent--a level that is one-half its peak during the depths of the recession in 2009. Last Friday, we learned that employment growth has averaged 223,000 per month over the past 12 months. And there likely is some room to go: The prime-age employment-to-population ratio remains 1-3/4 percentage points below levels prevailing prior to the financial crisis, while a relatively large share of employees who are working part time would prefer to work full time. In addition, wage growth remains relatively slow.\n\nDomestic activity continues to grow at a moderate pace. The pace of consumer spending, after slowing some at the end of last year, looks to have picked up in January, and auto sales remained strong in February. Over the past two years, consumption has increased at about a 3 percent pace, on average, and I expect to see growth to continue at close to this pace based on solid job and income growth--together with elevated readings on consumer confidence and the boost to household purchasing power from persistent declines in energy prices.\n\nThe housing sector has also contributed steadily to growth over the past year. With housing activity well below pre-recession norms, it appears there is still scope for continued growth in construction activity.\n\nIn contrast, sectors of the economy that are sensitive to energy prices or international demand have been a drag. In response to the plunge in oil prices, investment in drilling and mining structures fell 50 percent last year, and continued reductions in the number of drilling rigs this year suggest that further declines are likely.2 At the same time, firms and workers in the energy sector have experienced extreme financial difficulties and severe job losses.\n\nAlthough the euro area and Japan are recovering, their demand growth remains very low, despite extraordinary monetary accommodation. In emerging market economies growth last year came in at only one-half the average rate from 2009 to 2013. Because China has accounted for one-third of the growth in world Gross Domestic Product (GDP) and trade, the recent slippage in Chinese economic growth is having an important effect globally. Even if Chinese growth does not slide further, the changing composition of its growth toward consumption and services and away from resource-intensive manufacturing and investment will pose important challenges to commodity exporters and other emerging economies, especially since China had previously accounted for upwards of one-half of global imports of many base metals.\n\nWeak foreign demand relative to the United States has pushed down net exports and contributed to a nearly 20 percent strengthening of the real trade-weighted dollar since mid-2014. As a result, net exports subtracted a little more than 1/2 percentage point from GDP growth in 2014 and 2015, and econometric models suggest that past appreciation will lead to close to another 1 percentage point subtraction this year.3\n\nThese effects are especially prominent in the U.S. manufacturing sector, where output is sluggish, and the agricultural sector has also been hit hard by the rise in the value of the dollar. In addition, with profits at many firms adversely affected by the rise in the dollar and weak demand abroad, business fixed investment increased only 1-1/2 percent last year after contributing significantly to growth earlier in the recovery.\n\nOn balance, in recent months, financial conditions have tightened somewhat with equity prices moving lower and corporate risk spreads widening, although conditions have improved in recent weeks. In addition, progress on inflation has been slow. Prices for personal consumption expenditures (PCE) have increased 1.3 percent over the 12 months through January, well below the Federal Open Market Committee's (FOMC) 2 percent target. Reductions in energy prices are, in part, responsible for this low rate, and if energy prices stabilize, top-line inflation should move higher. Still, a stabilization in energy prices is not assured. Market participants have been repeatedly surprised by the depth and persistence of oil price declines: Both spot and far futures oil prices, for example, have fallen in five out of the past six quarters since mid-2014.\n\nBut even after discounting the influence of energy prices, core PCE inflation has been stubbornly stuck in the vicinity of 1-1/4 to 1-1/2 percent since 2012.4 Most recently, the dollar has played an important role in holding down non-oil import prices, which fell 3-1/2 percent last year and subtracted an estimated 1/2 percentage point from core inflation.5 Should the dollar stabilize, the downward influence on inflation should dissipate. But, as with oil prices, the movement in the value of the dollar has been more persistent than markets and many observers expected, with increases in every quarter since mid-2014.\n\nIf the labor market continues to improve, higher resource utilization should also put some upward pressure on inflation going forward. However, the effect of resource utilization on inflation is estimated to be much lower today than in past decades.6\n\nAn important concern about persistently low inflation is that it can lead to a fall in longer-term inflation expectations, making it much more difficult to achieve our inflation target. For the most part, longer-term inflation expectations appear to have remained reasonably stable, though there are some concerning signs. Longer-term inflation expectations of professional forecasters and primary dealers have held quite steady in recent years at levels consistent with the FOMC's target. However, households' inflation expectations appear to have moved down somewhat recently. Five-to-10-year inflation expectations in the University of Michigan Surveys of Consumers have edged lower over the past year or two with the level in February nearly 1/2 percentage point below the 10-year average. Three-year inflation expectations in the New York Federal Reserve's Survey of Consumer Expectations have also moved steadily lower over the past two years, though the recent decline in energy prices may explain much of this drift.\n\nNotably, market-based measures of inflation compensation based on Treasury Inflation-Protected Securities (TIPS) and nominal Treasury yields are at historically low levels. At the five-year, five-year-ahead horizon, inflation compensation is 1 percentage point lower than mid-2014 levels. Declines in swap-based measures of inflation compensation have been similar. However, these declines appear correlated with oil prices, and it is not clear to what extent these declines reflect a change in inflation expectations, changes in investor demand for TIPS versus nominal Treasury securities, or an improvement in the risk characteristics of nominal Treasury securities versus other assets.\n\nOver the next couple of years, there are reasons to expect energy prices and the dollar to eventually stabilize, output to increase at around the moderate pace it has averaged over the recovery thus far, foreign growth to recover somewhat, the U.S. labor market to improve further, and inflation to move toward our 2 percent target. However, there are risks around this baseline forecast, the most prominent of which lie to the downside. For example, China faces risks as it navigates a sharp slowing in its goods sector, a large buildup in corporate debt, and an apparent surge in demand for foreign assets, although China possesses resources to deal with these challenges. More broadly, sources of robust demand around the globe are few, and sources of weakness relatively greater, as evidenced by persistently below target inflation in all of the major advanced economies.\n\nMonetary Policy\nIn today's circumstances, policy could usefully follow two simple guidelines. First, we should not take the strength in the U.S. labor market and consumption for granted. Given weak and decelerating foreign demand, it is critical to carefully protect and preserve the progress we have made here at home through prudent adjustments to the policy path. Tighter financial conditions and softer inflation expectations may pose risks to the downside for inflation and domestic activity. From a risk-management perspective, this argues for patience as the outlook becomes clearer.7\n\nSecond, we should put a high premium on clear evidence that inflation is moving toward our 2 percent target. Inflation has persistently underperformed relative to our target. Moreover, measures of inflation compensation and some survey-based measures of inflation expectations suggest that inflation expectations may have edged lower. Given the currently weak relationship between economic slack and inflation and the persistent, depressing effects of energy price declines and exchange rate increases, we should be cautious in assessing that a tightening labor market will soon move inflation back to 2 percent. We should verify that this is, in fact, taking place. In this regard, core PCE inflation increased 1.7 percent over the 12 months ending in January, a noticeable step-up from an increase of 1.3 percent over the preceding 12 months.8\n\nLiquidity\nIn addition to raising uncertainty around the outlook, the recent financial market volatility has underscored the importance of ongoing attention to the resilience of market liquidity. Although it is fair to say that the recent uptick in volatility has in part reduced earlier concerns about prolonged low volatility and associated reach-for-yield behavior, it has placed added focus on the resilience of liquidity, particularly in markets, such as the market for corporate bonds, that may be prone to gapping between liquidity demand and supply in stressed conditions.\n\nThe Federal Reserve's surveillance of liquidity conditions in financial markets has broadened and deepened considerably since the \"taper tantrum\" in mid-2013 and the events of October 2014 in the Treasury market. The analysis so far suggests a few preliminary observations. While it does not appear that day-to-day liquidity has declined notably, some characteristics of liquidity provision are changing. Broadly, traditional price-based measures of liquidity such as bid-asked spreads and the price effect of a given trade size generally remain in line with pre-crisis norms in most markets. In contrast, both anecdotes from market participants and the declining size of trades in some markets suggest it may have become more expensive to conduct, and may take more time to implement, large trades.9\n\nMoreover, there may be some deterioration in the resilience of liquidity at times of stress, along with a greater incidence of outsized intraday price movements. Relatedly, liquidity appears to be more segmented based on the characteristics of the securities being traded and the underlying structure of the markets in which they are traded. Based on granular disaggregation of the traded securities, liquidity appears little changed in secondary markets that have traditionally been highly liquid, such as on-the-run Treasury bonds and highly rated corporate bonds. By contrast, there has been some reduction in liquidity in the segments of these markets that have historically been less liquid.10\n\nThe move toward somewhat greater segmentation of liquidity, in conjunction with ongoing electronification and acceleration of trade execution, might be contributing to increased linkages across markets. Anecdotally, it appears market participants may be using relatively more liquid instruments to hedge exposures in other less liquid market segments, perhaps unintentionally contributing to increased correlation across markets.11\n\nFrom a broader financial stability perspective, the possible deterioration in the resilience of liquidity suggests a special focus on segments where price gaps are most likely to arise at times of stress between holders of relatively illiquid or thinly traded securities that want to sell and dealers with an apparently reduced willingness to take the other side of the trade, as indicated, for example, by leaner dealer inventory holdings.12 Mutual funds holding relatively less liquid assets is one area of focus. Despite having share prices that move with market prices, these funds can give rise to first-mover advantages for redeeming shareholders and create the potential for destabilizing waves of redemptions and asset fire sales if liquidity buffers and other tools to manage liquidity risk prove insufficient.13 In this regard, our surveillance has been closely monitoring for any signs of liquidity strains associated with the recent increases in spreads for high-yield corporate bonds, as well as for idiosyncratic events affecting particular funds in this segment, such as the events surrounding the abrupt closing of Third Avenue Management's Focused Credit Fund last December.\n\nMore broadly, the regulatory agencies in the United States and the Financial Stability Board internationally have work under way focusing on possible fire-sale risk associated with the growing share of less liquid bonds held in asset management portfolios on behalf of investors who may be counting on same-day redemption when valuations fall. The recent proposal by the Securities and Exchange Commission (SEC) to ensure mutual funds have ample liquidity buffers under stressed scenarios and undertake measures to address the risk of heavy redemptions and fire sales is notable in this regard. Our surveillance will continue to undertake more granular analysis of liquidity resilience and associated risks.\n\nAcross financial markets, it is difficult to disentangle the effects on liquidity of changes in technology and market structure and changes in broker-dealer risk-management practices in the wake of the crisis on the one hand and enhanced regulation on the other. While the leverage ratio and other Dodd-Frank Act requirements likely are encouraging broker-dealers to be more rigorous about risk management in allocating balance sheet capacity to certain trading activities, the growing presence of proprietary firms using algorithmic trading in many of these markets, which predated the crisis, is also influencing trading dynamics in important ways.14 The Request for Information issued by the U.S. Treasury and the recent proposals from the Commodity Futures Trading Commission and the SEC will be important in deepening our understanding. While acknowledging the role of regulation as a possible contributor, it is important to recognize that this regulation was designed to reduce the concentration of liquidity risk on the balance sheets of the large, interconnected banking organizations that proved to be a major amplifier of financial instability at the height of the crisis.\n\nResilience and Resolvability\nThis brings me to the last item on my agenda: an update on efforts to strengthen the resilience and resolvability of these systemic banking organizations. With recent and upcoming proposals, much of the new regulatory architecture will be in the process of implementation or in train. Even so, I would expect the rules and their application to continue to be strengthened and modified as financial risks evolve, just as I would expect these rules to be increasingly tailored over time to better reflect risk profiles.\n\nAs a result of the capital and liquidity regulations already in place as well as the associated stress tests, the eight most systemic U.S. banking organizations are now holding $800 billion more in high-quality liquid assets than they were in 2011 and $500 billion more in common equity capital than they were in 2008. These liquidity and capital buffers are designed to strengthen the going-concern resilience of systemic banking organizations during periods of market volatility and financial stress. In addition, we recently released our proposed framework for determining the application of an additional countercyclical buffer to our large banking firms and made the first determination under the rule.\n\nOn top of this, the capital surcharge we have proposed, which is designed to ensure the largest, most systemic banking organizations internalize the risk they pose to the system, is estimated to range from 1.0 to 4.5 percent of risk-weighted assets, based on 2013 data, over and above the 7 percent minimum and capital conservation buffers under Basel III. Indeed, it appears that some institutions may have already reduced their systemic footprint in anticipation of these additional charges.\n\nOf course, the crisis starkly illustrated that what seem like thick capital cushions in good times can become uncomfortably thin in the face of financial stress. Our Comprehensive Capital Analysis and Review (CCAR) stress-testing framework is arguably our most powerful tool for ensuring that these capital buffers remain robust to a variety of possible shocks to the trading and banking book exposures of the large, interconnected banking organizations. Therefore, as we work to fine-tune and strengthen this framework, I would hope to see the capital surcharge for systemic banking organizations integrated into CCAR to ensure robustness, even as adjustments might be made on other parameters of the framework.\n\nAlthough today's greatly enhanced common equity capital requirements should materially reduce the probability that a large bank might fail in response to a severe economic downturn or financial stress, it is not enough to reduce the risks of failure. In parallel, our supervisory and regulatory efforts are raising the bar on ensuring that the large, interconnected banking organizations have in place credible plans and preparations as well as properly calibrated and positioned liquidity and loss absorbing capacity to ensure failure can take place in an orderly manner.\n\nTo that end, we have proposed a Total Loss-Absorbing Capacity rule that contains a long-term debt requirement that is critical to the feasibility of bankruptcy for the systemic banking organizations. It is a necessary counterpart to the Dodd-Frank Act requirement that large banking organizations have credible resolution plans and undertake preparations to make those plans operationally feasible. In particular it requires the top-tier holding companies of systemic banking organizations to maintain a sufficiently large buffer of long-term debt that can be converted into equity and used to fully recapitalize their important operating subsidiaries in the event of bankruptcy. The proposed levels of long-term debt are calibrated to the specific riskiness and scale of each institution's activities, taking into account the likely shrinkage of the operations of their subsidiaries in resolution.\n\nThe requirement is designed to mitigate contagion, fire-sale, and run risks by providing comfort to depositors, short-term debt holders, and counterparties of the operating subsidiaries of the firm, since the long-term unsecured debt issued by the top-tier holding company would be structurally subordinated to the claims on the operating subsidiaries. The presence of long-term debt holders that will be bailed in ensures that taxpayer resources will not be used and should provide incentives to preserve the firm's value as it approaches insolvency, thus aligning the firm's interests with the public's broader interest in financial stability.\n\nThe Board has received many detailed comments on the proposed long-term debt rule. Some have commented on the existing stock of outstanding long-term debt with acceleration clauses that might not qualify under the rule's criteria and have proposed grandfathering as a possible solution. Others have raised questions about whether the leverage ratio or the risk-based capital framework provides the more appropriate calibration benchmark for the minimum long-term debt requirement. Comments from foreign banks have also addressed our proposal to impose internal long-term debt requirements on the U.S. intermediate holding companies of foreign banks and have asked, among other things, whether the proposed requirement should vary more depending on the resolution strategy of the parent foreign bank. We are currently carefully reviewing these comments. One thing is clear: the long-term debt requirement is a critical component in ending too big to fail.\n\nThe long-term debt requirement together with rigorous resolution plans and operational preparedness, the capital surcharges along with the capital stress tests, and the availability of sufficient amounts of high-quality liquidity where it is most likely to be needed will all substantially decrease the risk that a large financial institution's distress could pose to the broader financial system and help ensure that no banking institution is too large and too complex to fail. They will move us closer to our goal of a safer, more responsible, and more resilient financial system.\n\nReferences\nAdrian, Tobias, Michael Fleming, Or Shachar, and Erik Vogt (2015). \"Has U.S. Corporate Bond Market Liquidity Deteriorated?\"  Federal Reserve Bank of New York, Liberty Street Economics (blog), October 5.\n\nAdrian, Tobias, Michael Fleming, Daniel Stackman, and Erik Vogt (2015). \"What's Driving Dealer Balance Sheet Stagnation?\"  Federal Reserve Bank of New York, Liberty Street Economics (blog), August 21.\n\nAdrian, Tobias, Michael Fleming, Erik Vogt, and Zachary Wojtowicz (2016a), \"Corporate Bond Market Liquidity Redux: More Price-Based Evidence,\"  Federal Reserve Bank of New York, Liberty Street Economics (blog), February 9.\n\n--------- (2016b), \"Further Analysis of Corporate Bond Market Liquidity,\"  Federal Reserve Bank of New York, Liberty Street Economics (blog), February 10.\n\nBank for International Settlements, Committee on the Global Financial System (2016). \"Fixed Income Market Liquidity (PDF),\"  CGFS Papers, no. 55. Basel, Switzerland: BIS, January.\n\nBlanchard, Olivier (2016). \"The U.S. Phillips Curve: Back to the 60s? (PDF)\"  Policy Brief PB16-1. Washington: Peterson Institute of International Economics, January.\n\nBlanchard, Olivier, Eugenio Cerutti, and Lawrence Summers (2015). \"Inflation and Activity--Two Explorations and Their Monetary Policy Implications (PDF),\"  NBER Working Paper Series 21726. Cambridge, Mass.: National Bureau of Economic Research, November.\n\nBoard of Governors of the Federal Reserve System (2016). Monetary Policy Report (PDF). Washington: Board of Governors, February.\n\nBrainard, Lael (2015). \"Normalizing Monetary Policy When the Neutral Interest Rate Is Low,\" speech delivered at Stanford Institute for Economic Policy Research, Stanford, Calif., December 1.\n\nCai, Fang, Song Han, Dan Li, and Yi Li (2015). \"Institutional Herding in the Corporate Bond Market,\" working paper, Board of Governors of the Federal Reserve System, December, available at the Social Science Research Network.\n\nCetorelli, Nicola, Fernando Duarte, and Thomas Eisenbach (2016). \"Are Asset Managers Vulnerable to Fire Sales?\"  Federal Reserve Bank of New York, Liberty Street Economics (blog), February 18.\n\nDel Negro, Marco, Marc Giannoni, Matthew Cocci, Sara Shahanaghi, and Micah Smith (2015). \"Why Are Interest Rates So Low?\"  Federal Reserve Bank of New York, Liberty Street Economics (blog), May 20.\n\nDobrev, Dobrislav, and Ernst Schaumburg (2016). \"High-Frequency Cross-Market Trading and Market Volatility,\"  Federal Reserve Bank of New York, Liberty Street Economics (blog), February 17.\n\nFleming, Michael (2016). \"Is Treasury Market Liquidity Becoming More Concentrated?\"  Federal Reserve Bank of New York, Liberty Street Economics (blog), February 11.\n\nGruber, Joseph, Andrew McCallum, and Robert Vigfusson (2016). \"The Dollar in the U.S. International Transactions (USIT) Model,\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System, February 8.\n\nHamilton, James D., Ethan S. Harris, Jan Hatzius, and Kenneth D. West (2015). \"The Equilibrium Real Funds Rate: Past, Present, and Future (PDF),\"  NBER Working Paper Series 21476. Cambridge, Mass.: National Bureau of Economic Research, August.\n\nInternational Monetary Fund (2014). \"Perspectives on Global Real Interest Rates,\"  chapter 3 in World Economic Outlook: Recovery Strengthens, Remains Uneven. Washington: IMF, April, pp. 81-112.\n\nJohannsen, Benjamin K., and Elmar Mertens (2016). \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, February 9.\n\nKiley, Michael T. (2015a). \"What Can the Data Tell Us about the Equilibrium Real Interest Rate? (PDF)\" Finance and Economics Discussion Series 2015-077. Washington: Board of Governors of the Federal Reserve System, August.\n\n--------- (2015b). \"Low Inflation in the United States: A Summary of Recent Research,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, November 23.\n\nLaubach, Thomas, and John C. Williams (2015). \"Measuring the Natural Rate of Interest Redux (PDF),\"  Working Paper Series 2015-16. San Francisco: Federal Reserve Bank of San Francisco, October.\n\n\n\nI am grateful to Andrew Figura for his assistance in preparing this text.\n\n1. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. Despite the drop-off in drilling investment, oil production has been surprisingly resilient, as producers have increased the productivity of established wells. Return to text\n\n3. See Gruber, McCallum, and Vigfusson (2016). Return to text\n\n4. Core consumer price index (CPI) inflation has been 1/2 percentage point higher than core PCE inflation over the 12 months through January. Over the past 15 years, core CPI inflation has averaged about 1/4 percentage point more than core PCE inflation. Much of the recent larger gap is due to differences in the coverage of health-care services and to differences in the weight accorded to housing services and health-care services. The CPI only covers out-of-pocket expenditures for health-care services, while the PCE index covers a much broader range of spending. Expenditures on housing are a larger share of the CPI than of the PCE index, and prices for housing services have increased at an above-average pace recently. Return to text\n\n5. See pp. 8-9 of the February 2016 Monetary Policy Report (Board of Governors, 2016). Return to text\n\n6. See Blanchard (2016); Blanchard, Cerutti, and Summers (2015); and Kiley (2015b). Return to text\n\n7. To the extent that the neutral rate of interest--the rate that keeps output at its potential level and inflation at its target--has fallen in the United States and is low around the world, this may weigh on the policy path. See Laubach and Williams (2015), Hamilton and others (2015), Kiley (2015a), Johannsen and Mertens (2016), Del Negro and others (2015), Brainard (2015), and chapter 3 of World Economic Outlook (International Monetary Fund, 2014). Return to text\n\n8. Because the most recent 12-month change in core PCE prices includes several relatively large monthly increases in core PCE prices in the first part of 2015, it is possible that 12-month core PCE inflation will move lower in coming months as these relatively large monthly increases drop out of the 12-month window. Return to text\n\n9. See Adrian, Fleming, Shachar, and Vogt (2015); and Adrian, Fleming, Vogt, and Wojtowicz (2016b). Return to text\n\n10. See Adrian, Fleming, Vogt, and Wojtowicz (2016a); and Fleming (2016). Return to text\n\n11. See Dobrev and Schaumburg (2016). Return to text\n\n12. See Bank for International Settlements (2016). Return to text\n\n13. In particular, research has suggested that corporate bond funds exhibit herding behavior--that is, a tendency for waves of sales or purchases of common securities across funds. This herding appears more significant for less liquid bonds, which could exacerbate the concerns noted above. See Cai and others (2015). Also, see Cetorelli, Duarte, and Eisenbach (2016) for estimates of the effects of asset fire sales. Return to text\n\n14. See Adrian, Fleming, Stackman, and Vogt (2015). Return to text"
    },
    {
        "speaker": "Lael Brainard",
        "position": "Governor",
        "date": "February 26, 2016",
        "title": "What Happened to the Great Divergence?",
        "href": "https://www.federalreserve.gov/newsevents/speech/brainard20160226a.htm",
        "content": "February 26, 2016\n\nGovernor Lael Brainard\n\nAt the 2016 U.S. Monetary Policy Forum, New York, New York\n\nBeginning in 2014, we saw confident predictions of a coming strong divergence in monetary policy among the major economies. To date, there has been less policy divergence in reality than had been predicted. This observation raises the question of whether there may be limits on policy divergence in current circumstances. Such limits might reflect common forces buffeting economies around the world or the powerful transmission of shocks across borders through exchange rate and other financial channels that may have the effect of front-running monetary policy adjustments in the vicinity of the zero lower bound. Put differently, predictions that U.S. monetary policy would chart a notably divergent path have been tempered by powerful crosscurrents from abroad.1\n\nHow Different Are Underlying Conditions?\nBefore turning to divergences in policy, it is useful to review briefly the extent of differences in the underlying economic conditions in the major advanced economies. While the recovery from the global financial crisis has been frustratingly slow in every major economy, there nonetheless have been important differences in the pace and extent of healing. Speaking loosely, among the advanced economies, the United States and United Kingdom appear farthest along in closing resource gaps, Japan is next in line, and the euro area has been somewhat slower to recover. In the United States, resource utilization has increased substantially over the past five years. The U.S. unemployment rate is now under 5 percent, compared with 10 percent at its recent peak. Even so, there is evidence that some labor market slack still remains.2 The United Kingdom has experienced a rapid drop in unemployment to 5.1 percent, as low as pre-crisis levels, and labor force participation has remained relatively strong. In contrast, unemployment in the euro area was 10-1/2 percent in the fourth quarter, down just 1-3/4 percentage points from its recent peak and still well above pre-crisis levels. Accordingly, market participants have expected policy in the United States and the United Kingdom to become less accommodative, while remaining very accommodative over the medium term in the euro area.3\n\nIn Japan, expectations of monetary policy divergence have reflected Japan's long period of disappointments on its inflation target to a greater extent than its remaining resource gap. Japan's unemployment rate is 3.3 percent, already below the previous cyclical trough, and the International Monetary Fund estimates the output gap to have been the same in Japan and the United States in 2015 at 1-1/2 percent. However, with inflation in Japan previously having been near zero for an extended period and inflation expectations under pressure, the Bank of Japan's commitment to increasing inflation expectations and moving inflation up to its 2 percent target has led market participants to expect extremely accommodative monetary policy to persist for quite a while.\n\nCurrently, however, there are smaller differences among the major economies on measures of realized and expected inflation than there are on resource utilization. In 2015, the 12-month change in total personal consumption expenditures (PCE) inflation in the United States was 0.6 percent, while headline inflation in the United Kingdom, euro area, and Japan were 0.2 percent. All inflation rates are well below target. Of course, to the extent that the downward pressure on global inflation is due to falling oil prices, this pressure would be expected to abate if oil prices stabilize.\n\nBut even after removing energy prices, core PCE inflation has come in consistently under the Federal Reserve's 2 percent target here in the United States and does not look very different from inflation in economies that are expected to maintain accommodative monetary policy for some time. Core PCE inflation, or inflation excluding food and energy prices, has remained stubbornly in the vicinity of 1-1/4 to 1-1/2 percent over the past three years in the United States, similar to the United Kingdom and not very different from the roughly 1 percent core inflation in the euro area and Japan.\n\nWe also see notable similarities in the recent deterioration in market measures of inflation expectations. While in the euro area, swaps-based inflation compensation has fallen about 3/4 percentage point since the middle of 2014 and is now around 1-1/2 percent at the five-year, five-year-ahead horizon, in the United States, swaps-based inflation compensation has fallen 1 full percentage point over the same period and is now at 1-3/4 percent. Japan has experienced a similar decline over this period, while the United Kingdom has seen a much more modest decline.\n\nWith realized and expected future inflation not showing large differences, the expectation of monetary policy divergence between the United States, on the one hand, and the United Kingdom and the euro area, on the other, must rest to a large extent on remaining differences in resource utilization and expectations that inflation outcomes will diverge as a result of these differences. However, it is important to note that the extent of inflation divergence generated by differences in resource utilization across countries is likely much smaller now than it has been in earlier decades. Recent research suggests a dramatic flattening of the Phillips curve in recent decades.4 If this finding continues to hold true, resource utilization would need to differ more sharply across national economies to produce a noticeable difference in inflation.\n\nThe persistence of relatively soft core PCE inflation readings in the United States, despite a substantial improvement in employment, suggests we should be cautious in relying on the historical relationship between employment gains and stronger inflation in today's economy. Moreover, the softening in market-based measures of inflation expectations and some hints of weakening in survey measures deserve our attention. This deterioration in inflation expectations and a weakened link between labor market tightening and inflation--together with the asymmetry of policy in the vicinity of the lower bound--lead me to put a high premium on evidence that actual inflation is firming sustainably.\n\nPutting these pieces of evidence together suggests that if core inflation remains below target in all major advanced economies and inflation expectations remain under pressure in many, I might expect policy divergence to remain more limited than previously predicted.\n\nCommon Conditions\nTo the extent that we are observing limited divergence in inflation outcomes and less divergence in realized policy paths than many anticipated, this could be attributable to common shocks or trends that cause economic conditions to be synchronized across economies. The sharp repeated declines in the price of oil have been a major common factor depressing headline inflation and are also likely feeding into low core inflation, although to a lesser extent.5 As noted previously, these price declines have led headline inflation across the globe to behave quite similarly over this time period. Even so, most observers expect this source of convergence in inflationary outcomes to eventually fade and thereafter not affect monetary policy paths over the medium term.\n\nIn contrast, a more persistent source of convergence may be found in an apparent decline in the neutral rate of interest. The neutral rate of interest--or the rate of interest consistent with the economy remaining at its potential rate of output and inflation remaining at target level--appears to have declined over the past 30 years in the United States and is now at historically low levels.6 Similarly, longer-run interest rates appear also to have fallen across a broad group of advanced and emerging market economies, suggesting that neutral rates are at historically low levels in many countries around the world and near or below zero in the major advanced foreign economies.7 Although the reasons for the declines in neutral rates are not perfectly understood and may differ across countries, there are some common drivers, such as slower productivity and labor force growth and a heightened sensitivity to risk.8\n\nThe very low levels of the shorter run neutral rate reflect in part headwinds from the crisis that are likely to dissipate over time. However, if many of the common forces holding down neutral rates prove persistent, then neutral rates may remain low through the medium term, implying a shallower path for policy trajectories.\n\nThe global economy is also experiencing a downshift in emerging market growth momentum led by China, which may prove somewhat persistent. Whereas earlier in the recovery there was a striking divergence between the relatively buoyant growth in major emerging economies and depressed growth in advanced economies, lately the extent of divergence has diminished noticeably.9 China is undergoing a challenging set of economic transitions. Trend growth has slowed substantially and is expected to slow further, and the composition of growth is shifting away from resource-intensive manufacturing and exports toward a greater share for consumption and services. China's investment has slowed sharply recently after accounting for nearly one-third of global investment over the past three years and about one-half of global consumption in certain metals such as iron ore, aluminum, copper, and nickel. Commodity exporters and close trading partners in Asia will be most affected, but the changes in the composition and rate of growth in a country that has accounted for about one-third of the growth in world output and trade will likely ripple through the global economy much more generally.\n\nAmplified Spillovers \nOf course, policy divergence among major economies could be limited by rapid and strong transmission of foreign shocks across borders. In particular, although the U.S. real economy has traditionally been seen as more insulated from foreign trade shocks than many smaller economies, the combination of the highly global role of the dollar and U.S. financial markets and the proximity to the zero lower bound may be amplifying spillovers from foreign financial conditions. By one rough estimate, accounting for the net effect of exchange rate appreciation and changes in equity valuations and long term yields, over the past year and a half, the United States has experienced a tightening of financial conditions that is the equivalent of an additional increase of over 75 basis points in the federal funds rate.10\n\nThe transmission of divergent economic conditions across borders typically occurs though a couple of different channels. First, a decline in demand in one country reduces its demand for imports from other countries. Second, the fall in economic activity would be expected to trigger a more accommodative monetary policy, which helps offset the effect of the shock by both supporting domestic demand and weakening the exchange rate. The weaker exchange rate in turn leads domestic consumers to switch their expenditures away from more expensive foreign imports to cheaper domestic products while increasing the competitiveness of exports. The extent to which monetary policy offsets the shock by dispersing it to trade partners as opposed to strengthening domestic demand depends on the responsiveness of domestic demand relative to the exchange rate. The exchange rate channel, by raising the price of imports in domestic currency, also pushes up domestic inflation and exerts downward pressure on foreign inflation.\n\nThe strength of spillovers across countries and the extent to which that affects policy divergence across countries depend on a foreign economy's openness to these different channels. The recent experience of Sweden suggests that for highly open economies, the effect of foreign shocks can be extremely powerful.11 Sweden's economic growth has been relatively rapid recently, reaching nearly 4 percent over the most recent four quarters. Moreover, the employment gap is estimated to be nearly closed, and there are signs of financial excess in the housing market. In ordinary times, these conditions would be consistent with relatively tight monetary policy. However, inflation has run persistently well below the central bank's 2 percent inflation target. Given the relative openness of Sweden's economy, moving the inflation rate back up to target has been greatly complicated by the sensitivity of Sweden's exchange rate and financial conditions to developments in the euro area, where domestic economic conditions are consistent with much more accommodative policy. As a result, the Riksbank has been pursuing extremely accommodative monetary policy, most recently lowering the interest rate on deposits to minus 0.5 percent and authorizing the Governor and Deputy Governor to intervene in foreign currency markets.\n\nEven in the much larger United States economy, with imports accounting for a little over 15 percent of gross domestic product (GDP), spillovers can be quite strong, in part reflecting the international role of U.S. financial markets and the dollar. Since the middle of 2014, with a reassessment of demand growth in the euro area and subsequently in emerging markets and other commodity exporters, the real trade-weighted value of the dollar has increased nearly 20 percent. As a result, in 2014 and 2015, net exports subtracted a little over 1/2 percentage point from GDP growth each year, and econometric models point to a subtraction of a further 1 percentage point this year.12 In addition, the dollar's appreciation is estimated to have put significant downward pressure on inflation: Non-oil import prices fell 3-1/2 percent in 2015, subtracting an estimated 1/2 percentage point from core PCE inflation.13\n\nFinancial channels can powerfully propagate negative shocks in one market by catalyzing a broader reassessment of risks and increases in risk spreads across many financial markets. Since the beginning of the year, U.S. financial markets have reacted strongly to adverse news on emerging market growth, even though the news on the U.S. labor market has remained positive. In this regard, although China's direct imports from the United States are modest, uncertainty about changes to its exchange rate system and financial imbalances, together with changes in the composition of its growth, have had broader global spillovers that may pose risks to the U.S. outlook.\n\nRecent events suggest the transmission of foreign shocks can take place extremely quickly such that financial markets anticipate and indeed may thereby front-run the expected monetary policy reactions to these developments. It also appears that the exchange rate channel may have played a particularly important role recently in transmitting economic and financial developments across national borders. Indeed, recent research suggests that financial transmission is likely to be amplified in economies with near-zero interest rates, such that anticipated monetary policy adjustments in one economy may contribute more to a shifting of demand across borders than a boost to overall demand.14 This finding could explain why the sensitivity of exchange rate movements to economic news and to changes in foreign monetary policy appear to have been relatively elevated recently.\n\nFinancial tightening associated with cross-border spillovers may be limiting the extent to which U.S. policy diverges from major economies. As policy adjusts to the evolution of the data, the combination of heightened spillovers from weaker foreign economies, along with a lower neutral rate, could result in a lower policy path in the United States relative to what many had predicted.\n\nPolicy\nIn circumstances where many economies face common negative shocks or where negative shocks in one country are quickly transmitted across borders, it is natural to consider whether coordination can improve outcomes. Under certain conditions--such as flexible exchange rates, deep and well-regulated financial markets, and flexible product and labor markets--policies designed for the domestic economy can readily offset any spillovers from economic conditions abroad, and policies designed to address domestic conditions can achieve desirable outcomes both within the national economy and more broadly.15\n\nIn some circumstances, however, cooperation can be quite helpful. If, for example, economies face a common challenge, coordination can communicate to markets that policymakers recognize the challenge and will work to address it. Reducing uncertainty about the direction of policy and addressing concerns about policies working at cross-purposes can boost the confidence of businesses and households. With intensified transmission effects in the vicinity of the zero lower bound, there is a risk that uncoordinated policy on its own could have the effect of shifting demand across borders rather than addressing the underlying weakness in global demand. The difficult start to the year should be a prompt for greater policy coherence and clarity. This might be a good time for policymakers to reaffirm their commitment to work toward the common goal of strengthening global demand.\n\nSimilarly, with anemic global demand and interest rates near zero, in some economies there is scope for monetary policy to be more effective with fiscal policy working in the same direction. With potential growth and nominal borrowing rates both low, public investment that increases potential in the longer run and demand in the shorter run could make an important contribution. A joint determination by policymakers across major economies to better deploy policy tools to provide support for global demand could be beneficial.\n\nReferences\nBlanchard, Olivier (2016). \"The U.S. Phillips Curve: Back to the 60s? (PDF)\" Policy Brief PB16-1. Washington: Peterson Institute of International Economics, January.\n\nBlanchard, Olivier, Eugenio Cerutti, and Lawrence Summers (2015). \"Inflation and Activity--Two Explorations and Their Monetary Policy Implications,\" NBER Working Paper Series 21726. Cambridge, Mass.: National Bureau of Economic Research, November.\n\nBoard of Governors of the Federal Reserve System (2016). Monetary Policy Report. Washington: Board of Governors, February, www.federalreserve.gov/monetarypolicy/files/20160210_mprfullreport.pdf.\n\nBrainard, Lael (2015a). \"Unconventional Monetary Policy and Cross-Border Spillovers,\" speech delivered at \"Unconventional Monetary and Exchange Rate Policies,\" the 16th International Monetary Fund Jacques Polak Research Conference, sponsored by the International Monetary Fund, Washington, November 6.\n\n--------- (2015b). \"Normalizing Monetary Policy When the Neutral Interest Rate Is Low,\" speech delivered at Stanford Institute for Economic Policy Research, Stanford, Calif., December 1.\n\nCaballero, Ricardo J., Emmanuel Farhi, and Pierre-Olivier Gourinchas (2015). \"Global Imbalances and Currency Wars at the ZLB,\" NBER Working Paper Series 21670. Cambridge, Mass.: National Bureau of Economic Research, October.\n\nDel Negro, Marco, Marc Giannoni, Matthew Cocci, Sara Shahanaghi, and Micah Smith (2015). \"Why Are Interest Rates So Low?\" Federal Reserve Bank of New York, Liberty Street Economics (blog), May 20.\n\nGruber, Joseph, Andrew McCallum, and Robert Vigfusson (2016). \"The Dollar in the U.S. International Transactions (USIT) Model,\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System, February 8.\n\nHamilton, James D., Ethan S. Harris, Jan Hatzius, and Kenneth D. West (2015). \"The Equilibrium Real Funds Rate: Past, Present, and Future,\" NBER Working Paper Series 21476. Cambridge, Mass.: National Bureau of Economic Research, August.\n\nInternational Monetary Fund (2014). \"Perspectives on Global Real Interest Rates,\" chapter 3 in World Economic Outlook: Recovery Strengthens, Remains Uneven. Washington: IMF, April, pp. 81-112.\n\nJohannsen, Benjamin K., and Elmar Mertens (2016). \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, February 9.\n\nKiley, Michael T. (2015a). \"What Can the Data Tell Us about the Equilibrium Real Interest Rate?\" Finance and Economics Discussion Series 2015-077. Washington: Board of Governors of the Federal Reserve System, August.\n\n--------- (2015b). \"Low Inflation in the United States: A Summary of Recent Research,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, November 23.\n\nLaubach, Thomas, and John C. Williams (2015). \"Measuring the Natural Rate of Interest Redux (PDF),\" Working Paper Series 2015-16. San Francisco: Federal Reserve Bank of San Francisco, October.\n\nI am grateful to Andrew Figura for his assistance in preparing this text.\n\n1. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. The employment-to-population ratio for prime-age individuals, for example, is nearly 2 percentage points below its 2004-07 average, while part-time work remains elevated and progress on wages has been slow. Return to text\n\n3. See p. 24 of the February 2016 Monetary Policy Report (Board of Governors, 2016). Return to text\n\n4. In the United States, for example, Blanchard (2016) estimates that the slope of the Phillips curve has declined by more than two-thirds since the 1970s. Other recent research includes Blanchard, Cerutti, and Summers (2015) and Kiley (2015b). Return to text\n\n5. In five of the six quarters since mid-2014, the price of oil has decreased for a cumulative decline of 70 percent. Return to text\n\n6. See Brainard (2015b), Hamilton and others (2015), Kiley (2015a), Laubach and Williams (2015), and Johannsen and Mertens (2016). Return to text\n\n7. See Hamilton and others (2015), Del Negro and others (2015), and chapter 3 of World Economic Outlook (International Monetary Fund, 2014). Return to text\n\n8. While the empirical link between potential growth and the neutral rate is not precisely estimated, the evidence suggests that slower trend growth is associated with lower interest rates; see Laubach and Williams (2015) and Hamilton and others (2015). U.S. labor force growth has slowed from 1 percent from 2001 to 2004 to 1/2 percent over the most recent 4 years. Over the same periods, euro-area growth has slowed from 1.3 percent to 0.4 percent. In Japan the labor force was essentially flat from 2011 to 2015, though this was a slight improvement from a small rate of decline in the early 2000s. Productivity growth over the same periods has slowed from 3.0 percent to 0.5 percent in the United States, from 0.6 percent to 0.2 percent in the euro area, and 1.5 percent to 0.5 percent in Japan.\n\nRegarding sensitivity to risk, the risk premium for capital investment appears to have increased since the crisis; see Del Negro and others (2015). A higher risk premium requires a lower risk-free rate to generate an equivalent level of investment. Return to text\n\n9. From the end of 2009 to the end of 2013, growth in important U.S. emerging market trading partners averaged 4.7 percent, while growth in advanced economies averaged 1.8 percent. However, in 2014 emerging country growth slowed to 3.3 percent, compared with 1.6 percent in advanced economies, and for the first three quarters of 2015, annualized growth was 2.5 percent and 1.1 percent, respectively. Return to text\n\n10. These estimates are based on rough rules of thumb regarding the effects on output of changes in long-term interest rates, equity prices, the exchange rate, and the federal funds rate from the FRB/US model and assume a highly persistent change in the federal funds rate. Some private-forecaster estimates of financial tightening--expressed in terms of the federal funds rate--are larger, which may reflect an assumption of a less persistent funds rate change. An alternative estimate from the Federal Reserve Bank of New York's DSGE model, which explicitly includes a financial sector, suggests the tightening in financial conditions since mid-2015 is equivalent to an increase in the federal funds rate of roughly 100 basis points. Return to text\n\n11. Imports and exports each account for a little under one-half of Sweden's GDP. Return to text\n\n12. See Gruber, McCallum, and Vigfusson (2016). Return to text\n\n13. See pp. 8-9 of the February 2016 Monetary Policy Report (Board of Governors, 2016). Return to text\n\n14. See Caballero, Farhi, and Gourinchas (2015). Return to text\n\n15. See Brainard (2015a). Return to text"
    },
    {
        "speaker": "Jerome H. Powell",
        "position": "Governor",
        "date": "February 26, 2016",
        "title": "Discussion of the paper \"Language after Liftoff: Fed Communication Away from the Zero Lower Bound\"",
        "href": "https://www.federalreserve.gov/newsevents/speech/powell20160226a.htm",
        "content": "February 26, 2016\n\nGovernor Jerome H. Powell\n\nAt the 2016 U.S. Monetary Policy Forum, New York, New York\n\nThis paper reviews Federal Open Market Committee (FOMC) communications from the time the Committee began issuing regular postmeeting statements in 1999 to the present.1 The authors provide an extended and insightful discussion of the theory and practice of providing forward guidance about monetary policy. They offer one central lesson: Data-based forward guidance is mostly good, while time-based forward guidance is mostly bad.\n\nThe authors show that data-based guidance has desirable characteristics and can make monetary policy more effective. When clearly articulated and well understood, it allows markets to react appropriately to incoming data, doing the heavy lifting for the central bank.\n\nTime-based guidance is found to have certain bad characteristics and should be avoided, except at the zero lower bound and when other options are not available or not working. Time-based guidance may reduce the sensitivity of rates to incoming macroeconomic data, suppress volatility, encourage risk-taking and increased leverage, and threaten financial stability. It may also put policymakers in a box when changes in the economy make it optimal to deviate from previously expressed guidance, but the Committee cannot do so without losing credibility.\n\nThe authors blame time-based guidance for several episodes in which the Committee zigged when the market looked for it to zag, leaving market participants unhappy and, in the authors' view, the FOMC's credibility damaged. They argue that the Committee has relied too much on time-based guidance in recent years and should use it only parsimoniously in the future.\n\nI commend the authors for undertaking this enormously challenging and useful exercise. The paper forces us to reconsider the Committee's evolving understanding of the macroeconomic environment before, during, and after the Great Recession; its decisions and its communications; and the market's understanding of those decisions, which have sometimes deviated from what the Committee actually said.\n\nThe distinction between time-based and data-based guidance is an important one, and the potential problems with time-based guidance are real and well described in the paper. That said, I am not convinced that this distinction has played a central role in determining the successes and challenges of FOMC communications in this remarkable era, or that it helps us improve in the future. The authors are, in their words, \"unabashedly judgmental\" in labeling specific communications to be either time- or data-based.2 My own judgments differ in significant respects from those described in the paper.\n\nDiscussion of Forward Guidance\nI will start in December 2008, when the Committee said that \"weak economic conditions are likely to warrant exceptionally low levels of the federal funds rate for some time.\"3 This relatively weak time-based guidance was strengthened in a series of steps until August 2011, when the time-based language became \"at least through mid-2013.\"4 The calendar reference was later extended in a couple of steps to \"at least through mid-2015.\"5 This guidance was explicitly time-based, and the authors seem to agree that, through this point, the guidance served its intended purpose at the zero lower bound by pushing down medium- and longer-term rates.6\n\nAt the December 2012 meeting, the Committee ended this calendar-based guidance. The Committee instead adopted thresholds, saying that it did not intend to raise rates at least as long as unemployment remained above 6-1/2 percent, inflation one to two years ahead was projected to be no higher than 2-1/2 percent, and longer-term inflation expectations remained well anchored.7 The adoption of thresholds was a clear change to data-based guidance, as its principal sponsors had frequently urged.8 The point was not to provide additional stimulus at the time of adoption, but rather to allow market participants to adjust their expectations about future monetary policy in response to incoming data--exactly what the authors advocate.9\n\nThe Committee also used balance sheet policy through most of this period. The first two programs of large-scale asset purchases (LSAPs), popularly known as QE1 and QE2, and the maturity extension program were announced in terms of time and quantity--that is, a certain quantity of assets would be purchased over a certain time. In adopting QE3, by contrast, the Committee committed to continuing purchases until there was a substantial improvement in the outlook for the labor market.10 QE3 was fully data-contingent.\n\nFormer Chairman Bernanke recounts in his recent book that he saw QE3 as akin to Mario Draghi's statement that the European Central Bank would do \"whatever it takes.\"11 He also notes that FOMC participants held divergent views on the potential costs and benefits of the program. Minutes of the relevant meetings described the complex discussions and differing views. Contemporaneous reports by Wall Street analysts show frustration and confusion about the Committee's intentions.\n\nWhen various FOMC communications suggested that the time to begin reducing purchases was nearing, long-term rates rose sharply--the so-called taper tantrum. The contention of this paper is that time-based guidance was responsible. But as the paper acknowledges, the open-ended, data-contingent nature of the QE3 program created a strong sense that the Fed was \"all in\" and that the purchases might go on for a long time. That powerful commitment \"would set things up for some fireworks\" when the time came to provide more precise guidance as to the timing of tapering, whether that was done through time- or data-based guidance.12 While Committee communications are subject to fair criticism, I don't see an important role in this narrative for time-based guidance.\n\nLet's turn briefly to 2015 and the run-up to last December's increase in the federal funds rate--also an important focus of the paper. The authors and many market participants are critical of communication around the September meeting. With the June 2015 Summary of Economic Projections (SEP) showing that 15 of 17 FOMC participants judged that appropriate policy would entail an initial increase in the federal funds rate by the end of 2015, markets saw about a 50 percent chance that the first increase would occur in September. This probability fell to about 30 percent after global markets experienced a sudden bout of volatility following China's surprise devaluation of its currency in August. At the September meeting, the FOMC decided to wait to see how global markets and the economy evolved, noting in its statement that \"Recent global economic and financial developments may restrain economic activity somewhat and are likely to put further downward pressure on inflation in the near term.\"13\n\nA data-driven Committee, making decisions meeting by meeting, is likely to surprise markets from time to time. The authors join many others in criticizing the \"measured pace\" period of 2004 through 2006, during which the Committee increased rates by 25 basis points at 17 consecutive FOMC meetings. A common criticism has been that this high level of predictability made investors complacent, encouraging a buildup of leverage and helping set the stage for the Global Financial Crisis. That criticism may well overstate the importance of the Committee's communications; nonetheless, a number of FOMC participants have said that the Committee intends to be \"data driven\" and not fall into an excessively predictable, data-insensitive path. Lower predictability implies more surprises.\n\nIn the statement released after its October 2015 meeting, the Committee reemphasized data dependence and focused on the importance of incoming data for the Committee's decision \"at its next meeting,\" which led the market to increase its estimated probability of a December rate increase from 38 percent to 50 percent.14 The October and November non-farm payroll reports came in strong and above expectations, raising that probability by the time of the December meeting to about 90 percent. In other words, the Committee used modest time-based guidance to set the stage and then let incoming data do the heavy lifting. In the statement released after the FOMC's most recent meeting in January, the Committee said that, in evaluating future adjustments to the target range for the federal funds rate, it would \"assess realized and expected economic conditions relative to its objectives of maximum employment and 2 percent inflation.\"15 This language shows that the Committee has moved away from the time-based guidance of the crisis years.\n\nAlthough time-based guidance can create communications challenges, I see other factors as having been more important in recent years. In particular, the challenge of deciding when and how to use unconventional tools--and ultimately when and how to reduce that usage--is a great one. The task of communicating clearly about those decisions is equally great. And the reality of the FOMC's size and diversity, not to mention uncertainty about the evolving structure of the economy and the effects of monetary policy actions, means that we are still far from the ideal world of a fully worked out, clearly specified and transparent consensus on what economists call a \"reaction function\"--a complete description of how policy will respond to changes in economic conditions.\n\nOften when communicating about the path of policy, it will be hard to avoid a combination of the two forms of guidance. For example, the Committee has embraced the view that the equilibrium level of the federal funds rate is currently below its pre-crisis level and expects the funds rate to return only gradually to its longer-run value.16 This view is a key aspect of many Committee participants' reaction functions, including mine. Try saying that without referring to time.\n\nThe authors acknowledge that the distinction between rules and discretion is too simple to capture the problems that monetary policymakers face.17 I would say the same of the distinction between time-based and data-based forward guidance.\n\nLessons Learned and Suggested Improvements\nBefore turning to the paper's conclusions, I would like to put the Federal Reserve's communications into a broader context. In recent years, the FOMC has adopted many new and significant communications tools. Since the fall of 2007, policymakers have submitted projections in conjunction with four FOMC meetings each year; in 2012, those projections were augmented to include each participant's path for appropriate monetary policy. In 2011, the Chairman began holding quarterly press conferences. In 2012, the Committee first released its statement on Longer-run Goals and Monetary Policy Strategy, which formalized the FOMC's 2 percent inflation objective and is reaffirmed each year at the January meeting. These and other changes have kept the Federal Reserve among the world's most transparent central banks in its communications with the public.\n\nWith that as background, I find significant grounds for agreement and further analysis in the paper's concluding section, which lays out lessons learned and suggested improvements. The discussion of what is colloquially known as the \"dot plot\" included in the SEP is particularly interesting. The dot plot represents each FOMC participant's individual assessment of the path of the federal funds rate over the next three years that is most likely to promote maximum employment and stable prices.18\n\nThe dot plot presents a number of challenges. The individual dots are not tied to the individual macroeconomic forecasts presented in the SEP, and no information is provided on the identity of the forecaster--for example, voting members of the Committee are not distinguished from non-voting participants. There is no easy path to the identification of a Committee reaction function. The dots speak as of their date of publication after the FOMC meetings held in March, June, September, and December. Three months pass between SEPs. The economic outlook can change quite significantly, making the reigning dots look out of touch. On occasion, the dot plot and the postmeeting statement have seemed to send conflicting signals. The dot plot reflects individual views of appropriate policy, while the postmeeting statement reflects the consensus of the Committee.\n\nThe authors weigh these challenges and ponder whether to eliminate the dot plot; some appear to favor that idea.19 I doubt that most market participants would welcome the elimination of this chart. The SEP provides a number of benefits. It requires FOMC participants to write down their forecasts for inflation, unemployment, and growth, as well as their assessments of appropriate monetary policy. This exercise helps policymakers to be more systematic. In addition, by observing how the SEP changes over time, the public can better understand how Committee members react to changes in the economy. My view is that the dot plot, on balance, is helpful to market participants and hence to the Committee. As the dot plot enters its fifth year of existence, my hope is that we will be able to capture those benefits while avoiding its shortcomings.\n\nI agree with the paper's suggestion of greater emphasis on the degree of uncertainty around the projections, which is much larger than the dispersion of the individual forecasts. As you know, at its January meeting, the Committee discussed adding fan charts to the SEP. Fan charts could help emphasize that the economic outlook is uncertain, and that consequently there is considerable uncertainty around the path of policy.\n\n1. The views expressed here are my own, and not those of the FOMC.\n\nSee Michael Feroli, David Greenlaw, Peter Hooper, Frederic Mishkin, and Amir Sufi (2016), \"Language after Liftoff: Fed Communication Away from the Zero Lower Bound,\" paper presented at the 2016 U.S. Monetary Policy Forum, a conference sponsored by the University of Chicago Booth School of Business, held in New York, February 26; see https://research.chicagobooth.edu/igm/events/conferences/2016-usmonetaryforum.aspx. Return to text\n\n2. See Feroli and others, \"Language after Liftoff,\" in note 1, p. 20. Return to text\n\n3. Board of Governors of the Federal Reserve System (2008), \"FOMC Statement and Board Approval of Discount Rate Requests of the Federal Reserve Banks of New York, Cleveland, Richmond, Atlanta, Minneapolis, and San Francisco,\" press release, December 16, paragraph 4. Return to text\n\n4. Board of Governors of the Federal Reserve System (2011), \"FOMC Statement,\" press release, August 9, paragraph 3. Return to text\n\n5. Board of Governors of the Federal Reserve System (2012), \"Federal Reserve Issues FOMC Statement,\" press release, September 13, paragraph 5. Return to text\n\n6. Some viewed this guidance as merely a forecast of Committee action, designed to better inform the market and reduce uncertainty. Others have argued that such guidance is understood as a promise to which the Committee will be held irrespective of future macroeconomic developments. The Committee never offered a single explanation, and participants may have had different views. Engen, Laubach, and Reifschneider (2015) argue that the Federal Reserve's time-based guidance initiated in August 2011 was highly effective in inducing market participants to change their beliefs about the Committee's reaction function and to regard monetary policy as more accommodative. Using Blue Chip survey data, the authors estimate that the perceived weight on resource slack roughly doubled between March 2011 and March 2012. In an August 2011 speech, Chairman Bernanke indicated that the guidance about the federal funds rate path was highly conditional on the outlook, saying, \"in what the Committee judges to be the most likely scenarios for resource utilization and inflation in the medium term, the target for the federal funds rate would be held at its current low levels for at least two more years.\" (Ben S. Bernanke (2011), \"The Near- and Longer-Term Prospects for the U.S. Economy,\" a speech delivered at \"Achieving Maximum Long-Run Growth (PDF),\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 26, p. 7.) Return to text\n\n7. Board of Governors of the Federal Reserve System (2012), \"Federal Reserve Issues FOMC Statement,\" press release, December 12, paragraph 5. Return to text\n\n8. For example, see Charles L. Evans (2012), \"Macroeconomic Effects of FOMC Forward Guidance,\" speech delivered at the Spring Panel on Economic Activity, Brookings Institution, Washington, March 22; and Alejandro Justiniano, Charles L. Evans, Jeffrey R. Campbell, and Jonas D.M. Fisher (2012), \"Macroeconomic Effects of FOMC Forward Guidance (PDF),\" Brookings Papers on Economic Activity, Spring, pp. 1-54. Return to text\n\n9. The thresholds' useful life was fairly short because the unemployment rate fell sharply, from 8.0 percent in December 2012 to 6.2 percent in April 2014, while inflation remained below 2.0 percent. Return to text\n\n10. The December 2012 FOMC statement indicated that, \"If the outlook for the labor market does not improve substantially, the Committee will continue its purchases of Treasury and agency mortgage-backed securities, and employ its other policy tools as appropriate, until such improvement is achieved in a context of price stability. In determining the size, pace, and composition of its asset purchases, the Committee will, as always, take appropriate account of the likely efficacy and costs of such purchases.\" (Board of Governors of the Federal Reserve System (2012), \"Federal Reserve Issues FOMC Statement,\" press release, December 12, paragraph 4.) Return to text\n\n11. Ben S. Bernanke (2015), The Courage to Act: A Memoir of a Crisis and Its Aftermath (New York: W.W. Norton), p. 532. Return to text\n\n12. See Feroli and others, \"Language after Liftoff,\" in note 1, p. 29. Return to text\n\n13. Board of Governors of the Federal Reserve System (2015), \"Federal Reserve Issues FOMC Statement,\" press release, September 17, paragraph 2. Return to text\n\n14. Board of Governors of the Federal Reserve System (2015), \"Federal Reserve Issues FOMC Statement,\" press release, October 28, paragraph 3. Return to text\n\n15. Board of Governors of the Federal Reserve System (2016), \"Federal Reserve Issues FOMC Statement,\" press release, January 27, paragraph 4. Return to text\n\n16. For example, the January 2016 FOMC statement says, \"The Committee expects that economic conditions will evolve in a manner that will warrant only gradual increases in the federal funds rate; the federal funds rate is likely to remain, for some time, below levels that are expected to prevail in the longer run.\" (Board of Governors of the Federal Reserve System (2016), \"Federal Reserve Issues FOMC Statement,\" press release, January 27, paragraph 4.) Return to text\n\n17. Feroli and others, \"Language after Liftoff,\" in note 1, p. 11; and Ben S. Bernanke and Frederic S. Mishkin (1997), \"Inflation Targeting: A New Framework for Monetary Policy?\" Journal of Economic Perspectives, vol. 11 (Spring), pp. 97-116. Return to text\n\n18. In the SEP collected prior to the March and June FOMC meetings, participants submit projections for the current calendar year and two subsequent years; in the September SEP, the forecast horizon is extended out an additional calendar year. Thus, the forecast window does not remain constant for the different SEPs in a given year; Wrightson commentary has suggested that a rolling forecast horizon might be an improvement over the current calendar-year focus (Wrightson ICAP (2016), \"January 26-27 FOMC Minutes Recap,\" February 18). Return to text\n\n19. For instance, Michael Feroli (as quoted in a recent article) said, \"I think they have outlived their usefulness and they risk sending a signal that (Fed officials) have a ‘plan' rather than that they are data dependent\" (see Ann Saphir (2016), \"Fed's ‘Dot Plot' Looks Increasingly out of Touch on Rates,\" Markets, Reuters, February 14, paragraph 8, http://in.reuters.com/article/us-usa-fed-path-analysis-idINKCN0VN0PU); and in a 2012 speech, former Governor of the Bank of Canada Mark Carney stated, \"Overall research has not generally found that publishing a path leads to better outcomes.\" (Mark Carney (2012), \"Guidance,\" a speech delivered to the CFA Society Toronto, Toronto, Canada, December 11, paragraph 24, www.bankofcanada.ca/2012/12/guidance. Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "February 23, 2016",
        "title": "Recent Monetary Policy Developments",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20160223a.htm",
        "content": "February 23, 2016\n\nVice Chairman Stanley Fischer\n\nAt the \"Energy Transition: Strategies for a New World,\" 35th Annual IHS CERAWeek, Houston, Texas\n\nI would like to thank Daniel Yergin for his kind invitation to speak this evening at the CERAWeek conference. The energy industry--more precisely, the price of oil--is on the minds of almost everyone these days, and this conference is addressing many important issues. I am a macroeconomist, and do not plan on focusing tonight on developments in the energy sector. But from time to time the price of oil becomes a macroeconomic issue, and this is one of those times. So I have been listening intently to the many experts who have already spoken here today, and look forward to the discussion that will follow this speech, in the belief that I will emerge with a better understanding of recent and future developments in the industry.\n\nTo get things started, I thought I could provide some background on recent monetary policy decisions.1\n\nAs you all know, at our December meeting the Federal Open Market Committee (FOMC) decided to raise the target range for the federal funds rate by 1/4 percentage point, to 1/4 to 1/2 percent.2 At our meeting in January, we decided to maintain that range. The increase in December came after seven years during which the FOMC had kept the federal funds rate between 0 and 25 basis points. This ultra-low rate was in keeping with our congressional mandate to pursue a monetary policy that fosters maximum employment and price stability, which we define as 2 percent inflation.\n\nOur decision in December was based on the substantial improvement in the labor market and the Committee's confidence that inflation would return to our 2 percent goal over the medium term. Employment growth last year averaged a solid 230,000 per month, and the unemployment rate declined from 5.6 percent to 5.0 percent over the course of 2015--and declined further to 4.9 percent last month. This is close to the unemployment rate generally regarded as the full employment rate of unemployment.\n\nInflation ran well below our target last year, held down by the transitory effects of declines in crude oil prices and also in the prices of non-oil imports. Prices for these goods have fallen further and as you all know, for longer than expected. Once these oil and import prices stop falling and level out, their effects on inflation will dissipate, which is the main reason we expect that inflation will rise to 2 percent over the medium term, supported by a further strengthening in labor market conditions.\n\nOf course, with the federal funds target now at between 25 and 50 basis points, and the effective federal funds rate currently almost at the center of that target range, our monetary policy remains accommodative. And, at the time of our January decision, my colleagues and I anticipated that economic conditions would evolve in a manner warranting only gradual increases in the federal funds rate, and that the federal funds rate would likely remain, for some time, below the levels that we expect to prevail in the longer run. I should emphasize, however, that that was an expectation, not a decision, and our future policy actions are by no means predetermined.\n\nDuring the years in which we held the federal funds rate near zero, the Federal Reserve also engaged in large-scale asset purchases to further ease financial conditions and promote economic recovery. Consequently, the Federal Reserve's balance sheet grew from less than $1 trillion in mid-2008 to $4.5 trillion by late 2014. As a result of the size of our balance sheet, the FOMC is employing new tools to implement monetary policy. In particular, to raise the federal funds rate we increased the interest rate we pay on reserve balances that depository institutions hold at the Federal Reserve. We also employed an overnight reverse repurchase facility, through which we interact with a broad range of firms to help provide a soft floor for the federal funds rate consistent with our target range.3 These new tools have worked well, and the federal funds rate and other short-term interest rates have increased as expected. We will continue to monitor these markets closely, and we can make adjustments to our tools if necessary to maintain control over money market rates.\n\nThe economic data that have come in since our December interest rate decision suggest that the labor market has continued to improve. Although job gains slowed some last month, over the most recent three months payrolls have increased 230,000 jobs per month on average, as the unemployment rate declined. Moreover, the spending indicators that we have in hand for January point to a pickup in economic growth this quarter. Further, the 12-month change in average hourly earnings has moved up in recent months and stood at 2‑1/2 percent in January. In addition, the rate of core consumer price index inflation over the past 12 months exceeded 2 percent, though this was not true of the core price index of personal consumption expenditures that the Fed monitors closely. However--and there is frequently a \"however\" in our business--further declines in oil prices suggest that total inflation will likely remain low for somewhat longer than had been previously expected before moving back to 2 percent.\n\nIn addition, global financial markets have been unusually volatile since the turn of the year. For instance, the S&P 500 volatility index (VIX) rose markedly in early January, though it remains below the levels it reached in August of last year and in 2011, and it last week declined below its average value since the start of the year. The large movements in asset prices likely reflect increased concern about the global outlook, particularly ongoing developments in China and the effects of the declines in the prices of oil and other commodities on commodity-exporting nations. Asset price declines may also reflect a reassessment of the prospects for growth in Europe and Japan, and perhaps also a recognition that U.S. gross domestic product and productivity growth have remained stubbornly low.\n\nIf the recent financial market developments lead to a sustained tightening of financial conditions, they could signal a slowing in the global economy that could affect growth and inflation in the United States. But we have seen similar periods of volatility in recent years--including in the second half of 2011--that have left little visible imprint on the economy, and it is still early to judge the ramifications of the increased market volatility of the first seven weeks of 2016. As Chair Yellen said in her testimony to the Congress two weeks ago, while \"global financial developments could produce a slowing in the economy, I think we want to be careful not to jump to a premature conclusion about what is in store for the U.S. economy.\" Of course, the FOMC is closely monitoring global economic and financial developments and assessing their implications for the labor market and inflation and the balance of risks to the outlook.\n\nNow, with our next FOMC meeting just three weeks away, I expect most of you are less interested in what we did at our previous meetings, and more interested in what we are going to do at the next one. I can't answer that question because, as I have emphasized in the past, we simply do not know. The world is an uncertain place--sometimes more uncertain than at other times--and all monetary policymakers can really be sure of is that what will happen is often different from what we currently expect. That is why the Committee has indicated that its policy decisions will be data dependent, which is to say that we will adjust policy appropriately in light of economic and financial events to best foster conditions consistent with the attainment of our employment and inflation objectives.\n\nAs you know, in making our policy decisions, my FOMC colleagues and I spend considerable time assessing the incoming economic and financial information and its implications for the economic outlook. But we must also consider some other issues, two of which I would like to mention briefly today.\n\nFirst, most estimates of the full employment rate of unemployment are close to 5 percent. The actual rate of unemployment is now slightly below 5 percent, and the median view of the members of the FOMC is that it will decline further, perhaps even to the vicinity of 4.7 percent. The question is, should we be concerned about that possibility? In my view, a modest overshoot of this sort would be appropriate in current circumstances for two reasons. The first reason is that other measures of labor market conditions--such as the fraction of workers with part-time employment who would prefer to work full time and the number of people not actively looking for work who would like to work--indicate that more slack may remain in the labor market than the unemployment rate alone would suggest. And the second reason is that with inflation currently well below 2 percent, a modest overshoot could actually be helpful in moving inflation back to 2 percent more rapidly. Nonetheless, a persistent large overshoot of our employment mandate would risk an undesirable rise in inflation that might require a relatively abrupt policy tightening, which could inadvertently push the economy into recession. Monetary policy should aim to avoid such risks and keep the expansion on a sustainable track.\n\nThe second issue is how best to integrate balance sheet policy with interest rate policy. The FOMC has indicated that the Federal Reserve will, in the longer run, hold no more securities than necessary to implement monetary policy efficiently and effectively--which will require us to reduce the size of our balance sheet substantially. But that statement leaves open the question of when we should begin that process. Because the tools I mentioned earlier--the payment of interest on reserve balances and the overnight reverse repurchase facility--can be used to raise the federal funds rate independent of the size of the balance sheet, we have the flexibility to adjust the size of our balance sheet at the appropriate time. With the federal funds rate still quite low and expected to rise only gradually, there is some benefit to maintaining a larger balance sheet for a time. Doing so should help support accommodative financial conditions and so reduce the risks to the economy in the event of an adverse shock. Consistent with this view, the Committee has decided to continue to reinvest principal payments from its securities portfolio until normalization of the federal funds rate is well under way. The decision about when to cease or begin phasing out reinvestment will depend on how economic and financial conditions and the economic outlook evolve.4\n\nWith that background, I thank you for listening, and look forward to continuing the discussion, initially with Dan Yergin.\n\n1. I am grateful to William English, Trevor Reeve, and Stacey Tevlin for their assistance. My comments today reflect my own views and are not an official position of the Board of Governors or the Federal Open Market Committee. Return to text\n\n2. See Board of Governors of the Federal Reserve (2015), \"Federal Reserve Issues FOMC Statement,\" press release, December 16, www.federalreserve.gov/newsevents/press/monetary/20151216a.htm. Return to text\n\n3. The Committee's Policy Normalization Principles and Plans are available at www.federalreserve.gov/newsevents/press/monetary/20140917c.htm. Return to text\n\n4. See the Committee's Policy Normalization Principles and Plans (see note 3) as well as the discussion under the heading \"System Open Market Account Reinvestment Policy\" in the minutes of the September 2015 Committee meeting (www.federalreserve.gov/monetarypolicy/fomcminutes20150917.htm). Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "February 10, 2016",
        "title": "The Lender of Last Resort Function in the United States",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20160210a.htm",
        "content": "February 10, 2016\n\nVice Chairman Stanley Fischer\n\nAt \"The Lender of Last Resort: An International Perspective,\" a conference sponsored by the Committee on Capital Markets Regulation, Washington, D.C.\n\nI would like to thank Hal Scott for inviting me to address this conference.1\n\nThe financial system is built on trust, which, history shows, from time to time breaks down as a financial panic develops. Fortunately, major panics are relatively rare, but as we all know following the Great Financial Crisis, when they do occur they can be extremely destructive of economic activity.\n\nDuring the Great Financial Crisis, the Federal Reserve System worked together with the Treasury and other parts of the U.S. government to limit the damage caused by the crisis. Although the financial crisis inflicted massive damage on the economy and on the public, the damage would have been far greater had the Fed not deployed its lender of last resort powers to deal with the incipient breakdown of the functioning of the U.S. monetary and credit systems.\n\nChanges in Regulation and Supervision\nIn the wake of the crisis, acting within the framework of the Dodd-Frank Act, the Federal Reserve and the other supervisory agencies have taken a number of steps that reduce the likelihood that lender-of-last-resort loans will be needed. First and foremost, banks and bank holding companies are much better capitalized. Regulatory requirements have been made more stringent, global systemically important banks are subject to substantial additional capital requirements, and capital planning and supervisory stress testing make capital regulation more forward looking--and the importance of the stress tests bears emphasis.\n\nLargely as a result of these measures, the common equity capital ratios of the largest U.S. bank holding companies have more than doubled since the crisis. In addition, banking organizations are, for the first time, subject to a numerical liquidity requirement. The requirement ensures that large banking organizations maintain buffers of high-quality liquid assets sufficient to meet cash outflows during a 30-day episode of systemic and idiosyncratic liquidity stress. In addition, the Financial Stability Oversight Council has designated four key nonbanking institutions as \"systemically important financial institutions,\" and these firms are also subject to supervision and regulation by the Federal Reserve.\n\nThese changes in supervision and regulation, along with the enhancement of resolution mechanisms for financial institutions, have made the financial system more resilient and lessened the probability that a lender of last resort will be needed to deal with financial stresses in the future. Because the regulated firms are much better capitalized, doubts about their financial condition are less likely to arise, making them in turn less likely to lose access to funding in the marketplace. Moreover, their substantial stockpiles of liquid assets should allow them to weather temporary periods of illiquidity without assistance or, if necessary, provide time for the authorities to implement an orderly resolution.\n\nWhile we have likely reduced the probability that lender of last resort loans will be needed in the future, we have not reduced that probability to zero. We could, presumably, require financial institutions to fund illiquid assets entirely with longer-term debt and equity or, equivalently, allow them to use short-term liabilities to fund only safe and highly liquid assets. However, such an approach would be costly in terms of reduced lending to American businesses and households. Moreover, as yields on credit products rise and yields on cash-like instruments decline, lending would become increasingly profitable and would likely move outside the regulated sector, probably leading to a need to widen the regulatory perimeter of the financial system.\n\nLending to Insured Depository Institutions\nAlthough attention following the passage of Dodd-Frank Act has focused on the limitations it places on lender-of-last-resort lending, it must be noted that, if necessary and appropriate, the Federal Reserve has the authority to act as lender of last resort in several ways. Most importantly, the Fed retains the power to extend discount window loans to insured depository institutions--including commercial banks, thrift institutions, credit unions, or U.S. branches and agencies of foreign banks. Such loans can be to individual institutions facing funding pressures, or they can be to banks more generally to address broader financial stresses.2\n\nSince the Great Depression, the Fed's actions as lender of last resort were undertaken using its authority to provide discount window funding to insured depository institutions. Such was the case in the Federal Reserve's reaction to the Penn Central default of 1970, the stock market crash of 1987, the 9/11 terrorist attacks, and the initial stages of the recent financial crisis in August 2007. Discount window loans have to be collateralized to the satisfaction of the lending Reserve Bank, and it is noteworthy that all of the Federal Reserve System's lending during the Great Financial Crisis was collateralized and that all the loans have been repaid in full, on time, and with interest.\n\nAlthough the Dodd-Frank Act did not change the Fed's authority to lend to insured depository institutions, it has changed, among other things, the reporting requirements for such loans. The act requires the Fed to publish information on any discount window loan, including the identity of the borrowers, with a two-year lag. This change is consequential, because an important challenge for the Federal Reserve over the years has been the stigma associated with borrowing from the discount window.3 Discount window access cannot serve as an effective means to backstop insured depository institutions' liquidity if banks fear that borrowing from the discount window will signal to the public, their competitors, or their counterparties that the bank is in trouble. Prior to Dodd-Frank, the Federal Reserve only published information on discount window borrowing in aggregate, but stigma was nonetheless an issue. And I suspect that the stigma associated with the discount window is even higher, given the public's incorrect association of ordinary discount window borrowing with \"bailouts.\" While the two-year lag should help limit the increase in stigma associated with the increased reporting requirement, the fact that the Fed will no longer be able to assert unequivocally that discount window borrowing is strictly confidential will likely add to the challenge of reducing stigma.\n\nThat aside, the Fed's ability to act as lender of last resort to insured depository institutions was not significantly impeded by the Dodd-Frank Act.\n\nThe Shadow Banking System\nDuring a crisis, liquidity pressures can materialize in the shadow banking sector--that is, the set of nonbanks that use a range of markets and instruments to provide financing to borrowers. At the time of their initial difficulties, both Bear Stearns and Lehman Brothers were in the shadow banking system.\n\nTo help improve the resiliency of this sector, a few new regulations have been introduced, including the final rule on risk retention in securitization issued jointly by the Federal Reserve and five other agencies in October 2014 and the new money market fund rules issued by the Securities and Exchange Commission (SEC) in July 2014. Other provisions implemented since the crisis that should help address risks in the nonbank segment of the credit system include the central clearing requirement for standardized over-the-counter derivatives and margin requirements for uncleared swaps, as well as disclosure requirements that provide investors with standardized loan-level information for securitizations backed by certain assets, including residential and commercial mortgages.4 More recently, the SEC has also proposed rules to modernize data reporting by investment companies and advisers, as well as to enhance liquidity risk management and disclosure by open-end mutual funds, including exchange-traded funds.\n\nIn addition, the Federal Reserve can, if needed in an emergency, and with the approval of the Secretary of the Treasury, lend through a broad-based facility, including to nonbanks, to provide liquidity to financial markets. Indeed, during the financial crisis--which can be thought of as an old-fashioned bank run, but on the shadow banks--the Fed's credit facilities were used in an effort to stop the run in the shadow banking system. Such broad-based facilities were instrumental in ensuring that money market mutual funds were able to liquefy their assets and so meet investor withdrawals, that the markets for critical short-term funding remained open, and that funding remained available for securitizations that were, in turn, funding loans to students, car buyers, small businesses, and others. The facilities were many and varied, and developed as needed, because the U.S. financial system is complex and, as the crisis unfolded, the nature of the next phase was largely unforeseeable. In several of these interventions, the Fed was lending to increase the liquidity of, or activity in, securities markets, in order to maintain the flow of essential credit to businesses and to households.5 Had that flow of credit ceased, the financial crisis, the severe recession that resulted, and the consequences for the U.S. economy, and thus every American, would have been far more serious.\n\nIn November of last year, in a revision to its regulations reflecting the changes to the Federal Reserve's emergency lending authority included in the Dodd-Frank Act, the Board spelled out how the Federal Reserve would design and operate such broad-based emergency lending facilities in the future. Among other things, an emergency facility would be designed to provide liquidity to a market or sector of the financial system and not be for the purpose of assisting a specific firm, or group of firms, in avoiding bankruptcy. \"Broad based\" is defined to mean that there are at least five potential participants; further, even if many more than five firms were eligible for the facility, it could not be considered \"broad based\" if its purpose was to assist failing firms avoid bankruptcy or resolution, or to lend to insolvent borrowers. In addition, the interest rates on the loans would be at penalty rates above those on similar forms of credit in normal times, and the loans would be backed by collateral that was sufficient to protect the taxpayer from losses. All of these criteria are consistent with how the Federal Reserve operated its broad-based facilities in the crisis.\n\nLending to Individual Nonbank Institutions\nDuring the crisis, the Federal Reserve also lent to individual nonbank institutions whose default would have been extremely damaging for the financial system and the state of the economy.6 The Dodd-Frank Act removed the Federal Reserve's authority to lend to an individual troubled institution.7 Instead, the act required large banks and systemically important nonbanks to submit plans under which they could be resolved under bankruptcy in a rapid and orderly manner if they suffered material financial distress. In addition, it established expanded authority for the Federal Deposit Insurance Corporation (FDIC) to resolve a troubled systemic institution in an orderly manner that would not disrupt the rest of the financial system. This expanded power includes the authority to convert some existing creditor claims into equity in a new bridge institution. If liquidity problems arose at the new bridge institution, the FDIC could guarantee the institution's short-term liabilities, or it could act as a lender of last resort using funds provided by the Treasury and ultimately repaid by the institution and, if necessary, the banking industry through assessments.\n\nDeciding what authority should be given to a potential lender of last resort requires weighing the costs and benefits including, importantly, moral hazard. Moral hazard costs may be substantial, especially when the potential borrower got itself into trouble by taking on excessive risk, and especially if the loan is seen as expanding the safety net. But the costs of a disorderly default of a large interconnected firm may also be substantial, especially when the financial system is in a fragile state--as was the case in the default of Lehman Brothers.\n\nThe best way to deal with those types of situations is to prevent them from occurring. Such prevention requires appropriately tight supervision and regulation, consistent with the changes to supervision and regulation introduced in the past five years in the United States. Further, strengthening resolution procedures to the point where they can be used to resolve an insolvent institution without causing runs and exacerbating a potential crisis is an essential component of the reform strategy underlying the Dodd-Frank Act.8\n\nConcluding Comments\nOverall, the U.S. financial agencies collectively have substantial lender-of-last-resort authorities to meet future contingencies. The Federal Reserve maintains the ability to provide liquidity to markets during times of unusual financial stress, including the authority to lend to insured depository institutions. Indeed, for the 70 years between the Great Depression and the recent financial crisis, the Fed executed its lender-of-last-resort responsibility exclusively through such loans. Moreover, broad-based facilities of the sort that the Fed operated during the financial crisis generally could still be introduced under our new regulations if they were needed to limit the effect of a future crisis on financial markets and the economy.\n\nAnd while the Federal Reserve no longer can lend to individually troubled nonbanks, the FDIC's expanded resolution authorities should allow it to address troubles at such institutions with sufficiently low risk of cascading disruptions to the rest of the financial system and thus the economy. Handling such situations through resolution has the advantage of ensuring that any costs are primarily incurred by the existing owners and creditors of the troubled firm, but such an approach is currently untried. It is important that the government have the ability to execute the resolution seamlessly and with little or no warning--for example, Bear Stearns informed the Fed on a Thursday that it would default on Friday.9\n\nThere are nonetheless three major sources of concern about potential weaknesses in the new framework for financial crisis management that has been introduced since the Great Financial Crisis. The first is its failure to resolve the problem of stigma--that is, the stigma of borrowing from the central bank at a time when the financial markets are on guard, looking for signs of weakness in individual financial institutions at a time of overall financial stress.10 Indeed, some of the Dodd-Frank Act reporting requirements may worsen the stigma problem.11\n\nThe second is a concern that arises from the nature of financial and other crises. It is essential that we build strong frameworks to deal with potential crisis situations, and Dodd-Frank has done that. But these plans need to ensure that the authorities retain the capacity to deal with unanticipated events, for unanticipated events are inevitable. Retaining the needed flexibility may conflict with the desire to reduce moral hazard to a minimum. But, in simple language: Strengthening fire prevention regulations does not imply that the fire brigade should be disbanded.12\n\nThird, this concern is heightened by a related problem: The new system has not undergone its own stress test. That is, in one sense, fortunate, for the financial system will undergo its fundamental stress test only when we have to deal with the next potential financial crisis. That day will likely come later than it would have without Dodd-Frank and the excellent work done by regulators in the United States and around the world in strengthening financial institutions and the financial system. But it will come, and when it comes, we will need the flexibility required to deal with it.\n\n1. My comments today reflect my own views and are not an official position of the Board of Governors or the Federal Open Market Committee.\n\nI am grateful to William Nelson, Scott Alvarez, Rochelle Edge, William English, Michael Gibson, and Mark van der Weide of the Federal Reserve Board for their assistance. Return to text\n\n2. The Federal Deposit Insurance Corporation Improvement Act of 1991 (FDICIA) imposes costs and a reporting requirement on the Federal Reserve Board in some cases if Federal Reserve lending to a weak depository institution that ultimately fails raises the Federal Deposit Insurance Corporation's costs of resolving the institution. Return to text\n\n3. The President's Working Group on Financial Markets and the Financial Stability Forum (since renamed the Financial Stability Board) identified the stigma associated with borrowing from the Federal Reserve's discount window as a significant threat to financial stability. See the President's Working Group on Financial Markets (2008), \"Policy Statement on Financial Market Developments\" (Washington: President's Working Group, March), p. 9; FSF Working Group on Market and Institutional Resilience (2008), Interim Report to the G-7 Finance Ministers and Central Bank Governors (Basel: Financial Stability Forum, April), p. 8; and FSF Working Group on Market and Institutional Resilience (2008), Report of the Financial Stability Forum on Enhancing Market and Institutional Resilience (Basel: FSF, October), p. 47. Return to text\n\n4. The SEC's rule on disclosure requirements for certain securitizations was adopted by the SEC in August 2014. The intent of these rules is to make it easier for investors to review and access the information they need to make informed investment decisions, including independently conducting due diligence so as to better assess the credit risk of asset-backed securities. Return to text\n\n5. For example, on October 7, 2008, the Federal Reserve established the Commercial Paper Funding Facility (CPFF). Under the CPFF, the Federal Reserve lent to a special purpose vehicle that in turn purchased top-rated three-month commercial paper directly from eligible issuers. And on November 25, 2008, the Federal Reserve and Treasury announced the creation of the Term Asset-Backed Securities Loan Facility (TALF). Under the TALF, the Federal Reserve extended loans to investors in certain triple-A-rated asset-backed securities (ABS) to promote renewed issuance of ABS, thereby increasing the availability of credit to households and small businesses. See Dietrich Domanski, Richhild Moessner, and William Nelson (2014), \"Central Banks as Lenders of Last Resort: Experiences during the 2007-2010 Crisis and Lessons for the Future (PDF),\" Finance and Economics Discussion Series 2014-110 (Washington: Board of Governors of the Federal Reserve System, May). Return to text\n\n6. The Federal Reserve used its authority to lend to individual nonbank institutions two times during the crisis: It lent to Bear Stearns and AIG (American International Group, Inc.). Working with the Treasury and the FDIC, it agreed to lend, but did not in fact extend credit, as part of ring-fence arrangements established for two additional firms, Bank of America and Citigroup. See Domanski, Moessner, and Nelson, \"Central Banks as Lenders of Last Resort,\" in note 5. Return to text\n\n7. The Federal Reserve's authority to lend to depository institutions cannot be used as a backchannel for lending to nonbank subsidiaries of bank holding companies. Return to text\n\n8. C.A.E. Goodhart (1999), \"Myths about Lender of Last Resort,\" International Finance, vol. 2 (November), pp. 339-60. See also a forthcoming paper by Goodhart titled \"Balancing Lender-of-Last-Resort Assistance with Avoidance of Moral Hazard.\" Return to text\n\n9. See Board of Governors of the Federal Reserve System (2008), \"Report Pursuant to Section 129 of the Emergency Economic Stabilization Act of 2008: Loan to Facilitate the Acquisition of the Bear Stearns Companies, Inc. by JPMorgan Chase & Co. (PDF)\" (Washington: Board of Governors). Return to text\n\n10. This concern is emphasized in Ben Bernanke's blog post, \"Fed Emergency Lending,\" Brookings Institution, December 3, 2015. Return to text\n\n11. In particular, as I suggested earlier, the additional reporting requirements under the Dodd-Frank Act could increase potential borrowers' concerns that the public, their creditors, or their counterparties could learn about their borrowing and conclude that the bank is in trouble. Return to text\n\n12. I think it would be a serious mistake, as some have suggested, to go beyond the limitations on the Federal Reserve's emergency lending authority that are set out in the Dodd-Frank Act. Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "February 01, 2016",
        "title": "Recent Monetary Policy",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20160201a.htm",
        "content": "February 01, 2016\n\nVice Chairman Stanley Fischer\n\nAt the C. Peter McColough Series on International Economics, Council on Foreign Relations, New York, New York\n\nI would like to thank the Council on Foreign Relations for the kind invitation to come meet with all of you this morning. I am looking forward to a lively discussion. To get things started, I thought I could provide some background on recent monetary policy decisions.1\n\nAs you all know, at our December meeting my colleagues and I on the Federal Open Market Committee (FOMC) decided to raise the target range for the federal funds rate by 1/4 percentage point, to 1/4 to 1/2 percent.2 This increase came after seven years during which we kept the federal funds rate at what we call the ELB--the effective lower bound. This ultra-low rate was in keeping with our congressional mandate to pursue a monetary policy that fosters maximum employment and price stability, which we define as 2 percent inflation. Our decision in December was based on the substantial improvement in the labor market and the Committee's confidence that inflation would return to our 2 percent goal over the medium term. Employment growth last year averaged a solid 220,000 per month, and the unemployment rate declined from 5.6 percent to 5.0 percent over the course of 2015. Inflation ran well below our target last year, held down by the transitory effects of declines in crude oil prices and also in the prices of non-oil imports. Prices for these goods have fallen further and for longer than expected. Once these oil and import prices stop falling and level out, their effects on inflation will dissipate, which is why we expect that inflation will rise to 2 percent over the medium term, supported by a further strengthening in labor market conditions.\n\nI would note that our monetary policy remains accommodative after the small increase in the federal funds rate adopted in December. And my colleagues and I anticipate that economic conditions will evolve in a manner that will warrant only gradual increases in the federal funds rate, and that the federal funds rate is likely to remain, for some time, below the levels that we expect to prevail in the longer run.\n\nGiven the large size of the Federal Reserve's balance sheet, the FOMC is employing new tools to implement monetary policy. In particular, to raise the federal funds rate we increased the interest rate we pay on reserve balances that depository institutions hold at the Federal Reserve. We also employed an overnight reverse repurchase facility, through which we interact with a broad range of firms to help provide a soft floor for the federal funds rate consistent with our target range.3 These new tools have worked well, and the federal funds rate and other short-term interest rates have increased slightly, as expected. We will continue to monitor financial market developments closely, and we can make adjustments to our tools if necessary to maintain control over money market rates.\n\nAt our meeting last week, we left our target for the federal funds rate unchanged. Economic data over the intermeeting period suggested that improvement in labor market conditions continued even as economic growth slowed late last year. But further declines in oil prices and increases in the foreign exchange value of the dollar suggested that inflation would likely remain low for somewhat longer than had been previously expected before moving back to 2 percent. In addition, increased concern about the global outlook, particularly the ongoing structural adjustments in China and the effects of the declines in the prices of oil and other commodities on commodity exporting nations, appeared early this year to have triggered volatility in global asset markets. At this point, it is difficult to judge the likely implications of this volatility. If these developments lead to a persistent tightening of financial conditions, they could signal a slowing in the global economy that could affect growth and inflation in the United States. But we have seen similar periods of volatility in recent years that have left little permanent imprint on the economy. As the FOMC said in its statement last week, we are closely monitoring global economic and financial developments and assessing their implications for the labor market and inflation, and for the balance of risks to the outlook.4\n\nNow, I expect that in a few minutes one of you will ask not about what we did at our last meeting, but rather what we are going to do at the next one. I can't answer that question because, as I have emphasized in the past, we simply do not know. The world is an uncertain place, and all monetary policymakers can really be sure of is that what will happen is often different from what we currently expect. That is why the Committee has indicated that its policy decisions will be data dependent. That is, we will adjust policy appropriately in light of economic and financial events to best foster conditions consistent with the attainment of our employment and inflation objectives.\n\nAs you know, in making our policy decisions, my FOMC colleagues and I spend considerable time assessing the incoming economic and financial information and its implications for the economic outlook. But we also must consider some other issues, two of which I would like to mention briefly today.\n\nFirst, should we be concerned about the possibility of the unemployment rate falling somewhat below its longer-run normal level, as the most recent FOMC projections suggest? In my view, a modest overshoot of this sort would be appropriate in current circumstances for two reasons. First, other measures of labor market conditions--such as the fraction of workers with part-time employment who would prefer to work full time and the number of people out of the labor force who would like to work--indicate that more slack may remain in labor market than the unemployment rate alone would suggest. Second, with inflation currently well below 2 percent, a modest overshoot actually could be helpful in moving inflation back to 2 percent more rapidly. Nonetheless, a persistent large overshoot of our employment mandate would risk an undesirable rise in inflation that might require a relatively abrupt policy tightening, which could inadvertently push the economy into recession. Monetary policy should aim to avoid such risks and keep the expansion on a sustainable track.\n\nIn this context, I would point out that at our January meeting, we reaffirmed our Statement on Longer-Run Goals and Monetary Policy Strategy with an adjustment to clarify that our inflation goal is symmetric.5 That is, the Committee would be concerned if inflation were running persistently above or below our objective. In my view, even if inflation was expected to return to 2 percent over time, persistent deviations from our goal in either direction could cause economic harm and could ultimately unmoor longer-term inflation expectations. Of course, whether the Committee would take action to address a persistent deviation from its inflation objective would depend on the circumstances--and, in particular, on the outlook for employment and inflation and an assessment of the likely lags in the effects of monetary policy.\n\nMy second topic is how best to integrate balance sheet policy with interest rate policy. The Committee has indicated that the Federal Reserve will, in the longer run, hold no more securities than necessary to implement monetary policy efficiently and effectively. But that statement leaves open the question of when we should begin to reduce the size of our balance sheet. Because the tools I mentioned earlier--the payment of interest on reserve balances and the overnight reverse repurchase facility--can be used to raise the federal funds rate independent of the size of the balance sheet, we have the flexibility to adjust the size of our balance sheet at the appropriate time. With the federal funds rate still quite low and expected to rise only gradually, I think there is some benefit to maintaining a larger balance sheet for a time. Doing so should help support accommodative financial conditions and so reduce the downside risks to the economic outlook in the event of a future adverse shock to the economy. Consistent with this view, the Committee has decided to continue to reinvest principal payments from its securities portfolio until normalization of the federal funds rate is well under way. The decision about when to cease or begin phasing out reinvestment will depend on how economic and financial conditions and the economic outlook evolve.6\n\nThank you. I would be happy to respond to some questions, starting with those from our moderator today, Tom Keene.\n\n1. I am grateful to William English for his assistance. My comments today reflect my own views and are not an official position of the Board of Governors or the Federal Open Market Committee. Return to text\n\n2. See Board of Governors of the Federal Reserve (2015), \"Federal Reserve Issues FOMC Statement,\" press release, December 16, www.federalreserve.gov/newsevents/press/monetary/20151216a.htm. Return to text\n\n3. The Committee's Policy Normalization Principles and Plans are available at www.federalreserve.gov/newsevents/press/monetary/20140917c.htm. Return to text\n\n4. See Board of Governors of the Federal Reserve (2016), \"Federal Reserve Issues FOMC Statement,\" press release, January 27, www.federalreserve.gov/newsevents/press/monetary/20160127a.htm. Return to text\n\n5. The FOMC's Statement on Longer-Run Goals and Monetary Policy Strategy, amended effective January 26, 2016, is available on the Board's website at www.federalreserve.gov/monetarypolicy/files/FOMC_LongerRunGoals_20160126.pdf. Return to text\n\n6. See the Committee's Policy Normalization Principles and Plans (see note 1) as well as the discussion under the heading \"System Open Market Account Reinvestment Policy\" in the minutes of the September 2015 Committee meeting (www.federalreserve.gov/monetarypolicy/fomcminutes20150917.htm). Return to text"
    },
    {
        "speaker": "Stanley Fischer",
        "position": "Vice Chairman",
        "date": "January 03, 2016",
        "title": "Monetary Policy, Financial Stability, and the Zero Lower Bound",
        "href": "https://www.federalreserve.gov/newsevents/speech/fischer20160103a.htm",
        "content": "January 03, 2016\n\nVice Chairman Stanley Fischer\n\nAt the Annual Meeting of the American Economic Association, San Francisco, California\n\nVice Chairman Fischer presented identical remarks to the Banque de France and Bank for International Settlements Farewell Symposium for Christian Noyer on January 12, 2016.\n\nThank you. It is a great pleasure to be here today and to participate in this panel together with such a distinguished group.\n\nMuch has happened in the world of central banking in the past 10 years. The list of challenges we face is long and includes fundamental issues such as lender-of-last-resort policies in the modern financial system, the role of central banks in the supervision of the financial sector, and the appropriate role of forward guidance in monetary policy communications. Those are the topics I will not discuss today.\n\nRather, I will focus primarily on three related issues associated with the zero lower bound (ZLB) on nominal interest rates and the nexus between monetary policy and financial stability: first, whether we are moving toward a permanently lower long-run equilibrium real interest rate; second, what steps can be taken to mitigate the constraints imposed by the ZLB on the short-term interest rate; and, third, whether and how central banks should incorporate financial stability considerations in the conduct of monetary policy.1\n\nAre We Moving Toward a World With a Permanently Lower Long-Run Equilibrium Real Interest Rate?\nWe start with a key question of the day: Are we moving toward a world with a permanently lower long-run equilibrium real interest rate? The equilibrium real interest rate--more conveniently known as r*--is the level of the short-term real rate that is consistent with full utilization of resources. It is often measured as the hypothetical real rate that would prevail in the long-run once all of the shocks affecting the economy die down.2 In terms of the Federal Reserve's approach to monetary policy, it is the real interest rate at which the economy would settle at full employment and with inflation at 2 percent--provided the economy is not at the ZLB.\n\nRecent interest in estimates of r* has been strengthened by the secular stagnation hypothesis, forcefully put forward by Larry Summers in a number of papers, in which the value of r* plays a central role.3 Research that was motivated in part by attempts that began some time ago to specify the constant term in standard versions of the Taylor rule has shown a declining trend in estimates of r*. That finding has become more firmly established since the start of the Great Recession and the global financial crisis.4\n\nA variety of models and statistical approaches suggest that the current level of short-run r* may be close to zero. Moreover, the level of short-run r* seems likely to rise only gradually to a longer-run level that is still quite low by historical standards. For example, the median long-run real federal funds rate reported in the Federal Reserve's Summary of Economic Projections prepared in connection with the December 2015 meeting of the Federal Open Market Committee has been revised down about 1/2 percentage point over the past three years to a level of 1-1/2 percent.5 As shown in the figure, a decline in the value of r* seems consistent with the decline in the level of longer-term real rates observed in the United States and other countries.\n\nWhat determines r*? Fundamentally, the balance of saving and investment demands does so. A very clear systematic exposition of the theory of r* is presented in a 2015 paper from the Council of Economic Advisers. Several trends have been cited as possible factors contributing to a decline in the long-run equilibrium real rate. One a priori likely factor is persistent weakness in aggregate demand. Among the many reasons for that, as Larry Summers has noted, is that the amount of physical capital that the revolutionary IT firms with high stock market valuations have needed is remarkably small. The slowdown of productivity growth, which has been a prominent and deeply concerning feature of the past four years, is another factor reducing r*.6 Others have pointed to demographic trends resulting in there being a larger share of the population in age cohorts with high saving rates.7 Some have also pointed to high saving rates in many emerging market countries, coupled with a lack of suitable domestic investment opportunities in those countries, as putting downward pressure on rates in advanced economies--the global savings glut hypothesis advanced by Ben Bernanke and others at the Fed about a decade ago.8\n\nWhatever the cause, other things being equal, a lower level of the long-run equilibrium real rate suggests that the frequency and duration of future episodes in which monetary policy is constrained by the ZLB will be higher than in the past. Prior to the crisis, some research suggested that such episodes were likely to be relatively infrequent and generally short lived.9 The past several years certainly require us to reconsider that basic assumption.\n\nMoreover, the experience of the past several years in the United States and many other countries has taught us that conducting monetary policy effectively at the ZLB is challenging, to say the least.10 And while unconventional policy tools such as forward guidance and asset purchases have been extremely helpful, there are many uncertainties associated with the use of such tools.11\n\nI would note in passing that one possible concern about our unconventional policies has eased recently, as the Federal Reserve's normalization tools proved effective in raising the federal funds rate following our December meeting. Of course, issues may yet arise during normalization that could call for adjustments to our tools, and we stand ready to do that.\n\nThe answer to the question \"Will r* remain at today's low levels permanently?\" is that we do not know. Many of the factors that determine r*, particularly productivity growth, are extremely difficult to forecast. At present, it looks likely that r* will remain low for the policy-relevant future, but there have in the past been both long swings and short-term changes in what can be thought of as equilibrium real rates Eventually, history will give the answer.\n\nBut it is critical to emphasize that history's answer will depend also on future policies, monetary and other, notably including fiscal policy.\n\nWhat Steps Can Be Taken to Mitigate the Constraints Associated with the ZLB?\nAgainst that backdrop, a second key question for central banks is, What steps, if any, can be taken to mitigate the constraints associated with the ZLB?\n\nNone of these options for dealing with the difficulties of the ZLB suggest that it will be easy either to raise the equilibrium real rate or to mitigate the constraints associated with the ZLB. But when the real rate is close to zero, even small effects can make a noticeable difference. And, of course, such issues are clearly worthy of additional research.\n\nHow Should Central Banks Incorporate Financial Stability Considerations in the Conduct of Monetary Policy?\nThe challenges associated with the ZLB and the potential risks resulting from an environment of extremely low rates for a prolonged period of time bring me to the third question: How should central banks incorporate financial stability considerations in the conduct of monetary policy? Or, put another way, can we conduct monetary policy in a way that reduces the likelihood of financial instability?15\n\nThe first response of policymakers to the question of whether monetary policy--defined as the short-term policy interest rate--should be used to support financial stability is to say that macroprudential tools, rather than adjustments in short-term interest rates, should be the first line of defense.\n\nMacroprudential tools are primarily regulatory or supervisory in nature and target specific activities, markets, and financial institutions. In the United States, we now have some experience with such tools. The interagency guidance on leveraged lending issued in 2013 and the annual coordinated stress tests (the Dodd-Frank Act stress test, or DFAST, mandated by the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010; and the Comprehensive Capital Analysis and Review, or CCAR), focused on the capital adequacy of the largest banking firms, are two examples implemented for a few years now and for which data are available for an assessment of their effectiveness.16\n\nAn important new element of the post-crisis capital regime is the Countercyclical Capital Buffer (CCyB), which the Federal Reserve put out for comment on December 21, 2015.17 The CCyB is designed to be activated when there is an elevated risk of above-normal losses in the future and released when the risk of above-normal losses recedes. The higher levels of capital would increase the resilience of the largest banks because they would be better positioned to absorb the losses.\n\nDespite the tools that the Fed can use to support financial stability, including the Fed's authority to impose margin requirements on secured financing transactions, the Fed has fewer macroprudential tools at its command than some other central banks, particularly with respect to real estate. Regulators in many countries facing or anticipating problems with rising real estate prices often turn to controls over loan-to-value or debt-to-income ratios. Such measures are potentially important, as the real estate sector is the most common source of the beginnings of financial instability. In the United States, responding to such problems with these tools would require interagency coordination, which could make their use cumbersome at critical moments.\n\nIt is important to acknowledge that there remain cases in which macroprudential tools are either not available or have not been sufficiently tested in the United States, or they may be in conflict with other objectives such as widespread access to credit. The effective lack of such tools has two important consequences. First, it requires placing greater weight on the ability of financial institutions and the financial system as a whole to withstand financial shocks without the authorities having to use macroprudential instruments--that is to say, on structural reforms to the financial system. Second, in such instances, one could consider using monetary policy--the short term policy interest rate--to lean against the wind of financial stability risks.18\n\nThe use of monetary policy to address financial stability concerns raises two distinct but closely related sets of questions. The first is whether adjustments in the policy rate can indeed enhance financial stability by reducing either the odds of a financial crisis or the severity of such a crisis once it is under way--and, if so, through which channels.19\n\nProvided that the first question is answered in the affirmative, the second question is how leaning against the wind interacts with the traditional objectives of monetary policy--namely, the employment and inflation mandates in the United States. This tradeoff could be small or even nonexistent when both traditional macro objectives and financial stability objectives call for the same policy action--for example, when the credit cycle is approaching its peak, output is above potential, and inflation pressures appear to be building. In contrast, when different objectives call for different policy actions--for example, when some financial assets appear overvalued but economic growth remains tepid and inflation is subdued--policymakers may find this tradeoff much more difficult to assess and will search for macroprudential tools. Perhaps unsurprisingly, recent contributions in the literature that quantify this tradeoff point to a range of recommendations, with some reporting an optimal monetary policy that leans against the wind and some suggesting otherwise.20\n\nI would like to conclude on this issue by saying that the issue is a bit more complicated than suggested so far--for, given that financial variables are a critical part of the transmission mechanism of monetary policy, when policymakers say the economy is overheating, they may well be considering the behavior of asset prices as a critical part of that phenomenon and part of the reason to tighten monetary policy. Thus, I believe that the real issue of whether adjustments in interest rates should be used to deal with problems of potential financial instability is macroeconomic, and that if asset prices across the economy--that is, taking all financial markets into account--are thought to be excessively high, raising the interest rate may be the appropriate step. Further discussion of this issue will probably bear considerable similarity to the analysis of how to deal with asset bubbles that took place in the United States in the decade starting about two decades ago.\n\nConclusion\nIn closing, let me concede that it is easier to pose these questions than it is to answer them definitively. The issues are both deep and interesting. Along with other monetary policy issues, particularly the role of the lender of last resort in a world of significant uncertainty, they deserve the attention the profession in both academic and governmental institutions is, will be, and should be giving them.\n\nReferences\nAdrian, Tobias, Daniel Covitz, and Nellie Liang (2014). \"Financial Stability Monitoring,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, August 4.\n\nAgarwal, Ruchir, and Miles Kimball (2015). \"Breaking through the Zero Lower Bound (PDF) ,\" IMF Working Paper WP/15/224. Washington: International Monetary Fund, October.\n\nAjello, Andrea, Thomas Laubach, David Lopez-Salido, and Taisuke Nakata (2015). \"Financial Stability and Optimal Interest-Rate Policy (PDF),\" working paper. Washington: Board of Governors of the Federal Reserve System, February.\n\nAlderman, Liz (2015). \"In Sweden, a Cash-Free Future Nears,\" New York Times, December 26, www.nytimes.com/2015/12/27/business/international/in-sweden-a-cash-free-future-nears.html.\n\nBernanke, Ben S. (2005). \"The Global Saving Glut and the U.S. Current Account Deficit,\" speech delivered at the Homer Jones Lecture, St. Louis, April 14.\n\nBlanchard, Olivier, and John Simon (2001). \"The Long and Large Decline in U.S. Output Volatility (PDF) ,\" Brookings Papers on Economic Activity, 1, pp. 135-74.\n\nBoard of Governors of the Federal Reserve System (2015). \"Federal Reserve Board Seeks Public Comment on Proposed Policy Statement Detailing the Framework the Board Would Follow in Setting the Countercyclical Capital Buffer (CCyB),\" press release, December 21.\n\nBuiter, Willem H., and Nikolaos Panigirtzoglou (2003). \"Overcoming the Zero Bound on Nominal Interest Rates with Negative Interest on Currency: Gesell's Solution,\" Economic Journal, vol. 113 (October), pp. 723-46.\n\nCaballero, Ricardo J., Emmanuel Farhi, and Pierre-Olivier Gourinchas (2008). \"An Equilibrium Model of 'Global Imbalances' and Low Interest Rates,\" American Economic Review, vol. 98 (1), pp. 358-93.\n\nCarlson, Mark, Burcu Duygan-Bump, Fabio Natalucci, William R. Nelson, Marcelo Ochoa, Jeremy Stein, and Skander Van den Heuvel (forthcoming). \"The Demand for Short-Term, Safe Assets and Financial Stability: Some Evidence and Implications for Central Bank Policies,\" International Journal of Central Banking.\n\nChamp, Bruce (2008). \"Stamp Scrip: Money People Paid to Use ,\" Economic Commentary. Cleveland: Federal Reserve Bank of Cleveland, April.\n\nFisher, Irving (1933). Stamp Scrip. New York: Adelphi Company.\n\nGoodfriend, Marvin (2000). \"Overcoming the Zero Bound on Interest Rate Policy,\" Journal of Money, Credit and Banking, vol. 32 (November), pp. 1007-35.\n\nGordon, Robert J. (2014). \"The Demise of U.S. Economic Growth: Restatement, Rebuttal, and Reflections,\" NBER Working Paper Series 19895. Cambridge, Mass.: National Bureau of Economic Research, February.\n\n-------- (forthcoming). The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War. Princeton, N.J.: Princeton University Press.\n\nHall, Robert E. (2014). \"Quantifying the Lasting Harm to the U.S. Economy from the Financial Crisis,\" in Jonathan Parker and Michael Woodford, eds., NBER Macroeconomics Annual 2014, vol. 29. Chicago: University of Chicago Press.\n\nHamilton, James D., Ethan S. Harris, Jan Hatzius, and Kenneth D. West (2015). \"The Equilibrium Real Funds Rate: Past, Present and Future,\" NBER Working Paper Series 21476. Cambridge, Mass.: National Bureau of Economic Research, August.\n\nHicks, J.R. (1937). \"Mr. Keynes and the 'Classics': A Suggested Interpretation,\" Econometrica, vol. 5 (April), pp. 147-59.\n\nInternational Monetary Fund (2015). Monetary Policy and Financial Stability (PDF) , IMF staff report. Washington: International Monetary Fund, September.\n\nKeynes, John Maynard (1936). The General Theory of Employment, Interest, and Money. London: Macmillan.\n\nKiley, Michael T. (2015). \"What Can the Data Tell Us about the Equilibrium Real Interest Rate? (PDF)\" Finance and Economics Discussion Series 2015-077. Washington: Board of Governors of the Federal Reserve System, August.\n\nLaubach, Thomas, and John C. Williams (2003). \"Measuring the Natural Rate of Interest ,\" Review of Economics and Statistics, vol. 85 (November), pp. 1063-70.\n\nMcAndrews, James (2015). \"Negative Nominal Central Bank Policy Rates: Where Is the Lower Bound? \" speech delivered at the University of Wisconsin, Madison, Wis., May 8.\n\nMendoza, Enrique G., Vincenzo Quadrini, and José-Víctor Ríos-Rull (2009). \"Financial Integration, Financial Development, and Global Imbalances,\" Journal of Political Economy, vol. 117 (3), pp. 371-416.\n\nReifschneider, David, and John C. Williams (2000). \"Three Lessons for Monetary Policy in a Low-Inflation Era,\" Journal of Money, Credit, and Banking, vol. 32 (November), pp. 936-66.\n\nReinhart, Carmen M., and Kenneth S. Rogoff (2009). This Time Is Different: Eight Centuries of Financial Folly. Princeton, N.J.: Princeton University Press.\n\nRogoff, Kenneth (2014). \"Costs and Benefits to Phasing out Paper Currency (PDF) ,\" paper presented at the NBER Macroeconomics Annual Conference, Cambridge, Mass., April 11.\n\nStein, Jeremy C. (2013). \"Overheating in Credit Markets: Origins, Measurement, and Policy Responses,\" speech delivered at \"Restoring Household Financial Stability after the Great Recession: Why Household Balance Sheets Matter,\" a research symposium sponsored by the Federal Reserve Bank of St. Louis.\n\nStock, James H., and Mark W. Watson (2003). \"Has the Business Cycle Changed and Why?\" NBER Macroeconomics Annual 2002, vol. 17 (January).\n\nSummers, Lawrence H. (2014). \"U.S. Economic Prospects: Secular Stagnation, Hysteresis, and the Zero Lower Bound,\" Business Economics, vol. 49 (2), pp. 65-73.\n\n-------- (2015). \"Low Real Rates, Secular Stagnation & the Future of Stabilization Policy,\" remarks delivered at the Bank of Chile Research Conference, November 20, http://larrysummers.com/2015/11/20/low-real-rates-secular-stagnation-the-future-of-stabilization-policy.\n\nSvensson, Lars E.O. (2015). \"Cost-Benefit Analysis of Leaning Against the Wind: Are Costs Always Larger than Benefits, and Even More So with a Less Effective Macroprudential Policy? (PDF) \" unpublished paper, September.\n\nU.S. Executive Office of the President, Council of Economic Advisers (2015). Long-Term Interest Rates: A Survey (PDF). Washington: EOP.\n\nWilliams, John C. (2013). \"A Defense of Moderation in Monetary Policy (PDF) ,\" Working Paper Series 2013-15. San Francisco: Federal Reserve Bank of San Francisco, July.\n\nWoodford, Michael (2012). \"Inflation Targeting and Financial Stability,\" NBER Working Paper Series 17967. Cambridge, Mass.: National Bureau of Economic Research, April.\n\n1. I am grateful to James Clouse, William English, Thomas Laubach, Nellie Liang, David Lopez-Salido, Jeff Marquardt, David Mills, Fabio Natalucci, David Reifschneider, Stacey Tevlin, David Wilcox, and Paul Wood for their assistance. I have benefited also from discussions with John Williams. My comments today reflect my own views and are not an official position of the Board of Governors or the Federal Open Market Committee. Return to text\n\n2. See Laubach and Williams (2003). Return to text\n\n3. See Summers (2014, 2015). Return to text\n\n4. This research includes recent work by Kiley (2015) and others that uses extensions of the original Laubach and Williams (2003) framework. An international perspective on medium-to-long-run real interest rates is provided by U.S. Executive Office of the President (2015). Reinhart and Rogoff (2009) and Hall (2014) discuss the long-lived effects of financial crises on economic performance. See also Hamilton and others (2015). Return to text\n\n5. The projections materials associated with the Federal Open Market Committee's December 2015 meeting are available on the Board's website at www.federalreserve.gov/monetarypolicy/fomccalendars.htm. Return to text\n\n6. It is also a major factor explaining the phenomenon of the economy's impressive performance on the jobs front during a period of historically slow growth. Return to text\n\n7. See, for instance, Gordon (2014, forthcoming). Return to text\n\n8. See Bernanke (2005). See also the recent work by Caballero, Farhi, and Gourinchas (2008) and Mendoza, Quadrini, and Rios-Rull (2009). Return to text\n\n9. See, for instance, Reifschneider and Williams (2000), Blanchard and Simon (2001), and Stock and Watson (2003). Return to text\n\n10. For a discussion of various issues reviewed by the Federal Open Market Committee in late 2008 and 2009 regarding the complications of unconventional monetary policy at the ZLB, see the set of staff memos on the Board's website at www.federalreserve.gov/foia/fomc/readingrooms.htm. Return to text\n\n11. See Williams (2013). Return to text\n\n12. The Europeans have long been intrigued by the possibility of negative rates, beginning with Gesell's stamp scrip proposal in 1906 and some apparently successful experiments with stamp scrip in Austria in the 1930s. See Keynes (1936), Fisher (1933), and Hicks (1937). For an extensive discussion of Gesell's work, see Keynes (1936), chap. 23, pp. 353-58. Return to text\n\n13. See Alderman (2015). Return to text\n\n14. As an alternative to eliminating currency, a number of authors--including Goodfriend (2000), Buiter (2003), Agarwal and Kimball (2015), McAndrews (2015), and Rogoff (2014)--have discussed various mechanisms that could effectively implement a Gesell tax on physical currency. Return to text\n\n15. See International Monetary Fund (2015) for a broad discussion of many issues in this area. Return to text\n\n16. More information about DFAST and CCAR is available on the Board's website at www.federalreserve.gov/bankinforeg/stress-tests-capital-planning.htm. Return to text\n\n17. See Board of Governors (2015). Return to text\n\n18. See, for instance, Stein (2013) and Carlson and others (forthcoming) for a discussion on the possible use of monetary policy tools to foster financial stability objectives. Return to text\n\n19. Implicit in this discussion is some degree of confidence that the central bank could identify a buildup of financial stability risks. Adrian, Covitz, and Liang (2014) offer some views on effective financial stability monitoring. Return to text\n\n20. This variability is in part due to different model set-ups, such as how financial instability builds up and how it affects economic outcomes. For example, Woodford (2012) finds that leaning against the wind does not change the basis for traditional stabilization objectives in a standard New Keynesian model, whereas the cost-benefit analysis in Svensson (2015) finds little basis for the \"leaning against the wind\" strategy. Ajello and others (2015) find that optimal adjustment of the policy rate, when the possibility of a crisis is taken into account, is small unless the policymaker is assumed to be quite uncertain about the likelihood and severity of the crisis. Return to text"
    }
]