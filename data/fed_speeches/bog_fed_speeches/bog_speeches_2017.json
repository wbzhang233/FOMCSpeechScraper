[
    {
        "title": "Workforce Development in Today's Economy",
        "date": "December 13, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20171213a.htm",
        "content": "December 13, 2017\n\nGovernor Lael Brainard\n\nAt \"Leading the Way: A Workforce Development Video Campaign\" awards ceremony hosted by the Federal Reserve Bank of New York and Pathways in Technology Early College High Schools in the Greater Rochester Area, Rochester, N.Y.\n\nI would like to thank the staff at the Federal Reserve Bank of New York for inviting me to attend this awards ceremony.1 As many of you may already know, the Leading the Way campaign is a joint effort between the Federal Reserve Bank and the P-TECH2 schools of the Greater Rochester area. It is wonderful to be part of an event that celebrates collaboration between educational institutions, local government, the Federal Reserve, and employers as they work together to provide appropriate training for young workers to fill local jobs needs. Collaboration creates a more vibrant workforce that is connected to actual jobs.\n\nToday's Job Market\nI have just come from a meeting of the Federal Open Market Committee (FOMC). The FOMC is one of the main policymaking committees of the Federal Reserve System. Our main job on the FOMC is to set interest rates to achieve the maximum level of employment in the country and sustain inflation at a moderate level.\n\nThe nation's unemployment rate is currently around 4.1 percent, which is a relatively low level by historical standards. What that means for the young people participating in this program is that this is a great time to find a job. Moreover, not only is the national unemployment rate low, so are unemployment rates for young people and members of ethnic and racial groups that have traditionally faced greater challenges in the labor market. As many of you know, during the deep recession of 2008 and 2009, many Americans were so discouraged by poor job prospects that they stopped even looking for work. That meant that too many Americans were sitting on the sidelines. In the past few years, the job market has gotten so strong that many of these people have come off the sidelines--and many are now back at work.\n\nThe Rochester area, like much of the country, has now recovered from the Great Recession. The education and health-care sectors continue to be the main drivers of job growth. And, the local community colleges have partnered with local employers to align their curriculums with the employers' job openings, to increase workers' connections to jobs, and to become a resource for regional job information. Finally, the local government has worked to contend with a long-term loss of jobs in manufacturing and a more recent loss of jobs in professional services by attracting investment in a world-class photonics hub in Rochester.\n\nI often meet with people who run large companies to get their take on the strength of the economy. Whereas a few years ago, they might not have been engaged in a lot of hiring, today they tell me that it is becoming more challenging to find well-qualified workers for the job openings they want to fill. That's good news for those of you participating in the P-TECH program. It means employers are looking for graduates of programs just like yours, which are attuned to the job opportunities of employers. P‑TECH Rochester programs offer students professional mentors, job shadowing opportunities, and on-the-job experience to ensure that they are ready to contribute positively to the workplaces of local employers. I also understand that companies are investing more in on-the-job training and are strengthening efforts to retain more of the workers they attract, which means younger workers--such as P‑TECH graduates--have a better chance of securing jobs that lead to long-lasting careers. By any measure, the market for younger workers today looks much better than it did in the years just after the Great Recession, when unemployment rates for teenagers were above 20 percent.3\n\nIn fact, firms are turning more and more to programs like P-TECH to help them find and train the workers they need. So the skills you are gaining today are likely to provide pathways not only to the jobs of today but also the careers of the future.\n\nWorkforce Development\nThe Federal Reserve Bank of New York is one of the facilitators of the Leading the Way campaign. The Federal Reserve System has a long-standing interest in understanding labor market dynamics and promoting workforce development opportunities. Programs like this help workers prepare for jobs and help firms invest in workforce development. Together, these efforts help make the economy more productive and help us achieve our goal of maximum employment. In addition to the Federal Reserve Bank of New York's efforts, the Federal Reserve Bank of Boston is learning about labor markets in small industrial cities through their Working Cities Challenge and the Federal Reserve Bank of Dallas has focused on the importance of infrastructure including broadband for economic inclusion. The Federal Reserve Bank of Atlanta has been a leader within the Federal Reserve System in establishing the Investing in America's Workforce Initiative, an effort across the Federal Reserve System to reframe training expenditures as investments in human capital rather than costs. In October, Atlanta established the Center for Workforce and Economic Opportunity to focus on employment policies and labor market issues that affect low- and moderate-income individuals. The System also recently hosted a national conference in Austin to promote the importance of investing in America's workforce.4\n\nAs employers' demand for specific education and training increase, collaborative initiatives, like those exhibited through the P-TECH programs of Greater Rochester, will help minimize the skills mismatch appearing in many communities with burgeoning job markets.\n\nYoung Workers\nSince 2013, the Federal Reserve Board has been administering the Survey of Young Workers to learn more about work experiences and future prospects for 18-to-30-year-olds nationwide. When I look at the survey findings, I am struck by how well the P-TECH program addresses many of the issues young people identified in the survey.\n\nAs a first example, the survey findings highlight the important correlation between postsecondary education and labor market outcomes. The survey data indicate that higher levels of educational attainment are associated with higher earnings, greater job satisfaction, and increased optimism about one's job future. P-TECH focuses on providing students with postsecondary credentials, helping to address one of the survey's main concerns.\n\nSecond, responses to the survey underscore the importance of young workers receiving appropriate information that enables them to select an educational program that provides better labor market outcomes. The survey found that more than 30 percent of young adults did not receive information about jobs and careers in high school and college. P-TECH is focused on providing information about educational opportunities and jobs to students before they enter high school.\n\nThird, the survey found that many young workers are not employed in fields aligned with their education. Fewer than half (45 percent) of the young workers surveyed said they were employed in a career field that is closely related to their educational and training background. P-TECH focuses on aligning education with actual jobs.\n\nFinally, the survey found that steady employment is very important to young workers. In 2015, young adults had a strong preference for steady employment (62 percent) over higher pay (36 percent). And, among the respondents who preferred steady employment, 80 percent would rather have one steady job than a stream of steady jobs for the next five years. The work that P‑TECH students do directly with employers helps steer them toward long-term, steady employment.\n\nConclusion\nIn conclusion, I am proud that the Federal Reserve is contributing to the efforts of the P-TECH program in the Rochester area and I look forward to the video presentations we will have shortly. I want to congratulate in advance the winners of the video competition, who will also be announced shortly. I also want to congratulate all of you for being part of a 21st century education program that will help connect you to pathways of opportunity and help enable you to make important contributions to the vitality of your community.\n\n1. I am grateful to Heidi Kaplan for her assistance in preparing this text. The remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. P-TECH is short for Pathways in Technology Early College High. Return to text\n\n3. See Lael Brainard, \"Coming of Age in the Great Recession,\" speech given to the Federal Reserve's conference on \"Economic Mobility: Research and Ideas on Strengthening Families, Communities, and the Economy,\" April 2, 2015. Return to text\n\n4. For more information on the Working Cities Challenge, see https://www.bostonfed.org/community-development/smaller-industrial-cities/working-cities-challenge.aspx. For the Dallas Fed's work on closing the digital divide, see www.dallasfed.org/cd/pubs.aspx. For the Atlanta Fed's Center for Workforce and Economic Opportunity, see https://www.frbatlanta.org/cweo.aspx. And on the Investing in America's Workforce Initiative, see www.investinwork.org. Return to text"
    },
    {
        "title": "Thoughts on Prudent Innovation in the Payment System",
        "date": "November 30, 2017",
        "speaker": "Vice Chairman for Supervision Randal K. Quarles",
        "url": "https://www.federalreserve.gov/newsevents/speech/quarles20171130a.htm",
        "content": "November 30, 2017\n\nVice Chairman for Supervision Randal K. Quarles\n\nAt the 2017 Financial Stability and Fintech Conference sponsored by the Federal Reserve Bank of Cleveland, the Office of Financial Research, and the University of Maryland's Robert H. Smith School of Business, Washington, D.C.\n\nIt is a pleasure to be with you today to talk about financial stability and fintech. Being in the Treasury's beautifully restored Cash Room calls to mind the themes of both history and finance. History, because the room was constructed just after the Civil War. Finance, because it was designed to be the Treasury's bank and was originally used to conduct daily banking and payment transactions with other banks and the general public. Of course the functionality of this room has changed over the decades as the financial system landscape has evolved, and today we are holding a conference here to discuss financial innovation.\n\nBefore I begin, I will note that my colleague, Jay Powell, was supposed to be your speaker today. However, as you can likely surmise, he had to attend to other matters and asked me to speak in his place. So to carry through the theme of today's topic, one might call Jay the innovator on payments issues at the Federal Reserve, as he has spoken extensively on the subject for many years. And one might think of me as tech support on these issues for the day.\n\nNew technologies have brought tremendous, positive change to our lives, raising productivity and living standards and contributing to economic growth. In the past few years, innovation has profoundly transformed industries such as retail shopping, the media, and even transportation by providing greater speed, convenience, and competition. Not surprisingly, both the banking industry and technology firms have also been seeking innovations in financial services that mirror and complement changes that have been made in other industries. Innovation is coming to finance with changes to consumer lending, financial advice, and retail payments, to name a few. The Federal Reserve, itself, is engaged in a multiyear effort to address challenges and opportunities in the current payment system.\n\nDuring my experience in the realm of private equity, I had a chance to interact with many new firms in these areas. The pace of innovation was often dizzying. In my new role as Vice Chairman for Supervision at the Federal Reserve, I see innovation as something that can and should be fostered, but of course I must also scrutinize these innovations from a different perspective. That is to say, it is appropriate not only to evaluate the potential of innovations to improve on existing services, but also to judge their ramifications for the safety and soundness of the institutions we supervise and for financial stability--the topic of this conference. Although many of these technologies are still nascent, it is important to have an eye on the potential financial stability implications both in the short- and long-run. Payment systems need to be resilient during adversity. Without that resilience, we could face a sudden loss of public confidence and the seizing up of systems and critical activities.\n\nWith the Cash Room's perspective on history and daily financial operations in mind, I would like to concentrate my remarks on the U.S. payment system, which is a critical foundation on which financial transactions and the conduct of business take place. New technologies are being proposed that could alter the design of our payment system. Today, I will talk about the necessary trust and confidence that the system requires, the tension between the need for financial stability and the need to innovate, and the challenges that digital currencies, in particular, present relative to the current system. These considerations highlight the need for a prudent approach to innovation in payment systems.\n\nPayment Systems, Networks, and Trust\nPayment systems are both financial networks and technical networks. In simple terms, there is an asset that functions as money that can be transferred by households and businesses to buy goods and services, which, along with their financial institutions, make up the bulk of the financial network. Today, the predominant forms of money used in payment systems are Federal Reserve notes and reserve balances as well as transaction balances at depository institutions.\n\nPayment systems also require a technical network to hold and transfer money. In earlier times, the network was less technical in nature and almost exclusively designed for the logistical storage and transfer of physical forms of money. Today, the main payments networks use centralized technology to process and safeguard the public's electronic funds transfers. Regulated banking institutions provide deposit money to the public and are a main source of trust for these systems. Transfers of balances on the books of these institutions are at the center of the public's transactions, with the Federal Reserve Banks playing a central, supporting role in interbank clearing and settlement for the most critical systems.\n\nA great amount of resources and effort goes into the networks that make the overall payment system safe, efficient, and resilient. It is fair to say that the general public places a great deal of trust in the components of the overall system to safeguard their money and operate as planned every day, and that trust is necessary for the system to work. From the perspective of financial stability, if the safety and integrity of the institutions and assets at the heart of a system erode or the transfer operations are not dependable, then the necessary trust and confidence that the system requires to work may quickly cease to function as needed.\n\nPayment System Innovation\nWith a steady diet of news about the effect of electronic networks, personal devices, apps, and more on U.S. industries, many question the effect of these technologies on the payment system. I think we should recognize that there can be a tension between the need for financial stability in the overall payment system and the need to innovate to keep up with the demands of modern technology and lifestyles. However, we should also recognize that this tension is not necessarily troubling. By definition innovation means doing something new, which usually involves taking risk in furtherance of some gain. But at the same time, we should be vigilant in balancing the benefits of innovation with the safe and reliable operation of systems and critical activities.\n\nFrom an analytical perspective, payment systems typically increase in value as more people use a system and the more attractive it becomes to others. In addition, there is an inverse relationship between the volume of users of a system and the cost of production--more users lower the cost of production. Until recently, these features may have hindered innovation by presenting high barriers to entry and may have also fostered greater concentration into a few key entities that could become systemically important.1 Of course, technology may be able to reduce the effect of at least some of these hurdles by, for example, attracting high numbers of users quickly or reducing the costs of production. However, the effect of reducing technological barriers for financial stability is not clearly positive or negative. For example, on the one hand, new market participants attracted by lower barriers to entry may introduce new and unknown risks in the payment system. On the other hand, new market participants may relieve the concentration of activity in a limited number of players.\n\nThus, the potential tension between innovation and stability can be more difficult to manage in the case of payment systems as compared to other industries that are less affected by these hurdles. One sensible approach to risk management would emphasize \"starting small\" and taking small risks. But unless a payment system grows a fairly large network of users in a reasonable time, it is unlikely to achieve the scope and scale it needs to be successful. Conversely, if a system attempts to start on a large scale and is successful, there will surely be questions about resilience in adversity, particularly if cutting-edge technologies and methods are used to handle people's money. The essential problem is how to achieve scale and manage financial and technical risk at the same time. Not surprisingly, because striking the right balance takes time, genuine innovation in payment systems over history has often been measured in decades, not years.\n\nPrivate Digital Currencies\nAs part of the new technology associated with fintech, we are now seeing the emergence of privately developed digital currencies using new decentralized technologies. Fundamental to these digital currencies is the establishment of a new asset, the unit of the digital currency--for example, a bitcoin--and a new record-keeping and transfer mechanism that enables users to store and trade those units--for example, a blockchain--often without reliance on traditional financial institutions.\n\nI believe the financial industry is increasingly recognizing that we should separate the concept of digital currencies from the innovative new technologies that they have employed to transfer assets. Those technologies, such as distributed ledgers, may offer useful new ways to store, transfer, and protect data and traditional financial assets. The industry is now moving cautiously from pilot projects in many of these areas to the use of these new technologies in limited production settings. This cautious approach to using new technology appears to reflect the weight of responsibility the financial industry bears for protecting both their customers and their reputations. Continued monitoring of developments is in order, and time will tell how these new technologies--and others--can contribute to a safe and secure payment system and broader financial system. The Federal Reserve has been actively monitoring these developments and will continue to do so.2\n\nBut when we examine the assets at the center of digital currency systems, I think we should begin to think clearly about the long-term properties we seek for large-scale payment networks and systems used by the general public. Today, the vast majority of our payments by volume and value are processed by regulated financial institutions. In the U.S. payment system, digital currencies are a niche product that sometimes garners large headlines. But from the standpoint of analysis, the \"currency\" or asset at the center of some of these systems is not backed by other secure assets, has no intrinsic value, is not the liability of a regulated banking institution, and in leading cases, is not the liability of any institution at all. Indeed, how to treat and define this new asset is complicated.3\n\nWhile these digital currencies may not pose major concerns at their current levels of use, more serious financial stability issues may result if they achieve wide-scale usage. Risk management can act as a mitigant, but if the central asset in a payment system cannot be predictably redeemed for the U.S. dollar at a stable exchange rate in times of adversity, the resulting price risk and potential liquidity and credit risk pose a large challenge for the system. During times of crisis, the demand for liquidity can increase significantly, including the demand for the central asset used in settling payments. Even private-sector banks and certainly non-banks can have a hard time meeting large-scale demands for extra liquidity at the very time when their balance sheets may be in question. Moreover, this inability to meet the demand for extra liquidity can have spillover effects to other areas of the financial system.\n\nEarlier in our history, the United States frequently witnessed bank runs that severely disrupted financial and economic activity, an example of what can happen when people lose faith in a payment system. In response, Congress ultimately introduced both a central bank and deposit insurance programs to help regulate fluctuations in the supply of liquidity in order to keep prices stable. Without the backing of a central bank asset and institutional support, it is not clear how a private digital currency at the center of a large-scale payment system would behave, or whether the payment system would be able to function, in times of stress.\n\nCentral-Bank-Issued Digital Currency\nGiven that privately developed digital currencies may raise important financial stability issues tied to the value of the asset, some have argued that central banks should begin to issue their own digital currency as a 21st century analogue to paper currency. I would urge caution, particularly for countries like the United States with highly developed banking systems and ongoing robust demand for physical cash.\n\nAs a practical matter, I believe that consideration of a central-bank-issued digital currency to the general public would require extensive reviews and consultations about legal issues, as well as a long list of risk issues, including the potential deployment of unproven technology, money laundering, cybersecurity, and privacy to name a few. I am particularly concerned that a central-bank-issued digital currency that's held widely around the globe could be the subject of serious cyberattacks and could be widely used in money laundering and terrorist financing. The effect of all this would significantly divert our focus from work to improve or establish new private-sector retail payment systems based on existing institutions. The prospect of a government-sponsored digital currency might even derail private-sector plans to enhance the payment services provided to their customers, thereby significantly disrupting the financial networks that exist today in ways that could create instability. For example, if payment activity radically shifted from using deposits at financial institutions to using central-bank-issued digital currency, deposits could significantly shrink and potentially disrupt financial institutions' ability to make loans that spur economic activity.\n\nThat said, research into digital currency issues, including highly liquid and secure limited-purpose digital currencies for use as a settlement asset for wholesale payment systems, should continue. As technologies are developed and refined, old issues are resolved and new issues arise. Other countries may have different environments and experiences. We should always be open to learning and understanding from the experiences of others.\n\nPrudent Innovation\nFor the United States, the alternative to privately issued digital currency is not necessarily a publicly issued digital currency. Instead, the near-term alternative is to build on the trusted foundations of the existing payment system and work to improve private-sector payment services. Importantly, this means looking to the banking system, which holds the bulk of the transaction deposits in this country, to improve services. This began a number of years ago with internet banking. Today, many banks offer around-the-clock internet-based access to accounts as well as mobile banking and payment capabilities. Many banks typically allow real-time or near real-time transfers of funds among their own customer base. What does not yet exist in the United States is the sort of ubiquitous, real-time payment system that would allow banks and their customers to make transfers and settlements of funds across the banking system instantly, conveniently, and securely all the time.\n\nAs my colleague at the Board, Jay Powell, recently discussed at a conference in New York, the Federal Reserve has been working with the banking industry and a wide range of other payment system stakeholders to better understand the consequences of this state of affairs and support efforts to expand the available options through our payment system improvement initiative.4 For example, based on recommendations from the industry, the Federal Reserve is currently studying potential improvements in its settlement services--a traditional core function of a central bank--that could address the future needs of a ubiquitous real-time retail payments environment.\n\nBuilding on our existing banking system also makes sense from a financial stability perspective. Federally insured and supervised institutions are the core of our current payment system and largely address the potential financial stability problem of relying on payment systems with unbacked and unregulated digital currencies at their heart. But leveraging our existing banking system does not suggest that there is no room for new or emerging institutions and technologies. Indeed, there are a number of promising avenues that would allow the innovations that appear to be of the greatest interest to households and business--attributes like instant payment capabilities and around-the-clock operations--to be offered using a variety of existing and new technologies without requiring significant tradeoffs in safety and resiliency.\n\nSummary\nTo conclude, our financial stability requires that the payment system be reliable and dependable so that the public can trust it. As a result, there can be a tension between innovation and the need for financial stability in the overall payment system. Innovation must therefore account for the effects that it has on both the financial and technology networks that make up our payment system.\n\nThe innovation that is beginning to flow from the development of digital currencies--and other technologies--will likely have a long-run effect on the technical networks and the business processes used in the payment system and the wider financial system. Privately developed digital currencies as currently configured would raise concerns about the effect on financial stability if they take on more prominence in the payments and overall financial system. Central bank digital currencies are also not immune to a large range of risks and could even adversely affect financial stability. As such, central banks should tread cautiously as they contemplate issuing them. But this does not mean that we should avoid further innovation. Working cooperatively, private-sector participants and central banks can incorporate innovation that may be able to strike the right balance of improving the technical networks without adversely generating financial stability concerns. I am optimistic that the Federal Reserve's work with the payments industry will facilitate a future with a safe and more efficient payment system.\n\n1. See Financial Stability Board, Financial Stability Implications from FinTech: Supervisory and Regulatory Issues that Merit Authorities' Attention (PDF), June 27, 2017. Return to text\n\n2. See David Mills, Kathy Wang, Brendan Malone, Anjana Ravi, Jeff Marquardt, Clinton Chen, Anton Badev, Timothy Brezinski, Linda Fahy, Kimberley Liao, Vanessa Kargenian, Max Ellithorpe, Wendy Ng, and Maria Baird, \"Distributed Ledger Technology in Payments, Clearing, and Settlement (PDF),\" Finance and Economics Discussion Series 2016-095 (Washington: Board of Governors of the Federal Reserve System, 2016). Return to text\n\n3. For example, the Commodity Futures Trading Commission published a statement on digital currencies making clear that many fall into the category of commodities under the Commodity Exchange Act (www.cftc.gov/PressRoom/PressReleases/pr7231-15). The Securities and Exchange Commission has published guidance on the treatment of digital currencies under the Securities Exchange Act (www.sec.gov/news/press-release/2017-131). The Internal Revenue Service has published guidance on the tax treatment of digital currencies (www.irs.gov/pub/irs-drop/n-14-21.pdf). And the Financial Crimes Enforcement Network has published guidance on the treatment of digital currencies under the Bank Secrecy Act (www.fincen.gov/resources/statutes-regulations/guidance/application-fincens-regulations-persons-administering). Return to text\n\n4. See Jerome H. Powell, \"Financial Innovation: A World in Transition\" (speech delivered at the 41st Annual Central Banking Seminar, sponsored by the Federal Reserve Bank of New York, New York, October 18, 2017). Return to text"
    },
    {
        "title": "Where Do Consumers Fit in the Fintech Stack?",
        "date": "November 16, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20171116a.htm",
        "content": "November 16, 2017\n\nGovernor Lael Brainard\n\nAt \"FinTech Risks and Opportunities: An Interdisciplinary Approach,\" a conference sponsored by the University of Michigan, Ann Arbor, Michigan\n\nThe new generation of fintech tools offers the potential to help consumers manage their increasingly complicated financial lives, but also poses risks that will need to be managed as the marketplace matures.1\n\nIn many ways, the new generation of fintech tools can be seen as the financial equivalent of an autopilot. The powerful new fintech tools represent the convergence of numerous advances in research and technology--ranging from new insights into consumer decisionmaking to a revolution in available data, cloud computing, and artificial intelligence (AI). They operate by guiding consumers through complex decisions by offering new ways of looking at a consumer's overall financial picture or simplifying choices, for example with behavioral nudges.\n\nAs consumers start to rely on financial autopilots, however, it is important that they remain in the driver's seat and have a good handle on what is happening under the hood. Consumers need to know and decide who they are contracting with, what data of theirs is being used by whom and for what purpose, how to revoke data access and delete stored data, and how to seek relief if things go wrong. In short, consumers should remain in control of the data they provide. In addition, consumers should receive clear disclosure of the factors that are reflected in the recommendations they receive. If these issues can be appropriately addressed, the new fintech capabilities have enormous potential to deliver analytically grounded financial services and simplified choices, tailored to the consumers' needs and preferences, and accessible via their smartphones.2\n\nConsumers Face Complex Financial Choices\nWhen the first major \"credit card,\" the Diner's Club Card, was introduced in 1949, consumers could only use the cardboard card at restaurants and, importantly, only if they paid the entire amount due each month.3 Today, the average cardholder has about four credit cards, and the Federal Reserve Bank of New York estimates that American consumers collectively carry $785 billion in credit card debt.4\n\nWhen signing up for a credit card, consumers face a bewildering array of choices. Half of consumers report that they select new cards based on reward programs, weighing \"cash back\" offers against \"points\" with their credit card provider that may convert into airline or hotel \"miles,\" which may have varying values depending on how they are redeemed.5 In some cases, rewards may apply to specific spending categories that rotate by quarter and require that consumers re-register each term, and the rewards may expire or be forfeited under complicated terms.6\n\nIn some cases, the choices may be confusing. Let's take the example of zero percent interest credit card promotions. A consumer may choose a zero percent interest credit card promotion and expect to pay no interest on balances during a promotional period, after which any balances are assessed at a higher rate of interest going forward. But if a consumer instead chooses a zero percent interest private-label credit card with deferred interest and has a positive balance when the promotional period expires, interest could be retroactively assessed for the full time they held a balance during the promotional period.7 Even sophisticated consumers could be excused for confusing these products.\n\nAs it turns out, it is often the most vulnerable consumers who have to navigate the most complicated products. For instance, one recent study of the credit card market found that the average length of agreements for products offered to subprime consumers was 70 percent longer than agreements for other products.8\n\nThe complexity multiplies when we go beyond credit cards and consider other dimensions of consumers' financial lives.9 The Federal Deposit Insurance Corporation has found that nearly a quarter of the Americans that don't maintain bank accounts are concerned that bank fees are too unpredictable.10 Even though mortgage debt is over two-thirds of household debt, nearly half of consumers don't comparison shop before taking out a mortgage.11 Student loans now make up 11 percent of total household debt, more than twice its share in 2008.12 Over 11 percent of student debt is more than 90 days delinquent or in default--and researchers at the Federal Reserve Bank of New York estimate that this figure may understate the problem by as much as half.13\n\nToday, consumers navigate numerous weighty financial responsibilities for themselves and their dependents.14 It seems fair to assume they could use some help managing this complexity. In the Federal Reserve Board's annual Survey of Household Economics and Decisionmaking (SHED), more than half of respondents reported that their spending exceeded their income in the prior year.15 Indeed, 44 percent of SHED respondents reported that they could not cover an emergency expense costing $400 without selling something or borrowing money.16\n\nNew Tools to Help Consumers Manage Their Finances\nGiven the complexity and importance of these decisions, it is encouraging to see the fast-growing development of advanced, technology-enabled tools to help consumers navigate the complex issues in their financial lives. These tools build on important advances in our understanding of consumer financial behavior and the applications, or \"app,\" ecosystem.\n\nResearchers have invested decades of work exploring how consumers actually make decisions. We all tend to use shortcuts to simplify financial decisions, and it turns out many of these can prove faulty, particularly when dealing with complex problems.17 For example, empirical evidence consistently shows that consumers overvalue the present and undervalue the future.18 Researchers have documented that consumers make better savings decisions when they are presented with fewer options.19 They have shown the importance of \"anchoring\" bias--the tendency to place disproportionate weight on the first piece of information presented. This bias can lead consumers either to make poor financial choices or instead to tip the scales in favor of beneficial choices, as with automatic savings defaults.20 Similarly, \"nudges\" can help consumers in the right circumstances or instead backfire in surprising ways.21\n\nThese behavioral insights are especially powerful when paired with the remarkable advances we have seen in the technological tools available to the average consumer, especially through their smartphones.22 Smartphones are ubiquitous. The 2016 Federal Reserve Survey of Consumer and Mobile Financial Services (SCMF) found that 87 percent of the U.S. adult population had a mobile phone, the vast majority of which were smartphones. 23 Smartphone use is prevalent even among the unbanked and underbanked populations. Survey evidence suggests we are three times more likely to reach for our phone than our significant other when we first wake up in the morning.24\n\nSome evidence suggests that smartphones are already helping consumers make better financial decisions. The 2016 SCMF found that 62 percent of mobile banking users checked their account balances on their phones before making a large purchase, and half of those that did so decided not to purchase an item as a result.25 In addition, 41 percent of smartphone owners checked product reviews or searched product information online while shopping in a retail store, and 79 percent of those respondents reported changing their purchase decision based on the information they accessed on their smartphone.26\n\nAnd those use cases just scratch the surface of what is possible. First of all, the smartphone platform has become a launch pad for a whole ecosystem of apps created by outside developers for a wide variety of services, including helping consumers manage their financial lives.\n\nSecond, the smartphone ecosystem puts the enormous computing power of the cloud at the fingertips of consumers. Interfacing with smartphone platforms and other apps, outside developers can tap the computing power of the leading cloud computing providers in building their apps. Importantly, cloud computing offers not only the power to process and store data, but also powerful algorithms to make sense of it. Due to early commitment to open-source principles, app developers have open access to many of the same machine-learning and artificial intelligence tools that power the world's largest internet companies.27 Further, the major cloud computing providers have now taken these free building blocks and created different machine-learning and artificial intelligence stacks on their cloud platforms. A developer that wants to incorporate artificial intelligence into their financial management app can access off-the-shelf models of cloud computing providers, potentially getting to market faster than by taking the traditional route of finding training data and building out models in-house from scratch.\n\nThird, fintech developers can also draw from enormous pools of data that were previously unavailable outside of banking institutions. Consumer financial data are increasingly available to developers via a new breed of business-to-business suppliers, called data aggregators.28 These companies enable outside developers to access consumer account and transactional information typically stored by banks. But aggregators do more than just provide access to raw data. They facilitate its use by developers, by cleaning the data, standardizing it across institutions, and offering their own application programming interfaces for easy integration. Further, similar to cloud computing providers, data aggregators are also beginning to provide off-the-shelf product stacks on their own platforms.29 This means that developers can quickly and easily incorporate product features, such as predicting creditworthiness, determining how much a consumer can save each month, or creating alerts for potential overdraft charges.\n\nResearchers have documented the benefits of tailored one-on-one financial coaching.30 Until recently, though, it has been hard to deliver that kind of service affordably and at scale, due to differences in consumers' circumstances. Let's again consider the example of deferred interest credit cards. It turns out only a small minority of consumers miss the deadlines for repaying promotional balances and are charged retroactive interest payments, and they typically have deep subprime scores.31 Similarly, for consumers that opt into overdraft products on their checking accounts, 8 percent of consumers pay 75 percent of the fees.32 Up until now, it has been hard for consumers to understand those odds and objectively assess whether they are likely to be in the group of customers that will face challenges with a particular financial product. The convergence of smartphone ubiquity, cloud computing, data aggregation, and off-the-shelf AI products offer the potential to make tailored financial advice scalable. For instance, a fintech developer could pair historical data about how different types of consumers fare with a specific product, on the one hand, with a consumer's particular financial profile, on the other hand, to make a prediction about how that consumer is likely to fare with the product.\n\nThe Evolution of Financial Autopilots\nSince the early days of internet commerce, developers have tried to move beyond simple price comparison tools to offer tailored \"agents\" for consumers that can recommend products based on analyses of individual behavior and preferences.33 Today, a new generation of personal financial management tools seems poised to make that leap. When a consumer wishes to select a new financial product, he or she can now solicit options from a number of websites and mobile apps. These new comparison sites can walk the consumer through a wide array of financial products, offering to compare features like rewards, fees, and rates, or tailoring to a consumer's stated goals. Some fintech advisors ask consumers to provide access to their bank accounts, retirement accounts, college savings accounts, and other investment platforms in order to enable a fintech advisor to offer a consumer a single, near complete picture of his balances and cash flows across different institutions.\n\nIn reviewing the advertising, terms and conditions, and apps of an array of fintech advisors, it appears that many of these tools offer advanced data analysis, machine learning, and even artificial intelligence to help consumers cut down on unnecessary spending, set aside money for savings, and use healthy nudges to improve their financial decisions. For instance, a fintech advisor may help a consumer automate savings \"rules,\" like rounding up charges and putting the difference into savings, enabling these small balances to accumulate over time or setting a small amount of money aside every time a consumer spends money on little splurges.\n\nThe early stages of innovation inevitably feature a lot of learning from trial and error. Fortunately, as the fintech ecosystem advances, there are useful experiences and good practices to draw upon from the evolution of the commercial internet. To begin with, one internet adage is that if a product is free, \"you are the product.\"34 In this vein, fintech advisors frequently offer free services to consumers and earn their revenue from the credit cards and other financial products that they recommend through lead generation.\n\nOf course, many fintech advisors are not lead generators. Some companies offer fee-for-service models, with consumers paying a monthly fee for the product. Other companies are paid by employers, who then provide the products free of charge to their employees as an employee benefit. In these cases, they likely have quite different business models.\n\nBut for those services that do act as lead generators, there are important considerations about whether and how best to communicate information to the consumer about the nature of the recommendations being made. For instance, according to some reports, fintech advisors can make between $100 and $700 in lead generation fees for every customer that signs up for a credit card they recommend.35\n\nIn many cases, a fintech advisor may describe their service as providing tailored advice or making recommendations as they would to friends and family. In such cases, a consumer might not know whether the order in which products are presented by a fintech assistant is based on the product's alignment with his or her needs or different considerations. Different fintech advisors may order the lists they show consumers using different criteria. A product may be at the top of the advisor's recommendations because the sponsoring company has paid the advisor to list it at the top, or the sponsoring company may pay the fintech assistant a high fee, contingent upon the consumer signing up for the product. Alternatively, a fintech advisor may change the order of the loan offers or credit cards based on the likelihood that the consumer will be approved. Moreover, in some cases, the absence of lead generation fees for a particular product may impact whether that product is on the list shown to consumers at all.\n\nThere appears to be a wide variety of practices regarding the prominence and placement of advertising and other disclosures relative to the advice and recommendations such firms provide. Overall, fintech assistants have increasingly improved the disclosures that explain to consumers how they get paid, but this is still a work in progress.\n\nThe good news is that these challenges are not new. The experience with internet search engines outside of financial products, such as Google, Bing, and Yahoo!, as well as with other product comparison sites, such as Travelocity and Yelp, may provide useful guidance. As consumers and businesses have adapted to the internet, we have, collectively, adopted norms and standards for how we can expect search and recommendation engines to operate. In particular, we generally expect that search results will be included and ranked based on what's organically most responsive to the search--unless it is clearly labeled otherwise.36 Accordingly, when we search for a product, we now know to look for visual cues that identify paid search results, usually in the form of a text label like \"Sponsored\" or \"Ad\", different formatting, and visually separating advertising from natural search results.37 Even when an endorsement is made in a brief Twitter update, we now expect disclosures to be clear and conspicuous.38\n\nAs fintech advisors evolve to engage consumers in new ways, disclosure methodologies will no doubt be expected to adapt as well. For instance, some personal financial management tools now interact with consumers via text message. If consumers move to a world in which most of their interactions with their advisors occur via text-messaging \"chatbots\"--or voice communication--I am hopeful that industry, regulators, consumers, and other stakeholders will work together to adapt the norms to distinguish between advice and sponsored recommendations.\n\nThe Data Relationship\nWhile the lead generation revenue model presents some familiar issues that are readily apparent, under the hood, fintech relationships raise even more complex issues for consumers in knowing who they are providing their data to, how their data will be used, for how long, and what to expect in the case of a breach or fraud. Let me briefly touch on each issue in turn.\n\nOften, when a consumer signs up with a fintech advisor or other fintech app, they are asked to log into their bank account in order to link the fintech app with their bank account data. In reviewing apps' enrollment processes, it appears that consumers are often shown log-in screens featuring bank logos and branding, prompting consumers to enter their online banking logins and passwords. In many cases, the apps note that they do not store the consumers' banking credentials.\n\nWhen the consumer logs on, he or she is often not interfacing with a banks' computer systems, but rather, providing the bank account login and password to a data aggregator that provides services to the fintech app. In many cases, the data aggregator may store the password and login and then use those credentials to periodically log into the consumer's bank account and copy available data, ranging from transaction data, to account numbers, to personally identifiable information. In other cases, things work differently under the hood. Some banks and data aggregators have agreed to work together to facilitate the ability to share data with outside developers in authorized ways. These agreements may delineate what types of data will be shared, and authorization credentials may be tokenized so that passwords are never stored by the aggregator.39\n\nIt is often hard for the consumer to know what is actually happening under the hood of the financial app they are accessing. In most cases, the log in process does not do much to educate the consumer on the precise nature of the data relationship. Screen scraping usually invokes the bank's logo and branding but infrequently shows the logo or name of the data aggregator. In reviewing many apps, it appears that the name of the data aggregator is frequently not disclosed in the fintech app's terms and conditions, and a consumer generally would not easily see what data is held by a data aggregator or how it is used. The apps, websites, and terms and conditions of fintech advisors and data aggregators often do not explain how frequently data aggregators will access a consumer's data or how long they will store that data.40\n\nRecognizing this is a relatively young field, but one that is growing fast, there are a myriad of questions about the consumer's ability to opt out and control over data that will need to be addressed appropriately. In examining the terms and conditions for a number of fintech apps, it appears that consumers are rarely provided information explaining how they can terminate the collection and storage of their data. For instance, when a consumer deletes a fintech app from his or her phone, it is not clear this would guarantee that a data aggregator would delete the consumer's bank login and password, nor discontinue accessing transaction information. If a consumer severs the data access, for instance by changing banks or bank account passwords, it is also not clear how he or she can instruct the data aggregator to delete the information that has already been collected. Given that data aggregators often don't have consumer interfaces, consumers may be left to find an email address for the data aggregator, send in a deletion request, and hope for the best.\n\nIf things go wrong, consumers may have limited remedies. In reviewing terms, it appears that many fintech advisors include contractual waivers that purport to limit consumers' ability to seek redress from the advisor or an underlying data aggregator. In some cases, the terms and conditions assert that the fintech developer and its third-party service providers will not be liable to consumers for the performance of or inability to use the services. It is not uncommon to see terms and conditions that limit the fintech adviser's liability to the consumer to $100.\n\nTraditionally, under the Electronic Funds Transfer Act and its implementing Regulation E, consumers have had protections to mitigate their losses in the event of erroneous or fraudulent transactions that would otherwise impact their credit and debit cards, such as data breaches. Those protections are not absolute, however.41 In particular, if a consumer gives another person an \"access device\" to their account and grants them authority to make transfers, then the consumer is \"fully liable\" for transfers made by that person, even if that person exceeds his or her authority, until the consumer notifies the bank.42 As the industry matures, the various stakeholders will need to develop a shared understanding of who bears responsibility in the event of a breach.43\n\nShared Responsibility and Shared Benefit Moving Forward\nSo what can be done to make sure consumers have the requisite information and control to remain squarely in the driver's seat? Establishing and implementing new norms is in the shared interest of all of the participants in the fintech stack. For instance, in the case of credit cards, mortgages, and many other products, it is often banks or parties closely affiliated with banks that pay fees to fintech advisors to generate leads for their products, pursuant to a contract. Through these contractual relationships with fintech advisors, banks have considerable influence in the lead generation relationship, including through provisions describing how a sponsored product should be described or displayed. Banks have a stake in ensuring that their vendors and third-party service providers act appropriately, that consumers are protected and treated fairly, and that the banks' reputations aren't exposed to unnecessary risk.44 Likewise, some of the leading speech-only financial products are currently credit card and bank products.45 Accordingly, banks have incentives to invest in innovating the way they disclose information to consumers, as they also invest in new ways of interacting with them.\n\nAs for consumers' relationships with data aggregators, there's an increasing recognition that consumers need better information about the terms of their relationships with aggregators, more control over what is shared, and the ability to terminate the relationship.46 We have spoken to data aggregators who recognize the importance of finding solutions to many of the complex issues involved with the important work of unlocking the potential of the banking stack to developers. And while there are some difficult issues in this space, other issues seem relatively straightforward. It shouldn't be hard for a consumer to be informed who they are providing their credentials to. Consumers should have relatively simple means of being able to consent to what data are being shared and at what frequency. And consumers should be able to stop data sharing and request the deletion of data that have been stored.\n\nResponsibility for establishing appropriate norms in the data aggregation space should be shared, with banks, data aggregators, fintech developers, consumers, and regulators all having a role.47 Banks and data aggregators are negotiating new relationships to determine how they can work together to provide consumers access to their data, while also ensuring that the process is secure and leaves consumers in the driver's seat.48 In many cases, banks themselves were often the original customers of data aggregators, and many continue to use these services. According to public filings, more than half of the 20 largest banks are customers of data aggregators.49 The banks have an opportunity as customers of data aggregation services to ensure that the terms of data provision protect consumers' data and handle it appropriately.\n\nRegulators also recognize that there may be opportunities to provide more clarity about how the expectations about third-party risk management would work in this sector, as well as other areas experiencing significant technological change. Through external outreach and internal analysis, we are working to determine how best to encourage socially beneficial innovation in the marketplace, while ensuring that consumers' interests are protected. We recognize the importance of working together and the potential to draw upon existing policies, norms, and principles from other spaces. Consumers may not fully understand the differences in regulations across financial products or types of financial institutions, or whether the rules change when they move from familiar search and e-commerce platforms to the fintech stack. Consumers, as well as the market as a whole, will benefit if regulators coordinate to provide more unified messages and support the development of standards that serve as a natural extension of the common-sense norms that consumers have come to expect in other areas of the commercial internet.\n\nConclusion\nThe combination of technologies that put vast computing power, rich data sets, and artificial intelligence onto simple smartphone apps together with important research into consumer financial behaviors has great potential to help consumers navigate their complex financial lives more effectively, but there are also important risks. I am hopeful that fintech developers, data aggregators, bank partners, consumers, and regulators will work together to keep consumers in the driver's seat as we move forward with these new technologies. If we work together effectively toward this goal, the fintech stack may be able to offer enormous benefits to the consumers they aim to serve, while appropriately identifying and managing the risks.\n\n1. I am grateful to Kelvin Chen for his assistance in preparing this text. The remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See Lael Brainard, \"The Opportunities and Challenges of Fintech (PDF),\" (speech at the Conference on Financial Innovation, Washington, D.C., December 2, 2016). Return to text\n\n3. See, e.g., Damaris Olaechea, \"Who Issued the First Credit Card?\" Nerd Wallet (February 12, 2014), www.nerdwallet.com/blog/credit-cards/issued-first-credit-card/. Return to text\n\n4. See, e.g., Consumer Financial Protection Bureau, The Consumer Credit Card Market (PDF), Executive Summary December 2015, and Federal Reserve Bank of New York, August 2017, www.newyorkfed.org/medialibrary/interactives/householdcredit/data/pdf/HHDC_2017Q2.pdf. Return to text\n\n5. See J.D. Power, \"Attractive Rewards and Benefits Drive Credit Card Selection, Satisfaction and Spend,\" press release, August 20, 2015, www.jdpower.com/sites/default/files/2015137_U.S._Credit_Card_Study_PR_Final.pdf. Return to text\n\n6. See, e.g., Jeanine Skowronski, \"Why 5 Percent Cash Back Is an Overrated Selling Point,\" American Banker, November 6, 2013, www.americanbanker.com/opinion/why-5-cash-back-is-an-overrated-selling-point. Consumer Financial Protection Bureau, The Consumer Credit Card Market (PDF), section 7, December 2015. Return to text\n\n7. See, e.g., Consumer Financial Protection Bureau, The Consumer Credit Card Market (PDF), section 6, December 2015. Return to text\n\n8. Id at section 5.1.2. Return to text\n\n9. In 2007 researchers at Carnegie Mellon estimated that it would take the average consumer 244 hours a year just to read the privacy policies of the websites that he viewed that year. Aleecia McDonald and Lorrie Faith Cranor, The Cost of Reading Privacy Policies,\" I/s: A Journal of Law and Policy for the Information Society (2008), pre-press version available at http://lorrie.cranor.org/pubs/readingPolicyCost-authorDraft.pdf. Return to text\n\n10. Federal Deposit Insurance Corporation, FDIC National Survey of Unbanked and Underbanked Households (PDF), (2015). Return to text\n\n11. See, e.g., Michael Corkery and Stacy Cowley, \"Household Debt Makes a Comeback in the U.S.,\" New York Times, May 17, 2017, www.nytimes.com/2017/05/17/business/dealbook/household-debt-united-states.html; See Alexei Alexandrov and Sergei Koulayev, \"No Shopping in the U.S. Mortgage Market: Direct and Strategic Effects of Providing Information,\" Consumer Financial Protection Bureau Office of Research Working Paper No. 2017-01 (Washington: CFPB, April 7, 2017), https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2948491. (\"[M]any consumers do not seem to realize that there is price dispersion. . . . In one of our counterfactuals, we show that eliminating non-price preferences results in savings of about $9 billion dollars a year.\") Return to text\n\n12. See, e.g., Michael Corkery and Stacy Cowley, \"Household Debt Makes a Comeback in the U.S.,\" New York Times, May 17, 2017, www.nytimes.com/2017/05/17/business/dealbook/household-debt-united-states.html. (\"Student borrowers today owe $1.3 trillion, more than double the $611 billion owed nearly nine years ago. About one in 10 student borrowers is behind on repaying the loans, the highest delinquency rate of any type of loan tracked by the New York Fed's quarterly household debt report.\"); Jesse Bricker, Lisa J. Dettling, Alice Henriques, Joanne W. Hsu, Lindsay Jacobs, Kevin B. Moore, Sarah Pack, John Sabelhaus, Jeffrey Thompson, and Richard A.Windle, \"Changes in U.S. Family Finances from 2013 to 2016: Evidence from the Survey of Consumer Finances (PDF),\" Federal Reserve Bulletin vol. 103, no. 3 (September 2017). Return to text\n\n13. Federal Reserve Bank of New York, Quarterly Report on Household Debt and Credit (PDF), August 2017. ( \"...[D]elinquency rates for student loans are likely to understate effective delinquency rates because about half of these loans are currently in deferment, in grace periods or in forbearance and therefore temporarily not in the repayment cycle. This implies that among loans in the repayment cycle delinquency rates are roughly twice as high.\" Id. n.2 ). Return to text\n\n14. This can be particularly challenging for older consumers. See, e.g., AARP, \"Financial Innovation Frontiers (PDF),\" April 2017. (\"50+ Consumers Face Unprecedented Financial Complexity.\") Return to text\n\n15. Board of Governors of the Federal Reserve System, Report on the Economic Well-Being of U.S. Households in 2016 (PDF) (Washington: Board of Governors, May 2017). Return to text\n\n16. Id. Return to text\n\n17. See, e.g., Krista Tippett, On Being, radio interview with Daniel Kahneman, October 5, 2017. (\"...[It] is actually completely not possible for a finite human mind to be rational or to obey the axioms of rationality. You'd have to know too much . . . [T]he cognitive rules are, to a large extent, simplifying rules. They are shortcuts.\") Return to text\n\n18. See, e.g., David Laibson, Andrea Repetto, and Jeremy Tobacman, \"Estimating Discount Functions with Consumption Choices over the Lifecycle (PDF),\" National Bureau of Economic Research Working Paper 13314 (Cambridge, Mass.: NBER, August 2007). Return to text\n\n19. See, e.g., John Beshears, James J. Choi, David Laibson, and Bridgitt C. Madrian, \"Simplification and Saving (PDF),\" National Bureau of Economic Research Working Paper 12659 (Cambridge, Mass.: NBER, 2006). (\"Many financial decisions that individuals face are complicated and daunting for those who are not financial experts. .By collapsing a multidimensional set of options into a binary choice between the status quo and the pre-selected alternative, this intervention increases participation rates by 10 to 20 percentage points among affected employees.\"); Sheena S. Iyengar, Wei Jiang, and Gur Huberman, \"How Much Choice is Too Much?: Contributions to 401(k) Retirement Plans (PDF),\" Pension Research Council Working Paper (Philadelphia: University of Pennsylvania, The Wharton School, PRC, 2003). (\"Using data from nearly 800,000 employees, …[our] results confirm that participation in 401(k) plans is higher in plans offering a handful of funds, as compared to plans offering ten or more options.\") Return to text\n\n20. See, e.g., Daniel Navarro-Martinez, et al., \"Minimum Required Payment and Supplemental Information Disclosure Effects on Consumer Debt Repayment Decisions,\" Journal of Marketing Research, vol. 48 (November 2011), http://journals.ama.org/doi/pdf/10.1509/jmkr.48.SPL.S60?code=amma-site. (\"They find that while presenting minimum required payment information has a negative impact on repayment decisions, increasing the minimum required level has a positive effect on repayment for most consumers.\") See, e.g., Bridgette C. Madrian, \"Matching Contributions and Savings Outcomes: A Behavioral Economics Perspective (PDF),\" National Bureau of Economic Research Working Paper 18220 (Cambridge, Mass.: NBER, July 2012). (\"Indeed, automatic enrollment is an extreme form of simplification; individuals who want to save need not do anything. Psychologists have long recognized that choice complexity can affect decision-making outcomes. One result is procrastination--individuals put off decision making as choices become more complicated.\") (Internal citations omitted.) Return to text\n\n21. See, e.g., Dean S. Karlan, et al, \"Getting to the Top of Mind: How Reminders Increase Savings,\" National Bureau of Economic Research Working Paper 16205, (Cambridge, Mass.: NBER, July 2010). See, e.g., Jialan Wang and Benjamin J. Keys, \"Perverse Nudges: Minimum Payments and Debt Paydown in Consumer Credit Cards,\" Penn Wharton Public Policy Initiative Issue Brief, vol. 2. no. 4 (Philadelphia: University of Pennsylvania, April 2014), https://publicpolicy.wharton.upenn.edu/issue-brief/v2n4.php. Return to text\n\n22. See, e.g., Lael Brainard, \"Where Do Banks Fit in the Fintech Stack (PDF),\" (speech at Northwestern Kellogg Public–Private Interface Conference on New Developments in Consumer Finance: Research and Practice). Return to text\n\n23. Board of Governors of the Federal Reserve System, Consumers and Mobile Financial Services 2016 (PDF), (Washington, Board of Governors, March 2016). The survey found that 40 percent of the unbanked population and 70 percent of the underbanked and banked populations had access to a smartphone. Return to text\n\n24. See Bank of America, Trends in Consumer Mobility Report, 2015, http://newsroom.bankofamerica.com/files/doc_library/additional/2015_BAC_Trends_in_Consumer_Mobility_Report.pdf. (Finding that 35 percent of survey respondents reported that they reach for their mobile devices first thing, as compared to 10 percent for their significant other.) Return to text\n\n25. Board of Governors of the Federal Reserve System, Consumers and Mobile Financial Services 2016 (PDF) . Return to text\n\n26. Id. Return to text\n\n27. See, e.g., Blair Hanley Frank, \"Meet Google's Cool New Natural Language Tool, Parsey McParseface,\" Computerworld, May 12, 2016, www.computerworld.com/article/3070059/artificial-intelligence/meet-googles-cool-new-natural-language-tool-parsey-mcparseface.html. See also Google Research Blog, \"TensorFlow--Google's Latest Machine Learning System, Open Sourced for Everyone,\" November 9, 2015, https://research.googleblog.com/2015/11/tensorflow-googles-latest-machine_9.html. Cf. Tom Simonite, \"Facebook Quietly Enters Starcraft War for AI Bots, and Loses,\" Wired, October 9, 2017, www.wired.com/story/facebook-quietly-enters-starcraft-war-for-ai-bots-and-loses/. Return to text\n\n28. See, e.g., Lael Brainard, \"Where Do Banks Fit in the Fintech Stack (PDF),\" (speech at Northwestern Kellogg Public–Private Interface Conference on New Developments in Consumer Finance: Research and Practice). Return to text\n\n29. See, e.g., Envestnet Yodlee, \"Envestnet Yodlee Unveils Personal Financial Wellness Solution Powered by Data Intelligence,\" news release, June 12, 2017, www.prnewswire.com/news-releases/envestnet--yodlee-unveils-personal-financial-wellness-solution-powered-by-data-intelligence-300472018.html. Return to text\n\n30. See, e.g., Brett Theodos, et al., An Evaluation of the Impacts and Implementation Approach of Financial Coaching Programs (PDF) (Washington: Urban Institute, October 2015). Return to text\n\n31. Consumer Financial Protection Bureau, The Consumer Credit Card Market (PDF) (Washington: CFPB, December 2015). Return to text\n\n32. Trevor Bakker, Nicole Kelly, Jesse Leary, and Eva Nagypal, Data Point: Checking Account Overdraft (PDF), Consumer Financial Protection Bureau report (Washington: CFPB, July 2014). Likewise, one out of five new payday loans are rolled over six times or more. Kathleen Burke, Jonathan Lanning, Jesse Leary, and Jialan Wang, Data Point: Payday Lending (PDF), Consumer Financial Protection Bureau report (Washington: CFPB, March 2014). Return to text\n\n33. See, e.g., Phil Patton, \"Buy Here, and We'll Tell You What You Like,\" New York Times, September 22, 1999, https://partners.nytimes.com/library/tech/99/09/biztech/technology/22patt.html?mcubz=1. Return to text\n\n34. See, e.g., John Lanchester, \"You Are the Product,\" London Review of Books, vol. 39, no. 16-17, August 17, 2017, www.lrb.co.uk/v39/n16/john-lanchester/you-are-the-product. Cf., Monica Anderson, \"Key Takeaways on Mobile Apps and Privacy,\" Pew Research Center FactTank, November 10, 2015, www.pewresearch.org/fact-tank/2015/11/10/key-takeaways-mobile-apps/. Return to text\n\n35. See, e.g., Nathaniel Popper, \"Automated Assistants Will Soon Make a Bid for Your Finances,\" New York Times, December 7, 2016, www.nytimes.com/2016/12/07/business/dealbook/automated-assistants-will-soon-make-a-bid-for-your-finances.html. Return to text\n\n36. Cf., Federal Trade Commission, \"Mary Engle Letter to Search Engine Providers (PDF),\" n.4, June 24, 2013; Federal Trade Commission, \"FTC Consumer Protection Staff Update Agency's Guidance to Search Engine Industry on the Need to Distinguish Between Advertisements and Search Results,\" press release, June 25, 2013; Federal Trade Commission, \"Commercial Alert Response Letter,\" June 27, 2002. Return to text\n\n37. Cf., Federal Trade Commission, \"Mary Engle Letter to Search Engine Providers (PDF),\" n.4, June 24, 2013. Return to text\n\n38. Cf., Federal Trade Commission, \"The FTC's Endorsement Guides: What People Are Asking,\" September 2017, \".com Disclosures: How to Make Effective Disclosures in Digital Advertising (PDF),\" March 2013. Return to text\n\n39. See, e.g., Finicity, \"Finicity and Wells Fargo Ink Data Exchange Deal,\" press release, April 4, 2017, www.finicity.com/press-release-finicity-wells-fargo-ink-data-exchange-deal/; Wells Fargo & Co., \"Intuit Signs New Data-Exchange Agreement with Wells Fargo,\" press release, February 3, 2017, www.wellsfargo.com/about/press/2017/intuit-agreement_0203/; Intuit, \"Chase, Intuit to Give Customers Greater Control of Their Information,\" press release, January 25, 2017, www.intuit.com/company/press-room/press-releases/2017/Chase-Intuit-to-Give-Customers-Greater-Control-of-Their-Information/; Wells Fargo & Co., \"Wells Fargo, Xero Agree on New Data-Exchange Method,\" press release, June 7, 2016, www.wellsfargo.com/about/press/2016/new-dataexchange-method_0607/; Silicon Valley Bank, \"Xero and Silicon Valley Bank Partner to Offer Innovative Companies Next-Generation Financial Management,\" press release, July 16, 2014, www.svb.com/News/Company-News/Xero-and-Silicon-Valley-Bank-Partner-to-Offer-Innovative-Companies-Next-Generation-Financial-Management/. Return to text\n\n40. See, e.g., Penny Crosman, \"Data-Sharing Debate Grows Contentious as Fintechs Vent Grievances,\" American Banker, August 15, 2017, www.americanbanker.com/news/data-sharing-debate-grows-contentious-as-fintechs-vent-grievances. Return to text\n\n41. See 12 CFR section 1005.2(m) (1). (Excluding from the definition of \"unauthorized electronic fund transfer\" any \"electronic fund transfer initiated… [by] a person who was furnished the access device to the consumer's account by the consumer…..\") Return to text\n\n42. Comment 2(m)-2 clarifies that if \"a consumer furnishes an access device and grants authority to make transfers to a person . . . who exceeds the authority given, the consumer is fully liable for the transfers unless the consumer has notified the financial institution that transfers by that person are no longer authorized.\" Return to text\n\n43. See Kaitlin Asrow and Beth Brockland, Liability, Transparency and Consumer Control in Data Sharing (Washington: Center for Financial Services Innovation, September 18, 2017). (\"There are differing interpretations of how regulations, such as the OCC's Third Party Risk Management guidance, the Gramm-Leach-Bliley Act's privacy and safeguard rules, and Regulation E liability limits, should be applied to data sharing between financial institutions and third parties like data aggregators and financial technology applications.\")\n\nSee also JPMorgan Chase, \"How You Can Protect Yourself,\" (last visited October 18, 2017), www.chase.com/digital/resources/privacy-security/security/how-you-can-protect>; Liz Weston, \"Why Banks Want You to Drop Mint, Other 'Aggregators,'\" Reuters, November 9, 2015, www.reuters.com/article/us-column-weston-banks/why-banks-want-you-to-drop-mint-other-aggregators-idUSKCN0SY2GC20151109. Return to text\n\n44. See, e.g., Board of Governors of the Federal Reserve System, \"Guidance on Managing Outsourcing Risk (PDF),\" SR letter 13-19/CA letter 13-21, December 5, 2013. Return to text\n\n45. See, e.g., American Express, \"Introducing the Amex Skill for Amazon Alexa\" (last visited October 18, 2017), www.americanexpress.com/us/content/alexa/.; Leena Rao, \"American Express Debuts Its First Amazon Alexa Skill,\" Fortune, May 11, 2017, http://fortune.com/2017/05/11/american-express-alexa-skill/; Capital One, \"CapitalOne is on Amazon Echo\" (last visited October 18, 2017), www.capitalone.com/applications/alexa/. Return to text\n\n46. See, e.g., Consumer Financial Protection Bureau, \"Consumer Protection Principles: Consumer-Authorized Financial Data Sharing and Aggregation (PDF),\" October 18, 2017; Kaitlin Asrow and Beth Brockland, Liability, Transparency and Consumer Control in Data Sharing, Center for Financial Services Innovation, September 18, 2017. Return to text\n\n47. Cf. Kaitlin Asrow and Beth Brockland, Liability, Transparency and Consumer Control in Data Sharing, Center for Financial Services Innovation, September 18, 2017. Return to text\n\n48. See, e.g., Penny Crosman, \"Data-Sharing Debate Grows Contentious as Fintechs Vent Grievances,\" American Banker, August 15, 2017, www.americanbanker.com/news/data-sharing-debate-grows-contentious-as-fintechs-vent-grievances. Return to text\n\n49. Envestnet, Inc., Form 10-K, March 17, 2017, www.envestnet.com/report/2016/download/Envestnet-2016AnnualReport-Form10-K.pdf. Return to text"
    },
    {
        "title": "Regional Food Systems and Community Development",
        "date": "November 15, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20171115a.htm",
        "content": "November 15, 2017\n\nGovernor Lael Brainard\n\nAt a Federal Reserve Bank of Boston Regional Food Systems Meeting, Boston, Massachusetts\n\nThank you for inviting me. I appreciate the opportunity to listen and learn about the important work that you do.1\n\nOne of the Federal Reserve's responsibilities is to understand how communities across America are experiencing the economy. That is why Congress established a network of Federal Reserve Banks and Branches across the country. Our local presence gives us valuable opportunities to engage with communities across a broad spectrum--from those who are thriving to those who are confronting challenges, and from inner-city neighborhoods to rural towns.\n\nOne of the lessons that our community engagement has taught us is that there is an important connection between the strength of regional food systems and community health. Today's meeting is one in a series that Federal Reserve Banks are holding across the country to talk about local efforts to support regional food systems, and how such efforts can advance communities' goals. These meetings build on the Federal Reserve Board's release last August of Harvesting Opportunity, a publication that explores the community and economic development potential of investing in regional food systems.2 Through this collaborative research effort, we learned several important lessons about what works to strengthen regional food systems.\n\nFirst, we learned that appropriately tailored investments in regional food systems have the potential to support the creation of new jobs and small businesses in local communities, as well as to improve farm profitability and financial resilience.\n\nSecond, we learned that in order to take advantage of new business opportunities in the regional food sector, entrepreneurs need access to capital, specialized knowledge, and general business skills. Unfortunately, one or more of these is often missing from historically marginalized communities.\n\nWe also learned that organizations across the country are filling these gaps and empowering communities to take advantage of opportunities. I understand that many of you in this room are engaged in this important work; for that I thank you and hope that this meeting will help advance your efforts.\n\nAs a result of an intentional focus on equity and inclusiveness, these investments can create new access to economic opportunity for segments of communities that have often faced challenges, such as people of color, recent immigrants, the formerly homeless, and the previously incarcerated.\n\nLastly, we learned that no organization has all of the resources or expertise necessary to effectively carry out this work alone. As such, long-term partnerships and collaboration are necessary for success in implementing regional food strategies. Because of the critical role of multi-sectoral partnerships, I am heartened to see so many of you here today to talk about the current state of regional food system investment in New England, to build new relationships, and to strengthen existing ones. It is this ongoing commitment to working together that will carry you through to the next stage of regional food systems development.\n\nLater today, I will be meeting with several local organizations that not only bring important resources and expertise to their communities, but also exemplify this important dedication to partnership and cross-sector collaboration.\n\nThe Urban Farming Institute of Boston demonstrates dedication to cross-sector collaboration through their Farmer Training Program, many of whose graduates go on to work for or start up regional food enterprises. They also advance the broader regional food system by co-hosting an annual conference that brings together farmers, policymakers, investors, and other stakeholders.\n\nLikewise, CommonWealth Kitchen has emerged as an important hub where farmers, entrepreneurs, universities, investors, and other stakeholders come together in ways that not only advance regional food systems, but also increase access to economic opportunity for people impacted by racial, social, or economic inequality. In this way, CommonWealth Kitchen is dedicated to addressing Greater Boston's growing wealth divide by promoting inclusive entrepreneurship through an integrated approach that links education, training, and manufacturing to a strong network of industry partners, including anchor institutions.\n\nThese are just two examples of the great work going on in New England, and I look forward to visiting both organizations later today. This morning, I am eager to learn about the work of the many organizations represented here, especially the barriers and opportunities you face when trying to invest in this sector, and how your investments are linking more families and communities to meaningful economic opportunities.\n\nAttending events like this and visiting communities around the country provide me with opportunities to speak with families, farmers, small business owners, investors, bankers, and other community members about their experiences in the economy. These conversations help me to develop a granular and very human understanding of the economy that, when combined with the information provided by our traditional research and data collection efforts, are important considerations informing judgments about policy.\n\nA community-level understanding of the economy is especially important in today's economy, where we see welcome strength in the aggregate statistics coexisting side-by-side with important disparities at the community and family levels. In addition to disparities based on the community where a family lives and significant and persistent racial disparities, I have been struck while traveling around the country by the widening gulf between the economic fortunes of our large metropolitan areas and those of our small cities, towns, and rural areas.\n\nThe statistics bear this out: the convergence in income across regions of the country has slowed dramatically over recent decades.3 Much of the gains in employment, income, and wealth since the end of the recession--and more broadly over the past few decades--have accrued to workers and families in larger cities. If some workers and families find it difficult to move, this concentration of economic opportunities in larger cities may have adverse implications for the well-being of these households and, potentially, the economy overall.\n\nIn my visits, I have also been heartened by the efforts of local partners to address these disparities and improve their communities, including those aimed at capitalizing on local food-based assets to advance economic opportunity and address food insecurity. For instance, in El Paso, I visited with several vibrant community organizations that were running community gardens, local nutrition and farming educational outreach programs, a commercial kitchen, and a food pantry to improve nutrition and access to fresh food in an area that lacked full-scale grocery stores. In the Mississippi Delta, I met with people involved in an interesting collaboration between a local entrepreneur, a community development financial institution, the engineering department of a local community college, local farmers, and local food organizations--the aim of which was to produce biofuels from food waste.\n\nOf course, pockets of both opportunity and persistent poverty are found in large metro and rural areas alike. In fact, a recent report found Boston to have one of the highest rates of income inequality among the 100 largest metropolitan areas in the United States, despite the overall strength of Boston's economy.4 Findings like this remind us that not all communities are well positioned to access the opportunities available in the economy, even those in their own backyard.\n\nOur research suggests there are things that can be done to improve the likelihood that an area will be a community of opportunity. Some localities have fared better than others in this respect, and their successes can provide us with actionable lessons. For instance, the Federal Reserve Bank of Boston undertook an in-depth study of 25 medium-sized cities nationwide that had experienced a post-industrial decline and identified 10 that experienced an economic resurgence. The study found that the critical determinant of success was the ability of leaders in those cities to collaborate across sectors around a long-term vision for revitalization.5 To encourage such collaboration, the Boston Fed has facilitated Working Cities Challenges in Massachusetts, Rhode Island, and Connecticut that reward effective public–private collaboration to reach communitywide goals. For instance, one of the winning cities, Lawrence, Massachusetts, set goals of increasing the income of parents with children in the Lawrence Public School system by 15 percent, dramatically increasing parental engagement in the schools and tracking the impact of these efforts on student achievement. A cross-section of partners from the public, private, nonprofit, and philanthropic sectors sought to achieve this, in part, by embedding Family Resource Centers within the Lawrence Public Schools. To-date, these efforts have placed over 200 parents in new positions paying 25 percent higher wages on average than their previous jobs, with 200 more parents in the training pipeline.\n\nLearning about what works reinforces for me the importance of events like this one: events that bring together different stakeholders to talk about the future of their communities and how they can work together to advance common goals.\n\nThank you for being our valued partners in this important work.\n\n1. I am grateful to Andrew Dumont for his assistance in preparing these remarks. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. A. Dumont, D. Davis, J. Wascalus, T. Cheeks Wilson, J. Barham, and D. Tropp. Harvesting Opportunity: The Power of Regional Food System Investments to Transform Communities (St. Louis: Federal Reserve Bank of St. Louis and Board of Governors of the Federal Reserve System, 2017). Return to text\n\n3. P. Ganong, and D.W. Shoag. \"Why Has Regional Income Convergence in the U.S. Declined?\" National Bureau of Economic Research Working Paper No. 23609 (Cambridge, Mass: NBER, 2017). Return to text\n\n4. Natalie Holmes and Alan Berube. \"City and Metropolitan Inequality on the Rise, Driven by Declining Incomes.\" (Washington: Brookings Institution, January 2016). Return to text\n\n5. Y.K. Kodrzycki, A.P. Muñoz, L. Browne, D. Green, M. Benton, P. Chakrabarti, D. Plasse, R. Walker, and B. Zhao. \"Reinvigorating Springfield's Economy: Lessons from Resurgent Cities,\" Federal Reserve Bank of Boston Community Affairs Discussion Paper No. 2009-03 (Boston: Federal Reserve Bank of Boston, 2009). Return to text\n\n "
    },
    {
        "title": "Remarks accepting the 2017 Paul H. Douglas Award for Ethics in Government",
        "date": "November 07, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20171107a.htm",
        "content": "November 07, 2017\n\nChair Janet L. Yellen\n\nAt the Institute of Government and Public Affairs at the University of Illinois, Washington, D.C.\n\nThank you for the honor of sharing this award with such a worthy person, my friend and former colleague Ben Bernanke, and also for the honor of being associated with the exemplary life and legacy of Paul Douglas.\n\nSen. Douglas's contributions to ethics in government are an important aspect of that legacy, but since Ben and I are the first economists to win this award, I would also like to give due credit to Professor Douglas for his contributions to economics.\n\nWorking with the mathematician Charles Cobb, Douglas gathered data and created a statistical model that advanced economists' understanding of the relative contributions to production made by capital and labor. This work demonstrated many of the methods that economists would come to use and continue to use to this day. Douglas constructed empirical measures of key economic concepts. He then employed what were, for the time, advanced statistical techniques to analyze these data, thereby shedding light on a basic economic relationship. As one recent commentator put it, work such as Douglas's was part of \"a growing literature , , , [that] played an important role in shaping the approach to combining statistical methods and economic theory that would become the standard econometric practice in the later decades of the 20th century.\"1\n\nBut, of course, Paul Douglas was much more than an economist. From an early age, he always seemed to be the man in the middle, seen by the two sides of a dispute as intelligent, knowledgeable, and impartial enough to be trusted to seek a solution. He mediated labor disputes and advised local government officials in Illinois. He also helped governors in Pennsylvania and New York develop what became Social Security, unemployment insurance, and the idea of publicly owned power utilities. After losing his first election for the U.S. Senate in 1942, at the age of 49 he enlisted in the U.S. Marines and was awarded a Bronze Star and Purple Heart for his service in the Pacific. Later, after he was elected to the Senate, Douglas was a champion of consumer protection laws, including the 1968 Truth in Lending Act, and was a leading supporter of civil rights legislation.\n\nOne of Paul Douglas's most important achievements in public life was to promote ethics in government. He was raised with a strong sense of right and wrong and was heavily influenced by the philosopher John Stuart Mill to believe that ethical behavior was also an eminently practical approach to life. As a college professor, he entered public life in Chicago in the 1920s somewhat reluctantly to fight the spectacular political and commercial corruption that was strangling the city. Once elected to office, he faced the challenge of how to act ethically when corruption was so universal that the city's aldermen were expected to funnel large sums to their constituents, based on the presumption that all politicians were \"on the take.\" If he refused bribes and then had no money to hand out, how would he convince people that he wasn't simply refusing to share?\n\nThe key was transparency and communication. Everyone who asked for a large payment was handed a mimeographed statement titled \"Please Help Me to Be an Honest Alderman.\" At first, the public, inured to corruption, either disbelieved him or thought him a sucker for refusing to take bribes. But over time, Douglas's stand changed both the demands made by supplicants and his constituents' expectations for ethical behavior by a government official.\n\nSimilarly, in 1939, Paul Douglas was one of the first public officials in America to publish a full accounting of his personal finances. In his memoir, Douglas admits that this and other ethical rules he imposed on himself were often a nuisance and, in some cases, probably went further than needed to demonstrate his honesty. But he believed that the public's trust was so fundamental to the effectiveness of government that such steps were appropriate. As a senator, he continued to publish his finances and observed strict limits on the value of personal gifts he received from those seeking benefits from him as a public official. He strongly believed that these gift limits also made him more effective as a public servant, and he campaigned for legislation that ultimately led to the widespread requirement of financial disclosure and limits on accepting gifts.\n\nI share Paul Douglas's view that behaving ethically is both the right thing to do and, in practical terms, helps maintain the trust the public places in those who act on its behalf. The Federal Reserve's very effectiveness in setting monetary policy depends on the public's assured confidence that we act only in its interest. We must act ethically, and we must demonstrate our ethical standards in ways that leave little room for doubt.\n\nI am grateful to share this award with Ben, and I am even more grateful for the example Paul Douglas set for ethics in government that has guided countless public officials since his day and also shaped the public's expectation that its leaders will put the public's interests first.\n\n1. See p. 228 in Jeff Biddle (2012), \"Retrospectives: The Introduction of the Cobb-Douglas Regression,\" Journal of Economic Perspectives, vol. 26 (Spring), pp. 223-36. Return to text"
    },
    {
        "title": "Introductory Remarks",
        "date": "November 02, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20171102a.htm",
        "content": "November 02, 2017\n\nGovernor Jerome H. Powell\n\nAt the Roundtable of the Alternative Reference Rates Committee, The Federal Reserve Bank of New York, New York, New York (via prerecorded video)\n\nGood morning. I am sorry that I am not able to be with you today at the FRBNY for this important meeting. I thought that I would begin by discussing the LIBOR related events that have brought us here, and then talk about the way forward.\n\nLIBOR gained negative public attention when reports began to surface during the financial crisis that employees at some banks had attempted to manipulate the rate by altering the quotes they submitted for use in the calculation of LIBOR. A number of agencies, including the Commodity Futures Trading Commission (CFTC), the Department of Justice, and the U.K. Financial Conduct Authority (FCA), took the lead in investigating and prosecuting the cases of LIBOR manipulation that were uncovered. The Federal Reserve also joined in international efforts to strengthen LIBOR. Among other things, we joined the ICE Benchmark Administration's (IBA's) LIBOR Oversight Committee as an observer, and we also worked intensively with international authorities and IBA in developing and encouraging the reforms set out in IBA's Roadmap for LIBOR.\n\nBut at the same time, as we and other authorities collected data on the transactions underlying banks' submissions to LIBOR, we began to see that those transactions were relatively few and far between. As a result, many began to question whether LIBOR could be truly and permanently fixed. To be sure, much has been done to address the cases of attempted manipulation, and LIBOR has much stronger governance in place than it did before the crisis. The question instead was whether there were enough actual LIBOR transactions to form a stable basis for this critical rate.\n\nSince many of the pressures around LIBOR stem from the low level of underlying transactions, let me share some data regarding activity in U.S. dollar wholesale funding markets. Today, there are 17 banks that submit quotes in support of dollar LIBOR. Some have suggested requiring more banks to submit LIBOR data, but doing so would not materially improve the situation. The panels in Figure 1 show the distribution of daily aggregate wholesale dollar funding volumes for the 30 global systemically important banks (or GSIBs). The data here include all of the Eurodollar, federal funds, CD, and commercial paper transactions that the Federal Reserve has access to--the most complete picture of U.S. dollar unsecured funding that I am aware of. For one-month funding, shown in the top panel, the median daily volume of transactions by these banks since money-market reforms took effect last year was just over $1 billion. For three-month funding (the middle panel), the most heavily referenced LIBOR tenor, the median is less than $1 billion per day. On some days we see less than $100 million. If we compare this to the more than $100 trillion in outstanding volumes of U.S. dollar LIBOR contracts, it should be clear that the activity in this market is miniscule compared to the size of the contracts written on it.\n\nIn our view, it would not be feasible to produce a robust, transaction-based rate constructed from the activity in wholesale unsecured funding markets. A transactions-based rate from this market would be fairly easy to manipulate given such a thin level of activity, and the rate itself would likely be quite volatile. Thus, LIBOR seems consigned to rely primarily on some form of expert judgment rather than direct transactions.\n\nAs we discussed these issues with the officials in the United Kingdom who oversee and regulate LIBOR, we also became aware that they were receiving a steady stream of requests, and sometimes demands, from banks seeking to leave the LIBOR panels. The use of expert judgment in submissions allows LIBOR to be published every day, but many banks are now understandably uncomfortable with being asked to provide judgment about something that they do very little of. In his July speech, Andrew Bailey discussed the efforts of the FCA to keep these banks on the panels. Market participants should understand that the official sector has done everything it can to stabilize and strengthen LIBOR. Without the intervention of U.K. authorities, LIBOR would be in a weaker state today.\n\nBut that balancing act has grown increasingly difficult. As time has passed, some banks have grown more resistant to public-sector entreaties to remain on the panels. As you know, one bank left the U.S. dollar panel last year. At the same time, we have had to confront the fact that, if banks could not be persuaded to voluntarily remain on panels, then the legal powers to compel them to do so were limited. Under European Union benchmark regulations, which LIBOR will soon be subject to, authorities can only compel submissions to a critical benchmark for a period of two years. Given this time limit, brokering a voluntary agreement with the submitting banks to stay on for a longer period was the last, best choice that authorities had available to guarantee some further period of stability for LIBOR. CFTC Chairman Chris Giancarlo and I have publicly supported the FCA's efforts to secure an agreement with the submitting banks to stay on through the end of 2021, and we have encouraged the U.S. banks that submit to LIBOR to cooperate with FCA's effort.\n\nOf course, LIBOR may remain viable well past 2021, but we do not think that market participants can safely assume that it will. Users of LIBOR must now take in to account the risk that it may not always be published. While the public's understanding of this risk has increased significantly since Andrew Bailey's speech, the official sector has been concerned about it for some years, as reflected for example in our public comments and in the annual reports of the Financial Stability Oversight Council. Given our understanding of the risks to LIBOR, the Federal Reserve convened the Alternative Reference Rates Committee (or ARRC) in 2014 in cooperation with the Treasury Department and CFTC. Consistent with recommendations from the Financial Stability Board (FSB), we charged the ARRC with identifying a robust alternative to U.S. dollar LIBOR and with developing a plan to encourage its use in some derivatives and other transactions as appropriate.\n\nThe ARRC has accomplished the things that we asked of it. I want to thank the members for their work and also to extend my special thanks to Sandie O'Connor as the chair of the ARRC. Sandie will discuss the ARRC's work shortly, but I'll make a few points.\n\nFirst, I'd note that, like most market participants, the ARRC members initially had a difficult time conceiving of any kind of transition from LIBOR. As is the case for all of you, a transition will be a complicated task for the broker-dealers and other members of the ARRC, and will involve significant costs. Over time, however, I think the ARRC members have developed a greater understanding of the risks to LIBOR and now see that, despite those complications and costs, a transition may prove necessary. I also think that, having had time to consider the transition plans that Sandie will talk about, ARRC members have become more comfortable with the idea that a transition is feasible, even if the necessity of achieving it is regrettable.\n\nSecond, it is clear that any rate the ARRC selected as a potential alternative needed to be highly robust. There would be no point in selecting a rate that might find itself quickly in the same kinds of conditions that LIBOR is in now. In our view, the ARRC has chosen the most robust rate available. In general, only overnight unsecured or secured funding markets appeared to have enough underlying transactions to produce a robust rate. The overnight Treasury repo market is the largest and most active market in any tenor of U.S. rates markets. Figure 2 illustrates the point: the transactions underlying the Secured Overnight Financing Rate (SOFR), at about $700 billion per day or more, are much larger than the volumes in overnight unsecured markets, even much larger than estimates of the volume in Treasury bills, and they dwarf the volumes in other term markets. The alternative reference rate needs to be able to stand the weight of having trillions of dollars written on it, and the ARRC has definitely met this standard in choosing SOFR.\n\nThird, we charged the ARRC with devising plans for a voluntary transition that encouraged the use of their recommended rate where appropriate. We have never told anyone that they cannot use LIBOR. The ARRC did consider whether other cash products could move from LIBOR to the rates it evaluated, but their paced transition plan has focused on derivatives because that is where the largest gross exposures to LIBOR are, and because it may be easier for many derivatives transactions to move away from LIBOR to a new rate.\n\nNow, however, market participants have realized that they may need to more seriously consider transitioning other products away from LIBOR, and the ARRC has expanded its work to help ensure that this can be done in a coordinated way that avoids unnecessary disruptions. Sandie will discuss plans to eventually create a term reference rate, which may help to smooth any transition. That term reference rate would have to be built by first developing futures and OIS markets that reference SOFR. It will likely never be as robust as SOFR itself, and so derivatives transactions will almost certainly need to be based on the overnight rate, but a term reference rate could conceivably be used in some loan or other contracts that currently reference LIBOR.\n\nAll of the work that we will talk about today will help, but we have to acknowledge that the transition will be complicated. Unfortunately, as I have discussed, we cannot guarantee that it won't be necessary. The most complicated aspects involve the legacy contracts that reference LIBOR, many of which do not have strong language in place if LIBOR were to stop publication. The FSB has been working with the International Swaps and Derivatives Association (or ISDA) to devise better language for derivatives, and ISDA's Scott O'Malia and Katherine Tew Darras will discuss that work later this morning. As people now consider the risks around LIBOR for other types of contracts, they will need to go through their documentation to understand what the fallback language is and how it can be improved. We will also discuss those issues today. This is important work, both for the parties to these contracts and for our financial stability. While there may be no perfect contract language or fallback, good risk management requires that we work together to find language and fallbacks that are robust and that limit unintended valuation changes.\n\nSo, while much work has been done, there is more still to do. I have been heartened in seeing that many market participants are already confronting these issues. For some, Andrew Bailey's speech was a difficult wake-up call. But the efforts we have undertaken with the ARRC show what is possible when the official sector works collectively with market participants. If market participants are willing to continue to work together, then we can safely achieve the transitions needed to create a better and more robust system that will help to ensure our ongoing financial stability."
    },
    {
        "title": "A Challenging Decade and a Question for the Future",
        "date": "October 20, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20171020a.htm",
        "content": "October 20, 2017\n\nChair Janet L. Yellen\n\nAt the 2017 Herbert Stein Memorial Lecture, National Economists Club, Washington, D.C.\n\nI am delighted to address the National Economists Club, and I am also honored on this occasion to be associated with Herb Stein, whose public service and scholarship--characterized by careful analysis, clear-eyed pragmatism, and sharp wit--exemplified the best in our profession. Herb was willing to consider new ideas and new approaches to government policy, and that openness fits with the subject of my remarks today. Namely, I will discuss the unconventional monetary policy tools used by the Federal Reserve since the start of the financial crisis and Great Recession and the role that those tools may play in addressing future economic challenges.\n\nNearly 10 years ago, with our nation mired in its worst economic and financial crisis since the Great Depression, the Federal Open Market Committee (FOMC) confronted a key challenge to the pursuit of its congressionally mandated goals of maximum employment and price stability: how to support a weakening U.S. economy once our main conventional policy tool, the federal funds rate, had been lowered to essentially zero. Addressing that problem eventually led to a second challenge: how to ensure that we could scale back monetary policy accommodation in an orderly fashion once it was no longer needed. Failure to meet either challenge would have significantly compromised our ability to foster maximum employment and price stability, leading to serious consequences for the livelihoods of millions of Americans.\n\nI will argue today that we have met the first challenge and have made good progress to date in meeting the second. Thanks in part to the monetary policy accommodation provided in the aftermath of the crisis--especially through enhanced forward rate guidance and large-scale asset purchases--the U.S. economy has made great strides. Indeed, with the economy now operating near maximum employment and inflation expected to rise to the FOMC's 2 percent objective over the next couple of years, the FOMC has been scaling back the accommodation provided in response to the Great Recession. In no small part because of our authority to pay interest on excess reserves, the process of removing policy accommodation is working well.\n\nAfter discussing a few issues related to our recent decision to start reducing the size of the Federal Reserve's balance sheet, I will address a key question: What is the appropriate future role of the unconventional policy tools that we deployed to address the Great Recession? While I believe that influencing short-term interest rates should continue to be our primary monetary policy lever in normal times, our unconventional policy tools will likely be needed again should some future economic downturn drive short-term interest rates back to their effective lower bound. Indeed, empirical analysis suggests that the neutral federal funds rate--defined as the level of the federal funds rate that is neither expansionary nor contractionary when the economy is operating near its potential--is much lower than in previous decades. Consequently, the probability that short-term interest rates may need to be reduced to their effective lower bound at some point is uncomfortably high, even in the absence of a major financial and economic crisis.\n\nI will return to the question about the future of our various policy tools, but first I would like to review our experience this decade, which I view as instructive for addressing that question.\n\nMeeting the Challenge of Providing Additional Accommodation\nA substantial body of evidence suggests that the U.S. economy is much stronger today than it would have been without the unconventional monetary policy tools deployed by the Federal Reserve in response to the Great Recession. Two key tools were large-scale asset purchases and forward guidance about our intentions for the future path of short-term interest rates. The rationale for those tools was straightforward: Given our inability to meaningfully lower short-term interest rates after they reached near-zero in late 2008, the FOMC used increasingly explicit forward rate guidance and asset purchases to apply downward pressure on longer-term interest rates, which were still well above zero.\n\nLonger-term interest rates reflect, in part, financial market participants' expectations of the future path of short-term interest rates. As a result, FOMC communications that affect those expectations--such as the enhanced forward rate guidance provided in our post-meeting statements in the aftermath of the Great Recession--can affect longer-term interest rates.1 In addition, longer-term interest rates include a term premium, which is the compensation demanded by investors for bearing the interest rate risk associated with longer-term securities. When the Federal Reserve buys longer-term securities in the open market, the remaining stock of securities available for purchase by the public declines, which pushes the prices of those securities up and thus depresses their yields by lowering the term premiums embedded in those yields.2 Several studies have found that our forward rate guidance and asset purchases did appreciably reduce longer-term interest rates.3\n\nThe FOMC's goal in lowering longer-term interest rates was to help the U.S. economy recover from the recession and stem the disinflationary forces that emerged from it. Some have suggested that the slow pace of the economic recovery proves that our unconventional policy tools were ineffective. However, one should recognize that the recovery could have been much slower in the absence of our unconventional tools. Indeed, the evidence strongly suggests that forward rate guidance and securities purchases--by substantially lowering borrowing costs for millions of American families and businesses and making overall financial conditions more accommodative--did help spur consumption and business spending, lower the unemployment rate, and stave off disinflationary pressures.4\n\nOther central banks also deployed unconventional policy tools in the years that followed the financial crisis.5 Evidence accumulated from their experience also supports the notion that these tools have helped stimulate economic activity in their countries after their short-term interest rates were lowered to near-zero--and, in some cases, even below zero.6\n\nMeeting the Challenge of Scaling Back Accommodation\nBy 2014, the U.S. economy was making notable progress toward the FOMC's goals of maximum employment and price stability. The unemployment rate had dropped to 6 percent by midyear--well below its Great Recession peak of 10 percent--and other measures of labor market conditions were also showing significant improvement. In addition, inflation, as measured by the change in the price index for personal consumption expenditures, had reached about 1-3/4 percent by mid-2014 after hovering around 1 percent in the fall of 2013. Reflecting that progress, the Federal Reserve's focus was shifting from providing additional monetary policy accommodation to scaling it back.7 A key question for the FOMC then was how to reduce the degree of accommodation in the context of a vastly expanded Federal Reserve balance sheet.\n\nOne possible approach was to start by reducing the Federal Reserve's securities holdings while short-term interest rates remained at the lower bound. We could allow securities to roll off the Federal Reserve's balance sheet and even sell securities, thereby putting upward pressure on long-term rates while calibrating the pace and configuration of the reduction in our holdings as warranted by our maximum employment and price stability objectives. Eventually, once our securities holdings had shrunk sufficiently, the FOMC could start nudging up its short-term interest rate target.\n\nOne problem of this \"last in, first out\" approach was that the FOMC does not have any experience in calibrating the pace and composition of asset redemptions and sales to actual and prospective economic conditions. Indeed, as the so-called taper tantrum of 2013 illustrated, even talk of prospective changes in our securities holdings can elicit unexpected abrupt changes in financial conditions.\n\nGiven the lack of experience with reducing our asset holdings to scale back monetary policy accommodation and the need to carefully calibrate the removal of accommodation, the FOMC opted to allow changes in the Federal Reserve's securities holdings to play a secondary role in the Committee's normalization strategy. Rather than balance sheet shrinkage, the FOMC decided that its primary tool for scaling back monetary policy accommodation would be influencing short-term interest rates.\n\nAs we explained in our \"normalization principles\" issued in September 2014, the FOMC decided to maintain the overall size of the Federal Reserve's securities holdings at an elevated level until sometime after the FOMC had begun to raise short-term interest rates.8 Once normalization of the level of the federal funds rate was \"well under way\" and the Committee judged that the economic expansion was strong enough that further increases in short-term interest rates were likely to be warranted, the FOMC would gradually and predictably reduce the size of the balance sheet by allowing the Federal Reserve's securities holdings to \"run off\"--that is, we would allow our balance sheet to shrink passively by not reinvesting all of the principal payments from our securities.9\n\nOne advantage of the FOMC's chosen approach to scaling back accommodation is that both the FOMC and the public have decades of experience with adjustments in short-term interest rates in response to changes in economic conditions. Nonetheless, the post-crisis environment presented a new test to the FOMC's ability to influence short-term interest rates.\n\nBefore the crisis, the FOMC could raise the federal funds rate--the rate at which banks with excess reserves lend to banks with a reserve need--by removing a small amount of reserves from the banking system. That would translate into a higher federal funds rate because reserves were relatively scarce to begin with. The intuition was simple: The FOMC would signal that it was going to tighten conditions in the reserve market, and the cost of obtaining reserves in the market--the federal funds rate--would rise. Other market interest rates would then increase accordingly.\n\nAfter the crisis, however, reserves were plentiful because the Federal Reserve funded its large-scale asset purchases through adding reserves to the system--crediting the bank accounts of those who were selling assets to the Fed. Moreover, in light of the FOMC's decision not to sell the longer-term securities it acquired, reserves were likely to remain plentiful for the foreseeable future. Consequently, when the time came to remove accommodation, a key question for the Committee was how to raise the federal funds rate in an environment of abundant reserves.10 An important part of the answer to that question came in the Federal Reserve's authority to pay interest on excess reserves. The Congress granted the Federal Reserve that authority in 2006, to become effective in 2011. However, in the fall of 2008, the Congress moved up the effective date to October 2008.\n\nHaving authority to pay interest on excess reserves means that the Federal Reserve can influence the federal funds rate and other short-term interest rates regardless of the amount of excess reserves in the banking system. The mechanics of the new framework are straightforward: Banks will generally only provide short-term funding at an interest rate around or above what they could earn at the Fed. As a result, if the Federal Reserve raised the rate it paid, other short-term lending rates would likely rise as well.11 This new approach for raising short-term interest rates is working well: Since December 2015, we have raised the interest paid on excess reserves and the target range for the federal funds rate by 100 basis points, and the effective federal funds rate has risen accordingly.12\n\nA Closer Look at Our Balance Sheet Strategy\nIn light of our recent decision to start reducing our securities holdings this month, I would like to discuss a few aspects of our balance sheet strategy.13 The FOMC anticipated that its decision to maintain the size of the Federal Reserve's securities holdings at an elevated level until sometime after the beginning of rate hikes would keep some downward pressure on longer-term interest rates well after the end of its asset purchase programs. Although estimates of the effect of our securities holdings on longer-term interest rates are subject to uncertainty, a recent study reported that the Federal Reserve's securities holdings were reducing the term premium on the 10-year Treasury yield by roughly 1 percentage point at the end of 2016.14\n\nThe guidance that the FOMC would eventually start a gradual and predictable reduction of the Federal Reserve's securities holdings implied that the downward pressure on longer-term yields would likely diminish over time as financial market participants came to expect that the start of balance sheet normalization was nearing. Indeed, with that process now under way, it is likely that our securities holdings are now depressing the term premium on the 10-year yield by somewhat less than the 1 percentage point estimate reported for late last year.\n\nSeveral factors suggest that the downward pressure on term premiums exerted by our securities holdings is likely to diminish only gradually as our holdings shrink. For instance, as I have already noted, our intention to reduce our balance sheet by reducing reinvestment of repayments of principal on our holdings--rather than selling assets--has been well communicated for several years now. As a result, we do not anticipate a jump in term premiums as our balance sheet reduction plan gets under way. In addition, the maturity distribution of our securities holdings is such that it will take some years for the size of our holdings to normalize via runoff.15\n\nThe judgment that the downward pressure on term premiums will decline only gradually as we reduce the size of our balance sheet stands in sharp contrast to evidence suggesting that this pressure built up rather quickly when we were expanding our balance sheet. To understand this contrast, remember that, unlike our plan to shrink our balance sheet, the various phases of our asset purchases had, to differing degrees, an element of surprise, with asset purchase announcements occasionally leaving a distinct imprint on the path of longer-term yields. Moreover, each of our asset purchase programs resulted in a rapid increase in our securities holdings during a relatively short period, whereas the normalization process will play out gradually over many years.\n\nI have focused thus far on the likely response of term premiums to our balance sheet reduction plan. Let me turn my attention briefly to the likely response of longer-term yields, which, as I have noted, reflect both a term premium component and expectations of the future path of short-term interest rates. While the available evidence points to a strong reaction of longer-term yields to our asset purchases, it is conceivable that those yields will react much more modestly to our balance sheet reduction plan.\n\nConsider, for instance, a hypothetical scenario in which the FOMC has decided not to rely on balance sheet reduction to scale back accommodation, choosing instead to continue to reinvest indefinitely all principal payments from the Federal Reserve's securities holdings. If financial market participants perceived no change in the economic outlook and no intention on the part of the FOMC to alter the overall stance of monetary policy, the FOMC's inclination to leave the size of the balance sheet unchanged would be taken as an indication that the FOMC would instead rely more on increases in short-term interest rates to scale back accommodation, resulting in a faster pace of short-term interest hikes. On net, longer-term yields may be little affected by this hypothetical scenario: While the decreased emphasis on balance sheet reduction would depress term premiums and hold longer-term yields lower, the expected faster pace of short-term interest rate increases would push longer-term yields higher.16\n\nA Key Question for the Future\nAs the financial crisis and Great Recession fade into the past and the stance of monetary policy gradually returns to normal, a natural question concerns the possible future role of the unconventional policy tools we deployed after the onset of the crisis. My colleagues on the FOMC and I believe that, whenever possible, influencing short-term interest rates by targeting the federal funds rate should be our primary tool. As I have already noted, we have a long track record using this tool to pursue our statutory goals. In contrast, we have much more limited experience with using our securities holdings for that purpose.\n\nWhere does this assessment leave our unconventional policy tools? I believe their deployment should be considered again if our conventional tool reaches its limit--that is, when the federal funds rate has reached its effective lower bound and the U.S. economy still needs further monetary policy accommodation.\n\nDoes this mean that it will take another Great Recession for our unconventional tools to be used again? Not necessarily. Recent studies suggest that the neutral level of the federal funds rate appears to be much lower than it was in previous decades.17 Indeed, most FOMC participants now assess the longer-run value of the neutral federal funds rate as only 2-3/4 percent or so, compared with around 4-1/4 percent just a few years ago.18 With a low neutral federal funds rate, there will typically be less scope for the FOMC to reduce short-term interest rates in response to an economic downturn, raising the possibility that we may need to resort again to enhanced forward rate guidance and asset purchases to provide needed accommodation.19\n\nOf course, substantial uncertainty surrounds any estimates of the neutral level of short-term interest rates. In this regard, there is an important asymmetry to consider. If the neutral rate turns out to be significantly higher than we currently estimate, it is less likely that we will have to deploy our unconventional tools again. In contrast, if the neutral rate is as low as we estimate or even lower, we will be glad to have our unconventional tools in our toolkit.\n\nThe bottom line is that we must recognize that our unconventional tools might have to be used again. If we are indeed living in a low-neutral-rate world, a significantly less severe economic downturn than the Great Recession might be sufficient to drive short-term interest rates back to their effective lower bound.\n\nConclusion\nLet me conclude with a brief summary. As a result of the Great Recession, the Federal Reserve has confronted two key challenges over the past several years: One, the FOMC had to provide additional policy accommodation after short-term interest rates reached their effective lower bound; and two, subsequently, as we made progress toward the achievement of our mandate, we had to start scaling back that accommodation in the presence of a vastly expanded Federal Reserve balance sheet.\n\nToday I highlighted two points about the FOMC's experience with those challenges. First, the monetary policy tools that the Federal Reserve deployed in the immediate aftermath of the crisis--explicit forward rate guidance, large-scale asset purchases, and the payment of interest on excess reserves--have helped us overcome these challenges.\n\nSecond, in light of evidence suggesting that the neutral level of short-term interest rates is significantly lower than it was in previous decades, the likelihood that future monetary policymakers will have to confront those two challenges again is uncomfortably high. For this reason, we must keep our unconventional policy tools ready to be deployed again should short-term interest rates return to their effective lower bound.\n\n1. Before the Great Recession, the FOMC occasionally provided forward rate guidance, but that guidance was typically confined to a relatively short horizon. Return to text\n\n2. In addition to depressing term premiums, large-scale asset purchases by the Federal Reserve can lower longer-term yields if those purchases are perceived by the public as a signal that short-term interest rates are likely to remain lower for longer than previously anticipated. Return to text\n\n3. See, for instance, Eric T. Swanson and John C. Williams (2014), \"Measuring the Effect of the Zero Lower Bound on Medium- and Longer-Term Interest Rates,\" American Economic Review, vol. 104 (October), pp. 3154-85; Joseph Gagnon, Matthew Raskin, Julie Remache, and Brian Sack (2011), \"The Financial Market Effects of the Federal Reserve's Large-Scale Asset Purchases (PDF),\" International Journal of Central Banking, vol. 7 (March), pp. 3-43; and Stefania D'Amico, William English, David Lopez-Salido, and Edward Nelson (2012), \"The Federal Reserve's Large-Scale Asset Purchase Programmes: Rationale and Effects,\" Economic Journal, vol. 122 (November), pp. F415-46. Return to text\n\n4. See, for instance, Eric M. Engen, Thomas Laubach, and David Reifschneider (2015), \"The Macroeconomic Effects of the Federal Reserve's Unconventional Monetary Policies,\" Finance and Economics Discussion Series 2015-005 (Washington: Board of Governors of the Federal Reserve System, January). Return to text\n\n5. The Bank of Japan had deployed unconventional tools well before the crisis. Return to text\n\n6. See, for instance, Andrew G. Haldane, Matt Roberts-Sklar, Tomasz Wieladek, and Chris Young (2016), \"QE: The Story So Far (PDF),\" Staff Working Paper No. 624 (London: Bank of England, October); and Luca Gambetti and Alberto Musso (2017), \"The Macroeconomic Impact of the ECB's Expanded Asset Purchase Programme (APP) (PDF),\" ECB Working Paper 2075 (Frankfurt: European Central Bank, June). Return to text\n\n7. See Janet L. Yellen (2017), \"From Adding Accommodation to Scaling It Back,\" speech delivered at the Executives' Club of Chicago, Chicago, Ill., March 3. Return to text\n\n8. Information on the FOMC's Policy Normalization Principles and Plans is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/policy-normalization.htm. Return to text\n\n9. The FOMC announced in December 2015 that it anticipated maintaining its reinvestment policy until normalization of the level of the federal funds rate was \"well under way.\" That announcement is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/files/monetary20151216a1.pdf. More recently, in June 2017, the FOMC provided additional details regarding its approach to reduce the Federal Reserve's securities holdings, indicating that once the balance sheet normalization plan began, principal payments received from securities held by the Federal Reserve would be reinvested only to the extent that those payments exceeded certain monthly caps. The caps would rise gradually but would remain in place during the normalization process. The June 2017 announcement, Addendum to the Policy Normalization Principles and Plans, is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/files/FOMC_PolicyNormalization.20170613.pdf. Return to text\n\n10. For a discussion of the pre- and post-crisis frameworks for implementing short-term interest rate decisions, see Jane E. Ihrig, Ellen E. Meade, and Gretchen C. Weinbach (2015), \"Rewriting Monetary Policy 101: What's the Fed's Preferred Post-Crisis Approach to Raising Interest Rates? (PDF)\" Journal of Economic Perspectives, vol. 29 (Fall), pp. 177-98. Return to text\n\n11. The Federal Reserve created supplementary tools to be used as needed to help strengthen its influence over short-term interest rates when reserves are plentiful. For instance, the overnight reverse repurchase agreement facility allows a variety of counterparties, including eligible money market funds, government-sponsored enterprises, broker-dealers, and depository institutions to invest funds overnight with the Federal Reserve at a rate determined by the FOMC. Return to text\n\n12. For a discussion of how increases in the FOMC's target range for the federal funds rate have transmitted to other short-term interest rates, see Alyssa Anderson, Jane Ihrig, Mary-Frances Styczynski, and Gretchen C. Weinbach (2017), \"How Have the Fed's Three Rate Hikes Passed through to Selected Short-Term Interest Rates?\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, June 2). Return to text\n\n13. The FOMC's announcement of the beginning of implementation of the balance sheet normalization plan is available on the Board's website; see Board of Governors of the Federal Reserve System (2017), \"Federal Reserve Issues FOMC Statement (PDF),\" press release, September 20. Return to text\n\n14. See Brian Bonis, Jane Ihrig, and Min Wei (2017), \"Projected Evolution of the SOMA Portfolio and the 10-Year Treasury Term Premium Effect,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, September 22). Return to text\n\n15. Moreover, as the FOMC announced in June, the Committee decided to cap the monthly run-off in the Federal Reserve's securities holdings, making the balance sheet normalization process even more predictable and gradual. The FOMC's announcement is available on the Board's website; see Board of Governors of the Federal Reserve System (2017), \"FOMC Issues Addendum to the Policy Normalization Principles and Plans,\" press release, June 14. Return to text\n\n16. In contrast, when the Federal Reserve was purchasing assets, short-term interest rates were at their effective lower bound, and they were expected to remain there for the foreseeable future. As a result, decisions to buy additional assets--and the resulting additional downward pressure on term premiums--were not offset by expectations of a higher path for short-term interest rates. The end result was that there was greater potential for asset purchases to have a discernible effect on longer-term yields in the years immediately following the financial crisis than in current circumstances. Return to text\n\n17. See, for instance, James D. Hamilton, Ethan S. Harris, Jan Hatzius, and Kenneth D. West (2015), \"The Equilibrium Real Funds Rate: Past, Present, and Future,\" NBER Working Paper Series 21476 (Cambridge, Mass.: National Bureau of Economic Research, August); Olivier Blanchard (2016), \"Three Remarks on the U.S. Treasury Yield Curve,\" Peterson Institute for International Economics, RealTime Economic Issues Watch (blog), June 22, https://piie.com/blogs/realtime-economic-issues-watch/three-remarks-us-treasury-yield-curve; and Kathryn Holston, Thomas Laubach, and John C. Williams (2016), \"Measuring the Natural Rate of Interest: International Trends and Determinants (PDF),\" Working Paper Series 2016-11 (San Francisco: Federal Reserve Bank of San Francisco, December). Return to text\n\n18. FOMC participants' most recent projections of the federal funds rate are discussed in an addendum to the minutes of the Committee's September 2017 meeting, available in an October 11, 2017, press release on the Federal Reserve Board's website at https://www.federalreserve.gov/newsevents/pressreleases/monetary20171011a.htm. Return to text\n\n19. See Janet L. Yellen (2016), \"The Federal Reserve's Monetary Policy Toolkit: Past, Present, and Future,\" speech delivered at \"Designing Resilient Monetary Policy Frameworks for the Future,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 26; and David Reifschneider (2016), \"Gauging the Ability of the FOMC to Respond to Future Recessions (PDF),\" Finance and Economics Discussion Series 2016-068 (Washington: Board of Governors of the Federal Reserve System, August). Return to text"
    },
    {
        "title": "Financial Innovation: A World in Transition",
        "date": "October 18, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20171018a.htm",
        "content": "October 18, 2017\n\nGovernor Jerome H. Powell\n\nAt the 41st Annual Central Banking Seminar, sponsored by the Federal Reserve Bank of New York, New York, New York\n\nWe live in a world defined by the rapid pace of technological change. Four of the five largest U.S. companies by market capitalization are classified as \"technology companies,\" where the term describes the products that these companies sell and how they operate. Thanks to decades of investment in information technology, especially in electronic communication networks, consumers now expect services to be available instantly at their fingertips. This statement is true for almost every industry and every aspect of daily life, including financial transactions.\n\nThis evening, I will consider how technology is changing the delivery of retail banking and payments services. I will discuss the roles of banks, fintech companies, and other stakeholders in moving the United States forward to a better payment system. I will also review the Federal Reserve's collaboration with these payment system stakeholders in pursuing that goal. I will argue that, for policymakers as well as the private sector, the challenge is to embrace technology as a means of improving convenience and speed in the delivery of financial services, while also assuring the security and privacy necessary to sustain the public's trust. As always, the views I express here are my own.\n\nRetail Banking Innovation\nAs with so many sectors of the economy, technology is transforming the retail banking sector. The banking industry has traditionally been characterized by physical branches, privileged access to financial data, and distinct expertise in analyzing such data.1 But in today's world companies need not be bound by physical infrastructure and related overhead expenses. For example, companies can take advantage of an explosion in available data, and leverage advances in computing power, via cloud computing, analytical tools, and off-the-shelf machine learning tools, to make sense of those data. The banking industry is adjusting to this world, and facing significant challenges to traditional banking business models.\n\nFor example, today financial technology can support access to credit through innovative approaches to gathering and analyzing data. Historically, a customer seeking a loan has provided financial statements to a bank or other traditional lending institution. More recently, the use of a fintech platform may allow a lender to quickly monitor and analyze more up-to-date data from a broader range of sources, including those outside of the traditional lending process, to verify an applicant's identity and make inferences about the applicant's overall financial health. For example, a business loan applicant could submit information such as shipping data or customer reviews as additional input to more traditional data sources. With this additional information, the bank would have a more complete picture of an applicant's day-to-day activity and overall financial capacity, and potentially a greater ability to provide credit to customers, including some who might have been otherwise denied a loan based on traditional data.\n\nFintech firms are also finding ways to use banks' data, in some cases without entering into an explicit partnership with the bank. With customers' permission, fintech firms have increasingly turned to data aggregators to \"screen scrape\" information from financial accounts. In such cases, data aggregators collect and store online banking logins and passwords provided by the bank's customers and use them to log directly into the customer's banking account. This information can be used to provide consumers with convenient real-time snapshots of their financial information across multiple banks and accounts.\n\nThese examples highlight that there is a balance that needs to be achieved in this innovative environment.2 On the one hand, new technologies have enabled banks and other firms to find different ways of meeting consumers' demand for speed and convenience. On the other hand, these same technologies raise new considerations about data security and safety, as well as consumer privacy and protection. Policymakers and the financial industry must assure that enhanced convenience and speed in financial services do not undermine the safety, security, and reliability of those services.\n\nRetail Payments Innovation\nTechnology is also shaping changes in retail payments. As with retail banking, retail payments will need to evolve to meet consumer expectations of constant connectivity and instant access while assuring security and privacy.\n\nIt is not news that consumers' lives, including the way they pay, are now intertwined with mobile phone usage. While the overall amount of time we spend on our phones continues to grow, the duration of individual phone sessions is actually shrinking. In late 2015, Google estimated that the average mobile session lasts only 70 seconds, and may be repeated dozens of times per day.3 As a result, payment innovators have had to create new ways to move money that are not only fast and mobile-focused, but also sufficiently \"frictionless\" that consumers can now fit commerce into these brief interludes.\n\nThis development has ushered in a world of multiple smartphone apps that allow for \"instant\" payments. We can use a payments app to move funds instantly to anyone who has that app.4 Some banks have similarly collaborated to build faster payments applications that leverage their deposit account systems. And we are already moving to a world in which we need not open a special app or go to our bank's website in order to send money. Many people here will have taken an Uber or Lyft, and then paid your driver without relaunching the app, much less reaching for your wallet. Similarly, payment providers can now leverage the application programming interfaces (APIs)--essentially the protocols--of smartphone messaging services to integrate their payment tools directly into messaging applications: Nowadays, consumers can simply \"attach\" money while messaging a friend.\n\nInnovation in retail payments can also offer tangible benefits to consumers beyond convenience. Improvements in security, such as our ability to authenticate consumers and detect fraudulent transactions, are also possible through innovation. For instance, mobile payments introduce a wide array of ways to authenticate a consumer's identity, including two-factor authentication codes sent via text message to the phone; biometrics, like a fingerprint or face scan; device identification information; IP address; and geolocation data. Similarly, increased access to transaction data and cloud computing resources means that we have smarter, faster computational processes--like enhanced neural networks--to detect payments that do not match a consumer's spending patterns and help prevent fraudulent transactions. Both security and convenience are crucial elements for successful payments innovation. Consumers will not store their funds in a system that is not secure and will not want to transfer funds out of an otherwise secure system if the process is cumbersome.\n\nThe Role of Banks in Payments Innovation\nThe examples I have highlighted so far illustrate payments innovations from fintech firms and banks alike. I want to spend a moment highlighting the special role of banks in the payments process, and how banks are needed in order to create innovations that can be used broadly across the economy.\n\nThe traditional role of banks in the payments process has been to hold deposits and enable their transfer from one individual or business to another. A depositor might withdraw cash from the bank's ATM to pay a friend or write a check to make a payment. Over time, we have moved from ATMs and paper checks toward electronic payments and online payments through banking platforms--payment methods for which banks are still perceived as essential. More recently, consumer-facing technology has become front and center. At times, the payments process is so seamlessly integrated that one can forget that there is even a bank in the process, as with the Uber and Lyft example. But despite this shift in focus, payments innovation is still fundamentally about how, when, and where an individual's deposits can be held, transferred, and packaged with other information. And banks are still important players in making that happen. Even where this reality is obscured by several layers of technology, there is almost always a bank involved in consumer transactions.\n\nGiven their importance in holding and transferring funds, banks continue to have a key role to play in the design and safety of more efficient retail payment systems. Without bank participation, it would be difficult to change how funds are transferred in a way that brings pervasive benefits to consumers. For example, if the aim is to capture the speed and continuous nature of today's commerce in the payment system as a whole--as has become a focus for many countries, including the United States--it would be difficult to do so without banks allowing the transfer of their deposits on a 24x7 real-time basis. Of course, individual payment systems are already doing this for consumers within their own network. But achieving these benefits on a broad scale would be challenging without the banking system's participation, because of the large role banks have in holding and transferring funds.\n\nAll this is to say that we are at a critical juncture in the payment system's evolution, where technology is rapidly changing many facets of the payments process. Fintech firms and banks are seizing these technological changes in their own ways. But a collective and collaborative effort by all payment stakeholders will also be important as the United States works to achieve a payment system that has broad reach and can seamlessly integrate with other systems to transfer funds in a reliable, secure, and convenient manner. When we pay with cash or write a check, we don't spend a lot of time worrying about who our recipient banks with; that universality seems an appropriate standard for new payment options as well.\n\nStrategies for Improving the U.S. Payment System\nAt the Federal Reserve, we believe it is important to embrace opportunities provided by technological change to improve the convenience and safety of the U.S. payment system. About five years ago, we launched our payment system improvement initiative, which committed the Federal Reserve to working with the full range of payments system stakeholders to achieve a faster, more secure payment system. We saw that technology was transforming the nature of commerce and end-user expectations for payment services. We saw some players coming to market with innovative product offerings, but it was a fragmented approach. Meanwhile, other countries were advancing on initiatives to improve the speed and safety of their payment systems, creating a gap between the U.S. payment system and those abroad.\n\nWhile the Federal Reserve does not have plenary authority over payment systems, as is the case in some other countries, we have often played an important role as a leader and catalyst for change. It was in this role that we issued a call to action asking stakeholders to come together in pursuit of a better payment system for the future--focusing on speed, security, efficiency, international payments, and collaboration.5 I believe a collaborative approach ensures that change is designed by those whose commitment and expertise are needed to improve the payment system.\n\nStakeholders – including banks, fintech companies, consumer groups, regulators, and others -- answered our call to action, signing up for two task forces convened by the Federal Reserve. More than 300 stakeholders joined the Faster Payments Task Force, and around 200 joined the Secure Payments Task Force. Let me first touch upon the Faster Payments Task Force, which has recently completed its work.6\n\nThe Faster Payments Task Force's mission was to identify and assess alternative approaches for implementing a safe, ubiquitous, faster payments system in the United States. The task force began its work by developing a set of effectiveness criteria laying out desirable attributes for faster payment solutions covering the broad categories of ubiquity, efficiency, safety and security, speed, legal framework, and governance. While the task force was focused on improving speed and convenience, it also underscored the importance of safety and security by establishing 11 criteria of a total of 36 focused on those objectives.\n\nThe task force encouraged its members to submit proposals for faster payment solutions that would meet the criteria that its members had agreed upon. A diverse range of task force members rose to the challenge by submitting 16 proposals to be vetted against its criteria.7 These proposals represent a broad universe of creative and innovative ways to deliver faster payments by embracing technology. They range in structure from solutions that use a centralized clearing and settlement mechanism to others that focus on distributed networks. Some are based on traditional assets held in transaction accounts, and others depend on new asset forms like digital currencies. The role of the task force process was not to recommend or implement a faster payment solution, but rather to offer a range of ideas to move the United States further along the path to a better payment system. We believe that the task force has successfully carried out this role.\n\nWe are very grateful to the members of the Faster Payment Task Force for all of their work and for the collaborative spirit they brought to the job. But there is more to be done to advance our collective vision of a ubiquitous, real-time, secure future payment system. Last month, the Federal Reserve reaffirmed its commitment to that vision in the paper, \"Federal Reserve Next Steps in the Payments Improvement Journey,\" which outlines refreshed strategies and tactics that we, in collaboration with the payment industry, will employ to make further progress.8 I will mention just a few.\n\nOne of the recommendations from the Faster Payments Task Force work was to establish an industry governance framework for collaboration and decision-making on faster payments. To move forward in creating this framework, the task force established the Governance Framework Formation Team to develop, publish, and solicit public comment on a proposal for a governance framework. This work group will carry out many of the task force recommendations and the Federal Reserve, at the request of the task force, is chairing and facilitating this effort.\n\nIn addition, the Federal Reserve is considering providing settlement services--a traditional core function of a central bank--to address the future needs of a ubiquitous real-time retail payments environment. We plan to actively engage with the industry and other stakeholders to further understand gaps and requirements for real-time retail payments settlement and assess alternative models that will support needs over the long term. We also plan to explore and assess the need, if any, for other related Federal Reserve services or capabilities. In carrying out this assessment, we will be guided by current and potential market developments and challenges, as well as our long-established criteria for offering new products and services. These criteria include the need to fully recover costs over the long term; the expectation that the new service will yield clear public benefit; and the expectation that other providers alone cannot be expected to provide the service with a reasonable effectiveness, scope, and equity.9\n\nThe Federal Reserve will also continue to support the ongoing work of the Secure Payments Task Force. This task force has been working to educate stakeholders on payment security practices, risks, and actions that could enhance payment security. These are challenging topics, because they require stakeholders to be open and forthcoming about potential vulnerabilities if there is to be substantial progress.\n\nThe Federal Reserve will also pursue two new efforts focused on security. Early in 2018, we plan to launch a study analyzing payment security vulnerabilities. This study is similar to other research efforts that the Federal Reserve has pursued to build foundational and collective understanding of the U.S. payment system. We also plan to build upon the contributions of the Secure Payments Task Force to establish work groups focused on approaches for reducing the cost and prevalence of specific payment security vulnerabilities. In a world of ever-escalating threats to the integrity of our payment system, this collective action is needed to sustain public confidence.\n\nThese were just a few of our new initiatives. The package of next steps the Federal Reserve outlined in its recent paper confirm that we remain steadfast in our commitment to work with industry and other stakeholders to achieve a better payment system through both leadership and action.\n\nSummary\nRapidly changing technology is providing a historic opportunity to transform our daily lives, including the way we pay. Fintech firms and banks are embracing this change, as they strive to address consumer demands for more timely and convenient payments. A range of innovative products that seamlessly integrate with other services is now available at our fingertips. It is essential, however, that this innovation not come at the cost of a safe and secure payment system that retains the confidence of its end users. The examples I have drawn upon today highlight that fintech firms and banks must each play a role in assuring that enhancements to convenience and speed do not undermine safety and security. More broadly, the Faster and Secure Payments Task Forces demonstrate the importance of broad and diverse stakeholder input, which are essential if the United States is to implement safe, ubiquitous real-time retail payments. Working together, we can achieve a safe and fast payments system that meets the evolving needs of consumers and our dynamic economy.\n\n1. See, e.g., Miklos Dietz, Somesh Khanna, Tunde Olanrewaju, and Kausik Rajgopal, \"Cutting Through the Noise around Financial Technology,\" McKinsey & Company, February, 2016, www.mckinsey.com/industries/financialservices/our-insights/cutting-through-the-noise-around-financial-technology. Return to text\n\n2. See Lael Brainard, \"Where Do Banks Fit in the Fintech Stack?\" (speech delivered at the Northwestern Kellogg Public-Private Interface Conference on \"New Developments in Consumer Finance: Research & Practice,\" Evanston, Illinois, April 28, 2017). Return to text\n\n3. \"Your Guide to Winning the Shift to Mobile,\" Google, Micro-Moments, September 2015, https://www.thinkwithgoogle.com/marketing-resources/micro-moments/micromoments-guide-pdf-download/. Return to text\n\n4. Cashing the funds out of the app to use for other payments, however, has traditionally taken longer. Return to text\n\n5. See Federal Reserve System, \"Strategies for Improving the U.S. Payment System (PDF),\" January 26, 2015. Return to text\n\n6. See Faster Payments Task Force (2017), \"The U.S. Path to Faster Payments, Final Report Part Two: A Call to Action,\" https://fasterpaymentstaskforce.org/. Return to text\n\n7. The task force recommended establishing an external Qualified Independent Assessment Team to conduct objective proposal assessments. On behalf of the task force, the Federal Reserve selected McKinsey & Company to conduct a comprehensive assessment of each faster payment solution proposal against the task force's set of criteria. Return to text\n\n8. See Federal Reserve System, \"Federal Reserve Next Steps in the Payments Improvement Journey (PDF),\" September 6, 2017. Return to text\n\n9. See Board of Governors of the Federal Reserve System, \"Policies: The Federal Reserve in the Payments System,\" revised 1990. Return to text"
    },
    {
        "title": "The U.S. Economy and Monetary Policy",
        "date": "October 15, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20171015a.htm",
        "content": "October 15, 2017\n\nChair Janet L. Yellen\n\nAt the Group of 30 International Banking Seminar, Washington, D.C.\n\nI would like to thank the Group of Thirty for inviting me to participate in their International Banking Seminar and also thank Luis Alberto Moreno of the Inter-American Development Bank for hosting this event. My comments today will focus on U.S. economic prospects and monetary policy.\n\nEconomic activity in the United States has been growing moderately so far this year, and the labor market has continued to strengthen. The terrible hurricanes that hit Texas, Florida, Puerto Rico, and our neighbors in the Caribbean caused tremendous damage and upended many lives, and our hearts go out to those affected. While the effects of the hurricanes on the U.S. economy are quite noticeable in the short term, history suggests that the longer-term effects will be modest and that aggregate economic activity will recover quickly.\n\nStarting with the labor market, through August, payroll job gains averaged 170,000 per month this year, down only a little from the average pace of gains in 2016 and still well above estimates of the pace necessary to absorb new entrants to the labor force. In September, payrolls were reported to have declined 33,000, but that weakness reflected the effects of Hurricane Irma, which hit Florida during the reference week for the September labor market surveys. I would expect employment to bounce back in subsequent months as communities recover and people return to their jobs. Other aspects of the jobs report for September were strong. The unemployment rate, which seems not to have been noticeably affected by the hurricanes, declined further to 4.2 percent, down about 1/2 percentage point from the end of 2016 and below the median of Federal Open Market Committee (FOMC) participants' estimates of its longer-run normal level. Labor force participation continues to strengthen relative to a downward trend that reflects, in part, the aging of the population. Other labor market indicators, including the rates of job openings and the number of people who voluntarily quit their jobs, also point to strength.\n\nWage indicators have been mixed, and the most recent news, on average hourly earnings through September, was encouraging. On balance, wage gains appear moderate, and the pace seems broadly consistent with a tightening labor market once we account for the disappointing productivity growth in recent years.\n\nI expect the labor market to strengthen further as economic growth continues. The hurricanes will likely result in some hit to GDP growth in the third quarter but a rebound thereafter, and smoothing through those movements, I'm expecting growth that continues to exceed potential in the second half of the year. The latest projections from FOMC participants have a median of 2-1/2 percent GDP growth this year. Growth of consumer spending has been supported by the ongoing job gains and relatively high levels of household wealth and consumer sentiment. Business investment has strengthened this year following surprising weakness in 2016. The faster gains partly reflect an upturn in investment in the energy sector as oil prices have firmed. But the gains have been broader than that, and some measures of business sentiment remain quite strong. Exports also have risen this year, as growth abroad has solidified and the exchange value of the dollar has declined somewhat. My fellow FOMC participants and I perceive that risks to global growth have receded somewhat and expect growth to continue to improve over the near term.\n\nThe biggest surprise in the U.S. economy this year has been inflation. Earlier this year, the 12-month change in the price index for personal consumption expenditures (PCE) reached 2 percent, and core PCE inflation reached 1.9 percent. These readings seemed consistent with the view that inflation had been held down by both the sizable fall in oil prices and the appreciation of the dollar starting around mid-2014, and that these influences have diminished significantly by this year. Accordingly, inflation seemed well on its way to the FOMC's 2 percent inflation objective on a sustainable basis.\n\nInflation readings over the past several months have been surprisingly soft, however, and the 12-month change in core PCE prices has fallen to 1.3 percent. The recent softness seems to have been exaggerated by what look like one-off reductions in some categories of prices, especially a large decline in quality-adjusted prices for wireless telephone services. More generally, it is common to see movements in inflation of a few tenths of a percentage point that are hard to explain, and such \"surprises\" should not really be surprising. My best guess is that these soft readings will not persist, and with the ongoing strengthening of labor markets, I expect inflation to move higher next year. Most of my colleagues on the FOMC agree. In the latest Summary of Economic Projections, my colleagues and I project inflation to move higher next year and to reach 2 percent by 2019.\n\nTo be sure, our understanding of the forces that drive inflation is imperfect, and we recognize that this year's low inflation could reflect something more persistent than is reflected in our baseline projections. The fact that a number of other advanced economies are also experiencing persistently low inflation understandably adds to the sense among many analysts that something more structural may be going on. Let me mention a few possibilities of more fundamental influences.1\n\nFirst, given that estimates of the natural rate of unemployment are so uncertain, it is possible that there is more slack in U.S. labor markets than is commonly recognized, which may be true for some other advanced economies as well. If so, some further tightening in the labor market might be needed to lift inflation back to 2 percent.\n\nSecond, some measures of longer-term inflation expectations have edged lower over the past few years in several major economies, and it remains an open question whether these measures might be reflecting a true decline in expectations that is broad enough to be affecting actual inflation outcomes.\n\nThird, our framework for understanding inflation dynamics could be misspecified in some way. For example, global developments--perhaps technological in nature, such as the tremendous growth of online shopping--could be helping to hold down inflation in a persistent way in many countries. Or there could be sector-specific developments--such as the subdued rise in medical prices in the United States in recent years--that are not typically included in aggregate inflation equations but which have contributed to lower inflation. Such global and sectoral developments could continue to be important restraining influences on inflation. Of course, there are also risks that could unexpectedly boost inflation more rapidly than expected, such as resource utilization having a stronger influence when the economy is running closer to full capacity.\n\nIn this economic environment, with ongoing improvements in labor market conditions and softness in inflation that is expected to be temporary, the FOMC has continued its policy of gradual policy normalization. As the Committee announced after our September meeting, we are initiating our balance sheet normalization program this month. That program, which was described in the June Addendum to the Policy Normalization Principles and Plans, will gradually scale back our reinvestments of proceeds from maturing Treasury securities and principal payments from agency securities. As a result, our balance sheet will decline gradually and predictably.2 By limiting the volume of securities that private investors will have to absorb as we reduce our holdings, the caps should guard against outsized moves in interest rates and other potential market strains.\n\nChanging the target range for the federal funds rate is our primary means of adjusting the stance of monetary policy. Our balance sheet is not intended to be an active tool for monetary policy in normal times. We therefore do not plan on making adjustments to our balance sheet normalization program. But, of course, as we stated in June, the Committee would be prepared to resume reinvestments if a material deterioration in the economic outlook were to warrant a sizable reduction in the federal funds rate.\n\nAlso at our September meeting, the Committee decided to maintain its target for the federal funds rate. We continue to expect that the ongoing strength of the economy will warrant gradual increases in that rate to sustain a healthy labor market and stabilize inflation around our 2 percent longer-run objective. That expectation is based on our view that the federal funds rate remains somewhat below its neutral level--that is, the level that is neither expansionary nor contractionary and keeps the economy operating on an even keel. The neutral rate currently appears to be quite low by historical standards, implying that the federal funds rate would not have to rise much further to get to a neutral policy stance. But we expect the neutral level of the federal funds rate to rise somewhat over time, and, as a result, additional gradual rate hikes are likely to be appropriate over the next few years to sustain the economic expansion. Indeed, FOMC participants have built such a gradual path of rate hikes into their projections for the next couple of years.\n\nOf course, policy is not on a preset course. I have spoken about some of the uncertainties associated with the inflation outlook in particular, and we will be paying close attention to the inflation data in the months ahead. But uncertainty about the outlook is by no means limited to inflation. As always, the Committee will adjust the stance of monetary policy in response to incoming economic information and the evolution of the economic outlook to achieve its objectives of maximum employment and stable prices. Moreover, we are mindful of the possibility that shifting expectations concerning the path of U.S. policy can lead to spillovers to other economies via financial markets and the value of the dollar. We remain committed to communicating as clearly and effectively as possible to help mitigate the risk of sudden changes in the policy outlook among market participants that could spur unintended effects in global financial markets.\n\n1. For further discussion, see Janet Yellen (2017), \"Inflation, Uncertainty, and Monetary Policy,\" speech delivered at \"Prospects for Growth: Reassessing the Fundamentals,\" the 59th annual meeting of the National Association for Business Economics, Cleveland, Ohio, September 26. Return to text\n\n2. For October through December of this year, the decline in the Federal Reserve's securities holdings will be capped at $6 billion per month for Treasury securities and $4 billion per month for agency securities. These caps will gradually rise over the course of the following year to maximums of $30 billion per month for Treasury securities and $20 billion per month for agency securities and will remain in place through the process of normalizing the size of our balance sheet. Return to text"
    },
    {
        "title": "Rethinking Monetary Policy in a New Normal",
        "date": "October 12, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20171012a.htm",
        "content": "October 12, 2017\n\nGovernor Lael Brainard\n\nAt the Panel on Monetary Policy \"Rethinking Macroeconomic Policy,\" a conference sponsored by the Peterson Institute for International Economics, Washington D.C.\n\nI enjoyed Ben Bernanke's paper titled \"Monetary Policy in a New Era.\"1 He presents a compelling diagnosis of the issues facing policymakers and discusses a variety of policy options. Bernanke proposes an approach to policy that is elegant and straightforward to communicate. I will focus on those elements that I find particularly relevant for the challenges faced by policymakers and suggest some implications and complications. My comments are not intended to address current policy.2\n\nThe New Normal\nPolicymakers in advanced economies are confronting a different constellation of challenges today than those that dominated the canon of U.S. monetary policymaking over the previous half-century, which I refer to as the \"new normal.\"3 A key feature of the new normal is that the neutral interest rate--the level of the federal funds rate that is consistent with the economy growing close to its potential rate, full employment, and stable inflation--appears to be much lower than it was in the decades prior to the crisis. In the Federal Open Market Committee's (FOMC) most recent Summary of Economic Projections (SEP), the median FOMC participant expected a longer-run real federal funds rate, after subtracting inflation, of 3/4 percent, down sharply from the value the first time the policy projection was published in the January 2012 SEP of 2-1/4 percent--and the average value in the decades prior to the financial crisis of 2-1/2 percent.4\n\nThe low level of the neutral rate limits the amount of space available for cutting the federal funds rate to offset adverse developments and thereby can be expected to increase the frequency and duration of periods when the policy rate is constrained by the effective lower bound, unemployment is elevated, and inflation is below target. In this environment, frequent or extended periods of low inflation run the risk of pulling down private-sector inflation expectations, which could amplify the degree and persistence of shortfalls of inflation, thereby making future lower bound episodes even more challenging in terms of output and employment losses. To the extent it is weighing on longer-run inflation expectations, the persistently low level of the neutral federal funds rate may be a factor contributing to the persistent shortfall of U.S. inflation from the FOMC's target.5\n\nFurther complicating the ability of central banks to achieve their inflation objectives in today's new normal is the very flat Phillips curve observed in the United States and many other advanced economies, which makes the relationship between labor market conditions and price inflation more tenuous. For instance, inflation has remained stubbornly below the FOMC's 2 percent target for the past five years even as unemployment has fallen from 8.2 percent to 4.2 percent, a level that most experts believe is in the vicinity of full employment.6\n\nBernanke's paper provides an excellent review of the Federal Reserve's efforts to operate in this new environment and makes some interesting new proposals. Reflecting on the Fed's available \"policy toolbox,\" Bernanke concludes that the available tools are not likely to be sufficient and proposes a framework that relies on forward guidance with commitment to help central banks achieve their inflation and employment objectives.\n\nThe Makeup Principle\nThe academic literature on monetary policy suggests a variety of prescriptions for preventing a lower neutral rate of interest from eroding longer-run inflation expectations. The paper argues convincingly that many of these proposals present practical difficulties that would create a very high bar for their adoption. For instance, raising the inflation target sufficiently to provide meaningfully greater policy space could engender public discomfort or, at the other extreme, risk unmooring inflation expectations. The transition to a notably higher target is likely to be challenging and could heighten uncertainty.\n\nAs I have noted previously, the persistence of the shortfall in inflation from our objective is an important consideration for monetary policy.7 The makeup principle, in which policy would make up for past misses of the inflation target, is not reflected in most standard monetary policy frameworks, although it is an important precept in theory.8 Some of the proposals that have been advanced to implement this principle present some difficulties. For example, while price-level targeting would be helpful in the aftermath of a recession that puts the economy at the effective lower bound, it could require tightening into a negative supply shock, which is a very unattractive feature, as Bernanke points out.9\n\nBernanke proposes a framework that avoids this undesirable possibility by implementing a temporary price-level targeting framework only in periods where conventional policy is constrained by the lower bound. Bernanke's proposal thus has the advantage of maintaining standard practice in normal times while proposing a makeup policy in periods when the policy rate is limited by the lower bound and inflation is below target. His proposed temporary price-level target would delay the liftoff of the policy rate from the lower bound until the average inflation over the entire lower bound episode has reached 2 percent and full employment is achieved. This type of policy, which would result in temporary overshooting of the inflation target in order to make up for the previous period of undershooting, is designed to, in Bernanke's words, \"calibrate the vigor of the policy response...to the severity of the episode.\"\n\nThe Normalization Bias\nThe proposed temporary price-level targeting policy is designed to address what I see as one of the key challenges facing policymakers. Following deep recessions of the type we experienced in 2008-09, there appears to be an important premium on \"normalization.\" This was apparent in 2010, for instance, when there was substantial pressure among Group of Twenty officials to commit to timelines and targets for reducing fiscal support and to articulate exit principles for monetary policy.10 This inclination proved premature, as was evident from the subsequent intensification of the euro-area crisis.\n\nMoreover, the benchmark for \"normal\" tends to be defined in terms of pre-crisis standards that involved policy settings well away from the lower bound, at least initially, because it may take some time to learn about important changes in underlying financial and economic relationships. For example, the factors underlying what we now understand to be the new normal of persistently low interest rates were in many cases initially viewed as temporary headwinds. In these circumstances, a standard policy framework calibrated around the pre-crisis or \"old\" normal may be biased to underachieving the inflation target in a low neutral rate environment. The kind of policy framework that Bernanke proposes, which pre-commits to implementing the makeup principle based on the actual observed performance of inflation during a lower bound episode, could guard against premature liftoff and help prevent the erosion of longer-term inflation expectations.\n\nMonetary policymakers operate in an environment of considerable uncertainty and therefore have to weigh the risks of tightening too little or too late against those of tightening too much or too soon. While past experience has conditioned U.S. policymakers to be highly attentive to the risks associated with a breakout of inflation to the upside, as in the 1970s, they balance these risks against those associated with undershooting the inflation target persistently, as in Japan in the late 1990s and the 2000s.\n\nIn weighing these risks, the standard approach is typically designed to achieve \"convergence from below,\" in which inflation gradually rises to its target. Given the lags in the effects of monetary policy, convergence from below would necessitate raising interest rates preemptively, well in advance of inflation reaching its target. Moreover, particularly in the early stage of a recovery, this kind of preemptive approach tends of necessity to rely on economic relationships derived from pre-crisis observations, when policy rates were comfortably above the lower bound.\n\nDuring a period when the policy rate is limited by the lower bound, Bernanke's proposal would represent a substantial departure from the standard approach. While a standard policy framework would tend to prescribe that tightening should start preemptively, well before inflation reaches target, Bernanke's temporary price-level target proposal would imply maintaining the policy rate at the lower bound well past the point at which inflation has risen above target. In principle, policymakers would have to be willing to accept elevated rates of above-target inflation for a period following a lengthy period of undershooting.\n\nJust as policymakers could run a risk of low inflation becoming entrenched in the standard preemptive framework, so, too, there are risks in the temporary price-level target framework. One risk is that the public, seeing elevated rates of inflation, may start to doubt that the central bank is still serious about its inflation target. It is worth noting that the policy is motivated by the opposite concern--that convergence from below, following an extended lower bound episode, may lead to an unanchoring of inflation expectations to the downside. Still, a conscious policy of overshooting may be difficult to calibrate, especially since the large confidence intervals around inflation forecasts suggest that the risks of an undesired overshooting are nontrivial. A related risk is that the central bank would lose its nerve: Maintaining the interest rate at zero in the face of a strong economy and inflation notably above its target would place a central bank in uncomfortable territory.\n\nOne additional challenge of the proposed framework is specifying a path for the policy rate immediately following liftoff that smoothly and gradually eases inflation back down to target and facilitates a gradual adjustment of the labor market. In the proposed framework, once the cumulative average rate of inflation during the lower-bound period has reached the target of 2 percent, policy would revert to a standard policy rule.11 This implies that a standard policy rule would kick in at a point when inflation is above target and the economy is at or beyond full employment. Even with a smoothing (inertial) property, a standard policy rule could result in a relatively sharp path of tightening, and the anticipation of the steep post-liftoff rate path itself could undo some of the benefits associated with the framework. Thus, there would likely need to be a transitional framework to guide policy initially post-liftoff that might make both communications and policy somewhat more complicated.\n\nIntegrating the Policy Rate and the Balance Sheet\nThe temporary price-level targeting framework proposed by Bernanke is appealing on a conceptual level because it proposes a simple and clear mechanism to help policymakers deal with the challenges posed by the lower bound on the policy rate in an environment of uncertainty. The reality is more complicated, however, especially if, as the paper suggests, many central banks in advanced economies are likely to operate with an additional tool when the policy rate is constrained. In the paper, Bernanke cites Chair Yellen's 2016 Jackson Hole speech, which suggests that in a recession, the FOMC could be expected to turn to large-scale asset purchases as well as forward guidance after the federal funds rate is lowered to zero.12\n\nToday, when many central banks in advanced economies are operating with two distinct tools, policymakers consider the effects of the balance sheet as well as the policy rate in their assessment of the extent of accommodation provided by monetary policy. In the United States, from the time tapering was first discussed to the September 2017 meeting, when the path for balance sheet runoff was adopted, FOMC minutes and statements suggest that participants considered the degree of accommodation provided by both policy tools in their discussions of the sequencing and timing of changes to policy settings. Discussions about the sequencing of \"normalization\" and the delay of balance sheet runoff \"until normalization of the level of the federal funds rate is well under way\" effectively consider the extent to which maintaining the balance sheet may continue to provide makeup support for the economy while enabling the policy rate to escape the lower bound earlier than otherwise in a low neutral rate environment.\n\nAs Bernanke acknowledges, now that many central banks have developed playbooks specifying the operational modalities associated with asset purchases, and there is some familiarity with their effects on asset prices and financial conditions, there is a greater likelihood that asset purchases would become a part of the policy reaction function, along with forward guidance, during lower-bound episodes. Yet, as I have noted previously in the international context, asset purchases can complicate policy frameworks and communications, because their deployment and withdrawal has tended to be discontinuous and discrete and thus may be associated with greater uncertainty about the policy reaction function.13 It appears the public closely follows statements about both the policy rate and asset purchases to glean possible information about the future overall stance of monetary policy. This suggests there may be benefits in communications and predictability of a unified policy framework across the tools that is more predictable and continuous. Relatedly, one helpful elaboration of the framework Bernanke proposes might be to incorporate a unified measure, or shadow rate, that would capture the degree of policy accommodation provided through the combined settings of both asset purchases and the policy rate.14\n\nGreater Cross-Border Spillovers\nMoving away from the policy proposal in the paper, there are two other aspects of a low neutral rate world that I want to touch on briefly: cross-border spillovers and financial imbalances. The new normal appears to be characterized by low neutral rates and a weak relationship between overall inflation and unemployment not only in the United States, but also in many other advanced economies with lower-bound episodes likely to be more prevalent. The current environment appears also to evidence intensified cross-border feedback into financial conditions.15 In this kind of environment, it is conceivable the kind of committed forward guidance associated with the temporary price-level targeting framework proposed by Bernanke, by helping rule out anticipation of a standard preemptive tightening, could help avoid unwarranted premature tightening through the exchange rate.\n\nGiven available data, it is difficult to disentangle whether the heightened cross-border feedback effects are attributable to the low level of neutral rates, particular features of today's lower-bound episodes, or the interaction of the policies adopted by many central banks. In any case, recent Federal Reserve staff analysis suggests that cross-border spillovers have increased notably since the crisis and are quite large. For instance, European Central Bank policy news that leads to a 10 basis point decrease in the German 10-year term premium is associated with a roughly 5 basis point decrease in the U.S. 10-year term premium; by contrast, these spillovers were smaller in the years leading up to the crisis.16\n\nMoreover, news about policy rates and term premiums appears to have quite different effects on exchange rates, such that the ordering of policy normalization can have important implications for exchange rates and associated financial conditions, as I discussed earlier this year.17 Recent staff estimates suggest that news about expected changes in the policy rate tends to have a large spillover through the exchange rate, whereas news about changes in term premiums tends to lead to corresponding cross-border changes in term premiums, as discussed previously, with much smaller effects on the exchange rate. Moreover, the exchange rate effect of changes in short-term rates is much greater than it was pre-crisis. For instance, policy news that leads to a 25 basis point increase in the expected interest rate portion of the 10‑year Treasury yield is associated with a roughly 3 percentage point appreciation in the dollar, which is three times greater than the response pre-crisis. By contrast, policy news surrounding a change in U.S. term premiums has a muted effect on the exchange rate both now and pre-crisis.\n\nFinancial Imbalances\nFinally, a low neutral rate environment may also be associated with a heightened risk of asset price bubbles, which could exacerbate the tradeoff for monetary policy between achieving the traditional dual-mandate goals and preventing the kinds of imbalances that could contribute to financial instability. Standard asset-valuation models suggest that a persistently low neutral rate, depending on the factors driving it, could lead to higher ratios of asset prices to underlying income flows--for example, higher ratios of prices to earnings for stocks or higher prices of buildings relative to rents. If asset markets were highly efficient and participants had excellent foresight, this would not necessarily lead to imbalances. However, to the extent that financial markets extrapolate price movements, markets may not transition smoothly to asset valuations that reflect underlying fundamentals but may instead evidence periods of overshooting.18 Such forces may have played a role in both the stock market boom that ended in the bust of 2001 and the house price bubble that burst in 2007-09.\n\nThe risks of such financial imbalances may be greater in the context of the kind of explicit inflation target overshooting policies proposed in the paper. Again, if market participants were perfectly rational, overshooting policies would not likely pose financial stability risks. But the combination of low interest rates and low unemployment that would prevail during the inflation overshooting period could well spark capital markets to overextend, leading to financial imbalances.\n\nMacroprudential tools are the preferred first line of defense to address such financial imbalances, which should in principle enable monetary policy to focus on price stability and macroeconomic stabilization. But the development and deployment of macroprudential tools is still relatively untested in the U.S. context, and the toolkit is limited. Although important research suggests that the situations under which monetary policy should take financial imbalances into account are likely to be very rare, some recent research has pointed out that the case in favor of taking financial imbalances into account is strengthened when the consequences of financial crises are long lasting.19 In this case, another complication of a persistently low neutral rate may be a sharper tradeoff between achieving the traditional dual-mandate objectives and avoiding financial stability risks, which may make it even more difficult to achieve our price-stability objective.\n\nReferences\nBernanke, Ben S. (2017). \"Monetary Policy for a New Era,\" paper prepared for \"Rethinking Macroeconomic Policy,\" a conference held at the Peterson Institute for International Economics, Washington, October 12.\n\nBrainard, Lael (2015). \"Normalizing Monetary Policy When the Neutral Interest Rate Is Low,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford, Calif., December 1.\n\n-------- (2016a). \"What Happened to the Great Divergence?\" speech delivered at the 2016 U.S. Monetary Policy Forum, New York, February 26.\n\n-------- (2016b). \"The 'New Normal' and What It Means for Monetary Policy,\" speech delivered at the Chicago Council on Foreign Affairs, Chicago, September 12.\n\n-------- (2017a). \"Cross-Border Spillovers of Balance Sheet Normalization,\" speech delivered at the National Bureau of Economic Research's Monetary Economics Summer Institute, Cambridge, Mass., July 13.\n\n-------- (2017b). \"Understanding the Disconnect between Employment and Inflation with a Low Neutral Rate,\" speech delivered at the Economic Club of New York, New York, September 5.\n\nCase, Karl E., Robert J. Shiller, and Anne K. Thompson (2012). \"What Have They Been Thinking? Homebuyer Behavior in Hot and Cold Markets (PDF),\" Brookings Papers on Economic Activity, Fall, pp. 265-98.\n\nEggertsson, Gauti B., and Michael Woodford (2003). \"The Zero Bound on Interest Rates and Optimal Monetary Policy,\" Brookings Papers on Economic Activity, Spring, pp. 139-233.\n\nGerdrup, Karsten R., Frank Hansen, Tord Krogh, and Junior Maib (2017). \"Leaning against the Wind When Credit Bites Back,\" International Journal of Central Banking, September.\n\nGourio, Francois, Anil K. Kashyap, and Jae Sim (2016). \"The Tradeoffs in Leaning against the Wind (PDF),\" paper presented at the 17th Jacques Polak Annual Research Conference, sponsored by the International Monetary Fund, Washington, November 3.\n\nGreenwood, Robin, and Andrei Shleifer (2014). \"Expectations of Returns and Expected Returns,\" Review of Financial Studies, vol. 27 (March), pp. 714-46.\n\nKamin, Steven B., Canlin Li, and Marius D. Rodriguez (forthcoming). \"International Spillovers from Conventional and Unconventional Monetary Policy,\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System.\n\nKiley, Michael T., and John M. Roberts (2017). \"Monetary Policy in a Low Interest Rate World (PDF),\" Finance and Economics Discussion Series 2017-080. Washington: Board of Governors of the Federal Reserve System, August.\n\nKrippner, Leo (2016). \"Documentation for Measures of Monetary Policy (PDF),\" Reserve Bank of New Zealand Working Paper. Wellington, New Zealand: Reserve Bank of New Zealand, July.\n\nNakata, Taisuke, and Sebastian Schmidt (2016). \"The Risk-Adjusted Monetary Policy Rule (PDF),\" Finance and Economics Discussion Series 2016-061. Washington: Board of Governors of the Federal Reserve System, July.\n\nReifschneider, David, and John C. Williams (2000). \"Three Lessons for Monetary Policy in a Low-Inflation Era,\" Journal of Money, Credit and Banking, vol. 32 (November), pp. 936-66.\n\nSvensson, Lars E. (2016). \"Cost-Benefit Analysis of Leaning against the Wind,\" NBER Working Papers Series 21902. Cambridge, Mass.: National Bureau of Economic Research, January.\n\nWu, Jing Cynthia, and Fan Dora Xia (2016). \"Measuring the Macroeconomic Impact of Monetary Policy at the Zero Lower Bound,\" Journal of Money, Credit and Banking, vol. 48 (March-April), pp. 253-91.\n\nYellen, Janet L. (2016). \"The Federal Reserve's Monetary Policy Toolkit: Past, Present, and Future,\" speech at \"Designing Resilient Monetary Policy Frameworks for the Future,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyoming, August 26.\n\n1. Bernanke (2017). Return to text\n\n2. I am grateful to John Roberts for his assistance in preparing this text. The remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n3. See Brainard (2015, 2016b). Return to text\n\n4. The well-known Laubach-Williams model currently suggests an estimate of the longer-run neutral federal funds rate that is close to zero. The latest estimates are available on the Federal Reserve Bank of San Francisco's website at http://www.frbsf.org/economic-research/files/Laubach_Williams_updated_estimates.xlsx. Over the 1960-2007 period, the real federal funds rate--measured as the nominal federal funds rate less trailing four-quarter core PCE (personal consumption expenditures) inflation--averaged 2-1/2 percent. Return to text\n\n5. See, for example, Brainard (2017b), Kiley and Roberts (2017), and Nakata and Schmidt (2016). Return to text\n\n6. The inflation information refers to core PCE inflation measured on a 12-month average basis. Return to text\n\n7. See Brainard (2017b). Return to text\n\n8. See, for example, Eggertsson and Woodford (2003) or Reifschneider and Williams (2000). Return to text\n\n9. As Bernanke notes, one way to avoid this feature is to adopt \"flexible price-level targeting,\" in which policy takes into account resource utilization as well as the deviation of the price level from its target. Kiley and Roberts (2017) examine a form of flexible price-level targeting—which they refer to as a \"shadow rate rule\"—and find that it performs well. Return to text\n\n10. The 2010 G-20 Toronto communiqué indicated that advanced economies \"committed to fiscal plans that will at least halve deficits by 2013 and stabilize or reduce government debt-to-GDP ratios by 2016.\" The document is available on the U.S. Department of the Treasury's website at https://www.treasury.gov/resource-center/international/Documents/The%20G-20%20Toronto%20Summit%20Declaration.pdf (PDF). Return to text\n\n11. In the paper, this rule is specified as an inertial Taylor rule. Return to text\n\n12. See Yellen (2016). Return to text\n\n13. See Brainard (2015). Return to text\n\n14. See, for instance, Krippner (2016) and Wu and Xia (2016). Return to text\n\n15. See Brainard (2016a, 2016b). Return to text\n\n16. See Kamin, Li, and Rodriguez (forthcoming). Return to text\n\n17. See Brainard (2017a). Return to text\n\n18. See, for example, Case, Shiller, and Thompson (2012) and Greenwood and Schleifer (2014). Return to text\n\n19. See, for example, Svensson (2016). See Gourio, Kashyap, and Sim (2016) and Gerdrup and others (2016). Return to text"
    },
    {
        "title": "Prospects for Emerging Market Economies in a Normalizing Global Economy",
        "date": "October 12, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20171012a.htm",
        "content": "October 12, 2017\n\nGovernor Jerome H. Powell\n\nAt the 2017 Annual Membership Meeting of the Institute of International Finance, Washington, D.C.\n\nThank you for inviting me to speak here at the Institute of International Finance Annual Membership meeting. I am pleased to note that there have been signs lately that a sustainable global recovery may finally be materializing. This is certainly good news, although significant risks and uncertainties remain. One important question is how the emerging market economies (EMEs) will fare as global monetary conditions normalize. In our intertwined world, prospects for these economies are a significant driver of prospects for the United States and other advanced economies. In my remarks today I will argue that, despite the risks and uncertainties, EMEs are likely to manage that normalization reasonably well.\n\nAs many observers have noted, EME economic prospects are strongly linked to the evolution of capital flows.1 Accordingly, I will first review the recent rebound in EME capital inflows and analyze the drivers of this rebound. Against this backdrop, I will then discuss how the prospects for EMEs depend on three factors: Vulnerabilities in the EMEs themselves; the evolution of advanced-economy monetary conditions, including those in the United States; and market responses to that evolution. As always, my comments here represent my own views.\n\nThe Rebound in Economic Growth and Capital Flows in Emerging Markets\nAfter real GDP growth plummeted in many EMEs during the Global Financial Crisis (GFC), economic activity rebounded sharply (slide 1). But that recovery proved to be short lived and was followed by a notable, widespread fall in EME growth as advanced economies remained sluggish, economic imbalances in China mounted, and commodity prices plunged. Lately, however, the streak of weak growth in the EMEs appears to have been broken: The downward trend in Chinese growth has flattened, growth in other EMEs has picked up some, and Brazil seems to be moving into recovery mode. The factors that underlie the pickup in EMEs to a large extent represent a reversal of developments that led to the slowing. The improvement in the performance of the advanced economies has become more widespread. Chinese authorities have bolstered their economy by providing more credit stimulus. And commodity prices have bounced back from their lows in early 2016, bolstering activity and allaying financial stability concerns in commodity-exporting economies. These developments have also contributed to a modest reversal of the slowdown in global trade seen in recent years.2\n\nA rebound in capital flows has come along with the pickup in economic performance in the EMEs. Slide 2 shows net private capital flows to EMEs--the difference between gross private inflows and gross private outflows. These private net inflows are quite volatile, as the experience of the past 10 years shows. Strong pre-GFC net inflows to major emerging markets (the black line)--hovering in the neighborhood of 3 to 4 percent of EME gross domestic product (GDP)--were interrupted by a collapse during the crisis, but inflows quickly recovered and stayed strong through 2010. After that, net inflows trended down for several years and turned negative by 2015. Part of this retrenchment reflected Chinese net inflows turning into net outflows due to what might be considered special circumstances--notably, changes in expectations of Chinese exchange rate policy. But even taking China out of the picture, as shown by the dashed blue line, there was a clear downward trend in net inflows.\n\nOver the past couple of years, however, net inflows have recovered and have averaged, if China is excluded, 0.7 percent of GDP in 2016 and about 1-1/2 percent of GDP in early 2017. As shown in slide 3, other measures of capital flows, such as flows into EME investment funds, show an even sharper rebound.\n\nThe recent recovery of investor appetite for EME exposure has shown up in asset prices as well. Emerging-market credit spreads have declined, and equity prices have risen (slide 4). These developments are not occurring in isolation, but in the context of a general improvement in the global outlook and in investor risk sentiment. The improvement in economic fundamentals raises the following question: To what extent can the recent recovery in EME capital flows be explained by these better economic fundamentals?\n\nOne way to shed light on this question is to compare the recent behavior of EME capital flows with what we might expect from a model of these flows based on historical data. In a recent study, Federal Reserve staff regressed net private capital inflows into several key EMEs on measures of investment opportunities in these economies, monetary policy variables, and risk sentiment variables.3 As can be seen in slide 5, by comparing the solid and dashed lines, the model does a fairly good job overall of fitting the data.\n\nIt is instructive to look at what the model tells us about the slowing of flows between 2010 and 2015. Note that the falloff in commodity prices (the red portion of the bars) was the largest contributor to the slowdown in flows. The decline in economic growth differentials between the EMEs and advanced economies (the yellow portions) was also a major contributor. In fact, growth differentials became a slightly negative contributor in 2015 after being substantially positive in 2010.4 Monetary policies (the blue portions) also became less of a factor in 2015 in driving flows to EMEs.\n\nAs for the recent rebound in flows, over the past year the model's predicted net inflows (the dashed line) have actually been significantly above actual net inflows (the solid line), suggesting that there is some room for flows to increase further without raising concerns. The model attributes the recovery of flows primarily to the turnaround in commodity prices and, to a substantially lesser extent, to improvements in risk sentiment (as seen by some waning of the negative contribution from the slashed green bars). The growth differential is not playing a major role because the rise in EME growth has been accompanied by a rise in advanced-economy growth.5\n\nAll in all, this evidence suggests that the recent pickup of capital flows to EMEs has not outrun its fundamental determinants, which provides some encouragement that these flows will not reverse themselves and endanger EME prospects, a situation that is also encouraging for U.S. prospects.\n\nRisks to Emerging Market Economy Prospects from the Future Course of Monetary Policy\nSome observers have noted that the risk of a reversal of EME capital flows may become more pronounced as U.S. and global interest rates return to more normal levels. These developments could encourage capital to return to the advanced economies and, by raising domestic interest rates and putting downward pressures on emerging market currencies, could also enlarge EME debt burdens. In assessing this risk, as I mentioned earlier, three elements are important: first, the vulnerabilities in the EMEs themselves; second, the evolution of advanced-economy monetary policies; and, third, how markets might respond to that evolution. Let me discuss each of these elements in turn.\n\nEmerging Market Economy Vulnerabilities\nThere is clear empirical evidence that the response of EME financial markets to different shocks, including changes in U.S. interest rates, depends importantly on the state of economic fundamentals in the EMEs themselves. For example, Bowman and coauthors document in their study that a deterioration in a country's economic conditions significantly increases its vulnerability to adverse effects from changes in U.S. interest rates.6 A case in point is the so-called taper tantrum in 2013, when rises in sovereign bond spreads were significantly greater in those EMEs with greater relative vulnerabilities.\n\nThere is little doubt that over the past couple of decades, EME macroeconomic fundamentals and policy frameworks have improved substantially. One way you can see this improvement is through an index of aggregate EME vulnerability (the black line in slide 6), which is based economic data on a variety of variables from 13 major economies.7 According to this index, EME vulnerabilities today stand well below those in the 1990s--a period during which financial crises in EMEs were much more prevalent.\n\nThat said, the vulnerability index has been trending up since 2008. Part of this increase in the vulnerability index can be attributed to a run-up in bank credit to the private sector, which brings me to a key risk for EME prospects: the position of EME corporates. Observers have been expressing concerns about the mounting levels of corporate debt and the risk that a normalization of global conditions could exacerbate debt service burdens of EME corporations--particularly those with elevated levels of dollar-denominated debt--by raising global interest rates, boosting the value of the dollar, and perhaps damping economic activity. Given the prominence of this risk, I will discuss EME corporates in a bit more detail.\n\nSince 2008, the debt of EME nonfinancial corporations has tripled in dollar value, reaching roughly $27 trillion in the first quarter of 2017. As a share of GDP, as shown by the black line in slide 7, it has nearly doubled, to over 100 percent of GDP. China's situation is distinct from many other EMEs. On the one hand, as can be seen by the red line, its corporate debt, at 170 percent of GDP now, is much higher than most other EMEs and substantially above the level we saw in East Asia before the Asian crisis. On the other hand, Chinese corporates are much less exposed to changes in exchange rates and global interest rates.\n\nBut the rising amount of debt by itself does not tell us whether this debt is excessive and how vulnerable EME corporates are to global monetary and market shocks. For that assessment we need to drill down deeper into the health of the corporate sector. In a recent study, Beltran and coauthors undertake such an analysis using a common metric of debt service capacity--the interest coverage ratio, or ICR, which is the ratio of earnings to interest expense.8 All else being equal, this ratio is lower for firms that are less profitable, more leveraged, and have a higher cost of borrowing. Using firm-level data, the authors classify the debt of those firms with an ICR of less than 2 as \"debt-at-risk.\"9 They find, as shown by the black line in slide 8, that this measure of risky EME corporate debt has almost tripled since 2011 to about 30 percent of GDP. But this share is still considerably lower than the 46 percent of GDP debt-at-risk in East Asia on the eve of the Asian crisis (the horizontal dashed black line in the chart). For China, though, the debt-at-risk now exceeds what we saw in East Asia before the Asian crisis. Outside of China (the dashed blue line), EME debt-at-risk, at about 10 percent of GDP, seems much more manageable. However, as can be seen by the blue portions of the bars in slide 9, debt-at-risk in a number of EMEs, including South Korea, India, Turkey, and Brazil exceeds that average level.\n\nHow will EME corporate debt fare going forward as global normalization proceeds? The results of the study I just discussed imply that a 1 percentage point increase in EME corporate borrowing costs by itself would not be so problematic, at least outside of China.10 What this shock would do to debt-at-risk is shown by the red cross‑hatched portions of the bars in the chart. But it would be a bigger deal if the rise in borrowing costs was accompanied by a more generalized adverse turn of events in EMEs, modeled here as a 20 percent earnings reduction and a 20 percent hit to the value of EME currencies against the dollar. The estimated effects of these additional shocks on debt-at-risk are shown by the slashed red portions of the bars.11 In this case, aggregate EME debt-at-risk rises from about 30 percent of GDP to around the level seen prior to the Asian financial crisis.12 Notably, the increase comes mainly from China, where debt‑at‑risk jumps to about 85 percent of GDP. Outside of China, risky debt also rises substantially but seemingly not to levels that would be considered unmanageable.\n\nOverall, based on this analysis, I would conclude that corporate debt represents a moderate degree of vulnerability for EME prospects. The situation is not alarming, but risks are significant and bear close watching, especially in China.\n\nThe Evolution of Federal Reserve Policy\nWhat of the evolution of monetary conditions in the advanced economies? I will confine myself here to Fed policy. One factor that favors easier adjustment in EMEs is that U.S. monetary policy normalization has been and should continue to be gradual, as long as the U.S. economy evolves roughly as expected.\n\nSince the start of normalization in December 2015, the federal funds rate has risen to about 1‑1/4 percent from its effective lower bound (slide 10). The median projections of Federal Open Market Committee (FOMC) participants (the blue dots) have it rising to 2.9 percent by the end of 2020, fairly close to what is regarded by the median participant as its long-run value and significantly below its average value in the years prior to the GFC. As reflected in the FOMC's recent communications, the shrinkage of the Fed's balance sheet is also expected to proceed quite gradually, with slowly phased-in increases in caps on the monthly reductions in the Federal Reserve's security holdings.\n\nThe expectation of gradual policy normalization should reduce the likelihood of outsized movements in interest rates. Indeed, even if we add, say, a 50 basis point term premium to the expected long-run federal funds rate, this value would still leave long-term U.S. interest rates (shown in slide 11) well below their pre-GFC averages. As long as global financial conditions normalize in an orderly fashion, EMEs should have sufficient time to adjust. And, as we saw earlier, interest rate changes of this magnitude should not lead to generalized corporate distress in EMEs, although undoubtedly some corporates are more exposed and could experience difficulties.\n\nMarket Response\nAll that said, market movements can be noisy, which brings me to what I believe is the most uncertain element--the potentially volatile behavior of markets even in an environment of relatively contained EME vulnerabilities and of gradual and clearly communicated advanced-economy monetary policies.\n\nSo far, markets have behaved in a manner consistent with a relatively benign scenario for EMEs: Risk sentiment is holding up, credit spreads in emerging markets have been declining, equities are up, long-term yields have hardly budged, and the dollar has been declining. Markets, however, can turn on a dime, and reactions can be outsized. This concern may be especially relevant at present, given the low level of volatility and elevated asset prices in global markets, which may increase the likelihood and severity of an adjustment.\n\nMost of the time bouts of market turbulence lead to relatively quick corrections that leave markets more resilient without substantially depressing global growth. The taper tantrum of 2013 that I mentioned earlier is a good example. Ultimately, the policy adjustments made by some of the most affected economies, along with the more realistic appraisal of risks by global investors, likely left the global economy in a somewhat better position than before the episode. That said, however, market tantrums pose complex economic and financial challenges, and such episodes carry a significant risk of snowballing into something bigger that more substantially threatens the economic expansion.\n\nConclusion\nTo conclude, I have suggested that the most likely outcome is that the challenges posed to EMEs by the normalization of global financial conditions will be manageable.13 So far, capital flows have been moving in line with market fundamentals. Although, EME vulnerabilities have been rising, they are still well below the levels of the crisis-prone years of the 1980s and 1990s. Global monetary conditions are expected to normalize only gradually, as the Federal Reserve and other advanced-economy central banks continue to stress clear communication and transparency. And the reaction of EME financial markets so far has been benign. But significant risks of more adverse scenarios remain. The corporate debt situation in EMEs has been worsening, particularly in China, and market reactions to even small surprises can be unpredictable and outsized.\n\nEven with these risks, however, the best thing the Federal Reserve can do--not just for the United States, but for the global economy at large--is to keep our house in order through the continued pursuit of our dual mandate. Finally, it bears remembering that Fed policy normalization is occurring not in isolation, but in the context of a solid U.S. economic recovery, which should benefit all economies around the world.\n\nReferences\nAhmed, Shaghil, and Andrei Zlate (2014). \"Capital Flows to Emerging Market Economies: A Brave New World?\" Journal of International Money and Finance, vol. 48 (November), pp. 221-48.\n\nAlfaro, Laura, Gonzalo Asis, Anusha Chari, and Ugo Panizza (2017). \"Lessons Unlearned? Corporate Debt in Emerging Markets,\" NBER Working Paper 23407. Washington: National Bureau of Economic Research, May.\n\nAyala, Diana, Milan Nedelijkovic, and Christian Saborowski (2015). \"What Slice of the Pie? The Corporate Bond Market Boom in Emerging Economies (PDF),\" IMF Working Paper WP/15/148. Washington: International Monetary Fund, July.\n\nBeltran, Daniel, Keshav Garud, and Aaron Rosenblum (2017). \"Emerging Market Nonfinancial Corporate Debt: How Concerned Should We Be?\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System, June 1.\n\nBowman, David, Juan M. Londono, and Horacio Sapriza (2015). \"U.S. Unconventional Monetary Policy and Transmission to Emerging Market Economies,\" Journal of International Money and Finance, vol. 55 (July), pp. 27-59.\n\nBruno, Valentina, and Hyun Song Shin (2015). \"Capital Flows and the Risk-Taking Channel of Monetary Policy,\" Journal of Monetary Economics, vol. 71 (April), pp. 119‑32.\n\nCavallo, Eduardo, Andrew Powell, Mathieu Pedemonte, and Pilar Tavella (2015). \"A New Taxonomy of Sudden Stops: Which Sudden Stops Should Countries Be Most Concerned About?\" Journal of International Money and Finance, vol. 51 (March), pp. 47-70.\n\nChen, Jiaqian, Tommaso Mancini-Griffoli, and Ratna Sahay (2014). \"Spillovers from United States Monetary Policy on Emerging Markets: Different This Time? (PDF)\" IMF Working Paper WP/14/240. Washington: International Monetary Fund, December.\n\nChow, Julian T.S. (2015). \"Stress Testing Corporate Balance Sheets in Emerging Economies,\" IMF Working Paper WP/15/216. Washington: International Monetary Fund, September, available at http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=8A054997E3FBA6EC30B9601BA692B9F4?doi=10.1.1.698.5498&rep=rep1&type=pdf (PDF).\n\nClark, John, Nathan Converse, Brahima Coulibaly, and Steve Kamin (2016). \"Emerging Market Capital Flows and U.S. Monetary Policy,\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System, October 18.\n\nFratzscher, Marcel (2012). \"Capital Flows: Push Versus Pull Factors, and the Global Financial Crisis,\" Journal of International Economics, vol. 88 (November), pp. 341-56.\n\nFratzscher, Marcel, Marco Lo Duca, and Roland Straub (2013). \"On the International Spillovers of U.S. Quantitative Easing,\" ECB Working Paper 1557. Frankfurt: European Central Bank, June.\n\nGhosh, Atish R., Jun Kim, Mahvash S. Qureshi, and Juan Zalduendo (2012). \"Surges (PDF),\" IMF Working Paper WP/12/22. Washington: International Monetary Fund, January.\n\nHausman, Joshua, and Jon Wongswan (2011). \"Global Asset Prices and FOMC Announcements,\" Journal of International Money and Finance, vol. 30 (April), pp. 547-71.\n\nInternational Monetary Fund (2014). \"Moving from Liquidity to Growth-Driven Models,\" chapter 1 of Global Financial Stability Report. Washington: IMF, April, pp. 1-65.\n\n--------- (2016a). \"Financial Stability Challenges in a Low-Growth, Low-Rate Era,\" chapter 1 of Global Financial Stability Report. Washington: IMF, October, pp. 1-48.\n\n--------- (2016b). \"Understanding the Slowdown in Capital Flows to Emerging Markets,\" chapter 2 in World Economic Outlook: Too Slow for Too Long. Washington: IMF, April, pp. 63-99.\n\n--------- (2017). \"Is Growth at Risk?\" chapter 1 of Global Financial Stability Report. Washington: IMF, October, pp.1-52.\n\nKoepke, Robin (2015). \"What Drives Capital Flows to Emerging Markets? A Survey of the Empirical Literature,\" IIF Working Paper. Washington: Institute of International Finance, April, available at https://www.iif.com/publication/capital-flows/what-drives-capital-flows-emerging-markets-2.\n\nPomerleano, Michael (1998). \"Corporate Finance Lessons from the East Asian Crisis (PDF),\" Note 155. Washington: World Bank Group, October.\n\nPowell, Jerome H. (2013). \"Advanced Economy Monetary Policy and Emerging Market Economies,\" speech delivered at \"Prospects for Asia and the Global Economy,\" the 2013 Asia Economic Policy Conference sponsored by the Federal Reserve Bank of San Francisco, San Francisco, Calif., November 4.\n\n--------- (2016). \"The Global Trade Slowdown and Its Implications for Emerging Asia,\" speech delivered at \"CPBS 2016 Pacific Basin Research Conference,\" sponsored by the Center for Pacific Basin Studies at the Federal Reserve Bank of San Francisco, San Francisco, Calif., November 18.\n\nTepper, Alexander, Jeffrey Moore, Myeongguk Suh, and Sunwoo Nam (2013). \"Estimating the Impacts of U.S. LSAPs on Emerging Market Economies' Local Currency Bond Markets,\" Staff Report 595. New York: Federal Reserve Bank of New York, January.\n\n1. For more on this linkage, see Powell (2013). Return to text\n\n2. For more on the global trade slowdown, see Powell (2016). Return to text\n\n3. The specific variables in the regression include the GDP growth differential between EMEs and advanced economies, commodity prices, EME interest rate differentials with advanced economies, measures of the Federal Reserve's quantitative easing, the VIX (which is the one-month-ahead option-implied volatility of the S&P 500 index), and country-specific emerging market credit spreads (see Clark and others, 2016). Note that, because of special factors driving its flows over the past few years, China is not included in this analysis. Other studies that have also examined determinants of EME capital flows include International Monetary Fund (2016b), Koepke (2015), Ahmed and Zlate (2014), Fratzscher (2012), and Ghosh and others (2012). Generally, these papers find that many factors, including both \"pull\" and \"push,\" affect EME capital flows. Return to text\n\n4. This negative contribution reflects that the average growth differential between the selected group of EMEs, which does not include China, and the advanced economies itself became negative. Return to text\n\n5. Variants of the model applied to gross capital inflows, rather than net capital inflows, give qualitatively similar results. In particular, the model of gross flows also finds that the pickup in these flows has been less strong than predicted by the model. However, the relative contribution of the risk variables to the pickup in EME flows relative to the turnaround in commodity prices is somewhat larger with the gross flows model than the net inflows model. The consequences of net versus gross flows for the recipient economies can potentially differ as, for example, Cavallo and others (2015) have argued. Return to text\n\n6. See Bowman, Londono, and Sapriza (2015). Other papers that have looked at the effects of U.S. monetary policies on EME asset prices and the channels through which these effects are transmitted include Bruno and Shin (2015); Chen, Mancini-Griffoli, and Sahay (2014); Fratzscher, Lo Duca, and Straub (2013); Tepper and others (2013); and Hausman and Wongswan (2011). Return to text\n\n7. Variables used in creating the index include external debt, the current account position, foreign reserves, public debt, control of inflation, and bank credit to the private sector. Return to text\n\n8. See Beltran, Garud, and Rosenblum (2017). Other studies that have recently investigated EME corporate vulnerabilities include Alfaro, Chari and Panizza (2017); International Monetary Fund (2014, 2016a); and Chow (2015). Return to text\n\n9. An ICR of 2 or less is often associated with increased likelihood of distress. For example, just before the Asian financial crisis, firms in Indonesia, South Korea, and Thailand had an average ICR of 2 (see Pomerleano, 1998). Return to text\n\n10. A 1 percentage point positive shock to the borrowing costs of EME corporates undoes about half of the decline in average borrowing costs from 2009 to 2016. Although on the face of it, this shock does not seem too large, as discussed in Beltran and others (2017), it is applied to the average interest rate on the entire existing debt, not just on new debt. Given that the average interest rate for EME firms is about 4‑3/4 percent, a 1 percentage point rise increases the interest expense by about a fifth. Return to text\n\n11. The calibration of the shocks is the same as in Beltran and others (2017). A 20 percent earnings shock corresponds to about half of the decline in EME corporate earnings experienced after the global financial crisis. It is difficult to say how much emerging market currencies might depreciate under stress, but 20 percent currency depreciation seems well within the plausible range. While the calibration of the shocks is the same as the above-mentioned study, the effects have been updated to reflect a larger sample of firms that is now available. Qualitatively, the results and conclusions do not change from this update. Return to text\n\n12. In computing the new debt-at-risk after exchange rate shocks, we need the share of debt that is foreign currency-denominated, which is taken from Ayala, Nedelijkovic, and Saborowski (2015). Return to text\n\n13. The IMF's most recent Global Financial Stability Report, released October 11, (IMF, 2017), also concludes that EMEs should be able to handle any reduction in flows from global monetary policy normalization \"in a relatively smooth manner, given their enhanced resilience and stronger growth outlook.\" Return to text"
    },
    {
        "title": "Treasury Markets and the TMPG",
        "date": "October 05, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20171005a.htm",
        "content": "October 05, 2017\n\nGovernor Jerome H. Powell\n\nAt TMPG Best Practices @ 10: A Look Back and a Look Ahead, Federal Reserve Bank of New York, New York, New York\n\nI am honored to join you to celebrate the first 10 years of the Treasury Market Practices Group (TMPG). The TMPG has become an essential forum where industry participants gather under the auspices of the Federal Reserve Bank of New York to address market practice issues as they arise in the fast evolving markets for Treasury securities. Outside this room, you are competitors, and that vigorous competition serves your firms, your customers, and ultimately the U.S. taxpayer. But when members of the TMPG attend meetings, they bring their long experience and deep expertise to bear to safeguard the functioning and overall health of these markets. As I have heard a number of people say, TMPG members check their partisan interests at the door. The TMPG is the place where market participants recognize and address their responsibilities to each other. I know that they take that responsibility seriously, and I encourage all of the market participants here today to take the TMPG's recommendations just as seriously and to adopt them as best practices that will enhance the market's functioning.\n\nI first encountered Treasury markets in a serious way 25 years ago, when I served as Under Secretary of the Treasury for Finance under President George H. W. Bush. These markets made national headlines when we learned that a Salomon Brothers' trader had repeatedly circumvented Treasury auction rules to corner the market for the on-the-run two-year Treasury. As it became clear that Salomon's senior management had known about the issue for several months without alerting regulators, the scandal threatened to bring down one of the largest financial firms of that time. Over one memorable August weekend, we first prohibited the firm from dealing in government securities on behalf of customers, and then reduced that sanction as top Salomon management left the firm and Warren Buffett, then a large Salomon shareholder, agreed to assume the chairmanship of the board of directors. This event takes up a chapter in Buffett's biography, The Snowball, and it is a good illustration of why we need the TMPG. I reread that chapter every couple of years, and it still gives me nightmares.1\n\nAfter the dust settled, we had to grapple with the wider implications of the scandal for the market itself and particularly the role of regulatory oversight. We certainly could have used a TMPG to help us with this work, but none existed at that time. Our recommendations were summarized in a joint report to the Congress issued by the Treasury Department, the Securities and Exchange Commission (SEC), and the Federal Reserve Board. Among the issues we considered were how to encourage a level playing field for all market participants, and when and where regulators should respond to the periodic technical difficulties the market sometimes experienced.\n\nAs we drew up the report, we were deeply aware of the importance that Treasury markets held for the American economy. The sale of Treasury bonds, notes, and bills finances the U.S. government, and those securities are in turn a primary vehicle for savings for a wide range of U.S. households. Treasury securities are also an important source of collateral within the financial system. This last role has become all the more critical in recent years as regulations have required banks to hold larger amounts of high-quality liquid assets so that they can safely meet their potential liquidity needs.\n\nWe also knew that, despite the misconduct by Salomon Brothers, Treasury markets generally worked quite well. These markets are and have long been among the deepest and most liquid markets in the world. It was important to make the auction system more robust to potential manipulation, and we made several recommendations to do so and to open up the process to greater competition. However, in other areas that already worked well, we chose, for example, to open up issuance of securities that were in short supply (or \"squeezed\") when needed rather than to risk negatively affecting the functioning of Treasury markets by instituting more invasive regulation.\n\nThere is certainly a role for regulation, but regulation should always take into account the impact that it has on markets--a balance that must be constantly weighed. More regulation is not the best answer to every problem. There is also a role for a body such as the TMPG to address market problems.\n\nThe TMPG's approach to \"fails\" in the Treasury and mortgage-backed securities markets provides a good example. Fails--that is, the failure to deliver collateral in either a cash or repurchase agreement transaction--impose a cost on the party expecting delivery. If the practice were to become too frequent, then it could seriously impair market functioning. But at the same time, it doesn't make sense to simply outlaw the practice, since that limits flexibility in a way that may not always be called for and would likely reduce market liquidity. The TMPG's recommendations were carefully calibrated to set financial incentives that would minimize fails and have been a marked success.\n\nThe TMPG also plays an important role in helping to \"fill in the cracks\" between the competing regulations that various Treasury market participants face. Many different institutions and individuals depend on these markets, and the regulatory system reflects that. The Government Securities Act gave the Treasury Department some rulemaking authority over all government securities brokers and dealers. But the act also required these firms to register with the SEC. At the same time, the Federal Reserve regulates many of the banks that are active in these markets, and the Federal Reserve Bank of New York also plays an essential role, both as fiscal agent for the U.S. government and, by nature of its frequent activity in these markets, in conducting monetary policy operations. And of course, the Commodity Futures Trading Commission regulates Treasury futures markets. The agencies work well together, but there is real value in having an industry group help to identify issues that cross regulatory boundaries.\n\nI'll give two examples. First, in 2016, the TMPG conducted a study of financial benchmarks and uncovered uses of ICAP's federal funds open rate that had not previously been well understood.2 As ICAP decided to stop publishing the rate, the TMPG also helped to guide market participants to an alternative that is aligned with the International Organizations of Securities Commissions Principles for Financial Benchmarks while steering the market away from the London Interbank Offered Rate (LIBOR) as a potential alternative--a move that now seems prescient given the subsequent news around the long-run risks to LIBOR. More recently, the TMPG has been busy creating a map of clearing and settlement in Treasury markets, work that I am sure all of the regulatory agencies will find to be of great interest.\n\nAll of this is incredibly valuable. In fact, my only regret about the TMPG is that we didn't think of creating something like it earlier. As regulators, we fully support your work, and will continue to make sure that our own rules support these markets. The Financial Industry Regulatory Authority's (FINRA's) new collection of the Treasury transactions of its members through its Trade Reporting and Compliance Engine, or TRACE system, will do much to improve the regulatory agencies' understanding of the dynamics of this market. But as in the past, we should also be concerned about creating a level playing field. For that reason, the Board of Governors is continuing to negotiate with FINRA for it to act as our agent in collecting similar data from banks. We do not want to create a regulatory arbitrage where the same activity done within a broker-dealer is treated differently than when it is done within a bank.\n\nThe TMPG and similar groups around the world play an important role by helping both regulators and industry leaders address market concerns before they threaten market function. I thank the members for their service and look forward to today's discussions.\n\n1. Alice Schroeder, The Snowball: Warren Buffett and the Business of Life (New York: Bantam, 2009). Return to text\n\n2. The ICAP Fed Funds Open rate was a daily indicator published by ICAP, a broker in the federal funds market, as to where a representative federal fund transaction would be priced at the start of the U.S. trading day. ICAP did not consider the rate to be International Organizations of Securities Commissions compliant, although it was nonetheless used as a financial benchmark by some market participants. ICAP ceased publication of the index in September 2016. Return to text"
    },
    {
        "title": "Welcoming Remarks",
        "date": "October 04, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20171004a.htm",
        "content": "October 04, 2017\n\nChair Janet L. Yellen\n\nAt Community Banking in the 21st Century Fifth Annual Community Banking Research and Policy Conference cosponsored by the Federal Reserve System and Conference of State Bank Supervisors, Federal Reserve Bank of St. Louis, St. Louis, Missouri\n\nI am very glad to welcome everyone here to this conference sponsored by the Federal Reserve System and the Conference of State Bank Supervisors. Since the first of these gatherings five years ago, this research and policy conference has established itself as an important event where industry leaders, academics, and supervisors discuss the latest research and exchange ideas about promoting a healthy and growing community banking industry.\n\nAll of us share an interest in seeing that community banks continue their vital role in their customers' lives and in a strong and stable U.S. financial system. The Fed has been working hard to ensure that its regulation and supervision of banks are tailored appropriately to the size, complexity, and role different institutions play in the financial system. For community banks, which by and large avoided the risky business practices that contributed to the financial crisis, we have been focused on making sure that much-needed improvements to regulation and supervision since the crisis are appropriate and not unduly burdensome.\n\nOne way we are doing this is through the regulatory review required by the Economic Growth and Regulatory Paperwork Reduction Act, known as EGRPRA. The first step we took, pursuant to EGRPRA, was to listen to industry and others with a stake in how community banks are supervised, which was accomplished through soliciting written comments and by holding six outreach meetings in 2014 and 2015. Our EGRPRA report, issued in March, was focused on community banks, and it noted steps that had already taken place, for example, to simplify Call Report requirements and expand the number of firms eligible for less frequent examinations. Since that report, the Board of Governors, along with the Federal Deposit Insurance Corporation and the Office of the Comptroller of the Currency, has proposed a rule expanding the number of commercial real estate transactions that will no longer require an appraisal, allowing for a less detailed evaluation. And just last week, the Fed, along with other regulators, took a significant step to reduce the regulatory burden on community banks and other smaller and less complex institutions by proposing to simplify several requirements in the regulatory capital rule.\n\nWe have done this because we have an abiding commitment to consider how our decisions affect institutions and the customers they serve. We are well aware that community banks serve communities, businesses, and households that are often underserved by larger institutions and offer more extensive and more personalized services than are often otherwise available. We know that community bankers are part of the communities they serve, and they are often better able to understand the needs and the aspirations of their customers.\n\nWe hope that the research presented at this conference stimulates discussion about the leading policy issues facing the industry and supervisors. As in the past, I see that this year's agenda includes presentations related to several important issues, including the effect of supervision on risk-tasking and the effects of greater competition on community banks. I am cheered to see that finance students at the University of Akron remain interested enough in community banking to participate in a case-study competition related to community banking, and I am pleased that the conference will hear a presentation of the winning case study.\n\nIn closing, let me thank the conference organizers with the Fed and the Conference of State Bank Supervisors, the scholars and others making presentations, and all of you for attending. I hope you have a terrific conference."
    },
    {
        "title": "The Independent Bank of England--20 Years On",
        "date": "September 28, 2017",
        "speaker": "Vice Chairman Stanley Fischer",
        "url": "https://www.federalreserve.gov/newsevents/speech/fischer20170928a.htm",
        "content": "September 28, 2017\n\nVice Chairman Stanley Fischer\n\nAt \"20 Years On,\" a conference sponsored by the Bank of England, London, England\n\nRevised version: October 12, 2017\n\nIt is a pleasure to speak at this commemoration of 20 years of Bank of England monetary policy independence. In my remarks today, I will consider how central banking in the United Kingdom and the United States has evolved in response to the challenges of recent years. I will address a limited set of topics and will have time to touch only briefly on each.1\n\nThese remarks are divided into three parts. In the first part, I will discuss several aspects of aggregate monetary policy: central bank independence, policy transparency, and policy tools. In the second part, I consider differences between the approaches of the two banks to their lender-of-last-resort function. And, third, I will close with brief reflections on the central bank's responsibility for financial stability.\n\nRevisiting Goal Independence versus Instrument Independence\nWe start by considering a central bank that influences economic activity only through its influence over the general level of interest rates.2 More than two decades ago, Guy Debelle and I offered two terms--goal independence and instrument independence--to describe such a central bank's degree of independence. Our definitions were as follows: \"A central bank has goal independence when it is free to set the final goals of monetary policy. ... A bank that has instrument independence is free to choose the means by which it seeks to achieve its goals.\"3 In May 1997, the Bank of England achieved instrument independence--something the Federal Reserve had already long had.4\n\nUnder the new law, the Bank of England's Monetary Policy Committee (MPC), rather than the Treasury, set the policy interest rate. Inflation targeting, which began in the United Kingdom in 1992, continued under the new system and was codified in the Bank of England Act of 1998.5 The MPC was given an explicit numerical inflation target, corresponding to effective price stability, alongside an implied stabilization goal for real economic activity.6 Consequently, the Bank of England from 1997 had the combination that Debelle and I advocated: instrument independence but not goal independence.\n\nWe also judged that the vagueness of the Federal Reserve's statutory objectives meant that the Federal Reserve \"has considerable goal independence.\"7 Today both the FOMC and the MPC have a numerical inflation goal--2 percent. However, this numerical goal is not specified in legislation in either country. In the United Kingdom, the Chancellor of the Exchequer sets the MPC's inflation target: currently 2 percent per year for the U.K. consumer price index.8 In the United States, in the FOMC's Statement on Longer-Run Goals and Monetary Policy Strategy, first issued in 2012 and discussed annually, Committee participants have judged that the longer-run inflation objective that corresponds to the Federal Reserve's mandate is a rate of 2 percent per year, as measured by the change in the price index for personal consumption expenditures.9\n\nIn practice there is little difference between the policy goals of the two central banks, or between the variables that are targeted. But there is a subtle difference between them in terms of who sets the inflation target. To date, that difference has not generated any major divergence between the approaches to monetary policy of the two central banks.\n\nAlthough much has changed in central banking since the 1990s, the case for instrument independence and against goal independence remains sound. The case against goal independence is that it is not appropriate in a democracy: goals should reflect the preferences of society at large and should not be determined by unelected officials.\n\nThe goals of monetary policy should be set by the central government, as is the case in both the United States and the United Kingdom. We all know what the goals of the Bank of England and the Fed are: For both, the goals are stability of the price level and full employment. Although there is a hint of a lexicographic ordering in favor of the rate of inflation in the Bank of England's mandate, the Federal Reserve's dual mandate unambiguously places equal weight on both goals. Across the world, there seems to be a preference for inflation either to be the only goal variable or to be lexicographically emphasized over unemployment. But I do not regard that difference as very significant. There is no central bank that--in Mervyn King's terminology--is an \"inflation nutter.\"10\n\nInstrument independence is necessary because, without it, the central bank is unable to set the stance of monetary policy that it believes to be most consistent with achievement of the statutory mandate. That said, there are, to be sure, degrees of instrument independence, and one can easily envisage central banks with considerable instrument independence whose actions on their instruments are constrained by law or by decisions by the treasury. For example, in a country that has committed its central bank to enforce an exchange rate band (with the exchange rate free to move within the band), the central bank will not be fully instrument independent, though it may have a substantial amount of independence with respect to the precise settings of the policy interest rate and other monetary tools.\n\nHistorically, central banks were frequently created to finance public spending. However, these banks--such as those in Sweden and the United Kingdom--were later sometimes given their operational independence in part to create a greater separation of monetary policy from fiscal policy--in particular, in order to ensure that they would not be vulnerable to pressure to finance the government budget (that is, to monetize public spending). Around the world, the fear of the central bank losing its ability to meet its price stability goal may well have been the prime reason for governments to implement instrument independence.11\n\nFundamentally, however, central bank instrument independence is desirable because monetary policy is an esoteric and complicated art or science, involving technical judgments that have economy-wide and often long-lasting consequences: A separate institution is needed to manage and take responsibility for monetary policy. Central banks have over the years--in some cases over a few centuries--amassed an expertise and developed a character that makes them the natural candidates to perform the functions expected of such institutions. As the Governor of the Riksbank has observed, the most important skill and reputation that a central bank needs is one of reliability.12 That is, both the central government and the general public should be confident that their central bank can be relied on to deliver a stable price level and close to full employment, along with financial stability. If such independent institutions did not exist, we would have to invent them; if they exist and perform well, the country is blessed; and if they exist and perform badly, they need to be reformed--by a change in the laws by which they are governed, by changes in their structure, or by changes in personnel--and sometimes all of the above.\n\nTransparency, Accountability, and Communications\nIn a paper written for the Bank of England's tercentenary, I considered how an instrument-independent central bank might conduct itself.13 My discussion noted that an independent central bank should adhere to the \"principle of accountability to the public of those who make critically important policy decisions.\"14 Accountability, in the senses I defined it, included the requirement \"to explain and justify its policies to the legislature and the public\"--that is, policy transparency and communications.15 Transparency, public accountability, and policy communications form the quid pro quo of central bank independence, and they can also contribute to achievement of macroeconomic goals. These were points the FOMC recognized in its Statement on Longer-Run Goals and Monetary Policy Strategy, which observed that clarity concerning policy decisions \"increases the effectiveness of monetary policy, and enhances transparency and accountability, which are essential in a democratic society.\" In my coverage of these issues today, however, I would like to concentrate on the Bank of England, which in the past quarter-century has been an innovator in several ways with regard to accountability and transparency.\n\nCalls for more transparency concerning U.K. monetary policy and the Bank of England's monetary actions predated independence. For example, in the late 1950s, Richard Sayers observed: \"It may not be wise to turn the central bank into a goldfish bowl, but at least some relaxation of the traditional secretiveness would make for better health in the nation's monetary affairs.\"16 And some Bank communications vehicles, such as the economic analysis in the Quarterly Bulletin and testimony and speeches by the Governor and other Bank officials, were of long standing by the mid-1990s. But the Bank of England made further strides toward improved transparency and communications during the 1990s. In 1993, it initiated the Inflation Report. From the beginning, the Inflation Report was intended to increase transparency about the U.K. monetary policy reaction function--that is, the connection between policy instruments and economic variables, including the goal variables.17 After independence, the Inflation Report presented the MPC's inflation forecast. Furthermore, alongside other Bank statements, the Inflation Report provides a publicly available analysis of the economy and of economic implications of developments like Brexit. The content reflects the Bank's change in focus--from markets in the pre-inflation-targeting era to macroeconomic implications of financial and other developments.18\n\nThe Bank expanded its policy communications after 1997, publishing MPC analogues to the FOMC releases (some of them only recent innovations by the Fed), namely, postmeeting MPC statements and meeting minutes. And an innovation of Mervyn King in the early years of inflation targeting that has continued in the era of independence is the Inflation Report press conference. Here, senior Bank figures discuss the MPC's forecast and the state of the economy. This innovation was a forerunner of the Federal Reserve Chair's press conference, begun in 2011, in which the Chair describes the latest policy decision together with the Summary of Economic Projections (SEP) of FOMC participants.\n\nNew Monetary Policy Tools\nThe MPC and FOMC have extensively--particularly in recent years--used two monetary policy tools other than decisions on the current short-term interest rate. These tools are forward guidance and asset purchases.19\n\nMonetary authorities used to be reluctant to discuss the future course of the policy rate.20 By 1997, however, there was widespread recognition of the merits of clarity on the reaction function and of having long-term interest rates incorporate accurate expectations of future policy. These considerations led to the FOMC's use of forward guidance regarding the short-term interest rate in its postmeeting statements during the mid-2000s. The MPC, in contrast, for a long time generally preferred to let markets infer likely future rates from the extensive communication it provided about its reaction function.21\n\nBeginning in 2008, with the policy rate at or near its lower bound, regular forward guidance acquired new efficacy.22 Through forward guidance, additional accommodation from short-term interest rate policy could be provided by lengthening the period over which the policy rate was expected to remain at its lower bound. The knowledge that the short-term policy rate likely would be lower for longer would put downward pressure on longer-term rates. The FOMC has provided forward guidance on the policy rate in its postmeeting statements ever since the target federal funds rate was brought to the lower bound in December 2008. In addition, the SEP shows individual FOMC participants' expectations regarding the policy rate, though it does not identify the individuals in the interest rate dot plot. In the United Kingdom, the MPC started providing forward guidance in its postmeeting statements in 2013.23\n\nAs the policy rate--Bank Rate--is still at its lower bound in the United Kingdom, it remains to be seen whether MPC forward guidance will continue during policy firming. For its part, the FOMC has provided forward guidance in its policy statements during the tightening phase that began with the increase in the target range for the federal funds rate in December 2015. I expect that the Bank of England will also likely continue to use forward guidance when it begins to raise the policy interest rate above its effective lower bound.\n\nAsset purchases are less of a new tool than forward guidance. In the early post-World War II decades, both U.K. and U.S. authorities sporadically attempted to influence long-term interest rates directly by transacting in longer-term Treasury securities. By 1997, however, monetary policy operations in longer-term securities markets had fallen into disuse.24 The financial crisis changed matters, with both countries' central banks expanding their balance sheets through large-scale purchases of longer-dated securities to put downward pressure on longer-term interest rates and set in motion movements in asset prices and borrowing costs that would stimulate spending by households and businesses. It is widely, though not universally, recognized that these asset purchases helped contain the economic downturns in the United Kingdom and the United States and underpinned the subsequent recovery in each country. This experience raises the question of whether the balance sheet will continue to be a routine tool of monetary policy once interest rates normalize.25 The FOMC has indicated its preference that, barring large adverse shocks to the economy, adjustments to the federal funds rate will be the main means of altering the stance of monetary policy.26\n\nChanging Perspectives on the Lender of Last Resort\nThe second section concerns the role of the lender of last resort. The financial crisis and recession confirmed the value of central bank tools that affect the financial system, beyond those most associated with monetary policy. One of these tools is the discount window or lender-of-last-resort function. As of the mid-2000s, the posture of the Bank of England and the Federal Reserve toward the lender-of-last-resort function reflected the principles enunciated by Bagehot and the long absence of a severe financial crisis: The discount rate stood above the key policy rate by a fixed amount; the discount window was not used for macroeconomic stabilization; and depository institutions were the users of the discount window, typically on a short-term basis.27\n\nIn 1978, Rudi Dornbusch and I noted that the lender-of-last-resort function should imply that \"the central bank steps in to ensure that funds are available to make loans to firms which are perfectly sound but, because of panic, are having trouble raising funds.\"28 In the financial crisis that started in 2007, wide-ranging measures were taken along these lines. In order to improve the functioning of U.S. credit markets, the Federal Reserve made numerous changes to its lending arrangements: The spread of the discount rate over the policy rate was lowered, lending was extended to include loans to nondepository financial institutions, and facilities were created allowing longer maturity of, and broader collateral for, loans than was usual for the central bank.29\n\nAfter its own experience during the financial crisis, the Bank of England permanently widened lender-of-last-resort access to include not only commercial banks, but also other systemically important financial institutions.30 In the United States, the discount rate has for several years been back to its normal relationship with the policy rate, and the special lending facilities have long since been wound up. Emergency lending facilities of the type seen during the financial crisis remain feasible, if needed, though their usage has not been incorporated into the Federal Reserve's routine lender-of-last-resort powers, along the lines of the changes seen in the United Kingdom. Instead, the restriction on their deployment has been tightened by requiring approval by the U.S. Treasury.\n\nDiscount window lending puts public funds at risk--though I stress that the Federal Reserve's lending during the crisis did not, in fact, lead to any losses. The lender of last resort is also a less impersonal, and more allocative, device than aggregate monetary policy tools, because it involves direct lending by the central bank instead of an attempt by monetary policy to alter the overall cost of private-sector borrowing. For these reasons, the lender-of-last-resort function is bound to be more rule driven than interest rate policy, and it is inevitably associated with collateral arrangements and other safeguards to protect against losses and with strict eligibility criteria.\n\nThe Financial Stability Responsibility of the Central Bank\nOur third and final section concerns the financial stability responsibility of the central bank. This responsibility has been subject to considerable institutional change over the past two decades. Until 1997, the Bank of England had wide supervisory and regulatory powers. With the reforms of the late 1990s, the Bank had a deputy governor responsible for financial stability, but regulatory powers were largely moved to a different institution, the Financial Services Authority (FSA). A decade later, the financial crisis demonstrated that financial imbalances can ultimately endanger macroeconomic stability and highlighted the need for enhanced central bank oversight of the financial system. In the post-crisis era, the FSA became two separate regulatory authorities, one of which--the Prudential Regulation Authority, created in 2012--is part of the Bank of England. In effect, regulatory powers have largely returned to the Bank. It is fair to say that the Bank was initially glad to cede many of its financial powers, but that it was later even more glad to have those powers restored.\n\nFinancial supervision has also been reformed in the United States in light of the crisis. The Federal Reserve, which always had regulatory powers, received enhanced authority and devoted more resources to financial stability.31 In both countries, it remains the case that not all financial stability responsibilities rest with the central bank--so it is less independent in this area than in monetary policy proper--and the central bank's tools for achieving financial stability are still being refined. Indeed, as I have noted previously, a major concern of mine is that the U.S. macroprudential toolkit is not large and not yet battle tested.32\n\nThe Federal Reserve and the Bank of England benefit from each other's experience as they develop and improve arrangements to meet their financial stability responsibilities. One major innovation that deserves mention is that the Bank of England has two policy committees: Alongside the MPC is the Financial Policy Committee (FPC). Although they coordinate and have partially overlapping memberships, the MPC and FPC are distinct committees.\n\nWhy have both the MPC and the FPC? I offer a few possible reasons. First, not all of a central bank's responsibilities typically rest with its monetary committee. This is true not only of the Bank of England, but also of the Federal Reserve: Our financial regulatory authority resides in the Board of Governors, not the FOMC. Second, aggregate monetary policy tools--typically, one is talking of the policy interest rate--are often blunt weapons against financial imbalances, so deploying them might produce a conflict between financial stability and short-term economic stabilization. Macroprudential tools may be more direct and more appropriate for fostering financial stability.33 Third, financial policy might need less frequent adjustment than monetary policy. Perhaps reflecting this judgment, the FPC meets on a quarterly basis, which contrasts with the MPC's eight meetings a year.34 The lower frequency of meetings may also reflect the desirability of a relatively stable regulatory structure; financial tools likely should not be as continuously data dependent as monetary policy tools.\n\nIt is clear that the U.K. institutional framework for the preservation of financial stability has much to be said for it. But it also seems clear that there is no uniquely optimal set-up of the framework for the maintenance of financial stability that is independent of the size and scale of the financial system of the country or of its political and financial history.\n\nConclusion\nIt has been more than 20 years since the Bank of England celebrated its 300th birthday with a conference focused on central bank independence. Since then, central banks' operating frameworks have undergone substantial changes, many in response to the financial crisis. But the case for monetary policy independence set out in the 1990s remains sound, and monetary policy independence is now widely accepted in the United Kingdom, as it long has been in the United States. It is also clear that central bank responsibilities other than policy rate decisions--specifically, the lender-of-last-resort function and financial stability--are closely connected with monetary policy and that these responsibilities play a prominent role in macroeconomic stabilization.\n\nLet me conclude by observing that, while the crisis and its aftermath motivated central banks to reappraise and adapt their tools, institutions, and thinking, future challenges will doubtless prompt further reforms.35 Or, if I may be permitted a few final words on my way out the door, the watchwords of the central banker should be \"Semper vigilans,\" because history and financial markets are masters of the art of surprise, and \"Never say never,\" because you will sometimes find yourself having to do things that you never thought you would.\n\nReferences\nAllsopp, Christopher (2002). \"Macroeconomic Policy Rules in Theory and Practice,\" Bank of England Quarterly Bulletin, vol. 42 (Winter), pp. 485-504.\n\nBagehot, Walter ([1873] 1897). Lombard Street: A Description of the Money Market. New York: Charles Scribner's Sons.\n\nBank of England (2015a). The Bank of England Act 1998, the Charters of the Bank and Related Documents (PDF). London: BOE, July.\n\n-------- (2015b). The Bank of England's Sterling Monetary Framework: Updated June 2015 (PDF). London: BOE.\n\n-------- (2017a). \"Monetary Policy Committee (MPC),\" webpage, BOE.\n\n-------- (2017b). Inflation Report (PDF). London: BOE, August.\n\n-------- (2017c). \"Financial Policy Committee Meeting Records and Statements,\" webpage, BOE.\n\nBatini, Nicoletta, and Edward Nelson (2005). \"The U.K.'s Rocky Road to Stability,\" Working Paper Series 2005-020A. St. Louis: Federal Reserve Bank of St. Louis, March.\n\nBean, Charles (2009). \"Comment on 'Interest Rate Signals and Central Bank Transparency,'\" in Richard H. Clarida and Francesco Giavazzi, eds., NBER Seminar on Macroeconomics 2007. Chicago: University of Chicago Press, pp. 52-54.\n\nBernanke, Ben S. (2010). \"Central Bank Independence, Transparency, and Accountability,\" speech delivered at the Institute for Monetary and Economic Studies International Conference, Bank of Japan, Tokyo, May 25.\n\n-------- (2011). \"The Effects of the Great Recession on Central Bank Doctrine and Practice,\" speech delivered at the Federal Reserve Bank of Boston 56th Economic Conference, Boston, October 18.\n\n-------- (2012). \"Semiannual Monetary Policy Report to the Congress,\" statement before the Committee on Financial Services, U.S. House of Representatives, February 29.\n\n-------- (2015). The Courage to Act: A Memoir of a Crisis and Its Aftermath. New York: W.W. Norton and Company.\n\nBernanke, Ben S., Thomas Laubach, Frederic S. Mishkin, and Adam S. Posen (1999). Inflation Targeting: Lessons from the International Experience. Princeton, N.J.: Princeton University Press.\n\nBoard of Governors of the Federal Reserve System (2016). \"Minutes of the Federal Open Market Committee, April 26-27, 2016,\" press release, May 18.\n\n-------- (2017). \"Minutes of the Federal Open Market Committee, March 14-15, 2017,\" press release, April 5.\n\nBurns, Arthur F. (1977). \"Statement before the Committee on Banking, Finance and Urban Affairs, U.S. House of Representatives, July 26, 1977 (PDF),\" Federal Reserve Bulletin, vol. 63 (August), pp. 717-21.\n\nCarney, Mark (2014). Speech delivered at the Lord Mayor's Banquet for Bankers and Merchants of the City of London at the Mansion House (PDF), London, June 12.\n\n-------- (2016). Letter from the Governor of the Bank of England to the Chancellor of the Exchequer (PDF), February 4.\n\nCecchetti, Stephen G. (2009). \"Crisis and Responses: The Federal Reserve in the Early Stages of the Financial Crisis,\" Journal of Economic Perspectives, vol. 23 (Winter), pp. 51-75.\n\nCrockett, Andrew D. (1994). \"Rules versus Discretion in Monetary Policy,\" in J. Onno de Beaufort Wijnholds, Sylvester C.W. Eiffinger, and Lex H. Hoogduin, eds., A Framework for Monetary Stability: Papers and Proceedings of an International Conference Organised by De Nederlandsche Bank and the CentER for Economic Research at Amsterdam. Dordrecht, Netherlands: Springer, pp. 165-84.\n\nDebelle, Guy, and Stanley Fischer (1994). \"How Independent Should a Central Bank Be? (PDF)\" in Goals, Guidelines, and Constraints Facing Monetary Policymakers, proceedings of a conference held in North Falmouth, Massachusetts, in June 1994. Boston: Federal Reserve Bank of Boston, pp. 195-221.\n\nDornbusch, Rudiger, and Stanley Fischer (1978). Macroeconomics. New York: McGraw-Hill.\n\nEichengreen, Barry, and Peter M. Garber (1991). \"Before the Accord: U.S. Monetary-Financial Policy, 1945-51,\" in R .Glenn Hubbard, ed., Financial Markets and Financial Crises. Chicago: University of Chicago Press, pp. 175-206.\n\nFederal Open Market Committee (2017). Statement on Longer-Run Goals and Monetary Policy Strategy (PDF), amended effective January 31 (original version adopted effective January 24, 2012).\n\nFischer, Stanley (1987). \"Monetary Policy,\" in Rudiger Dornbusch and Richard Layard, eds., The Performance of the British Economy. Oxford, United Kingdom: Clarendon Press, pp. 6-28.\n\n-------- (1994). \"Modern Central Banking,\" in Forrest Capie, Charles Goodhart, Stanley Fischer, and Norbert Schnadt, eds., The Future of Central Banking: The Tercentenary Symposium of the Bank of England. New York: Cambridge University Press, pp. 262-308.\n\n-------- (1995). \"Modern Approaches to Central Banking,\" NBER Working Paper Series 5064. Cambridge, Mass.: National Bureau of Economic Research, March.\n\n-------- (2015a). \"Central Bank Independence,\" speech delivered at the 2015 Herbert Stein Memorial Lecture, National Economists Club, Washington, November 4.\n\n-------- (2015b). \"Macroprudential Policy in the U.S. Economy,\" speech delivered at \"Macroprudential Monetary Policy,\" 59th Economic Conference of the Federal Reserve Bank of Boston, Boston, October 2.\n\nGoodhart, Charles A.E. (1999). \"Monetary Policy and Debt Management in the United Kingdom: Some Historical Viewpoints,\" in K. Alec Chrystal, ed., Government Debt Structure and Monetary Conditions. London: Bank of England, pp. 43-97.\n\nHammond, Philip (2017). \"Remit of the Bank of England (PDF),\" letter from the Chancellor of the Exchequer to the Governor of the Bank of England, March 8.\n\nHowe, Geoffrey (1981). \"Written Answers: Minimum Lending Rate,\" House of Commons debates, June 4, http://hansard.millbanksystems.com/written_answers/1981/jun/04/minimum-lending-rate#S6CV0005P0_19810604_CWA_167.\n\nKing, Mervyn (1997). \"Changes in UK Monetary Policy: Rules and Discretion in Practice,\" Journal of Monetary Economics, vol. 39 (June), pp. 81-97.\n\n-------- (2002). \"The Inflation Target Ten Years On,\" Bank of England Quarterly Bulletin, vol. 42 (Winter), pp. 459-74.\n\nLeigh-Pemberton, Robin (1992). \"The Case for Price Stability (PDF),\" Bank of England Quarterly Bulletin, vol. 32 (November), pp. 441-48.\n\nMadigan, Brian (2009). \"Bagehot's Dictum in Practice: Formulating and Implementing Policies to Combat the Financial Crisis,\" in Financial Stability and Macroeconomic Policy, proceedings of the Federal Reserve Bank of Kansas City's Annual Economic Symposium. Kansas City, Mo.: Federal Reserve Bank of Kansas City, pp. 169-89.\n\nMeltzer, Allan H. (2009). A History of the Federal Reserve, vol. 2, book 1: 1951-1969. Chicago: University of Chicago Press.\n\nSayers, R.S. (1958). Modern Banking, 4th ed. Oxford, United Kingdom: Clarendon Press.\n\nTucker, Paul (2007). \"Money and Credit: Banking and the Macroeconomy (PDF),\" speech delivered at the Monetary Policy and the Markets Conference, London, December 13.\n\nWoodford, Michael (2013). \"Forward Guidance by Inflation-Targeting Central Banks.\" CEPR Discussion Paper 9722. London: Centre for Economic Policy Research, November.\n\nYellen, Janet L. (2017). \"Inflation, Uncertainty, and Monetary Policy,\" speech delivered at the 59th Annual Meeting of the National Association for Business Economics, Cleveland, September 26.\n\n1. I am grateful to Ed Nelson of the Federal Reserve Board for his excellent assistance. Views expressed in this presentation are my own and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. The implications for monetary policy of central bank actions other than the use of its general monetary policy tools will be considered in the latter parts of this presentation. Return to text\n\n3. See Debelle and Fischer (1994, p. 197). Return to text\n\n4. U.S. monetary policy independence in the post-World War II era dates at least from the Federal Reserve/Treasury Accord of 1951. See Eichengreen and Garber (1991). I discussed Federal Reserve independence in detail in Fischer (2015a). Return to text\n\n5. See the text of the act in Bank of England (2015a). (Since 1998, the U.K. Parliament has made a number of amendments to the Bank of England Act 1998--among them a change, in 2016, to the frequency of MPC meetings, from monthly to eight times a year. See Bank of England (2017a).) Return to text\n\n6. From the start of inflation targeting in the United Kingdom in 1992, it was made clear that the authorities, when faced with a situation in which inflation was different from the target rate, would generally not seek to restore inflation to target as quickly as possible. Rather, they typically would opt for a policy that sought to bring inflation back to target gradually, without unnecessary destabilization of real output. See Leigh-Pemberton (1992) and Bernanke and others (1999, pp. 156-57). This approach has continued in the MPC era, as discussed later. It is an approach consistent with the MPC's remit in the Bank of England Act 1998 to achieve the inflation target through policies consistent with the economic policy of the U.K. government, \"including its objectives for growth and employment.\" Return to text\n\n7. See Debelle and Fischer (1994, p. 217). Return to text\n\n8. For the most recent statement by the Chancellor of the Exchequer on the inflation target to be pursued by the MPC, see Hammond (2017). Return to text\n\n9. See Federal Open Market Committee (2017). See Bernanke (2012) for testimony discussing the longer-run objective shortly after it was announced. Bernanke (2015, p. 528) indicated that the FOMC's announcement of the 2 percent longer-run objective was preceded by consultation between himself and congressional leaders. In Fischer (2015a), I took the explicit 2 percent longer-run objective as the means by which the FOMC had made its legislated price stability goal operational. Return to text\n\n10. See King (1997, p. 89). Return to text\n\n11. For further discussion, see, for example, Bernanke (2010), Debelle and Fischer (1994, p. 217), and Fischer (1994, pp 262, 290-91). Initially, the argument was that the central bank was needed to prevent inflation from becoming too high; now, the argument is couched in terms of symmetry of the losses from both too-high and too-low inflation. Return to text\n\n12. The Governor of the Riksbank is Stefan Ingves. Return to text\n\n13. See Fischer (1994, 1995). Much of my discussion was with particular reference to the United Kingdom, and I argued that the Bank of England should receive independence. Return to text\n\n14. See Fischer (1994, p. 262). Return to text\n\n15. See Fischer (1994, p. 301). Return to text\n\n16. See Sayers (1958, p. 314). Return to text\n\n17. See Crockett (1994, p. 183). The desire to be explicit about the reaction function has continued to be a theme of policymaker statements in the era of the MPC. See, for example, King (2002), Allsopp (2002), Tucker (2007), and Bean (2009). Return to text\n\n18. The MPC arrangements also require that a letter be written from the Bank Governor to the Chancellor of the Exchequer in the event of an overshoot or undershoot of the inflation target that is in excess of 1 percent. As well as providing accountability, this arrangement gives the Bank an opportunity to emphasize the longer-term nature of the inflation goal and the consideration given in MPC policy decisions to the stabilization of real economic activity. For example, Carney (2016) outlined, among other things, \"the horizon over which the MPC judges it appropriate to return inflation to the target\" and \"the trade-off that has been made with regard to inflation and output variability in determining the scale and duration of any expected deviation of inflation from the target.\" Return to text\n\n19. In addition to these tools, the MPC has used the Funding for Lending Scheme to boost bank lending. It is beyond the scope of my talk to discuss this further innovation. Return to text\n\n20. For example, Federal Reserve Chairman Arthur Burns once noted (Burns, 1977, p. 717): \"Federal Reserve officials are extremely careful to avoid any public comment that might suggest or imply some particular outlook for interest rates.\" In the United Kingdom, in 1981 Chancellor of the Exchequer Geoffrey Howe observed (Howe, 1981) that it was not the authorities' \"practice to forecast interest rate movements.\" Return to text\n\n21. Although it provides an inflation forecast in the Inflation Report, the MPC does not form an interest rate forecast in conjunction with that inflation forecast. Instead, its current practice is to report a \"CPI inflation projection based on market interest rate expectations\" (Bank of England, 2017b, chart 5.1). The fact that the MPC's Inflation Report forecasts (for real output growth, inflation, and the unemployment rate) condition on market expectations of interest rates is one difference between the MPC forecasts and the FOMC participants' projections that are summarized in the SEP. Another difference is that the SEP consolidates information on the projections constructed and submitted separately by the individual FOMC participants, while the Inflation Report's economic projections are arrived at collectively by the MPC and are therefore the forecasts of the committee as a whole. This is another aspect of the differences of behavior between the two monetary committees that is both interesting and possibly important, but for which there is not enough time for a more detailed discussion. Return to text\n\n22. Woodford (2013) provides an analysis of the value of forward guidance under various conditions, including the case in which the policy rate is at its lower bound. Return to text\n\n23. See Carney (2014) for a discussion of the benefits of forward guidance for the U.K. economy. Return to text\n\n24. Federal Reserve operations for monetary policy purposes in longer-term securities markets had largely been absent since the Operation Twist experiment of the early 1960s (see, for example, Meltzer (2009, pp. 316-23)). In the United Kingdom, operations in longer-term securities markets had continued to figure importantly in monetary policy until the mid-1980s, reflecting attempts by the authorities to influence the term structure of interest rates or to control the stock of money or the volume of liquidity (see Fischer (1987), Goodhart (1999), and Batini and Nelson (2005)). A difference between most of these earlier operations and those in the modern era is that recent years' asset purchases have usually involved an expansion of the central bank's overall balance sheet. Return to text\n\n25. For a recent discussion of the Federal Reserve's position on the matter, see Yellen (2017). Return to text\n\n26. See, for example, Board of Governors (2017). Return to text\n\n27. See Bagehot ([1873] 1897) for the classic discussion of the central bank's role as lender of last resort. Return to text\n\n28. See Dornbusch and Fischer (1978, p. 528). Return to text\n\n29. This is a very brief and simplified discussion of the actions taken by the Federal Reserve with regard to the discount window during the crisis. See, among others, Cecchetti (2009) and Madigan (2009) for detailed discussions. For reasons of space, I will not recount the United Kingdom's policy response in this area during the crisis. Return to text\n\n30. Specifically, the Bank provided access to the largest broker-dealers subject to U.K. regulation and to central counterparties. See Carney (2014) and Bank of England (2015b). Return to text\n\n31. This resource decision led, in 2010, to the creation within the Federal Reserve Board of the Office of Financial Stability Policy and Research (which later became the Division of Financial Stability). Return to text\n\n32. See Fischer (2015b). Return to text\n\n33. For policymakers' consideration of this point in the U.S. context, see, for example, Bernanke (2011) and Board of Governors (2016). Return to text\n\n34. See Bank of England (2017c). Return to text\n\n35. It is worth noting that the 20-year period that is the focus of these remarks constitutes only a little over 6 percent of the history of the Bank of England--and there certainly have been a lot of surprises during that short period in the history of the second oldest of the world's central banks. Return to text"
    },
    {
        "title": "Labor Market Disparities and Economic Performance",
        "date": "September 27, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170927a.htm",
        "content": "September 27, 2017\n\nGovernor Lael Brainard\n\nAt \"Banking and the Economy: A Forum for Minority Bankers,\" a conference hosted by the Federal Reserve Bank of Kansas City, Kansas City, Missouri\n\nI would like to thank President George and her staff at the Federal Reserve Bank of Kansas City for inviting me to participate in today's conference, which is a joint effort of the Federal Reserve Banks of Atlanta, Kansas City, Minneapolis, Philadelphia, Richmond, and St. Louis as well as the Federal Reserve Board.1\n\nDiversity in Financial Services\nAs you may know, this is the second minority bankers forum hosted by the Federal Reserve System. Diversity and inclusion are important to the strength of the banking industry, and therefore I am pleased that the Federal Reserve System is sponsoring this conference. Among other benefits, diversity and inclusion strengthen organizations by improving deliberations and decisionmaking. Banks with more diverse workforces are also better able to reach broader groups of customers, especially customers who have historically been underbanked, when they show that serving those customers is a top priority. One of the most effective ways of showing a commitment to a diverse customer base is showing a commitment to a diverse workforce.\n\nWe now have substantial empirical evidence documenting the benefits of diversity in broadening the range of ideas and perspectives that are brought to bear on solving problems, and thereby contributing to better outcomes, in research, policy, and business. Studies suggest that increased diversity alters group dynamics and decisionmaking in positive ways. Microeconomic experiments and other research have confirmed these ideas. One experiment found that greater racial diversity helped groups of business students outperform other students in solving problems. And another found similar benefits from gender diversity. A study of 2.5 million research papers across the sciences found that those written by ethnically diverse research teams received more citations and had a greater influence than papers by authors with the same ethnicity.2\n\nAs a bank regulator, the Federal Reserve has an interest in promoting diversity in the financial services industry. For example, the Federal Reserve Bank of Chicago is actively engaged in developing diverse talent in the financial services industry as a key partner of the Financial Services Pipeline Initiative (FSP). The FSP is a collaborative of about 20 financial services organizations that are working together to increase the representation of Latinos and African Americans, at all levels, within the Chicago-area financial services industry. The members of this initiative recognize they have a collective interest in developing a diverse pipeline of talent. They are more likely to be more successful in achieving their internal pipeline goals if they succeed in improving diversity and inclusion in the finance workforce more broadly.\n\nAnother example of our work to promote diversity at banking institutions is the standards developed by the Board's Office of Minority and Women Inclusion to promote transparency and awareness of diversity policies and practices within banking institutions. The Board encourages banking institutions not only to provide their policies, practices, and self-assessment information to the Board, but also to disclose this information to the public. We hope that this new self-assessment tool will help individual banks achieve their own diversity and inclusion goals and contribute to greater diversity in the banking industry more generally.\n\nI also want to take this opportunity to update you on what we are doing to preserve and promote Minority Depository Institutions (MDIs). Though I know that only some of you work for MDIs, the Federal Reserve recognizes their vital role in serving low- and moderate-income and minority communities as well as bringing diversity to the field of banking. I make a point of meeting with the leadership of MDIs as I travel around the country so I can hear firsthand about the challenges these institutions face and the important work they are doing to provide financial services to minority and historically underserved populations. I have heard from CEOs of MDIs about how challenging it can be to simultaneously serve their target market and be a bank of choice in a competitive banking market. Some have managed to thread that needle successfully by remaining firmly rooted and accessible in the communities they serve as well as maintaining their focus on trust, loyalty, and personalized relationship banking, which is a particular strength and competitive advantage for MDIs.\n\nThe Federal Reserve has developed a national outreach program called the Partnership for Progress to assist MDIs in confronting business model challenges, cultivating safe banking practices, and competing more efficiently. Recently, the Board doubled its resources for this program to better support MDIs. We brought to bear the resources of our community development function, which promotes economic growth and financial stability in lower-income communities. Combining the resources of our banking and supervision staff with our community development staff allows us to be more creative in supporting MDIs around the country. Recognizing that there has been a dearth of MDI research in recent decades, last year, for the first time, we commissioned two external researchers to develop papers on MDIs. The resulting new papers, along with another written by economists at the Federal Reserve Bank of Chicago, were presented at the interagency biennial MDI conference this past April in Los Angeles. We are in the process of commissioning research for next year in an effort to deepen our understanding of these unique institutions.\n\nLabor Market Disparities\nTurning to the workforce more broadly, I want to spend some of my time today talking about disparities and share some findings from a conference we hosted yesterday at the Board titled \"Disparities in the Labor Market: What Are We Missing?\" In fulfilling its dual mandate, the Federal Open Market Committee (FOMC) has set a target of 2 percent for inflation but does not have a similarly fixed numerical goal for maximum employment. That is because the level of maximum employment depends on \"nonmonetary factors that affect the structure and dynamics of the labor market,\" which \"may change over time and may not be directly measurable.\"3 Understanding how close the labor market is to our full-employment goal requires consulting a variety of evidence along with a healthy dose of judgment. This approach to maximum employment has allowed the FOMC to navigate the current expansion in a way that has likely brought more people back into productive employment than might have been the case with a fixed unemployment rate target based on pre-crisis standards.\n\nThe Federal Reserve is also keenly interested in disparities in employment, labor force participation, income, and wealth because they may have implications for the growth capacity of the economy. When we consider appropriate monetary policy, we need to have a good sense of how fast the economy can grow without fueling excessive price inflation. At a time when the retirement of the baby-boom generation looks likely to be something of a drag on the growth of the labor force, it is especially important to consider whether relatively low levels of employment and labor force participation for some prime working-age groups represent slack that, if successfully tapped, could increase the labor force and boost economic activity.\n\nMore broadly, when a person who was previously unemployed or discouraged secures a job, not only does it boost the economy, but that person also may gain a greater sense of economic security, self-sufficiency, and self-worth and be better able to invest in their family's future. With a richer understanding of economic or social barriers that inhibit labor market success and prosperity for some groups, we may better grasp how much these individuals can be helped by broad economic expansion and how much targeted intervention is required through other policy means.4\n\nThere is also an important connection between the economy's potential growth rate and equality of opportunity. Large disparities in opportunity based on race, ethnicity, gender, or geography mean that the enterprise, exertion, and investments of households and businesses from different groups are not rewarded commensurately. To the extent that disparities in income and wealth across race, ethnicity, gender, or geography reflect such disparities in opportunity, families and small businesses from the disadvantaged groups will then underinvest in education or business endeavors, and potential growth will fall short of the levels it might otherwise attain.5\n\nAside from reducing the long-run productive potential of the economy, persistently high levels of income and wealth inequality may also have implications for the robustness of consumer spending, which accounts for roughly two-thirds of aggregate spending in the United States. The gaps in household income and wealth between the richest and poorest households are at historically high levels, as income and wealth have increasingly accrued to the very richest households. For example, results from the Federal Reserve's latest Survey of Consumer Finances (SCF), which is due to be released soon, indicate that the share of income held by the top 1 percent of households reached 24 percent in 2015, up from 17 percent in 1988. The share of wealth held by the top 1 percent rose to 39 percent in 2016, up from 30 percent in 1989.6 Some research suggests that widening income and wealth inequality may damp consumer spending in the aggregate, as the wealthiest households are likely to save a much larger proportion of any additional income they earn relative to households in lower income groups that are likely to spend a higher proportion on goods and services.7\n\nDisparities by Race and Ethnicity\nWhen we disaggregate the economy-wide labor market statistics, we find significant and persistent racial and ethnic disparities.8 In August, the national unemployment rate of 4.4 percent, which is low by historical standards, masked substantial differences across different demographic groups. As shown in figure 1, unemployment rates ranged from 3.9 percent for whites to 4 percent for Asians, 5.2 percent for Hispanics, and 7.7 percent for African Americans. Labor force participation rates, shown in figure 2, also differ substantially, although by less than unemployment rates, with the rate for African Americans lowest at 62.2 percent. These differences are not a recent development--similar differences across racial and ethnic dimensions have existed for as long as these data have been collected. Even more striking, a significant portion of the gaps in unemployment rates across racial and ethnic groups cannot be attributed to differences in their underlying characteristics, such as age and education levels.9\n\nAlthough the differences in employment rates between racial and ethnic groups are still quite large, they have narrowed recently, after having widened considerably during the recession, and are near their lowest levels in decades. Differences in unemployment rates across racial and ethnic groups tend to widen sharply during recessions, as less advantaged groups shoulder an outsized share of total layoffs, and these differences shrink during recoveries. For example, in the second quarter of 2017, the unemployment rate for black adult men was a little more than 3 percentage points higher than for white adult men. This differential, while sizable, is nonetheless close to the smallest gap seen since comparable data became available in the mid-1970s. Differences in unemployment rates are similarly near historical lows for black women relative to white women, and for Hispanics relative to whites. Since racial disparities tend to get smaller throughout the course of an economic expansion, it seems likely that racial differences in unemployment rates will continue to shrink if the overall unemployment rate falls further.10\n\nMore broadly, the persistent disparities in employment outcomes are mirrored in significant and persistent racial and ethnic differences in families' income and wealth. According to forthcoming findings from the latest SCF and as shown in figure 3, the average income for white families in 2015 was about $123,000 per year, compared with $54,000 for black families and $57,000 for Hispanic families.11 Disparities in wealth, shown in figure 4, are even larger: Average wealth holdings for white families in 2016 were about $933,000, compared with $191,000 for Hispanic families and $138,000 for black families.12 Moreover, these racial and ethnic gaps in average family income and wealth have generally widened rather than narrowed over the past few decades. Based on SCF data, median family wealth has grown much more rapidly for white families than for other families over the past few decades, while median family incomes have risen by about the same amount for white, black, and Hispanic families.\n\nAs the economic expansion continues and brings more Americans off the sidelines and into productive employment, it seems likely that the positive trends in employment and participation rates for historically disadvantaged groups will continue. That said, the benefits of a lengthy recovery can only go so far, as the research points to some barriers to labor market outcomes for particular groups that appear to be structural. After controlling for sectoral and educational differences, the research suggests that these factors include discrimination as well as differences in access to quality education and informal social networks that may be an important source of information and support regarding employment opportunities.13\n\nFederal Reserve Work on Labor Market Disparities\nWhile the policy tools available to the Federal Reserve are not well suited to addressing the barriers that contribute to persistent disparities in labor market outcomes, understanding these barriers and efforts to address them is vital in assessing maximum employment as well as potential growth. The Federal Reserve is deeply engaged in understanding disparities through our data collection, research collaboration, and community development work. One way the Federal Reserve seeks to obtain a clearer picture is by collecting data ourselves. For instance, some of the data I have cited today come from the Federal Reserve's triennial Survey of Consumer Finances, which provides detailed information on income and wealth holdings by demographic groups. The Survey of Household Economics and Decisionmaking provides a portrait of household finances, employment, housing, and debt; the Survey of Young Workers provides insights into younger adults' employment experiences soon after entering the labor force; and the Enterprising and Informal Work Activities Survey provides information about income generating activities that are often outside the scope of other employment and income surveys.14\n\nEach recent edition of the semiannual Monetary Policy Report (MPR) has focused on some aspect of the comparative economic experience of different racial and ethnic groups. In addition, as indicated in the minutes published after each meeting of the Federal Open Market Committee (FOMC), Federal Reserve staff regularly report on the differential labor experiences of different racial and ethnic groups as background for the FOMC's deliberations on monetary policy.\n\nAcross the Federal Reserve System, a variety of initiatives are aimed at understanding economic disparities and how to foster more-inclusive growth. The Opportunity and Inclusive Growth Institute at the Federal Reserve Bank of Minneapolis brings together researchers from a variety of fields to analyze barriers to economic opportunity and advancement. The Economic Growth and Mobility Project at the Federal Reserve Bank of Philadelphia aims to bring together researchers with community stakeholders to focus on differences in poverty and economic mobility across demographic characteristics. The Investing in America's Workforce Initiative is a collaboration between the Federal Reserve System and academic research institutions to promote investment in workforce skills that better align with employers' needs.15\n\nIn short, a deeper understanding of labor market disparities is central to the mission of the Federal Reserve because it may help us better assess full employment, where resources may be underutilized, and the likely evolution of the labor market and overall economic activity. Let me conclude by thanking you again for having me here today and allowing me the opportunity to explore some of the factors that influence labor market disparities.\n\nReferences\nAlichi, Ali, Kory Kantenga, and Juan Solè (2016). \"Income Polarization in the United States (PDF),\" IMF Working Paper 16/121. Washington: International Monetary Fund.\n\nBayer, Amanda, and Cecelia Elena Rouse (2016). \"Diversity in the Economics Profession: A New Attack on an Old Problem,\" Journal of Economic Perspectives, vol. 30 (Fall), pp. 221-42.\n\nBernstein, Jared (2013). \"The Impact of Inequality on Growth.\" Washington: Center for American Progress.\n\nBricker, Jesse, Lisa J. Dettling, Alice Henriques, Joanne W. Hsu, Lindsay Jacobs, Kevin B. Moore, Sarah Pack, John Sabelhaus, Jeffrey Thompson, and Richard A. Windle (forthcoming). \"Changes in U.S. Family Finances from 2013 to 2016: Evidence from the Survey of Consumer Finances,\" Federal Reserve Bulletin.\n\nCajner, Tomaz, Tyler Radler, David Ratner, and Ivan Vidangos (2017). \"Racial Gaps in Labor Market Outcomes in the Last Four Decades and over the Business Cycle (PDF),\" Finance and Economics Discussion Series 2017-071. Washington: Board of Governors of the Federal Reserve System.\n\nCarpenter, Seth, and William M. Rodgers (2004). \"The Disparate Labor Market Impacts of Monetary Policy,\" Journal of Policy Analysis and Management, vol. 23 (Fall), pp. 813-30.\n\nFryer, Jr., Roland G. (2011). \"Racial Inequality in the 21st Century: The Declining Significance of Discrimination,\" in David Card and Orley Ashenfelter, eds., Handbook of Labor Economics, vol. 4b. Amsterdam: North Holland, pp. 855‑971.\n\nMarrero, Gustavo, and Juan Rodrìguez (2013). \"Inequality of Opportunity and Growth,\" Journal of Development Economics, vol. 104 (September), pp. 107-22.\n\nRitter, Joseph A., and Lowell J. Taylor (2011). \"Racial Disparity in Unemployment,\" Review of Economics and Statistics, vol. 93 (February), pp. 30-42.\n\nSemega, Jessica L., Kayla R. Fontenot, and Melissa A. Kollar (2017). \"Income and Poverty in the United States: 2016 (PDF),\" Current Population Reports, pp. 60-259. Washington: U.S. Census Bureau, September.\n\nYellen, Janet L. (2015). \"So We All Can Succeed: 125 Years of Women's Participation in the Economy,\" speech delivered at \"125 Years of Women at Brown,\" a conference sponsored by Brown University, Providence, Rhode Island, May 5.\n\n1. I am grateful to Amanda Roberts and Christopher Smith for their assistance in preparing this text. The remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See Bayer and Rouse (2016). Return to text\n\n3. The FOMC's Statement on Longer-Run Goals and Monetary Policy Strategy is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/files/fomc_longerrungoals.pdf. Return to text\n\n4. For evidence on the relationship between monetary policy and labor market disparities between some demographic groups, see Carpenter and Rodgers (2004). Return to text\n\n5. For more on inequality of opportunity see Marrero and Rodriquez (2013). Return to text\n\n6. Staff calculations from forthcoming SCF data (to be released on September 27); for additional analysis of these data, see Bricker and others (forthcoming). Return to text\n\n7. See Bernstein (2013) and Alichi, Kantenga, and Solè (2016) for more on the potential link between income and wealth inequality and consumer spending. Return to text\n\n8. For a discussion of gender disparities, see Yellen (2015). Return to text\n\n9. See Cajner and others (2017) for more on racial gaps and the labor market. Return to text\n\n10. Data on recent estimates of unemployment rates for adult men (20 years and older) by race and ethnicity are available from the Bureau of Labor Statistics. Historical gaps are provided by Cajner and others (2017). Return to text\n\n11. Staff calculations from forthcoming SCF data. Recent estimates of household income from Current Population Survey data and reported by the Census in Semega, Fontenot, and Kollar (2017) are qualitatively similar, in that between 2013 and 2016 for both sets of data, family income has increased for whites, blacks, and Hispanics (with greater increases, in percentage terms, for black and Hispanic families). Return to text\n\n12. Racial and ethnic differences in median income and wealth are somewhat smaller. For example, in 2016 median income for white families was about $61,000, compared with $35,000 for black families and $39,000 for Hispanic families. Median wealth was about $171,000 for white families, compared with about $20,000 for black and Hispanic families. The larger gap in average income and wealth than median income and wealth reflects a greater concentration of income and wealth among the wealthiest white families than for other races and ethnicities. Return to text\n\n13. For example, see Fryer (2011) and Ritter and Taylor (2011). Return to text\n\n14. Further information on these surveys are found on the Board's website; see the Survey of Consumer Finances; the Survey of Household Economics and Decisionmaking; the Survey of Young Workers; and the Survey of Enterprising and Informal Work Activities (PDF). Return to text\n\n15. For information about the Opportunity and Inclusive Growth Institute, see https://www.minneapolisfed.org/institute, for information about the Economic Growth and Mobility Project, see https://www.philadelphiafed.org/egmp, and for information about the America's Workforce Initiative, see https://www.investinwork.org. Return to text"
    },
    {
        "title": "Inflation, Uncertainty, and Monetary Policy",
        "date": "September 26, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20170926a.htm",
        "content": "September 26, 2017\n\nChair Janet L. Yellen\n\nAt the \"Prospects for Growth: Reassessing the Fundamentals\" 59th Annual Meeting of the National Association for Business Economics, Cleveland, Ohio\n\nI would like to thank the National Association for Business Economics for inviting me to speak today and for the vital role the association plays in fostering debate on important economic policy questions.\n\nToday I will discuss uncertainty and monetary policy, particularly as it relates to recent inflation developments. Because changes in interest rates influence economic activity and inflation with a substantial lag, the Federal Open Market Committee (FOMC) sets monetary policy with an eye to its effects on the outlook for the economy. But the outlook is subject to considerable uncertainty from multiple sources, and dealing with these uncertainties is an important feature of policymaking. Key among current uncertainties are the forces driving inflation, which has remained low in recent years despite substantial improvement in labor market conditions. As I will discuss, this low inflation likely reflects factors whose influence should fade over time. But as I will also discuss, many uncertainties attend this assessment, and downward pressures on inflation could prove to be unexpectedly persistent. My colleagues and I may have misjudged the strength of the labor market, the degree to which longer-run inflation expectations are consistent with our inflation objective, or even the fundamental forces driving inflation. In interpreting incoming data, we will need to stay alert to these possibilities and, in light of incoming information, adjust our views about inflation, the overall economy, and the stance of monetary policy best suited to promoting maximum employment and price stability.\n\nRecent Inflation Developments and the Outlook\nLet me begin by reviewing recent inflation developments and the economic outlook. As the solid blue line in figure 1 indicates, inflation as measured by the price index for personal consumption expenditures (PCE) has generally run below the FOMC's 2 percent longer-run objective since that goal was announced in January 2012.1 Core inflation, which strips out volatile food and energy prices, has also fallen persistently short of 2 percent (the red dashed line). Furthermore, both overall and core inflation, after moving up appreciably last year, have slipped again in recent months. Sustained low inflation such as this is undesirable because, among other things, it generally leads to low settings of the federal funds rate in normal times, thereby providing less scope to ease monetary policy to fight recessions. In addition, a persistent undershoot of our stated 2 percent goal could undermine the FOMC's credibility, causing inflation expectations to drift and actual inflation and economic activity to become more volatile.\n\nAs noted in its recent statement, the FOMC continues to anticipate that, with gradual adjustments in the stance of monetary policy, inflation will rise and stabilize at around 2 percent over the medium term. This expectation is illustrated by the green stars, which represent the medians of the inflation projections submitted by FOMC participants at our meeting last week. In part, this expectation reflects the significant improvement in labor market conditions over the past few years. As shown in figure 2, the unemployment rate (the blue line) now stands at 4.4 percent, somewhat below the median of FOMC participants' estimates of its longer-run sustainable level (the black line). As the green stars indicate, labor market conditions are expected to strengthen a bit further. The inflation outlook also reflects the Committee's judgment that inflation expectations will remain reasonably well anchored at a level consistent with PCE price inflation of 2 percent in the long run, and that the restraint imposed in recent years by a variety of special factors, including movements in the relative prices of food, energy, and imports, will wane in coming quarters.\n\nTo understand this assessment, it is useful to decompose the forces driving movements in inflation since the financial crisis, as estimated using a simple model of inflation that I presented in a speech two years ago.2 Figure 3 reports this decomposition as the contributions made by various factors to the shortfall of PCE price inflation from 2 percent, year by year. As illustrated by the purple dotted portion of the bars, labor underutilization, or \"slack,\" accounts for a shrinking share of the shortfall since 2012 and is now having a negligible effect. By comparison, the influence of changes in relative food, energy, and import prices--the solid blue and checkered red portions--has been more substantial in the past few years, although their contribution is estimated to have greatly diminished this year.3\n\nNot surprisingly, the simple model does not account for all of the year-to-year movements in inflation. As indicated by the green striped portion of the bars, the residual component of the shortfall was modestly positive on average from 2008 through last year. This year, however, inflation has been unexpectedly weak from the model's perspective. This unusually large error does not necessarily imply that inflation is more likely to continue to come in on the low side in coming years.4 Some of the recent decline in inflation, although not all, reflects idiosyncratic shifts in the prices of some items, such as the large decline in telecommunication service prices seen earlier in the year, that are unlikely to be repeated. As the green dashed line in figure 4 illustrates, if the average change in consumer prices each month is calculated excluding items whose price changes are outliers on both the high and low side, the resulting \"trimmed mean\" measure of inflation shows less of a slowdown this year.5\n\nBased on analyses of this sort, my colleagues and I currently think that this year's low inflation is probably temporary, so we continue to anticipate that inflation is likely to stabilize around 2 percent over the next few years. But our understanding of the forces driving inflation is imperfect, and we recognize that something more persistent may be responsible for the current undershooting of our longer-run objective. Accordingly, we will monitor incoming data closely and stand ready to modify our views based on what we learn.\n\nUncertainty about the Inflation Outlook\nAlthough we judge that inflation will most likely stabilize around 2 percent over the next few years, the odds that it could turn out to be noticeably different are considerable. This point is illustrated by figure 5. Here the red line indicates the median of the latest inflation projections submitted by FOMC participants that I showed previously. The pertinent feature of this figure is the blue shaded region around the red line, which shows a 70 percent confidence interval around FOMC participants' median outlook. The width of this region reflects the average accuracy of inflation projections made by private and government forecasters over the past 20 years. As the figure shows, based on that history, there is a 30 percent probability that inflation could be greater than 3 percent or less than 1 percent next year.6\n\nMost of this uncertainty reflects the influence of unexpected movements in oil prices and the foreign exchange value of the dollar, as well as that of idiosyncratic developments unrelated to broader economic conditions. These factors could easily push overall inflation noticeably above or below 2 percent for a time. But such disturbances are not a great concern from a policy perspective because their effects fade away as long as inflation expectations remain anchored.7 For this reason, the FOMC strives to look through these transitory inflation effects when setting monetary policy. Such was the case when rising oil prices pushed headline inflation noticeably above 2 percent for several years prior to the financial crisis. Similarly, the Committee substantially discounted the reductions in inflation that occurred from 2014 through 2016 as a result of the decline in oil prices and the effects of the dollar's appreciation on import prices.\n\nA more important issue from a policy standpoint is that some key assumptions underlying the baseline outlook could be wrong in ways that imply that inflation will remain low for longer than currently projected. For example, labor market conditions may not be as tight as they appear to be, and thus they may exert less upward pressure on inflation than anticipated. Alternatively, long-run inflation expectations, which have an important influence on actual inflation, may not be consistent with the FOMC's 2 percent goal. More broadly, the conventional framework for understanding inflation dynamics could be misspecified in some fundamental way. Let's now consider each of these possibilities in turn.\n\nResource Utilization\nThe unemployment rate consistent with long-run price stability at any time is not known with certainty; we can only estimate it. The median of the longer-run unemployment rate projections submitted by FOMC participants last week is around 4‑1/2 percent. But the long-run sustainable unemployment rate can drift over time because of demographic changes and other factors, some of which can be difficult to quantify--or even identify--in real time.8 For these and other reasons, the statistical precision of such estimates is limited, and the actual value of the sustainable rate could well be noticeably lower than currently projected.9 Thus, although FOMC participants generally view current labor utilization as probably somewhat greater than what can be sustained in the longer run, the statistical evidence from past experience does not rule out the possibility that some slack still remains in the labor market. If so, the economy could sustain a higher level of employment and output in the longer run than now anticipated--a very beneficial outcome, albeit one that would require recalibrating monetary policy over time in order to reap those benefits and compensate for the accompanying reduction in inflationary pressures.\n\nA related question is whether the unemployment rate alone is an adequate gauge of economic slack for the purposes of explaining inflation. Although the unemployment rate is probably the best single summary measure of labor utilization, some indicators have shown less improvement since the financial crisis.10 As the solid blue line in figure 6 illustrates, the employed share of the \"prime-age worker\" population--that is, persons from ages 25 to 54--remains noticeably below the 2007 level.11 But employment rates for this group may now be permanently lower than in the past as a result of declining employment opportunities for less-skilled workers, a rising number of people receiving disability insurance, and other worrisome trends.12 Similarly, although the share of part-time workers who would like a full-time job is still somewhat above where it stood before the last two recessions (the dashed red line), it could reflect a structural change in firms' reliance on part-time labor.13 In addition, these two measures have to be weighed against other labor indicators that have either returned to, or are currently above, their pre-recession levels. As shown in figure 7, those indicators include the quits rate (the short-dashed blue line), household perceptions of job availability (the short-and-long-dashed green line), the jobs opening rate (the long-dashed red line), and the percentage of small firms finding it hard to fill jobs (the solid black line).\n\nOn balance, the unemployment rate probably is correct in signaling that overall labor market conditions have returned to pre-crisis levels. But that return does not necessarily demonstrate that the economy is now at maximum employment because, due to demographic and other structural changes, the unemployment rate that is sustainable today may be lower than the rate that was sustainable in the past.\n\nIn that regard, some observers have pointed to the continued subdued pace of wage growth as evidence that the economy is not yet back to full employment. As shown in figure 8, labor compensation as measured by the employment cost index (the short-dashed red line) has been growing at more or less the same rate since 2014, and hourly compensation in the nonfarm business sector (the short-and-long-dashed green line)--a quite noisy measure, even after smoothing--is actually growing more slowly. But growth in average hourly earnings (the solid blue line) and the Atlanta Fed's Wage Growth Tracker (the long-dashed black line) have clearly picked up.14 In addition, productivity growth has been quite weak in recent years, and empirical analysis suggests that it is has been holding down aggregate growth in labor compensation independent of labor utilization in recent years.15 An analysis of the pattern of wage growth at the U.S. state level also suggests that subdued growth for the country as a whole probably reflects sluggish productivity or some other factor common to all states, because cross-state differences in wage growth are about what one would expect given cross-state differences in unemployment rates.16 Finally, I would note that the percentage of firms planning wage increases has moved back up to its pre-recession level, many firms report difficulties in finding qualified workers, and some have responded by expanding training programs and offering signing bonuses--possible harbingers of stronger wage gains to come.\n\nOverall, I view the data we have in hand as suggesting a generally healthy labor market, not one in which substantial slack remains or one that is overheated. That said, the evidence does not allow for any definitive assessment, so policymakers must remain open minded on this question and its implications for reaching our inflation goal.\n\nInflation Expectations\nAnother source of uncertainty concerns inflation expectations. In standard economic models, inflation expectations are an important determinant of actual inflation because, in deciding how much to adjust wages for individual jobs and prices of goods and services at a particular time, firms take into account the rate of overall inflation they expect to prevail in the future. Monetary policy presumably plays a key role in shaping these expectations by influencing the average rate of inflation experienced in the past over long periods of time, as well as by providing guidance about the FOMC's objectives for inflation in the future. Even so, economists' understanding of exactly how and why inflation expectations change over time is limited.17 Moreover, we have to contend with the fact that we do not directly observe the inflation expectations relevant to wage and price setting. Instead, we can only imperfectly infer how they might have changed based on survey responses and other data.\n\nThe FOMC's outlook depends importantly on the view that longer-run inflation expectations have been stable for many years at a level consistent with PCE price inflation that will average around 2 percent in the longer run. Provided this stability continues, standard models suggest that actual inflation should stabilize at about 2 percent over the next two or three years in an environment of roughly full employment, absent any future shocks. However, there is a risk that inflation expectations may not be as well anchored as they appear and perhaps are not consistent with our 2 percent goal. To assess this risk, the FOMC considers a variety of survey measures of expected longer-run inflation, some of which are shown in figure 9. Long-range projections of PCE price inflation made by private forecasters, the solid red line, have been remarkably stable for many years, as have been the longer-run inflation expectations reported in surveys of financial market participants (not shown).18 Households' longer-term expectations as reported in the University of Michigan Surveys of Consumers, the short-dashed blue line, have also been fairly stable overall since the late 1990s.19 That said, results from this survey, as well as a survey of consumers carried out by the Federal Reserve Bank of New York, do hint that expectations may have slipped a bit over the past two or three years. If so, stabilizing inflation at around 2 percent could prove to be more difficult than expected.20\n\nIn theory, differences between yields on conventional Treasury securities and those on Treasury Inflation-Protected Securities (TIPS) are also informative about inflation expectations in that they measure the compensation received by investors for exposing themselves to future changes in consumer prices. As indicated by the long-dashed green line, TIPS inflation compensation for the five-year period starting five years from now has fallen roughly 1 percentage point over the past three years. This decline could be interpreted as a significant drop in market participants' expectations for the most likely outcome for inflation in the longer run. However, research suggests that the fall in TIPS inflation compensation instead primarily reflects a decline in inflation risk premiums and differences in the liquidity of nominal and indexed Treasury securities.21 This research notwithstanding, the notable decline in inflation compensation may be a sign that longer-term inflation expectations have slipped recently.\n\nMisspecified Inflation Dynamics\nAnother risk is that our framework for understanding inflation dynamics could be misspecified in some fundamental way, perhaps because our econometric models overlook some factor that will restrain inflation in coming years despite solid labor market conditions. One possibility in this vein is a continuation of the subdued growth in health-care prices that we have seen in recent years--a sector-specific factor not controlled for in standard models. Because health care accounts for a large share of total consumer spending, this slow growth has restrained overall inflation materially and may continue to do so for some time.22 A similar situation occurred during the 1990s, when a significant shift in health insurance enrollment away from fee-for-service and toward HMO (that is, Health Maintenance Organization) plans reduced cost pressures and held down overall inflation for several years. If these sorts of favorable supply-type shocks continue, achieving our 2 percent inflation goal over the medium term may require a more accommodative stance of monetary policy than might otherwise be appropriate.\n\nSome commentators have conjectured that, because of rising trade volumes and the integration of production chains across countries, U.S. inflation now depends on global resource utilization, not just on conditions here at home and those effects arising through movements in energy and import prices. However, studies of this issue do not, on balance, provide much empirical support for this possibility.23 Moreover, foreign economic growth has firmed this year and the global economy appears to have largely recovered, so any influence that global resource utilization might have on U.S. inflation would presumably be small. Nevertheless, increased competition from the integration of China and other emerging market countries into the world economy may have materially restrained price margins and labor compensation in the United States and other advanced economies. In fact, one study concludes that most of the decline in the labor share of national income in the United States since the late 1980s can be attributed to offshoring of labor-intensive production.24 If this restraint on the labor share continues to build over the next few years (and not merely holds steady), then it could indirectly hold down the growth of domestic wages and prices in ways not captured by conventional models.\n\nMore speculatively, changes in the structure of the domestic economy may also be altering inflation dynamics in ways not captured by conventional models. The growing importance of online shopping, by increasing the competitiveness of the U.S. retail sector, may have reduced price margins and restrained the ability of firms to raise prices in response to rising demand.25 That said, the economy overall appears to have become more concentrated and less dynamic in recent years, which may tend to increase firms' pricing power.26 Because these changes occur slowly, determining their complex effects on the economy will, as a practical matter, require studying data over a considerable time.\n\nFinally, I would note the possibility that inflation may rise more sharply in response to robust labor market conditions than anticipated. The influence of labor utilization on inflation has become quite modest over the past 20 years, implying that the inflationary consequences of misjudging the sustainable rate of unemployment are low. But we cannot be sure that this modest sensitivity will persist in the face of strong labor market conditions, given that we do not fully understand how it came to be so modest in the first place. Although the evidence is weak that inflation responds in a nonlinear manner to resource utilization, this risk is one that we cannot entirely dismiss.\n\nPolicy Implications\nWhat are the policy implications of these uncertainties? For one, my colleagues and I must be ready to adjust our assessments of economic conditions and the outlook when new data warrant it. In this spirit, FOMC participants--like private forecasters--have reduced their estimates of the sustainable unemployment rate appreciably over the past few years in response to the continual flow of information about the always changing economy.27 To the extent these assessments change over time, so too will the outlook and judgments about the appropriate stance of monetary policy. Importantly, even if resource utilization is currently lower than we estimate or if longer-run inflation expectations are running at levels consistent with longer-run PCE price inflation somewhat below 2 percent, the FOMC can still achieve its inflation goal. Under those conditions, continuing to revise our assessments in response to incoming data would naturally result in a policy path that is somewhat easier than that now anticipated--an appropriate course correction that would reflect our commitment to maximum employment and price stability.\n\nSimilar considerations apply to other important sources of uncertainty, such as the value of the neutral real interest rate--that is, the inflation-adjusted level of the federal funds rate consistent with keeping the economy operating on an even keel. Estimates of this rate have declined considerably in recent years, and, by some estimates, the real neutral rate is currently close to zero. But the neutral rate changes over time as a result of the interaction of many forces, including demographics, productivity growth, fiscal policy, and the strength of global demand, so its value at any point in time cannot be estimated or projected with much precision. My FOMC colleagues and I will therefore need to continue to reassess and revise our assessments of the neutral rate in response to incoming data and adjust monetary policy accordingly.\n\nHow should policy be formulated in the face of such significant uncertainties? In my view, it strengthens the case for a gradual pace of adjustments. Moving too quickly risks overadjusting policy to head off projected developments that may not come to pass. A gradual approach is particularly appropriate in light of subdued inflation and a low neutral real interest rate, which imply that the FOMC will have only limited scope to cut the federal funds rate should the economy be hit with an adverse shock.28 But we should also be wary of moving too gradually. Job gains continue to run well ahead of the longer-run pace we estimate would be sufficient, on average, to provide jobs for new entrants to the labor force. Thus, without further modest increases in the federal funds rate over time, there is a risk that the labor market could eventually become overheated, potentially creating an inflationary problem down the road that might be difficult to overcome without triggering a recession. Persistently easy monetary policy might also eventually lead to increased leverage and other developments, with adverse implications for financial stability. For these reasons, and given that monetary policy affects economic activity and inflation with a substantial lag, it would be imprudent to keep monetary policy on hold until inflation is back to 2 percent.\n\nConclusion\nTo conclude, standard empirical analyses support the FOMC's outlook that, with gradual adjustments in monetary policy, inflation will stabilize at around the FOMC's 2 percent objective over the next few years, accompanied by some further strengthening in labor market conditions. But the outlook is uncertain, reflecting, among other things, the inherent imprecision in our estimates of labor utilization, inflation expectations, and other factors. As a result, we will need to carefully monitor the incoming data and, as warranted, adjust our assessments of the outlook and the appropriate stance of monetary policy. But in making these adjustments, our longer-run objectives will remain unchanged--to promote maximum employment and 2 percent inflation.\n\nAppendix: PCE Inflation Model, Inflation Decomposition Procedure, and the ECI Growth Equation\n\nPCE Inflation Model\n\nThe inflation model used in the decomposition procedure includes two equations: an identity for the change in the price index for total personal consumption expenditures (PCE) and a simple reduced-form forecasting equation for core PCE price inflation. The identity is\n\nπ\nt\n=\nπ\nc\nt\n+\nω\ne\nt\nRPIE\nt\n+\nω\nf\nt\nRPIF\nt\n,\n\nwhere\nπ\nt\nand\nπ\nc\nt\ndenote growth rates (expressed as annualized log differences) of total and core PCE prices, respectively.\nRPIE\nt\nand\nRPIF\nt\nare annualized growth rates for prices of consumer energy goods and services and prices of food and beverages, both expressed relative to core PCE prices, and\nω\ne\nt\nand\nω\nf\nt\nare the weights of energy and food in total consumption. The core inflation forecasting equation is\n\nπ\nc\nt\n=.41\nπ\ne\nt\n+.36\nπ\nc\nt−1\n+.23\nπ\nc\nt−2\n−.08\nSLACK\nt\n+.56\nRPIM\nt\n+\nϵ\nt\n,\n\nwhere\nπ\ne\nt\nis expected long-run inflation;\nSLACK\nt\ndenotes the level of resource utilization,\nRPIM\nt\ncontrols for the effect of changes in the relative price of core imported goods,\nϵ\nt\nis a white-noise error term, and the coefficients are ordinary least squares estimates obtained using data from 1990:Q1 to 2014:Q4. 29\n\nFor estimation purposes,\nSLACK\nt\nis approximated using the unemployment rate less the Congressional Budget Office's (CBO) historical series for the long-run natural rate. From 2007 to the present,\nπ\ne\nt\nis approximated using the median forecasts of long-run PCE price inflation reported in the Survey of Professional Forecasters; from 1991:Q4 to 2006:Q4, the series is based on the median long-run forecasts of inflation as measured by the consumer price index (CPI), less a constant adjustment of 40 basis points to put the CPI forecasts on a PCE basis; before 1991:Q4,\nπ\ne\nt\nis approximated by the long-run inflation expectations reported in the Hoey survey. The relative import price term,\nRPIM\nt\n, is defined as the annualized growth rate of the price index for core imported goods (defined to exclude petroleum, natural gas, computers, and semiconductors) less the lagged four-quarter change in core PCE inflation, all multiplied by the share of nominal core imported goods in nominal GDP.30\n\nInflation Decomposition Procedure\n\nTo decompose recent movements in inflation into its various components, the series used in the inflation model--for which complete quarterly data are available only through 2017:Q2 in most cases--are first extended through the end of 2017. In the case of inflation, the extensions are consistent with the medians of Federal Open Market Committee (FOMC) participants' projections for total and core PCE inflation in 2017 that were reported at the press conference following the September 2017 FOMC meeting.31 Similarly,\nSLACK\nt\nover the second half of 2017 is defined to be consistent with the median of FOMC projections for the 2017:Q4 unemployment rate less the CBO's estimates of the historical path of the long-run natural rate. The CBO's 2017 estimate is slightly higher than the median of FOMC participants' most recent projections of the normal longer-run level of the unemployment rate. For changes in the price of core imports, the 2017:H2 extrapolations are based on a regression of this series on current and lagged changes in exchange rates. This approach predicts that core import prices should rise about 4-1/2 percent at an annual rate in the second half of this year.32 Energy and food prices over the second half of 2017 are assumed to rise at annual rates of 10 percent and 1.6 percent, respectively; these assumptions (which take into account published monthly PCE data through July and published CPI data through August, as well as recent movements in gasoline prices in the wake of Hurricanes Harvey and Irma) ensure that the combined contribution of food and energy prices to inflation in 2017 is consistent with the median difference between FOMC participants' projections for total and core inflation. Finally, nominal spending shares for food, energy, and core imports are assumed to remain unchanged at their 2017:Q2 levels, and long-run inflation expectations are assumed to remain constant at 2 percent.\n\nAfter computing historical\nϵ\nt\ntracking errors for the two equations of the model, the final step in the decomposition procedure is to run a sequence of counterfactual simulations of the model from 1990:Q1 through 2017:Q4. One by one, each explanatory variable of the model is set to zero, and the model is simulated; the resulting difference between actual inflation and its simulated value equals the historical contribution of that particular factor. Importantly, the simulations are all dynamic in that the lagged inflation term in the core inflation equation is set equal to its simulated value in the preceding period rather than its actual value. As a result, the decompositions incorporate the effects of changes in lagged inflation that are attributable to previous movements in the explanatory variables.\n\nECI Growth Equation\n\nThe estimated equation for the employment cost index (ECI) is:\n\nπ\nw\nt\n=−0.72+.58\nπ\ne\nt−1\n+.10\nπ\nw\nt−1\n+.12\nπ\nw\nt−2\n+.10\nπ\nw\nt−3\n+.11\nπ\nw\nt−4\n−.19\nSLACK\nt\n−.57Δ\nSLACK\nt\n+.58\nMA_PROD\nt\n+\nε\nt\n,\n\nwhere\nπ\nw\nt\nis the annualized log difference of the ECI for hourly compensation of private industry workers,\nπ\ne\nt\nand\nSLACK\nt\nhave the same definition as the corresponding variables from the PCE price inflation model,\nΔ\nSLACK\nt\ndenotes the first difference of\nSLACK\nt\n,\nMA_PROD\nt\nis a moving average of an estimate of trend productivity growth for the business sector, and\nε\nt\nis an error term.33 The coefficients are obtained from a restricted least squares regression using quarterly data from 1988:Q1 to 2017:Q2.34 Trend productivity growth is estimated as the low-frequency component of the annualized log difference of business-sector output per hour from the Bureau of Labor Statistics Productivity and Costs report.35 The moving average of trend productivity growth (which is used in the estimation) is computed as a geometrically declining weighted average,\n\nMA_PROD\nt\n=0.95\nMA_PROD\nt−1\n+0.05\nPROD\nt\n,\n\nwhere\nPROD\nt\ndenotes trend productivity growth and where the moving average is initialized in 1955:Q1 with that quarter's estimate of the trend growth rate.\n\nThe model is used to compute a decomposition of ECI growth following a procedure similar to that used to construct the decomposition for core PCE price inflation. The table summarizes the results of this decomposition over various periods; note that the column labeled \"Slack\" combines the effects of\nΔ\nSLACK\nt\nand\nSLACK\nt\n, the effect of the model's constant term is included in the column labeled \"Trend productivity,\" and the column labeled \"Other\" gives the contributions of the model's tracking errors.\n\nModel-Based Decomposition of ECI Hourly Compensation Growth\n\nReferences\nAaronson, Daniel, Luojia Hu, Arian Seifoddini, and Daniel G. Sullivan (2015). \"Changing Labor Force Composition and the Natural Rate of Unemployment,\" Chicago Fed Letter 338. Chicago: Federal Reserve Bank of Chicago, May.\n\nAaronson, Stephanie, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014). \"Labor Force Participation: Recent Developments and Future Prospects,\" Brookings Papers on Economic Activity, Fall, pp. 197-255.\n\nAcemoglu, Daron, and David Autor (2011). \"Skills, Tasks and Technologies: Implications for Employment and Earnings,\" in David Card and Orley Ashenfelter, eds., Handbook of Labor Economics, vol. 4B (Amsterdam: North Holland), pp. 1043-171.\n\nAndreasen, Martin M., and Jens H.E. Christensen (2016). \"TIPS Liquidity and the Outlook for Inflation,\" FRBSF Economic Letter 2016-35. San Francisco: Federal Reserve Bank of San Francisco, November 21.\n\nAutor, David, David Dorn, and Gordon Hanson (2013). \"The China Syndrome: Local Labor Market Effects of Import Competition in the United States,\" American Economic Review, vol. 103 (October), pp. 2121-68.\n\nAutor, David H., and Mark G. Duggan (2003). \"The Rise in the Disability Rolls and the Decline in Unemployment,\" Quarterly Journal of Economics, vol. 118 (February), pp. 157-205.\n\nBarnichon, Regis, and Christian Matthes (2017). \"The Natural Rate of Unemployment over the Past 100 Years,\" FRBSF Economic Letter 2017-23. San Francisco: Federal Reserve Bank of San Francisco, August 14.\n\nBarnichon, Regis, and Geert Mesters (2017). \"How Tight Is the U.S. Labor Market?\" FRBSF Economic Letter 2017-07. San Francisco: Federal Reserve Bank of San Francisco, March 20.\n\nBorio, Claudio, and Andrew Filardo (2007). \"Globalization and Inflation: New Cross-Country Evidence on the Global Determinants of Domestic Inflation (PDF),\" BIS Working Paper 227. Basel, Switzerland: Bank for International Settlements, May.\n\nCase, Anne, and Angus Deaton (2017). \"Mortality and Morbidity in the 21st Century (PDF),\" Brookings Papers on Economic Activity, Spring, pp. 397-476.\n\nClemens, Jeffery, Joshua D. Gottlieb, and Adam Hale Shapiro (2016). \"Medicare Payment Cuts Continue to Restrain Inflation,\" FRBSF Economic Letter 2016-15. San Francisco: Federal Reserve Bank of San Francisco, May 9.\n\nCouncil of Economic Advisers (2016). \"Benefits of Competition and Indicators of Market Power (PDF),\" Council of Economic Advisers Issue Brief. Washington: CEA, April.\n\nCurran, Enda, and Michelle Jamrisko (2017). \"Expect a Return to Inflation--But Not as We Once Knew It,\" Bloomberg, May 16, www.bloomberg.com/news/articles/2017-05-16/amazon-effect-means-global-inflation-just-ain-t-what-it-once-was.\n\nDaly, Mary C., and Bart Hobijn (2017). \"Composition and Aggregate Real Wage Growth,\" American Economic Review, vol. 107 (May), pp. 349-52.\n\nDaly, Mary C., Bart Hobijn, and Benjamin Pyle (2016). \"What's Up with Wage Growth?\" FRBSF Economic Letter 2016-07. San Francisco: Federal Reserve Bank of San Francisco, March 7.\n\nDecker, Ryan A., John Haltiwanger, Ron S. Jarmin, and Javier Miranda (2016). \"Declining Business Dynamism: Implications for Productivity?\" Hutchins Center Working Paper 23. Washington: Hutchins Center on Fiscal and Monetary Policy, Brookings Institution, September.\n\nDeming, David J. (forthcoming). \"The Growing Importance of Social Skills in the Labor Market,\" Quarterly Journal of Economics.\n\nElsby, Michael W., Bart Hobijn, and Aysegul Sahin (2013). \"The Decline of the U.S. Labor Share (PDF),\" Brookings Papers on Economic Activity, Fall, pp. 1-52.\n\nFeenstra, Robert C., and David E. Weinstein (2017). \"Globalization, Markups, and U.S. Welfare,\" Journal of Political Economy, vol. 125 (August), pp. 1040-74.\n\nFrench, Eric, and Jae Song (2014). \"The Effect of Disability Insurance Receipt on Labor Supply,\" American Economic Journal: Economic Policy, vol. 6 (May), pp. 291-337.\n\nHathaway, Ian, and Robert E. Litan (2014). Declining Business Dynamism in the United States: A Look at States and Metros. Washington: Brookings Institution, May.\n\nIhrig, Jane, Steven B. Kamin, Deborah Lindner, and Jaime Marquez (2010). \"Some Simple Tests of the Globalization and Inflation Hypotheses,\" International Finance, vol. 13 (Winter), pp. 343-75.\n\nJ.P. Morgan (2017). \"U.S.: Tight State Labor Markets Show Effects on Wage Growth,\" Economic Research Note. New York: J.P. Morgan, August 3.\n\nJuselius, Mikael, and Elod Takats (2015). \"Can Demography Affect Inflation and Monetary Policy?\" BIS Working Paper 485. Basel, Switzerland: Bank for International Settlements, February.\n\nPeneva, Ekaterina (2014). \"Residual Seasonality in Core Consumer Price Inflation,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, October 14.\n\nPierce, Justin R., and Peter K. Schott (2016). \"The Surprisingly Swift Decline of US Manufacturing Employment,\" American Economic Review, vol. 106 (July), pp. 1632-62.\n\nReifschneider, David, and Peter Tulip (2017). \"Gauging the Uncertainty of the Economic Outlook Using Historical Forecasting Errors: The Federal Reserve's Approach (PDF),\" Finance and Economics Discussion Series 2017-020. Washington: Board of Governors of the Federal Reserve System, February.\n\nReifschneider, Dave, William Wascher, and David Wilcox (2015). \"Aggregate Supply in the United States: Recent Developments and Implications for the Conduct of Monetary Policy,\" IMF Economic Review, vol. 63 (May), pp. 71-109.\n\nSchanzenbach, Diane Whitmore, Ryan Nunn, Lauren Bauer, and Audrey Breitwieser (2017). The Closing of the Jobs Gap: A Decade of Recession and Recovery. Washington: Hamilton Project, Brookings Institution, August 4.\n\nTrainer, David (2016). \"How the Internet Economy Killed Inflation,\" Forbes, September 28.\n\nValletta, Rob, and Catherine van der List (2015). \"Involuntary Part-Time Work: Here to Stay?\" FRBSF Economic Letter 2015-19. San Francisco: Federal Reserve Bank of San Francisco, June 8.\n\nYellen, Janet L. (2014). \"Labor Market Dynamics and Monetary Policy,\" speech delivered at \"Re-evaluating Labor Market Dynamics,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 21-23.\n\n-------- (2015). \"Inflation Dynamics and Monetary Policy,\" speech delivered at the Philip Gamble Memorial Lecture, University of Massachusetts, Amherst, Amherst, Mass., September 24.\n\n-------- (2016). \"Macroeconomic Research after the Crisis,\" speech delivered at \"The Elusive 'Great' Recovery: Causes and Implications for Future Business Cycle Dynamics,\" 60th annual economic conference sponsored by the Federal Reserve Bank of Boston, Boston, Mass., October 14.\n\nYoon, Jong-Won, Janill Kim, and Jungjin Lee (2014). \"Impact of Demographic Changes on Inflation and the Macroeconomy (PDF),\" IMF Working Paper WP/14/210. Washington: International Monetary Fund, November.\n\n1. The Statement on Longer-Run Goals and Monetary Policy Strategy is available on the Board's website at www.federalreserve.gov/monetarypolicy/files/FOMC_LongerRunGoals.pdf. Return to text\n\n2. The simple model links the current rate of inflation to several factors, including lagged inflation, long-run inflation expectations, labor utilization, and changes in the relative prices of food, energy and imports (Yellen, 2015). Additional details on the model can be found in the appendix. Return to text\n\n3. In the decomposition procedure, movements in core inflation affect headline inflation one-for-one; as a result, the contributions of food and energy price inflation are defined as each component's price change relative to the core, weighted by its share in total nominal consumer spending. The estimated contribution of movements in import prices is also computed relative to core inflation; thus, if import prices are rising at the same rate as core inflation, they have no estimated effect on the shortfall of overall inflation from 2 percent. In addition, the decomposition takes account of lags in the adjustment of core inflation to movements in resource utilization and other factors. More details on the decomposition procedure can be found in the appendix. Return to text\n\n4. In the simple model, inflation depends in part on lagged inflation. As a result, an unexplained movement in inflation is predicted to influence inflation beyond the current quarter, but to a degree that fades over time. On average, the model predicts that roughly 85 percent of any unexplained movement will have disappeared after four quarters. Return to text\n\n5. In general, price changes measured over a few months tend to be noisy, even when measured on a core or trimmed-mean basis. For this reason, the FOMC usually focuses on the growth rate of PCE prices over the previous 12 months, which smooths through the volatility in the monthly price data. This approach also sidesteps distortions in the monthly data associated with residual seasonality; these distortions are likely to hold down month-to-month changes in prices over the balance of the year (see Peneva, 2014). That said, 12‑month rates of inflation will continue to be held down through early 2018 by the unusually weak monthly readings on price changes recorded in early 2017. Return to text\n\n6. See Reifschneider and Tulip (2017) for details on the calculation of these confidence intervals. Return to text\n\n7. This statement abstracts from any persistent effects such disturbances might have on real activity, which could have implications for monetary policy. Return to text\n\n8. For example, Aaronson and others (2015) estimate that increases in the average age and educational attainment of U.S. workers will reduce the sustainable rate of unemployment almost 1/2 percentage point between 2014 and 2020. Barnichon and Mesters (2017) also present evidence that demographic changes have somewhat reduced the structural unemployment rate in the United States in recent years. Relatedly, Yoon, Kim, and Lee (2014) and Juselius and Takats (2015) estimate that ongoing demographic transitions are having modest disinflationary effects in the United States and other developed economies. Return to text\n\n9. The statistical evidence also suggests that the sustainable rate of unemployment could be higher. As illustrated by the results reported in Reifschneider, Wascher, and Wilcox (2015) and Barnichon and Matthes (2017), standard errors for estimates of the sustainable rate of unemployment are typically at least 1/2 percentage point. Accordingly, if the sustainable rate is estimated to be about 4-1/2 percent, there is roughly a 15 percent probability that the actual value is less than 4 percent; symmetrically, there is a 15 percent probability that it is greater than 5 percent. Return to text\n\n10. Several years ago, I discussed the interpretation of a wide range of labor market indicators at length (Yellen, 2014). Return to text\n\n11. The employment-to-population ratio for all persons aged 16 and over has recovered much less than the prime-age ratio since 2007, in large part reflecting the ongoing retirement of the baby boomers and a rise in school attendance rates for young adults aged 20 to 24 (Aaronson and others, 2014). Schanzenbach and others (2017) estimate that the substantial overall employment-to-population gap that opened up in the wake of the financial crisis finally closed in July 2017. Return to text\n\n12. The labor force participation rate for prime-age men has been declining for decades. Evidence suggests that a portion of the decline is attributable to a reduction in the demand for low-skilled workers resulting from advances in technology and globalization. For a general discussion of the decline in male labor force participation, see Aaronson and others (2014). For a discussion of the role played by technical factors in this decline, see Deming (forthcoming) and Acemoglu and Autor (2011); for a discussion of the role of globalization, see Autor, Dorn, and Hanson (2013) and Pierce and Schott (2016). In addition to these factors, Autor and Duggan (2003) and French and Song (2014) present evidence suggesting that increases in the number of people on disability rolls have also been important. Relatedly, an alarming deterioration in health outcomes among low-education workers, including a rise in deaths related to alcohol, drugs, and suicide, may be having an adverse effect on both male and female employment (Case and Deaton, 2017). Return to text\n\n13. For a discussion of how secular forces may be influencing the trend share of part-time employment, see Valletta and van der List (2015). Return to text\n\n14. In contrast to the other wage and compensation measures, the Wage Growth Tracker only measures wage changes for individuals who had a job in both the current month and a year ago. Return to text\n\n15. For example, predictions from a simple empirical model track recent movements in the employment cost index reasonably well, because the model estimates that the increasing upward pressure on compensation growth from rising labor utilization is being offset by a declining contribution from productivity growth. (See the appendix for further details.) Relatedly, research also suggests that cyclical changes in the composition of the workforce associated with the absorption of new workers with relatively low skills and experience may be currently restraining growth in both aggregate wages and productivity. See Daly and Hobijn (2017) and Daly, Hobijn, and Pyle (2016), who also point to the retirement of baby boomers as a factor holding down wage growth. Return to text\n\n16. See J.P. Morgan (2017) for more on this analysis. Return to text\n\n17. As I discussed in a speech one year ago, I view expectations formation as one of the key areas requiring further research by economists (see Yellen, 2016). Return to text\n\n18. In the Survey of Primary Dealers conducted by the Federal Reserve Bank of New York, the median of respondents' longer-term projections for PCE inflation have been essentially flat at 2 percent since the survey began in 2011. Similarly, in the Blue Chip Financial Indicators survey, which solicits the views of a large number of financial firms (as well as a few other institutions) about the extended outlook every June and December, the median of long-run expectations for GDP price inflation has stayed close to 2.1 percent over the past six years. Comparisons of results from these surveys to those reported in the Survey of Professional Forecasters (as well as surveys of households) are somewhat complicated by differences in the projection period used. For example, some surveys include the low rates of inflation expected over the next few years in the calculation of projected longer-run averages, while other surveys exclude them. Return to text\n\n19. Expected inflation over the next 5 to 10 years as reported in the Michigan survey runs appreciably above PCE price inflation on average since the mid-1990s, perhaps because households are less informed about actual inflation developments than professional forecasters and financial firms. For this reason, it may be best to focus on changes over time in the Michigan measure, not on the level. Return to text\n\n20. In addition to monitoring survey measures of expected inflation, Federal Reserve staff also use statistical techniques to try to directly estimate possible movements over time in the underlying long-run trend in inflation, using data for actual inflation and other series, including resource utilization. Many of these statistical estimates suggest that the underlying trend in PCE inflation is currently somewhat below 2 percent. Econometrically, however, it is extremely difficult if not impossible to disentangle estimates of the underlying trend in PCE inflation from estimates of the sustainable rate of unemployment. To be consistent with the data, the higher one's estimate of trend inflation or expected long-run inflation, the lower must be one's estimate of the sustainable unemployment rate, at least over the medium run. Return to text\n\n21. For example, Andreasen and Christensen (2016) show that once TIPS liquidity premiums are taken into account, the model-implied one-year inflation expectation becomes more stable and shows a smaller decline since 2013. In addition, quotes on inflation derivatives suggest that most of the decline in inflation compensation over this period is associated with investor perceptions of reduced risks of above-target inflation outcomes rather than increased risks of below-target inflation outcomes. Return to text\n\n22. Personal consumption expenditures include all medical services, including those paid by Medicare and Medicaid; prices for the latter may be viewed as \"administered\" because they are essentially set by the government. The formulas used to set Medicare prices were adjusted by the 2010 Affordable Care Act and additional legislation passed in 2015, resulting in smaller increases in prices for the same increase in costs than would have been the case in the prior decade. In addition, Medicaid prices have probably been restrained somewhat by budget pressures on state governments. Aside from these direct influences of government policy on healthcare prices, some research suggests that lower Medicare prices tend to lead to lower negotiated prices by private insurers as well (see Clemens, Gottlieb, and Shapiro, 2016). Return to text\n\n23. In an early study, Borio and Filardo (2007) reported results suggesting that global economic slack adds considerable explanatory power to reduced-form inflation equations (such as the one discussed in the appendix), and that its role has been growing over time. However, Ihrig, Kamin, Lindner, and Marquez (2010) subsequently argued that the estimated link was not robust to alternative measures of global resource utilization. Federal Reserve Board staff have updated this analysis using data through early 2017 and confirmed that global slack does not appear to exert an appreciable direct effect on domestic inflation in the United States and most other advanced economies. Return to text\n\n24. Using sector-level data, Elsby, Hobijn, and Sahin (2013) estimate the contributions of offshoring, the substitution of capital for low-skilled labor, and several other factors on the aggregate U.S. labor share of income, and find that only offshoring has been important. They also conclude that the decline in the labor share since the late 1980s has been overstated as a result of statistical measurement problems. In contrast to the influence of globalization on the U.S. labor share, Feenstra and Weinstein (2017) find that the influence of increased globalization on price markups in the United States has been modest. Return to text\n\n25. For more on the inflation implications of innovation in the retail sector, see Curran and Jamrisko (2017) and Trainer (2016). Return to text\n\n26. For a review of changes over time in the competitive structure of the overall economy, see Council of Economic Advisers (2016). For a discussion of the evidence for, and some of the implications of, changes in the dynamism of the economy, see Hathaway and Litan (2014) and Decker and others (2016). Return to text\n\n27. The median of FOMC participants' projections of the longer-run unemployment rate has declined almost a full percentage point over the past five years; the revision in the long-run consensus forecast reported in the Blue Chip Survey between October 2012 and March 2017 was slightly larger. Return to text\n\n28. It might be thought that the FOMC could mitigate this problem by raising the federal funds rate higher than might otherwise be called for while the economy continues to expand in order to increase the extent to which interest rates could be cut later should a recession occur. But this strategy would be counterproductive, because it would only serve to weaken economic activity and push down inflation before the recession. Return to text\n\n29. Although the data used in the decomposition analysis have been revised and extended, the specification of the model and the estimation period are the same as that discussed in a speech I gave two years ago (Yellen, 2015). As a result, the estimated coefficients of the model are essentially unchanged. Extending the estimation period through 2017:Q2 has little effect on the estimated coefficients and the decomposition estimates. Return to text\n\n30. This measure of core import prices is constructed by Board staff using published and unpublished data provided by the Bureau of Economic Analysis and the Bureau of Labor Statistics. Return to text\n\n31. The information on participants' forecasts provided at the September 20, 2017, press conference is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/files/fomcprojtabl20170920.pdf. Return to text\n\n32. The level of core import prices, expressed relative to core consumer prices, displayed a modest downward trend from 1990 through 2001 but since then has displayed little persistent trend, particularly if one controls for shifts related to recent changes in the real exchange rate. If the post-2001 pattern persists in coming years, then\nRPIM\nt\nwould be expected to converge to zero within a few quarters and core PCE inflation to converge to 2 percent within two or three years, assuming that the unemployment rate remains near 4-1/2 percent (the median of the longer-run projections provided by FOMC participants) and there are no further shocks to the exchange rate and other factors. If, however, core import prices were expected to resume trending down relative to consumer prices, then the model as specified would imply that the unemployment rate consistent with inflation stabilizing at 2 percent in the longer run would be somewhat lower than 4-1/2 percent. Return to text\n\n33. The ECI series used here is obtained from a ratio splice of the SIC- and NAICS-based indexes; the SIC-based index is used before 2001 and the NAICS-based index used thereafter. (All data used in the model were current as of September 1, 2017.) Return to text\n\n34. The estimation procedure imposes the joint restriction that the sum of the coefficients on\nπ\ne\nt−1\nand the lagged ECI growth terms are equal to 1, and that the coefficients on\nπ\ne\nt−1\nand\nMA_PROD\nt\nare equal. This joint restriction receives a\np\nvalue of 0.57. Return to text\n\n35. The low-pass component is obtained from a band-pass filter. The filter width and cutoffs are set equal to the values used in Douglas Staiger, James Stock, and Mark Watson (2001), \"Prices, Wages, and the U.S. NAIRU in the 1990s,\" in Alan Krueger and Robert Solow, eds., The Roaring Nineties: Can Full Employment Be Sustained? (New York: Russell Sage Foundation and Century Foundation Press), pp. 3‑60. Before the series' starting point in 1947:Q2, actual productivity growth is padded with an ARIMA(4,1,0) model; after its 2017:Q2 endpoint, the series is padded with the CBO's January 2017 forecast of average nonfarm business trend productivity growth from 2017 to 2027 (which is 1.67 percent in log differences) and with the 2027 value of the CBO forecast (1.77 percent) thereafter. Return to text"
    },
    {
        "title": "Why Persistent Employment Disparities Matter for the Economy's Health",
        "date": "September 26, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170926a.htm",
        "content": "September 26, 2017\n\nGovernor Lael Brainard\n\nAt \"Disparities in the Labor Market: What Are We Missing?\" a research conference sponsored by the Board of Governors of the Federal Reserve System, Washington, D.C.\n\nI want to compliment the organizers and others for gathering an outstanding group of researchers and papers for this conference. Understanding why some groups persistently fare better than others in the job market and how these disparities may affect the economy's overall performance is vitally important to the Federal Reserve. While opportunity and inclusion have long been central to American values, it is increasingly clear that they are also central to the strength of our economy.1\n\nAs directed by the Congress, the Federal Reserve's dual mandate is to promote maximum employment and stable prices. In fulfilling its dual mandate, the Federal Open Market Committee (FOMC) has set a target of 2 percent for inflation but does not have a similarly fixed numerical goal for maximum employment. That is because the level of maximum employment depends on \"nonmonetary factors that affect the structure and dynamics of the labor market,\" which \"may change over time and may not be directly measurable.\"2 Understanding how close the labor market is to our full-employment goal requires consulting a variety of evidence along with a healthy dose of judgment. The recognition that maximum employment evolves over time to reflect changes in the economic landscape serves us well by requiring FOMC participants to develop a nuanced understanding of labor market developments.\n\nThis approach to maximum employment has allowed the FOMC to navigate the current expansion in a way that has likely brought more people back into productive employment than might have been the case with a fixed unemployment rate target based on pre-crisis standards. This is especially true at a time when the traditional Phillips curve relationship is flatter than in the past, which means that price inflation is likely to be less informative regarding labor market tightness than it was previously.3 It therefore seems particularly valuable to look beyond inflation and headline unemployment to assess the strength of the labor market. Even when aggregate economic statistics look strong, studying geographic areas and demographic groups that are not faring as well can point to ways of further improving the economy's performance.\n\nThe Federal Reserve is also keenly interested in disparities in employment, labor force participation, income, and wealth because they may have implications for the growth capacity of the economy. When we consider appropriate monetary policy, we need to have a good sense of how fast the economy can grow without fueling excessive price inflation. At a time when the retirement of the baby-boom generation looks likely to be something of a drag on the growth of the labor force, it is especially important to consider whether relatively low levels of employment and labor force participation for some prime working-age groups represent slack that, if successfully tapped, could increase the labor force and boost economic activity.\n\nMore broadly, when a person who was previously unemployed or discouraged secures a job, not only does it boost the economy, but that person also may gain a greater sense of economic security, self-sufficiency, and self-worth and be better able to invest in their family's future. With a richer understanding of economic or social barriers that inhibit labor market success and prosperity for some groups, we may better grasp how much these individuals can be helped by broad economic expansion and how much targeted intervention is required through other policy means.\n\nThere is also an important connection between the economy's potential growth rate and equality of opportunity. Large disparities in opportunity based on race, ethnicity, gender, or geography mean that the enterprise, exertion, and investments of households and businesses from different groups are not rewarded commensurately. To the extent that disparities in income and wealth across race, ethnicity, gender, or geography reflect such disparities in opportunity, families and small businesses from the disadvantaged groups will then underinvest in education or business endeavors, and potential growth will fall short of the levels it might otherwise attain.4\n\nAside from reducing the long-run productive potential of the economy, persistently high levels of income and wealth inequality may also have implications for the robustness of consumer spending, which accounts for roughly two-thirds of aggregate spending in the United States. The gaps in household income and wealth between the richest and poorest households are at historically high levels, as income and wealth have increasingly accrued to the very richest households. For example, results from the Federal Reserve's latest Survey of Consumer Finances (SCF), which is due to be released soon, indicate that the share of income held by the top 1 percent of households reached 24 percent in 2015, up from 17 percent in 1988. The share of wealth held by the top 1 percent rose to 39 percent in 2016, up from 30 percent in 1989.5 Some research suggests that widening income and wealth inequality may damp consumer spending in the aggregate, as the wealthiest households are likely to save a much larger proportion of any additional income they earn relative to households in lower income groups that are likely to spend a higher proportion on goods and services.6\n\nDisparities by Race and Ethnicity\nWhen we disaggregate the economy-wide labor market statistics, we find significant and persistent racial and ethnic disparities.7 In August, the national unemployment rate of 4.4 percent, which is low by historical standards, masked substantial differences across different demographic groups. As shown in figure 1, unemployment rates ranged from 3.9 percent for whites to 4 percent for Asians, 5.2 percent for Hispanics, and 7.7 percent for African Americans. Labor force participation rates, shown in figure 2, also differ substantially, although by less than unemployment rates, with the rate for African Americans lowest at 62.2 percent. These differences are not a recent development--similar differences across racial and ethnic dimensions have existed for as long as these data have been collected. Even more striking, a significant portion of the gaps in unemployment rates across racial and ethnic groups cannot be attributed to differences in their underlying characteristics, such as age and education levels.8\n\nAlthough the differences in employment rates between racial and ethnic groups are still quite large, they have narrowed recently, after having widened considerably during the recession, and are near their lowest levels in decades. Differences in unemployment rates across racial and ethnic groups tend to widen sharply during recessions, as less advantaged groups shoulder an outsized share of total layoffs, and these differences shrink during recoveries. For example, in the second quarter of 2017, the unemployment rate for black adult men was a little more than 3 percentage points higher than for white adult men. This differential, while sizable, is nonetheless close to the smallest gap seen since comparable data became available in the mid-1970s. Differences in unemployment rates are similarly near historical lows for black women relative to white women, and for Hispanics relative to whites. Since racial disparities tend to get smaller throughout the course of an economic expansion, it seems likely that racial differences in unemployment rates will continue to shrink if the overall unemployment rate falls further.9\n\nMore broadly, the persistent disparities in employment outcomes are mirrored in significant and persistent racial and ethnic differences in families' income and wealth. According to forthcoming findings from the latest SCF and as shown in figure 3, the average income for white families in 2015 was about $123,000 per year, compared with $54,000 for black families and $57,000 for Hispanic families.10 Disparities in wealth, shown in figure 4, are even larger: Average wealth holdings for white families in 2016 were about $933,000, compared with $191,000 for Hispanic families and $138,000 for black families.11 Moreover, these racial and ethnic gaps in average family income and wealth have generally widened rather than narrowed over the past few decades. Based on SCF data, median family wealth has grown much more rapidly for white families than for other families over the past few decades, while median family incomes have risen by about the same amount for white, black, and Hispanic families.\n\nAs the economic expansion continues and brings more Americans off the sidelines and into productive employment, it seems likely that the positive trends in employment and participation rates for historically disadvantaged groups will continue. That said, the benefits of a lengthy recovery can only go so far, as the research points to some barriers to labor market outcomes for particular groups that appear to be structural. After controlling for sectoral and educational differences, the research suggests that these factors include discrimination as well as differences in access to quality education and informal social networks that may be an important source of information and support regarding employment opportunities.12 While the policy tools available to the Federal Reserve are not well suited to addressing the barriers that contribute to persistent disparities in labor market outcomes, understanding these barriers and efforts to address them is vital in assessing maximum employment as well as potential growth.\n\nGeographic Disparities\nThe Federal Reserve System benefits not only from our engagement with research, statistics, and surveys, but also from our presence in communities all across America. This local presence, by design, provides valuable perspectives on how Americans in different communities are experiencing the economy and the varied challenges that lie beneath the aggregate numbers. While traveling around the country with our community development staff, I have been struck by the widening gulf between the economic fortunes of our large metropolitan areas and those of our small cities, towns, and rural areas.\n\nThe statistics bear this out. Over the past 30 years, the convergence in income across regions of the country has slowed dramatically.13 Much of the gains in employment, income, and wealth since the end of the recession, and more broadly over the past few decades, have accrued to workers and families in larger cities. Since some workers and families may find it difficult to move, this concentration of economic opportunities in larger cities may have adverse implications for the well-being of these households and, potentially, the growth capacity of the economy as a whole.\n\nAlthough pockets of opportunity and poverty are found in large metropolitan and rural areas alike, a greater share of the new jobs and business establishments created during the recovery that followed the Great Recession have been in larger metro areas than was the case in previous recoveries.14 In countless rural towns and small cities we are seeing how a deep economic setback can leave a profound and long-lasting mark. These experiences challenge common assumptions about the ability of local economies to recover from a setback. This could be the legacy of the concentrated presence of an industry that experiences decline due to trade or technology, or it could be the byproduct of a lack of connectivity--whether by highways or broadband. Technological change, globalization, and other shifts in demand and costs are not new to the U.S. economy, but there are troubling signs that less diversified or connected localities have a diminished ability to adapt. And the evidence suggests that concentrated economic shocks and the associated labor market stress also have broader consequences for health and mortality.15\n\nTo provide some sense of the magnitudes, on average over the past year the unemployment rate for adults of prime working age (25 to 54) was about 1 percentage point higher in nonmetropolitan areas than in larger metro areas.16 But there is an even greater gap in labor force engagement, as can be seen in figure 5. The participation rate for prime-age adults in larger metro areas is currently nearly 3‑1/2 percentage points above the participation rate for prime-age adults in nonmetro areas. Interestingly, the geographic participation rate gap between more and less populous areas is apparent for all races as well as, in recent years, for both men and women.17\n\nThis gap in labor force participation between large cities and other areas has widened substantially since just before the Great Recession: Since 2007, the participation rate for prime-age adults in nonmetro areas has fallen nearly 3 percentage points, as compared with less than 1 percentage point on net in larger metro areas. Indeed, since 2007, the large decline in labor force participation in small metro and rural areas can explain about 40 percent of the economy-wide decline in prime-age labor force participation, even though these areas account for a smaller 25 percent of the population.\n\nBefore discussing possible contributors to this growing participation gap, it is important to emphasize that less populous areas appear to be falling behind in ways beyond these employment outcomes. Based on forthcoming SCF data, for example, the average annual income for families in metro areas was about $54,000 higher than for families in nonmetro areas, and the average wealth holdings for families in metro areas exceeded average wealth for families in nonmetro areas by nearly $500,000--and these gaps have more than doubled over the past three decades.18 i The gaps in many other measures of well-being have widened as well. In small towns and rural areas, college attainment rates have increased by less, disability rates have increased by more, divorce rates have risen by more, and mortality due to lung disease, cancer, or cardiovascular disease have either improved by less or worsened by more.19 Opioid use is also most prevalent in less populous metro and rural areas.20\n\nI have seen many of these challenges first hand. In the small towns and hollers of eastern Kentucky, I visited with community development financial institutions that are trying to plug the gap in access to credit so that small businesses can continue operating and hiring locally, and so that families can access housing that is safe and affordable. In rural communities in the Mississippi Delta, I learned about diminished access to financial services available to rural residents, which can be a barrier to housing and business investment and pose vexing challenges to local governments. In Texas, I learned about barriers to economic development in the rural colonias areas on the southern border associated with underinvestment in physical and broadband infrastructure.21\n\nAs we consider the long-term health of the U.S. economy, it is important to better understand the decade-long decline in aggregate labor force participation. It is striking that in larger metro areas, the labor force participation rate for prime-age men has recently retraced much of the decline experienced during the recession, while in smaller metro and rural areas, the labor force participation rate remains well below its pre-recession level, with only modest improvements of late. The evidence increasingly suggests that much of the decline relates to a sustained decline in job opportunities for prime-age men, especially less-educated prime-age men, resulting in languishing wages relative to other groups.22 Indeed, it is notable that the striking decrease in labor force participation rates for nonmetro areas relative to large metro areas is highly concentrated among adults with no more than a high school education, who comprise a larger share of the prime-age population in nonmetro areas. The labor force participation rate for adults with no more than a high school education has fallen to 72 percent in nonmetro areas--about 3-1/2 percent below larger metro areas.23\n\nAlthough the precise causes of this decline are still not fully settled, one contributing factor is advancing automation and computerization.24 Another contributor is globalization. For example, a growing body of research has identified a steeper decline in the employment and labor force attachment of prime-age men in areas of the country that specialized in the industries that were most negatively affected by increased imports from China.25\n\nResearch suggests that some of the decline in prime-age labor force participation relates to some individuals' reduced ability or desire to work, in some cases resulting directly from the ongoing decline in job opportunities. There are many reasons why some prime-age men may be less willing or able to work. One possibility is that the unusually long spells of nonemployment associated with the Great Recession may have eroded job skills and informal employment networks. Another possibility that is increasingly in focus is that physical disabilities, as well as sharp increases in opioid use, have increasingly inhibited some individuals from participating in the labor force. The fraction of prime-age men receiving disability insurance benefits has increased from 1 percent in the late 1970s to 3 percent more recently.26 Recent research also finds that among all prime-age men who are not in the labor force, about one-third reported having at least one disability, and nearly one-half reported taking pain medications daily.27 These supply-side explanations may be related to the drop in labor demand: the despair related to diminished prospects of a stable and quality job may lead to substance abuse and related health or mortality concerns.28\n\nAt least some of these explanations potentially relate to the growing divide between large metro areas and other areas of the country. As noted earlier, the opioid epidemic appears to be particularly acute in smaller cities and rural areas. In addition, employment in non-metro areas tends to be more concentrated in manufacturing, which is the sector that has experienced the largest decline in employment from automation and globalization.29 Similarly, research suggests that workers in less populous areas have been more likely to be directly affected by increased import competition from China due to the geographical distribution of industries.30 And for many less populous areas, job opportunities are less diverse than in bigger cities, so that when a plant shuts down, there are fewer local alternative job opportunities for unemployed workers, especially with comparable levels of employment security or benefits.\n\nThese striking results naturally raise the question of whether we are seeing heightened migration from the less populous areas to the larger metros with greater economic opportunity. A conventional assumption in economics is that regional differences should narrow over time as workers move toward areas where jobs are more plentiful and wages are higher.31 In reality, Americans' propensity to move is currently at its lowest level in many decades. In 2016, the fraction of the population that had moved within the United States in the past year was 11 percent, down from 17 percent or more in the early 1980s, with the steepest decline in the fraction of people moving longer distances, across county or state lines.32 The evidence suggests that the decline in geographic mobility cannot be fully explained by population aging, by the housing boom and bust, by changes in the composition of industries, by the increasing ease of telecommuting from longer distances, or by the rise in dual-earner households which may make work-related relocation more difficult. Some of the decline may be related to changes in the labor market, perhaps because workers are more likely to perceive that job opportunities are no better elsewhere, and consequently that the labor market returns to switching jobs or locations--in terms of better wages or higher job quality--have declined.33 Also, zoning requirements may be boosting housing costs in cities where job opportunities are most abundant, such as San Francisco, pricing out many potential workers and inhibiting migration.34\n\nWhatever the reason, the fact that families are less likely to move now than in the past suggests that many of those in less populous areas are not able to access the economic opportunity present in denser and more diversified large metropolitan areas at a time when the gap in labor market outcomes for larger metros relative to other areas continues to grow.\n\nFederal Reserve Work on Labor Market Disparities\nThe Federal Reserve is deeply engaged in understanding disparities through our data collection, research collaboration, and community development work. One way the Federal Reserve seeks to obtain a clearer picture is by collecting data ourselves. For instance, some of the data I have cited today come from the Federal Reserve's triennial Survey of Consumer Finances, which provides detailed information on income and wealth holdings by demographic groups. The Survey of Household Economics and Decisionmaking provides a portrait of household finances, employment, housing, and debt; the Survey of Young Workers provides insights into younger adults' employment experiences soon after entering the labor force; and the Enterprising and Informal Work Activities Survey provides information about income generating activities that are often outside the scope of other employment and income surveys.35\n\nAcross the Federal Reserve System, a variety of initiatives are aimed at understanding economic disparities and how to foster more-inclusive growth. The Opportunity and Inclusive Growth Institute at the Federal Reserve Bank of Minneapolis brings together researchers from a variety of fields to analyze barriers to economic opportunity and advancement. The Economic Growth and Mobility Project at the Federal Reserve Bank of Philadelphia aims to bring together researchers with community stakeholders to focus on differences in poverty and economic mobility across demographic characteristics. The Investing in America's Workforce Initiative is a collaboration between the Federal Reserve System and academic research institutions to promote investment in workforce skills that better align with employers' needs.36\n\nAll of that brings me to today's conference, which I am confident will make an important contribution to this mission. I am heartened to see so many researchers and practitioners from a variety of backgrounds focused on these important issues. This conference is part of our efforts to hear from experts with diverse backgrounds and perspectives to better understand the nature and implications of labor market disparities.\n\nA deeper understanding of labor market disparities is central to the mission of the Federal Reserve because it may help us better assess full employment, where resources may be underutilized, and the likely evolution of the labor market and overall economic activity. We look forward to hearing what you have to say about these important questions and learning what other questions are in need of attention.\n\nReferences\nAaronson, Stephanie, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014). \"Labor Force Participation: Recent Developments and Future Prospects,\" Brookings Papers on Economic Activity, Fall, pp. 197-255.\n\nAcemoglu, Daron, David Autor, David Dorn, Gordon H. Hanson, and Brendan Price (2016). \"Import Competition and the Great U.S. Employment Sag of the 2000s,\" Journal of Labor Economics, vol. 34 (part 2, January), S141-98.\n\nAcemoglu, Daron, and Pascual Restrepo (2017). \"Robots and Jobs: Evidence from U.S. Labor Markets (PDF),\" unpublished paper, March 17.\n\nAdamy, Janet, and Paul Overberg (2017). \"Rural America is the New 'Inner City',\" Wall Street Journal, May 26.\n\nAlichi, Ali, Kory Kantenga, and Juan Solè (2016). \"Income Polarization in the United States (PDF),\" IMF Working Paper 16/121. Washington: International Monetary Fund.\n\nAutor, David (2010). \"The Polarization of Job Opportunities in the U.S. Labor Market: Implications for Employment and Earnings (PDF).\" Washington: Center for American Progress and Hamilton Project.\n\nAutor, David, David Dorn, and Gordon Hanson (2013). \"The China Syndrome: Local Labor Market Effects of Import Competition in the United States,\" American Economic Review, vol. 103 (October), pp. 1553-97.\n\nAutor, David, David Dorn, and Gordon Hanson (2015). \"Untangling Trade and Technology: Evidence from Local Labor Markets,\" Economic Journal, vol. 125 (May), pp. 621-46.\n\nBernstein, Jared (2013). \"The Impact of Inequality on Growth.\" Washington: Center for American Progress.\n\nBlanchard, Olivier (2016). \"The U.S. Phillips Curve: Back to the 60s? (PDF)\" Policy Brief PB16-1. Washington: Peterson Institute for International Economics, January.\n\nBlanchard, Olivier and Lawrence Katz (1992). \"Regional Evolutions (PDF),\" Brookings Papers on Economic Activity, no. 1, pp. 1-75.\n\nBrainard, Lael (2015). \"Economic Outlook and Monetary Policy,\" speech delivered at the 57th National Association for Business Economics Annual Meeting, Washington, October 12.\n\nBrainard, Lael (2017). \"Why Opportunity and Inclusion Matter for America's Economic Strength,\" speech delivered at the Opportunity and Inclusive Growth Institute Conference, sponsored by the Federal Reserve Bank of Minneapolis, Minneapolis, Minnesota, May 22.\n\nBricker, Jesse, Lisa J. Dettling, Alice Henriques, Joanne W. Hsu, Lindsay Jacobs, Kevin B. Moore, Sarah Pack, John Sabelhaus, Jeffrey Thompson, and Richard A. Windle (forthcoming). \"Changes in U.S. Family Finances from 2013 to 2016: Evidence from the Survey of Consumer Finances,\" Federal Reserve Bulletin.\n\nCajner, Tomaz, Tyler Radler, David Ratner, and Ivan Vidangos (2017). \"Racial Gaps in Labor Market Outcomes in the Last Four Decades and over the Business Cycle (PDF),\" Finance and Economics Discussion Series 2017-071. Washington: Board of Governors of the Federal Reserve System.\n\nCase, Anne and Angus Deaton (2015). \"Rising Morbidity and Mortality in Midlife among White Non-Hispanic Americans in the 21st Century,\" Proceedings of the National Academy of Sciences, vol. 112 (December), pp. 15078-83.\n\n-------- (2017). \"Mortality and Morbidity in the 21st Century (PDF),\" Brookings Papers on Economic Activity, Spring, pp. 397-452.\n\nCouncil of Economic Advisors (2014). \"The Labor Force Participation Rate since 2007: Causes and Policy Implications (PDF).\" Washington: Council of Economic Advisors, Executive Office of the President of the United States.\n\n-------- (2016). \"The Long-Term Decline in Prime-Age Male Labor Force Participation (PDF).\" Washington: Council of Economic Advisors, Executive Office of the President of the United States.\n\nEconomic Innovation Group (2016). The New Map of Economic Growth and Recovery (PDF). Washington: EIG, May.\n\nFryer, Jr., Roland G. (2011). \"Racial Inequality in the 21st Century: The Declining Significance of Discrimination,\" in David Card and Orley Ashenfelter, eds., Handbook of Labor Economics, vol. 4b. Amsterdam: North Holland, pp. 855‑971.\n\nGanong, Peter, and Daniel W. Shoag (2017). \"Why Has Regional Income Convergence in the U.S. Declined?\" National Bureau of Economic Research Working Paper No. 23609.\n\nGoetz, Stephen, Mark Partridge, and Heather Stephens (2017). \"The Economic Status of Rural America in the Trump Era,\" MPRA Paper 77830. Munich: Munich Personal RePEc Archive, March.\n\nGuy, Jr., Gery P., Kun Zhang Kun, Michele K. Bohm, Jan Losby, Brian Lewis, Randall Young, Louise B. Murphy, and Deborah Dowell (2017). \"Vital Signs: Changes in Opioid Prescribing in the United States, 2006–2015 (PDF),\" Morbidity and Mortality Weekly Report, vol. 66 (July 7), pp. 697-704.\n\nHerkenhoff, Kyle F., Lee E. Ohanian, and Edward C. Prescott (2017). \"Tarnishing the Golden and Empire States: Land-Use Regulations and the U.S. Economic Slowdown.\" NBER Working Paper No. 23790. Cambridge, Mass.: National Bureau of Economic Research, September.\n\nKaplan, Greg, and Sam Schulhofer-Wohl (2017). \"Understanding the Long-Run Decline in Interstate Migration,\" International Economic Review, vol. 58 (February) pp. 57-94.\n\nKiley, Michael T. (2015). \"Low Inflation in the United States: A Summary of Recent Research,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, November 23.\n\nKrueger, Alan (forthcoming). \"Where Have All the Workers Gone? An Inquiry into the Decline of the U.S. Labor Force Participation Rate.\" Brookings Papers on Economic Activity. (The conference draft is available at https://www.brookings.edu/bpea-articles/where-have-all-the-workers-gone-an-inquiry-into-the-decline-of-the-u-s-labor-force-participation-rate.)\n\nMarrero, Gustavo, and Juan Rodrìguez (2013). \"Inequality of Opportunity and Growth,\" Journal of Development Economics, vol. 104 (September), pp. 107-22.\n\nMolloy, Raven, Christopher L. Smith and Abigail Wozniak (2011). \"Internal Migration in the United States,\" Journal of Economic Perspectives, vol. 25 (Summer), pp. 173-96.\n\n-------- (2017). \"Job Changing and the Decline in Long-Distance Migration in the United States,\" Demography, vol. 54 (April), pp. 631-53.\n\nPierce, Justin R. and Peter K. Schott (2016a). \"The Surprisingly Swift Decline of U.S. Manufacturing Employment,\" American Economic Review, vol. 106 (July), pp. 1632-62.\n\n-------- (2016b). \"Trade Liberalization and Mortality: Evidence from U.S. Counties (PDF),\" Finance and Economics Discussion Series 2016-094. Washington: Board of Governors of the Federal Reserve System, November.\n\nRitter, Joseph A., and Lowell J. Taylor (2011). \"Racial Disparity in Unemployment,\" Review of Economics and Statistics, vol. 93 (February), pp. 30-42.\n\nSampson, Robert J. (2016). \"Individual and Community Economic Mobility in the Great Recession Era: The Spatial Foundations of Persistent Inequality (PDF),\" in Federal Reserve Bank of St. Louis and Board of Governors of the Federal Reserve System, eds., Economic Mobility: Research and Ideas on Strengthening Families, Communities, and the Economy. St. Louis: Federal Reserve Bank of St. Louis, pp. 259-87.\n\nSemega, Jessica L., Kayla R. Fontenot, and Melissa A. Kollar (2017). \"Income and Poverty in the United States: 2016 (PDF),\" Current Population Reports, pp. 60-259. Washington: U.S. Census Bureau, September, .\n\nWeingarden, Alison (2017). \"Labor Market Outcomes in Metropolitan and Non-metropolitan Areas: Signs of Growing Disparities,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, September 25.\n\nYellen, Janet L. (2015). \"So We All Can Succeed: 125 Years of Women's Participation in the Economy,\" speech delivered at \"125 Years of Women at Brown,\" a conference sponsored by Brown University, Providence, Rhode Island, May 5.\n\n1. I am grateful to Christopher Smith for his assistance in preparing this text. The remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. The FOMC's Statement on Longer-Run Goals and Monetary Policy Strategy is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/files/fomc_longerrungoals.pdf. Return to text\n\n3. For more on the Phillips curve and its ability to provide information on labor-market slack, see Brainard (2015), Blanchard (2016), and Kiley (2015). Return to text\n\n4. For more on inequality of opportunity see Marrero and Rodriquez (2013). Return to text\n\n5. Staff calculations from forthcoming SCF data (to be released on September 27); for additional analysis of these data, see Bricker and others (forthcoming). Return to text\n\n6. See Bernstein (2013) and Alichi, Kantenga, and Solè (2016) for more on the potential link between income and wealth inequality and consumer spending. Return to text\n\n7. For a discussion of gender disparities, see Yellen (2015). Return to text\n\n8. See Cajner and others (2017) for more on racial gaps and the labor market. Return to text\n\n9. Data on recent estimates of unemployment rates for adult men (20 years and older) by race and ethnicity are available from the Bureau of Labor Statistics. Historical gaps are provided by Cajner and others (2017). Return to text\n\n10. Staff calculations from forthcoming SCF data. Recent estimates of household income from Current Population Survey data and reported by the Census in Semega, Fontenot, and Kollar (2017) are qualitatively similar, in that between 2013 and 2016 for both sets of data, family income has increased for whites, blacks, and Hispanics (with greater increases, in percentage terms, for black and Hispanic families). Return to text\n\n11. Racial and ethnic differences in median income and wealth are somewhat smaller. For example, in 2016 median income for white families was about $61,000, compared with $35,000 for black families and $39,000 for Hispanic families. Median wealth was about $171,000 for white families, compared with about $20,000 for black and Hispanic families. The larger gap in average income and wealth than median income and wealth reflects a greater concentration of income and wealth among the wealthiest white families than for other races and ethnicities. Return to text\n\n12. For example, see Fryer (2011) and Ritter and Taylor (2011). Return to text\n\n13. See Ganong and Shoag (2017) and references therein for more on the decline in income convergence. Return to text\n\n14. See Goetz, Partridge, and Stephens (2017) and Economic Innovation Group (2016) for details on growing regional differences during the recovery. Return to text\n\n15. See Autor, Dorn, and Hanson (2013) and Pierce and Schott (2016b). Return to text\n\n16. Larger metro areas are defined as metropolitan statistical areas (MSAs) with a population of 500,000 or larger, while smaller metro areas are MSAs with population between 100,000 and 500,000, and nonmetro areas are the remainder; see Weingarden (2017). Return to text\n\n17. This gap appears to be a post-crisis phenomenon for women, while for men the gap began to widen in the 1990s. Return to text\n\n18. Staff estimates from forthcoming SCF data. Although the difference in average income and wealth has grown, there has been little change in differences in median family income and wealth in larger metros relative to other areas. The widening gap for average income and wealth, but not for median income and wealth, is because in larger metro areas income and wealth has become increasingly held by wealthier families. Return to text\n\n19. These statistics are provided in Adamy and Overberg (2017). Return to text\n\n20. See Guy, Jr., and others (2017). Return to text\n\n21. See the Brainard (2017) speech on opportunity and inclusion. Return to text\n\n22. Most analysis suggests that at least half of the decline in the aggregate labor force participation rate since 2007 is attributable to the aging of the population, with a significant portion of the decline that is not related to aging attributable to a longer-run decline in participation for younger individuals and prime-age men; for example, see Aaronson and others (2014) and the Council of Economic Advisors (2014). For an overview of factors potentially attributable to the decline in labor force participation of prime-age men, see the Council of Economic Advisors (2016). Return to text\n\n23. These estimates are based on data from Weingarden (2017). Return to text\n\n24. For an overview of factors that have potentially impacted job opportunities for this group, see Autor (2010). For examples of research on the recent labor market effects of technology and automation, see Autor, Dorn, and Hanson (2015) and Acemoglu and Restrepo (2017). Return to text\n\n25. For national-level estimates of the labor market effects from cheaper Chinese imports, see Pierce and Schott (2016a) and Acemoglu and others (2016). For evidence related to cross-country differences in these effects, see Autor, Dorn, and Hanson (2013), and Pierce and Schott (2016b). Return to text\n\n26. See Council of Economic Advisors (2016). Return to text\n\n27. Krueger (forthcoming) describes evidence from a variety of surveys showing that a significant fraction of prime-age men who are out of the labor force report having pain, being in poor health, or taking medication related to this pain, and that these behaviors are far more common among prime-age men than prime-age women. Return to text\n\n28. See Case and Deaton (2015, 2017). Return to text\n\n29. Based on staff analysis of publically available data from the Bureau of Economic Analysis on metropolitan and nonmetropolitan employment by industry. Return to text\n\n30. This observation reflects unpublished calculations from Pierce and Schott (2016b). Return to text\n\n31. See Blanchard and Katz (1992). Return to text\n\n32. Data on internal migration rates come from the Current Population Survey and are published annually by the Census Bureau; see \"Table A-1. Annual Geographic Mobility Rates, by Type of Movement: 1948-2016.\" Return to text\n\n33. For a discussion of the multidecade decline in internal migration and its potential causes, see Molloy, Smith, and Wozniak (2011, 2017) and Kaplan and Schulhofer-Wohl (2017). Return to text\n\n34. See Ganong and Shoag (2017) and Herkenhoff, Ohanian, and Prescott (2017). Return to text\n\n35. Further information on these surveys are found on the Board's website; see the Survey of Consumer Finances; the Survey of Household Economics and Decisionmaking; the Survey of Young Workers; and the Survey of Enterprising and Informal Work Activities (PDF). Return to text\n\n36. For information about the Opportunity and Inclusive Growth Institute, see https://www.minneapolisfed.org/institute, for information about the Economic Growth and Mobility Project, see https://www.philadelphiafed.org/egmp, and for information about the America's Workforce Initiative, see https://www.investinwork.org. Return to text\n\ni. Note. On September 27, 2017, a typo was corrected to change $25,000 to $54,000 in the following sentence on page 9: \"Based on forthcoming SCF data, for example, the average annual income for families in metro areas was about $54,000 higher than for families in nonmetro areas, and the average wealth holdings for families in metro areas exceeded average wealth for families in nonmetro areas by nearly $500,000--and these gaps have more than doubled over the past three decades.\" The original number incorrectly stated the median instead of the mean. Return to text"
    },
    {
        "title": "Understanding the Disconnect between Employment and Inflation with a Low Neutral Rate",
        "date": "September 05, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170905a.htm",
        "content": "September 05, 2017\n\nGovernor Lael Brainard\n\nAt The Economic Club of New York New York, New York\n\nOverall, the U.S. economy remains on solid footing, against the backdrop of the first synchronized global economic growth we have seen in many years and accommodative financial conditions. This benign outlook is clouded somewhat by uncertainty about government funding and the fiscal outlook, and geostrategic risk has risen. While the heartbreaking human toll exacted by Hurricane Harvey is already all too clear, it will take some time to assess the macroeconomic impact.\n\nThe labor market continues to bring more Americans off the sidelines and into productive employment, which is a very welcome development. Nonetheless, there is a notable disconnect between signs that the economy is in the neighborhood of full employment and a string of lower-than-projected inflation readings, especially since inflation has come in stubbornly below target for five years. With normalization of the federal funds rate under way and the start of gradual balance sheet normalization widely anticipated, I will want to take some time to assess the path of the federal funds rate that will best support a sustainable move in inflation to our 2 percent goal.1 Sustainably achieving our inflation objective is especially important, given the apparent persistently low level of the neutral rate and the resulting limited room for maneuver above the effective lower bound.\n\nLet me start by reviewing the economic outlook. There has been a noteworthy pickup in business investment this year compared with last year. Investment in the equipment and intellectual property category has risen at an annual rate of 6 percent so far this year after remaining roughly flat last year. The latest data on orders and shipments of capital equipment suggest that solid growth will likely continue in the second half of the year. In addition, oil drilling had rebounded this year after dropping sharply last year, although Hurricane Harvey creates uncertainty about drilling in coming months. While lackluster consumer spending was one of the key reasons for the weak increase in first-quarter gross domestic product (GDP), growth in personal consumption expenditures (PCE) bounced back strongly in the second quarter, and recent readings on retail sales suggest another solid increase in consumer spending this quarter.\n\nOf course, the likely economic effects of Hurricane Harvey raise uncertainties about the economic outlook for the remainder of the year. Based on past experience, it appears likely that the hurricane will have a notable effect on GDP in the current quarter, although output is likely to rebound by the end of the year. According to the U.S. Department of Energy, between 20 and 30 percent of the nation's oil refining capacity was shut down at the peak last week, and it is estimated that about 50 percent of petrochemical production was similarly shut down. Some oil production has also been disrupted. These developments have put upward pressure on gasoline prices. Based on previous hurricane events, the increase in gasoline prices should be short lived, but this outcome is uncertain and will depend on the extent of damage to refining capacity.\n\nImprovements in the labor market have continued. According to last Friday's labor market report, nonfarm payrolls have increased around 185,000 per month over the three months through August, about the same as the average monthly gains last year. The unemployment rate has been roughly flat for the past several months at 4.4 percent, which is 1/2 percentage point lower than at the same time last year. The employment-to-population ratio for prime-age workers has also improved over the past year, although it is still 2 percentage points lower than its pre-crisis peak in 2007.\n\nEarlier this year, many observers saw the prospect of fiscal stimulus as presenting the possibility of a substantial boost to domestic demand. Since then, however, many commentators have downgraded their assessments of the extent and timing of fiscal stimulus, and I have revised my outlook as well.\n\nThat said, we are seeing synchronized global economic growth for the first time in many years. Foreign economies--including Canada, the euro area, and China--have posted robust GDP growth so far this year. This improvement has been reflected here at home in dollar depreciation; higher earnings and stock prices; tighter risk spreads; and an increase in net exports, which made a small positive contribution in the first half of this year after holding down GDP growth over the past several years. In addition, there are indications that, before too long, central banks in several major economies could begin normalizing monetary policy, in many cases through adjustments to their balance sheets as well as their policy rates. Those changes in foreign monetary policies could have important implications for term premiums and, in turn, longer-term Treasury rates, depending on the timing and approach.2\n\nDespite this benign picture for the U.S. economy and continued increases in resource utilization, core inflation, as measured by changes in the PCE price index for items other than food and energy, slowed by almost 1/2 percentage point relative to the pace a year ago. Indeed, both overall and core inflation were only 1.4 percent for the year through July, well short of the Federal Open Market Committee's (FOMC) objective.\n\nTo what extent does it make sense to look through the recent low inflation readings on the grounds they are transitory? It appears that temporary factors, such as discounted cell phone plans, are pushing down inflation to some extent this year. By the same token, it is likely that other temporary factors--for example, prescription drug prices--boosted inflation last year. Going forward, we should see a temporary boost to headline inflation due to Hurricane Harvey's effect on gasoline prices that I mentioned earlier. Temporary factors, by their nature, have little implication for the underlying trend in inflation.\n\nIn contrast, what is troubling is five straight years in which inflation fell short of our target despite a sharp improvement in resource utilization. It is instructive to put the shortfall in inflation in recent years in perspective by comparing inflation in the past few years with the last time the economy was in the neighborhood of full employment--namely, just before the financial crisis. In particular, over the past three years, unemployment has averaged roughly 5 percent. Similarly, over the three years ending in early 2007--before the unemployment rate started rising--the unemployment rate also averaged 5 percent. Despite a similar degree of resource utilization, core inflation averaged 2.2 percent from 2004 to 2007, notably higher than the comparable three-year average inflation rate today of 1.5 percent. Why is inflation so much lower now than it was previously? The fact that the period from 2004 to 2007 had inflation around target with similar unemployment rates casts some doubt on the likelihood that resource utilization is the primary explanation.3 Similarly, a 12-quarter average is typically long enough that temporary factors should not be the dominant concern.\n\nOne key factor that may have played a role in the past three years is the decline in import prices, reflecting the dollar's surge, especially in 2015. By contrast, in the 2004‑07 period, non-oil import prices increased at roughly a 2 percent annual rate and had a more neutral effect on inflation. Nonetheless, while the decline in non-oil import prices likely accounts for some of the weakness in inflation over the past few years, these prices have begun rising again in the past year at a time when inflation remains relatively low.\n\nSo if import prices, resource utilization, and transitory factors together do not provide a complete account, why has inflation been so much lower in the past few years than it was previously? In many of the models economists use to analyze inflation, a key feature is \"underlying,\" or trend, inflation, which is believed to anchor the rate of inflation over a fairly long horizon. Underlying inflation can be thought of as the slow-moving trend that exerts a strong pull on wage and price setting and is often viewed as related to some notion of longer-run inflation expectations.\n\nThere is no single highly reliable measure of that underlying trend or the closely associated notion of longer-run inflation expectations. Nonetheless, a variety of measures suggest underlying trend inflation may currently be lower than it was before the crisis, contributing to the ongoing shortfall of inflation from our objective. That conclusion is suggested by estimates based on time-series models, longer-run expectations from the University of Michigan Surveys of Consumers and Survey of Professional Forecasters, and market-based measures of inflation compensation.\n\nStarting with time-series models, one model that has been used by a variety of researchers suggests that underlying trend inflation may have moved down by perhaps as much as 1/2 percentage point over the past decade.4 Market-based measures of inflation compensation provide another read on inflation expectations. Comparing the three-year period ending in the second quarter of this year with the three-year period ended just before the financial crisis, 10-year-ahead inflation compensation based on TIPS (Treasury Inflation-Protected Securities) yields is 3/4 percentage point lower.5 Survey-based measures of inflation expectations are also lower. The Michigan survey measure of median household expectations of inflation over the next five to 10 years suggests a 1/4 percentage point downward shift over the most recent three-year period compared with the pre-crisis years, similar to the five-year, five-year forward forecast for the consumer price index from the Survey of Professional Forecasters.\n\nWhy might underlying inflation expectations have moved down since the financial crisis? One simple explanation may be the experience of persistently low inflation: Households and firms have experienced a prolonged period of inflation below our objective, and that may be affecting their perception of underlying inflation. A related explanation may be the greater proximity of the federal funds rate to its effective lower bound due to a lower neutral rate of interest.6 By constraining the amount of policy space available to offset adverse developments using our more effective conventional tools, the low neutral rate could increase the likely frequency of periods of below-trend inflation. In short, frequent or extended periods of low inflation run the risk of pulling down private-sector inflation expectations.7\n\nGiven today's circumstances, with the economy near full employment and inflation below target, how should the FOMC achieve its dual-mandate goals? Some might determine that preemptive tightening is appropriate on the grounds that monetary policy operates with long lags, and inflation will inevitably accelerate as the labor market continues to tighten because of the Phillips curve. However, in today's economy, there are reasons to worry that the Phillips curve will not prove very reliable in boosting inflation as resource utilization tightens. Since 2012, inflation has tended to change relatively little as the unemployment rate has fallen considerably, from 8.2 percent to 4.4 percent.8 In short, the Phillips curve appears to be flatter today than it was previously.9 This is also apparent in a number of advanced foreign economies, where declines in their unemployment rates to relatively low levels have failed to generate significant upward pressures on inflation.10 Given the flatness of the Phillips curve, it could take a considerable undershooting of the natural rate of unemployment to achieve our inflation objective if we were to rely on resource utilization alone.\n\nFor all these reasons, achieving our inflation target on a sustainable basis is likely to require a firming in longer-run inflation expectations--that is, the underlying trend. The key question in my mind is how to achieve an improvement in longer-run inflation expectations to a level that will allow us to achieve our inflation objective. The persistent failure to meet our inflation objective should push us to think broadly about diagnoses and solutions.\n\nThe academic literature on monetary policy suggests a variety of prescriptions for preventing a lower neutral rate of interest from eroding longer-run inflation expectations.11 One feature that is common to many proposals is that the persistence of the shortfall in inflation from our objective should be one of the considerations in setting monetary policy. Most immediately, we should assess inflation developments closely before making a determination on further adjustments to the federal funds rate.\n\nMonetary Policy\nThis brings me to the implications for monetary policy. A key upcoming decision for the Committee is when to commence balance sheet normalization. I consider normalization of the federal funds rate to be well under way, the criterion for commencing balance sheet normalization. The approaching change to our reinvestment policy has been clearly communicated and is well anticipated.\n\nIn principle, the FOMC could use both the balance sheet and the federal funds rate as active tools for setting monetary policy. However, I view the federal funds rate as the preferred active tool, because its effect on financial conditions and the economy has been more extensively tested and therefore is better understood than changes to the balance sheet. As a result, once we set in motion the change in balance sheet policy, as long as the economy evolves broadly as expected, we should allow the balance sheet to run off in the background at the gradual pace that was announced. We would primarily look to ongoing adjustments in the federal funds rate to calibrate the stance of monetary policy as economic conditions evolve.\n\nOnce balance sheet normalization is under way, I will be looking closely at the evolution of inflation before making a determination about further adjustments to the federal funds rate. We have been falling short of our inflation objective not just in the past year, but over a longer period as well. My own view is that we should be cautious about tightening policy further until we are confident inflation is on track to achieve our target.\n\nUnless we expect inflation to move quickly back toward target--or there are indications that the short-run neutral rate has moved up further--a variety of empirical estimates suggest we could approach neutral without too many additional rate increases. Many forecasters assume that the neutral rate of interest is very low currently, and that it is likely to be low relative to historical norms in the longer run.12 For example, the well-known Laubach-Williams model currently suggests an estimate of the longer-run neutral federal funds rate that is actually slightly below zero.13 And in the most recent Summary of Economic Projections (SEP), the median longer-run nominal federal funds rate was 3 percent, which implies the long-run real federal funds rate would only be 1 percent, lower than its average in the decades before then of around 2-1/2 percent.14\n\nThese estimates suggest that the neutral rate of interest is likely to rise only modestly in the medium term. It is worth remembering, in addition, that the Federal Reserve's balance sheet policy may be reinforcing this tendency over the next several years. A recent study suggests balance sheet runoff could boost the level of the term premium on the 10-year Treasury yield by about 40 basis points over the first few years.15 Typical rules of thumb suggest that such an increase in term premiums would imply a decrease in the short-run neutral rate of interest.\n\nAlthough the FOMC expects to begin normalizing its balance sheet relatively soon, several foreign central banks are continuing their purchases of longer-term assets in their own currencies.16 Because longer-term government securities in the major economies are close substitutes, the ongoing balance sheet programs of some foreign central banks will likely continue to hold down U.S. longer-term interest rates. But with economies abroad strengthening, it may not be too long before some foreign central banks will end their net purchases and, eventually, begin reducing their balance sheets. As that happens, the current downward pressure on longer-term interest rates from foreign spillovers will abate.\n\nFor these reasons, my current expectation is that the short-run neutral rate of interest may not rise much over the medium term. But this is an open question and bears close monitoring. Of course, it is entirely possible that other factors will be working to offset this downward pressure on the equilibrium funds rate--as could be the case, for instance, if fiscal stimulus is greater than many observers currently expect.\n\nTo the extent that the neutral rate remains low relative to its historical value, there is a high premium on guiding inflation back up to target so as to retain space to buffer adverse shocks with conventional policy. In this regard, I believe it is important to be clear that we would be comfortable with inflation moving modestly above our target for a time. In my view, this is the clear implication of the symmetric language in the Committee's Statement on Longer-Run Goals and Monetary Policy Strategy.\n\nBefore concluding, it is worth considering the possible implications of a sustained period of low neutral rates and low unemployment for financial imbalances. Historically, extended periods with very low unemployment rates tend to be associated with below-average spreads of expected returns on risky assets over safe interest rates--low bond risk premiums, for example, or low equity premiums. Although, to some extent, low risk premiums and rising asset valuations may be consistent with strong economic fundamentals, such as low default rates and strong corporate earnings, there have also been episodes when a very strong economy and low unemployment rate have led to overvaluation of asset prices, underpricing of risk, and growing financial imbalances.\n\nThus, in today's environment, it is important to be vigilant to the signs that asset valuations appear to be elevated, especially in areas such as commercial real estate and corporate bonds, as well as the exceptionally low levels of expected volatility. Nonetheless, there are few signs of a dangerous buildup of leverage or of maturity transformation, which have traditionally been important contributors to financial instability. This is due, in no small measure, to the improvements in capital, liquidity, and risk management made by the financial institutions at the core of the system, which are associated with post-crisis financial reforms, as well as money market reform and the greater transparency in the derivatives markets.\n\nTo conclude, much depends on the evolution of inflation. If, as many forecasters assume, the current shortfall of inflation from our 2 percent objective indeed proves transitory, further gradual increases in the federal funds rate would be warranted, perhaps along the lines of the median projection from the most recent SEP. But, as I noted earlier, I am concerned that the recent low readings for inflation may be driven by depressed underlying inflation, which would imply a more persistent shortfall in inflation from our objective. In that case, it would be prudent to raise the federal funds rate more gradually. We should have substantially more data in hand in the coming months that will help us make that assessment.\n\nReferences\nBlanchard, Olivier (2016). \"The U.S. Phillips Curve: Back to the 60s?\" Policy Brief PB16‑1. Washington: Peterson Institute for International Economics, January, https://piie.com/publications/pb/pb16-1.pdf.\n\nBonis, Brian, Jane Ihrig, and Min Wei (2017). \"The Effect of the Federal Reserve's Securities Holdings on Longer-Term Interest Rates,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, April 20.\n\nBrainard, Lael (2015). \"Normalizing Monetary Policy When the Neutral Interest Rate Is Low,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford, California, Dec. 1.\n\n-------- (2016). \"The \"New Normal\" and What it Means for Monetary Policy,\" speech delivered at the Chicago Council on Foreign Affairs, Chicago, Ill., September 12.\n\n-------- (2017). \"Cross-Border Spillovers of Balance Sheet Normalization,\" speech delivered at the National Bureau of Economic Research's Monetary Economics Summer Institute, Cambridge, Mass., July 13.\n\nCecchetti, Stephen G., Michael E. Feroli, Peter Hooper, Anil K. Kashyap, and Kermit L. Schoenholtz (2017). Deflating Inflation Expectations: The Implications of Inflation's Simple Dynamics (PDF), report prepared for the 2017 U.S. Monetary Policy Forum, sponsored by the Initiative on Global Markets at the University of Chicago's Booth School of Business, held in New York, N.Y., on March 3.\n\nInternational Monetary Fund (IMF, 2013). \"The Dog that Didn't Bark: Has Inflation Been Muzzled or Is It Just Sleeping (PDF),\" in World Economic Outlook April 2013: Hopes Realities, and Risks. Washington: International Monetary Fund.\n\nKiley, Michael T. (2015). \"Low Inflation in the United States: A Summary of Recent Research,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, November 23.\n\nKiley, Michael T., and John M. Roberts (2017). \"Monetary Policy in a Low Interest Rate World (PDF),\" Finance and Economics Discussion Series 2017-080. Washington: Board of Governors of the Federal Reserve System, August.\n\nNakata, Taisuke, and Sebastian Schmidt (2016). \"The Risk-Adjusted Monetary Policy Rule (PDF),\" Finance and Economics Discussion Series 2016-061. Washington: Board of Governors of the Federal Reserve System, July.\n\nStock, James H., and Mark W. Watson (2007). \"Why Has U.S. Inflation Become Harder to Forecast?\" Journal of Money, Credit and Banking, vol. 39 (s1, February), pp. 3-33, available at https://scholar.harvard.edu/stock/publications/why-has-inflation-become-harder-forecast.\n\n1. I am grateful to John Roberts for his assistance in preparing this text. The remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See Brainard (2017) for a fuller discussion of this topic. Return to text\n\n3. According to Congressional Budget Office estimates, the natural rate of unemployment was about the same in the two periods: It was 4.8 percent in the 2014-17 period and 5.0 percent a decade earlier. Return to text\n\n4. Stock and Watson (2007) introduced an estimate of trend inflation that assumed time-varying volatility. Cecchetti and others (2017) provided a recent update of that model; their estimate of trend inflation for core PCE prices has been about 1-1/2 percent in the past few years, compared with readings above 2 percent in the 2006-08 period (see figure 4.1, p. 23). Return to text\n\n5. Of course, inflation compensation isn't a straight read on inflation expectations, as liquidity and term premiums can affect it. Still, inflation suggests a notable downward shift in expectations. Return to text\n\n6. See Brainard (2016) for a fuller discussion of this topic. Return to text\n\n7. See, for example, Kiley and Roberts (2017) and Nakata and Schmidt (2016). Return to text\n\n8. The inflation information refers to core PCE inflation measured on a 12-month average basis. Return to text\n\n9. Similarly, inflation did not fall very much as the unemployment rate climbed to 10 percent during the Great Recession. See Blanchard (2016), Kiley (2015), and Brainard (2015). Return to text\n\n10. See IMF (2013). Return to text\n\n11. See, for example, Kiley and Roberts (2017). Return to text\n\n12. See, for example, the July 2017 Survey of Market Participants (PDF) from the Federal Reserve Bank of New York. Return to text\n\n13. Latest estimates from the Laubach-Williams model are available at http://www.frbsf.org/economic-research/files/Laubach_Williams_updated_estimates.xlsx. Return to text\n\n14. Over the 1960-2007 period, the real federal funds rate--measured as the nominal federal funds rate less trailing four-quarter core PCE inflation--averaged 2-1/2 percent. Return to text\n\n15. Bonis, Ihrig, and Wei (2017). Return to text\n\n16. For more information, see Board of Governors of the Federal Reserve System (2017), \"Federal Reserve Issues FOMC statement,\" press release, July 26. Return to text"
    },
    {
        "title": "The Role of Boards at Large Financial Firms",
        "date": "August 30, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170830a.htm",
        "content": "August 30, 2017\n\nGovernor Jerome H. Powell\n\nAt the Large Bank Directors Conference, Chicago, Illinois\n\nGood morning. Thank you to President Evans for inviting me to speak here today about the role of boards of directors of large banking firms.1 Ten years ago this month, the world witnessed the first tremors of what we now think of as the Global Financial Crisis and the subsequent Great Recession. For the United States and many other countries, this would turn out to be the most painful economic period since the Great Depression.\n\nIn the wake of the crisis, governments around the world instituted a wide range of reforms that were designed to reduce the likelihood and severity of a recurrence. In the United States, the core elements of those reforms included significantly higher capital standards; new liquidity requirements; forward-looking stress tests; and resolution planning. Our largest banking firms are without question much stronger than before the crisis. We are nearing completion of the major parts of this reform program, and are undertaking a thorough review to help assure that the reforms we put in place are both effective and efficient.2\n\nDuring the crisis, some large banking firms incurred massive losses. Some of these losses were from products--such as super-senior collateralized debt obligations (CDOs) or structured investment vehicles (SIVs)--whose risks were not even on the radar screen of the firm's board of directors. After the crisis, the Federal Reserve significantly raised our expectations for the boards of directors of large banking firms. Taking risk in service of clients is an essential part of the business of banking, including credit risk, interest rate risk, and various forms of operational risk. Our reforms were designed to assure that boards of directors understand and approve the strategy of the company and the risks inherent in that strategy, and that the institution has the capital, liquidity, and risk management capabilities necessary to manage those risks.\n\nToday, the role of a director of a large banking firm is more expansive, more challenging, and more important than ever. Boards now oversee management's participation in highly challenging annual exercises, such as stress testing, capital planning, and resolution planning, that have fundamentally changed the business of our largest institutions. Boards now more carefully evaluate the compensation practices of these large institutions to assure that they reinforce positive incentives and discourage unwanted risk taking. Across a range of responsibilities, we simply expect much more of boards of directors than ever before. There is no reason to expect that to change.\n\nWe do take seriously our obligation to assess whether our reforms are achieving their desired effects, without imposing unnecessary burden. In 2014, we began a review of these higher expectations for directors. We found that many boards have significantly improved their practices. We also found some ways to make our reforms both more effective and more efficient. For example, while directors generally say that they understand and embrace their more challenging responsibilities, we consistently hear that directors feel buried in hundreds or even thousands of pages of highly granular information, to the point where more important strategic issues are crowded out of board deliberations. Some of this granular information was likely driven by our supervisory guidance, which included specific expectations not only for the management of the institution, but also for the board of directors. Over time, this guidance has increased the number of specific directives aimed at boards well into the hundreds, which may have fostered a \"check-the-box\" approach by boards.\n\nThere is also a widespread feeling that our supervision seems to have downplayed the difference in roles between boards and management. Our current ratings system for bank holding companies, which for large banking firms would be replaced by the currently proposed LFI ratings system, refers to the \"board and senior management\" as a subcomponent rating of risk management.3 We have also combined the roles of the board and senior management in many of our supervisory feedback letters.\n\nAfter careful consideration, last month we proposed a new framework for our oversight of boards.4 In formulating this proposal, we had discussions with academics, consultants, legal practitioners, and directors of banking firms.\n\nLet me start by saying what the new approach will not do. We do not intend that these reforms will lower the bar for boards or lighten the loads of directors. The new approach distinguishes the board from senior management so that we can spotlight our expectations of effective boards. The intent is to enable directors to spend less board time on routine matters and more on core board responsibilities: overseeing management as they devise a clear and coherent direction for the firm, holding management accountable for the execution of that strategy, and ensuring the independence and stature of the risk management and internal audit functions. These were all areas that were found wanting in the financial crisis, and it is essential that boards get these fundamentals right.\n\nOur new proposal will move to a principles-based approach. We have identified five common attributes that effective boards should exhibit, and for which we will have high expectations. This principles-based approach recognizes that large firms have a broad range of business models, structures, and practices. While we want to be clear about our expectations, we also want to give directors the flexibility to meet them in a manner that works for their particular boards.\n\nFirst, an effective board should guide the development of a clear and coherent strategy for the firm and set the types and levels of risks it is willing to take. Alignment of business strategy and risk appetite should minimize the firm's exposure to large and unexpected losses. In addition, the firm's risk management capabilities need to be commensurate with the risks it expects to take.\n\nSecond, an effective board should actively manage its information flow and deliberations, so that the board can make sound, well-informed decisions that take into account risks and opportunities.\n\nThird, an effective board should hold senior management accountable for implementing the firm's strategy and risk appetite and maintaining the firm's risk management and control framework.\n\nFourth, an effective board should ensure the independence and stature of the independent risk management and internal audit functions. It is difficult to overstate the importance of this. Risk management systems and controls may discourage or limit certain revenue-generating opportunities. Failure to ensure the independence of these functions from the revenue generators and risk takers has been shown to be dangerous, and this is something for which the board is accountable.\n\nFinally, an effective board should have a composition, governance structure, and set of established practices that are appropriate in light of the firm's size, complexity, scope of operations, and risk profile. Boards need to be aware of their own strengths and weaknesses, and to ensure that directors bring an appropriately diverse range of skills, knowledge, experience, and perspective. Significant events, such as an unexpected loss or compliance failure, should cause boards to reflect and reassess their structure, composition, and processes. An effective board takes a preventative approach and engages in probing self-assessments regularly and systematically.\n\nBefore I conclude, let me say a few words about an aspect of the proposal that has attracted some attention, which is the reversal of a relatively recent practice of directing all examination and inspection findings--what we call \"matters requiring attention\" (MRAs) and \"matters requiring immediate attention\" (MRIAs)--to the board as well as to management.5 The practice resulted in boards of directors reviewing and signing off on management's compliance with every MRA and MRIA. When we began that practice in 2013, our intention was to ensure that directors were in a position to hold management accountable in addressing risk management shortcomings. By 2014, we realized that the practice was \"almost surely distracting from strategic and risk-related analyses and oversight by boards\".6 For perspective, a large banking firm may have one hundred or more MRAs outstanding at a given time, many of which are at a level of granularity that is more appropriate for management to remediate, with board oversight. The new proposed framework is designed to make boards more effective in holding management accountable in these efforts. While we have proposed that most MRAs and MRIAs be addressed in the first instance to management and not to the board, the board would continue to receive MRAs where board practices are at issue or where management has failed to promptly and adequately take the required actions. The board would also continue to receive copies of examination and inspection reports, including formal communications with the institution. In the parlance of the proposed guidance I just outlined, we fully expect the board to actively manage the information flow related to MRAs and to hold management accountable for remediating them. In doing so, a board may choose to track progress and closure of MRAs through an appropriate board committee, rather than getting into the granular detail on every individual MRA.\n\nConclusion\nWe need financial institutions that are strong enough to support economic growth by lending through the economic cycle. To achieve that goal, we need strong and effective boards of directors at firms of all sizes. A strong and effective board provides strategic leadership and oversight, which is much more challenging and important than checking off lists of assigned tasks. I look forward to our continuing dialogue on this subject today and in the months to come, and reviewing carefully the comments received on the proposal.\n\n1. The views I express here are my own and not necessarily those of the Board of Governors of the Federal Reserve System. Return to text\n\n2. Jerome H. Powell, \"Relationship Between Regulation and Economic Growth,\" (testimony before the Committee on Banking, Housing, and Urban Affairs, U.S. Senate, June 22, 2017). Return to text\n\n3. See SR letter 04-18, \"Bank Holding Company Rating System,\" 69 FR 70444 (December 6, 2004). Return to text\n\n4. See www.federalreserve.gov/newsevents/pressreleases/bcreg20170803a.htm. Return to text\n\n5. MRIAs are matters of significant importance and urgency that the Federal Reserve requires banking organizations to address immediately and include, for example, matters that have the potential to pose significant risk to the safety and soundness of the banking organization, matters that represent significant noncompliance with applicable laws or regulations and repeat criticisms that have escalated in importance due to insufficient attention or inaction by the banking organization. MRAs, on the other hand, are matters that are important and that the Federal Reserve is expecting a banking organization to address over a reasonable period of time, but when the timing need not be \"immediate.\" See Supervision and Regulation (SR) letter 13-13/Consumer Affairs letter 13-10, \"Supervisory Considerations for the Communication of Supervisory Findings.\" Return to text\n\n6. See \"Corporate Governance and Prudential Regulation,\" remarks by Governor Daniel J. Tarullo at Association of American Law Schools Midyear Meeting, June 9, 2014. (\"We should probably be somewhat more selective in creating the regulatory checklist for board compliance and regular consideration. One example, drawn from Federal Reserve practice, is the recent supervisory guidance requiring that every notice of a \"Matter Requiring Attention\" (MRA) issued by supervisors must be reviewed, and compliance signed off, by the board of directors. There are some MRAs that clearly should come to the board's attention, but the failure to discriminate among them is almost surely distracting from strategic and risk-related analyses and oversight by boards.\") Return to text"
    },
    {
        "title": "Financial Stability a Decade after the Onset of the Crisis",
        "date": "August 25, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20170825a.htm",
        "content": "August 25, 2017\n\nChair Janet L. Yellen\n\nAt \"Fostering a Dynamic Global Recovery,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, Jackson Hole, Wyoming\n\nA decade has passed since the beginnings of a global financial crisis that resulted in the most severe financial panic and largest contraction in economic activity in the United States since the Great Depression. Already, for some, memories of this experience may be fading--memories of just how costly the financial crisis was and of why certain steps were taken in response. Today I will look back at the crisis and discuss the reforms policymakers in the United States and around the world have made to improve financial regulation to limit both the probability and the adverse consequences of future financial crises.\n\nA resilient financial system is critical to a dynamic global economy--the subject of this conference. A well-functioning financial system facilitates productive investment and new business formation and helps new and existing businesses weather the ups and downs of the business cycle. Prudent borrowing enables households to improve their standard of living by purchasing a home, investing in education, or starting a business. Because of the reforms that strengthened our financial system, and with support from monetary and other policies, credit is available on good terms, and lending has advanced broadly in line with economic activity in recent years, contributing to today's strong economy.1\n\nAt the same time, reforms have boosted the resilience of the financial system. Banks are safer. The risk of runs owing to maturity transformation is reduced. Efforts to enhance the resolvability of systemic firms have promoted market discipline and reduced the problem of too-big-to-fail. And a system is in place to more effectively monitor and address risks that arise outside the regulatory perimeter.\n\nNonetheless, the scope and complexity of financial regulatory reforms demand that policymakers and researchers remain alert to both areas for improvement and unexpected side effects. The Federal Reserve is committed to continuing to evaluate the effects of regulation on financial stability and on the broader economy and to making appropriate adjustments.\n\nI will start by reviewing where we were 10 years ago. I will then walk through some key reforms our country has put in place to diminish the chances of another severe crisis and limit damage during times of financial instability. After reviewing these steps, I will summarize indicators and research that show the improved resilience of the U.S. financial system--resilience that is due importantly to regulatory reform as well as actions taken by the private sector. I will then turn to the evidence regarding how financial regulatory reform has affected economic growth, credit availability, and market liquidity.\n\nDevelopments 10 Years Ago\nThe U.S. and global financial system was in a dangerous place 10 years ago. U.S. house prices had peaked in 2006, and strains in the subprime mortgage market grew acute over the first half of 2007.2 By August, liquidity in money markets had deteriorated enough to require the Federal Reserve to take steps to support it.3 And yet the discussion here at Jackson Hole in August 2007, with a few notable exceptions, was fairly optimistic about the possible economic fallout from the stresses apparent in the financial system.4\n\nAs we now know, the deterioration of liquidity and solvency within the financial sector continued over the next 13 months. Accumulating strains across the financial system, including the collapse of Bear Stearns in March 2008, made it clear that vulnerabilities had risen across the system. As a result, policymakers took extraordinary measures: The Federal Open Market Committee (FOMC) sharply cut the federal funds rate, and the Federal Reserve, in coordination with the Treasury Department and other agencies, extended liquidity facilities beyond the traditional banking sector, applying to the modern structure of U.S. money markets the dictum of Walter Bagehot, conceived in the 19th century, to lend freely against good collateral at a penalty rate.5 Still, the deterioration in the financial sector continued, with Fannie Mae and Freddie Mac failing in early September.6\n\nBut the deterioration from early 2007 until early September 2008‑‑already the worst financial disruption in the United States in many decades‑‑was a slow trickle compared with the tidal wave that nearly wiped out the financial sector that September and led to a plunge in economic activity in the following months­. Not long after Fannie and Freddie were placed in government conservatorship, Lehman Brothers collapsed, setting off a week in which American International Group, Inc. (AIG), came to the brink of failure and required large loans from the Federal Reserve to mitigate the systemic fallout; a large money market fund \"broke the buck\" (that is, was unable to maintain a net asset value of $1 per share) and runs on other money funds accelerated, requiring the Treasury to provide a guarantee of money fund liabilities; global dollar funding markets nearly collapsed, necessitating coordinated action by central banks around the world; the two remaining large investment banks became bank holding companies, thereby ending the era of large independent investment banks in the United States; and the Treasury proposed a rescue of the financial sector. Within several weeks, the Congress passed--and President Bush signed into law--the Emergency Economic Stabilization Act of 2008, which established the $700 billion Troubled Asset Relief Program; the Federal Reserve initiated further emergency lending programs; and the Federal Deposit Insurance Corporation (FDIC) guaranteed a broad range of bank debt.7 Facing similar challenges in their own jurisdictions, many foreign governments also undertook aggressive measures to support the functioning of credit markets, including large-scale capital injections into banks, expansions of deposit insurance programs, and guarantees of some forms of bank debt.\n\nDespite the forceful policy responses by the Treasury, the Congress, the FDIC, and the Federal Reserve as well as authorities abroad, the crisis continued to intensify: The vulnerabilities in the U.S. and global economies had grown too large, and the subsequent damage was enormous. From the beginning of 2008 to early 2010, nearly 9 million jobs, on net, were lost in the United States. Millions of Americans lost their homes. And distress was not limited to the U.S. economy: Global trade and economic activity contracted to a degree that had not been seen since the 1930s. The economic recovery that followed, despite extraordinary policy actions, was painfully slow.\n\nWhat the Crisis Revealed and How Policymakers Have Responded\nThese painful events renewed efforts to guard against financial instability. The Congress, the Administration, and regulatory agencies implemented new laws, regulations, and supervisory practices to limit the risk of another crisis, in coordination with policymakers around the world.\n\nThe vulnerabilities within the financial system in the mid-2000s were numerous and, in hindsight, familiar from past financial panics. Financial institutions had assumed too much risk, especially related to the housing market, through mortgage lending standards that were far too lax and contributed to substantial overborrowing. Repeating a familiar pattern, the \"madness of crowds\" had contributed to a bubble, in which investors and households expected rapid appreciation in house prices. The long period of economic stability beginning in the 1980s had led to complacency about potential risks, and the buildup of risk was not widely recognized.8 As a result, market and supervisory discipline was lacking, and financial institutions were allowed to take on high levels of leverage. This leverage was facilitated by short-term wholesale borrowing, owing in part to market-based vehicles, such as money market mutual funds and asset-backed commercial paper programs that allowed the rapid expansion of liquidity transformation outside of the regulated depository sector. Finally, a self-reinforcing loop developed, in which all of the factors I have just cited intensified as investors sought ways to gain exposure to the rising prices of assets linked to housing and the financial sector. As a result, securitization and the development of complex derivatives products distributed risk across institutions in ways that were opaque and ultimately destabilizing.\n\nIn response, policymakers around the world have put in place measures to limit a future buildup of similar vulnerabilities. The United States, through coordinated regulatory action and legislation, moved very rapidly to begin reforming our financial system, and the speed with which our banking system returned to health provides evidence of the effectiveness of that strategy. Moreover, U.S. leadership of global efforts through bodies such as the Basel Committee on Banking Supervision, the Financial Stability Board (FSB), and the Group of Twenty has contributed to the development of standards that promote financial stability around the world, thereby supporting global growth while protecting the U.S. financial system from adverse developments abroad. Preeminent among these domestic and global efforts have been steps to increase the loss-absorbing capacity of banks, regulations to limit both maturity transformation in short-term funding markets and liquidity mismatches within banks, and new authorities to facilitate the resolution of large financial institutions and to subject systemically important firms to more stringent prudential regulation.\n\nSeveral important reforms have increased the loss-absorbing capacity of global banks. First, the quantity and quality of capital required relative to risk-weighted assets have been increased substantially.9 In addition, a simple leverage ratio provides a backstop, reflecting the lesson imparted by past crises that risk weights are imperfect and a minimum amount of equity capital should fund a firm's total assets. Moreover, both the risk-weighted and simple leverage requirements are higher for the largest, most systemic firms, which lowers the risk of distress at such firms and encourages them to limit activities that could threaten financial stability.10 Finally, the largest U.S. banks participate in the annual Comprehensive Capital Analysis and Review (CCAR)‑‑the stress tests. In addition to contributing to greater loss-absorbing capacity, the CCAR improves public understanding of risks at large banking firms, provides a forward-looking examination of firms' potential losses during severely adverse economic conditions, and has contributed to significant improvements in risk management.\n\nReforms have also addressed the risks associated with maturity transformation. The fragility created by deposit-like liabilities outside the traditional banking sector has been mitigated by regulations promulgated by the Securities and Exchange Commission affecting prime institutional money market funds. These rules require these prime funds to use a floating net asset value, among other changes, a shift that has made these funds less attractive as cash-management vehicles. The changes at money funds have also helped reduce banks' reliance on unsecured short-term wholesale funding, since prime institutional funds were significant investors in those bank liabilities. Liquidity risk at large banks has been further mitigated by a new liquidity coverage ratio and a capital surcharge for global systemically important banks (G-SIBs). The liquidity coverage ratio requires that banks hold liquid assets to cover potential net cash outflows over a 30-day stress period. The capital surcharge for U.S. G-SIBs links the required level of capital for the largest banks to their reliance on short-term wholesale funding.11\n\nWhile improvements in capital and liquidity regulation will limit the reemergence of the risks that grew substantially in the mid-2000s, the failure of Lehman Brothers demonstrated how the absence of an adequate resolution process for dealing with a failing systemic firm left policymakers with only the terrible choices of a bailout or allowing a destabilizing collapse. In recognition of this shortcoming, the Congress adopted the orderly liquidation authority in Title II of the Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank Act) to provide an alternative resolution mechanism for systemically important firms to be used instead of bankruptcy proceedings when necessary to preserve financial stability. The orderly liquidation authority contains a number of tools, including liquidity resources and temporary stays on the termination of financial contracts, that would help protect the financial system and economy from the severe adverse spillovers that could occur if a systemic firm failed. Importantly, any losses incurred by the government in an Orderly Liquidation Authority resolution would not be at the expense of taxpayers, since the statute provides that all such losses must be borne by other large financial firms through subsequent assessments. In addition, the Congress required that the largest banks submit living wills that describe how they could be resolved under bankruptcy.12 And the Federal Reserve has mandated that systemically important banks meet total loss-absorbing capacity requirements, which require these firms to maintain long-term debt adequate to absorb losses and recapitalize the firm in resolution. These enhancements in resolvability protect financial stability and help ensure that the shareholders and creditors of failing firms bear losses. Moreover, these steps promote market discipline, as creditors--knowing full well that they will bear losses in the event of distress--demand prudent risk-taking, thereby limiting the problem of too-big-to-fail.\n\nFinancial stability risks can also grow large outside the regulated banking sector, as amply demonstrated by the events of 2007 and 2008. In response, a number of regulatory changes affecting what is commonly referred to as the shadow banking sector have been instituted. A specific example of such risks, illustrative of broader developments, was the buildup of large counterparty exposures through derivatives between market participants and AIG that were both inappropriately risk-managed and opaque. To mitigate the potential for such risks to arise again, new standards require central clearing of standardized over-the-counter derivatives, enhanced reporting requirements for all derivatives, and higher capital as well as margin requirements for noncentrally cleared derivatives transactions.13\n\nAnother important step was the Congress's creation of the Financial Stability Oversight Council (FSOC). The council is responsible for identifying risks to financial stability and for designating those financial institutions that are systemically important and thus subject to prudential regulation by the Federal Reserve. Both of these responsibilities are important to help guard against the risk that vulnerabilities outside the existing regulatory perimeter grow to levels that jeopardize financial stability.14\n\nThe Financial System Is Safer\nThe evidence shows that reforms since the crisis have made the financial system substantially safer. Loss-absorbing capacity among the largest banks is significantly higher, with Tier 1 common equity capital more than doubling from early 2009 to now.15 The annual stress-testing exercises in recent years have led to improvements in the capital positions and risk-management processes among participating banks. Large banks have cut their reliance on short-term wholesale funding essentially in half and hold significantly more high-quality, liquid assets. Assets under management at prime institutional money market funds that proved susceptible to runs in the crisis have decreased substantially. And the ability of regulators to resolve a large institution has improved, reflecting both new authorities and tangible steps taken by institutions to adjust their organizational and capital structure in a manner that enhances their resolvability and significantly reduces the problem of too-big-to-fail.\n\nThe progress evident in regulatory and supervisory metrics has been accompanied by shifts in private-sector assessments that also suggest enhanced financial stability. Investors have recognized the progress achieved toward ending too-big-to-fail, and several rating agencies have removed the government support rating uplift that they once accorded to the largest banks. Credit default swaps for the large banks also suggest that market participants assign a low probability to the distress of a large U.S. banking firm. Market-based assessments of the loss-absorbing capacity of large U.S. banks have moved up in recent years, and market-based measures of equity now lie in the range of book estimates of equity. To be sure, market-based measures may not reflect true risks--they certainly did not in the mid-2000s--and hence the observed improvements should not be overemphasized.16 But supervisory metrics are not perfect, either, and policymakers and investors should continue to monitor a range of supervisory and market-based indicators of financial system resilience.\n\nEconomic research provides further support for the notion that reforms have made the system safer. Studies have demonstrated that higher levels of bank capital mitigate the risk and adverse effects of financial crises.17 Moreover, researchers have highlighted how liquidity regulation supports financial stability by complementing capital regulation.18 Economic models of the resilience of the financial sector--so called top-down stress-testing models--reinforce the message from supervisory stress tests that the riskiness of large banks has diminished over the past decade.19 Similarly, model-based analyses indicate that the risk of adverse fire sale spillovers across banks or broker-dealers have been substantially mitigated.20\n\nIs This Safer System Supporting Growth?\nI suspect many in this audience would agree with the narrative of my remarks so far: The events of the crisis demanded action, needed reforms were implemented, and these reforms have made the system safer. Now--a decade from the onset of the crisis and nearly seven years since the passage of the Dodd-Frank Act and international agreement on the key banking reforms--a new question is being asked: Have reforms gone too far, resulting in a financial system that is too burdened to support prudent risk-taking and economic growth?\n\nThe Federal Reserve is committed individually, and in coordination with other U.S. government agencies through forums such as the FSOC and internationally through bodies such as the Basel Committee on Banking Supervision and the FSB, to evaluating the effects of financial market regulations and considering appropriate adjustments. Furthermore, the Federal Reserve has independently taken steps to evaluate potential adjustments to its regulatory and supervisory practices. For example, the Federal Reserve initiated a review of its stress tests following the 2015 cycle, and this review suggested changes to reduce the burden on participating institutions, especially smaller institutions, and to better align the supervisory stress tests with regulatory capital requirements.21 In addition, a broader set of changes to the new financial regulatory framework may deserve consideration. Such changes include adjustments that may simplify regulations applying to small and medium-sized banks and enhance resolution planning.22\n\nMore broadly, we continue to monitor economic conditions, and to review and conduct research, to better understand the effect of regulatory reforms and possible implications for regulation. I will briefly summarize the current state of play in two areas: the effect of regulation on credit availability and on changes in market liquidity.\n\nThe effects of capital regulation on credit availability have been investigated extensively. Some studies suggest that higher capital weighs on banks' lending, while others suggest that higher capital supports lending.23 Such conflicting results in academic research are not altogether surprising. It is difficult to identify the effects of regulatory capital requirements on lending because material changes to capital requirements are rare and are often precipitated, as in the recent case, by financial crises that also have large effects on lending.\n\nGiven the uncertainty regarding the effect of capital regulation on lending, rulemakings of the Federal Reserve and other agencies were informed by analyses that balanced the possible stability gains from greater loss-absorbing capacity against the possible adverse effects on lending and economic growth.24 This ex ante assessment pointed to sizable net benefits to economic growth from higher capital standards--and subsequent research supports this assessment.25 The steps to improve the capital positions of banks promptly and significantly following the crisis, beginning with the 2009 Supervisory Capital Assessment Program, have resulted in a return of lending growth and profitability among U.S. banks more quickly than among their global peers.\n\nWhile material adverse effects of capital regulation on broad measures of lending are not readily apparent, credit may be less available to some borrowers, especially homebuyers with less-than-perfect credit histories and, perhaps, small businesses. In retrospect, mortgage borrowing was clearly too easy for some households in the mid-2000s, resulting in debt burdens that were unsustainable and ultimately damaging to the financial system. Currently, many factors are likely affecting mortgage lending, including changes in market perceptions of the risk associated with mortgage lending; changes in practices at the government-sponsored enterprises and the Federal Housing Administration; changes in technology that may be contributing to entry by nonbank lenders; changes in consumer protection regulations; and, perhaps to a limited degree, changes in capital and liquidity regulations within the banking sector. These issues are complex and interact with a broader set of challenges related to the domestic housing finance system.\n\nCredit appears broadly available to small businesses with solid credit histories, although indicators point to some difficulties facing firms with weak credit scores and insufficient credit histories.26 Small business formation is critical to economic dynamism and growth. Smaller firms rely disproportionately on lending from smaller banks, and the Federal Reserve has been taking steps and examining additional steps to reduce unnecessary complexity in regulations affecting smaller banks.27\n\nFinally, many financial market participants have expressed concerns about the ability to transact in volume at low cost--that is, about market liquidity, particularly in certain fixed-income markets such as that for corporate bonds. Market liquidity for corporate bonds remains robust overall, and the healthy condition of the market is apparent in low bid-ask spreads and the large volume of corporate bond issuance in recent years. That said, liquidity conditions are clearly evolving. Large dealers appear to devote less of their balance sheets to holding inventories of securities to facilitate trades and instead increasingly facilitate trades by directly matching buyers and sellers. In addition, algorithmic traders and institutional investors are a larger presence in various markets than previously, and the willingness of these institutions to support liquidity in stressful conditions is uncertain. While no single factor appears to be the predominant cause of the evolution of market liquidity, some regulations may be affecting market liquidity somewhat. There may be benefits to simplifying aspects of the Volcker rule, which limits proprietary trading by banking firms, and to reviewing the interaction of the enhanced supplementary leverage ratio with risk-based capital requirements. At the same time, the new regulatory framework overall has made dealers more resilient to shocks, and, in the past, distress at dealers following adverse shocks has been an important factor driving market illiquidity. As a result, any adjustments to the regulatory framework should be modest and preserve the increase in resilience at large dealers and banks associated with the reforms put in place in recent years.\n\nRemaining Challenges\nSo where do we stand a decade after the onset of the most severe financial crisis since the Great Depression? Substantial progress has been made toward the Federal Reserve's economic objectives of maximum employment and price stability, in putting in place a regulatory and supervisory structure that is well designed to lower the risks to financial stability, and in actually achieving a stronger financial system. Our more resilient financial system is better prepared to absorb, rather than amplify, adverse shocks, as has been illustrated during periods of market turbulence in recent years. Enhanced resilience supports the ability of banks and other financial institutions to lend, thereby supporting economic growth through good times and bad.\n\nNonetheless, there is more work to do. The balance of research suggests that the core reforms we have put in place have substantially boosted resilience without unduly limiting credit availability or economic growth. But many reforms have been implemented only fairly recently, markets continue to adjust, and research remains limited. The Federal Reserve is committed to evaluating where reforms are working and where improvements are needed to most efficiently maintain a resilient financial system.\n\nMoreover, I expect that the evolution of the financial system in response to global economic forces, technology, and, yes, regulation will result sooner or later in the all-too-familiar risks of excessive optimism, leverage, and maturity transformation reemerging in new ways that require policy responses. We relearned this lesson through the pain inflicted by the crisis. We can never be sure that new crises will not occur, but if we keep this lesson fresh in our memories--along with the painful cost that was exacted by the recent crisis--and act accordingly, we have reason to hope that the financial system and economy will experience fewer crises and recover from any future crisis more quickly, sparing households and businesses some of the pain they endured during the crisis that struck a decade ago.\n\n1. Over the 12 quarters ending in the first quarter of this year, borrowing by the nonfinancial business sector increased at an annual rate just above 6 percent, on average, and borrowing by households and nonprofit institutions rose at an annual rate of 3-1/4 percent, on average; the corresponding average pace of increase in nominal gross domestic product was 3-3/4 percent. Over the same period, lending by private depository institutions advanced at an annual rate of nearly 6-1/2 percent. Return to text\n\n2. A contemporaneous perspective on subprime mortgage market developments at this time is provided in Ben S. Bernanke (2007), \"The Subprime Mortgage Market,\" speech delivered at the Federal Reserve Bank of Chicago's 43rd Annual Conference on Bank Structure and Competition, Chicago, May 17. Return to text\n\n3. On August 17, 2007, the Federal Reserve Board reduced the primary credit rate at the discount window by 50 basis points and announced a change to the Reserve Banks' usual practices to allow the provision of term financing for as long as 30 days, renewable by the borrower. The changes were announced to remain in place until the Federal Reserve determined that market liquidity had improved materially. See Board of Governors of the Federal Reserve System (2007), \"Federal Reserve Board Discount Rate Action,\" press release, August 17. Return to text\n\n4. The proceedings from the 2007 conference are instructive about the range of views regarding housing-related developments preceding the acute phase of the financial crisis. See Federal Reserve Bank of Kansas City (2007), Housing, Housing Finance, and Monetary Policy, proceedings of an economic policy symposium (Kansas City: FRBKC). Return to text\n\n5. For a discussion of the correspondence between the steps taken by the Federal Reserve and those suggested by Walter Bagehot in the 19th century, see Brian F. Madigan (2009), \"Bagehot's Dictum in Practice: Formulating and Implementing Policies to Combat the Financial Crisis,\" speech delivered at the Federal Reserve Bank of Kansas City's annual economic symposium, Jackson Hole, Wyo., August 21. Return to text\n\n6. A timeline of developments in the United States over the financial crisis is available on the Federal Reserve Bank of St. Louis's website at https://www.stlouisfed.org/financial-crisis/full-timeline. The failure of Fannie Mae and Freddie Mac is marked by the decision of the Federal Housing Finance Agency (FHFA) to place Fannie Mae and Freddie Mac in government conservatorship on September 7, 2008. Links to documents outlining the actions taken around this time are available on the FHFA's website at https://www.fhfa.gov/Media/PublicAffairs/Pages/Conservatorship-of-Fannie-Mae-and-Freddie-Mac.aspx. Return to text\n\n7. In the fall of 2008, the three largest investment banks were (in alphabetical order) Goldman Sachs, Merrill Lynch, and Morgan Stanley. Merrill Lynch agreed to be acquired by Bank of America, and the remaining two firms became bank holding companies. Return to text\n\n8. The notion that popular sentiment may contribute to mispricing of assets--for example, the power of the madness of crowds--is attributed to Charles Mackay (1841), Memoirs of Extraordinary Popular Delusions and the Madness of Crowds (London: Richard Bentley). A more modern perspective, and one using a phrase as memorable as the madness of crowds, is provided by Robert J. Shiller (2016), Irrational Exuberance, 3rd ed. (Princeton, N.J.: Princeton University Press). The notion that economic stability can generate a buildup of imbalances that subsequently contributes to instability is presented in Hyman P. Minsky (1974), \"The Modeling of Financial Instability: An Introduction,\" in Modeling and Simulation, Vol. 5, Part 1, proceedings of the Fifth Annual Pittsburgh Conference (Pittsburgh: Instrument Society of America), pp. 267-72. A related discussion of how financial excesses often precede downturns (and even panics) is provided in Charles P. Kindleberger and Robert Z. Aliber (2005), Manias, Panics, and Crashes: A History of Financial Crises, 5th ed. (Hoboken, N.J.: John Wiley & Sons). Return to text\n\n9. These improvements encompass a number of changes. The regulatory requirements for capital have been increased and focus on Tier 1 common equity, which proved more capable of absorbing losses than lower-quality forms of capital. The role of bank internal models in determining risk-weighted assets also has been significantly constrained in the United States. In addition, exposures previously considered off balance sheet have been incorporated into risk-weighted assets. Return to text\n\n10. The Federal Reserve Board, the FDIC, and the Office of the Comptroller of the Currency adopted a final rule to strengthen the leverage ratio standards for the largest, most interconnected U.S. banking organizations on April 8, 2014. Under the final rule, covered bank holding companies must maintain a leverage buffer of 2 percentage points above the minimum supplementary leverage ratio requirement of 3 percent, for a total of 5 percent, to avoid restrictions on capital distributions and discretionary bonus payments (see Board of Governors of the Federal Reserve System, Federal Deposit Insurance Corporation, and Office of the Comptroller of the Currency (2014), \"Agencies Adopt Enhanced Supplementary Leverage Ratio Final Rule and Issue Supplementary Leverage Ratio Notice of Proposed Rulemaking,\" joint press release, April 8). The Federal Reserve approved a final rule imposing risk-based capital surcharges on the largest, most systemically important U.S. bank holding companies on July 20, 2015; in connection with the final rule, the Board issued a white paper describing the calibration of the risk-based capital surcharges (see Board of Governors of the Federal Reserve System (2015), \"Federal Reserve Board Approves Final Rule Requiring the Largest, Most Systemically Important U.S. Bank Holding Companies to Further Strengthen Their Capital Positions,\" press release, July 20). Return to text\n\n11. Moreover, the Federal Reserve's Comprehensive Liquidity Analysis and Review, in which supervisors analyze the liquidity risks and practices at large banks, has promoted improvements in liquidity-risk management. The U.S. banking agencies also have proposed a net stable funding ratio (NSFR) to help ensure that large banks have a stable funding profile over a one-year horizon, and we are working toward finalization of the NSFR. Return to text\n\n12. In addition to these steps, the Board issued another proposal to make G-SIBs more resolvable in May of last year (see Board of Governors of the Federal Reserve System (2016), \"Federal Reserve Board Proposes Rule to Support U.S. Financial Stability by Enhancing the Resolvability of Very Large and Complex Financial Firms,\" press release, May 3). This proposed rule would impose restrictions on G-SIBs' qualified financial contracts--including derivatives and repurchase agreements (or repos)--to guard against the rapid, mass unwinding of those contracts during the resolution of a G-SIB. The proposed restrictions are a key step toward G-SIB resolvability because rapidly unwinding these contracts could destabilize the financial system by causing asset fire sales and toppling other firms. Return to text\n\n13. One area in which regulations have shifted to a lesser degree in the United States is that of time-varying macroprudential tools, in which regulatory requirements are adjusted to address changes in vulnerabilities that may affect the financial system. For example, U.S. regulatory authorities have adopted rules that allow use of the countercyclical capital buffer, but other time-varying tools are limited in the United States. This issue is discussed in, for example, Stanley Fischer (2015), \"Macroprudential Policy in the U.S. Economy,\" speech delivered at \"Macroprudential Monetary Policy,\" 59th Economic Conference of the Federal Reserve Bank of Boston, Boston, October 2. Return to text\n\n14. For example, the FSOC contributed, through its identification process, to the development of the Securities and Exchange Commission reforms affecting money market funds. The FSOC has also designated four firms as systemically important--AIG, GE Capital, Prudential, and MetLife. GE Capital chose to shrink, adjust its business model, and reduce its footprint in short-term wholesale funding markets--and hence reduce a source of systemic risk. These actions caused the FSOC to subsequently remove its designation as systemically important last year--illustrating how the designation process allows both identifying systemic firms and removing such designations when appropriate. Return to text\n\n15. The increase in Tier 1 common equity among bank holding companies has been sizable, especially for the largest banks. If the largest banks are defined as either the eight U.S. global systemically important banks or the U.S. bank holding companies that participated in the CCAR in 2017 (and for which data are available for 2009:Q1), Tier 1 common equity has more than doubled in dollar terms and relative to risk-weighted assets from the first quarter of 2009 to the most recent observations. Return to text\n\n16. For example, Natasha Sarin and Lawrence Summers have reviewed market-based measures of bank equity and related measures of bank risks and concluded that such measures have not improved since the mid-2000s. This assessment may understate the improvement in fundamental risk within the banking sector, as it takes the elevated valuations and low assessment of default risk implied by market prices during the earlier period as indicative of fundamentals. Despite these shortcomings, their analysis is a useful reminder of the importance of considering both regulatory metrics and assessments implied by market prices. See Natasha Sarin and Lawrence H. Summers (2016), \"Understanding Bank Risk through Market Measures (PDF),\" Brookings Papers on Economic Activity, Fall, pp. 57-109. Return to text\n\n17. For example, see the review of evidence in Simon Firestone, Amy Lorenc, and Ben Ranish (2017), \"An Empirical Economic Assessment of the Costs and Benefits of Bank Capital in the US (PDF),\" Finance and Economics Discussion Series 2017-034 (Washington: Board of Governors of the Federal Reserve System, April). Some research is less supportive of the role of bank capital in limiting the risk of financial crises but suggests that higher levels of bank capital limit the economic costs of a financial crisis (for example, Òscar Jordà, Björn Richter, Moritz Schularick, and Alan M. Taylor (2017), \"Bank Capital Redux: Solvency, Liquidity, and Crisis,\" NBER Working Paper Series 23287 (Cambridge, Mass.: National Bureau of Economic Research, March)). Some of the differences in findings across studies may be due to the degree to which the studies incorporate data from different countries and over different periods, as researchers disagree over the extent to which comparisons across countries or periods appropriately account for other factors that differ across such dimensions. Return to text\n\n18. For example, Charles A.E. Goodhart, Anil K. Kashyap, Dimitrios P. Tsomocos, and Alexandros P. Vardoulakis (2013), \"An Integrated Framework for Analyzing Multiple Financial Regulations,\" International Journal of Central Banking, supp. 1, vol. 9 (January), pp. 109-43; and Gazi I. Kara and S. Mehmet Ozsoy (2016), \"Bank Regulation under Fire Sale Externalities (PDF),\" Finance and Economics Discussion Series 2016-026 (Washington: Board of Governors of the Federal Reserve System, April). Return to text\n\n19. For example, researchers at the Federal Reserve Bank of New York have developed a top-down stress-testing model, and simulation results from the model suggest that the resilience of the U.S. banking system has improved since the crisis; see Beverly Hirtle, Anna Kovner, James Vickery, and Meru Bhanot (2014), \"Assessing Financial Stability: The Capital and Loss Assessment under Stress Scenarios (CLASS) Model (PDF),\" Staff Report 663 (New York: Federal Reserve Bank of New York, February; revised July 2015). Return to text\n\n20. For example, see Fernando Duarte and Thomas Eisenbach (2013), \"Fire-Sale Spillovers and Systemic Risk (PDF),\" Staff Report 645 (New York: Federal Reserve Bank of New York, October; revised February 2015). Return to text\n\n21. In response to the Federal Reserve's review and other information, the Board finalized a rule adjusting its capital plan and stress-testing rules, effective for the 2017 cycle, on January 30, 2017. The final rule removes large and noncomplex firms from the qualitative assessment of the Federal Reserve's CCAR, reducing significant burden on these firms and focusing the qualitative review in CCAR on the largest, most complex financial institutions. More generally, changes to improve regulatory and supervisory practices related to stress testing by reducing unnecessary burden while preserving resilience are under consideration. Possible changes have been discussed in Daniel K. Tarullo (2016), \"Next Steps in the Evolution of Stress Testing,\" speech delivered at the Yale University School of Management Leaders Forum, New Haven, Conn., September 26. Return to text\n\n22. An overview of a set of principles that may guide such adjustments is discussed by Jerome H. Powell (2017), \"Relationship between Regulation and Economic Growth,\" statement before the Committee on Banking, Housing, and Urban Affairs, U.S. Senate, June 22. In addition, the Federal Reserve Board has continued to engage in international efforts to assess the effects of reforms and possible adjustments; in this context, the FSB has developed a framework for the post-implementation evaluation of the effects of the Group of Twenty financial regulatory reforms; see Financial Stability Board (2017), Framework for Post-Implementation Evaluation of the Effects of the G20 Financial Regulatory Reforms (PDF) (Basel, Switzerland: FSB, July). Return to text\n\n23. The related literature is sizable. An early contribution is Ben S. Bernanke and Cara S. Lown (1991), \"The Credit Crunch,\" Brookings Papers on Economic Activity, no. 2, pp. 205-47. Research finding a sizable negative relationship between capital requirements and lending includes Shekhar Aiyar, Charles W. Calomiris, and Tomasz Wieladek (2014), \"Does Macro-Prudential Regulation Leak? Evidence from a UK Policy Experiment,\" Journal of Money, Credit and Banking, vol. 46 (s1; February), pp. 181-214. Research finding little relationship between lending and capital ratios (outside financial crises) includes Mark Carlson, Hui Shan, and Missaka Warusawitharana (2013), \"Capital Ratios and Bank Lending: A Matched Bank Approach,\" Journal of Financial Intermediation, vol. 22 (October), pp. 663-87. Research suggesting that higher capital levels may increase lending includes Leonardo Gambacorta and Hyun Song Shin (2016), \"Why Bank Capital Matters for Monetary Policy (PDF),\" BIS Working Papers 558 (Basel, Switzerland: Bank for International Settlements, April). Return to text\n\n24. For example, see Basel Committee on Banking Supervision (2010), An Assessment of the Long-Term Economic Impact of Stronger Capital and Liquidity Requirements (PDF) (Basel, Switzerland: BCBS, August); and Macroeconomic Assessment Group (2010), Interim Report: Assessing the Macroeconomic Impact of the Transition to Stronger Capital and Liquidity Requirements (PDF) (Basel, Switzerland: MAG, August). Return to text\n\n25. The ex ante studies from the Basel Committee and the Macroeconomic Assessment Group referenced in note 24 pointed to sizable net benefits from higher capital requirements. More academic research pointing to similar conclusions using macroeconomic models (and typically focused on model-specific measures of economic welfare) includes Michael T. Kiley and Jae W. Sim (2014), \"Bank Capital and the Macroeconomy: Policy Considerations,\" Journal of Economic Dynamics and Control, vol. 43 (June), pp. 175-98; Laurent Clerc, Alexis Derviz, Caterina Mendicino, Stephane Moyen, Kalin Nikolov, Livio Stracca, Javier Suarez, and Alexandros P. Vardoulakis (2015), \"Capital Regulation in a Macroeconomic Model with Three Layers of Default,\" International Journal of Central Banking, vol. 11 (June), pages 9-63; and Juliane Begenau (2016), \"Capital Requirements, Risk Choice, and Liquidity Provision in a Business Cycle Model,\" unpublished paper, Harvard Business School, September. Subsequent analyses, albeit ones that follow similar approaches, also suggest that there are net benefits to higher capital standards. One example is the analysis by Firestone, Lorenc, and Ranish, \"An Empirical Economic Assessment,\" in note 17. Another is Ingo Fender and Ulf Lewrick (2016), \"Adding It All Up: The Macroeconomic Impact of Basel III and Outstanding Reform Issues (PDF),\" BIS Working Papers 591 (Basel, Switzerland: Bank for International Settlements, November). Indeed, this research points to benefits from capital requirements in excess of those adopted, a conclusion also reached in Wayne Passmore and Alexander H. von Hafften (2017), \"Are Basel's Capital Surcharges for Global Systemically Important Banks Too Small? (PDF)\" Finance and Economics Discussion Series 2017-021 (Washington: Board of Governors of the Federal Reserve System, February). Return to text\n\n26. This conclusion is consistent with, for example, the findings in Federal Reserve Banks (2017), 2016 Small Business Credit Survey: Report on Employer Firms (PDF) (New York: Federal Reserve Bank of New York, April). Return to text\n\n27. As I have discussed previously, the Federal Reserve has been considering improvements through a number of work streams. For example, the Federal Reserve and the other banking agencies have recently completed the Economic Growth and Regulatory Paperwork Reduction Act (EGRPRA) review. Under EGRPRA, the federal banking agencies are required to conduct a joint review of their regulations every 10 years to identify provisions that are outdated, unnecessary, or unduly burdensome. The Federal Reserve viewed this review as a timely opportunity to step back and identify ways to reduce regulatory burden, particularly for smaller or less complex banks that pose less risk to the U.S. financial system. I discussed preliminary emerging themes from this review in Janet L. Yellen (2016), \"Supervision and Regulation,\" statement before the Committee on Financial Services, U.S. House of Representatives, September 28. For the final EGRPRA report to the Congress, see Board of Governors of the Federal Reserve System, Office of the Comptroller of the Currency, Federal Deposit Insurance Corporation, and National Credit Union Administration (2017), Joint Report to Congress: Economic Growth and Regulatory Paperwork Reduction Act (PDF) (Washington: Federal Financial Institutions Examination Council, March). Return to text"
    },
    {
        "title": "The Low Level of Global Real Interest Rates",
        "date": "July 31, 2017",
        "speaker": "Vice Chairman Stanley Fischer",
        "url": "https://www.federalreserve.gov/newsevents/speech/fischer20170731a.htm",
        "content": "July 31, 2017\n\nVice Chairman Stanley Fischer\n\nAt the Conference to Celebrate Arminio Fraga’s 60 Years, Casa das Garcas, Rio de Janeiro, Brazil\n\nI am very happy to be participating in this conference celebrating Arminio. My tenure at the International Monetary Fund overlapped with the first two and a half years of Arminio's time as president of the Central Bank of Brazil, and in our capacities at the time, we had frequent opportunities to interact and converse. Of course, I watched with admiration the remarkable management of the economy by the Malan-Fraga team in the run-up to the election that brought Lula to power. In particular, Arminio and his Central Bank team's management of the exchange rate--which at one point reached 3.95 reais per dollar--was masterly and put in place a sound foundation for that essential part of Brazil's economic machinery in the years that followed.\n\nSubsequently, as I was on the brink of transitioning to the world of central banking early in 2005--that is, prior to taking up my position as governor of the Bank of Israel--Arminio was able to turn the tables and offered me some hard-edged advice on how to be a central banker. I have kept that advice close since then. It comes in the form of six commandments on a small laminated piece of paper. Needless to say, it very much reflects his values and his behavior. Let me quote just three of his rules: \"Number 2. Do [the job] in a way that shows you care, but in a way that shows you will serenely pursue your goals\"--excellent advice, which is easier said than done; \"Number 5. Beware of a tendency to be overly conservative once you start wearing the central bank hat\"; and \"Number 6. Remember, most people lose half their IQ when they take a job such as this one.\"\n\nNow I will turn to the main topic of my discussion, the low level of global real interest rates, an important and distinguishing feature of the current global economic environment. In the United States, the yield on 10-year Treasury bonds is near all-time lows, with the same being true in the euro area, the United Kingdom, and Japan (figure 1). Yields have also declined in many emerging markets, with interest rates falling almost 400 basis points in Korea since the financial crisis and by a similar amount in Israel. As shown in figure 2, the decline has been less apparent in Brazil and South Africa, though interest rates in both countries remain well below previous peaks.\n\nIn this talk, I will address two questions: Why are interest rates so low? And why has the decline in interest rates been so widespread?1\n\nGlobal Real Interest Rates Have Declined\nLower inflation explains a portion of the decline in nominal interest rates. Longer-term interest rates reflect market participants' expectations of future inflation as well as the expected path of real, or inflation-adjusted, interest rates. And while lower realized inflation and credible central back inflation targets have likely stabilized expected inflation at relatively low levels compared with much of the 20th century, inflation-adjusted yields have also notably decreased.\n\nThe decline in interest rates also does not appear to be primarily an outcome of the economic cycle. Longer-term interest rates in the United States have remained low even as the Federal Open Market Committee (FOMC) has increased the short-term federal funds rate by 100 basis points and as the unemployment rate has declined below the median of FOMC participants' assessments of its longer-run normal level.\n\nRather, it appears as though much of the decline has occurred in the equilibrium level of the real interest rate--also known as the natural rate of interest or, alternatively, r*. Knut Wicksell, in his 1898 treatise Interest and Prices, wrote, \"There is a certain level of the average rate of interest which is such that the general level of prices has no tendency to move either upwards or downwards.\"2 In recent years, the coincidence of low inflation and low interest rates suggests that the natural rate of interest is likely very low today.\n\nWicksell was clearly referring to the natural rate as the real interest rate when the economy is at full employment. The widely cited methodology of my Federal Reserve colleagues Thomas Laubach and John Williams, attempts to gauge the natural rate in the longer run after various shorter-term influences, including the business cycle, have played out. In a recent update of their analysis, they find that the natural rate of interest has declined about 150 basis points in the United States since the financial crisis and is currently about 50 basis points. We must remember, however, that r* is a function and not a constant, and its estimation is subject to a number of assumptions, the modification of which can lead to a wide range of estimates.3\n\nIn an extension of this analysis, shown in figure 3, Laubach, Williams, and Kathryn Holston, also a Federal Reserve colleague, show that the decline in the natural rate of interest is a common feature across a number of foreign economies.4 The fall in equilibrium interest rates was most pronounced at the time of the financial crisis, but rates have shown little tendency to increase during the long recovery from the crisis.\n\nHow Should We Think about the Decline in Equilibrium Interest Rates? An Investment and Savings Framework\nThere are many factors that could be holding down interest rates, some of which could fade over time, including the effects of quantitative easing in the United States and abroad and a heightened demand for safe assets affecting yields on advanced-economy government securities. I will focus on some of the more enduring factors that could potentially lower the equilibrium interest for some time.\n\nIn attempting to explain why real interest rates have fallen, a useful starting point is to think of the natural interest rate as the price that equilibrates the economy's supply of saving with the demand for investment in the long run, when the economy is at full employment. With this framework in mind, low interest rates reflect factors that increase saving, depress investment demand, or both.\n\nFocusing initially on the United States, I will look at three interrelated factors that are likely contributing to low interest rates: slower trend economic growth, an aging population and demographic developments, and relatively weak investment. I will then discuss global developments and spillovers between countries.\n\nBut first I would like to interject a quick word on why we as policymakers might be concerned about low interest rates. I highlight three main worries. First, as John Maynard Keynes discussed in the concluding chapters of The General Theory of Employment, Interest and Money, a low equilibrium interest rate increases the risks of falling into a liquidity trap, a situation where the nominal interest rate is stuck, by an effective lower bound, above the rate necessary to bring the economy back to potential.5 Relatedly, but more broadly, low equilibrium interest rates are a key pillar of the secular stagnation hypothesis, which Larry Summers has carried forward during the past few years.6 Second, a low natural rate could potentially hurt financial stability if it leads investors to reach for yield or hurts financial firms' profitability. And, third--and perhaps most troubling--a low equilibrium rate sends a powerful signal that the growth potential of the economy may be limited.7\n\nSlow trend growth\nOne factor contributing to low equilibrium interest rates in the United States has been a slowdown in the pace of potential, or trend, growth. According to the Congressional Budget Office (CBO), real potential growth in the United States is currently around 1.5 percent, compared with a pace about double that, on average, in the two decades leading up to the financial crisis. A prime culprit in the growth slowdown has been the slow rate of labor productivity growth, which has increased only 1/2 percent, on average, over the past five years, compared with a 2 percent growth rate over the period from 1976 to 2005.8 A declining rate of labor force growth has also worked to push down trend growth. The CBO is projecting that the potential labor force in the United States will grow at about 1/2 percent per year over the next decade, less than half the pace observed, on average, in the two decades before the financial crisis.\n\nSlower growth can both boost saving and depress investment. As households revise down their expectations for future income growth, they become less likely to borrow and more likely to save. Likewise, slower growth diminishes the number of business opportunities that can be profitably undertaken, weighing on investment demand.\n\nDemographics\nThe aging of the population can work to lower the equilibrium interest rate beyond its effect on the size of the labor force and trend growth. As households near retirement, they tend to save more, anticipating having to run down their savings after they leave the labor force. Federal Reserve economists, in one study, estimate that higher saving by near-retirement households could be pushing down the longer-run equilibrium federal funds rate relative to its level in the 1980s by as much as 75 basis points.9\n\nInvestment\nAnother factor weighing on equilibrium real interest rates has been the recent weakness of investment. What explains the tepid response of capital spending to historically low interest rates? As mentioned earlier, low productivity growth has certainly been a contributing factor, as firms see fewer profitable investment opportunities. But elevated uncertainty, both political and economic, has likely also played a role. For one, uncertainty about the outlook for government policy in health care, regulation, taxes, and trade can cause firms to delay projects until the policy environment clarifies.\n\nFirms also seem quite uncertain about the disruptive capacity of new technologies. Technological developments appear to be rapidly reshaping entire industries‑‑in retail, transportation, and communications. Elevated uncertainty about the continued viability of long-standing business models could be weighing on investment decisions. Relatedly, it is possible that as the economy evolves in response to new technologies, production is becoming less capital intensive than it was in earlier decades.10\n\nAnother possible explanation for the weakness of investment in the United States has been a decrease in competition within industries, as evidenced by decreasing firm entry and exit rates as well as increased industry concentration.11 Less competition allows firms to maintain high profits while lowering the pressure on them to increase production to maintain market share.\n\nIn an earlier discussion, I attempted to quantify the effect that these factors--slow growth, demographics, and investment--might be having on the long-run equilibrium rate in the United States.12 According to simulations from the Board's FRB/US model, the slowdown in growth appears likely to be the primary factor depressing the long-run equilibrium rate, although the contributions from demographics and weak investment demand were also sizable.\n\nGlobal Links: Why Has the Decline in Interest Rates Been So Widespread?\nUp until now, I have looked primarily at factors within the United States. However, as I have pointed out earlier, the decline in interest rates is a global phenomenon. Why has the decline in interest rates been so widespread?\n\nOne important reason is that many of the same factors that have been driving down the equilibrium interest rate in the United States have operated with equal or even greater force in many foreign economies. The slowdown in labor productivity growth has been widespread across many countries. Likewise, the advanced economies and some emerging markets have experienced demographic shifts that are in some cases much more pronounced than in the United States, with the working-age population in some countries even declining over the past decade.\n\nAnother explanation is that we live in an integrated global economy where economic developments in one country spill over into other countries via trade and capital flows as well as prices, including interest rates and exchange rates.13 In the most general sense, these spillovers are captured in the pattern of current balances, shown in figure 4. If we abstract from a somewhat sizable statistical discrepancy, the sum of global current accounts should be equal to zero, as, in the aggregate, one country's deficit must be matched by a surplus in some configuration of other countries--but it is not always apparent who is spilling over onto whom.\n\nCurrent Account Balances and Global Spillovers\nPrior to the financial crisis, it was widely speculated that foreign developments were depressing U.S. interest rates. Former Chairman Bernanke characterized the foreign forces acting on U.S. interest rates as the \"global saving glut,\" with particular reference to emerging market economies that were running persistent current account surpluses, sometimes as a result of specific policy decisions regarding exchange rates, reserve accumulation, and fiscal policy.14 The global saving glut was also a factor in the \"Greenspan conundrum,\" or the observation that a series of Federal Reserve rate hikes over the period from 2004 to 2006 seemed to have little effect on longer-term interest rates in the United States. As shown in figure 5, the deterioration of the U.S. deficit in the early 2000s was matched by growing surpluses in the emerging markets, particularly in emerging Asia and China as well as OPEC. The explosive growth of the U.S. current account deficit from 2001 to 2006, coincident with falling interest rates both in the United States and globally, supports the notion that higher foreign saving relative to foreign investment was likely holding down U.S. interest rates at the time.\n\nWhat can the distribution of global current accounts tell us about international spillovers in the post-crisis era? As shown in figure 6, the most notable development has been the almost exact reversal of the expansion of the U.S. current account deficit observed during the time of the global saving glut. Has the global saving glut of the mid-2000s faded away? Falling interest rates over the period that the U.S. deficit narrowed suggest not.15 If a shrinking supply of foreign saving, the reversal of the global saving glut, was behind the narrowing of the U.S. deficit, then the tendency would have been for equilibrium real interest rates to have increased.16 Rather, falling equilibrium rates suggest that falling U.S. demand for foreign savings has precipitated the narrowing of the U.S. current account deficit. U.S. demand likely decreased for the reasons discussed earlier, including slowing growth, demographics, and weak investment demand.\n\nDoes the marked narrowing of the U.S. current account deficit post-crisis suggest that the United States has been the primary source of downward pressure on global interest rates over the past decade? Certainly, if the United States had maintained its previous deficit, interest rates would likely be higher around the world. However, the financial crisis revealed that the U.S. capacity to absorb global savings at the pace observed prior to the crisis was unsustainable.17 Rather, an alternative explanation would be that the sharp decline in global interest rates post-crisis reflects factors that were likely well in train before the financial crisis. The downward trend in interest rates would have been more pronounced earlier in the decade had not elevated, and ultimately unsustainable, borrowing in the United States slowed the decline in interest rates in the years immediately preceding the crisis. This narrative is consistent with empirical evidence that suggests that the slowdowns in global productivity growth and labor force growth, both key factors in the slowing pace of global growth and the downward pressure on interest rates, predate the global financial crisis.18\n\nIt is notable in figure 6 that the euro area has also seen a sizable increase in its current account position post-crisis, suggesting that developments in Europe have also played a role in pushing down interest rates. The increase in the euro-area current account in part reflects sharp reversals in the current account deficits of Greece, Portugal, Spain, and Ireland--all countries that had witnessed large increases in their deficits during the global saving glut period prior to the crisis, in a pattern similar to that experienced by the United States. However, the euro-area increase also reflects increased surpluses in Germany and the Netherlands, countries that were already in considerable surplus during the pre-crisis period.\n\nWhat, If Anything, Can Be Done about Low Interest Rates?\nGiven the potential risks around low interest rates I discussed earlier, including the impact on the effectiveness of monetary policy and financial stability concerns, what should policymakers do to address the problem?\n\nMonetary policy has a role to play. Transparent and sound monetary policy can boost confidence in the stability of the growth outlook, an outcome that can in turn alleviate precautionary demand for savings and encourage investment, pushing up the equilibrium interest rate.\n\nHowever, as I have said before--and Ben Bernanke before me--\"Monetary policy is not a panacea.\"19 Also, to repeat myself, policies to boost productivity growth and the longer-run potential of the economy are more likely to be found in effective fiscal and regulatory measures than in central bank actions. This statement is true not only in the United States, but also around the globe. But it is not to say that monetary policy is irrelevant to the growth rate of the economy.\n\nReferences\nBernanke, Ben S. (2005). \"The Global Saving Glut and the U.S. Current Account Deficit,\" speech delivered at the Homer Jones Lecture, St. Louis, April 14.\n\n-------- (2012). \"U.S. Monetary Policy and International Implications,\" speech delivered at \"Challenges of the Global Financial System: Risks and Governance under Evolving Globalization,\" a High-Level Seminar sponsored by the Bank of Japan-International Monetary Fund, Tokyo, October 14.\n\n-------- (2015). \"Why Are Interest Rates So Low, Part 3: The Global Savings Glut,\" Ben Bernanke's Blog, April 1.\n\nClarida, Richard H. (2017). \"The Global Factor in Neutral Policy Rates: Some Implications for Exchange Rates, Monetary Policy, and Policy Coordination,\" NBER Working Paper Series 23562. Cambridge, Mass.: National Bureau of Economic Research, June.\n\nDöttling, Robin, Germán Gutiérrez, and Thomas Philippon (2017). \"Is There an Investment Gap in Advanced Economies? If So, Why? (PDF)\" paper presented at the Fourth Annual ECB Forum on Central Banking, Sintra, Portugal, June 27.\n\nFernald, John G. (2015). \"Productivity and Potential Output before, during, and after the Great Recession,\" in Jonathan A. Parker and Michael Woodford, eds., NBER Macroeconomics Annual 2014, vol. 29. Chicago: University of Chicago Press, pp. 1-51.\n\nFernald, John G., Robert E. Hall, James H. Stock, and Mark W. Watson (2017). \"The Disappointing Recovery of Output after 2009,\" NBER Working Paper Series 23543. Cambridge, Mass.: National Bureau of Economic Research, June.\n\nFischer, Stanley (2016a). \"Low Interest Rates,\" speech delivered at the 40th Annual Central Banking Seminar, sponsored by the Federal Reserve Bank of New York, New York, October 5.\n\n-------- (2016b). \"Why Are Interest Rates So Low? Causes and Implications,\" speech delivered at the Economic Club of New York, New York, October 17.\n\nGagnon, Etienne, Benjamin K. Johannsen, and David Lopez-Salido (2016). \"Understanding the New Normal: The Role of Demographics (PDF),\" Finance and Economics Discussion Series 2016-080. Washington: Board of Governors of the Federal Reserve System, October.\n\nGutiérrez, Germán, and Thomas Philippon (2017). \"Declining Competition and Investment in the U.S.,\" NBER Working Paper Series 23583. Cambridge, Mass.: National Bureau of Economic Research, July.\n\nHilsenrath, Jon, and Bob Davis (2016). \"Tech Boom Creates Too Few Jobs,\" Wall Street Journal, October 13.\n\nHolston, Kathryn, Thomas Laubach, and John C. Williams (forthcoming). \"Measuring the Natural Rate of Interest: International Trends and Determinants,\" in Richard Clarida and Lucrezia Reichlin, organizers, NBER International Seminar on Macroeconomics 2016. Amsterdam: Journal of International Economics (Elsevier).\n\nIrwin, Neil (2017). \"Rethinking Low Productivity,\" New York Times, July 26.\n\nJohannsen, Benjamin K., and Elmar Mertens (2016). \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, February 9.\n\nKeynes, John Maynard (1936). The General Theory of Employment, Interest and Money. London: Macmillan.\n\nLaubach, Thomas, and John C. Williams (2003). \"Measuring the Natural Rate of Interest,\" Review of Economics and Statistics, vol. 85 (November), pp. 1063-70.\n\nLewis, Kurt F., and Francisco Vazquez-Grande (2017). \"Measuring the Natural Rate of Interest: Alternative Specifications (PDF),\" Finance and Economics Discussion Series 2017-059. Washington: Board of Governors of the Federal Reserve System, June.\n\nSummers, Lawrence H. (2014). \"U.S. Economic Prospects: Secular Stagnation, Hysteresis, and the Zero Lower Bound,\" Business Economics, vol. 49 (April), pp. 65-73.\n\n-------- (2015). \"Demand Side Secular Stagnation,\" American Economic Review, vol. 105 (May), pp. 60-65.\n\n-------- (2016). \"The Age of Secular Stagnation: What It Is and What to Do about It,\" Foreign Affairs, vol. 95 (March-April), pp. 2-9.\n\nWicksell, Knut (1936). Interest and Prices (Geldzins und Güterpreise): A Study of the Causes Regulating the Value of Money, trans. R.F. Kahn. London: Macmillan.\n\n1. I am grateful to Joseph W. Gruber of the Federal Reserve Board for his assistance. Views expressed in this presentation are my own and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. Wicksell's Interest and Prices, published in German in 1898 as Geldzins und Güterpreise by Gustav Fischer (Jena), was first published in English in 1936--see Wicksell (1936). Return to text\n\n3. See Laubach and Williams (2003). See also Gagnon, Johannsen, and Lopez-Salido (2016) and Johannsen and Mertens (2016). It is important to point out that r* is not an observable variable and that estimates generally reflect assumptions about how the economy works and should be modeled. As such, different methodologies or underlying economic models can come up with a wide range of estimates of r*. Lewis and Vazquez-Grande (2017) examine parameter uncertainty and alternative specifications in the estimation of the natural rate of interest. Under some specifications, they find an estimated r* at the end of 2016 of close to 2 percent, far higher than the about 0.5 percent reported by the methodology of Holston, Laubach, and Williams (forthcoming). Return to text\n\n4. See Holston, Laubach, and Williams (forthcoming). Return to text\n\n5. In chapter 23, p. 353, Keynes includes an interesting discussion of the \"strange, unduly neglected prophet Silvio Gesell (1862-1930), whose work contains flashes of deep insight and who only just failed to reach down to the essence of the matter.\" He adds that Gesell was a successful German merchant in Buenos Aires. See Keynes (1936). Return to text\n\n6. See Summers (2014, 2015, 2016). Return to text\n\n7. See Fischer (2016a) for a fuller discussion of the risks associated with a low equilibrium interest rate. Return to text\n\n8. See Irwin (2017) for an examination of an alternative pattern of causality, where slow growth--and, in particular, weak wage growth--has led to low productivity growth rather than vice versa. I should also remind the reader of Herbert Stein's observation that the difference between a growth rate of 1 percent and a growth rate of 2 percent is 100 percent. Return to text\n\n9. See Gagnon, Johannsen, and Lopez-Salido (2016), figure 12, p. 45. Return to text\n\n10. See Hilsenrath and Davis (2016). Return to text\n\n11. See Gutiérrez and Philippon (2017) and Döttling, Gutiérrez, and Philippon (2017). Return to text\n\n12. See Fischer (2016b). Return to text\n\n13. See Clarida (2017) for a model-based discussion of global factors and neutral interest rates. Return to text\n\n14. See Bernanke (2005). Return to text\n\n15. While it is unsurprising that interest rates fell sharply during the recession that followed the financial crisis, it is less apparent that equilibrium rates should have fallen so sharply or remain so low almost a decade later following the cyclical recovery in the United States and many other countries. Return to text\n\n16. See Bernanke (2015) for a discussion of the persistence of the global saving glut. Return to text\n\n17. This is not to suggest that the global saving glut was the only factor leading to the financial crisis. Rather, excessive risk-taking on the part of U.S. households and financial firms, along with structural defects in the structure of regulation and failures in supervision on the part of government regulators, also played a role. Return to text\n\n18. See Fernald (2015) and Fernald and others (2017). Return to text\n\n19. See Bernanke (2012). Of course, there are no panaceas--except, I have been told by experts, aspirin, and perhaps also statins. Return to text"
    },
    {
        "title": "Strengthening Diversity in Economics",
        "date": "July 28, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170728a.htm",
        "content": "July 28, 2017\n\nGovernor Lael Brainard\n\nAt the Conference for the 2017 Summer Training and Scholarship Program sponsored by the American Economic Association and the National Science Foundation and hosted by the Department of Economics, Michigan State University, East Lansing, Michigan\n\nLet me begin by expressing my appreciation to the American Economic Association (AEA), the National Science Foundation and the other organizations and institutions sponsoring this conference, which for nearly 20 years has focused attention on the benefits of diversity and the need for continued progress in ensuring that the best and the brightest have the opportunity to advance and contribute to the field of economics. I want to especially thank Lisa Cook for giving me the opportunity to be here today.1\n\nI am particularly pleased to be able to speak with students participating in the AEA's Summer and Mentoring Programs. At the Fed, we share the goal of making sure the group of students who go on to practice economics look more like America. So if you are interested in pursuing economics, we want to make sure you have an opportunity to contribute to the field.\n\nPerhaps more than any other profession, it is in the DNA of economists to believe that equality of opportunity is important not only as a matter of fairness, but also to our country's vitality. In addition, economists like to base conclusions on hard numbers. The numbers make clear there is a persistent lack of diversity in the economics profession, which indicates we are falling short of our ideals.\n\nThe quality of the economics profession and its contributions to society will be stronger when a broader range of people are engaged. We now have substantial empirical evidence documenting the benefits of diversity in broadening the range of ideas and perspectives that are brought to bear on solving problems, and thereby contributing to better outcomes, both in research and in policy. Studies suggest that increased diversity alters group dynamics and decisionmaking in positive ways.\n\nAs Amanda Bayer and Cecilia Rouse have noted, microeconomic experiments and other research have confirmed these ideas. One experiment found that greater racial diversity helped groups of business students outperform other students in solving problems. And another found similar benefits from gender diversity. A study of 2.5 million research papers across the sciences found that those written by ethnically diverse research teams received more citations and had a greater impact than papers by authors with the same ethnicity.2\n\nDiversity in the economics profession will bring important insights into the analysis of our economy and financial system and help policymakers make better decisions in promoting a healthier economy. So given that diversity in the economics profession is an important goal, how have we been doing? Unfortunately, by any measure, we are still falling short. Between 1995 and 2014, the share of women obtaining a doctorate in economics held roughly steady in the neighborhood of 30 percent. Among U.S. citizens and permanent residents earning doctorates, the representation of those identifying as black, Hispanic, or Native American among the pool of doctorate recipients improved from 6 percent in 1995 to 11 percent in 2007. But the improvement has since unwound and the underrepresented minority share stood at about 7 percent in 2014.\n\nI respectfully defer to others who have more closely studied the mix of possible reasons for why progress has not been greater, but I will defer to no one in expressing my view that the status quo is not good enough. I've laid out a number of arguments why policy and society at large would be better off if there were more women and minorities in the economics profession. But a more important question for the students here today might reasonably be, what's in it for me? One answer is that there are a ton of interesting questions out there for you to solve. Another is the considerable premium in earnings over other academic fields.\n\nEven for those students here who are not convinced that a career in economics is ultimately the goal for you, the intellectual framework associated with the study of economics is extremely powerful and applicable to a host of other areas. And who can say now how your career will unfold? I would encourage you to think expansively about your career trajectory. Some of you may already feel that economics is your calling and you may choose to go directly into graduate school with the aim of pursuing doctoral studies. Others may decide to work for a few years and then make a choice about graduate studies once you know more about what kind of job is likely to be most appealing and hopefully have made a dent in your student debt. Just as many people choose to leave the field of economics and pursue other interests at different junctures in their careers, so too there may be multiple points of entry. There are many stories of successful careers in economics that began only after other avenues had been explored. I want to make sure you know that even if you have not specialized in economics as an undergraduate, it is not too late to join. We need economists with diverse experiences and backgrounds, just as we need other sources of diversity.\n\nFor what it is worth, I did not major in economics as an undergraduate, and I worked for several years in the private sector before I decided to pursue a doctorate in economics. I am glad I did. I enormously value the intellectual framework associated with economics, and my career has provided terrific opportunities both to range far afield and to work within the field. In short, I hope you will think of economics not as shutting doors on other opportunities, but rather as equipping you to pursue a whole new set of opportunities.\n\nGiven the benefits I have described to the profession and society from increasing diversity in the ranks of economists, as well as the opportunity a degree in economics affords to individuals who pursue the field, it makes sense to look closely, as the AEA and others continue to do, at the reasons more women and minorities do not concentrate in economics in college or depart from economics as they move toward graduation. To the undergraduates in the audience today who are participating in the Summer Program, I would be interested to hear what you believe may be discouraging women and minorities from choosing economics in school and careers, so that we can take steps to reduce any barriers.\n\nThe AEA and other groups are rightly focused on what universities and other institutions can do to promote diversity in economics. Let me now direct my attention to diversity at my institution, the Federal Reserve, because it is both one of the largest employers of PhD economists in the country and a prominent public institution. The share of women and minorities among economists at the Fed is similar to the numbers for the profession at large, and these numbers have likewise improved fairly little since 2009. Something that has changed over that time, however, is the elevation in importance of diversity efforts, including recruitment. The Board of Governors is making considerable effort to recruit and retain economists who are women and minorities.\n\nWe are working hard at recruitment at the earliest stages of the career-formation process. Every year the Board hires 50 to 60 research assistants (RAs) for two-year terms; the 12 Reserve Banks together hire roughly an equal number. Our research assistant program is to some extent an apprenticeship program for economists and also for financial analysts and those in related fields. Our research assistants are typically recent college graduates and most are at least considering further study of economics. These are sought-after positions because our RAs have the opportunity to work with the Board's leading economists on both research and work that directly supports policymaking.\n\nFor the Summer Program students here today, I would encourage you to explore the RA program. Serving as an RA either at the Federal Reserve Board or at one of the Reserve Banks has proven to be a good way to learn more about the profession and prepare for graduate school. I can report that five graduates of last year's program are now working at the Board as RAs and several are working at Reserve Banks.\n\nFor the Federal Reserve System, our recruitment of RAs is a great opportunity to give a wide range of potential newcomers some exposure to what the career pathway of economics looks like. While not all RAs go on to further economics education and training, a considerable share do, and thus our diversity efforts have the potential to significantly affect career pathways later on. Indeed, at the highest levels of that process, the Federal Reserve under Chair Janet Yellen and with the strong support of the Governors and Reserve Bank Presidents is committed to increasing diversity among the top-ranking staff at the Board and among leaders of the Reserve Banks.\n\nIn the tradition of the discipline of economics, I have cited empirical support for the argument that diversity is good for economics. I know from my own personal experience we can and must do better, and in that spirit I want to tell you about one of my experiences that might resonate with some of you here. When I served at the Treasury Department for President Obama, one of my responsibilities was to represent the United States in the Group of 20 (G-20) deputy ministers of finance and central bank officials. At one of our negotiating meetings, the nearly 50 officials gathered for a group photo. When this photo was distributed to each of us as a memento, it caused a bit of a stir. I remember a colleague from another delegation doing a double take when he looked at the photo. He turned to me and said \"Did you realize you are the only woman in this group?\" I had indeed already noticed that. And I am happy to say that his delegation added a woman after that.\n\nSince that time, we have seen some particularly noteworthy milestones. At the time, there had been only one woman among the G-20 countries serving as head of a central bank, in South Africa, and none among the G-7 advanced economies. Since then, two other women have led G-20 central banks, and now I have the honor of serving with the first woman to lead the Federal Reserve, Janet Yellen.\n\nSo what's my take away from that experience? It was a good reminder to me that we have to see the challenges that are right in front of our eyes if we want to address them and we should not be satisfied until the people sitting around every decisionmaking table look like America in all its rich diversity.\n\nEarlier this year, the Federal Reserve Bank of Atlanta hired Raphael Bostic as its president and chief executive officer, the first African-American to lead a Reserve Bank. I look forward to the day when we have moved far beyond all the firsts, when we can see with satisfaction that the people of the Federal Reserve fully reflect the characteristics of the American people. We are working hard to get there, but we still have a long way to go.\n\nOf course, getting to that point in the future starts with people like you and the paths you choose today. You should choose the path where you feel you will make your greatest contribution--the one that is right for you. But if economics seems like a great fit, then choose it with the confidence that you have the capacity to make an important contribution that will be valued.\n\nSo with that, I will be glad to respond to your questions.\n\n1. I am grateful to John Maggs for his assistance in preparing this text. The remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. Amanda Bayer and Cecilia Elena Rouse, (2016) \"Diversity in the Economics Profession: A New Attack on an Old Problem,\" Journal of Economic Perspectives, vol. 30, no. 4 (Fall), pp. 221-42. Return to text"
    },
    {
        "title": "Cross-Border Spillovers of Balance Sheet Normalization",
        "date": "July 13, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170713a.htm",
        "content": "July 13, 2017\n\nGovernor Lael Brainard\n\nAt the National Bureau of Economic Research’s Monetary Economics Summer Institute, Cambridge, Massachusetts\n\nWhen the central banks in many advanced economies embarked on unconventional monetary policy, it raised concerns that there might be differences in the cross-border transmission of unconventional relative to conventional monetary policy.1 These concerns were sufficient to warrant a special Group of Seven (G-7) statement in 2013 establishing ground rules to address possible exchange rate effects of the changing composition of monetary policy.2\n\nToday the world confronts similar questions in reverse. In the United States, in my assessment, normalization of the federal funds rate is now well under way, and the Federal Reserve is advancing plans to allow the balance sheet to run off at a gradual and predictable pace. And for the first time in many years, the global economy is experiencing synchronous growth, and authorities in the euro area and the United Kingdom are beginning to discuss the time when the need for monetary accommodation will diminish.\n\nUnlike in previous tightening cycles, many central banks currently have two tools for removing accommodation. They can therefore pursue alternative normalization strategies--first seeking to guide policy rates higher before initiating balance sheet runoff, as in the United States, or instead starting to shrink the balance sheet before initiating a tightening of short-term rates, or undertaking both in tandem. Shrinking the balance sheet and raising the policy rate can both contribute to achieving the domestic goals of monetary policy, but it is an open question whether alternative normalization approaches might have materially different implications for the composition of demand and for cross-border spillovers, including through exchange rates and other financial channels.\n\nBefore discussing the cross-border effects of normalization, it is worth noting that the two tools for removing accommodation--raising policy rates and reducing central bank balance sheets--appear to affect domestic output and inflation in a qualitatively similar way. This means that central banks can substitute between raising the policy rate and shrinking the balance sheet to remove accommodation, just as both were used to support the recovery following the Great Recession.\n\nInsofar as a range of approaches is likely to be consistent with achieving a central bank's domestic objectives, the choice of normalization strategy may be influenced by other considerations, including the ease of implementing and communicating policy changes, or the desire to minimize possible credit market distortions associated with the balance sheet. In the case of the Federal Reserve, the Federal Open Market Committee (FOMC) decided to delay balance sheet normalization until the federal funds rate had reached a high enough level to enable it to be cut materially if economic conditions deteriorate, thus guarding against the risk of returning to the effective lower bound (ELB) in an environment with a historically low neutral interest rate.3 The greater familiarity and past experience with the federal funds rate also weighed in favor of this instrument initially. Separately, for those central banks that, unlike the Federal Reserve, moved to negative interest rates, there may be special considerations associated with raising policy rates back into positive territory.\n\nOne question that naturally arises is whether the major central banks' normalization plans may have material implications for cross-border spillovers--an important issue that until very recently had received scant attention. This question is a natural extension of the literature examining the cross-border spillovers of the unconventional policy actions taken by the major central banks to provide accommodation.\n\nAlthough this literature suggests there are good reasons to expect broadly similar cross-border spillovers from tightening through policy rates as through balance sheet runoff, the effects may not be exactly equivalent. The balance sheet might affect certain aspects of the economy and financial markets differently than the short-term rate due to the fact that the balance sheet more directly affects term premiums on longer-term securities, while the short-term rate more directly affects money market rates. As a result, similar to the domestic effects, while the international spillovers of conventional and unconventional monetary policy may operate broadly similarly, the relative magnitude of the different channels may be sufficiently different that, on net, the two policy strategies have distinct effects. For example, as will be discussed at greater length shortly, the two strategies may have very different implications for the exchange rate. Moreover, as was evident with the European Central Bank's (ECB) asset purchases in late 2014 and early 2015, and as we have seen again in reverse in recent weeks, in addition to the standard demand and exchange rate channels, expected or actual asset purchases may have spillovers to foreign financial conditions--by lowering term premiums and the associated longer-term foreign bond yields--that are greater than conventional monetary policy.\n\nTo explore possible differences, it is useful to compare two different approaches to policy normalization, each of which is designed to have identical effects on aggregate domestic activity and thus, at least in the long run, on inflation. At one extreme, a central bank could opt to tighten primarily through conventional policy hikes, while maintaining the balance sheet by reinvesting the proceeds of maturing assets. At the other extreme, a central bank could rely primarily on reducing the balance sheet, while keeping policy rates unchanged in the near term.\n\nThe question is whether there are circumstances in which the choice of normalization strategies, which are similarly effective in achieving domestic mandates, might matter for the global economy. Where the two approaches have entirely equivalent effects, the central bank could freely substitute between them without changing the composition of home demand, and net exports, the exchange rate, and foreign output would also be unaffected.\n\nConversely, under different assumptions about the transmission channels of monetary policy, alternative approaches to normalization can have quite different implications for foreign economies. Most prominently, the exchange rate may be more sensitive to the path of short term rates than to balance sheet adjustments, as some research suggests.4 Although several papers using an event study approach find on balance little disparity in the exchange rate sensitivity to short-term compared to long-term interest rates, this lack of empirical consensus may simply reflect the difficulty of disentangling changes in short-term and longer-term interest rates, which are highly correlated.5\n\nIndeed, the greater sensitivity of exchange rates to expected short-term interest rates than to term premiums was a key rationale behind the Operation Twist strategy in the early 1960s.6 Under Operation Twist, the Federal Reserve and the Treasury made large-scale purchases of longer-term Treasury securities to drive down yields and stimulate the economy, which was suffering from an unemployment rate of nearly 7 percent. This policy was combined with a modest increase in short-term interest rates intended to alleviate the capital outflow pressures that threatened the sustainability of the Bretton Woods global monetary system. Ultimately, this policy mix did succeed in reducing long-term interest rates, and also contributed to a reduction in private capital outflows that relieved pressure on U.S. international reserves, at least for a time.\n\nLet's turn to a simulation of a highly stylized model to explore how a greater sensitivity of the exchange rate to conventional policy relative to balance sheet actions can make a difference in terms of cross-border transmission. In particular, let's assume a 100-basis-point rise in long-term yields coming from the conventional channel of higher policy rates has double the effect on the exchange rate as a 100 basis point rise in yields coming from higher term premiums.7 If a large country, which is already at potential, experiences a favorable domestic demand shock, it would need to tighten monetary policy to return output to potential. If the central bank chooses to use the short-term interest rate as its active policy tool, and keeps its balance sheet on hold, the current and expected path of short-term interest rates rises, putting upward pressure on long-term bond yields and causing the real exchange rate to appreciate. The stronger currency coupled with some initial expansion of domestic demand in turn cause a deterioration in real net exports.\n\nTurning to the effects abroad, the decline in domestic real net exports corresponds to an increase in foreign net exports, which will tend to boost foreign GDP, other things being equal. How this affects a particular foreign economy will depend on its circumstances and the corresponding policy response of the foreign central bank. In the case where the foreign economy is pinned at the effective lower bound, the increase in net exports will provide a welcome boost to aggregate demand. By contrast, if foreign output is already near potential, the foreign central bank will need to respond by tightening policy in order to keep its economy in balance.\n\nNow, let's instead consider tightening through the balance sheet. If the same amount of policy tightening in the country experiencing a positive demand shock is achieved exclusively through a reduction in the balance sheet, while keeping the policy rate unchanged, the exchange rate would appreciate to a smaller degree, reflecting the lower assumed sensitivity of the exchange rate to the term premium than to policy rates. Net exports would decline by less--reflecting both the smaller exchange rate appreciation and the smaller rise in domestic demand--and similarly this would result in smaller cross-border spillovers to foreign GDP.\n\nThus, for a foreign economy that is at the effective lower bound, tightening in the home country through balance-sheet policy will be less welcome than through short-term rates. The foreign economy will experience less exchange rate depreciation, and so less of a boost to net exports. In addition, the stimulus to the foreign economy could be further diluted to the extent that the balance sheet policy boosted term premiums on its long-term bonds and hence tightened financial conditions, although this effect has not been built into the simulation model. By contrast, for a foreign economy that is close to potential, adjustment through the balance sheet in the home country will mean less of a need for the foreign central bank to respond by tightening policy than under home country adjustment through conventional policy.\n\nSo far, we have considered the case of central banks with freely floating exchange rates and well-anchored inflation expectations. What about central banks with managed exchange rates or weakly anchored inflation expectations? To keep the analysis simple, let's assume a foreign central bank aims to completely stabilize its exchange rate vis-à-vis a core country. Let's again consider circumstances in which the core country experiences a positive demand shock that calls for policy tightening. Although the pegging economy is likely to experience spillovers under either approach to normalization in the core country, the spillovers are likely to be greater when the core country tightens through the policy rate. The tightening in the core country will compel the country that is fixing its exchange rate to tighten policy in sync and the core country's currency will rise more against its trading partners with conventional tightening, leading to greater effective appreciation of the pegging country's currency as well. Although the pegging economy will benefit somewhat from the stronger demand of the core country, that benefit is likely to be outweighed by the adverse effects of a tightening of domestic monetary policy when domestic conditions would not otherwise call for it. Such considerations may have played a role in the market dynamics experienced by China as discussions about initiating rate hikes progressed in the United States in the second half of 2015 and early 2016.8\n\nNext let's explore alternative approaches to policy normalization by countries facing a similar need to tighten. This question is timely; with synchronous expansions now underway, we may be approaching a turning point before too long. In particular, let's consider the case when two large countries, which are assumed identical for the sake of simplicity, experience the same positive shock to domestic demand. Under these assumptions, if both economies were to choose the same normalization strategy--putting primary reliance on either the balance sheet or short-term interest rates--the implications for the exchange rate and net exports are the same: In both cases, the exchange rate between the two countries does not change, and neither do net exports between the countries. Each central bank would adjust interest rates by the same amount--enough to offset the stimulus from the demand shock--and with interest differentials unchanged, there would be no pressure on the exchange rate between them to move.9 Of course, if there are other economies in the rest of the world that do not experience the same shock, the choice of normalization strategy does matter, similar to the analysis of spillovers from the single core country, presumably magnified by the larger combined global weight of the two economies.\n\nNow let's turn to the case in which the two central banks choose to rely on different policy tools.10 In this case, one country responds to the positive shock by hiking its policy rate to reduce output to its initial level, while the second country responds by shrinking its balance sheet. The country that relies on the policy rate to make the adjustment experiences an appreciation in the exchange rate, a deterioration in net exports and some expansion of domestic demand, while the country that chooses to rely solely on the balance sheet for tightening experiences a depreciation of its exchange rate and an increase in net exports. Thus, while both countries achieve their domestic stabilization objectives, whether the requisite policy tightening occurs through increases in policy rates or reductions in the balance sheet matters for the composition of demand, the external balance, and the exchange rate.\n\nI highlighted at the outset the commitment adopted by many leading nations to set monetary policy to achieve domestic objectives such that the exchange rate would not be a primary consideration in the setting of monetary policy. In the case that balance-sheet and conventional monetary policies have equivalent effects on both domestic spending and the exchange rate, this common principle is straightforward. But if the cross-border spillovers of reductions in the balance sheet and increases in the policy rate are not equivalent, the sequencing of policy rate and balance sheet normalization could have important implications for the exchange rate and external balance.\n\nFinally, in circumstances where a major central bank is continuing to expand its balance sheet or maintaining a large balance sheet over a sustained period, this policy would likely exert downward pressure on term premiums around the globe, especially in those foreign economies whose bonds were perceived as close substitutes. Indeed, until very recently, it had been notable how little long yields moved up in the United States even as discussions of balance sheet normalization have moved to the forefront. This likely reflects at least in part the expectation that ongoing asset purchase programs in other advanced economies would continue holding down long-term yields globally. The tide seems to have turned in recent weeks, as long yields in the U.S. have increased notably on market perceptions that foreign officials are beginning to deliberate their own normalization strategies.\n\nI have used a simple stylized model to illustrate circumstances in which the choice of normalization strategies adopted by major central banks can potentially be quite consequential. If anything, the analysis presented here serves to highlight the importance of research assessing this question from both an empirical and theoretical perspective.\n\nLet me conclude by returning to the policy choices facing central banks. The Federal Reserve chose to remove accommodation initially through increases in the federal funds rate. In light of recent policy moves, I consider normalization of the federal funds rate to be well under way. If the data continue to confirm a strong labor market and firming economic activity, I believe it would be appropriate relatively soon to commence the gradual and predictable process of allowing the balance sheet to run off.\n\nOnce that process begins, I will want to assess the inflation process closely before making a determination on further adjustments to the federal funds rate in light of the recent softness in core PCE (personal consumption expenditures) inflation. In my view, the neutral level of the federal funds rate is likely to remain close to zero in real terms over the medium term. If that is the case, we would not have much more additional work to do on moving to a neutral stance. I will want to monitor inflation developments carefully, and to move cautiously on further increases in the federal funds rate, so as to help guide inflation back up around our symmetric target.\n\nMeanwhile, in recent days, we have begun to hear acknowledgement from other major central banks that they too are seeing conditions that suggest policy normalization could be on the table before too long, against the backdrop of a brighter global outlook. As I just discussed, the pace and timing of how central banks around the world proceed with normalization, and the importance of balance sheet policy relative to changes in short term rates in these normalization plans, could have important implications for exchange rates and financial conditions globally.\n\nAppendix: Description of Stylized Model and Simulation Results\n\nA. Model Description\nThe model is a stylized open economy model that includes two symmetric countries linked through trade flows. The model is specified in real terms under the implicit assumption that inflation is constant (so that real and nominal variables move by the same amount). Moreover, the model abstracts from any financial linkages between the two economies, including the possibility that monetary policy actions in one country could directly affect yields in the other (e.g., through portfolio balance channels), though such effects are clearly important empirically.\n\nThe two countries include a \"Home\" (H) county and a \"Foreign\" (F) country of equal size. Variables in the foreign country are denoted with an asterisk. In each country, the national accounting identity specifies that output,\ny\n, is equal to the sum of absorption\nd\nand net exports\nnx\n, that is:\n\ny=d+nx,\ny\n∗\n=\nd\n∗\n−nx,\n\nwhere the second equation incorporates the global resource constraint that\nnx+\nnx\n∗\n=0\n. Here output (\ny\n) and absorption (\nd\n) are expressed in percent deviation from their respective steady states, while net exports are expressed as share of output, and are equal to zero in the steady state (that is, prior to any shocks).\n\nHome and foreign absorption depend on long-term interest rates according to the following expressions:\n\nd=−σ(rc+ru)+u,\nd\n∗\n=−σ(\nrc\n∗\n+\nru\n∗\n)+\nu\n∗\n,\n\nHere\nrc\nis the component of long-term interest rates that is driven by conventional monetary policy,\nru\nis the component of long-term interest rates that is driven by unconventional monetary policy, and\nu\nis an exogenous aggregate demand shock (with autocorrelation given by\nρ\n). These interest rate components are assumed to have identical effects on aggregate demand, with the parameter\nσ\ndetermining the sensitivity of aggregate demand to either component (n.b., interest rates are expressed in percentage points deviation from the steady state).\n\nNet exports are assumed to fall if the real exchange rate (\ne\n) rises/appreciates, and also if domestic demand is higher relative to foreign demand (since this boost imports). Thus:\n\nnx=−ηe−α(d−\nd\n∗\n)\n\nwhere\nη\nis the elasticity of net exports with respect to the exchange rate, and\nα\nis the elasticity of net exports to the differential between home and foreign absorption. The real exchange rate is expressed in percent deviation from the steady state.\n\nThe exchange rate is determined according to an interest rate parity condition which implies that the exchange rate appreciates when domestic interest rates are higher than foreign interest rates, with elasticities (\nϕ\nc\nand\nϕ\nu\n) that can differ depending on whether interest rate movements are driven by conventional or unconventional policy:\n\ne=\nϕ\nc\n(rc−\nrc\n∗\n)+\nϕ\nu\n(ru−\nru\n∗\n).\n\nThe model is closed by specifying the behavior of the monetary authority. We assume that the monetary authority can adjust either the interest rate associated with conventional policy (\nrc\n), or the interest rate linked to balance sheet actions (\nru\n), or both, to affect output (its goal variable). The conventional feedback rule is thus:\n\nrc=\nγ\nc\ny,\nrc\n∗\n=\nγ\n∗\nc\ny\n∗\n,\n\nwhereas the unconventional feedback rule is:\n\nru=\nγ\nu\ny\nru\n∗\n=\nγ\n∗\nu\ny\n∗\n.\n\nThe system above contains 10 equations in 10 endogenous variables (\ny\n,\ny\n∗\n,\nd\n,\nd\n∗\n,\nnx\n,\ne\n,\nrc\n,\nrc\n∗\n,\nru\n,\nru\n∗\n), as well two shocks,\nu\nand\nu\n∗\n, that can move GDP, its components, exchange rates, and interest rates.\n\nB. Simulation Results\nFigures 1 and 2 show the results of simulating the model under alternative assumptions about the shocks and monetary policy reaction. In each case, the economy starts in steady state with all variables at zero and experiences a demand shock in period 1 that dies out with an autocorrelation\nρ\nof\n0.95\n. All parameter values are reported in Table 1.\n\nFigure 1. Home Demand Shock\nFigure 1 illustrates the case of a favorable demand shock in the home country. The solid lines illustrate the case when Home uses the short-term interest rate as its active policy tool, and keeps its balance sheet on hold, consistent with a desire to delay balance sheet normalization.\n\nThe policy reaction is calibrated to be sufficiently aggressive that home GDP always remains at baseline (see column 2 of Table 1). The higher policy rate path (that is, higher\nrc\n) causes the long-term interest rate (panel A) to rise, which in turn induces the real exchange rate to appreciate (panel B). The stronger currency and an expansion in domestic absorption (panel C) causes a deterioration in net exports (panel D). At the end of the period shown, domestic demand has nearly returned to baseline, while net exports are just a bit below baseline--consistent with Home country's GDP remaining at baseline (panel E). Because foreign monetary policy rates is assumed to remain on hold, foreign GDP (panel F) rises by the improvement in its net exports (that is, by the mirror image of panel D, given that foreign domestic absorption is unchanged).\n\nThe dashed lines illustrate the case of a favorable demand shock in the Home country when the central bank opts to tighten exclusively through reducing its balance sheet (again, by enough to keep output at potential--see column 3 of Table 1). Long-term interest rates (panel A) rise in response, but the exchange rate appreciates less in this case (panel B), reflecting the lower assumed sensitivity of the exchange rate to unconventional monetary policy actions (\nϕ\nu\n<\nϕ\nc\n). Net exports decline (panel D) by less--reflecting both the smaller exchange rate appreciation and a smaller rise in absorption (panel C)--which translates into less of a boost to foreign GDP (panel F) than when the home country adjusts through conventional policy.\n\nFigure 2. Common Demand Shock, Asymmetric Policy Tightening across Countries\nFigure 2 shows a simulation in which the demand shock is assumed to be common across countries (\nu=\nu\n∗\n). The home country is assumed to pursue a policy of actively adjusting its policy rate, while the foreign Country is assumed to rely exclusively on normalizing through the balance sheet. In each case, the central banks of the two countries tighten policy aggressively enough to keep output at potential (see the parameter settings in column 4 of Table 1).\n\nAs policy rates rise in the home country (panel A) and the exchange rate is more sensitive to policy rates than to the balance sheet, the home country's exchange rate (panel B) appreciates, while its net exports (panel D) decline. Although GDP remains at baseline in each country (panels E and F) given our assumption that monetary policy keeps output at potential (which is unchanged), the alternative policy normalization choices clearly have important effects--even under a common shock--on both exchange rates and the composition of demand in each country. In particular, because exchange rates in the foreign country are less sensitive to balance sheet than to interest rate policy, the foreign central bank must enact a relatively larger interest rate tightening in order to keep its GDP at potential.\n\nReferences\nAlon, Titan, and Eric Swanson (2011). \"Operation Twist and the Effect of Large-Scale Asset Purchases,\" FRBSF Economic Letter 2011-13. San Francisco: Federal Reserve Bank of San Francisco, April 25.\n\nBowman, David, Juan M. Londono, and Horacio Sapriza (2015), \"U.S. Unconventional Monetary Policy and Transmission to Emerging Market Economies,\" Journal of International Money and Finance, vol. 55 (July), pp. 27-59.\n\nBrainard, Lael (2015a). \"Unconventional Monetary Policy and Cross-Border Spillovers,\" speech delivered at \"Unconventional Monetary and Exchange Rate Policies,\" the 16th International Monetary Fund Jacques Polak Research Conference, sponsored by the International Monetary Fund, Washington, November 6.\n\nBrainard, Lael (2015b), \"Normalizing Monetary Policy When the Neutral Interest Rate is Low,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford, Calif., December 1.\n\nFerrari, Massimo, Jonathan Kearns, and Andreas Schrimpf (2016). \"Monetary Shocks at High-Frequency and Their Changing FX Transmission around the Globe,\" August.\n\nGlick, Reuven, and Sylvain Leduc, (2015). \"Unconventional Monetary Policy and the Dollar: Conventional Signs, Unconventional Magnitudes (PDF),\" Federal Reserve Bank of San Francisco Working Paper Series 2015-18, November.\n\nHofmann, Boris, Ilhyock Shim, and Hyun Song Shin (2016). \"Risk-Taking Channel of Currency Appreciation (PDF),\" BIS Working Paper No. 538. Basel, Switzerland: Bank for International Settlements, January (revised May 2017).\n\nModigliani, Franco, and Richard Sutch (1966). \"Innovations in Interest Rate Policy,\" American Economic Review, vol. 56 (March), pp. 178-97.\n\nRey, Hélène (2014). \"International Channels of Transmission of Monetary Policy and the Mundellian Trilemma (PDF),\" paper presented at the 15th Jacques Polak Annual Research Conference, sponsored by the International Monetary Fund, Washington, November 13-14.\n\nRoss, Myron H. (1966), \"'Operation Twist': A Mistaken Policy?\" Journal of Political Economy, vol. 74 (April), pp. 195-99.\n\nStavrakeva, Vania, and Jenny Tang (2016). \"Exchange Rates and the Yield Curve,\" Research Department Working Papers 16-21. Boston: Federal Reserve Bank of Boston, April.\n\nStein, Jerome L. (1965). \"International Short-Term Capital Movements,\" American Economic Review, vol. 55 (March), pp. 40-66.\n\nSwanson, Eric T. (2017). \"Measuring the Effects of Federal Reserve Forward Guidance and Asset Purchases on Financial Markets,\" NBER Working Paper 23311. Washington: National Bureau of Economic Research, April (revised June).\n\n1. I am grateful to John Ammer, Bastian von Beschwitz, Christopher Erceg, Matteo Iacoviello, and John Roberts for their assistance in preparing this text. The remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. The new commitment stated: \"We reaffirm that our fiscal and monetary policies have been and will remain oriented towards meeting our respective domestic objectives using domestic instruments, and that we will not target exchange rates.\" See Group of Seven (2013), \"Statement by G7 Finance Ministers and Central Bank Governors,\" February 12, paragraph 1. The corresponding Group of Twenty statement included the new commitment: \"We will not target our exchange rates for competitive purposes.\" See Group of Twenty (2013), \"Communiqué of Meeting of G20 Finance Ministers and Central Bank Governors,\" February 16, paragraph 5. Return to text\n\n3. See, for example, Board of Governors of the Federal Reserve System (2015), \"Federal Reserve Issues FOMC Statement,\" press release, December 16; and Brainard (2015b). Return to text\n\n4. See, for instance, Stavrakeva and Tang (2016). Return to text\n\n5. See Glick and Leduc (2015), Ferrari, Kearns, and Schrimpf (2016), and Swanson (2017); Swanson attempts to identify separately the effects of forward guidance and asset purchases. Return to text\n\n6. See Ross (1966), Modigliani and Sutch (1966), Stein (1965), and Alon and Swanson (2011). Return to text\n\n7. This simulation is shown in figure 1 in the appendix. The stylized model is composed of two identical countries that are linked through trade flows. The model is calibrated so that either type of policy action keeps the home country's GDP at baseline. Return to text\n\n8. See Brainard (2015a). A number of recent studies have considered financial spillovers to EMEs, including Rey (2014) and Bowman, Londono, and Sapriza (2015). The analysis of Hofmann, Shim, and Shin (2016) suggests that EMEs may be hurt more if their banks or nonfinancial corporations have relatively large dollar liabilities, as the larger dollar appreciation associated with the policy rate tool would precipitate greater EME balance sheet deterioration in this case. Return to text\n\n9. In this simple example, in which the two countries are hit by identical shocks, the offset in spillovers between the two economies will be complete. If one country faces a larger aggregate demand shock than the other, then the situation becomes more like the one-country case we examined before, the policy adjustments lead to spillovers of different magnitudes, and the offset will be partial. Return to text\n\n10. This simulation is shown in figure 2 in the appendix. Return to text"
    },
    {
        "title": "Cross-Border Spillovers of Balance Sheet Normalization",
        "date": "July 11, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170711a.htm",
        "content": "July 11, 2017\n\nGovernor Lael Brainard\n\nAt \"Normalizing Central Banks' Balance Sheets: What Is the New Normal?\" a conference sponsored by Columbia University’s School of International and Public Affairs and the Federal Reserve Bank of New York, New York, New York\n\nWhen the central banks in many advanced economies embarked on unconventional monetary policy, it raised concerns that there might be differences in the cross-border transmission of unconventional relative to conventional monetary policy.1 These concerns were sufficient to warrant a special Group of Seven (G-7) statement in 2013 establishing ground rules to address possible exchange rate effects of the changing composition of monetary policy.2\n\nToday the world confronts similar questions in reverse. In the United States, in my assessment, normalization of the federal funds rate is now well under way, and the Federal Reserve is advancing plans to allow the balance sheet to run off at a gradual and predictable pace. And for the first time in many years, the global economy is experiencing synchronous growth, and authorities in the euro area and the United Kingdom are beginning to discuss the time when the need for monetary accommodation will diminish.\n\nUnlike in previous tightening cycles, many central banks currently have two tools for removing accommodation. They can therefore pursue alternative normalization strategies--first seeking to guide policy rates higher before initiating balance sheet runoff, as in the United States, or instead starting to shrink the balance sheet before initiating a tightening of short-term rates, or undertaking both in tandem. Shrinking the balance sheet and raising the policy rate can both contribute to achieving the domestic goals of monetary policy, but it is an open question whether alternative normalization approaches might have materially different implications for the composition of demand and for cross-border spillovers, including through exchange rates and other financial channels.\n\nBefore discussing the cross-border effects of normalization, it is worth noting that the two tools for removing accommodation--raising policy rates and reducing central bank balance sheets--appear to affect domestic output and inflation in a qualitatively similar way. This means that central banks can substitute between raising the policy rate and shrinking the balance sheet to remove accommodation, just as both were used to support the recovery following the Great Recession.\n\nInsofar as a range of approaches is likely to be consistent with achieving a central bank's domestic objectives, the choice of normalization strategy may be influenced by other considerations, including the ease of implementing and communicating policy changes, or the desire to minimize possible credit market distortions associated with the balance sheet. In the case of the Federal Reserve, the Federal Open Market Committee (FOMC) decided to delay balance sheet normalization until the federal funds rate had reached a high enough level to enable it to be cut materially if economic conditions deteriorate, thus guarding against the risk of returning to the effective lower bound (ELB) in an environment with a historically low neutral interest rate.3 The greater familiarity and past experience with the federal funds rate also weighed in favor of this instrument initially. Separately, for those central banks that, unlike the Federal Reserve, moved to negative interest rates, there may be special considerations associated with raising policy rates back into positive territory.\n\nOne question that naturally arises is whether the major central banks' normalization plans may have material implications for cross-border spillovers--an important issue that until very recently had received scant attention. This question is a natural extension of the literature examining the cross-border spillovers of the unconventional policy actions taken by the major central banks to provide accommodation.\n\nAlthough this literature suggests there are good reasons to expect broadly similar cross-border spillovers from tightening through policy rates as through balance sheet runoff, the effects may not be exactly equivalent. The balance sheet might affect certain aspects of the economy and financial markets differently than the short-term rate due to the fact that the balance sheet more directly affects term premiums on longer-term securities, while the short-term rate more directly affects money market rates. As a result, similar to the domestic effects, while the international spillovers of conventional and unconventional monetary policy may operate broadly similarly, the relative magnitude of the different channels may be sufficiently different that, on net, the two policy strategies have distinct effects. For example, as will be discussed at greater length shortly, the two strategies may have very different implications for the exchange rate. Moreover, as was evident with the European Central Bank's (ECB) asset purchases in late 2014 and early 2015, and as we have seen again in reverse in recent weeks, in addition to the standard demand and exchange rate channels, expected or actual asset purchases may have spillovers to foreign financial conditions--by lowering term premiums and the associated longer-term foreign bond yields--that are greater than conventional monetary policy.\n\nTo explore possible differences, it is useful to compare two different approaches to policy normalization, each of which is designed to have identical effects on aggregate domestic activity and thus, at least in the long run, on inflation. At one extreme, a central bank could opt to tighten primarily through conventional policy hikes, while maintaining the balance sheet by reinvesting the proceeds of maturing assets. At the other extreme, a central bank could rely primarily on reducing the balance sheet, while keeping policy rates unchanged in the near term.\n\nThe question is whether there are circumstances in which the choice of normalization strategies, which are similarly effective in achieving domestic mandates, might matter for the global economy. Where the two approaches have entirely equivalent effects, the central bank could freely substitute between them without changing the composition of home demand, and net exports, the exchange rate, and foreign output would also be unaffected.\n\nConversely, under different assumptions about the transmission channels of monetary policy, alternative approaches to normalization can have quite different implications for foreign economies. Most prominently, the exchange rate may be more sensitive to the path of short term rates than to balance sheet adjustments, as some research suggests.4 Although several papers using an event study approach find on balance little disparity in the exchange rate sensitivity to short-term compared to long-term interest rates, this lack of empirical consensus may simply reflect the difficulty of disentangling changes in short-term and longer-term interest rates, which are highly correlated.5\n\nIndeed, the greater sensitivity of exchange rates to expected short-term interest rates than to term premiums was a key rationale behind the Operation Twist strategy in the early 1960s.6 Under Operation Twist, the Federal Reserve and the Treasury made large-scale purchases of longer-term Treasury securities to drive down yields and stimulate the economy, which was suffering from an unemployment rate of nearly 7 percent. This policy was combined with a modest increase in short-term interest rates intended to alleviate the capital outflow pressures that threatened the sustainability of the Bretton Woods global monetary system. Ultimately, this policy mix did succeed in reducing long-term interest rates, and also contributed to a reduction in private capital outflows that relieved pressure on U.S. international reserves, at least for a time.\n\nLet's turn to a simulation of a highly stylized model to explore how a greater sensitivity of the exchange rate to conventional policy relative to balance sheet actions can make a difference in terms of cross-border transmission. In particular, let's assume a 100-basis-point rise in long-term yields coming from the conventional channel of higher policy rates has double the effect on the exchange rate as a 100 basis point rise in yields coming from higher term premiums.7 If a large country, which is already at potential, experiences a favorable domestic demand shock, it would need to tighten monetary policy to return output to potential. If the central bank chooses to use the short-term interest rate as its active policy tool, and keeps its balance sheet on hold, the current and expected path of short-term interest rates rises, putting upward pressure on long-term bond yields and causing the real exchange rate to appreciate. The stronger currency coupled with some initial expansion of domestic demand in turn cause a deterioration in real net exports.\n\nTurning to the effects abroad, the decline in domestic real net exports corresponds to an increase in foreign net exports, which will tend to boost foreign GDP, other things being equal. How this affects a particular foreign economy will depend on its circumstances and the corresponding policy response of the foreign central bank. In the case where the foreign economy is pinned at the effective lower bound, the increase in net exports will provide a welcome boost to aggregate demand. By contrast, if foreign output is already near potential, the foreign central bank will need to respond by tightening policy in order to keep its economy in balance.\n\nNow, let's instead consider tightening through the balance sheet. If the same amount of policy tightening in the country experiencing a positive demand shock is achieved exclusively through a reduction in the balance sheet, while keeping the policy rate unchanged, the exchange rate would appreciate to a smaller degree, reflecting the lower assumed sensitivity of the exchange rate to the term premium than to policy rates. Net exports would decline by less--reflecting both the smaller exchange rate appreciation and the smaller rise in domestic demand--and similarly this would result in smaller cross-border spillovers to foreign GDP.\n\nThus, for a foreign economy that is at the effective lower bound, tightening in the home country through balance-sheet policy will be less welcome than through short-term rates. The foreign economy will experience less exchange rate depreciation, and so less of a boost to net exports. In addition, the stimulus to the foreign economy could be further diluted to the extent that the balance sheet policy boosted term premiums on its long-term bonds and hence tightened financial conditions, although this effect has not been built into the simulation model. By contrast, for a foreign economy that is close to potential, adjustment through the balance sheet in the home country will mean less of a need for the foreign central bank to respond by tightening policy than under home country adjustment through conventional policy.\n\nSo far, we have considered the case of central banks with freely floating exchange rates and well-anchored inflation expectations. What about central banks with managed exchange rates or weakly anchored inflation expectations? To keep the analysis simple, let's assume a foreign central bank aims to completely stabilize its exchange rate vis-à-vis a core country. Let's again consider circumstances in which the core country experiences a positive demand shock that calls for policy tightening. Although the pegging economy is likely to experience spillovers under either approach to normalization in the core country, the spillovers are likely to be greater when the core country tightens through the policy rate. The tightening in the core country will compel the country that is fixing its exchange rate to tighten policy in sync and the core country's currency will rise more against its trading partners with conventional tightening, leading to greater effective appreciation of the pegging country's currency as well. Although the pegging economy will benefit somewhat from the stronger demand of the core country, that benefit is likely to be outweighed by the adverse effects of a tightening of domestic monetary policy when domestic conditions would not otherwise call for it. Such considerations may have played a role in the market dynamics experienced by China as discussions about initiating rate hikes progressed in the United States in the second half of 2015 and early 2016.8\n\nNext let's explore alternative approaches to policy normalization by countries facing a similar need to tighten. This question is timely; with synchronous expansions now underway, we may be approaching a turning point before too long. In particular, let's consider the case when two large countries, which are assumed identical for the sake of simplicity, experience the same positive shock to domestic demand. Under these assumptions, if both economies were to choose the same normalization strategy--putting primary reliance on either the balance sheet or short-term interest rates--the implications for the exchange rate and net exports are the same: In both cases, the exchange rate between the two countries does not change, and neither do net exports between the countries. Each central bank would adjust interest rates by the same amount--enough to offset the stimulus from the demand shock--and with interest differentials unchanged, there would be no pressure on the exchange rate between them to move.9 Of course, if there are other economies in the rest of the world that do not experience the same shock, the choice of normalization strategy does matter, similar to the analysis of spillovers from the single core country, presumably magnified by the larger combined global weight of the two economies.\n\nNow let's turn to the case in which the two central banks choose to rely on different policy tools.10 In this case, one country responds to the positive shock by hiking its policy rate to reduce output to its initial level, while the second country responds by shrinking its balance sheet. The country that relies on the policy rate to make the adjustment experiences an appreciation in the exchange rate, a deterioration in net exports and some expansion of domestic demand, while the country that chooses to rely solely on the balance sheet for tightening experiences a depreciation of its exchange rate and an increase in net exports. Thus, while both countries achieve their domestic stabilization objectives, whether the requisite policy tightening occurs through increases in policy rates or reductions in the balance sheet matters for the composition of demand, the external balance, and the exchange rate.\n\nI highlighted at the outset the commitment adopted by many leading nations to set monetary policy to achieve domestic objectives such that the exchange rate would not be a primary consideration in the setting of monetary policy. In the case that balance-sheet and conventional monetary policies have equivalent effects on both domestic spending and the exchange rate, this common principle is straightforward. But if the cross-border spillovers of reductions in the balance sheet and increases in the policy rate are not equivalent, the sequencing of policy rate and balance sheet normalization could have important implications for the exchange rate and external balance.\n\nFinally, in circumstances where a major central bank is continuing to expand its balance sheet or maintaining a large balance sheet over a sustained period, this policy would likely exert downward pressure on term premiums around the globe, especially in those foreign economies whose bonds were perceived as close substitutes. Indeed, until very recently, it had been notable how little long yields moved up in the United States even as discussions of balance sheet normalization have moved to the forefront. This likely reflects at least in part the expectation that ongoing asset purchase programs in other advanced economies would continue holding down long-term yields globally. The tide seems to have turned in recent weeks, as long yields in the U.S. have increased notably on market perceptions that foreign officials are beginning to deliberate their own normalization strategies.\n\nI have used a simple stylized model to illustrate circumstances in which the choice of normalization strategies adopted by major central banks can potentially be quite consequential. If anything, the analysis presented here serves to highlight the importance of research assessing this question from both an empirical and theoretical perspective.\n\nLet me conclude by returning to the policy choices facing central banks. The Federal Reserve chose to remove accommodation initially through increases in the federal funds rate. In light of recent policy moves, I consider normalization of the federal funds rate to be well under way. If the data continue to confirm a strong labor market and firming economic activity, I believe it would be appropriate soon to commence the gradual and predictable process of allowing the balance sheet to run off.\n\nOnce that process begins, I will want to assess the inflation process closely before making a determination on further adjustments to the federal funds rate in light of the recent softness in core PCE (personal consumption expenditures) inflation. In my view, the neutral level of the federal funds rate is likely to remain close to zero in real terms over the medium term. If that is the case, we would not have much more additional work to do on moving to a neutral stance. I will want to monitor inflation developments carefully, and to move cautiously on further increases in the federal funds rate, so as to help guide inflation back up around our symmetric target.\n\nMeanwhile, in recent days, we have begun to hear acknowledgement from other major central banks that they too are seeing conditions that suggest policy normalization could be on the table before too long, against the backdrop of a brighter global outlook. As I just discussed, the pace and timing of how central banks around the world proceed with normalization, and the importance of balance sheet policy relative to changes in short term rates in these normalization plans, could have important implications for exchange rates and financial conditions globally.\n\nAppendix: Description of Stylized Model and Simulation Results\n\nA. Model Description\nThe model is a stylized open economy model that includes two symmetric countries linked through trade flows. The model is specified in real terms under the implicit assumption that inflation is constant (so that real and nominal variables move by the same amount). Moreover, the model abstracts from any financial linkages between the two economies, including the possibility that monetary policy actions in one country could directly affect yields in the other (e.g., through portfolio balance channels), though such effects are clearly important empirically.\n\nThe two countries include a \"Home\" (H) county and a \"Foreign\" (F) country of equal size. Variables in the foreign country are denoted with an asterisk. In each country, the national accounting identity specifies that output,\ny\n, is equal to the sum of absorption\nd\nand net exports\nnx\n, that is:\n\ny=d+nx,\ny\n∗\n=\nd\n∗\n−nx,\n\nwhere the second equation incorporates the global resource constraint that\nnx+\nnx\n∗\n=0\n. Here output (\ny\n) and absorption (\nd\n) are expressed in percent deviation from their respective steady states, while net exports are expressed as share of output, and are equal to zero in the steady state (that is, prior to any shocks).\n\nHome and foreign absorption depend on long-term interest rates according to the following expressions:\n\nd=−σ(rc+ru)+u,\nd\n∗\n=−σ(\nrc\n∗\n+\nru\n∗\n)+\nu\n∗\n,\n\nHere\nrc\nis the component of long-term interest rates that is driven by conventional monetary policy,\nru\nis the component of long-term interest rates that is driven by unconventional monetary policy, and\nu\nis an exogenous aggregate demand shock (with autocorrelation given by\nρ\n). These interest rate components are assumed to have identical effects on aggregate demand, with the parameter\nσ\ndetermining the sensitivity of aggregate demand to either component (n.b., interest rates are expressed in percentage points deviation from the steady state).\n\nNet exports are assumed to fall if the real exchange rate (\ne\n) rises/appreciates, and also if domestic demand is higher relative to foreign demand (since this boost imports). Thus:\n\nnx=−ηe−α(d−\nd\n∗\n)\n\nwhere\nη\nis the elasticity of net exports with respect to the exchange rate, and\nα\nis the elasticity of net exports to the differential between home and foreign absorption. The real exchange rate is expressed in percent deviation from the steady state.\n\nThe exchange rate is determined according to an interest rate parity condition which implies that the exchange rate appreciates when domestic interest rates are higher than foreign interest rates, with elasticities (\nϕ\nc\nand\nϕ\nu\n) that can differ depending on whether interest rate movements are driven by conventional or unconventional policy:\n\ne=\nϕ\nc\n(rc−\nrc\n∗\n)+\nϕ\nu\n(ru−\nru\n∗\n).\n\nThe model is closed by specifying the behavior of the monetary authority. We assume that the monetary authority can adjust either the interest rate associated with conventional policy (\nrc\n), or the interest rate linked to balance sheet actions (\nru\n), or both, to affect output (its goal variable). The conventional feedback rule is thus:\n\nrc=\nγ\nc\ny,\nrc\n∗\n=\nγ\n∗\nc\ny\n∗\n,\n\nwhereas the unconventional feedback rule is:\n\nru=\nγ\nu\ny\nru\n∗\n=\nγ\n∗\nu\ny\n∗\n.\n\nThe system above contains 10 equations in 10 endogenous variables (\ny\n,\ny\n∗\n,\nd\n,\nd\n∗\n,\nnx\n,\ne\n,\nrc\n,\nrc\n∗\n,\nru\n,\nru\n∗\n), as well two shocks,\nu\nand\nu\n∗\n, that can move GDP, its components, exchange rates, and interest rates.\n\nB. Simulation Results\nFigures 1 and 2 show the results of simulating the model under alternative assumptions about the shocks and monetary policy reaction. In each case, the economy starts in steady state with all variables at zero and experiences a demand shock in period 1 that dies out with an autocorrelation\nρ\nof\n0.95\n. All parameter values are reported in Table 1.\n\nFigure 1. Home Demand Shock\nFigure 1 illustrates the case of a favorable demand shock in the home country. The solid lines illustrate the case when Home uses the short-term interest rate as its active policy tool, and keeps its balance sheet on hold, consistent with a desire to delay balance sheet normalization.\n\nThe policy reaction is calibrated to be sufficiently aggressive that home GDP always remains at baseline (see column 2 of Table 1). The higher policy rate path (that is, higher\nrc\n) causes the long-term interest rate (panel A) to rise, which in turn induces the real exchange rate to appreciate (panel B). The stronger currency and an expansion in domestic absorption (panel C) causes a deterioration in net exports (panel D). At the end of the period shown, domestic demand has nearly returned to baseline, while net exports are just a bit below baseline--consistent with Home country's GDP remaining at baseline (panel E). Because foreign monetary policy rates is assumed to remain on hold, foreign GDP (panel F) rises by the improvement in its net exports (that is, by the mirror image of panel D, given that foreign domestic absorption is unchanged).\n\nThe dashed lines illustrate the case of a favorable demand shock in the Home country when the central bank opts to tighten exclusively through reducing its balance sheet (again, by enough to keep output at potential--see column 3 of Table 1). Long-term interest rates (panel A) rise in response, but the exchange rate appreciates less in this case (panel B), reflecting the lower assumed sensitivity of the exchange rate to unconventional monetary policy actions (\nϕ\nu\n<\nϕ\nc\n). Net exports decline (panel D) by less--reflecting both the smaller exchange rate appreciation and a smaller rise in absorption (panel C)--which translates into less of a boost to foreign GDP (panel F) than when the home country adjusts through conventional policy.\n\nFigure 2. Common Demand Shock, Asymmetric Policy Tightening across Countries\nFigure 2 shows a simulation in which the demand shock is assumed to be common across countries (\nu=\nu\n∗\n). The home country is assumed to pursue a policy of actively adjusting its policy rate, while the foreign Country is assumed to rely exclusively on normalizing through the balance sheet. In each case, the central banks of the two countries tighten policy aggressively enough to keep output at potential (see the parameter settings in column 4 of Table 1).\n\nAs policy rates rise in the home country (panel A) and the exchange rate is more sensitive to policy rates than to the balance sheet, the home country's exchange rate (panel B) appreciates, while its net exports (panel D) decline. Although GDP remains at baseline in each country (panels E and F) given our assumption that monetary policy keeps output at potential (which is unchanged), the alternative policy normalization choices clearly have important effects--even under a common shock--on both exchange rates and the composition of demand in each country. In particular, because exchange rates in the foreign country are less sensitive to balance sheet than to interest rate policy, the foreign central bank must enact a relatively larger interest rate tightening in order to keep its GDP at potential.\n\nReferences\nAlon, Titan, and Eric Swanson (2011). \"Operation Twist and the Effect of Large-Scale Asset Purchases,\" FRBSF Economic Letter 2011-13. San Francisco: Federal Reserve Bank of San Francisco, April 25.\n\nBowman, David, Juan M. Londono, and Horacio Sapriza (2015), \"U.S. Unconventional Monetary Policy and Transmission to Emerging Market Economies,\" Journal of International Money and Finance, vol. 55 (July), pp. 27-59.\n\nBrainard, Lael (2015a). \"Unconventional Monetary Policy and Cross-Border Spillovers,\" speech delivered at \"Unconventional Monetary and Exchange Rate Policies,\" the 16th International Monetary Fund Jacques Polak Research Conference, sponsored by the International Monetary Fund, Washington, November 6.\n\nBrainard, Lael (2015b), \"Normalizing Monetary Policy When the Neutral Interest Rate is Low,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford, Calif., December 1.\n\nFerrari, Massimo, Jonathan Kearns, and Andreas Schrimpf (2016). \"Monetary Shocks at High-Frequency and Their Changing FX Transmission around the Globe,\" August.\n\nGlick, Reuven, and Sylvain Leduc, (2015). \"Unconventional Monetary Policy and the Dollar: Conventional Signs, Unconventional Magnitudes (PDF),\" Federal Reserve Bank of San Francisco Working Paper Series 2015-18, November.\n\nHofmann, Boris, Ilhyock Shim, and Hyun Song Shin (2016). \"Risk-Taking Channel of Currency Appreciation (PDF),\" BIS Working Paper No. 538. Basel, Switzerland: Bank for International Settlements, January (revised May 2017).\n\nModigliani, Franco, and Richard Sutch (1966). \"Innovations in Interest Rate Policy,\" American Economic Review, vol. 56 (March), pp. 178-97.\n\nRey, Hélène (2014). \"International Channels of Transmission of Monetary Policy and the Mundellian Trilemma (PDF),\" paper presented at the 15th Jacques Polak Annual Research Conference, sponsored by the International Monetary Fund, Washington, November 13-14.\n\nRoss, Myron H. (1966), \"'Operation Twist': A Mistaken Policy?\" Journal of Political Economy, vol. 74 (April), pp. 195-99.\n\nStavrakeva, Vania, and Jenny Tang (2016). \"Exchange Rates and the Yield Curve,\" Research Department Working Papers 16-21. Boston: Federal Reserve Bank of Boston, April.\n\nStein, Jerome L. (1965). \"International Short-Term Capital Movements,\" American Economic Review, vol. 55 (March), pp. 40-66.\n\nSwanson, Eric T. (2017). \"Measuring the Effects of Federal Reserve Forward Guidance and Asset Purchases on Financial Markets,\" NBER Working Paper 23311. Washington: National Bureau of Economic Research, April (revised June).\n\n1. I am grateful to John Ammer, Bastian von Beschwitz, Christopher Erceg, Matteo Iacoviello, and John Roberts for their assistance in preparing this text. The remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. The new commitment stated: \"We reaffirm that our fiscal and monetary policies have been and will remain oriented towards meeting our respective domestic objectives using domestic instruments, and that we will not target exchange rates.\" See Group of Seven (2013), \"Statement by G7 Finance Ministers and Central Bank Governors,\" February 12, paragraph 1. The corresponding Group of Twenty statement included the new commitment: \"We will not target our exchange rates for competitive purposes.\" See Group of Twenty (2013), \"Communiqué of Meeting of G20 Finance Ministers and Central Bank Governors,\" February 16, paragraph 5. Return to text\n\n3. See, for example, Board of Governors of the Federal Reserve System (2015), \"Federal Reserve Issues FOMC Statement,\" press release, December 16; and Brainard (2015b). Return to text\n\n4. See, for instance, Stavrakeva and Tang (2016). Return to text\n\n5. See Glick and Leduc (2015), Ferrari, Kearns, and Schrimpf (2016), and Swanson (2017); Swanson attempts to identify separately the effects of forward guidance and asset purchases. Return to text\n\n6. See Ross (1966), Modigliani and Sutch (1966), Stein (1965), and Alon and Swanson (2011). Return to text\n\n7. This simulation is shown in figure 1 in the appendix. The stylized model is composed of two identical countries that are linked through trade flows. The model is calibrated so that either type of policy action keeps the home country's GDP at baseline. Return to text\n\n8. See Brainard (2015a). A number of recent studies have considered financial spillovers to EMEs, including Rey (2014) and Bowman, Londono, and Sapriza (2015). The analysis of Hofmann, Shim, and Shin (2016) suggests that EMEs may be hurt more if their banks or nonfinancial corporations have relatively large dollar liabilities, as the larger dollar appreciation associated with the policy rate tool would precipitate greater EME balance sheet deterioration in this case. Return to text\n\n9. In this simple example, in which the two countries are hit by identical shocks, the offset in spillovers between the two economies will be complete. If one country faces a larger aggregate demand shock than the other, then the situation becomes more like the one-country case we examined before, the policy adjustments lead to spillovers of different magnitudes, and the offset will be partial. Return to text\n\n10. This simulation is shown in figure 2 in the appendix. Return to text"
    },
    {
        "title": "Government Policy and Labor Productivity",
        "date": "July 06, 2017",
        "speaker": "Vice Chairman Stanley Fischer",
        "url": "https://www.federalreserve.gov/newsevents/speech/fischer20170706a.htm",
        "content": "July 06, 2017\n\nVice Chairman Stanley Fischer\n\nAt the \"Washington Transformation? Politics, Policies, Prospects,\" a forum sponsored by the Summer Institute of Martha’s Vineyard Hebrew Center, Vineyard Haven, Massachusetts\n\nI want to talk tonight about labor productivity growth. Labor productivity is the amount of goods and services produced per hour spent on the job. Increases in labor productivity--again, that's the amount of goods and services produced per hour on the job--are a fundamental factor in determining how fast the economy grows, and how fast the average standard of living grows. And productivity growth can be influenced by government policy, about which I also want to say a few words.1\n\nLabor productivity growth varies a lot from year to year, but it is possible to discern longer historical periods with high or low productivity growth, as shown in figure 1. For example, labor productivity rose at an average annual rate of 3-1/4 percent from 1948 to 1973, whereas in the period 1974 to 2016, the average growth rate of productivity was about 1.7 percent. That is to say that, with the important exception of the information technology (IT) boom beginning in the mid-1990s, the U.S. economy has been in a low-productivity growth period since 1974. The record for the past five years has been particularly dismal.\n\nHow much does productivity growth matter? A great deal. The person who made that clear, in an article published in 1957, 60 years ago, Professor Robert Solow, is here tonight. That is a pleasure, an honor, a joy, and something of a difficulty for anyone wanting to talk about productivity and its growth in the presence of the master.\n\nThe reason the rate of productivity growth matters so much is that it is a basic determinant of the rate of growth of average income per capita over long periods.2 To understand that one needs to know only the trick of calculating how long it takes for a growing economy to double. A good rule of thumb for calculating the time it takes labor productivity (or anything else that is growing) to double can be calculated by dividing 70 by the growth rate. When labor productivity was growing at 3-1/4 percent per year--during the 25 years from 1948 to 1973--it took 22 years for labor productivity to double. Looking again at Figure 1, in the 42 years from 1974 to 2016, when labor productivity was growing on average at a rate of 1-3/4 percent, it would have taken approximately 41 years for labor productivity to double. There is a vast difference between the prospects facing the young in an economy where incomes per capita are doubling every 22 years and an economy in which incomes are on average doubling only every 41 years.\n\nNow, productivity statistics are imperfect in many respects--for example, capturing the value of the seemingly free apps we use on our smartphones is challenging. And many of us who live in the modern age cannot believe that the iPhone has not fundamentally changed our lives. It has certainly changed our lives to some extent, and there is likely some underestimation of productivity growth in the official data. But to figure out whether the current degree of data bias has reduced estimated growth, we have to ask not whether there is bias, but whether the bias has increased. To a first approximation, one could assume that the rate of bias is constant, and does not account for the estimated decline in productivity growth and that we should not dismiss the slowdown as an artifact of measurement difficulties3 That is the conclusion most researchers reach, but the data issue is not settled. As Bob Solow famously said, just before the increase in productivity growth of 1996-2003, \"the computer is everywhere except in the growth data.\" And there are serious researchers who have made serious arguments that we will soon be seeing more rapid growth in the productivity data.\n\nFactors determining productivity growth\nClearly, a key question for economic forecasters, and even more so for U.S. citizens, and indeed for the entire global economy, is whether we should anticipate a return of the more rapid productivity gains experienced in the IT boom and for the quarter century after the end of World War II, or should instead resign ourselves to tepid economic growth in future years. And a central policy issue is whether government policies can help push the economy toward a higher-productivity regime.\n\nIn this context, it is useful to think of labor productivity growth as coming from three sources, as shown in figure 2. First, greater investment by firms in tangible equipment and structures, as well as \"intangible\" investments such as software and product designs, raise labor productivity. Second, improvements in labor quality, or the capabilities of the workforce, contribute as well--through education, training, and experience. Finally, innovations yield more or better output from the same inputs--the same capital and labor--such as the introduction of the assembly line and computer-aided product design. I will consider the role that policy may play through each of these channels. It is noteworthy that most of the recent drop in productivity is due to a lower contribution from innovation, although weaker investment has played a role as well. The contribution to labor productivity from labor quality has changed very little.\n\nInnovation\nOur prospects for further significant technological innovations are hotly debated. Some observers believe that we have exhausted the low-hanging fruit on the productivity tree and, in particular, that efficiency gains from the use of IT have run their course.4 Other observers argue that we can reach fruit higher on the tree with each passing year. These observers believe that innovation yields better tools, such as 3-D printers and genetic sequencing equipment, which themselves enable further technological advances.5 For what it is worth, I believe the early signs of self-driving cars, the emergence of disease treatments based on genetics, and the falling costs for conventional and alternative energy production suggest that we are continuing to innovate, both in IT as well as in other parts of the economy. One possibility is that we are in a productivity lull while firms reorganize to exploit the latest innovations; it took decades before the full benefits of the steam engine, electrification, and computers were seen.6\n\nOne way to ensure the vigor of innovation is to support research and development (R&D), and here the recent record is mixed. As shown in figure 3, R&D spending in the United States softened during the Great Recession. R&D funded by U.S. businesses has since recovered. However, government-funded R&D as a share of gross domestic product is at the lowest level in recent history. A great deal of the \"R\" in overall R&D is government funded and not tied to a specific commercial goal. The applied research built on this basic research ultimately yields productivity gains far into the future.7 Consequently, the decline in government-funded R&D is disturbing.\n\nTo raise productivity and economic well-being, firms must adopt innovations that emerge from R&D as quickly as possible. This adjustment may occur as start-ups introduce innovation to the market, as existing innovative firms expand, or as competing firms imitate the innovators. Recent research suggests that all three of these channels, which reflect the economic dynamism of businesses, have been operating sluggishly of late: New firms are not created as often as in the past, innovative firms are not hiring or investing as aggressively as they once did, and the diffusion of innovations is weak from frontier firms to trailing firms.8\n\nIt is difficult to pinpoint specific policy actions that would address this decline in dynamism. Broadly speaking, however, government policymakers should carefully consider the effects of regulations and tax policy on the free flow of workers, capital, and ideas.\n\nInvestment\nIn recent years, the contribution to labor productivity growth from investment has declined. Business fixed investment rose roughly 2-1/2 percent per year, on average, from 2004 to 2016, compared with about 5 percent from 1996 to 2003.9 Some bright spots do exist: Capital expenditure by leading IT companies--Google, Amazon, and the like--has soared since 2010, and investment in the energy sector has returned to life. Nevertheless, firms as a whole seem reluctant to invest.\n\nThis cautious approach to investment may in part reflect uncertainty about the policy environment. By one measure, U.S. policy uncertainty was elevated for much of the recovery, subsided in 2013, and then rose again late last year, underpinned by uncertainty about policies associated with health care, regulation, taxes, and trade.10 Reasonable people can disagree about the right way forward on each of those issues, but mitigating the damping effect of uncertainty by providing more clarity on the future direction of government policy is highly desirable--particularly if the direction of policy itself is desirable.\n\nGovernment investment can be an important source of productivity growth as well. For example, the interstate highway system is credited with boosting productivity in the 1950s and 1960s.11 That highway system and many other federally supported roadways, waterways, and structures have been neglected in recent years. Indeed, real infrastructure spending (that is, adjusting for inflation) has fallen nearly 1 percent per year since 2005.12 This area of government investment deserves more attention.\n\nLabor Quality\nAlso important to raising labor productivity is investment in human capital--workers' knowledge and skills. Such investment is a particular issue because most forecasts anticipate that the long rise in educational attainment--both for college and high school--may soon come to an end. One area where policy may play a role is promoting educational access and readiness for groups for whom educational attainment is relatively low.\n\nRecent research has shown a substantial return to public investment in early childhood education for economically disadvantaged groups. Such programs increase high school graduation, promote income over the life cycle for both participants and their parents, and produce other socially beneficial outcomes, such as greater health. 13\n\nAt the other end of the education process, a college degree has long been considered a worthwhile investment, and thus our society should promote access to and readiness for college among a broad range of individuals--in particular through federal support for need-based financial aid.14\n\nLastly, I will note that ultimately the return on the human capital embodied in our workforce is closely tied to public health. A rise in morbidity or fall in longevity in the U.S. population is not a concern only for humanitarian reasons. Workers too ill to perform at their potential represent lost productivity and welfare for society as a whole. Research has shown just such a trend among prime-age non-Hispanic Americans without a college degree.15 More study is needed to determine what policies would help reverse this trend, and government funding could likely assist the effort. More broadly, programs to promote clean air and drinking water are examples of public health policies that bolster the health and longevity of the present and future workforce as a whole.\n\nConcluding remarks\nTo conclude, we return to the basic question: How much does productivity growth matter? The basic answer: simple arithmetic says it matters a lot. If labor productivity grows an average of 2 percent per year, average living standards for our children's generation will be twice what we experienced. If labor productivity grows an average of 1 percent per year, the difference is dramatic: Living standards will take two generations to double.16\n\nBut fortunately, when it comes to productivity, we are not simply consigned to luck or to fate. Governments can take sensible actions to promote more rapid productivity growth. Broadly speaking, government policy works best when it can address a need that the private sector neglects, including investment in basic research, infrastructure, early childhood education, schooling, and public health. Reasonable people can disagree about the right way forward, but if we as a society are to succeed, we need to follow policies that will support and advance productivity growth. That is easier said than done. But it can be done.\n\nReferences\nAndrews, Dan, Chiara Criscuolo, and Peter Gal (2015). Frontier firms, technology diffusion and public policy: Micro evidence from OECD countries, No. 2. OECD Publishing, 2015.\n\nBaker, Scott R., Nicholas Bloom, and Steven J. Davis (2012). \"Has Economic Policy Uncertainty Hampered the Recovery?\" in Lee E. Ohanian, John B. Taylor, and Ian J. Wright, eds., Government Policies and the Delayed Economic Recovery. Stanford, Calif.: Hoover Institution Press, pp. 39-56.\n\nBosler, Canyon, Mary C. Daly, John G. Fernald, and Bart Hobijn (2016). \"The Outlook for U.S. Labor-Quality Growth,\" NBER Working Paper Series 22555. Cambridge, Mass.: National Bureau of Economic Research, August.\n\nBrynjolfsson, Erik, and Lorin M. Hitt (2000). \"Beyond Computation: Information Technology, Organizational Transformation, and Business Performance,\" Journal of Economic Perspectives, vol. 14 (Fall), pp. 23-48.\n\nByrne, David M., John G. Fernald, and Marshall B. Reinsdorf (2016). \"Does the United States Have a Productivity Slowdown or a Measurement Problem? (PDF)\" Brookings Papers on Economic Activity, Spring, pp. 109-57.\n\nByrne, David, Stephen Oliner, and Daniel Sichel (2017). \"Prices of High-Tech Products, Mismeasurement, and Pace of Innovation,\" NBER Working Paper Series 23369. Cambridge, Mass.: National Bureau of Economic Research, April.\n\nCase, Anne, and Angus Deaton (2017). \"Mortality and Morbidity in the 21st Century (PDF),\" Brookings Papers on Economic Activity, Spring, pp. 1-63.\n\nCongressional Budget Office (2015). Public Spending on Transportation and Water Infrastructure, 1956 to 2014. Washington: CBO, March.\n\nDavid, Paul A. (1990). \"The Dynamo and the Computer: An Historical Perspective on the Modern Productivity Paradox,\" American Economic Review, vol. 80 (May), pp. 355-61.\n\nDecker, Ryan A., John Haltiwanger, Ron S. Jarmin, and Javier Miranda (2016). \"Declining Business Dynamism: What We Know and the Way Forward,\" American Economic Review, vol. 106 (May), pp. 203-07.\n\nDynarski, Susan, and Judith Scott-Clayton (2013). \"Financial Aid Policy: Lessons from Research,\" NBER Working Paper Series 18710. Cambridge, Mass.: National Bureau of Economic Research, January.\n\nElango, Sneha, Jorge Luis García, James J. Heckman, and Andrés Hojman (2015). \"Early Childhood Education,\" NBER Working Paper Series 21766. Cambridge, Mass.: National Bureau of Economic Research, November.\n\nFernald, John G. (1999). \"Roads to Prosperity? Assessing the Link between Public Capital and Productivity,\" American Economic Review, vol. 89 (June), pp. 619‑38.\n\nFernald, John G. (2012). \"A Quarterly, Utilization-Adjusted Series on Total Factor Productivity (PDF),\" Working Paper 2012-19. San Francisco: Federal Reserve Bank of San Francisco, September (revised April, 2014).\n\nFernald, John G. (2015). \"Productivity and Potential Output before, during, and after the Great Recession,\" NBER Macroeconomics Annual, vol. 29 (1), pp. 1-51.\n\nFernald, John G., Robert E. Hall, James H. Stock, and Mark W. Watson (2017). \"The Disappointing Recovery of Output after 2009 (PDF),\" Brookings Papers on Economic Activity, Spring, 1-82.\n\nGarcía, Jorge Luis, James J. Heckman, Duncan Ermini Leaf, and María José Prados (2017). \"Quantifying the Life-Cycle Benefits of a Prototypical Early Childhood Program,\" NBER Working Paper Series 23479. Cambridge, Mass.: National Bureau of Economic Research, June.\n\nGordon, Robert (2014). \"The demise of US economic growth: Restatement, rebuttal, and reflections,\" NBER Working Paper Series 19895. Cambridge, Mass.: National Bureau of Economic Research, November.\n\nMohnen, Pierre, and Bronwyn H. Hall (2013). \"Innovation and Productivity: An Update,\" Eurasian Business Review, vol. 3 (Spring), pp. 47-65.\n\nMokyr, Joel (2014). \"Secular Stagnation? Not in Your Life,\" in Coen Teulings and Richard Baldwin, eds., Secular Stagnation: Facts, Causes, and Cures. London: CEPR Press, pp. 83-89.\n\nPinto, Eugenio P., and Stacey Tevlin (2014). \"Perspectives on the Recent Weakness in Investment,\" FEDS Notes, No. 2014-05-21.\n\nSolow, Robert M. (1957). \"Technical Change and the Aggregate Production Function,\" Review of Economics and Statistics, vol. 39 (August), pp. 312-20.\n\nUnited States. Bureau of the Census (1975). Historical statistics of the United States, colonial times to 1970. Washington: US Department of Commerce, Bureau of the Census, September, .\n\n1. I am grateful to David Byrne of the Federal Reserve Board for his assistance. Views expressed in this presentation are my own and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. One needs also to recognize that changes in either the average workweek or the employment to population ratio may damp or augment the effect of labor productivity on GDP per capita. Return to text\n\n3. Byrne, Fernald, and Reinsdorf (2016) discuss known measurement challenges and conclude they cannot explain the deceleration of productivity. Return to text\n\n4. Gordon (2014, p. 25) enumerates the inventions of the information age--the personal computer, the Internet, mobile phones, and so on--and notes that for innovation to continue at such a pace, \"the achievements of the past 40 years set a hurdle that is dauntingly high.\" Return to text\n\n5. Mokyr (2014, p. 83) considers advances in research methods and tools and concludes that \"the indirect effects of science on productivity through the tools it provides scientific research may dwarf the direct effects in the long run.\" Return to text\n\n6. David (1990) cautions that the effect of general-purpose technologies, such as electricity and electronic computing, can take decades to fully unfold. Brynjolfsson and Hitt (2000) consider the process followed by firms in leveraging innovations in IT equipment and emphasize the role of complementary investment in intangible assets like business reorganization. Return to text\n\n7. Mohnen and Hall (2013) survey the empirical literature pointing to a link between R&D and productivity. Return to text\n\n8. Decker and others (2016) highlight the decline in entrepreneurship and worker mobility; Andrews, Criscuolo, and Gal (2015) emphasizes that productivity for firms at the global frontier continues to advance rapidly even as global aggregate productivity growth has slowed. Return to text\n\n9. Pinto and Tevlin (2014) note that in the context of a long-run growth model, a slow pace of investment is not surprising in light of the slow growth in effective labor inputs--which equals the sum of labor quality and total factor productivity growth. Fernald and others (2017) raise a related point--the ratio of capital to output has returned to its apparent long-run trend. That said, Byrne, Oliner, and Sichel (2017) argue that the recent rapid declines in the price of IT capital may presage an uptick in investment in response. Return to text\n\n10. As discussed in Baker, Bloom, and Davis (2012), the Economic Policy Uncertainty (EPU) index, available on the EPU website at www.policyuncertainty.com, is constructed from component measures for references to policy uncertainty in major newspapers, the number of tax code provisions set to expire in future years, and disagreement among economic forecasters. Return to text\n\n11. See Fernald (1999). Return to text\n\n12. Although the share of nominal public spending devoted to infrastructure in recent years has been similar to the share dating back to the 1980s, Congressional Budget Office (2015) notes that real spending has been held down by the relatively rapid increase in the price of inputs used for construction. Return to text\n\n13. Research on the effect of early childhood education is surveyed in Elango and others (2015). Garcia and others (2017) consider the effect over the full life cycle of an early childhood program targeting disadvantaged families and estimate an internal rate of return of nearly 14 percent. Return to text\n\n14. Dynarski and Scott-Clayton (2013) review the evidence that college enrollment rates are positively affected by student aid. Return to text\n\n15. See Case and Deaton (2017). Return to text\n\n16. To be precise, this illustrative calculation assumes that the average workweek and the employment-to-population ratio are unchanged. Return to text"
    },
    {
        "title": "The Case for Housing Finance Reform",
        "date": "July 06, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170706a.htm",
        "content": "July 06, 2017\n\nGovernor Jerome H. Powell\n\nAt the American Enterprise Institute, Washington, D.C.\n\nGood morning. Thank you to the American Enterprise Institute and Steve Oliner for inviting me here to speak. My topic today is the urgent need for fundamental reform of our system of housing finance--the great unfinished business of post-financial crisis reform.1\n\nThe Federal Reserve is not charged with designing or evaluating proposals for housing finance reform. But we are responsible for regulating and supervising banking institutions to ensure their safety and soundness, and more broadly for the stability of the financial system. A robust, well-capitalized, well-regulated housing finance system is vital to achieving those goals, and to the long-run health of our economy. We need a system that provides mortgage credit in good times and bad to a broad range of creditworthy borrowers.\n\nWhile reforms have addressed some of the problems of the pre-crisis system, there is broad agreement that the job is far from done. The status quo may feel comfortable today, but it is also unsustainable. Today, the federal government's role in housing finance is even greater than it was before the crisis. The overwhelming majority of new mortgages are issued with government backing in a highly concentrated securitization market. That leaves us with both potential taxpayer liability and systemic risk. It is important to learn the right lessons from the failure of the old system. We can also apply lessons from post-crisis banking reform. Above all, we need to move to a system that attracts ample amounts of private capital to stand between housing sector credit risk and taxpayers. We should also use market forces to increase competition and help to drive innovation.\n\nThe global financial crisis ended in 2009, and the economy has just completed its eighth consecutive year of expansion. We are near full employment. The housing market is generally strong, although it is still recovering in some regions. To preserve these gains, we must ensure the stability of our financial system. With that goal in mind, we are near completion of a comprehensive program to raise prudential standards for our most systemically important banks. But fundamental housing finance reform--including reform to address the ultimate status of Fannie Mae and Freddie Mac, two systemically important government sponsored enterprises (GSEs)--remains on the \"to do\" list. As memories of the crisis fade, the next few years may present our last best chance to finish these critical reforms. Failure to do so would risk repeating the mistakes of the past.\n\nThe Pre-Crisis System\nCongress created Fannie Mae in 1938 and Freddie Mac in 1970. For many years, these institutions prudently pursued their core mission of enhancing the availability of credit for housing. Beginning in the early 1980s, Fannie and Freddie helped to facilitate the development of the securitization market for home mortgages. They purchased and bundled mortgage loans, and sold the resulting mortgage-backed securities (MBS) to investors. Fannie and Freddie also guaranteed payment of principal and interest on the MBS. With this guarantee in place, MBS investors took the risk of changing interest rates, and the GSEs took the risk of default on the underlying mortgages. Thanks to the growth in securitization, these two GSEs have dominated U.S. housing finance since the late 1980s.\n\nThe pre-crisis system did its job for many years. By promoting standardization, structuring securities to meet a broad range of investor risk appetites, and issuing guaranteed MBS, Fannie and Freddie brought greater liquidity to mortgage markets and made mortgages more affordable. But the system ultimately failed due to fundamental flaws in its structure. In the early days of securitization, the chance that either GSE would ever fail to honor its guarantee seemed remote. But the question always loomed in the background: Who would bear the credit risk if a GSE became insolvent and could not perform? Would Congress really allow the GSE to fail to honor its obligations, given the devastating impact that would have on mortgage funding and the housing market? The law stated explicitly that the government did not stand behind the GSEs or their MBS, as Fannie and Freddie frequently pointed out in order to avoid tougher regulation. Nonetheless, investors understandably came to believe that the two GSEs were too-big-to-fail, and priced in an implicit federal government guarantee behind GSE obligations. In the end the investors were right, of course. The implicit government guarantee also meant that investors--including banks, the GSEs themselves, and investors around the world--did not do careful due diligence on the underlying mortgage pools. Thus, securitization also enabled declining lending standards. This was not only a problem of the GSEs--private label securitizations also helped to enable lower underwriting standards.\n\nOver time, the system's bad incentives caused the two GSEs to change their behavior and take on ever greater risks. The GSEs became powerful advocates for their own bottom lines, providing substantial financial support for political candidates who supported the GSE agenda. Legislative reforms in the 1990s and the public/private structure led managements to expand the GSEs' balance sheets to enormous size, underpinned by wafer-thin slivers of capital, driving high shareholder returns and very high compensation for management. These factors and others eventually led to extremely lax lending conditions. The early 2000s became the era of Alt-A, low doc, and no doc loans.2 These practices contributed to the catastrophic failure of the housing finance system. Almost nine years ago, in September 2008, Fannie and Freddie were put into \"temporary\" conservatorship and received injections of taxpayer funds totaling $187.5 billion. In the end, the system privatized the gains and socialized the losses.\n\nThe buildup of risks is clear in hindsight. But many officials and commentators raised concerns long before the collapse.3 The long-standing internal structural weaknesses of the old system ultimately led to disastrous consequences for homeowners, taxpayers, the financial system, and the economy.\n\nReforms to Date\nBefore considering the path forward, it is important to acknowledge that today's housing sector is healthier and in some respects safer than it was in 2005. Although there are significant regional differences, national data show that housing prices have fully recovered from their gut-wrenching 35 percent drop during the crisis. Mortgage default rates have returned to pre-crisis levels. Mortgage credit is available and affordable for strong borrowers.\n\nThere has also been meaningful progress in reforming the old system. In 2008, Congress enacted the Housing and Economic Recovery Act, which, among other things, created the Federal Housing Finance Agency (FHFA), modeled on and with similar powers to the Federal Deposit Insurance Corporation. Under the FHFA's oversight, the two GSEs' retained portfolios have declined to about half of their pre-crisis size, and are expected to continue on a downward path. The FHFA and the GSEs have also been working to develop a market for the GSEs to lay off their credit risk. These innovative transactions have raised about $50 billion in private capital that now stands between taxpayers and mortgage credit risk in the GSEs' portfolios. In addition, the creation of a Common Securitization Platform should strengthen the GSEs' securitization infrastructure and facilitate further reforms with an eye toward enhancing competition.\n\nNew regulations have also been put in place since the crisis with the goal of encouraging sound underwriting of mortgage loans. Today, lenders must make a good faith effort to determine that the borrower has the ability to repay the mortgage. Moreover, if the lender provides a \"qualified mortgage\" contract to the borrower, then the lender needs to meet certain other requirements.4 For example, some contract features such as an interest-only period or negative amortization, where the loan balance increases even though the borrower is making payments, are taboo. Upfront points and fees are limited too.\n\nToday's Challenges\nThese reforms represent movement in the right direction, but leave us well short of where we need to be. Despite the GSEs' significant role in this key market, there is no clarity about their future. When they were put into conservatorship, Treasury Secretary Paulson noted that \"policymakers must view this next period as a 'time out' where we have stabilized the GSEs while we decide their future role and structure.\"5 Almost nine years into this time out, the federal government's domination of the housing sector has grown and is actually greater than it was before the crisis. Fannie, Freddie, the Federal Housing Administration (FHA) and U.S. Department of Veterans Affairs have a combined market share of about 80 percent of the purchase mortgage market, with the remaining 20 percent held by private financial institutions. After reaching nearly 30 percent of the market before the crisis, private-label securitization has dwindled to almost nothing today.\n\nThe two GSEs remain in government conservatorship, with associated contingent liabilities to US taxpayers.6 Fannie and Freddie have remitted just over $270 billion of profits to the Treasury, more than paying back the government's initial investment. However, under current terms of the contracts that govern their access to Treasury funds, their capital will decline to $0 by January 1, 2018. Today, Fannie Mae and Freddie Mac have more than $5 trillion of MBS and corporate debt outstanding, which is widely held and receives various forms of special regulatory treatment. And because of their scale, these enterprises continue to serve as important standard-setters and significant counterparties to other firms.\n\nWhile mortgage credit is widely available to most traditional mortgage borrowers, those with lower credit scores face significantly higher standards and lower credit availability than before the crisis. We can all agree that we do not want to go back to the poor underwriting standards used by originators prior to the crisis. But it may also be that the current system is too rigid, and that a lack of innovation and product choice has limited mortgage credit availability to some creditworthy households. According to a survey by the American Banker, in 2016 only nine percent of mortgage originations failed to meet the qualified mortgage contract criteria, down from 16 percent in 2013.7 The same survey reported that almost one-third of U.S. banks make only qualified mortgage loans, despite the fact that FHA- and GSE-eligible mortgages are exempt from the qualified mortgage requirements until January 2021 or until housing finance reform is enacted, whichever date comes first.\n\nApplying the Lessons of Banking Reform to Housing Finance\nThe post-crisis reform program for our largest banks presents an appropriate standard against which the housing finance giants should be judged. After eight years of reform, our largest banking institutions are now far stronger and safer. Common equity capital held by the eight U.S. global systemically important banks has more than doubled to $825 billion from about $300 billion before the crisis. After the crisis revealed significant underlying liquidity vulnerabilities, these institutions now hold $2.3 trillion in high-quality liquid assets, or 25 percent of their total assets. Under rigorous annual stress tests, they must demonstrate a high level of understanding of their risks and the ability to manage them, and must survive severely adverse economic scenarios with high levels of post-stress capital. And they must file regular resolution plans that have made them significantly more resolvable should they fail. These measures were implemented to reduce the risk that a future crisis will result in taxpayer support, and to help ensure that the financial system could continue to function even in the event that one of these banks were to default.\n\nIt is ironic that the housing finance system should escape fundamental reform efforts. The housing bubble of the early 2000s was, after all, an essential proximate cause of the crisis. Housing is the single largest asset class in our financial system, with total outstanding residential real estate owned by households of $24 trillion and roughly $10 trillion in single-family mortgage debt.8 While post-crisis regulation has addressed mortgage lending from a consumer protection standpoint, the important risks to taxpayers and the broader economy and financial system have not been robustly addressed.\n\nThe most obvious and direct step forward would be to require ample amounts of private capital to support housing finance activities, as we do in the banking system. We should also strive for a system that can continue to function even in the event of a default of any firm. No single housing finance institution should be too big to fail.\n\nGreater amounts of private capital could come through a variety of sources, including through the entry of multiple private guarantors who would insure a portion of the credit risk, through risk-sharing agreements, or through expanded use of credit-risk transfers. Although private capital must surely be part of the reform effort, there may be limits to the amount of risk that we can credibly expect the private sector to insure. It is extremely difficult to appropriately price the insurance of catastrophic risk--the risk of a severe, widespread housing crisis. Both the private-sector insurance industry and government have struggled with this, particularly with how to smooth the consistent collection of premiums with the irregular payout of potentially enormous losses that may be needed only once or twice in a century. Furthermore, losses can be correlated across asset classes and geographies in these catastrophic events, rendering risk-diversification strategies ineffective. Fannie Mae and Freddie Mac have successfully transferred some credit risk to the private sector, but have thus far avoided selling off much of this catastrophic credit risk, arguing that doing so is not economical.9\n\nPrinciples for Reform\nAfter promising legislative initiatives have moved forward but fallen short of enactment, the air is again thick with housing finance reform proposals. As I mentioned at the outset, housing finance reform has important implications for the Federal Reserve's oversight of financial institutions, and for the U.S. economy and its financial stability. While I would not presume to judge these reform proposals, I will offer some principles for reform. These principles are based on the lessons learned from the old system's collapse, and from the experience of post-crisis bank reform.\n\nFirst, we ought to do whatever we can to make the possibility of future housing bailouts as remote as possible. Housing can be a volatile sector, and housing is often found at the heart of financial crises.10 Our housing finance institutions were not--and are not--structured with that in mind. Extreme fluctuations in credit availability for housing hurt vulnerable households, reduce affordability and availability, and, as we have seen, can threaten financial stability. As with banks, the goal should be to ensure that our housing finance system can continue to function even in the face of significant house price declines and severe economic conditions. Changing the system to attract large amounts of private capital would be a major step toward that goal.\n\nThe question of the government's role in the new system is a challenging one for Congress. Many of the well-known reform proposals include some role for government. Some argue that government cannot avoid bearing the deep-in-the-tail risk of a catastrophic housing crisis. A number of proposals incorporate a government guarantee to cover this risk, to take effect after a significant stack of private capital is wiped out.\n\nThat brings me to my second principle: If Congress chooses to go in this direction, any such guarantee should be explicit and transparent, and should apply to securities, not to institutions. Reform should not leave us with any institutions that are so important as to be candidates for too-big-to-fail.\n\nThird, we should promote greater competition in this market. The economics of securitization do not require a duopoly. Yet there is no way for private firms to acquire a GSE charter and enter the industry. This is akin to having only two banks with federal deposit insurance, which would make competition by other banks very difficult. Greater competition would help to reduce the systemic importance of the GSEs, and spur more innovation. Greater competition also requires a level playing field, allowing secondary market access to a wide-range of lenders and thereby giving homebuyers a choice among many potential mortgage lenders and products.\n\nFourth, it is worth considering simple approaches that restructure and repurpose parts of the existing architecture of our housing finance system. We know that housing reform is difficult; completely redrawing the system may not be necessary and could complicate the search for a solution. Using the existing architecture would allow for a continued smooth, gradual transition.\n\nFifth and last, we need to identify and build upon areas of bipartisan agreement. In my view, at this late stage we should not be holding out for the perfect answer. We should be looking for the best feasible plan to escape the unacceptable status quo.\n\nConclusion\nI see two reasons why this is a good time to address the housing finance system's shortcomings. First, the economy and the housing sector are healthy. It would be far more disruptive to implement fundamental structural changes during difficult economic times. Second, memories of the crisis are fading. If Congress does not enact reforms over the next few years, we are at risk of settling for the status quo--a government-dominated mortgage market with insufficient private capital to protect taxpayers, and insufficient competition to drive innovation. There is a serious risk, if not a likelihood, that this state of affairs may persist indefinitely, leaving our housing finance system in a semi-permanent limbo. Fortunately, we are blessed with a growing menu of reform options available for public vetting. And there appear to be areas of broad agreement among them. One of those plans, or a combination of different features of various plans, might well suffice to move us to a better system. Housing finance reform will protect taxpayers from another bailout, be good for households and the economy, and go some distance toward mitigating the systemic risk that the GSEs still pose.\n\n1. The views I express here are my own and not necessarily those of the Board of Governors of the Federal Reserve System. Return to text\n\n2. See, for example, Markus K. Brunnermeier, \"Deciphering the Liquidity and Credit Crunch 2007-2008,\" The Journal of Economic Perspectives, Vol. 23, No. 1 (Winter 2009), pp. 77-100; Major Coleman IV, Michael LaCour-Little, and Kerry D. Vandell, \"Subprime Lending and the Housing Bubble: Tail Wags Dog?\" Journal of Housing Economics, Vol.17, Issue 4 (December 2008) pp. 272-290; Shiller, Robert J. (2012) The Subprime Solution: How Today's Global Financial Crisis Happened, and What to Do about It, Princeton, New Jersey: Princeton University Press; E. Pinto (2015), \"Three Studies of Subprime and Alt-A loans in the U.S. Mortgage Market,\" American Enterprise Institute (January 2015), www.aei.org/wp-content/uploads/2014/09/Pinto-Government-Housing-Policies-in-the-Lead-up-to-the-Financial-Crisis-3-Studies-1.6.15.pdf. Return to text\n\n3. See, for example, Alan Greenspan, \"Government-Sponsored Enterprises,\" remarks delivered at the Conference on Housing, Mortgage Finance, and the Macroeconomy, Federal Reserve Bank of Atlanta, May 19 2005, www.federalreserve.gov/boarddocs/speeches/2005/default.htm; and Randal Quarles \"Remarks Before the Women in Housing and Finance,\" June 13, 2006. Return to text\n\n4. More specifics on the features required for qualified mortgage contracts are available at www.consumerfinance.gov/askcfpb/1789/what-qualified-mortgage.html. Return to text\n\n5. Statement by Secretary Henry M. Paulson, Jr. on Treasury and Federal Housing Finance Agency Action to Protect Financial Markets and Taxpayers, September 7, 2008, www.treasury.gov/press-center/press-releases/Pages/hp1129.aspx. Return to text\n\n6. The size of these contingent liabilities is potentially quite large. FHFA's stress test results published in August 2016 found that under its severely adverse scenario the two GSEs could need to draw up to $125.8 billion from the U.S. Treasury. See www.fhfa.gov/AboutUs/Reports/ReportDocuments/2016_DFAST_Severely-Adverse-Scenario.pdf. Return to text\n\n7. American Bankers Association, \"24th Annual ABA Residential Real Estate Survey Report,\" (March 2017), www.aba.com/Press/Documents/2017ABARealEstateLendingSurveyReport.pdf. Return to text\n\n8. Based on information contained in the Financial Accounts of the United States available at www.federalreserve.gov/econresdata/releases/mortoutstand/current.htm. Return to text\n\n9. See \"Overview of Fannie Mae and Freddie Mac Credit Risk Transfer Transactions,\" FHFA (August 2015). The overview differentiates between expected loss (credit losses that would be projected to occur even under a stable baseline), unexpected loss (losses that might occur under a stressful but plausible event such as recession) and catastrophic loss (losses beyond those of an unexpected loss and that are deemed highly unlikely to occur). The overview notes that \" catastrophic risk events are deemed so unlikely, meaning they present so little risk, that the Enterprises have found it to be too costly (not economical) to transfer much of this risk to the private sector,\" https://www.fhfa.gov/aboutus/reports/reportdocuments/crt-overview-8-21-2015.pdf. Return to text\n\n10. See for example Carmen M. Reinhart and Kenneth S. Rogoff, \"The Aftermath of Financial Crises,\" American Economic Review, vol. 99 (May 2009) pp. 466-72; Òscar Jordà, Moritz Schularick, and Alan M. Taylor, \"The Great Mortgaging: Housing Finance, Crises, and Business Cycles,\" NBER Working Paper No. 20501 (September 2014), www.nber.org/papers/w20501; and the International Monetary Fund, \"Housing Finance and Financial Stability – Back to Basics?\" Global Financial Stability Report (April 2011), www.imf.org/en/Publications/GFSR/Issues/2016/12/31/~/media/Websites/IMF/imported-flagship-issues/external/pubs/ft/GFSR/2011/01/pdf/_chap3pdf.ashx. Return to text"
    },
    {
        "title": "An Assessment of Financial Stability in the United States",
        "date": "June 27, 2017",
        "speaker": "Vice Chairman Stanley Fischer",
        "url": "https://www.federalreserve.gov/newsevents/speech/fischer20170627a.htm",
        "content": "June 27, 2017\n\nVice Chairman Stanley Fischer\n\nAt the IMF Workshop on Financial Surveillance and Communication: Best Practices from Latin America, the Caribbean, and Advanced Economies, Washington, D.C.\n\nIn the years since the start of the global financial crisis, an enormous amount of effort has gone into ensuring that we have a robust financial system that promotes responsible risk taking and an efficient allocation of resources. But despite these efforts, financial stability cannot be taken for granted, for financial decisions that benefit the people who make them can create systemic risk and harm society as a whole. Further, the phenomenon familiar from macroeconomics‑‑and for that matter from life‑‑of decisions that result in short-run happiness and long-run grief is visible also in the area of financial stability. For example, excessive leverage and reliance on short-term funding, which may reward risk takers whose bets pay off, may also increase the risk of fire sales and contagion, creating a fragile financial situation. The disruption in credit intermediation that typically accompanies such episodes can have lasting negative consequences for the real economy and welfare‑‑some of which we are still seeing today. The Federal Reserve's financial stability responsibilities therefore strongly complement its dual-mandate objectives of achieving price stability and full employment.\n\nToday I will review the monitoring framework we have implemented at the Federal Reserve, before providing an assessment of current U.S. financial stability conditions. I will conclude by arguing that while significant progress has been made in recent years toward making the financial system more stable and resilient, we should not ever be complacent.1 We still lack sufficient information to understand some parts of the shadow banking system, and risks sometimes evolve outside the scope of prudential regulation, with potentially negative implications for financial stability. And sometimes we fail to understand the situation in which we find the financial system and the economy.\n\nFramework for Monitoring Financial Stability\nParticipants in today's workshops have grappled with the question of what is the best framework to monitor financial stability. One approach is to focus on trends in, and interactions among, financial vulnerabilities across financial institutions, markets, and instruments. Another approach is to track the resilience of institutions, either broad categories or individual systemically important institutions. Good monitoring frameworks combine elements of both.\n\nLet me start with the vulnerabilities-focused approach, as developed by Tobias Adrian, Daniel Covitz, and Nellie Liang.2 That approach defines financial vulnerabilities as a collection of factors that may amplify financial shocks and, when elevated, have the potential to generate systemic risk. The focus is on vulnerabilities rather than shocks, because the timing of shocks, such as sudden drops in asset prices, are inherently hard to predict. Vulnerabilities, in contrast, tend to build up over time, and policies can be designed to help contain these vulnerabilities, reducing the likelihood of systemic events.\n\nSome financial vulnerabilities are cyclical in nature, rising and falling over time, while others are structural, stemming from longer-term forces shaping the nature of credit intermediation. Informed by academic research, some of it in-house, we at the Federal Reserve focus on four broad cyclical vulnerabilities: (1) financial-sector leverage, (2) nonfinancial-sector borrowing, (3) liquidity and maturity transformation, and (4) asset valuation pressures.3 Briefly, leverage, across a range of institutions, is a key amplifier of solvency shocks, leading to a greater chance of a credit crunch or fire sale. Liquidity and maturity mismatches can generate run risk, leading to fire sales and contagion. Finally, elevated valuation pressures, especially when combined with high leverage, can lead to excessive credit growth. When asset prices are appreciating rapidly and expected to continue to do so, borrowers and lenders are more willing to accept higher degrees of risk and leverage.\n\nUsing a range of indicators, we assess these cyclical vulnerabilities relative to past experience. That is, we evaluate where the current levels of these indicators stand compared with their historical values, to identify whether they point to a low, average, or high level of vulnerabilities. While we try to rely on quantitative indicators, in the end, this evaluation requires some degree of judgment. We also closely monitor potential structural vulnerabilities, such as funding models and institutions that provide critical plumbing services to the system. Because these structural vulnerabilities are less amenable to traditional quantitative monitoring, their identification and assessment follow a less formal process. I will leave that discussion to another time.\n\nAs mentioned, complementary to the vulnerabilities-oriented approach is an approach that focuses on institutions. If the financial system is overleveraged, that vulnerability has to be evident at particular institutions. An institutions-oriented framework can help us keep track of sector- or institution-specific structural vulnerabilities that may be masked by our overall assessment and provides additional ways to understand how distress at a particular institution or class of institutions may spill over to the wider financial system.\n\nRegardless of whether we are looking at vulnerabilities or institutions, a key feature of this monitoring framework is its forward-looking nature. For example, evidence suggests that periods of elevated risk appetite are frequently accompanied by a rise in leverage at financial intermediaries.4 This evidence implies that elevated asset valuation pressures today may be indicative of rising vulnerabilities tomorrow.5\n\nOf course, while a framework provides a disciplined way to evaluate financial stability, we constantly evaluate the framework so that we can identify new risks and vulnerabilities, which may arise as the financial system evolves--for example, in response to market-driven innovation or regulatory reform. Federal Reserve staff research helps us understand and evaluate the evolving, dynamic financial system.\n\nBefore turning to the assessment of the current state of U.S. financial stability, let me discuss how we communicate our views on this matter. The Federal Reserve, unlike many other central banks, does not publish a financial stability report. The United States already has two congressionally mandated financial stability reports, one authored by the independent Office of Financial Research and a separate report published by the Financial Stability Oversight Council that represents the views of the range of financial regulators, including the Federal Reserve. Additional views of Federal Reserve officials can be reflected in a range of other venues, including, notably, the Board's semiannual Monetary Policy Report, the Board's annual report, and speeches, such as this one.\n\nCurrent Assessment\nThat was the framework, now for the current assessment: In the interest of time, my main focus will be on the four cyclical vulnerabilities--leverage, borrowing by households and non-financial firms, liquidity and maturity transformation, and asset valuations--but I will also briefly touch on the most salient structural vulnerabilities. To summarize the assessment, overall, a range of indicators point to vulnerability that is moderate when compared with past periods: Leverage in the financial sector is at historically low levels, and, following the reforms of money market mutual fund regulations by the Securities and Exchange Commission (SEC) last fall, vulnerabilities associated with liquidity and maturity transformation appear to have decreased. However, the increase in prices of risky assets in most asset markets over the past six months points to a notable uptick in risk appetites, although this shift has not yet led to a pickup in the pace of borrowing or a sizable rise in leverage at financial institutions.\n\nLeverage\nTo start with, leverage: Regulatory capital at large banks is now at multidecade highs. The largest banks have already met their fully phased-in capital requirements, including the conservation buffer and the capital surcharge for the global systemically important banks. Also, the largest banks have been able to meet the post-stress capital requirements in the past couple of stress-test exercises run by the Federal Reserve. Measures of earnings strength, such as the return on assets, continue to approach pre-crisis levels at most banks, although with interest rates being so low, the return on assets might be expected to have declined relative to their pre-crisis levels--and that fact is also a cause for concern.\n\nBorrowing by households and businesses\nIn the private nonfinancial sector, which includes corporations and households, total debt remains well below its long-run trend, largely driven by subdued borrowing among households. However, the corporate business sector appears to be notably leveraged, with the current aggregate corporate-sector leverage standing near 20-year highs.\n\nSome studies, including one by the International Monetary Fund in this April's Global Financial Stability Report, have recently highlighted this vulnerability, so let me briefly offer my perspective.6 Despite the elevated levels of corporate borrowing, recent developments show signs of improvement. Leverage has declined slightly since its peak a year ago, and firms with high debt growth appear relatively healthy. Interest expenses relative to earnings also declined of late and are below their median value since 2001. Furthermore, the fraction of corporate debt due within one year relative to total debt stands at historically low levels. Thus, positive shocks to interest rates may adversely affect the ability of some firms to service debt, but this risk may have only limited system-wide effects. Nonetheless, elevated leverage leaves the corporate sector vulnerable to other shocks, such as earnings shocks.\n\nIn the household sector, new borrowing is driven mostly by borrowers with higher credit scores, and the amount of debt that borrowers have relative to their incomes is falling, suggesting that the debt is more manageable. That said, two pockets in the household sector deserve scrutiny. Auto loan balances and delinquency rates are high for borrowers with lower credit scores, meaning that the riskiest borrowers are borrowing more and not paying it back as often. Of note, delinquencies on recently issued auto loans have also increased, indicating that underwriting standards in the auto loan industry may be deteriorating. Student loan balances keep rising, and delinquency rates on those loans are near historical highs. These strains within the household sector leave such borrowers vulnerable to adverse shocks and probably weigh on their spending. At first glance, one is tempted to say that the potential for this distress to adversely affect the financial system seems moderate, because both subprime auto loan and student loan borrowers account for a small share of other debt categories. But, on second thought, one should remember that pre-crisis subprime mortgage loans were dismissed as a stability risk because they accounted for only about 13 percent of household mortgages, and not take excessive confidence.7\n\nLiquidity and maturity transformation\nSimilar to my assessment of leverage, I believe that the primary vulnerability associated with liquidity and maturity transformation--that of a self-fulfilling run--is relatively low. In recent years, banks have shifted away from more run-prone short-term wholesale sources of funds toward more stable sources such as core deposits. Large domestic banks have also significantly boosted their holdings of high-quality liquid assets, making them more resilient to funding stress.\n\nIn the nonbanking sector, the SEC revised the regulations governing money market mutual funds, first adopted in 2014, with the aim of reducing the key structural vulnerabilities exposed by the massive and destabilizing run on the funds in late 2008. The second round of reforms went into full effect in October 2016; ahead of this date, $1.2 trillion flowed out of prime money funds--the more fragile funds that also provide direct funding to large banking institutions--toward government money funds, which are constrained to hold government-guaranteed assets. Those assets include repurchase agreements (or repos) with private banks backed by Treasury securities and the liabilities of government-sponsored enterprises, such as, notably, the Federal Home Loan Banks (FHLBs). While the current configuration of money markets reveals a reduced financial stability risk compared with the situation prior to the recent reforms, this configuration may not yet represent the final equilibrium. It will be important to keep an eye on the growth of alternative investment vehicles that perform liquidity transformation in money markets.\n\nOf note, in part supported by increased demand from government-only money funds, the FHLB system has increased its issuance of shorter-maturity liabilities, which are more attractive to money funds. In turn, this development has led to an increase in the FHLB system's maturity transformation because its assets--loans to banks and insurance companies--have remained relatively long maturity. As a result, the FHLBs face an increased need to roll over maturing liabilities and thus greater vulnerability should they encounter liquidity pressures. I should note that the FHLBs' regulator, the Federal Housing Finance Agency (also known as the FA-FA) flagged this issue more than a year ago and is working with the FHLBs (the FLUBS) to address it.\n\nAsset valuations\nLet me conclude my assessment of current financial stability conditions with a discussion of asset valuation pressures. Prices of risky assets have increased in most major asset markets in recent months even as risk-free rates also rose. In equity markets, price-to-earnings ratios now stand in the top quintiles of their historical distributions, while corporate bond spreads are near their post-crisis lows. Prices of commercial real estate (CRE) have grown faster than rents for some time, and measures of the amount of operating income relative to the sale price of commercial properties--the capitalization rate--have reached historical lows, suggesting continued pressures in the CRE market despite some tightening in credit conditions. Valuation pressures in single-family residential real estate markets appear, at most, modest, with price-to-rent ratios only slightly higher than their long-run trend.\n\nThe general rise in valuation pressures may be partly explained by a generally brighter economic outlook, but there are signs that risk appetite increased as well. For example, estimates of equity and bond risk premiums are at the lower end of their historical distributions, and, relative to some non-price-based measures of uncertainty, the implied volatility index VIX is particularly subdued. So far, the evidently high risk appetite has not lead to increased leverage across the financial system, but close monitoring is warranted.\n\nConclusion\nLet me conclude by offering my view on where we stand in our effort to promote financial stability in the United States. There is no doubt the soundness and resilience of our financial system has improved since the 2007-09 crisis. We have a better capitalized and more liquid banking system, less run-prone money markets, and more robust resolution mechanisms for large financial institutions. However, it would be foolish to think we have eliminated all risks. For example, we still have limited insight into parts of the shadow banking system, and--as already mentioned--uncertainty remains about the final configuration of short-term funding markets in the wake of money funds reform.\n\nThe U.S. financial system is inherently dynamic, with a range of institutions competing to offer a changing mix of financial products. New financial technologies promise great benefits but will no doubt carry novel risks. As a result, we monitor these vulnerabilities, and we are vigilant with respect to economic and financial developments across markets and institutions within the United States and around the world. And we know that complacency must be avoided.\n\nReferences\nAdrian, Tobias, Daniel Covitz, and Nellie Liang (2015). \"Financial Stability Monitoring,\" Annual Review of Financial Economics, vol. 7 (December), pp. 357-95.\n\nAdrian, Tobias, and Hyun Song Shin (2010). \"Liquidity and Leverage,\" Journal of Financial Intermediation, vol. 19 (July), pp. 418-37.\n\nAikman, David, Michael Kiley, Seung Jung Lee, Michael G. Palumbo, and Missaka Warusawitharana (forthcoming). \"Mapping Heat in the U.S. Financial System,\" Journal of Banking and Finance.\n\nGerardi, Kristopher, Andreas Lehnert, Shane M. Sherlund, and Paul Willen (2008). \"Making Sense of the Subprime Crisis (PDF),\" Brookings Papers on Economic Activity, Fall, pp. 69-145.\n\nInternational Monetary Fund (2017). \"Getting the Policy Mix Right,\" in Global Financial Stability Report. Washington: IMF, April.\n\n1. I am grateful to Chiara Scotti and Filip Zikes of the Federal Reserve Board for their assistance. Views expressed in this presentation are my own and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See Adrian, Covitz, and Liang (2015). Return to text\n\n3. For example, see Adrian, Covitz, and Liang (2015); Aikman and others (forthcoming); and the references therein. Return to text\n\n4. See Adrian and Shin (2012). Return to text\n\n5. See Aikman and others (forthcoming). Return to text\n\n6. See International Monetary Fund (2017). Return to text\n\n7. See Gerardi and others (2008). Return to text"
    },
    {
        "title": "Remarks",
        "date": "June 26, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170626a.htm",
        "content": "June 26, 2017\n\nGovernor Jerome H. Powell\n\nAt the Salzburg Global Seminar, Salzburg, Austria\n\nI appreciate the opportunity to speak at the Salzburg Global Seminar. Today I will discuss our current regulatory regime, and areas where we may be able to make adjustments. As always, the views I express here are my own.1\n\nWe need a resilient, well-capitalized, well-regulated financial system that is strong enough to withstand even severe shocks and support economic growth by lending through the economic cycle. The Federal Reserve has approached the post-crisis regulatory and supervisory reforms with that outcome in mind.\n\nThere is little doubt that the U.S. financial system is stronger today than it was a decade ago. Loss-absorbing capacity among banks is substantially higher as a result of both regulatory requirements and stress testing exercises. The banking industry, and the largest banking firms in particular, face far less liquidity risk than before the crisis. And progress in resolution planning by the largest firms has reduced the threat that their failure would pose. These efforts have made U.S. banking firms both more robust and more resolvable.\n\nEvidence overwhelmingly shows that financial crises can cause severe and lasting damage to the economy's productive capacity and growth potential. Post-crisis reforms to financial sector regulation and supervision have been designed to significantly reduce the likelihood and severity of future financial crises. We have sought to accomplish this goal in significant part by reducing both the probability of failure of a large banking firm and the consequences of such a failure were it to occur.\n\nAs I mentioned, we have substantially increased the capital, liquidity, and other prudential requirements for large banking firms. These measures are not free. Higher capital requirements increase bank costs, and at least some of those costs will be passed along to bank customers and shareholders. But in the longer term, stronger prudential requirements for large banking firms will produce more sustainable credit availability and economic growth.\n\nOur objective should be to set capital and other prudential requirements for large banking firms at a level that protects financial stability and maximizes long-term, through-the-cycle credit availability and economic growth. To accomplish that goal, it is essential that we protect the core elements of these reforms for our most systemic firms in capital and liquidity, stress testing and resolution.\n\nWith that in mind, I will highlight five key areas of focus for regulatory reform. The first is simplification and recalibation of regulation of small and medium-sized banks. We are working to build on the relief we have provided in the areas of call reports and exam cycles, by developing a proposal to simplify the generally applicable capital framework that applies to community banking organizations.\n\nThe second area is resolution plans. The Fed and the Federal Deposit Insurance Corporation believe that it is worthwhile to consider extending the cycle for living will submissions from annual to once every two years, and focusing every other of these filings on key topics of interest and material changes from the prior full plan submission. We are also considering other changes, as I discussed last week when testifying to Congress.\n\nThird, the Federal Reserve is reassessing whether the Volcker rule implementing regulation most efficiently achieves its policy objectives, and we look forward to working with the other four Volcker rule agencies to find ways to improve that regulation. In our view, there is room for eliminating or relaxing aspects of the implementing regulation in ways that do not undermine the Volcker rule's main policy goals.\n\nFourth, we will continue to enhance the transparency of stress testing and the Comprehensive Capital Analysis and Review (CCAR). We will soon seek public feedback concerning possible forms of enhanced disclosure, including a range of indicative loss rates predicted by the Federal Reserve's models for various loan and securities portfolios, and information about risk characteristics that contribute to the loss-estimate ranges. We will also provide more detail on the qualitative aspects of stress testing in next week's CCAR disclosure.\n\nFinally, the Federal Reserve is taking a fresh look at the enhanced supplementary leverage ratio. We believe that the leverage ratio is an important backstop to the risk-based capital framework, but that it is important to get the relative calibrations of the leverage ratio and the risk-based capital requirements right.\n\nU.S. banks today are as strong as any in the world. As we consider the progress that has been achieved in improving the resiliency and resolvability of our banking industry, it is important for us to look for ways to reduce unnecessary burden. We must also be vigilant against new risks that may develop. In all of our efforts, our goal is to establish a regulatory framework that helps ensure the resiliency of our financial system, the availability of credit, economic growth, and financial market efficiency. We look forward to working with our fellow regulatory agencies and with Congress to achieve these important goals.\n\nAnd finally, I would also like to note that work continues to address the risks identified with existing reference rates. Just last week, the Alternative Reference Rates Committee (ARRC) selected a new rate suitable for use with new derivative contracts. I am confident the broad Treasuries repo rate, which the Federal Reserve Bank of New York has proposed publishing in cooperation with the Office of Financial Research, is based on a deep and actively traded market and will be highly robust. With this choice, the ARRC has taken another step in addressing the risks involved with the LIBOR.\n\n1. These remarks are substantially similar to the testimony delivered at the Senate Committee on Banking, Housing, & Urban Affairs hearing titled \"Fostering Economic Growth: Regulator Perspective\" on June 22, 2017. Return to text"
    },
    {
        "title": "Central Clearing and Liquidity",
        "date": "June 23, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170623a.htm",
        "content": "June 23, 2017\n\nGovernor Jerome H. Powell\n\nAt the Federal Reserve Bank of Chicago Symposium on Central Clearing, Chicago, Illinois\n\nThank you for inviting me to speak today.1 The Federal Reserve Bank of Chicago and Darrell Duffie have provided a valuable public service in hosting this annual symposium on central clearing. I will start my remarks by taking stock of the progress made in strengthening central counterparties (or CCPs), and then offer some thoughts on central clearing and liquidity risks.\n\nThe huge losses suffered by the American International Group (AIG) on its over-the-counter derivatives positions contributed to the financial crisis and highlighted the risks in derivatives markets. In response, the Group of Twenty nations committed in 2009 to moving standardized derivatives to central clearing. Central clearing serves to address many of the weaknesses exposed during the crisis by fostering a reduction in risk exposures through multilateral netting and daily margin requirements as well as greater transparency through enhanced reporting requirements. Central clearing also enables a reduction in the potential cost of counterparty default by facilitating the orderly liquidation of a defaulting member's positions, and the sharing of risk among members of the CCP through some mutualization of the costs of such a default.\n\nBut central clearing will only make the financial system safer if CCPs themselves are run safely. Efforts to set heightened expectations for CCPs and other financial market infrastructures have been ongoing for years, with the regulatory community working collectively to clarify and significantly raise expectations. These efforts resulted in the Principles for Financial Market Infrastructures (or PFMI), which was published in 2012 by the Committee on Payments and Market Infrastructures (CPMI) and the International Organization of Securities Commissions (IOSCO). The PFMI lays out comprehensive expectations for CCPs and other financial market infrastructures.\n\nRecent Accomplishments\nExtensive work has been done to implement the PFMI.2 The joint CCP work plan agreed to in 2015 by the Financial Stability Board (or FSB), CPMI, IOSCO, and the Basel Committee on Banking Supervision (or BCBS) laid out an ambitious program to provide further guidance on the PFMI and better understand interdependencies between CCPs and their members.3\n\nCPMI and IOSCO will soon publish more granular guidance on CCP resilience, focusing on governance, stress testing credit and liquidity risk, margin, and recovery planning. While this guidance will not establish new standards beyond those set out in the PFMI, I believe that it will encourage CCPs and their regulators to engage in thoughtful dialogue on how they could further enhance their practices.\n\nThe FSB has led the work on resolution planning for CCPs, publishing draft guidance this past February. The guidance covers a range of topics, including the powers that resolution authorities need in order to effectively resolve a CCP, the potential incentives related to using various loss-allocation tools in resolution, the application of the \"no creditor worse off\" safeguard, and the formation of crisis management groups--a key step in facilitating cross-border regulatory coordination in the event of a failure of a systemically important CCP.\n\nEnsuring the safety of the system also requires an understanding of the interdependencies between CCPs and their clearing members. Work on this is ongoing. Preliminary analysis confirms that there are large interdependencies between banks and CCPs, including common exposures related to financial resources held to cover market and credit risk, as well as common lending and funding arrangements.\n\nHaving pushed for the move to greater central clearing, global authorities have a responsibility to ensure that CCPs do not themselves become a point of failure for the system. The progress I have just described is helping to meet this responsibility by making central clearing safer and more robust. Global authorities also have a responsibility to ensure that bank capital standards and other policies do not unnecessarily discourage central clearing. In my view, the calibration of the enhanced supplementary leverage ratio (SLR) for the U.S. global systemically important banks (G-SIBs) should be reconsidered from this perspective. A risk-insensitive leverage ratio can be a useful backstop to risk-based capital requirements. But such a ratio can have perverse incentives if it is the binding capital requirement because it treats relatively safe activities, such as central clearing, as equivalent to the most risky activities. There are several potential approaches to addressing this issue. For example, the BCBS is currently considering a proposal that would set a G-SIB's SLR surcharge at a level that is proportional to the G-SIB's risk-based capital surcharge. Taking this approach in the U.S. context could help to reduce the cost that the largest banks face in offering clearing services to their customers.\n\nThe Federal Reserve is also considering other steps. First, we are developing an interpretation of our rules in connection with the movement of some centrally cleared derivatives to a \"settled-to-market\" approach. Under this approach, daily variation margin is treated as a settlement payment rather than as posting collateral. Under our capital rules, this approach reduces the need for a bank to hold capital against these exposures under risk-based and supplementary leverage ratios. Second, we are also working to move from the \"current exposure method\" of assessing counterparty credit risk on derivative exposures to the standardized approach for counterparty credit risk (SA-CCR). The current exposure method generally treats potential future credit exposures on derivatives as a fixed percentage of the notional amount, which ignores whether a derivative is margined and undervalues netting benefits. SA-CCR is a more risk-sensitive measurement of exposure, which would appropriately recognize the counterparty risks on derivatives, including the lower risks on most centrally cleared derivatives.\n\nCentral Clearing and Liquidity\nCCPs are different from most other financial intermediaries in the sense that the CCP stands between two parties to a cleared transaction whose payment obligations exactly offset each other. A CCP faces market or credit risk only in the event that one of its members defaults and its required initial margin or other pre-funded financial resources are insufficient to cover any adverse price swings that occur during the period between the time of default and the time that the CCP is able to liquidate the defaulting party's positions.\n\nHowever, like most other financial intermediaries, CCPs do face liquidity risks. Their business model is based on timely payments and the ability to quickly convert either the underlying assets being cleared or non-cash collateral into cash. For this reason, CCPs should carefully consider liquidity when launching new products and only offer clearing of products that can be sold quickly, even in times of stress. Liquidity problems can occur in central clearing even if all counterparties have the financial resources to meet their obligations, if they are unable to convert those resources into cash quickly enough. The amount of liquidity risk that CCPs face can sometimes dwarf the amount of credit or market risk they face. This is particularly true for the clearing of cash securities such as Treasuries. In that case, the securities being cleared are extremely safe and likely to rise in value in times of stress. But in contrast to most cleared derivatives, the cash payments involved are very large because counterparties exchange cash for the delivery of the security on a gross basis.\n\nI will look at these risks from two perspectives, first in terms of the payments that CCPs must make, and then in terms of the payments they expect to receive.\n\nPayment Flows from CCPs\nIn the case of a member's default, a CCP must be equipped to make the cash payments owed to non-defaulting counterparties when due. This requirement can be met as long as there is sufficient margin, mutualized resources such as the guarantee fund, or the CCP's own resources held in cash and in the required currency. But if those funds are held in securities, then the CCP will need to convert them to cash, either by entering into a repurchase agreement, or using them as collateral to draw on a line of credit. And if the CCP holds either cash or securities denominated in a currency different from the one in which payment must be made, it will need to either engage in a spot FX transaction or in an FX swap.\n\nPrinciple seven of the PFMI addresses these liquidity risks, calling for all CCPs to meet a \"Cover 1 standard\"--that is, to hold enough liquid resources in all relevant currencies to make payments on time in the event of the default of the clearing member that would generate the largest payment obligation under a wide range of potential stress scenarios. More complex CCPs and those with a systemic presence in multiple jurisdictions are encouraged to meet a \"Cover 2 standard.\" The PFMI also provide guidance on the resources that qualify in meeting these requirements: cash held at a central bank or a creditworthy commercial bank, committed lines of credit, committed repurchase agreements, committed FX swap agreements, or highly marketable collateral that can be converted into cash under prearranged and highly reliable funding arrangements.\n\nThere are two sets of risks involved here. First, where should CCPs put their cash? As central clearing has expanded, CCPs have had to deal with increasingly large amounts of cash margin. CCPs can deposit some of these funds with commercial banks. But regulatory changes have made it more expensive for banks to take large deposits from other financial firms, and in some cases banks may be unwilling to accept more cash from a CCP. And many of the largest banks are also clearing members, which introduces a certain amount of wrong-way risk. A clearing-member default could be especially fraught if the defaulting bank also held large cash balances for the CCP. For this reason, CCPs may prudently place limits on the amount deposited at a given institution. In order to diversify their holdings, many also place cash in the repo market. If it is available, the ability to deposit cash at a central bank allows for another safe, flexible, and potentially attractive option--a subject I will return to later.\n\nSecond, how can CCPs be assured that they will be able to convert securities into cash or draw on other resources in times of stress? The PFMI uses the words \"committed\" and \"pre-arranged\" in describing qualifying liquid resources. Indeed, the PFMI does not view spot transactions on the open market as reliable sources of liquidity during times of stress. The Federal Reserve has strongly supported this approach. Liquidity plans should not take for granted that, at a time of stress involving a member default, lines of credit, repurchase agreements, or FX swaps could be arranged on the spot. Committed sources of liquidity are more likely to be available. They also allow market participants and regulators to make sure that plans are mutually consistent. If a CCP has arranged for a committed liquidity source, then the provider should account for it in its own plans and demonstrate that it can meet its commitment.\n\nOf course, this liquidity is not free, nor should it be. Regulatory changes have forced banks to closely examine their liquidity planning and to internalize the costs of liquidity provision. The costs of committed liquidity facilities will be passed on to clearing members. These costs are perhaps highest in clearing Treasury securities, where liquidity needs can be especially large. To meet its estimated needs, DTCC's Fixed Income Clearing Corporation (FICC) is planning to institute a committed repo arrangement with its clearing members. Despite initial concerns, the industry seems prepared to absorb these costs, but they will not be trivial for many members.4\n\nPayment Flows to CCPs\nWhile initial and variation margin help mitigate credit risk in central clearing, they can also create liquidity risk. Clearing members and their clients are required to make margin payments to CCPs on a daily basis, and in times of market volatility these payments may rise dramatically. This source of liquidity risk can occur even in the absence of a default. For example, after the UK referendum on Brexit, the resulting price swings triggered many CCPs to make substantial intraday and end-of-day margin calls. Fortunately, members had prepared and were able to make the needed payments, but the sums involved caught many off guard and the experience served as a useful warning.\n\nAccording to data from the Commodity Futures Trading Commission (CFTC), the top five CCPs requested $27 billion in additional margin over the two days following the referendum, about five times the average amount.5 In most cases, clearing members have an hour to meet intraday margin calls. Clearing members have no choice but to hold enough liquid resources to meet the range of possible margin calls, as the consequences of missing a margin call are considerable.\n\nBrexit was only the most recent example in which margin calls were unexpectedly large. Margin calls were also quite large after the stock market crash of October 1987. That episode helps to demonstrate how complicated payments flows can be and why liquidity risk also needs to be viewed from a macroprudential perspective, considering potential risks to flows across the system. After falling about 9 percent the week before, on October 19, 1987, the S&P 500 stock market index fell about 20 percent. Margin calls were about 10 times their normal size, and caused a very complicated set of payment flows across multiple exchanges, CCPs, and banks.6\n\nThe next slide helps to represent the ensuing payment flows.7 Calls requesting payment are on the left in red. When making a margin call, a CCP requests payment from its clearing members. Clearing members in turn request margin payments from the customers for whom they are clearing, and those customers must then direct their bank to make the payment. If everything works as it should, payments (in green, on the right) will ensue. The customer's bank will deliver the requested payment to the clearing member's bank (or payment bank). The payment bank will then deliver the funds to a settlement bank used by the CCP, and the settlement bank will then credit the funds to the CCP. In theory, each of these payments would have to happen sequentially, but often parties offer intraday credit (represented by the dashed orange lines) to help smooth these flows. For example, the settlement bank may provide intraday credit to the clearing member, sending funds to the CCP before the member has delivered funds to the payment bank or before those funds have been transferred to the settlement bank. Clearing members or the customer's bank may also provide intraday credit to their customers, again making payments before funds have been received in order to help speed the payments chain.\n\nOver the course of October 19, 1987, the system worked largely as I have just described. But on October 20, every single link in these payments and credit chains was interrupted. This is represented graphically in the next slide. By that morning, many settlement banks and clearing members had yet to receive offsetting payments for credit that had been extended the previous day. Goldman Sachs and Kidder, Peabody had together extended $1.5 billion in credit that had not yet been paid.8 As a result, some firms pulled back on providing further credit, which then forced each link of the payments chain to operate sequentially. Payments slowed, with the unintended consequence that uncovered positions grew larger and stayed open for even longer. Without credit, some customers were unable to meet their margin calls and were forced to liquidate their positions. This gridlock sparked fears that a clearing member or even a CCP would be forced to default. The Federal Reserve reacted to this threat by encouraging banks to continue to extend credit and by injecting funds into the system to help ensure that credit was available. The 1987 stock market crash did not leave much lasting impact on the economy, but if these liquidity problems had been allowed to cause the default of a major clearing member or even a CCP then it could have had a much more serious impact. While this might seem like simply an interesting bit of history, the payments chains involved in central clearing are still very similar today. To guard against the same sorts of liquidity risk today, we need to make sure that every link in these chains will work as it is intended to under stress.\n\nWhile neither Brexit nor the October 1987 crash involved a clearing member default, these incidents do point to the potential complications of such a default. I have already discussed the steps that a CCP might need to take in the event of a default to meet its liquidity needs. Some of those needs, such as committed lines of credit or repo agreements, could involve tapping financial resources at the same banks that are clearing members. Thus, clearing members may need to juggle several different liquidity exposures simultaneously in the event of a default. They may face draws on committed sources of liquidity, and if there are market stresses around the default, which seems a near certainty, they may at the same time face a sudden increase in intraday margin calls and their own internal demands for more liquid resources.9 These are risks that we should seek to understand better.\n\nPolicy Implications\nThe Federal Reserve is the primary supervisory authority for two designated financial market utilities (or DFMUs), and plays a secondary role relative to the six other DFMUs. As a central bank, we are particularly concerned with liquidity issues.10 I will address four policy issues that need careful consideration as the public sector and market participants continue to address liquidity risks in central clearing.\n\nStress Testing\nThe 1987 stock market crash showed that we need to look at liquidity risks from a systemwide perspective. That event involved multiple CCPs and also involved multiple links in the payments chains between banks and CCPs. Conducting supervisory stress tests on CCPs that take liquidity risks into account would help authorities better assess the resilience of the financial system. A stress test focused on cross-CCP liquidity risks could help to identify assumptions that are not mutually consistent; for example, if each CCP's plans involve liquidating Treasuries, is it realistic to believe that every CCP could do so simultaneously?\n\nAuthorities in both the United States and Europe have made progress in conducting supervisory stress tests of CCPs. In the United States, the CFTC conducted a useful set of tests of five major CCPs last year.11 The tests analyzed each individual institution's ability to withstand the credit risks emanating from the default of one or more clearing members. This was innovative and necessary work. It would be useful to build on it by adding tests that focus on liquidity risks across CCPs and their largest common clearing members. Such an exercise could focus on the robustness of the system as a whole rather than individual CCPs. The European Securities and Markets Authority is already expanding its supervisory stress testing exercise to incorporate liquidity risk. A similar exercise here in the United States should be seriously considered.\n\nEnsuring Efficiency\nThe industry collectively needs to ensure that the liquidity flows involved in central clearing are handled efficiently and in a way that minimizes potential disruption. As I noted, there was some concern about the size of margin calls following Brexit, and certain CCPs have taken measures to address this. For example, LCH has subsequently made changes to its intraday margining procedures in an effort to reduce liquidity pressures on its clearing members, allowing them to offset losses on their client accounts with gains on the house account.12\n\nOther CCPs are also actively engaged in efforts to increase their efficiency.FICC is looking at potential solutions using distributed ledger technology to clear both legs of overnight repo trades, which could allow for greater netting opportunities and thereby reduce potential liquidity needs.13 Several CCPs are also looking at ways to expand central clearing to directly include more buy-side firms, which could also offer greater netting opportunities. Doing so could also offer new sources of liquidity if the new entrants are able to take part in the CCP's committed liquidity arrangements. Diversification of sources of liquidity would offer tangible benefits--CCPs would avoid relying on the same limited set of clearing members for all of their liquidity needs. As one example, the Options Clearing Corporation established an innovative pre-funded, committed repurchase facility with a leading pension fund.\n\nAs regulators, we should encourage innovations that increase clearing efficiency and reduce liquidity risks where they meet the PFMI and our supervisory expectations.\n\nCentral Bank Accounts\nAs I discussed earlier, CCPs have a complicated set of decisions on how and where to hold their cash balances. Title VIII of the Dodd-Frank Act authorized the Federal Reserve to establish accounts for DFMUs, and we now have accounts with each of the eight institutions that the Financial Stability Oversight Council has so designated. These accounts permit DFMUs to hold funds at the Federal Reserve, but not to borrow from it.14 Allowing DFMUs to deposit balances at the Federal Reserve helps them avoid some of the risk involved in holding balances with their clearing members. Doing so also provides CCPs with a flexible way to hold balances on days when margin payments unexpectedly spike and it is difficult to find banks that are willing to accept an unexpected influx in deposits. In such a case, it may also be too late in the day to rely on the repo market. The availability of Fed accounts could help avoid potential market disruptions in those types of circumstances.\n\nCross-Border Cooperation\nThe lessons from Brexit also point to the need for cross-border cooperation. Brexit triggered payments flows to CCPs across many jurisdictions. As far as liquidity risks are concerned, it is immaterial whether a CCP is based in the United States or abroad so long as it clears U.S. dollar denominated assets and must make and receive U.S. dollar payments. There are different possible approaches to such cross-border issues. Efforts to address these liquidity risks should carefully take into consideration the effect that they would have on the broader financial system. For example, splintering central clearing by currency area would fragment liquidity and reduce netting opportunities, which in the case of events like Brexit could actually trigger even greater liquidity risk. In my opinion, we should be searching for cooperative solutions to these issues.\n\nConclusion\nIn the years following the financial crisis, one of the primary lessons for market participants and their regulators was the criticality of liquidity risk management. Financial firms such as Lehman Brothers and AIG struggled to obtain sufficient liquidity to meet their obligations. Liquidity is also a crucial concern in central clearing, and while regulatory reforms have done much to strengthen both CCPs and their clearing members, we should continue to make progress in creating a more robust and efficient system.\n\n1. The views I express here are my own and not necessarily those of others at the Federal Reserve. Return to text\n\n2. In 2013, CPMI-IOSCO launched a multi-level, multi-year monitoring program to evaluate how the principles and responsibilities in the PFMI are being implemented around the world. Several different assessments have been completed to date and the findings have provided important insight on both the progress and methods by which authorities and CCPs have sought to implement the PFMI. In 2014, CPMI-IOSCO published supplemental guidance and a menu of recovery tools to help financial market infrastructures, including CCPs, meet the expectations in the PFMI that all financial market infrastructures have a comprehensive and effective recovery plan. Return to text\n\n3. While the work done in the context of the joint work plan represents significant regulatory efforts related to CCPs, progress is also being made on a parallel path. In particular, it is important to highlight the adoption and implementation of the SEC's Covered Clearing Agency Standards, which further strengthens the risk management standards that clearing agencies registered with the SEC must meet. In addition, the SEC and the industry have been working jointly to shorten the settlement cycle to two days for many securities products, culminating in the SEC's adoption of amendments to Rule 15c6-1(a) earlier this year. Return to text\n\n4. \"Treasury repos may hit 20bp under DTCC liquidity plan,\" Risk.net, November 25, 2015. Return to text\n\n5. \"Derivatives traders forced to provide $27bn collateral post-Brexit,\" Financial Times, November 16, 2016. Return to text\n\n6. Cash equities were traded in New York on the New York Stock Exchange, equity futures were traded and cleared in Chicago by the Chicago Mercantile Exchange, while stock options were traded on the Chicago Board Options Exchange and cleared by the Options Clearing Corporation. Return to text\n\n7. This figure is an adaptation from one presented in Andrew Brimmer (1989), \"Central Banking and Systemic Risks in Capital Markets,\" Journal of Economic Perspectives, Spring, 3–16. Return to text\n\n8. \"The Day the Nation's Cash Pipeline Almost Ran Dry,\" The New York Times, October 2, 1988. Return to text\n\n9. Regulatory changes since the financial crisis have encouraged banks to hold much greater amounts of high-quality liquid assets, which would help them in meeting such liquidity demands. Return to text\n\n10. Section 804 of the Dodd-Frank Act requires the Financial Stability Oversight Council to designate those financial market utilities that the council determines are, or are likely to become, systemically important. Eight utilities have been designated: The Clearing House Payments Company, L.L.C.; CLS Bank International; Chicago Mercantile Exchange, Inc.; The Depository Trust Company; Fixed Income Clearing Corporation; ICE Clear Credit L.L.C.; National Securities Clearing Corporation; and The Options Clearing Corporation. Return to text\n\n11. \"Supervisory Stress Test of Clearinghouses (PDF),\" Commodity Futures Trading Commission, November 2016. Return to text\n\n12. LCH has also moved forward by one hour the timing of the last intraday margin call and made procedural changes that will speed up the processing of the call, which should also help with payment flows. Return to text\n\n13. \"DTCC & Digital Asset Move to Next Phase after Successful Proof-Of-Concept for Repo Transactions Using Distributed Ledger Technology,\" DTCC, February 2017. Return to text\n\n14. According to title VIII of the Dodd-Frank Act, a designated financial market utility may only borrow from the discount window only in unusual and exigent circumstances and only upon a majority vote of the Board of Governors following consultation with the Secretary of the Treasury. Return to text"
    },
    {
        "title": "Housing and Financial Stability",
        "date": "June 20, 2017",
        "speaker": "Vice Chairman Stanley Fischer",
        "url": "https://www.federalreserve.gov/newsevents/speech/fischer20170620a.htm",
        "content": "June 20, 2017\n\nVice Chairman Stanley Fischer\n\nAt the DNB-Riksbank Macroprudential Conference Series, Amsterdam, Netherlands\n\nIt is often said that real estate is at the center of almost every financial crisis. That is not quite accurate, for financial crises can, and do, occur without a real estate crisis. But it is true that there is a strong link between financial crises and difficulties in the real estate sector.1 In their research about financial crises, Carmen Reinhart and Ken Rogoff document that the six major historical episodes of banking crises in advanced economies since the 1970s were all associated with a housing bust.2 Plus, the drop in house prices in a bust is often bigger following credit-fueled housing booms, and recessions associated with housing busts are two to three times more severe than other recessions.3 And, perhaps most significantly, real estate was at the center of the most recent crisis.\n\nIn addition to its role in financial stability, or instability, housing is also a sector that draws on and faces heavy government intervention, even in economies that generally rely on market mechanisms. Coming out of the financial crisis, many jurisdictions are undergoing housing finance reforms, and enacting policies to prevent the next crisis. Today I would like to focus on where we now stand on the role of housing and real estate in financial crises, and what we should be doing about that situation. We shall discuss primarily the situation in the United States, and to a much lesser extent, that in other countries.\n\nHousing and Government\nWhy are governments involved in housing markets? Housing is a basic human need, and politically important‑‑and rightly so. Using a once-popular term, housing is a merit good‑‑it can be produced by the private sector, but its benefit to society is deemed by many great enough that governments strive to make it widely available.4 As such, over the course of time, governments have supported homebuilding and in most countries have also encouraged homeownership.5\n\nGovernments are involved in housing in a myriad of ways. One way is through incentives for homeownership. In many countries, including the United States, taxpayers can deduct interest paid on home mortgages, and various initiatives by state and local authorities support lower-income homebuyers. France and Germany created government-subsidized home-purchase savings accounts. And Canada allows early withdrawal from government-provided retirement pension funds for home purchases.6\n\nAnd‑‑as we all know‑‑governments are also involved in housing finance. They guarantee credit to consumers through housing agencies such as the U.S. Federal Housing Administration or the Canada Mortgage and Housing Corporation.7 The Canadian government also guarantees mortgages on banks' books. And at various points in time, jurisdictions have explicitly or implicitly backstopped various intermediaries critical to the mortgage market.\n\nGovernment intervention in the United States has also addressed the problem of the fundamental illiquidity of mortgages. Going back 100 years, before the Great Depression, the U.S. mortgage system relied on small institutions with local deposit bases and lending markets. In the face of widespread runs at the start of the Great Depression, banks holding large portfolios of illiquid home loans had to close, exacerbating the contraction. In response, the Congress established housing agencies as part of the New Deal to facilitate housing market liquidity by providing a way for banks to mutually insure and sell mortgages.8\n\nIn time, the housing agencies, augmented by post-World War II efforts to increase homeownership, grew and became the familiar government-sponsored enterprises, or GSEs: Fannie, Freddie, and the Federal Home Loan Banks (FHLBs). The GSEs bought mortgages from both bank and nonbank mortgage originators, and in turn, the GSEs bundled these loans and securitized them; these mortgage-backed securities were then sold to investors. The resulting deep securitized market supported mortgage liquidity and led to broader homeownership.9\n\nCosts of Mortgage Credit\nWhile the benefits to society from homeownership could suggest a case for government involvement in securitization and other measures to expand mortgage credit availability, these benefits are not without costs. A rapid increase in mortgage credit, especially when it is accompanied by a rise in house prices, can threaten the resilience of the financial system.\n\nOne particularly problematic policy is government guarantees of mortgage-related assets. Pre-crisis, U.S. agency mortgage-backed securities (MBS) were viewed by investors as having an implicit government guarantee, despite the GSEs' representations to the contrary. Because of the perceived guarantee, investors did not fully internalize the consequence of defaults, and so risk was mispriced in the agency MBS market. This mispricing can be notable, and is attributable not only to the improved liquidity, but also to implicit government guarantees.10 Taken together, the government guarantee and resulting lower mortgage rates likely boosted both mortgage credit extended and the rise in house prices in the run-up to the crisis.\n\nAnother factor boosting credit availability and house price appreciation before the crisis was extensive securitization.11 In the United States, securitization through both public and private entities weakened the housing finance system by contributing to lax lending standards, rendering the mid-2000 house price bust more severe.12 Although the causes are somewhat obscure, it does seem that securitization weakened the link between the mortgage loan and the lender, resulting in risks that were not sufficiently calculated or internalized by institutions along the intermediation chain. For example, even without government involvement, in Spain, securitization grew rapidly in the early 2000s and accounted for about 45 percent of mortgage loans in 2007.13 Observers suggest that Spain's broad securitization practices led to lax lending standards and financial instability.14\n\nYet, as the Irish experience suggests, housing finance systems are vulnerable even if they do not rely on securitization. Although securitization in Ireland amounted to only about 10 percent of outstanding mortgages in 2007, lax lending standards and light regulatory oversight contributed to the housing boom and bust in Ireland.15\n\nMacroprudential Policies\nTo summarize, murky government guarantees, lax lending terms, and securitization were some of the key factors that made the housing crisis so severe. Since then, to damp the house price-credit cycle that can lead to a housing crisis, countries worldwide have worked to create or expand existing macroprudential policies that would, in principle, limit credit growth and the rate of house price appreciation.16\n\nMost macroprudential policies focus on borrowers. Loan-to-value (LTV) and debt-to-income (DTI) ratio limits aim to prevent borrowers from taking on excessive debt. The limits can also be adjusted in response to conditions in housing markets; for example, the Financial Policy Committee of the Bank of England has the authority to tighten LTV or DTI limits when threats to financial stability emerge from the U.K. housing market. Stricter LTV or DTI limits find some measure of success. One study conducted across 119 countries from 2000 to 2013 suggests that lower LTV limits lead to slower credit growth.17 In addition, evidence from a range of studies suggests that decreases in the LTV ratio lead to a slowing of the rate of house price appreciation.18 However, some other research suggests that the effectiveness of LTV limits is not significant or somewhat temporary.19\n\nOther macroprudential policies focus on lenders. First and foremost, tightening bank capital regulation enhances loss-absorbing capacity, strengthening financial system resilience. In addition, bank capital requirements for mortgages that increase when house prices rise may be used to lean against mortgage credit growth and house price appreciation.20 These policies are intended to make bank mortgage lending more expensive, leading borrowers to reduce their demand for credit, which tends to push house prices down. Estimates of the effects of such changes vary widely: After consideration of a range of estimates from the literature, an increase of 50 percentage points in the risk weights on mortgages would result in a house price decrease from as low as 0.6 percent to as high as 4.0 percent.21 These policies are more effective if borrowers are fairly sensitive to a rise in interest rates and if migration of intermediation outside the banking sector to nonbanks is limited.\n\nOf course, regulatory reforms and in some countries, macroprudential policies‑‑are still being implemented, and analysis is currently under way to monitor the effects. So far, research suggests that macroprudential tightening is associated with slower bank credit growth, slower housing credit growth, and less house price appreciation. Borrower, lender, and securitization-focused macroprudential policies are likely all useful in strengthening financial stability.\n\nLoan Modification in a Crisis\nEven though macroprudential policies reduce the incidence and severity of housing related crises, they may still occur. When house prices drop, households with mortgages may find themselves underwater, with the amount of their loan in excess of their home's current price. As Atif Mian and Amir Sufi have pointed out, this deterioration in household balance sheets can lead to a substantial drop in consumption and employment.22 Extensive mortgage foreclosures--that is, undertaking the legal process to evict borrowers and repossess the house and then selling the house--as a response to household distress can exacerbate the downturn by imposing substantial dead-weight costs and, as properties are sold, causing house prices to fall further.23\n\nModifying loans rather than foreclosing on them, including measures such as reducing the principal balance of a loan or changing the loan terms, can allow borrowers to stay in their homes. In addition, it can substantially reduce the dead-weight costs of foreclosure.\n\nYet in some countries, institutional or legal frictions impeded desired mortgage modifications during the recent crisis. And in many cases, governments stepped in to solve the problem. For example, U.S. mortgage loans that had been securitized into private-label MBS relied on the servicers of the loans to perform the modification. However, operational and legal procedures for servicers to do so were limited, and, as a result, foreclosure, rather than modification, was commonly used in the early stages of the crisis. In 2008, new U.S. government policies were introduced to address the lack of modifications. These policies helped in three ways. First, they standardized protocols for modification, which provided servicers of private-label securities some sense of common practice. Second, they provided financial incentives to servicers for modifying loans. Third, they established key criteria for judging whether modifications were sustainable or not, particularly limits on mortgage payments as a percentage of household income. This last policy was to ensure that borrowers could actually repay the modified loans, which prompted lenders to agree more readily to the modification policies in the first place.\n\nIreland and Spain also aimed to restructure nonperforming loans. Again, government involvement was necessary to push these initiatives forward. In Ireland, mortgage arrears continued to accumulate until the introduction of the Mortgage Arrears Resolution Targets scheme in 2013, and in Spain, about 10 percent of mortgages were restructured by 2014, following government initiatives to protect vulnerable households.24 Public initiatives promoting socially desirable mortgage modifications in times of crises tend to be accompanied by explicit public fund support even though government guarantees may be absent in normal times.\n\nWhat Has Been Done? What Needs to Be Done?\nWith the recent crisis fresh in mind, a number of countries have taken steps to strengthen the resilience of their housing finance systems. Many of the most egregious practices that emerged during the lending boom in the United States‑‑such as no- or low-documentation loans or negatively amortizing mortgages‑‑have been severely limited. Other jurisdictions are taking actions as well. Canadian authorities withdrew government insurance backing on non-amortizing lines of credit secured by homes. The United States and the European Union required issuers of securities to retain some of the credit risk in them to better align incentives among participants (although in the United States, MBS issued by Fannie and Freddie are currently exempt from this requirement). And post-crisis, many countries are more actively pursuing macroprudential policies, particularly those targeted at the housing sector.25 New Zealand, Norway, and Denmark instituted tighter LTV limits or guidelines for areas that had overheating housing markets. Globally, the introduction of new capital and liquidity regulations has increased the resilience of the banking system.\n\nBut memories fade. Fannie, Freddie, and the Federal Housing Administration are now the dominant providers of mortgage funding, and the FHLBs have expanded their balance sheets notably. House prices are now high and rising in several countries, perhaps as a result of extended periods of low interest rates.\n\nWhat should be done as we move ahead?\n\nFirst, macroprudential policies can help reduce the incidence and severity of housing crises. While some policies focus on the cost of mortgage credit, others attempt directly to restrict households' ability to borrow. Each policy has its own merits and working out their respective advantages is important.\n\nSecond, government involvement can promote the social benefits of homeownership, but those benefits come at a cost, both directly, for example through the beneficial tax treatment of homeownership, and indirectly through government assumption of risk. To that extent, government support, where present, should be explicit rather than implicit, and the costs should be balanced against the benefits, including greater liquidity in housing finance engendered through a uniform, guaranteed instrument.\n\nThird, a capital regime that takes the possibility of severe stress seriously is important to calm markets and restart the normal process of intermediation should a crisis materialize. A well-capitalized banking system is a necessary condition for stability in bank-based financial systems as well as those with large nonbank sectors. This necessity points to the importance of having resilient banking systems and also stress testing the system against scenarios with sharp declines in house prices.\n\nFourth, rules and expectations for mortgage modifications and foreclosure should be clear and workable. Past experience suggests that both lenders and borrowers benefit substantially from avoiding costly foreclosures. Housing-sector reforms should consider polices that promote efficient modifications in systemic crises.\n\nIn the United States, as around the world, much has been done. The core of the financial system is much stronger, the worst lending practices have been curtailed, much progress has been made in processes to reduce unnecessary foreclosures, and the actions associated with the Housing and Economic Recovery Act of 2008 created some improvement over the previous ambiguity surrounding the status of government support for Fannie and Freddie.\n\nBut there is more to be done, and much improvement to be preserved and built on, for the world as we know it cannot afford another pair of crises of the magnitude of the Great Recession and the Global Financial Crisis.\n\nReferences\n\nAaronson, Daniel (2000). \"A Note on the Benefits of Homeownership,\" Journal of Urban Economics, vol. 47 (May), pp. 356-69.\n\nAdelino, Manuel, Antoinette Schoar, and Felipe Severino (2012). \"Credit Supply and House Prices: Evidence from Mortgage Market Segmentation,\" NBER Working Paper Series 17832. Cambridge, Mass.: National Bureau of Economic Research, February.\n\nAkinci, Ozge, and Jane Olmstead-Rumsey (forthcoming). \"How Effective Are Macroprudential Policies? An Empirical Investigation,\" Journal of Financial Intermediation.\n\nAndritzky, Jochen R. (2014). \"Resolving Residential Mortgage Distress: Time to Modify? (PDF)\" IMF Working Paper WP/14/226. Washington: IMF, December.\n\nBaker, Malcolm, and Jeffrey Wurgler (2013). \"Do Strict Capital Requirements Raise the Cost of Capital? Banking Regulation and the Low Risk Anomaly,\" NBER Working Paper Series 19018. Cambridge, Mass.: National Bureau of Economic Research, May.\n\nCampbell, John Y. (2013). \"Mortgage Market Design,\" Review of Finance, vol. 17 (January), pp. 1-33.\n\nCampbell, John Y., Stefano Giglio, and Parag Pathak (2011). \"Forced Sales and House Prices,\" American Economic Review, vol. 101 (August), pp. 2108-31.\n\nCanada Mortgage and Housing Corporation (2017). \"Loans Administration and Direct Lending,\" webpage, CMHC.\n\nCarbó-Valverde, Santiago, David Marques-Ibanez, and Francisco Rodríguez-Fernández (2012). \"Securitization, Risk-Transferring, and Financial Instability: The Case of Spain,\" Journal of International Money and Finance, vol. 31 (February), pp. 80-101.\n\nCerutti, Eugenio, Stijn Claessens, and Luc Laeven (2017). \"The Use and Effectiveness of Macroprudential Policies: New Evidence,\" Journal of Financial Stability, vol. 28 (February), pp. 203-24.\n\nClaessens, Stijn, M. Ayhan Kose, and Marco E. Terrones (2009). \"What Happens during Recessions, Crunches, and Busts?\" Economic Policy, vol. 24 (October), pp. 653-700.\n\nConnor, Gregory, Thomas Flavin, and Brian O'Kelly (2012). \"The U.S. and Irish Credit Crises: Their Distinctive Differences and Common Features,\" Journal of International Money and Finance, vol. 31 (February), pp. 60-79.\n\nCrowe, Christopher, Deniz Igan, Giovanni Dell'Ariccia, and Pau Rabanal (2011). \"Policies for Macrofinancial Stability: Options to Deal with Real Estate Booms,\" IMF Staff Discussion Notes 11/02. Washington: IMF, March 1.\n\nDeMarzo, Peter M. (2005). \"The Pooling and Tranching of Securities: A Model of Informed Intermediation,\" Review of Financial Studies, vol. 18 (Spring), pp. 1-35.\n\nDiPasquale, Denise, and Edward L. Glaeser (1999). \"Incentives and Social Capital: Are Homeowners Better Citizens?\" Journal of Urban Economics, vol. 45 (March), pp. 354-84.\n\nDuca, John V., John Muellbauer, and Anthony Murphy (2012). \"Credit Standards and the Bubble in U.S. House Prices: New Econometric Evidence (PDF),\" in Property Markets and Financial Stability, BIS Papers 64. Basel, Switzerland: Bank for International Settlements, March, pp. 83-89.\n\nGlaeser, Edward L., Joshua D. Gottlieb, and Joseph Gyourko (2010). \"Can Cheap Credit Explain the Housing Boom?\" NBER Working Paper Series 16230. Cambridge, Mass.: National Bureau of Economic Research, July.\n\nHanson, Samuel G., Anil K. Kashyap, and Jeremy C. Stein (2011). \"A Macroprudential Approach to Financial Regulation,\" Journal of Economic Perspectives, vol. 25 (Winter), pp. 3-28.\n\nInternational Monetary Fund (2011). \"Housing Finance and Financial Stability--Back to Basics?\" in Global Financial Stability Report. Washington: IMF, April.\n\n-------- (2014). \"Israel: Selected Issues (PDF),\" IMF Country Report 14/48. Washington: IMF, February.\n\nKeys, Benjamin J., Tanmoy Mukherjee, Amit Seru, and Vikrant Vig (2010). \"Did Securitization Lead to Lax Screening? Evidence from Subprime Loans,\" Quarterly Journal of Economics, vol. 125 (February), pp. 307-62.\n\nKuttner, Kenneth N., and Ilhyock Shim (2016). \"Can Non-Interest Rate Policies Stabilize Housing Markets? Evidence from a Panel of 57 Economies,\" Journal of Financial Stability, vol. 26 (October), pp. 31-44.\n\nMacroeconomic Assessment Group (2010). Assessing the Macroeconomic Impact of the Transition to Stronger Capital and Liquidity Requirements (PDF) (final report). Basel, Switzerland: Bank for International Settlements, December.\n\nMian, Atif, Kamalesh Rao, and Amir Sufi (2013). \"Household Balance Sheets, Consumption, and the Economic Slump,\" Quarterly Journal of Economics, vol. 128 (November), pp. 1687-1726.\n\nMian, Atif, and Amir Sufi (2014). \"What Explains the 2007-2009 Drop in Employment?\" Econometrica, vol. 82 (November), pp. 2197-2223.\n\nMian, Atif, Amir Sufi, and Francesco Trebbi (2015). \"Foreclosures, House Prices, and the Real Economy,\" Journal of Finance, vol. 70 (December), pp. 2587-2634.\n\nMusgrave, R.A. (1987). \"Merit Goods [dictionary entry],\" in J. Eatwell, M. Milgate, and P. Newman, eds., The New Palgrave: A Dictionary of Economics, vol. 3. London: Macmillan, pp. 452-53.\n\nNadauld, Taylor D., and Shane M. Sherlund (2013). \"The Impact of Securitization on the Expansion of Subprime Credit,\" Journal of Financial Economics, vol. 107 (February), pp. 454-76.\n\nPassmore, Wayne, Shane M. Sherlund, and Gillian Burgess (2005). \"The Effect of Housing Government-Sponsored Enterprises on Mortgage Rates,\" Real Estate Economics, vol. 33 (September), pp. 427-63.\n\nRappoport, David E. (2016). \"Do Mortgage Subsidies Help or Hurt Borrowers? (PDF)\" Finance and Economics Discussion Series 2016-081. Washington: Board of Governors of the Federal Reserve System, October.\n\nReinhart, Carmen M., and Kenneth S. Rogoff (2009). \"The Aftermath of Financial Crises,\" American Economic Review, vol. 99 (May), pp. 466-72.\n\nRohe, William M., and Mark Lindblad (2013). \"Reexamining the Social Benefits of Homeownership after the Housing Crisis,\" working paper. Cambridge, Mass.: Harvard University Joint Center for Housing Studies, August.\n\nSherlund, Shane M. (2008). \"The Jumbo-Conforming Spread: A Semiparametric Approach (PDF),\" Finance and Economics Discussion Series 2008-01. Washington: Board of Governors of the Federal Reserve System, October.\n\nTask Force of the Monetary Policy Committee of the European System of Central Banks (2009). \"Housing Finance in the Euro Area (PDF),\" Occasional Paper Series 101. Frankfurt: European Central Bank, March.\n\nVan den Heuvel, Skander J. (2008). \"The Welfare Cost of Bank Capital Requirements,\" Journal of Monetary Economics, vol. 55 (March), pp. 298-320.\n\n \n\n1. I am grateful to Elizabeth Klee, Andreas Lehnert, Mary Tian, and Alexandros Vardoulakis of the Federal Reserve Board for their assistance. Views expressed in this presentation are my own and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See Reinhart and Rogoff (2009). Return to text\n\n3. See Claessens, Kose, and Terrones (2009). Cerutti, Dagher, and Dell'Arricia (2015) find that the probability of a credit and house price boom being followed within three years by a recession is between 59 and 67 percent, depending on the precise definition of a boom episode. Return to text\n\n4. The concept of a merit good is defined in Musgrave (1987). Research suggests that homeownership is correlated with higher educational attainment (Aaronson 2000), community involvement (DiPasquale and Glaeser, 1999) and lower crime incidence (Rohe and Lindblad, 2013). Return to text\n\n5. An exception to the rule is Germany, where most government policies focus on subsidizing renting, not homeownership. See Campbell (2013). Return to text\n\n6. See the International Monetary Fund's April 2011 Global Financial Stability Report, table 3.5, p.126. Return to text\n\n7. See Canada Mortgage and Housing Corporation (2017). Return to text\n\n8. The National Housing Act of 1934 established the Federal Housing Administration (FHA) and the Federal Savings and Loan Insurance Corporation (FSLIC). Return to text\n\n9. \"Broader\" relative to other countries; see IMF (2011). Return to text\n\n10. See Passmore, Sherlund, and Burgess (2005) and Sherlund (2008). Return to text\n\n11. See Nadauld and Sherlund (2013) and DeMarzo (2005). Return to text\n\n12. See Keys and others (2010) and Nadauld and Sherlund (2013). Return to text\n\n13. Out of that 45 percent, 30 percent was \"true sale\" securitization. See Task Force of the Monetary Policy Committee of the European System of Central Banks (2009). Return to text\n\n14. See Carbó-Valverde, Marques-Ibanez, and Rodríguez-Fernández (2012). Return to text\n\n15. See Task Force of the Monetary Policy Committee of the European System of Central Banks (2009) and Connor, Flavin, and O'Kelly (2012). Return to text\n\n16. See Akinci and Olmstead-Rumsey (forthcoming). Return to text\n\n17. See Cerutti, Claessens, and Laeven (2017). Return to text\n\n18. See Crowe and others (2011); Duca, Muellbauer, and Murphy (2012); and Glaeser, Gottlieb, and Gyourko (2010). Return to text\n\n19. See Kuttner and Shim (2016) and International Monetary Fund (2014). Return to text\n\n20. For example, in 2016, the Norges Bank used house price appreciation as a criterion for raising its countercyclical capital buffer. Return to text\n\n21. Based on a range of estimates for banks' cost of capital and for the elasticity of house prices with respect to interest rates. See Macroeconomic Assessment Group (2010); Baker and Wurgler (2013); Hanson, Kashyap, and Stein (2011); and Van den Heuvel (2008) for a range of estimates for banks' cost of capital. See Adelino, Schoar, and Severino (2012); Glaeser, Gottlieb, and Gyourko (2010); and Rappoport (2016) for a range of estimates for the elasticity of house prices with respect to interest rates. Return to text\n\n22. See Mian, Rao and Sufi (2013) and Mian and Sufi (2014). Return to text\n\n23. See Mian, Sufi, and Trebbi (2015) and Campbell, Giglio, and Pathak (2011). Return to text\n\n24. See Andritzky (2014). Return to text\n\n25. See Akinci and Olmstead-Rumsey (forthcoming). Return to text"
    },
    {
        "title": "Thoughts on the Normalization of Monetary Policy",
        "date": "June 01, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170601a.htm",
        "content": "June 01, 2017\n\nGovernor Jerome H. Powell\n\nAt the Economic Club of New York, New York, New York\n\nThank you for the opportunity to speak here at the Economic Club of New York. Today I will discuss the ongoing progress of our economy and the prospects for returning both the federal funds rate and the size of the Fed's balance sheet to more normal levels. As always, the views I express here are mine and not necessarily those of the Federal Open Market Committee (FOMC).\n\nEconomic Developments\nThe Federal Reserve is committed to fulfilling our statutory mandate of stable prices and maximum employment. To begin with the labor market, many indicators suggest that the economy is close to full employment. In April, the unemployment rate was 4.4 percent, a level not reached since May 2007 and below most current estimates of the natural rate of unemployment (figure 1).1 Estimates of the natural rate are inherently uncertain, but other labor market measures are also near their pre-crisis levels, including a broader measure of labor market underutilization that includes those who would like to work but have not recently looked for a job and those working part time who want full-time work.2 The labor force participation rate, which had declined sharply after the crisis, has now been roughly stable for 3-1/2 years, which represents an improvement against its estimated downward trend (figure 2). Participation is now close to estimates of its trend level.3\n\nWage data have gradually moved up, consistent with a tightening labor market. Although average hourly earnings are rising only about 2.5 percent per year, slower than before the crisis, much of that downshift may reflect the slowdown in productivity growth we have experienced. For example, over the past three years, unit labor costs--that is, nominal wages adjusted for increases in productivity--have been generally rising a bit faster than prices.4\n\nTurning to inflation, the FOMC interprets price stability to mean inflation of 2 percent as measured by the price index for personal consumption expenditures (PCE).5 This objective is symmetric, so the Committee would be concerned if inflation were to run persistently above or below this target. Inflation has run below 2 percent for most of the period since the financial crisis, reflecting generally soft economic conditions as well as transitory factors such as the earlier declines in energy prices. But over the past two years, inflation has moved gradually closer to our objective. Prices rose 1.6 percent over the 12 months ending in April, compared with only 0.2 percent two years earlier (figure 3). But much of that movement reflects price changes in the often-volatile energy and food components of the index. Core inflation, which excludes food and energy prices, has proven historically to be a better indicator of where overall inflation is heading, although it, too, can be affected by transitory factors such as import prices. Core inflation was 1.5 percent for the 12 months through April. This measure has also risen since 2015, although its gradual increase appears to have paused because of weak inflation readings for March and April. Some of the recent weakness can be explained by transitory factors. And there are good reasons to expect that inflation will resume its gradual rise. Incoming spending data have been relatively strong, and the labor market should continue to tighten, exerting some upward pressure on wages and prices. Nonetheless, it is important that the Committee assess incoming inflation data carefully and continue to demonstrate a strong commitment to achieving our symmetric 2 percent objective.\n\nDespite strong job gains, very weak productivity gains have led to disappointingly slow economic growth of only about 2 percent over the course of this expansion (figure 4). While monetary policy can contribute to growth by supporting a durable expansion in a context of price stability, it cannot reliably affect the long-run sustainable level of the economy's growth.6 The success of monetary policy should be judged by the economy's performance against our statutory mandates of price stability and maximum employment. Today, the economy is as close to our assigned goals as it has been for many years (figure 5).\n\nMy baseline expectation is that the economy will continue on a path of growth of about 2 percent, strong job creation and tightening labor markets, and inflation moving up toward our 2 percent target. I expect that unemployment will decline a bit further and remain at low levels for some time, which could draw more workers into the workforce, put upward pressure on wages, or cause businesses to invest more as labor costs rise, all of which I would view as desirable outcomes. Risks to the forecast now seem more balanced than they have been for some time. In particular, the global picture has brightened as growth and inflation have broadly moved up for the first time in several years. Here at home, risks seem both moderate and balanced, including the downside risk of lower inflation and the upside risk of labor market overheating.\n\nMonetary Policy Normalization\nThe healthy state of our economy and favorable outlook suggest that the FOMC should continue the process of normalizing monetary policy. The Committee has been patient in raising rates, and that patience has paid dividends. While the recent performance of the labor market might warrant a faster pace of tightening, inflation has been below target for five years and has moved up only slowly toward 2 percent, which argues for continued patience, especially if that progress slows or stalls. If the economy performs about as expected, I would view it as appropriate to continue to gradually raise rates. I would also see it as appropriate to begin the process of reducing the size of the balance sheet later this year. Of course, both decisions will depend on the performance of the economy.\n\nTo put this process in context, consider where we have come from. Ten years ago, in the summer of 2007, we were just entering the most painful economic crisis since the Great Depression. The crisis and its aftermath prompted large-scale policy interventions by the Federal Reserve and other authorities to avert the collapse of the financial system and prevent the economy from spiraling into depression.\n\nMost of the Federal Reserve's targeted financial measures--such as liquidity facilities to ensure the flow of credit to households and businesses--were withdrawn soon after the crisis as orderly conditions resumed in financial markets. In contrast, the FOMC's easing of monetary policy increased over time as the longer-term economic effects of the crisis gradually became clear. From 2007 through 2013, the FOMC added ever greater support for the economy.7 From late 2008, with rates pinned at the zero lower bound, the Committee resorted to unconventional policies to put additional downward pressure on long-term rates, including strong calendar-based forward guidance regarding the likely future path of the federal funds rate, and several rounds of large-scale asset purchases (often referred to as quantitative easing (QE)).8\n\nBoth the federal funds rate and the balance sheet are currently set at levels intended to provide significant support to economic activity. Normalization of the stance of monetary policy will return both tools to a more neutral setting over time. That process can be said to have begun in 2014, when the FOMC ended its asset purchases and began active discussions on lifting the federal funds rate from its lower bound.9 Our first rate hike came in December 2015, with another in December 2016, and one additional increase so far this year. The normalization process is projected to have several years left to run.\n\nIn the case of the federal funds rate, the endpoint of that process will occur when our target reaches the long-run neutral rate of interest. Estimates of that rate are subject to significant uncertainty. The median estimate of its level by FOMC participants in March was 3 percent, more than a full percentage point below pre-crisis estimates. This decline in the long-run neutral rate, and an even larger decline in the short-run neutral rate, imply that even the very low rates of recent years may be providing less support to the economy than may appear. At present, the median FOMC participant estimates that we will reach a long-run neutral level by year-end 2019 if the economy performs about as expected (figure 6).\n\nThe Balance Sheet\nIn September 2014, the FOMC outlined its plans for the balance sheet. That initial guidance has been supplemented over time in other FOMC communications, most recently in the minutes of the May meeting. Here is a summary of the key points:\n\nTaken together, the Committee's communications present the broad outline of our likely approach to normalizing the balance sheet. Although the process of normalizing the size of the balance sheet will be in the background, that process will interact with the Committee's decisions regarding the federal funds rate. As the Fed's balance sheet shrinks, so debt held by the public will grow, which in theory should tighten financial conditions by putting upward pressure on long-term rates. Any such tightening could affect the Committee's decisions on the federal funds rate. But how big is this effect likely to be?\n\nModel-based approaches to that question estimate changes to financial conditions through increases in the term premium as the balance sheet shrinks. These estimates vary but are generally modest.16 One reason is that, for several years, the FOMC has signaled its intention to normalize the balance sheet as economic conditions allow, and so some of the effects of normalization should already be priced in. A recent research paper by Federal Reserve staff estimated that unconventional policies are holding down term premiums by about 100 basis points, but that these effects should decline to about 85 basis points by the end of 2017 as market participants see the normalization process approaching.17 The same approach suggests that bringing forward the date of the start of the anticipated phasing out of the Federal Reserve's reinvestments from mid-2018 to the end of 2017 should have raised the term premium by only about 5 basis points.18 Of course, markets sometimes react quite differently than expected, as the 2013 taper tantrum showed.\n\nThe market's response to recent changes in expectations for reinvestment policy also suggests that there need not be a major reaction when the Committee begins to phase out reinvestments. Long-term rates did not react strongly to the reinvestment discussions in the minutes for the FOMC's March and May meetings, which led market participants to bring forward their expectations about the starting date for this process by about six months (figure 7).19 A recent survey of economists also suggests that they expect that a gradual, well-telegraphed reduction in the Fed's balance sheet should have modest effects.20 These results augur well for an orderly phaseout of reinvestments. If changes to reinvestment policy do tighten financial conditions more than anticipated, then I expect that the FOMC would take that into account.\n\nThe Long-Run Framework\nOver the next few years, the runoff of assets acquired through QE is expected to reduce the balance sheet substantially below its current level of $4.5 trillion. In the long run, the ultimate size of the balance sheet will depend mainly on the demand for Federal Reserve liabilities--currency, reserves, and other liabilities--and on the Committee's long-run framework for setting interest rates.21\n\nThe next slide compares the Fed's balance sheet of May 2007 with that of May 2017 (figure 8). On the asset side, the balance sheet increased by about $3.5 trillion as the FOMC acquired securities in its QE programs. These assets were matched on the liability side of the Federal Reserve's balance sheet by a $2.2 trillion increase in reserve balances held by commercial banks, a $700 billion increase in currency outstanding, and a $500 billion increase in other liabilities.\n\nAs can be seen more clearly in the next slide, prior to the crisis, currency was the Fed's main liability (figure 9). Currency outstanding has nearly doubled over the past 10 years to $1.5 trillion, growing at a compound annual rate of 6.8 percent. This growth reflects strong domestic and international demand for U.S. currency, which is expected to continue. The eventual level of demand for reserves is less certain but is highly likely to exceed pre-crisis levels when reserve balances averaged only about $15 billion. Reserves are the ultimate \"safe asset,\" and demand for safe assets has increased substantially over time because of long-run trends, including regulatory requirements. Other liabilities include the Treasury General Account, the foreign repurchase agreement (or repo) pool, balances held at the Fed by designated financial market utilities, and other items.\n\nTo gain a sense of the possible long-run size of the balance sheet, the next slide shows simulations under three different assumptions for the ultimate level of reserve balances: $100 billion, $600 billion, and $1 trillion (figure 10).22 These simulations show that, due to the growth of currency and other liabilities, the balance sheet will remain considerably above its pre-crisis levels even if reserves were to fall back to $100 billion (the black line). At its current growth rate, currency in circulation would reach $2 trillion by 2022 and $2.8 trillion in 2027. Even in the low case in which reserves decline to $100 billion, our balance sheet would be about $2.4 trillion in 2022 and would grow from there in line with currency demand. If the long-run level of reserves is $600 billion in 2022, then the balance sheet would be about $2.9 trillion.23\n\nThe appropriate long-run level of reserves will also depend on the operating framework the Committee chooses. Before the crisis, reserves were scarce, and the Committee used open market operations to control the federal funds rate by managing reserve supply. This process was operationally and resource intensive for the Desk and its counterparties. As a consequence of QE, however, reserves have been highly abundant and will remain so for some years. To affect financial conditions, the Federal Reserve has therefore used administered rates, including the interest rate paid on excess reserves (IOER) and, more recently, the offering rate of the overnight reverse repurchase agreement (ON RRP) facility. This approach, sometimes referred to as a \"floor system,\" is simple to operate and has provided good control over the federal funds rate. In November 2016, when the Committee discussed using a floor system as part of its longer-run framework, I was among those who saw such an approach as \"likely to be relatively simple and efficient to administer, relatively straightforward to communicate, and effective in enabling interest rate control across a wide range of circumstances.\"24\n\nSome have advocated a return to a framework similar to the pre-2007 system, in which the volume of reserves would likely be far below its present level and the federal funds rate would be managed by frequent open market operations.25 This \"corridor\" framework remains a feasible option, although, in my view, it may be less robust over time than a floor system.\n\nConcluding Remarks\nAfter a tumultuous decade, the economy is now close to full employment and price stability. The problems that some commentators predicted have not come to pass. Accommodative policy did not generate high inflation or excessive credit growth; rather, it helped restore full employment and return inflation closer to our 2 percent goal. The current discussions of the normalization of monetary policy are a result of that success.\n\n1. For example, the Congressional Budget Office estimates that the natural rate of unemployment is currently 4.7 percent. The March 2017 Blue Chip Economic Indicators reported that the consensus forecast for the unemployment rate over 2024 to 2028 was 4.7 percent, with the top 10 projections averaging 5.1 percent and the bottom 10 averaging 4.3 percent. The median estimate of the longer-run normal rate of unemployment in the March 2017 Summary of Economic Projections was 4.7 percent. The uncertainty around these estimates is large. The canonical paper by Staiger, Stock, and Watson puts the 95 percent confidence interval at 1-1/2 percentage points on either side of the point estimate; see Douglas Staiger, James H. Stock, and Mark W. Watson (1997), \"How Precise Are Estimates of the Natural Rate of Unemployment?\" in Christina D. Romer and David H. Romer, eds., Reducing Inflation: Motivation and Strategy (Chicago: University of Chicago Press). Return to text\n\n2. The broader measure is the Bureau of Labor Statistics' U-6 alternative measure of labor underutilization. Return to text\n\n3. The labor force participation rate is currently slightly below the Congressional Budget Office's estimate of trend and slightly above trend estimates based on the methodology of Aaronson and others. See Congressional Budget Office (2017), The Budget and Economic Outlook: 2017 to 2027 (Washington: CBO, January); and Stephanie Aaronson, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014), \"Labor Force Participation: Recent Developments and Future Prospects,\" Brookings Papers on Economic Activity, Fall, pp. 197-275. Return to text\n\n4. There are several other measures of nominal wage growth in addition to the Bureau of Labor Statistics' (BLS) average hourly earnings. The BLS employment cost index measure of year-over-year wage and salary growth was also 2.5 percent in the first quarter, while the BLS measure of compensation per hour rose to 3.9 percent. Compensation per hour is quite volatile and subject to large revisions. The unit labor cost measure is based on the BLS measures of compensation per hour and productivity for the business sector. All of these measures indicate that compensation has picked up in recent years. Return to text\n\n5. See Federal Open Market Committee (2017), Statement on Longer-Run Goals and Monetary Policy Strategy (PDF), amended effective January 31 (original version adopted effective January 24, 2012). Return to text\n\n6. I have argued elsewhere that we need to find ways to increase our long-term growth and spread that prosperity broadly if we are to avoid this \"low growth trap.\" We need policies that support business investment, labor force participation, and productivity growth. Increased spending on public infrastructure may raise private-sector productivity over time. Greater support for public and private research and development, encouragement of workers to increase their skills, and policies that improve product and labor market dynamism may also be fruitful. See Jerome H. Powell (2016), \"Recent Economic Developments and Longer-Run Challenges,\" speech delivered at the Economic Club of Indiana, Indianapolis, Indiana, November 29, Return to text\n\n7. A chronology of changes in the FOMC's target federal funds rate is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/openmarket.htm. Return to text\n\n8. The FOMC's purchases of longer-term securities (U.S. Treasury securities, agency debt obligations, and agency-guaranteed mortgage-backed securities) reduced the outstanding stock of these securities available in the market and therefore tended to put upward pressure on bond prices and downward pressure on their yields--specifically, on the term premium component of longer-term interest rates. This unconventional monetary policy was an appropriate means of providing a boost to spending by households and firms during a period of economic slack, when our ability to provide accommodation by conventional means was limited by the fact that the federal funds rate had reached almost zero. Return to text\n\n9. Over this period, the size of the balance sheet has been maintained by our reinvestment policy, which I will consider later in the remarks. Return to text\n\n10. See Board of Governors of the Federal Reserve System (2015), \"Federal Reserve Issues FOMC Statement,\" press release, December 16. Return to text\n\n11. See Board of Governors of the Federal Reserve System (2017), \"Minutes of the Federal Open Market Committee, May 2-3, 2017,\" press release, May 24. Return to text\n\n12. See Board of Governors of the Federal Reserve System (2014), \"Federal Reserve Issues FOMC Statement on Policy Normalization Principles and Plans,\" press release, September 17. Return to text\n\n13. See Board of Governors of the Federal Reserve System (2017), \"Minutes of the Federal Open Market Committee, March 14-15, 2017,\" press release, April 5. Return to text\n\n14. See Board of Governors, \"Minutes of the Federal Open Market Committee, May 2-3, 2017,\" in note 11. Return to text\n\n15. See Board of Governors, \"Federal Reserve Issues FOMC Statement on Policy Normalization Principles and Plans,\" in note 12. Return to text\n\n16. See, for example, Eric M. Engen, Thomas Laubach, and David Reifschneider (2015), \"The Macroeconomic Effects of the Federal Reserve's Unconventional Monetary Policies (PDF),\" Finance and Economics Discussion Series 2015-005 (Washington: Board of Governors of the Federal Reserve System, February), http://dx.doi.org/10.17016/FEDS.2015.005; Brian Bonis, Jane Ihrig, and Min Wei (2017), \"The Effect of the Federal Reserve's Securities Holdings on Longer-Term Interest Rates,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, April 20), https://dx.doi.org/10.17016/2380-7172.1977; and Troy Davig and A. Lee Smith (2017), \"Forecasting the Stance of Monetary Policy under Balance Sheet Adjustments (PDF),\" Macro Bulletin (Kansas City, Mo.: Federal Reserve Bank of Kansas City, May 10). Return to text\n\n17. See Bonis, Ihrig, and Wei, \"Effect of the Federal Reserve's Securities Holdings,\" in note 16. Return to text\n\n18. Of course, estimates of the effects of monetary policy on term premiums often differ. Engen, Laubach, and Reifschneider estimated that the Federal Reserve's asset purchases are currently holding down term premiums by about 60 basis points, less than the estimate of Bonis, Ihrig, and Wei, but their findings still imply a similar small effect of bringing forward the date of normalization by six months; see Bonis, Ihrig, and Wei, \"Effect of the Federal Reserve's Securities Holdings,\" and Engen, Laubach, and Reifschneider, \"Macroeconomic Effects,\" in note 16. Return to text\n\n19. See the results of the March and May 2017 primary dealer surveys, which are available on the Federal Reserve Bank of New York's website at https://www.newyorkfed.org/markets/primarydealer_survey_questions.html. Return to text\n\n20. See David Harrison (2017), \"Economists See Modest Impact from a Fed Balance-Sheet Reduction,\" Wall Street Journal, May 11. Return to text\n\n21. For a more detailed discussion of the longer-run framework, see Lorie K. Logan (2017), \"Implementing Monetary Policy: Perspective from the Open Market Trading Desk,\" speech delivered at the Money Marketeers of New York University, New York, May 18. Return to text\n\n22. The intermediate figure of $600 billion is based on the Federal Reserve Bank of New York's May 2017 surveys of primary dealers and market participants. Following the 2017 study by Ferris, Kim, and Schlusche, the federal funds rate path used in the balance sheet simulations consists of the modal path given in the FOMC participants' Summary of Economic Projections (SEP); see Erin E. Syron Ferris, Soo Jeong Kim, and Bernd Schlusche (2017), \"Confidence Interval Projections of the Federal Reserve Balance Sheet and Income,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, January 13), https://dx.doi.org/10.17016/2380-7172.1875. In the simulations shown here, the SEP used pertains to the projections submitted in conjunction with the March 2017 FOMC meeting. All three of the simulated balance sheet paths shown are predicated on a 12-month reinvestment phaseout commencing in late 2017. The FRB/US model is used to generate the associated paths of the 10-year Treasury yield as well as the paths of other financial and macroeconomic variables. Different paths of these variables imply different trajectories of the balance sheet, in part by changing the implied path of currency in circulation. Other assumptions used in generating the simulations are like those described in Ferris, Kim, and Schlusche (2017). The time of balance sheet normalization is defined as the point at which reserve balances decline to their assumed terminal value. Both in Ferris, Kim, and Schlusche (2017) and in the illustration here, the evolution of the balance sheet is represented by the path of the Federal Reserve's System Open Market Account holdings. Return to text\n\n23. In the simulations from which these values are obtained, it is assumed that some prominent items in the \"Other liabilities\" category diminish to zero by the end of 2022. Return to text\n\n24. See Board of Governors of the Federal Reserve System (2016), \"Minutes of the Federal Open Market Committee, November 1-2, 2016,\" press release, November 23, paragraph 6. Return to text\n\n25. See, for example, John B. Taylor (2016), \"Interest on Reserves and the Fed's Balance Sheet,\" Cato Journal, vol. 36 (Fall), pp. 711-20. Return to text"
    },
    {
        "title": "Navigating the Different Signals from Inflation and Unemployment",
        "date": "May 30, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170530a.htm",
        "content": "May 30, 2017\n\nGovernor Lael Brainard\n\nAt the New York Association for Business Economics, New York, New York\n\nFor the first time in many years, we are seeing signs of synchronized economic expansions at home and abroad, and the balance of risks globally has become more positive. Recent data suggest that the underlying momentum of the domestic expansion remains solid. While U.S. consumption was weak in the first quarter of 2017, the data so far are consistent with a rebound in the current quarter. Moreover, financial conditions remain supportive of continued economic expansion despite some recent volatility.1\n\nThe ongoing progress in bringing Americans back into productive employment is especially heartening. With continued strength in the labor market, economic activity regaining momentum, and a brighter outlook abroad, it would be appropriate soon to see the federal funds rate moving closer to its neutral level. If the economy evolves in line with the March Summary of Economic Projections (SEP) median path, normalization of the federal funds rate is likely to be well underway before too long, setting the stage for a gradual and predictable running off of the balance sheet.\n\nEven so, I see some tension between signs that the economy is in the neighborhood of full employment and indications that the tentative progress we had seen on inflation may be slowing. If the tension between the progress on employment and the lack of progress on inflation persists, it may lead me to reassess the expected path of the federal funds rate in the future, although it is premature to make that call today.\n\nDifferent Signals from the Labor Market and Inflation\nLet me start by reviewing the conflicting readings we are getting from the labor market and from inflation.\n\nThe labor market has continued to strengthen. Payroll growth has averaged 175,000 over the past three months, more than sufficient to absorb new entrants into the labor market. Although earlier in the recovery, it appeared that the U-3 unemployment rate was running ahead of broader indicators of slack, more recently, it has been encouraging to see other margins of slack being drawn down. The labor force participation rate has held stable, against what many believe to be a downward trend based on demographics, and the employment-to-population ratio has reached a new post-recession high. Moreover, the share of employees who work part time for economic reasons has recently moved down close to its pre-crisis level, after a long period of remaining at elevated levels.\n\nThe most commonly used U-3 measure of the unemployment rate moved down to 4.4 percent in April. This happens to be the cyclical low reached in 2006-07, although unemployment was at or below this level much of the time from the middle of 1998 to the middle of 2001. Relative to recent decades, the unemployment rate is now quite low. In fact, some have voiced concerns that the economy has proven unable to sustain its expansion when the unemployment rate has fallen below these levels. With that in mind, it is worth asking whether we should be worried that history will inevitably repeat itself.\n\nThe truth is, we cannot know for sure. Although rising inflation often heralded the death knell of economic expansions in earlier decades, inflation expectations have been well anchored and rising inflation has presented less of a risk in the most recent business cycles.2 From 1998 to 2001, for instance, core personal consumption expenditures (PCE) inflation never exceeded 2 percent on a four-quarter basis. Core PCE inflation did reach as high as 2.4 percent in the period from 2006 to 2007, but, at the time, this higher inflation was viewed as reflecting the pass-through of a significant run-up in energy and non-energy import prices.3\n\nToday, there is little indication of an outbreak of inflation--rather, the latest data on inflation have been lower than expected. If anything, the puzzle today is why inflation appears to be slowing at a time when most forecasters place the economy at or near full employment.\n\nEven wage inflation, which is most tightly connected to labor market slack, shows little sign of heating up by most measures. Overall, wages are increasing a bit more rapidly than they were a few years ago, but the latest data on wages do not show much progress over the past year. Average hourly earnings rose only 2-1/2 percent in the 12 months through April, the same as a year earlier. Similarly, the employment cost index was up only 2-1/4 percent in the 12 months through March. While that is up from a year earlier, it is lower than two years ago. The Atlanta Fed's Wage Growth Tracker tells a similar story: Upward movement in wage gains was observed until about a year or so ago, but there has been little acceleration recently.\n\nTurning to overall inflation, earlier this year, reports indicated that the Federal Open Market Committee's (FOMC) preferred measure of inflation--the headline measure of consumer price inflation on a national accounts basis--had, on a 12-month change basis, risen close to the FOMC's objective, but the latest figures have edged down somewhat as the rebound in energy prices has abated. I tend to place greater weight on the core measure of inflation, which abstracts from the transitory movements in energy prices and is a better predictor of future inflation. In the April report, the core measure--that is, excluding food and energy prices--had increased only 1.5 percent on a 12-month change basis. That reading marks a considerable shortfall from the Committee's 2 percent objective. And there does not seem to have been any progress over the past year or so: Core PCE inflation is about the same over the past 12 months as over the preceding period. Although the past two monthly readings of core inflation have been held down in part by idiosyncratic factors, including upgrades to cell-phone plans, the apparent lack of progress in moving core inflation back to 2 percent is a source of concern.\n\nTraditionally, economists assessed that as labor market slack diminished and the economy approached full employment, upward pressure on inflation would result, in the statistical relationship known as the Phillips curve. But I am not confident we can count on the Phillips curve to restore inflation to target in today's economy. Since 2012, inflation has tended to change relatively little--both absolutely and relative to earlier decades--as the unemployment rate has fallen considerably.4 At a time when the unemployment rate has fallen from 8.2 percent to 4.4 percent, core inflation has undershot our 2 percent target for 58 straight months.5 In other words, the Phillips curve appears to be flatter today than it was previously. This is also true in a number of advanced foreign economies, where declines in unemployment rates to low levels have failed to generate significant upward pressures on inflation.\n\nWith the Phillips curve appearing to be a less reliable guidepost than it has been in the past, the anchoring role of inflation expectations remains critically important. Here, recent developments are mixed. The May reading of the University of Michigan Surveys of Consumers' measure of longer-term inflation expectations remained near its all-time low, while the New York Fed's measure of three-year inflation expectations edged up in its latest reading to the highest level in more than a year. And although market-based measures of inflation compensation have improved relative to their lows in the middle of last year, they are still below the average level in the period from 2010 to 2014.\n\nAttaining the Committee's symmetric target for inflation on a sustainable basis is especially important in the current environment, with the neutral real interest rate at historically lower levels, in order to ensure conventional policy has room to respond to unexpected adverse developments. Underlying fundamentals, such as import prices and diminishing slack, should lead inflation to resume moving closer to its goal. Nonetheless, currently I see more signs that progress on inflation is slowing than of a breakout of inflation to the upside, as might be the case with a nonlinearity in the relationship between inflation and unemployment when unemployment is very low.6\n\nBut as noted earlier, a breakout in inflation also was not a primary concern following the past two times the unemployment rate dropped as low as it is now, in 1998 and 2006, when recessions followed within two or three years. One notable feature of both episodes was that they were preceded by sharply elevated financial imbalances. In the late 1990s, equity prices had reached very high levels, according to common measures of stock market valuations. And the period from 2006 to 2007 coincided with a house price bubble, along with extreme leverage at a number of large financial institutions and widespread use of exotic financial products.\n\nBroadly speaking, financial conditions today appear to be more balanced: In most markets, house prices seem fairly well aligned with rents. Large banks are much better capitalized than before the crisis and appear to be managing their risk exposures and liquidity much more carefully. While today's equity market valuations appear somewhat elevated, they do not seem to be near the dizzying heights reached in 1999 and 2000. Moreover, for a variety of reasons, importantly including critical financial reforms as well as changes in risk appetite, leverage and maturity transformation are at much lower levels than they were before the crisis.\n\nOne area that merits ongoing vigilance is corporate indebtedness, which remains at a high level and where investor appetite still seems strong. Another area of concern is auto lending--particularly in the subprime segment--where underwriting appears to have become quite lax last year and, consequently, delinquency rates indicate more borrowers struggling to keep up with their payments. Eight years into the recovery, it is important to recognize that financial conditions can change rapidly and bear special vigilance. Nonetheless, risks to the U.S. financial system do not appear to be flashing red in the way they did in the run-up to previous downturns.\n\nIt is also possible that the natural rate of unemployment has moved lower or that the unemployment rate still may be overstating the strength of the labor market. While it is encouraging that the share of employees who work part time for economic reasons has continued to move down, there may well be slack remaining along this margin. And another key measure--the prime-age employment-to-population ratio--remains more than 1 percentage point below pre-crisis levels, and further improvement there would be welcome.\n\nThe Outlook\nLooking at economic activity more broadly, although first-quarter gross domestic product (GDP) was soft, the data so far suggest a rebound in the second quarter. The weak Q1 reading follows a recurring pattern in recent years, with the first quarter of the year often weaker than subsequent quarters. Moreover, below the top-line number, there were some encouraging signs of strength: Residential construction posted a double-digit increase and contributed 1/2 percentage point to first-quarter GDP growth. Drilling for oil and natural gas is rebounding sharply, and nonresidential construction contributed 3/4 percentage point to first-quarter GDP growth. Business spending on equipment and intangibles, which fell slightly in 2016, rebounded to a 7 percent annualized increase in the first quarter and contributed another 3/4 percentage point to the overall increase.\n\nA key reason overall GDP was so weak last quarter was consumer spending, which rose only 0.6 percent at an annual rate. Nonetheless, there are good reasons to think that the first-quarter weakness in consumer spending will not persist. Household incomes should continue rising with the continued strengthening in employment and wages, home prices should be contributing through improved household balance sheets, and consumer sentiment remains upbeat.\n\nRecent changes in financial conditions have, overall, been supportive of further gains in the real economy. The S&P 500 index is up almost 8 percent since the start of the year. At the same time, a broad measure of the exchange value of the dollar is down about 4 percent so far this year, which should help boost net exports. After moving up sharply late last year, long-term interest rates have moved down somewhat so far this year.\n\nIn addition, the balance of risks has shifted over the past two quarters, with a number of downside risks receding and some upside risks emerging. In particular, the latest international economic data have suggested waning downside risks from abroad, while continued labor market strength and the prospect for fiscal stimulus in the United States present a possible upside risk to domestic demand.\n\nImportantly, we are seeing synchronized global growth for the first time in many years. Growth forecasts for both advanced and emerging market economies are being marked up, breaking a pattern of repeated downward revisions from 2013 to 2016. Recent political developments significantly enhanced the prospects for policy continuity in the euro area, and there has been continued growth in euro-area employment and economic activity. While Italy continues to face political, economic, and financial risks, recent developments augur well for the resilience of the broader euro area.\n\nChina's first-quarter growth came in above 7 percent at an annual rate, although there appears to have been some moderation since then, and capital outflows slowed notably. China's economy bears watching in the medium term, especially given financial-sector risks and elevated debt levels. Although Mexico's growth may moderate this year, both the Mexican equity market and the exchange rate have strengthened, along with confidence, following sharp falls late last year.\n\nAlong with the favorable shift in foreign risks, recent announcements on fiscal policy suggest some upside risk to U.S. aggregate demand. The Administration has proposed deep tax cuts, which, if implemented, could amount to about 2 percentage points of GDP in the first few years according to independent estimates. Most estimates suggest that the supply-side effects of these policies would be fairly small, so, if enacted, the net effect could well be a boost to U.S. aggregate demand at a time when the economy could be at full employment. Nonetheless, there is considerable uncertainty about the magnitude and timing of any policy changes. There is also important uncertainty about the deliberations over the debt limit, which are likely to garner increasing attention in the early fall and will factor into my considerations of risks to the outlook.\n\nThe Path of Policy\nOn balance, when assessing economic activity and its likely evolution, it would be reasonable to conclude that further removal of accommodation will likely be appropriate soon. As I noted earlier, the unemployment rate is now at 4.4 percent, and we are seeing improvement in other measures of labor market slack, such as participation and the share of those working part time for economic reasons. There are good reasons to believe that the improvement in real economic activity will continue: Financial conditions remain supportive. Indicators of sentiment remain positive. The balance of risks at home has shifted favorably, downside risks from abroad are lower than they have been in several years, and we are seeing synchronous global growth.\n\nThe time for a change in balance sheet policy is coming into clearer view as normalization of the federal funds rate approaches the range that can be considered \"well under way.\" If the outlook and the expected federal funds rate path evolve in line with the median projection of FOMC participants reported in the March SEP, the federal funds rate will soon approach midway to its expected long-run equilibrium value.\n\nI shared my framework for thinking about the change in balance sheet policy in early March, and today I will elaborate on the approach that seems most appropriate to achievement of our goals.7 Consideration that normalization of the federal funds rate is well underway was the criterion the Committee adopted in its December 2015 decision to continue to reinvest principal payments. In my view, that \"well under way\" standard has served an important purpose.8 With asymmetry in the scope for conventional monetary policy to respond to shocks, maintaining reinvestments provided an important benefit by enabling the federal funds rate to rise more quickly than would have been possible with a shrinking balance sheet and sooner reach a level that allows for reductions if conditions deteriorate. This approach has ensured that our most proven tool, the federal funds rate, will have reached a level at which it can be cut if needed to buffer adverse shocks, thus helping to guard against the asymmetric risks associated with the effective lower bound. With the federal funds rate projected to be in the range that is midway to the Committee's projection of the long-run value of the federal funds rate later this year, I would consider it reasonable to assess that this threshold will have been attained before too long.\n\nAs we shrink the size of our balance sheet, the public's holdings of Treasury securities will rise, and that will tend to boost longer-term interest rates. In particular, most studies conclude that increases in central bank holdings of longer-maturity assets chiefly affect interest rates by reducing the quantity of longer-term securities held by the public and putting downward pressure on the term premium--that is, the difference between the yields on longer-dated assets and the path of expected short-term interest rates over the holding period. By some estimates, the effect is modestly above 90 basis points currently.9 Thus, balance sheet normalization should be associated with higher term premiums, which in turn, other things held equal, should be associated with higher long-term Treasury yields. Most studies find that higher Treasury yields also affect yields and prices of other securities: increasing interest rates faced by private-sector borrowers, making dollar-denominated assets more attractive, which tends to boost the exchange value of the dollar, and making fixed-income assets more attractive relative to stocks, tending to depress share prices. Together, these channels contribute to a tightening in financial conditions.10\n\nThese effects are, of course, in many respects, similar to the effects of increases in short-term interest rates.11 Thus, away from the zero lower bound, the two tools are, to a large extent, substitutes for one another. As a result, the FOMC will be in the unfamiliar posture of having two tools available for adjusting monetary policy. It is, therefore, important to clarify how they will be used in relation to each other. While, under most circumstances, the two tools are largely substitutes for one another in terms of their effects on the economy the federal funds rate is the tool with which we have the most experience. And using two tools at once could easily foster confusion. Thus, in my view, predictability, precision, and clarity of communications all argue in favor of focusing policy on the federal funds rate as the single active tool. In this framework, the balance sheet essentially would remain subordinate to the federal funds rate.\n\nUnder the subordinated balance sheet approach, once the change in reinvestment policy is triggered, the balance sheet would essentially be set on autopilot to shrink passively until it reaches a neutral level, expanding in line with the demand for currency thereafter. I favor an approach that would gradually and predictably increase the maximum amount of securities the market will be required to absorb each month, while avoiding spikes. Thus, in an abundance of caution, I prefer to cap monthly redemptions at a pace that gradually increases over a fixed period. In addition, I would be inclined to follow a similar approach in managing the reduction of the holdings of Treasury securities and mortgage-backed securities (MBS), calibrated according to their particular characteristics.\n\nThe Committee's policy normalization principles have made clear that the Federal Reserve \"will, in the longer run, hold no more securities than necessary to implement monetary policy efficiently and effectively.\"12 Over time, the gradual reduction in our balance sheet should result in a gradual decline in reserves to a longer-run level that is well below today's level but likely somewhat higher than in the pre-crisis regime. It is difficult to know in advance with any precision how low reserves can be allowed to drop. That minimum level will depend on the structural demand for reserves and the short-term variability in the demand for and supply of reserves. During the process of balance sheet normalization, I favor an approach of monitoring money markets carefully to gauge the appropriate longer-run level of reserves consistent with efficient and effective policy implementation.\n\nFinally, while subordination of the balance sheet to the federal funds rate should be our baseline policy, in my view, there may be circumstances when we may need to rely on the balance sheet more actively. During the period when the balance sheet is running down, if the economy encounters significant adverse shocks, it may be appropriate to commence the reinvestment of principal payments again in order to preserve conventional policy space.\n\nConclusion\nIn recent quarters, the balance of risks has become more favorable, the global outlook has brightened, and financial conditions have eased on net. With the labor market continuing to strengthen, and GDP growth expected to rebound in the second quarter, it likely will be appropriate soon to adjust the federal funds rate. And if the economy evolves in line with the SEP median path, the federal funds rate will likely approach the point at which normalization can be considered well under way before too long, when it will be appropriate to adjust balance sheet policy. I support an approach that retains the federal funds rate as the primary tool for adjusting monetary policy, sets the balance sheet to shrink in a gradual and predictable way for both Treasury securities and MBS, and avoids spikes in redemptions.\n\nWhile that remains my baseline expectation, I will be watching carefully for any signs that progress toward our inflation objective is slowing. With a low neutral real rate, achieving our symmetric inflation target is more important than ever in order to preserve some room for conventional policy to buffer adverse developments in the economy. If the soft inflation data persist, that would be concerning and, ultimately, could lead me to reassess the appropriate path of policy.\n\nReferences\nBlanchard, Olivier (2016). \"The U.S. Phillips Curve: Back to the 60s? (PDF)\" Policy Brief PB16‑1. Washington: Peterson Institute for International Economics, January.\n\nBoard of Governors of the Federal Reserve System (2007). \"Minutes of the Federal Open Market Committee, March 20-21,\" press release, April 11.\n\nBonis, Brian, Jane Ihrig, and Min Wei (2017). \"The Effect of the Federal Reserve's Securities Holdings on Longer-Term Interest Rates,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, April 20.\n\nBrainard, Lael (2015a). \"Economic Outlook and Monetary Policy,\" speech delivered at \"North America's Place in a Changing World Economy,\" 57th National Association for Business Economics Annual Meeting, Washington, October 12.\n\n-------- (2015b). \"Normalizing Monetary Policy When the Neutral Interest Rate Is Low,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford, Calif., December 1.\n\n-------- (2017). \"Transitions in the Outlook and Monetary Policy,\" speech delivered at the John F. Kennedy School of Government, Harvard University, Cambridge, Mass., March 1.\n\nIhrig, Jane, Elizabeth Klee, Canlin Li, Brett Schulte, and Min Wei (2012). \"Expectations about the Federal Reserve's Balance Sheet and the Term Structure of Interest Rates (PDF),\" Finance and Economics Discussion Series 2012-57. Washington: Board of Governors of the Federal Reserve System, July.\n\nKiley, Michael T. (2015). \"Low Inflation in the United States: A Summary of Recent Research,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, November 23.\n\nNalewaik, Jeremy (2016). \"Non-Linear Phillips Curves with Inflation Regime-Switching (PDF),\" Finance and Economics Discussion Series 2016‑078. Washington: Board of Governors of the Federal Reserve System.\n\nI am grateful to Jim Clouse and John Roberts for their assistance in preparing this text.\n\n1. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. In the period from 1950 to 2000, inflation often rose late in the business cycle. In response, the Federal Reserve raised interest rates, which in turn led to a weaker economy. Return to text\n\n3. For example, the FOMC minutes for March 2007 expressed \"concern\" about the rate of inflation but noted that increases in energy and non-energy imports could explain some of the upward pressure on core prices (see Board of Governors, 2007, paragraph 23). The outlook was for a gradual decline in core inflation. Return to text\n\n4. See Blanchard (2016), Kiley (2015), and Brainard (2015a). Similarly, inflation did not fall very much as the unemployment rate climbed to 10 percent during the Great Recession. Return to text\n\n5. The inflation information refers to core PCE inflation measured on a 12-month average basis. Return to text\n\n6. See Nalewaik (2016). Return to text\n\n7. See Brainard (2017). Return to text\n\n8. This rationale is in Brainard (2015b). Return to text\n\n9. Bonis, Ihrig, and Wei (2017) estimate that the cumulative effect of the Federal Reserve's asset purchases results in a reduction in the 10-year Treasury yield term premium moderately in excess of 90 basis points currently. Return to text\n\n10. It seems likely that many investors have developed an expectation of the likely path of the Federal Reserve’s balance sheet once the process of normalization is well underway, and these expectations are already priced into asset prices. See, for instance, Federal Reserve Bank of New York May 2017 Responses to Survey of Primary Dealers (PDF), and Responses to Survey of Market Participants (PDF). Return to text\n\n11. There may be differences in the specific ways changes in short-term rates and the balance sheet transmit to different asset prices and the exchange rate, although estimates are limited and lack precision. Return to text\n\n12. See the Committee's Policy Normalization Principles and Plans, available on the Board's website at https://www.federalreserve.gov/newsevents/press/monetary/20140917c.htm. Return to text"
    },
    {
        "title": "Why Opportunity and Inclusion Matter to America’s Economic Strength",
        "date": "May 22, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170522a.htm",
        "content": "May 22, 2017\n\nGovernor Lael Brainard\n\nAt the Opportunity and Inclusive Growth Institute Conference, sponsored by the Federal Reserve Bank of Minneapolis\n\nI want to thank Neel Kashkari for launching the Opportunity and Inclusive Growth Institute and for inviting me to join the deliberations of this distinguished group today. This new Institute is another great example of how individual Reserve Banks are taking the initiative in illuminating key dimensions of our work and shaping the agenda of the Federal Reserve System.1\n\nWhile it has long been understood that opportunity is central to the strength of America's social fabric, it is now increasingly clear that opportunity and inclusion are central to the strength of America's economy. I will touch on the key ways that opportunity and inclusion matter for policymaking at the Federal Reserve, ranging from our dual-mandate goal of maximum employment to our monitoring of household financial health to our engagement in low- and moderate-income communities all over the country. I will focus on how our work intersects with the groundbreaking work of the accomplished group of researchers assembled here.\n\nIn the original design of the Federal Reserve, it was recognized that the American economy is not monolithic; that is why the Congress created our system of 12 Federal Reserve Districts. We are present in communities all across America through our Reserve Banks and Branches and their boards and advisory councils. This local presence, by design, gives us valuable perspectives on how Americans are experiencing the economy in different communities around the country and critical insights about the varied challenges that lie beneath the aggregate numbers. In turn, our local engagement helps stakeholders in these communities partner to improve opportunity and inclusive growth.\n\nInclusion and Maximum Employment\nInclusion is an enduring goal of public policy that is embodied in our maximum-employment mandate. The Employment Act of 1946 charges the federal government with creating \"conditions under which there will be afforded useful employment for those able, willing, and seeking to work, and to promote maximum employment, production, and purchasing power.\"2 Maximum employment is inherently an inclusive goal. In 1977, the Congress amended the Federal Reserve Act to make achieving maximum employment an explicit objective of monetary policy, along with stable prices. In fulfilling its dual mandate, the Federal Open Market Committee (FOMC) has set a target of 2 percent for inflation but does not have a similarly fixed numerical goal for maximum employment. That is because the level of maximum employment depends on \"nonmonetary factors that affect the structure and dynamics of the labor market,\" which can change in important ways over time.3\n\nThe recognition that maximum employment evolves over time to reflect changes in the economic landscape serves us well. It puts the onus on members of the FOMC to analyze the changing features of the labor market and develop a nuanced understanding of the different margins of slack. This approach to maximum employment has allowed the FOMC to navigate the current recovery in a way that has likely brought more people back into productive employment than might have been the case with a fixed, aggregate unemployment-rate target based on pre-crisis norms, in effect, achieving more inclusive growth. This is especially true at a time when the traditional Phillips curve relationship between unemployment and inflation is extremely flat for reasons we do not fully understand.\n\nWhen we disaggregate the economy-wide labor market statistics, we often find significant and persistent racial disparities.4 For many decades, the unemployment rate of African Americans has been nearly double the national unemployment rate, with little indication that the relative difference is narrowing or that it can be fully accounted for by education or sectoral mix; the unemployment rate for Hispanics also has consistently been higher than the national unemployment rate.5 Similarly, during the Great Recession, the unemployment rates of African Americans and Hispanics rose more sharply and rapidly than for workers as a whole.6 Even though the unemployment rates of these groups are back around their pre-recession levels, they remain higher than the national average. We can also see persistent disparities by gender, such as the well-known wage premium earned by men relative to women with similar experience and expertise.7 With its focus on inclusive growth, this Institute could give us important insights on how far the overall economy is from full employment, as well as the barriers that could be limiting the economy's potential, by studying labor market outcomes of men and women of different racial and ethnic backgrounds in more depth.8\n\nResearch on the drivers of disparities in labor market outcomes can also help the Federal Reserve better assess potential tradeoffs in monetary policy. In meetings with community groups, we often hear from advocates who point to the stark discrepancy they see between the economy's aggregate U-3 unemployment rate, which many forecasters estimate to be at or approaching full employment, and the much higher rates of unemployment among the people in their neighborhoods. For instance, Rod Adams, a neighborhood advocate here in Minneapolis, noted the unemployment rate for African Americans locally was still almost 9 percent late last summer and observed that \"if the labor market were truly healthy, people in my community would all be able to find full-time jobs at decent wages.\"9 While the policy tools available to the Federal Reserve are not well suited to addressing the barriers that contribute to persistent disparities in the labor market outcomes of different groups, understanding these barriers and efforts to address them is vital in assessing maximum employment as well as potential growth.\n\nThe Federal Reserve's community development work is invaluable in supporting our efforts to understand and improve the labor market experiences of different groups.10 For instance, during the Great Recession, workforce development organizations in Atlanta found themselves overwhelmed by the sharp rise in unemployment, which highlighted the need for a better connected and stronger network of job training and placement services. I recently spent time with these organizations, along with community members and some of our Atlanta staff, who have been working on the creation of the Metro Atlanta eXchange (or MAX) for Workforce Solutions, the region's only comprehensive directory for workforce development services.\n\nJust as there is a connection between maximum employment and inclusive growth, so, too, there is an important connection between potential output and opportunity. If there are large disparities in opportunity based on geography or race or gender, such that households' enterprise, exertion, and investments are not rewarded commensurately, then families and small businesses will invest less in the future and potential growth will fall short.11 Indeed, one worrisome trend is the decline in the labor force participation of prime-age workers with less education, a trend that has been going on for decades among men and that has more recently begun to be mirrored in the participation rate of women.12 Understanding this growing detachment from work is important to improving both opportunity and potential growth.\n\nIn visits to Detroit, Milwaukee, North St. Louis, and Baltimore, I have heard from residents and community organizations about the challenging barriers standing between the many workers seeking jobs and the many jobs seeking workers. The local barriers separating jobs from job seekers can be as concrete as the physical isolation created by major traffic arteries or poorly designed transit systems.13 I have visited Los Angeles, where our staff have been actively engaged with businesses, transit authorities, and community groups in efforts around \"equitable transit-oriented development\" so that public transit systems are designed to enhance access for low- and moderate-income residents.14\n\nHousehold Financial Health\nInclusion and opportunity also figure prominently in our work on financial resilience. While the resilience of the financial system has long been central to Federal Reserve policy, in recent years we have come to more fully appreciate that a resilient financial system rests on the foundations of financially resilient households and businesses.\n\nThe ability to manage the ups and downs in family income and expenses without hardship and the ability to make sound investments for the future are both crucial to financial health. Yet we see from the latest edition of the Federal Reserve's Survey of Household Economics and Decisionmaking (SHED) that a strikingly high 40 percent of American households with high school degrees or less report that they are struggling financially.15 And the in-depth research in the U.S. Financial Diaries Project provides insights into the large amount of time and effort these families with thin financial buffers must devote to managing their volatile cash flows.16\n\nA seemingly modest mismatch between income and expenses can threaten to send the finances of some families into a downward spiral from which it can be expensive and difficult to recover. The results of the 2016 SHED show that nearly one-fourth of all households are unable to pay their current month's bills in full, nearly one-third would rely on borrowing or selling something to cover a $400 emergency expense, and one in eight would not be able to cover a $400 emergency expense by any means. Over half of households lack savings to cover three months' expenses if they lost their main source of income.17 This finding corroborates the evidence found in the financial diaries of low- to moderate-income families that show it is all too common for households to have no short-term savings to cover emergencies. According to the Survey of Consumer Finances, on average from 1989 to 2013, about 80 percent of households in the bottom quintile of the income distribution had less than $3,000 adjusted for inflation in liquid assets (cash, checking, or savings accounts). Even among households in the middle quintile of income, about half do not meet this threshold for liquid assets.\n\nIn addition, the financial crisis demonstrated that household financial imbalances can have important consequences for overall financial stability in extreme circumstances. The rapid and widespread rise in poorly underwritten mortgage debt prior to the Great Recession is widely viewed as a key contributor to the financial crisis.18 This suggests the potential value of better understanding the specific patterns in household finances that would give an early warning of a crisis. In carrying out our responsibilities to monitor and safeguard the stability of the financial system, although much of the work has focused on marketwide risks, core financial institutions, and macro-level shocks, we are also developing a more granular understanding of the distribution and strength of household balance sheets.19 Progress on this frontier is being aided by greater access to timely, account-level, and geographically specific data on consumer credit, mortgages, and spending, although more research in this area would be valuable.\n\nSlower income growth, as well as substantial volatility in income, has raised the financial stress faced by low- and moderate-income families and may be limiting absolute mobility across generations. Over time, the \"American Dream\" that each generation can expect to be better off than their parents' generation has gone from being widespread to increasingly out of reach for much of the population.20 Researchers have found that the reduction in economic mobility has been driven primarily by a more unequal distribution of economic growth, with slower overall gross domestic product (GDP) growth a secondary factor.21\n\nMany households had been contending with volatile incomes even before the large negative shocks of the Great Recession and the increase in contingent work arrangements (and the \"gig\" economy).22 23 Unpredictable income and dangerously low emergency savings raise the strain on households and, over time, have pushed them to rely on other means, such as borrowing and government transfers, to try to meet their spending needs.24\n\nEducation and homeownership have long been key paths to opportunity, but the Great Recession has raised some important questions about asset building strategies. The sharp decline in house prices and the substantial rise in student loan debt have made it clear that investments in homeownership and education are not without risk, and the payoff can vary depending on the circumstances.25\n\nHomeownership for many has been a way to turn a regular expense into an asset-building investment in the future, which is especially important given the wide and persistent disparities in wealth by race and ethnicity. But the experience of the past decade suggests that owning a home can, in some circumstances, exacerbate financial difficulties for vulnerable families in a downturn. The lesson that even a moderate decline in house prices can erase home equity applies broadly, along with the importance of sound underwriting and servicing, but the painful consequences in the recession were greater among minority and low-income homeowners.26 The fact, discussed earlier, that African American and Hispanic homeowners households are more likely to lose their jobs in a recession and are also more likely to live in neighborhoods with concentrated job loss led to even larger house price declines and more foreclosures among these households.27 Indeed, there are many low-income neighborhoods in which many homeowners remain \"underwater\" on their mortgages even today.\n\nCommunity development organizations are putting this more nuanced view of asset building into practice and thereby increasing opportunities for individuals to make smart investments in their future. Better Family Life, a community group I visited in North St. Louis, provides would-be homebuyers with education and counseling on how to manage the costs of homeownership, tools to navigate real estate markets, and information on lending.28 There is ample research demonstrating that housing counseling makes a notable improvement in the likelihood that asset building through homeownership will pay off for first-time buyers in low- to moderate-income communities.29\n\nSimilarly, under the right circumstances, education can be a critical investment in the future and a path to opportunity, leading to higher wages and improved financial outcomes. Over the past several decades, the earnings premium for those with a college degree relative to those with a high school education has risen substantially, making higher education, on average, even more valuable.30\n\nNonetheless, even though education is a sound investment for most students, the benefits can vary with the quality and type of education received.31 The SHED finds that fewer than 40 percent of nongraduates or graduates from for-profit institutions say their education was \"worth the cost,\" compared with two-thirds of graduates from public or nonprofit institutions.32 The downsides from such low-return education are compounded for those who took out student loans, in some cases leaving them worse off than before. As an indication of this problem, nearly three-fourths of recent borrowers who attended for-profit schools failed to make progress on paying off their student loans in the first few years, and almost half were in default within five years.33 Investments in education that do not pay off can set these individuals back on asset building as well as on other life goals they may have. To advance more inclusive growth and opportunity, it is essential to help people, especially first-time and nontraditional college students, access smarter educational investments with more reliable and better returns.34\n\nCommunities of Opportunity\nThe connection between the conditions in a community and individual opportunity has been demonstrated in powerful research that many of you have pioneered, and we see this connection every day in our work in communities around the country. The neighborhood where a family lives can have profound implications for their economic opportunities and their children's prospects. Families living in neighborhoods with high concentrations of poverty and low economic or demographic diversity are more likely to experience a range of negative outcomes, including exposure to crime and violence, physical and mental health problems, and weak academic performance.35 Low-skilled workers who live far from potential employers or accessible transportation networks have more difficulty finding and keeping jobs.36\n\nThese effects of geography on opportunity can stretch from one generation to the next. Raj Chetty and his collaborators have shown that upward mobility varies immensely across the country and even within a single metro area.37 Taken together, this research underscores the urgency of understanding how we can make communities work better for all their members. Since communities play a central role in determining opportunity, policy to promote inclusion often focuses on improving local conditions. With our presence in communities around the country and our efforts under the Community Reinvestment Act, the Federal Reserve is a source of high-quality research and region-specific expertise as well as a trusted convener and catalyst on community development approaches for lenders, community groups, and local and regional governments.\n\nOne important area of focus is housing, which connects families concretely to place and can be a source of strength or fragility. Last year, I met with Milwaukee community development groups and residents in one of the more racially segregated residential markets in the country. They highlighted the challenges facing the highly insecure rental population in Milwaukee, which were brought alive by Matthew Desmond's careful research.38 Other communities across the nation face similar challenges. In the recently released SHED, we found that among renters who had recently moved, 12 percent of African Americans, 16 percent of Hispanics, and 8 percent of whites had moved because of eviction or the threat of eviction.39\n\nThe barriers to safe and affordable housing often take on a different form in rural areas, where ownership of manufactured housing is often coupled with insecure land ownership. The geographic footprint of the 12 Federal Reserve Districts gives us a valuable presence in rural America as well as in towns and cities of all sizes and economic fortunes. Near El Paso, our team has developed important analysis of housing challenges in the colonias neighborhoods, where the lack of basic infrastructure and costly financing of warranty deeds pose special hurdles for local families.40 We have also seen successful models of providing affordable and safe housing when community development organizations and financial institutions, along with banks and local residents, work together collaboratively. On a recent visit in El Paso, I saw the value of these approaches, as a single mother with significant health challenges received the keys to a new home in a stable community, after many long years. While the densely wooded hills and hollers of Eastern Kentucky are a sharp contrast to the desert and floodplain expanses of the southwest, the keys to affordable housing in a healthy community can bring just as great an improvement in opportunity. These successes would not be possible without the ingenuity and collaboration of community development financial institutions, local officials, banks, and community members. As I have witnessed, whether it be for a retiree in Helena, Arkansas; a single mom in El Paso, Texas; or a dad on disability in Emlyn, Kentucky, the keys to affordable housing in a stable community can unlock opportunity for future generations.41\n\nIn some parts of the country, rural residents and small businesses also face increasing challenges in accessing financial services as small community banks close and larger banks close branches in low-population areas. Consequently, as I learned from the Mayors of Itta Bena and Moorhead, Mississippi, some rural residents, small businesses, and even municipalities have to drive long distances to reach a bank.42 In the Mississippi Delta, Community Development Financial Institutions (CDFIs) such as HOPE Credit Union and Southern Bancorp are acquiring bank branches earmarked for closing in order to maintain financial services for some rural communities.43\n\nAlthough both pockets of opportunity and of persistent poverty are found in large metro and rural areas alike, 44 a greater share of the new jobs and business establishments created in the recovery following the Great Recession have been in larger metro areas than was the case in previous recoveries.45 In countless communities, especially in rural towns and small to midsize cities, we have seen how a deep setback can leave a profound and long-lasting mark. These experiences challenge common assumptions about the ability of the economy to recover from an economic setback. This could be the legacy of concentrated reliance on an industry that experiences decline due to trade or technology or the byproduct of lack of connectivity-whether by highways or broadband. Technological change, globalization, and other shifts in demand and costs are not new to the U.S. economy, but there are troubling signs that less diversified or more isolated localities have diminished ability to recover. And there is increasing evidence that such concentrated economic shocks can also lead to severe labor market stress, as well as broader consequences for health and mortality.46 Over the past 30 years, the convergence in income across regions of the country has slowed dramatically.47\n\nEven so, some localities fare better than others in establishing new paths to opportunity and inclusive growth, and their successes provide actionable lessons. The Boston Fed's Working Cities Challenge undertook an in depth study of 25 medium-sized cities nationwide that had experienced a post-industrial decline and identified 10 that experienced an economic resurgence. The critical determinant of success was the ability of leaders in those cities to collaborate across sectors around a long-term vision for revitalization. To encourage such collaboration in other cities, the Boston Fed facilitated competitions that reward effective public-private collaboration in developing plans to reach community-wide goals. For example, Holyoke, Massachusetts, proposed a plan to simplify the city's permitting and licensing systems in order to raise the presence of Latino-owned businesses. On economic revitalization, as in other areas of community development, effective solutions start with the community setting its own goals, are powered by broad collaboration, and rely on evidence to drive results.\n\nConclusion\nWe all have our work cut out for us in helping to understand the state of opportunity and inclusion for different groups and communities across our country, and ensuring that policy is informed by those important insights. At the Federal Reserve, we will continue to navigate the recovery to ensure we reach and sustain our long-term goals of maximum employment and price stability. We will remain attentive to the financial health of vulnerable households. And we will remain committed to helping illuminate the specific challenges faced by low- and moderate-income communities around the country and to supporting banks and other financial institutions as they partner in strengthening these communities. In all of these efforts, our work will be greatly strengthened by the cutting-edge research and policy insights of the outstanding group gathered here tonight.\n\nReferences\nAaronson, Daniel, Luojia Hu, Arian Seifoddini, and Daniel G. Sullivan (2014). \"Declining Labor Force Participation and Its Implications for Unemployment and Employment Growth,\" Federal Reserve Bank of Chicago, Economic Perspectives, vol. 38 (Fourth Quarter), pp. 100-38.\n\nAdelino, Manuel, Antoinette Schoar, and Felipe Severino (2016). \"Loan Originations and Defaults in the Mortgage Crisis: The Role of the Middle Class,\" Review of Financial Studies, vol. 29 (July), pp. 1635-70.\n\nAltonji, Joseph G., and Rebecca M. Blank (1999). \"Race and Gender in the Labor Market,\" in Orley Ashenfelter and David Card, eds., Handbook of Labor Economics, vol. 3. New York: North-Holland.\n\nAutor, David H. (2014). \"Skills, Education, and the Rise of Earnings Inequality among the 'Other 99 Percent,'\" Science, May 23.\n\nAutor, David H., David Dorn, and Gordon H. Hanson (2013). \"The China Syndrome: Local Labor Market Effects of Import Competition in the United States,\" American Economic Review, vol. 103 (October), pp. 2121-68.\n\nBarnichon, Regis, and Geert Mesters (2017). \"How Tight Is the U.S. Labor Market?\" FRBSF Economic Letter 2017-07. San Francisco: Federal Reserve Bank of San Francisco, March.\n\nBhutta, Neil and Daniel Ringo (2015). \"Assessing the Community Reinvestment Act's Role in the Financial Crisis.\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, May 26.\n\nBhutta, Neil (2015). \"The Ins and Outs of Mortgage Debt during the Housing Boom and Bust,\" Journal of Monetary Economics, vol. 76 (November), pp. 284-298\n\nBoard of Governors of the Federal Reserve System (2016). Monetary Policy Report. Washington: Board of Governors, June.\n\n-------- (2017). Report on the Economic Well-Being of U.S. Households in 2016. Washington: Board of Governors, May.\n\nBoshara, Ray (2017). \"Black College Graduates Are Losing Wealth. Here's What Can Help,\" Washington Post, April 12.\n\nBrainard, Lael (2015). \"Coming of Age in the Great Recession,\" speech delivered at \"Economic Mobility: Research and Ideas on Strengthening Families, Communities, and the Economy\" conference, Washington, April 2.\n\n-------- (2016). \"The \"Gig\" Economy: Implications of the Growth of Contingent Work,\" speech delivered at \"Evolution of Work\" conference, New York, November 17.\n\nCajner, Tomaz, Tyler Radler, David Ratner, and Ivan Vidangos (forthcoming). \"Racial Gaps in Labor Market Outcomes in the Last Four Decades and over the Business Cycle,\" Finance and Economics Discussion Series. Washington: Board of Governors of the Federal Reserve System.\n\nCelik, Sule, Chinhui Juhn, Kristin McCue, and Jesse Thompson (2012). \"Recent Trends in Earnings Volatility: Evidence from Survey and Administrative Data,\" B.E. Journal of Economic Analysis and Policy, vol. 12 (June), pp. 1-24.\n\nChetty, Raj, David Grusky, Maximilian Hell, Nathaniel Hendren, Robert Manduca, and Jimmy Narang (2017). \"The Fading American Dream: Trends in Absolute Income Mobility since 1940,\" Science, April 24.\n\nChetty, Raj, Nathaniel Hendren, Patrick Kline, and Emmanuel Saez (2014). \"Where Is the Land of Opportunity? The Geography of Intergenerational Mobility in the United States,\" Quarterly Journal of Economics, vol. 129 (December), pp. 1553-1624.\n\nChou, Tiffany, Adam Looney, and Tara Watson (2017). \"Measuring Loan Outcomes at Postsecondary Institutions: Cohort Repayment Rates as an Indicator of Student Success and Institutional Accountability,\" NBER Working Paper Series 23118. Cambridge, Mass.: National Bureau of Economic Research, February.\n\nCollins, J. Michael and Maximilian D. Schmeiser (2013). \"The Effects of Foreclosure Counseling for Distressed Homeowners,\" Journal of Policy Analysis and Management, vol. 32 (January), pp. 83-106.\n\nCouncil of Economic Advisers (2016). The Long-Term Decline in Prime-Age Male Labor Force Participation (PDF). Washington: Executive Office of the President of the United States, June.\n\nDesmond, Matthew (2016). Evicted: Poverty and Profit in the American City. New York, N.Y.: Crown Publishers.\n\nDynan, Karen (2012). \"Is a Household Debt Overhang Holding Back Consumption? (PDF)\" Brookings Papers on Economic Activity, Spring, pp. 299-362.\n\nDynan, Karen, Douglas Elmendorf and Daniel Sichel (2012). \"The Evolution of Household Income Volatility.\" The B.E. Journal of Economic Analysis and Policy, vol. 12 (December).\n\nEconomic Innovation Group (2016). The New Map of Economic Growth and Recovery. (PDF) Washington: EIG, May.\n\nEmmons, William R., and Bryan J. Noeth (2015). \"Why Didn't Higher Education Protect Hispanic and Black Wealth? (PDF)\" In the Balance: Perspectives on Household Balance Sheets, no. 12. St. Louis: Federal Reserve Bank of St. Louis, August.\n\nFederal Reserve Bank of Dallas, Community Development Department (2015). Las Colonias in the 21st Century: Progress along the Texas-Mexico Border. (PDF) Dallas: Federal Reserve Bank of Dallas, April.\n\nFederal Reserve Bank of Kansas City and Center for Popular Democracy (2016). \"Federal Reserve and the Center for Popular Democracy Listening Session,\" August 25.\n\nGanong, Peter, and Daniel Shoag (2015). \"Why Has Regional Income Convergence in the U.S. Declined? (PDF)\" working paper. Cambridge, Mass.: Harvard Web Publishing, January.\n\nGoetz, Stephen, Mark Partridge, and Heather Stephens (2017). \"The Economic Status of Rural America in the Trump Era,\" MPRA Paper 77830. Munich: Munich Personal RePEc Archive, March.\n\nGorbachev, Olga (2011). \"Did Household Consumption Become More Volatile?\" American Economic Review, vol. 101 (August), pp. 2248-70.\n\nHellerstein, Judith K., David Neumark, and Melissa McInerney (2008). \"Spatial Mismatch or Racial Mismatch?\" Journal of Urban Economics, vol. 64 (September), pp. 464-79.\n\nKain, John F. (1968). \"Housing Segregation, Negro Employment, and Metropolitan Decentralization,\" Quarterly Journal of Economics, vol. 82 (May), pp. 175-97.\n\nKatz, Lawrence F., Jeffrey R. Kling, and Jeffrey B. Liebman (2001). \"Moving to Opportunity in Boston: Early Results of a Randomized Mobility Experiment,\" Quarterly Journal of Economics, vol. 116 (May), pp. 607-54.\n\nKatz, Lawrence F., and Alan B. Krueger (2017). \"Documenting Decline in U.S. Economic Mobility,\" Science, April 24.\n\nKoo, Kyong Hyun (2016). \"The Evolution of Earnings Volatility during and after the Great Recession,\" Industrial Relations, vol. 55 (October), pp. 705-32.\n\nLooney, Adam, and Constantine Yannelis (2015). \"A Crisis in Student Loans? How Changes in the Characteristics of Borrowers and in the Institutions They Attended Contributed to Rising Loan Defaults (PDF),\" Brookings Papers on Economic Activity.\n\nMarrero, Gustavo A., and Juan G. Rodríguez (2013). \"Inequality of Opportunity and Growth,\" Journal of Development Economics, vol. 104 (September), pp. 107-22.\n\nMayer, Christopher, Karen Pence, and Shane M. Sherlund (2009). \"The Rise in Mortgage Defaults,\" Journal of Economic Perspectives, vol. 23 (Winter), pp. 27-50.\n\nMian, Atif, Kamalesh Rao, and Amir Sufi (2013). \"Household Balance Sheets, Consumption, and the Economic Slump,\" Quarterly Journal of Economics, vol. 128 (November), pp. 1687-1726.\n\nPalumbo, Michael G. (forthcoming). \"Assessing the Contribution of Household Leverage to Systemic Risk in the U.S.,\" Finance and Economics Discussion Series. Washington: Board of Governors of the Federal Reserve System.\n\nParker, Jonathan A. (2014). \"LEADS on Macroeconomic Risks to and from the Household Sector,\" in Markus Brunnermeier and Arvind Krishnamurthy, eds., Risk Topography: Systemic Risk and Macro Modeling. Chicago: University of Chicago Press, pp. 183-203.\n\nPierce, Justin R., and Peter K. Schott (2016). \"Trade Liberalization and Mortality: Evidence from U.S. Counties,\" NBER Working Paper Series 22849. Cambridge, Mass.: National Bureau of Economic Research, November.\n\nRajan, Raghuram G. (2010). Fault Lines: How Hidden Fractures Still Threaten the World Economy. Princeton, N.J.: Princeton University Press.\n\nSampson, Robert J. (2016). \"Individual and Community Economic Mobility in the Great Recession Era: The Spatial Foundations of Persistent Inequality,\" in Federal Reserve Bank of St. Louis and Board of Governors of the Federal Reserve System, eds., Economic Mobility: Research and Ideas on Strengthening Families, Communities, and the Economy. St. Louis: Federal Reserve Bank of St. Louis, pp. 259-87.\n\nSmith, Marvin M., Daniel Hochberg, and William H. Greene (2014). \"The Effectiveness of Pre-Purchase Homeownership Counseling and Financial Management Skills. (PDF)\" Philadelphia, PA: Federal Reserve Bank of Philadelphia.\n\nSteelman, Aaron (2011). \"The Federal Reserve's 'Dual Mandate': The Evolution of an Idea (PDF),\" Economic Brief EB11-12. Richmond, Va.: Federal Reserve Bank of Richmond, December.\n\nSufi, Amir (2014). \"Detecting 'Bad' Leverage,\" in Markus Brunnermeier and Arvind Krishnamurthy, eds., Risk Topography: Systemic Risk and Macro Modeling. Chicago: University of Chicago Press, pp. 205-212.\n\nThornton, Daniel L. (2012). \"The Dual Mandate: Has the Fed Changed Its Objective? (PDF)\" Federal Reserve Bank of St. Louis, Review, vol. 94 (March/April), pp. 117-33.\n\nWinship, Scott (2017). Economic Mobility in America. Washington: Archbridge Institute, March.\n\nYellen, Janet L. (2017a). \"So We All Can Succeed: 125 Years of Women's Participation in the Economy,\" speech delivered at \"125 Years of Women at Brown Conference,\" sponsored by Brown University, Providence, R.I., May 5.\n\n-------- (2017b). \"Addressing Workforce Development Challenges in Low-Income Communities,\" speech delivered at \"Creating a Just Economy,\" the 2017 annual conference of the National Community Reinvestment Coalition, Washington, March 28.\n\nI am grateful to David Buchholz, Jeff Larrimore, Amanda Roberts, Claudia Sahm, and Jenny Schuetz for their assistance in preparing this text.\n\n1. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See the Employment Act of 1946, Pub. L. No. 79-304, § 2, 60 Stat. 23, 23 (1946). Return to text\n\n3. The FOMC's inflation target was adopted in January 2012 in the Statement on Longer-Run Goals and Monetary Policy Strategy. It was amended in January 2017 to clarify that the target is symmetric around 2 percent; the most recent Statement on Longer-Run Goals and Monetary Policy Strategy (in which the quoted text appears in paragraph 3) is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/files/fomc_longerrungoals.pdf. For the interim period, Thornton (2012) and Steelman (2011) document the evolution of views among FOMC members on the dual mandate. Return to text\n\n4. Board of Governors (2016) discusses some recent trends. See also Altonji and Blank (1999) and references therein for research on racial and gender differences in the labor market. Return to text\n\n5. Cajner and others (2017) find that the higher, more cyclical unemployment of African Americans than whites cannot be fully accounted for by differences in education, age, marital status, and state of residence. Return to text\n\n6. See the box \"Have the Gains of the Economic Expansion Been Widely Shared?\" in Board of Governors (2016). Return to text\n\n7. See Yellen (2017a) and the studies referenced therein. Return to text\n\n8. Aaronson and others (2014) and Barnichon and Mesters (2016) are examples of using details from demographic groups to assess overall labor market trends. In September, the Board of Governors is hosting a conference, \"Disparities in the Labor Market: What Are We Missing?' Return to text\n\n9. On August 25, 2016, the Federal Reserve Bank of Kansas City hosted a listening session with the Center for Popular Democracy for members of the Federal Reserve; a video of the session is available at https://www.kansascityfed.org/publications/research/escp/symposiums/escp-event. Return to text\n\n10. See Yellen (2017b) for an overview. In October, the Federal Reserve Bank of Dallas will host a conference, \"Investing in America's Workforce: Improving Outcomes for Workers and Employers.\" Return to text\n\n11. See Marrero and Rodriquez (2013). Return to text\n\n12. See Council of Economic Advisers (2016) and the studies cited therein. Return to text\n\n13. The information is from community development visits in 2015 (Baltimore and North St. Louis) and 2016 (Detroit and Milwaukee). Return to text\n\n14. The information is from community development visits in 2014. Return to text\n\n15. The SHED is an annual survey, representative of the U.S. population, conducted at the Board of Governors since 2013. It is available on the Board's website at https://www.federalreserve.gov/consumerscommunities/shed.htm. Return to text\n\n16. The U.S. Financial Diaries project, led by Jonathan Morduch and Rachel Schneider, is a detailed, ethnographic study of financial conditions among low- and moderate-income households. More information is available on the project's website at www.usfinancialdiaries.org. Return to text\n\n17. See Board of Governors (2017). Return to text\n\n18. See, for example, Rajan (2010); Dynan (2012); and Mian, Rao, and Sufi (2013) on how high levels of mortgage debt may have made the Great Recession more severe and slowed the recovery. While low-income households were particularly vulnerable to the consequences of the collapse in house prices, rise in unemployment, and tightening of credit in the Great Recession, the preceding rise in mortgage debt was widespread, also including higher-income households, as documented by Bhutta (2015) and Adelino, Schoar, and Severino (2016). Return to text\n\n19. See, for example, Parker (2014) and Sufi (2014) for useful, research-founded ideas for assessing and monitoring the potential for financial fragility among households in the context of the financial system; see also Palumbo (forthcoming) for a particular application. The Quarterly Report on Household Debt and Credit from the Federal Reserve Bank of New York, which draws on its Consumer Credit Panel, is another example of new monitoring efforts on household finances in the Federal Reserve System. More information is available on the Federal Reserve Bank of New York's website at https://www.newyorkfed.org/microeconomics/hhdc.html. Return to text\n\n20. Chetty and others (2017) estimate that rates of absolute mobility fell from about 90 percent for children born in 1940 to 50 percent for children born in the 1980s. Some research, such as Winship (2017), reaches different conclusions on the magnitude of the change, although not on the direction. Return to text\n\n21. Chetty and others (2017) estimate that the slower overall GDP growth experienced by the 1980 birth cohort relative to the 1940 birth cohort can account for about 10 percentage points of the decline in absolute mobility, while the less equal distribution of income can account for about 30 percentage points of the decline. Commenting on this work, Katz and Krueger (2017) underscore that stagnant growth of median household income since the 1970s has been central to the decline in absolute mobility. Return to text\n\n22. See Brainard (2016) on the gig economy and the growth of contingent work. Return to text\n\n23. Dynan, Elmendorf, and Sichel (2012) documented a rise in household income volatility from the early 1970s to late 2008. In contrast, studies such as Celik and others (2012) do not find a rise in household income volatility in the 2000s. Koo (2016) shows a rise in earnings volatility in the Great Recession. Studies of annual income may even understate the volatility, as the financial diaries showed considerable month-to-month fluctuations in income among low- and middle-income households. Return to text\n\n24. See Gorbachev (2011). Return to text\n\n25. See Brainard (2015). Return to text\n\n26. Bhutta and Ringo (2015) and the studies discussed therein argue that the Community Reinvestment Act, and its encouragement of lending in low- and moderate-income communities, was not a significant contributor to the financial crisis. Well-serviced and correctly-structured mortgages performed well for low-income borrowers even during a decline in house prices. Return to text\n\n27. See research by Emmons and Noeth (2015) and the related symposium; more information is available on the Federal Reserve Bank of St. Louis's website at https://www.stlouisfed.org/household-financial-stability/events/past-events/does-college-level-the-playing-field. Boshara (2017) provides an overview of the conference findings. Return to text\n\n28. The information is from community development visits in 2015. Return to text\n\n29. See, for example, Collins and Schmeiser (2013) and Smith, Hochberg, and Greene (2014). Return to text\n\n30. See Autor (2014). Return to text\n\n31. See Brainard (2015). Return to text\n\n32. See Board of Governors (2017). Return to text\n\n33. See Looney and Yannelis (2015). Return to text\n\n34. See Chou, Looney, and Watson (2017) as an example of research on policy tools that could improve educational choices. Return to text\n\n35. In an early evaluation of the Moving to Opportunity program, Katz, Kling, and Liebman (2001) find improvements of better neighborhoods on children's health and safety. Sampson (2016) summarizes much of the recent evidence. Return to text\n\n36. Kain (1968) first advanced the \"spatial mismatch\" hypothesis. More recently, Hellerstein, Neumark, and McInerney (2008) find evidence for a \"spatial-racial mismatch\"--namely, that employment among low-skilled black men depends on proximity to employers who hire black workers. Return to text\n\n37. In one of many studies on opportunity, Chetty and others (2014) use Internal Revenue Service tax return data from 40 million adult children to estimate the relative upward mobility across the 741 commuting zones (both metro and rural) in the United States. Return to text\n\n38. See Desmond (2016). Return to text\n\n39. See Board of Governors (2017). Return to text\n\n40. See Federal Reserve Bank of Dallas, Community Development Department (2015). Return to text\n\n41. Community visits in El Paso (2016), Mississippi Delta (2016), and Eastern Kentucky (2017), Return to text\n\n42. Discussions with Mayor Collins of Itta Bena, Mississippi and Mayor Holland of Moorhead, Mississippi (2016). Return to text\n\n43. Community Development visit in Mississippi Delta (2016). Return to text\n\n44. See Goetz, Partridge, and Stephens (2017). Return to text\n\n45. See Economic Innovation Group (2016). Return to text\n\n46. See Autor, Dorn, and Hanson (2013) and Pierce and Schott (2016). Return to text\n\n47. See Ganong and Shoag (2015) and references therein. Return to text"
    },
    {
        "title": "So We All Can Succeed: 125 Years of Women's Participation in the Economy",
        "date": "May 05, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20170505a.htm",
        "content": "May 05, 2017\n\nChair Janet L. Yellen\n\nAt \"125 Years of Women at Brown Conference,\" sponsored by Brown University, Providence, Rhode Island\n\nThank you, and let me say what an honor it is, as an alumna of this great university, to be here today and part of this important occasion.\n\nAs we celebrate the 125th anniversary of women being admitted to Brown, it seems appropriate to reflect on the progress that women have achieved in the intervening years. Since 1891, women have made tremendous strides in their ability to pursue their dreams of education and meaningful work and to support themselves and their families. In pursuing these goals, women have helped improve working conditions for all workers and have been a major factor in America's prosperity over the past century and a quarter.\n\nDespite this progress, evidence suggests that many women remain unable to achieve their goals. The gap in earnings between women and men, although smaller than it was years ago, is still significant; women continue to be underrepresented in certain industries and occupations; and too many women struggle to combine aspirations for work and family. Further advancement has been hampered by barriers to equal opportunity and workplace rules and norms that fail to support a reasonable work-life balance. If these obstacles persist, we will squander the potential of many of our citizens and incur a substantial loss to the productive capacity of our economy at a time when the aging of the population and weak productivity growth are already weighing on economic growth.\n\nTo enliven the history I will present today, I will include the experiences of women graduates of this institution, in most cases in their own words, as related in oral histories preserved by Brown.1 Among these alumnae, I am proud to say, is a member of my own family who was an early graduate of Pembroke, Elizabeth Stafford Hirschfelder of the Class of 1923. Her career and achievements as a mathematician embody both the opportunities that opened for Pembroke graduates in the decades after she left here and the limitations many women faced and the compromises she, like so many others, was forced to make.\n\nA Historical Perspective on Women in the Labor Force\nFrom the time that Brown began to accept women and into the 1920s, most women in the United States did not work outside the home, and those who did were primarily young and unmarried. In that era, just 20 percent of all women were \"gainful workers,\" as the Census Bureau then categorized labor force participation outside the home, and only 5 percent of those married were categorized as such.2 Of course, these statistics somewhat understate the contributions of married women to the economy beyond housekeeping and childrearing, since women's work in the home often included work in family businesses and the home production of goods, such as agricultural products, for sale. Also, the aggregate statistics obscure the differential experience of women by race. African American women were about twice as likely to participate in the labor force as were white women at the time, largely because they were more likely to remain in the labor force after marriage.3\n\nWhat was true for women in general was also true of the early graduates of what was then called the Women's College, the large majority of whom got married, raised families, and did not pursue careers. The fact that many women left work upon marriage reflected cultural norms, the nature of the work available to them, and legal strictures. The occupational choices of those young women who did work were severely circumscribed. Most women lacked significant education‑‑only 54 percent of girls aged 5 to 19 were enrolled in school in 1890.4 And women with little education mostly toiled as piece workers in factories or as domestic workers, jobs that were dirty and often unsafe. Educated women, like those who attended Brown's Women's College, were scarce. Fewer than 2 percent of all 18- to 24-year-olds were enrolled in an institution of higher education, and just one-third of those were women.5 Such women did not have to perform manual labor, but their choices were likewise constrained. Edna McDonald was a graduate of the Class of 1919, and in her oral history, she summed up the opportunities for her and her classmates: \"Let's be frank,\" she said. \"What choices did women have? Teaching. You could teach. You could be a lab technician. Or you could go into office work and be a secretary. Those were the only real choices.\" Margery Chittenden Leonard graduated from Pembroke in 1929 and went on to earn a J.D. as the only woman in her class at Boston University--after two others withdrew. And with that law degree, her first job was as a secretary, and she continued to struggle to find work as a lawyer. In her oral history, Doris Madeline Hopkins, a 1928 graduate, talked about the opportunity that she had to work, but also about being told she had to leave her job once she got married. Indeed, at the time, marriage bars were widespread.6\n\nThere were notable exceptions, such as, of course, Mary Emma Woolley, a Brown graduate who went on to serve as the president of Mount Holyoke College, and Ethel Robinson, the first black woman to graduate from Brown, who taught English at Howard University. Helen Butts, from the Class of 1928, taught natural sciences at Smith and later zoology at Wellesley, the beginning of a long and productive career as a biological researcher. Another exception was Betty Stafford, the aunt of my husband, George. She grew up in Providence, earned bachelor's and master's degrees at Brown in mathematics and then rather adventurously headed west, teaching at two universities in Texas in the 1920s before completing her Ph.D. and then teaching at the University of Wisconsin.\n\nDespite the widespread sentiment against women, particularly married women, working outside the home and with the limited opportunities available to them, women did enter the labor force in greater numbers over this period, with participation rates reaching nearly 50 percent for single women by 1930 and nearly 12 percent for married women. This rise suggests that while the incentive, and in many cases the imperative, remained for women to drop out of the labor market at marriage when they could rely on their husband's income, mores were changing. Indeed, these years overlapped with the so-called first wave of the women's movement, when women came together to agitate for change on a variety of social issues, including suffrage and temperance, and which culminated in the ratification of the 19th amendment in 1920 guaranteeing women the right to vote.\n\nBetween the 1930s and mid-1970s, women's participation in the economy continued to rise, with the gains primarily owing to an increase in work among married women. By 1970, 50 percent of single women and 40 percent of married women were participating in the labor force.7 Several factors contributed to this rise. First, with the advent of mass high school education, graduation rates rose substantially.8 At the same time, new technologies contributed to an increased demand for clerical workers, and these jobs were increasingly taken on by women. Moreover, because these jobs tended to be cleaner and safer, the stigma attached to work for a married woman diminished. And while there were still marriage bars that forced women out of the labor force, these formal barriers were gradually removed over the period following World War II. Another innovation was the introduction in the late 1940s of part-time schedules, which combined with the proliferation of modern appliances to make it more feasible for married women to work outside the home.9\n\nOver the decades from 1930 to 1970, increasing opportunities also arose for highly educated women, such as the graduates of what was by then called Pembroke College, to work in professions. That said, early in that period, most women still expected to have short careers, and women were still largely viewed as secondary earners whose husbands' careers came first. Thus, while it was becoming more common for women such as Betty Stafford to teach at colleges and universities, their career prospects were not the same as those for men. After earning her Ph.D. at Wisconsin, Betty married a fellow student and over the next decade coauthored five important papers with him and a well-regarded reference work. But, while her husband progressed from instructor to professor at Wisconsin, Betty worked as an instructor on an ad hoc basis. During World War II, while he worked for the government in Washington and New York, Betty stayed in Madison, teaching math to servicemen. When he took a job teaching in California after the war, they divorced, and it was only then that she was a given a position as assistant professor.\n\nAs time progressed, attitudes about women working and their employment prospects did change. As women gained experience in the labor force, they increasingly saw that they could balance work and family. A new model of the two-income family emerged.10 Some women began to attend college and graduate school with the expectation of working, whether or not they planned to marry and have families, as did Rita Schorr-Germain, an immigrant who survived Auschwitz, graduated from Pembroke in 1953, and went on to teach European history while her husband also had a successful academic career. In her oral history, Rita says she was encouraged by many Brown professors and never considered the possibility that her gender would stand in the way of an academic career, a shift in outlook that was becoming increasingly common in the 1950s. As did most women's colleges at the time, Pembroke continued to produce nurses, schoolteachers, and social workers, and many women who worked only until they married and had children. But, from the late 1950s on, it also increasingly graduated writers, doctors, lawyers, diplomats, physicians, psychotherapists, and archeologists, and, in 1959, the first female faculty member of Brown University. Among those women fortunate to attend Pembroke in this era of dramatic change was me. I enrolled at Brown fully planning to attend graduate school and have a career, as did many of my classmates in the Class of 1967.\n\nBy the 1970s, a dramatic change in women's work lives was under way. In the period after World War II, many women had not expected that they would spend as much of their adult lives working as turned out to be the case. By contrast, in the 1970s young women more commonly expected that they would spend a substantial portion of their lives in the labor force, and they prepared for it, increasing their educational attainment and taking courses and college majors that better equipped them for careers as opposed to just jobs.\n\nIn surveys of young people about their expectations of their futures, young women during this era increasingly placed an emphasis on career success.11 Susan Graber Slusky of the Class of 1971 said in her oral history that she chose Pembroke for Brown's excellence in chemistry and physics, because she was already planning the career she went on to have as a researcher. Perhaps unsurprisingly, this is also the period in which many all-male colleges admitted women or combined their women's and men's undergraduate schools, as Brown did when it merged Pembroke and Brown College in 1971.\n\nThese changes in attitudes and expectations were supported by other changes under way in society. Workplace protections were enhanced through the passage of the Pregnancy Discrimination Act in 1978 and the recognition of sexual harassment in the workplace. Access to birth control increased, which allowed married couples greater control over the size of their families and young women the ability to delay marriage and to plan children around their educational and work choices.12 And in 1974, women gained, for the first time, the right to apply for credit in their own name without a male co-signer.13\n\nBy the early 1990s, the labor force participation rate of prime working-age women--those between the ages of 25 and 54--reached just over 74 percent, compared with roughly 93 percent for prime working-age men.i By then, the share of women going into the traditional fields of teaching, nursing, social work, and clerical work declined, and more women were becoming doctors, lawyers, managers, and, yes, professors. As women increased their education and joined industries and occupations formerly dominated by men, the gap in earnings between women and men began to close significantly.14\n\nPositive Spillovers from Women's Increased Participation in the Workforce\nLooking back, the story of the past 125 years is one of slow but steady progress toward women's full participation in the economy and the fulfillment of their career goals. Unfortunately, the success of women has often been seen as coming at the expense of men. Indeed, regularly in the late 19th and 20th centuries there were calls to protect men from women's entry into the labor force. The early female graduates of Brown faced such attitudes from fellow students and even from faculty. Ruth Pederson, a member of the Class of 1919, said some professors did not want to teach women and prohibited women from taking their classes. Margery Leonard remembered one Boston University professor who urged her to drop out of law school. When she refused, this professor punished her by forcing her to recite the details of rape and seduction cases before her jeering, stomping classmates. And it wasn't only men who had this attitude. Among the women who were fighting for better labor standards early in the 20th century, many were heavily influenced by elite cultural standards that viewed a woman's place as in the home and argued that men should be paid a \"family wage\" that would allow them to support their family singlehandedly--a standard that many working-class families could not afford. Moreover, many of the labor protections promoted to protect women were often based on theories about women's weaker nature, and these protections served to circumscribe their work.15 During the Great Depression, limiting women's role in the workforce was considered a way to address the high rates of unemployment, although the experience of those years showed the importance of women in supporting their families financially.16 Similarly, women who had successfully worked during World War II, either as part of the war effort or to support their families while their husbands were fighting, often were pushed out of their jobs to make room for returning soldiers.17\n\nAfter the war and then single, my relative, Betty Stafford, remained an assistant professor at the University of Wisconsin despite an enviable body of research. She married another Wisconsin professor, an eminent chemist, and collaborated with him on his research. But, in 1954, she gave up her assistant professorship, she said, to be able to accompany her husband on his frequent international travels. Betty later moved with her husband to California, and after his death, she endowed a graduate fellowship in the sciences and a prize in theoretical chemistry. Although Betty's accomplishments were considerable, against the backdrop of increasing opportunity for women over her lifetime I believe that Betty Stafford Hirschfelder was denied opportunities and greater success simply because she was a woman.\n\nDespite the fears of some that women entering into the workforce would crowd out men, the evidence shows that the rise in women's participation has contributed to widespread improvements in the safety and productivity of our workplaces, to the health of families, and to the macroeconomic success that our country has enjoyed over the past 125 years.\n\nIn the first decades of the 20th century, the struggle to improve the working conditions of young women drawn into factories was a pillar of the overall movement toward improved labor standards. Women's demands for safer factories, humane workweeks, and higher pay, which were often pursued through organizing and striking, contributed substantially to the social upheaval and public debate of that period that eventually led to the passage of stronger labor standards. These efforts also produced generations of women who went on to be leaders in the broader labor movement and in the broader movements for equality.\n\nThe rise in female labor force participation was an early focus of and helped establish the fields of statistics and labor economics in their modern incarnations. Carroll Wright, the first commissioner of what is now known as the Bureau of Labor Statistics and who established the high standards for data collection and analysis for which the bureau is known, devoted his agency's fourth annual report, for the year 1888, to the topic of Working Women in Large Cities.18 Moreover, the issues surrounding women's work, such as the minimum wage, pay equity, and maximum workweeks, were topics of great interest to early practitioners of labor economics.19\n\nIt is often said that we should welcome women's presence in the workplace because it allows us to capitalize on the talents of our entire population, and this is certainly true. But it is also good business. A number of studies on how groups perform indicate that workforces that vary on dimensions such as gender, race, and ethnicity produce better decisionmaking processes and better outcomes.20\n\nEvidence also suggests that women's work has positive spillovers to their family lives and to the success of their children, which in turn benefits all of society. It is a well-established finding in the literature on development that maternal education and work are positively associated with better health and educational outcomes for children.21 A recent meta-study also suggests that children in the United States with working mothers do as well if not better in school, both academically and behaviorally, than children with mothers that stay home full time. This effect is particularly strong for families that have fewer social and economic resources, including single-parent families.22 As time goes on, girls with working mothers are more likely to be employed and hold supervisory positions, and they earn somewhat more. In addition, sons raised in families with working mothers assume greater childcare responsibilities as adults than sons whose mothers did not work.23\n\nThis is not to say that children do not need attention from both parents to develop into academically successful and socially well-adjusted adults--they certainly do. Also, as I will discuss, women are making choices that reflect their desire to balance work and family. These findings bear on the question of how best to support women's work through public policies aimed at helping women and men better manage work and family.\n\nFrom a macroeconomic perspective, women's incorporation into the economy contributed importantly to the rapid rise in economic output and well-being over the 20th century. Between 1948 and 1990, the rise in female participation contributed about 1/2 percentage point per year to the potential growth rate of real gross domestic product.24 And this estimate does not take into account the effect of the increases in women's education and work experience that also occurred over that period and boosted their productivity. In addition, since 1979, women have accounted for a majority of the rise in real household income. In dollar terms, the gains were greatest for households in the top third of the earnings distribution, but without the increase in women's earnings, families in the bottom and middle thirds of the distribution would have experienced declines.25\n\nRemaining Challenges and Some Possible Solutions\nI have argued thus far that we, as a country, have reaped great benefits from the increasing role that women have played in the economy. But evidence suggests that barriers to women's continued progress remain. The participation rate for prime working-age women peaked in the late 1990s and currently stands at about 75 percent.26 Of course, women, particularly those with lower levels of education, have been affected by the same economic forces that have been pushing down participation among men, including technical change and globalization. 27 However, women's participation plateaued at a level well below that of prime working-age men, which stands at over 88 percent. While some married women choose not to work, the size of this disparity should lead us to examine the extent to which structural problems, such as a lack of equal opportunity and challenges to combining work and family, are holding back women's advancement.\n\nAs I mentioned earlier, the gap in earnings between men and women has narrowed substantially, but progress has slowed lately, and women working full time still earn about 17 percent less than men, on average, each week.28 Even when we compare men and women in the same or similar occupations who appear nearly identical in background and experience, a gap of about 10 percent typically remains.29 As such, we cannot rule out that gender-related impediments hold back women, including outright discrimination, attitudes that reduce women's success in the workplace, and an absence of mentors.\n\nRecent research has shown that although women now enter professional schools in numbers nearly equal to men, they are still substantially less likely to reach the highest echelons of their professions.30 For instance, 47 percent of students at top-50 law schools are female, and women obtain 40 percent of M.B.A.'s from top programs. Nonetheless, women are still poorly represented among corporate CEOs, as partners in top law firms, and as executives in finance.31 Even in my own field of economics, women constitute only about one-third of Ph.D. recipients, a number that has barely budged in two decades.32 This lack of success in climbing the professional ladder would seem to explain why the wage gap actually remains largest for those at the top of the earnings distribution.33\n\nOne of the primary factors contributing to the failure of these highly skilled women to reach the tops of their professions and earn equal pay is that top jobs in fields such as law and business require longer workweeks and penalize taking time off. This would have a disproportionately large effect on women, who continue to bear the lion's share of domestic and child-rearing responsibilities.34 Within academia, the short timeframe in which assistant professors have to prove themselves good candidates for tenure by publishing typically overlaps with the period in which many women contemplate starting a family, forcing difficult trade-offs.35\n\nEmployers may require the long hours and short absences for good reasons--for instance, the work may involve relationships with clients or accumulating a significant amount of knowledge about a deal or case in a condensed period of time. If it is costly for employees to share information and split the work, then there would be a high premium, in the form of compensation, for those who can work the long hours.36 Workplaces where the income of employees depends on the effort of co-workers, such as law partnerships, also have an incentive to require long workweeks.37\n\nBut however sensible such arrangements may be from a business perspective, it can be difficult for women to meet the demands in these fields once they have children. The very fact that these types of jobs require such long hours likely discourages some women--as well as men--from pursuing these career tracks. Advances in technology have facilitated greater work-sharing and flexibility in scheduling, and there are further opportunities in this direction.38 Economic models also suggest that while it can be difficult for any one employer to move to a model with shorter hours, if many firms were to change their model, they and their workers could all be better off.39\n\nOf course, most women are not employed in fields that require such long hours or that impose such severe penalties for taking time off. But the difficulty of balancing work and family is a widespread problem. In fact, the recent trend in many occupations is to demand complete scheduling flexibility, which can result in too few hours of work for those with family demands and can make it difficult to schedule childcare.40 Reforms that encourage companies to provide some predictability in schedules, cross-train workers to perform different tasks, or require a minimum guaranteed number of hours in exchange for flexibility could improve the lives of workers holding such jobs. Another problem is that in most states, childcare is affordable for fewer than half of all families.41 And just 5 percent of workers with wages in the bottom quarter of the wage distribution have jobs that provide them with paid family leave.42 This circumstance puts many women in the position of having to choose between caring for a sick family member and keeping their jobs.\n\nIn this context, it is useful to compare the workforce experiences of American women to those in other advanced economies. In 1990, the labor force participation rate in the United States of prime working-age women, 74 percent, was higher than in all but a few industrialized nations. But in the intervening years, while the participation rate of U.S. women was roughly stable, elsewhere it increased steadily, and by 2010 the United States fell to 17th place out of 22 advanced economies with respect to female labor force participation.43 A number of studies have examined the role of various public policies in explaining patterns in female labor force participation across countries. These studies find that policy differences--in particular, the expansion of paid leave following childbirth, steps to improve the availability and affordability of childcare, and increased availability of part-time work--go a long way toward explaining the divergence between advanced economies.44 Evidence suggests that if the United States had policies in place such as those employed in many European countries, female labor force participation could be as high as 82 percent.45\n\nHowever, these policies entail tradeoffs. Women in other advanced economies are more likely than women in the United States to be employed part time, which could reflect a greater ease in arranging flexible schedules and more time with family, but it also comes with costs, including a wage penalty and fewer opportunities for training and advancement. Such findings raise the question of whether the policies enacted overseas in recent years have had the unintended consequence of making it more expensive for employers there to hire women into full-time jobs with opportunities for advancement, as women are more likely to be eligible for and to make use of such benefits.46\n\nThis possibility should inform our own thinking about policies to make it easier for women and men to combine their family and career aspirations. For instance, improving access to affordable and good quality childcare would appear to fit the bill, as it has been shown to support full-time employment.47 Recently, there also seems to be some momentum for providing families with paid leave at the time of childbirth. The experience in Europe suggests picking policies that do not narrowly target childbirth, but instead can be used to meet a variety of the health and caregiving responsibilities.48\n\nConclusion\nThe United States faces a number of longer-term economic challenges, including the aging of the population and the low growth rate of productivity. One recent study estimates that increasing the female participation rate to that of men would raise our gross domestic product by 5 percent.49 And, as I have argued, our workplaces and families, as well as women themselves, would benefit from continued progress. However, a number of factors, which I have only had a chance to touch upon, appear to be holding women back, including the difficulty women currently have in trying to combine their careers with other aspects of their lives, including caregiving. In looking to solutions, we should consider improvements to work environments and policies that benefit not only women, but all workers. Pursuing such a strategy would be in keeping with the story of the rise in women's involvement in the workforce, which, as I have described here, has contributed not only to their own well-being but more broadly to the welfare and prosperity of our country.\n\nThe title for my remarks today, \"So We All Can Succeed,\" was inspired by Malala Yousafzai, the advocate for girls' and women's education, who said, \"We cannot all succeed when half of us are held back.\"50 Brown University has played its own role by admitting women 125 years ago, by educating many thousands of women over the decades, and by continuing to be a place that equips men and women with the means to make our nation and the world a better place.\n\nReferences\nAaronson, Stephanie, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014). \"Labor Force Participation: Recent Developments and Future Prospects (PDF),\" Brookings Papers on Economic Activity, Fall, pp. 197-275.\n\nAguirre, DeAnne, Leila Hoteit, Christine Rupp, and Karim Sabbagh (2012). Empowering the Third Billion: Women and the World of Work in 2012. New York: Strategy&.\n\nAkerlof, George (1976). \"The Economics of Caste and of the Rat Race and Other Woeful Tales,\" Quarterly Journal of Economics, vol. 90 (November), pp. 599‑617.\n\nAntecol, Heather, Kelly Bedard, and Jenna Stearns (2016). \"Equal but Inequitable: Who Benefits from Gender-Neutral Tenure Clock Stopping Policies?\" IZA Discussion Paper 9904.\n\nBailey, Martha J. (2010). \"Momma's Got the Pill: How Anthony Comstock and Griswold v. Connecticut Shaped U.S. Childbearing,\" American Economic Review, vol. 100 (March), pp. 98-129.\n\nBayer, Amanda, and Cecilia Elena Rouse (2016). \"Diversity in the Economics Profession: A New Attack on an Old Problem,\" Journal of Economic Perspectives, vol. 30 (Fall), pp. 221-42.\n\nBertrand, Marianne, Claudia Goldin, and Lawrence Katz (2010). \"Dynamics of the Gender Gap for Young Professionals in the Financial and Corporate Sectors,\" American Economic Journal: Applied Economics, vol. 2 (July), pp. 228-55.\n\nBivens, Josh, Emma Garcia, Elise Gould, Elaine Weiss, and Valerie Wilson (2016). It's Time for an Ambitious National Investment in America's Children (PDF). Washington: Economic Policy Institute, April 6.\n\nBlau, Francine D., and Lawrence M. Kahn (2013), \"Female Labor Supply: Why Is the U.S. Falling Behind? (PDF)\" IZA Discussion Paper Series No. 7140. Bonn, Germany: Institute for the Study of Labor, January.\n\n------ (2016). \"The Gender Wage Gap: Extent, Trends, and Explanations,\" NBER Working Paper Series 21913. Cambridge, Mass.: National Bureau of Economic Research, January.\n\nBoushey, Heather, and Kavya Vaghul (2016). Women Have Made the Difference for Family Economic Security. Washington: Washington Center for Equitable Growth, April 4.\n\nBoustan, Leah Platt, and William J. Collins (2013). \"The Origins and Persistence of Black-White Differences in Women's Labor Force Participation,\" NBER Working Paper Series 19040. Cambridge, Mass.: National Bureau of Economic Research, May.\n\nBureau of Labor (1889). Fourth Annual Report of the Commissioner of Labor, 1888: Working Women in Large Cities. Washington: Government Printing Office.\n\nBureau of Labor Statistics (2016). National Compensation Survey: Employee Benefits in the United States (PDF), Table 32: Leave Benefits: Access, Private Industry Workers, March 2016. Washington: BLS, September.\n\nCajner, Tomaz, Dennis Mawhirter, Christopher Nekarda, and David Ratner (2014). \"Why Is Involuntary Part-Time Work Elevated?\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, April 14.\n\nCouncil of Economic Advisers (2016). The Long-Term Decline in Prime-Age Male Labor Force Participation. (PDF) Washington: Executive Office of the President of the United States, June.\n\nFernández, Raquel, Alessandra Fogli, and Claudia Olivetti (2004). \"Mothers and Sons: Preference Formation and Female Labor Force Dynamics,\" Quarterly Journal of Economics, vol. 119 (November), pp. 1249-99.\n\nGoldin, Claudia (1977). \"Female Labor Force Participation: The Origin of Black and White Differences, 1870 and 1880.\" Journal of Economic History, vol. 37 (March), pp. 87-108.\n\n------ (1990). Understanding the Gender Gap: An Economic History of American Women. New York: Oxford University Press.\n\n------ (2006). \"The Quiet Revolution that Transformed Women's Employment, Education, and Family,\" American Economic Review, vol. 96 (May), pp. 1-21.\n\n------ (2014). \"A Grand Gender Convergence: Its Last Chapter,\" American Economic Review, vol. 104 (April), pp. 1091-119.\n\nGoldin, Claudia, and Lawrence F. Katz (2002). \"The Power of the Pill: Oral Contraceptives and Women's Career and Marriage Decisions,\" Journal of Political Economy, vol. 110 (August), pp. 730-70.\n\n------ (2008). The Race between Education and Technology. Cambridge, Mass.: Belknap Press.\n\nKessler-Harris, Alice (1982). Out to Work: A History of Wage-Earning Women in the United States. New York: Oxford University Press.\n\nLambert, Susan J., Anna Haley-Lock, and Julia R. Henly (2012). \"Schedule Flexibility in Hourly Jobs: Unanticipated Consequences and Promising Directions,\" Community, Work, and Family, vol. 15 (3), pp. 293-315.\n\nLanders, Renée M., James B. Rebitzer, and Lowell J. Taylor (1996). \"Rat Race Redux: Adverse Selection in the Determination of Work Hours in Law Firms,\" American Economic Review, vol. 86 (June), pp. 329-48.\n\nLovell, Vicky (2008). \"Health and Family Care Leave for Federal Workers: Using a Short-Term Disability Insurance Model to Support Worker and Family Well-Being, Ensure Competitive Employee Compensation, and Increase Productivity (PDF),\" testimony presented to the Joint Economic Committee and the House Subcommittee on the Federal Workforce, Postal Service, and the District of Columbia at the hearing \"Investment in the Future of the Federal Workforce: Paid Parental Leave Improves Recruitment and Retention,\" Washington, March 6.\n\nLucas-Thompson, Rachel G., Wendy A. Goldberg, and JoAnn Prause (2010). \"Maternal Work Early in the Lives of Children and Its Distal Associations with Achievement and Behavior Problems: A Meta-Analysis,\" Psychological Bulletin, vol. 136 (November), pp. 915-42.\n\nManning, Alan, and Joanna Swaffield (2008). \"The Gender Gap in Early-Career Wage Growth,\" Economic Journal, vol. 118 (July), pp. 983-1024.\n\nMcGinn, Kathleen L., Mayra Ruiz Castro, and Elizabeth Long Lingo (2015). \"Mums the Word! Cross-National Effects of Maternal Employment on Gender Inequalities at Work and at Home,\" Harvard Business School Working Paper 15-094. Boston: HBS, June (revised July 2015).\n\nMoran, Gwen (2015). \"Women Now Make Up 40% of Students at Top MBA Programs,\" Fortune, November 9.\n\nNew York City Bar Association (2016). 2015 Diversity Benchmarking Report. (PDF) New York: NYC Bar Association.\n\nNoonan, Mary C., Mary E. Corcoran, and Paul N. Courant (2005). \"Pay Differences among the Highly Trained: Cohort Differences in the Sex Gap in Lawyers' Earnings,\" Social Forces, vol. 84 (December), pp. 851-70.\n\nOlson, Elizabeth (2016). \"More Law Degrees for Women, but Fewer Good Jobs,\" New York Times, November 30.\n\nOrganisation for Economic Co-operation and Development (2016). \"PF2.2: Use of Childbirth-Related Leave by Mothers and Fathers (PDF),\" OECD Family Database, last updated January 3.\n\nThévenon, Olivier (2013). \"Drivers of Female Labour Force Participation in the OECD,\" OECD Social, Employment, and Migration Working Papers No. 145. Paris: Organisation for Economic Co-operation and Development, May 23.\n\nU.S. Department of Education, Office of Educational Research and Improvement, National Center for Education Statistics (1993). 120 Years of American Education: A Statistical Portrait. (PDF) Washington: NCES, January.\n\nWorld Bank (2012). World Development Report 2012: Gender Equality and Development. Washington: World Bank.\n\nYousafzai, Malala (2013). Speech delivered at the Youth Takeover of the United Nations, organized by the president of the U.N. General Assembly, U.N. Special Envoy for Global Education Gordon Brown, and A World at School, an initiative from Theirworld, July 12, http://theirworld.org/explainers/malala-yousafzais-speech-at-the-youth-takeover-of-the-united-nations.\n\n1. I am grateful for the assistance of Brown University staff in facilitating access to Brown Women Speak, the University's oral history project, and particularly the help of archivist Mary Murphy. Return to text\n\n2. My discussion of the history of female labor force participation draws heavily on the pioneering work of Claudia Goldin, including her 2006 Ely Lecture \"The Quiet Revolution that Transformed Women's Employment, Education, and Family\" to the American Economic Association and her 1990 work Understanding the Gender Gap: An Economic History of American Women, from which the statistics on female labor force participation from the late 19th century until the mid-20th century are drawn. A thorough discussion of the quality of these data and their usefulness in making comparisons over time is included in that work. Return to text\n\n3. The higher participation rates of African American women have been attributed to different cultural norms that developed during slavery and the legacy of slavery, which left blacks impoverished and with low levels of education, making women's wages an important source of family income (Boustan and Collins, 2013; Goldin, 1977). Return to text\n\n4. U.S. Department of Education (1993). Return to text\n\n5. U.S. Department of Education (1993), p. 76. Return to text\n\n6. Goldin (1990), pp. 160-66. Return to text\n\n7. Note that for the 1970s and beyond, the participation rate is calculated as a share of those aged 16 and older, whereas for earlier years it is calculated as a share of those aged 15 and older. Return to text\n\n8. Goldin and Katz (2008). Return to text\n\n9. Goldin (2006), pp. 5-6. Return to text\n\n10. For instance, although many women who had joined the war effort in the 1940s were fired at the end of the war, as the Korean War effort picked up and the demand for the labor of women rose, women, who had learned that they could combine work and family were ready to reenter the labor force, so that by the early 1950s female labor force participation resumed its war-time high (Kessler-Harris, 1982, pp. 302-03). Moreover, evidence suggests that sons whose mothers increased their labor force participation in the wake of World War II had wives who were more likely to work (Fernández, Fogli, and Olivette, 2004). Return to text\n\n11. Interestingly, over this time young men put increasing weight on family. Goldin (2006), pp. 9 and 11. Return to text\n\n12. See, for example, Bailey (2010) and Goldin and Katz (2002). Return to text\n\n13. The Equal Credit Opportunity Act, passed in 1974, prohibited discrimination in the provision of credit on the basis of gender, race, religion, marital status and national origin. It also disallowed credit providers from asking women about their plans for future children. Return to text\n\n14. Blau and Kahn (2016). Return to text\n\n15. Kessler-Harris (1982), pp. 184-85. Return to text\n\n16. Kessler-Harris (1982), pp. 250-58. Return to text\n\n17. Kessler-Harris (1982), pp. 286-87. Return to text\n\n18. Bureau of Labor (1889). Return to text\n\n19. Goldin (2006), p. 4. Return to text\n\n20. See the discussion of this literature on pp. 232-33 of Bayer and Rouse (2016) and the studies cited therein. Return to text\n\n21. See, for example, World Bank (2012). Return to text\n\n22. Lucas-Thompson, Goldberg, and Prause (2010). Return to text\n\n23. McGinn, Ruiz Castro, and Lingo (2015). Return to text\n\n24. Board staff calculation using data from the Bureau of Labor Statistics. Return to text\n\n25. Boushey and Vaghul (2016). Return to text\n\n26. The labor force participation rate for all women declined from a peak of 60 percent in 1999 and 2000 and now stands a bit below 57 percent. However, as has been documented elsewhere, much of the decline for all women can be explained by the aging of the baby boomers into their retirement years and lower participation among teens and young adults. It is also possible that the labor force participation rate is still being held down a bit by the waning effects of the Great Recession. Aaronson and others (2014). Return to text\n\n27. Aaronson and others (2014). Also see Council of Economic Advisers (2016) and the studies cited therein. Return to text\n\n28. Blau and Kahn (2016). Return to text\n\n29. Manning and Swaffield (2008) find that although men and women enter the British labor force earning the same amount, among those who worked continuously and full time for 10 years, women would still earn 8 percent less than men, even if they have the same personality traits, were childless, and profess no interest in having children. Also see Blau and Kahn (2016) and Noonan, Corcoran, and Courant (2005). Return to text\n\n30. Moran (2015); Olson (2016). Return to text\n\n31. On the status of women in finance and corporations see Bertrand, Goldin, and Katz (2010) and the studies cited therein. For law partnerships, see New York City Bar Association (2016). Return to text\n\n32. Bayer and Rouse (2016), p. 223. Return to text\n\n33. Blau and Kahn (2016). Return to text\n\n34. Bertrand, Goldin, and Katz (2010); Goldin (2014). Return to text\n\n35. Unfortunately, in contrast to some of the successful gender neutral policies I discuss below, efforts to address the tenure problem by giving all new parents extra time before the tenure decision has actually had the effect of reducing female tenure rates and raising those of men. Antecol, Bedrard and Stearns, (2016). Return to text\n\n36. Goldin (2014). Return to text\n\n37. See, for example, Akerlof (1976) and Landers, Rebitzer, and Taylor (1996). Return to text\n\n38. See the discussion in Goldin (2014), p. 117. Return to text\n\n39. Landers, Rebitzer, and Taylor (1996), p. 334. Return to text\n\n40. Cajner and others (2014); Lambert, Haley-Lock, and Henly (2012). Return to text\n\n41. Bivens and others (2016). Return to text\n\n42. Bureau of Labor Statistics (2016). Return to text\n\n43. Blau and Kahn (2013). Return to text\n\n44. Note that Blau and Kahn (2013) do not find that improvement in the provision of childcare in other advanced economies relative to the United States explain the divergence in participation since the 1990s; however, Thévenon (2013) finds that the greater provision of childcare has a positive effect on full-time employment. Return to text\n\n45. Blau and Kahn (2013), p. 7. Return to text\n\n46. In most European countries, men are significantly less likely than women to use paid parental leave, although in a few countries, including Sweden and Iceland, over 40 percent of users of parental leave are men (OECD, 2016). Return to text\n\n47. Thévenon (2013), p. 26. Return to text\n\n48. In testimony before the Joint Economic Committee and the House Subcommittee on the Federal Workforce, Postal Service, and the District of Columbia, a breakdown of claims on New Jersey's short-term disability program in 2000 showed that pregnancy and childbirth constituted just 15 percent of all claims (Lovell, 2008). Return to text\n\n49. Aguirre and others (2012). Return to text\n\n50. Yousafzai (2013), paragraph 22. Return to text\n\ni. Note: On May 5, 2017, a typo was corrected to change 83 to 93 in the following sentence on page 8: \"By the early 1990s, the labor force participation rate of prime working-age women--those between the ages of 25 and 54--reached just over 74 percent, compared with roughly 83 percent for prime working-age men.\" Return to text"
    },
    {
        "title": "Committee Decisions and Monetary Policy Rules",
        "date": "May 05, 2017",
        "speaker": "Vice Chairman Stanley Fischer",
        "url": "https://www.federalreserve.gov/newsevents/speech/fischer20170505a.htm",
        "content": "May 05, 2017\n\nVice Chairman Stanley Fischer\n\nAt \"The Structural Foundations of Monetary Policy,\" a Hoover Institution Monetary Policy Conference, Stanford University, Stanford, California\n\nIt is a pleasure to be at the Hoover Institution again. I was privileged to be a Visiting Scholar here from 1981 to 1982. In addition, many of the researchers and practitioners with whom I have discussed monetary policy over the years have had affiliations with the Hoover Institution--including several people here today. It is a pleasure also to have been invited to speak at this Hoover Institution Monetary Policy Conference, for the Hoover conference series provides a valuable forum for policymakers and researchers to engage in dialogue about important monetary policy issues facing the United States and other countries.\n\nToday I will offer some observations on monetary policy rules and their place in decisionmaking by the Federal Open Market Committee (FOMC).1 I have two messages. First, policymakers should consult the prescriptions of policy rules, but--almost needless to say--they should avoid applying them mechanically. Second, policymaking committees have strengths that policy rules lack. In particular, committees are an efficient means of aggregating a wide variety of information and perspectives.\n\nMonetary Policy Rules in Research and Policy\nSince May 2014, I have considered monetary policy rules from the vantage point of a member of the FOMC. But my interest in them began many years ago and was reflected in some of my earliest publications.2 At that time, the literature on monetary policy rules, especially in the United States, remained predominantly concerned with the money stock or total bank reserves rather than the short-term interest rate.3 Seen with the benefit of hindsight, that emphasis probably derived from three sources: First, the quantity theory of money emphasized the link between the quantity of money and inflation; second, that research was carried out when monetarism was gaining credibility in the profession; and, third, there was a concern that interest rate rules might lead to price-level indeterminacy--an issue disposed of by Bennett McCallum and others.4\n\nSubsequently, John Taylor's research, especially his celebrated 1993 paper, was a catalyst in changing the focus toward rules for the short-term interest rate.5 Taylor's work thus helped shift the terms of the discussion in favor of rules for the instrument that central banks prefer to use. His 1993 study also highlighted the practical relevance of monetary policy rules, as he showed that a particular simple rule--the rule that now bears his name--provided a good approximation to the behavior of the federal funds rate during the early Greenspan years. The research literature on monetary policy rules has experienced a major revival since Taylor's seminal paper and has concentrated on rules for the short-term interest rate.\n\nConsideration of interest rate rules has also, as I will discuss, come to have a prominent role in FOMC discussions, with the Taylor rule being one benchmark that we regularly consult. But--building on recent remarks I made elsewhere--I will also indicate why policymakers might have good reasons for deviating from these rule benchmarks and why, in pursuing the objectives of monetary policy, they could appropriately behave in ways that are not very well characterized by simple monetary policy rules.6 In particular, I will point to reasons why the FOMC's discussions might lead to decisions that depart--temporarily or permanently--from the prescriptions of baseline monetary policy rules.\n\nRules as a Benchmark for Policy Discussions\nSome perspective on the status of policy rules in FOMC discussions is provided by considering what has changed over the past 20 years. Donald Kohn, at a landmark conference organized by John Taylor in January 1998, described the role played by monetary policy rules in the FOMC briefing process.7 His account noted that Federal Reserve staff members presented FOMC participants with prescriptions from several policy rules, including the Taylor (1993) rule. This description remains true today. Publicly available Bluebooks and Tealbooks of successive years demonstrate that the coverage of policy rules in the briefing material provided by the Board staff expanded considerably in the years after Kohn spoke.8\n\nKohn noted that policy rule prescriptions served two functions: as a \"benchmark for the stance of policy\" and \"to structure thinking about the implications of incoming information for the direction of policy action.\"9 These two functions continue to be important: Policy rule prescriptions provide a useful starting point for FOMC deliberations and a convenient way of organizing alternative arguments about the appropriate policy decision. Policy rule prescriptions, particularly prescriptions that are obtained from a dynamic model simulation, also help policymakers take to heart a key message of the literature on policy rules--namely, that monetary policy decisions should concern the appropriate path for the policy instrument and not merely the current setting of that instrument.\n\nKohn also observed, however, that \"in truth, only a few members look at this or similar information regularly, and the number does not seem to be growing.\" That state of affairs has probably changed in the two decades since Kohn wrote. It is clear from transcripts in the public record that rule prescriptions have frequently been cited at FOMC meetings.10 The prominence that interest rate rules have achieved in Federal Reserve policymakers' analysis of monetary policy was underscored by Chair Yellen in her speech at Stanford University earlier this year.11\n\nFurther, as is clear from Taylor's econometric derivation of his 1993 rule, actual monetary policy decisions may--and probably should--exhibit systematic patterns that can be described as a rule. In fact, as I have already noted, one attraction of the 1993 Taylor rule was that it described U.S. monetary policy patterns well over a certain period, one that was associated with a reasonable degree of economic stability.\n\nNevertheless, central bankers who are aware of the merits of the arguments for policy rules have on occasion deviated substantially from the prescriptions of standard policy rules. Further, while the implications of different monetary rules are described in the Tealbook and typically referred to in the presentations by several FOMC participants, the overall discussion in FOMC meetings is not generally cast in terms of how it relates to one version or another of the Taylor or any other rule. The other set of rules mentioned frequently in FOMC discussions are Wicksellian, for there is often a discussion of r*, which in some formulations of the Taylor rule is also the constant term.\n\nThe period since 2008 bears testimony to central bankers' willingness to depart from the prescriptions of a pre-specified rule. In the wake of the financial crisis, policymakers found it necessary to follow a more accommodative monetary policy that was appropriate for the new economic conditions.12 In addition, structural changes in the U.S. economy have apparently lowered the value of the interest rate--that is, r*--consistent with neutral policy.13\n\nSuch structural changes were not anticipated in advance.14 Of course, once a structural change has occurred and been ascertained by policymakers, they will know what rules would likely have performed well in the face of that change. For this reason, policymakers might change their judgment about what monetary policy rules constitute reasonable benchmarks, or, over time, they might develop a procedure for revising the monetary rule. But a frequently revised rule does not really qualify as a rule in the sense that we currently use the term.\n\nConsequently, when considering the relationship between monetary policy decisions and monetary policy rules, we can expect two regularities to hold. First, actual monetary policy will sometimes appropriately depart from the prescriptions of benchmark rules even when those benchmarks describe past decisions well. Second, in their use of rules, policymakers will from time to time change their assessment of what rule they regard as the appropriate benchmark. Both regularities have been amply observed in recent years, but they were also present 20 years ago, as reflected in Kohn's remark that policymakers \"do not see their past actions as a very firm guide to current or future policy.\" Or, as a teacher of mine at the London School of Economics, Richard Sayers, put it much earlier, \"There is no code of eternal rules. . . . We have central banks for the very reason that there are no such rules.\"15\n\nAs I will now elaborate, I believe the fact that monetary policy is made by committees in most economies is important in understanding both of these regularities.\n\nThe Role of Committees in Policy Formation\nMonetary policy decisions in the United States and elsewhere typically arise from a discussion and vote of a committee.16 In principle, a monetary policy committee could decide to follow a rule. But a decision of this kind is unlikely to occur in practice. Committee discussions bring into policymaking features that a rule lacks. A committee-based decision process is, I suggest, likely to produce policy decisions that depart from the prescriptions of benchmark rules.\n\nA policy rule prescription is more consistent with a single perspective on the economy than with the pooling of multiple perspectives that is associated with a committee policymaking process. Roger Lowenstein's book America's Bank details how the founding of the Federal Reserve involved reconciling a large number of interests in the United States.17 In a similar vein, the modern FOMC framework involves participation by 12 Reserve Bank presidents, each of whom represents a different district of the country. The FOMC framework also balances centralized and decentralized decisionmaking by having most of the permanent voting members--specifically, the Board of Governors--be based in Washington, D.C.\n\nAll of the FOMC participants have common goals--maximum employment and price stability--that are given by the Federal Reserve's statutory mandate. They have also agreed, for pursuing that mandate, on the Statement on Longer-Run Goals and Monetary Policy Strategy.18 But while they have this common ground, each FOMC participant brings to the table his or her own perspective or view of the world. Part of their role in meetings is to articulate that perspective and perhaps persuade their colleagues to revise their own perspectives--or vice versa.\n\nA member of a committee may well have valuable economic information not known by their colleagues until he or she relays it. This point has been brought home to me by Reserve Bank presidents' accounts of recent economic developments in their Districts. These narratives shed light on the real-world developments that lie behind the recorded economic data. They also help shape my interpretation of what part of incoming data may be an important signal and what part may reflect transitory factors or mismeasurement.\n\nThe information underlying a policy decision is, therefore, crucially shaped by a committee system. Committees can aggregate a large volume of diverse information about current and expected future economic conditions. The information includes anecdotes and impressions gleaned from business and other contacts, which can provide insights that are not recorded in current data releases.\n\nIn practice, it is likely that the information obtained and processed by the Committee will leave the FOMC less inclined to follow a benchmark rule. For example, the Committee's discussions might point up factors that have not yet affected real economic activity and inflation. Such factors would not lead to an immediate change in the prescription for the federal funds rate obtained from a rule like the Taylor rule, as this prescription is a function of current values of the output gap and inflation. The Committee might nevertheless wish to adjust the federal funds rate immediately because the newly unearthed factors are likely to affect output and inflation in coming months.\n\nIn addition, and as I have suggested, policymakers might also encounter unexpected or unusual events, or both, or they might perceive changes in the structure of the economy. A committee process is conducive to assessing the appropriate policy response to these developments. A case in point is the decline, as I mentioned, in estimates of the neutral interest rate. The concept of the neutral interest rate is a way of summarizing the various forces, many of them unobservable, that shift the relationship between monetary policy and economic activity. Bringing to the table diverse perspectives is a pragmatic way of confronting such deep sources of uncertainty and deciding how to deal with them. A committee discussion can flesh out the factors behind changes in the neutral rate, and a committee would likely be able to identify such changes more promptly than would a statistical exercise, because of the wider set of information from around the country that the committee is able to process.\n\nThe decisionmaking environment that I have described involves more flexibility for FOMC members than they would have if they simply followed a policy rule. But transparency and accountability must figure heavily in this more flexible environment. The FOMC's policy communications include its postmeeting statement, the minutes of its meetings, the Chair's quarterly press conference, the Chair's semiannual monetary policy testimony to the Congress, and other public remarks by individual FOMC members. In this framework, policymakers articulate the reasoning behind each decision and, in particular, explain how the policy decision contributes to the achievement of the Committee's statutory mandate.\n\nThere remains a deeper question about committee decisionmaking: Why have almost all countries decided that monetary policy decisions should be made by a committee rather than by a rule? One answer is that laws in most countries are passed by institutions in which committee deliberation is the norm. Of course, we then have to ask why that has become a norm in almost all democracies. The answer is that opinions--even on monetary policy--differ among experts, while the economy is in a constant process of change.\n\nBecause opinions differ among experts, democracies tend to prefer committees in which decisions are made by discussion among the experts--and, in many cases, other representatives of the public--who discuss, try to persuade each other, and must at the end of their deliberations reach a decision. But those decisions have to be explained to the public and to other parts of the government--and hence the appropriate emphasis on transparency and accountability. That is the democratic way of making decisions when opinions differ, as they often do in the monetary field.\n\nI have been a governor of two central banks and, even as the sole monetary policy decisionmaker in the Bank of Israel, would sometimes find that my initial view on the next decision changed as a result of discussions with the informal advisory committee with whom I consulted at that time. Those discussions, which recognize human frailty in analyzing a situation and the need to act despite considerable uncertainties, are the reason why committee decisionmaking is, on average, preferable to the use of a rule.19\n\nEmphasis on a single rule as the basis for monetary policy implies that the truth has been found, despite the record over time of major shifts in monetary policy--from the gold standard, to the Bretton Woods fixed but changeable exchange rate rule, to Keynesian approaches, to monetary targeting, to the modern frameworks of inflation targeting and the dual mandate of the Fed, and more. We should not make our monetary policy decisions based on that assumption. Rather, we need our policymakers to be continually on the lookout for structural changes in the economy and for disturbances to the economy that come from hitherto unexpected sources.\n\nConcluding Remarks\nLet me now sum up. The prescriptions of monetary policy rules play a prominent role in the FOMC's monetary policy deliberations. And this is as it should be, in view of the usefulness of rules as a starting point for policy discussion and the fact that comparison with a benchmark rule provides a useful means of articulating one's own preferred policy action. But, for the reasons I have outlined, adherence to a simple policy rule is not the most appropriate means of achieving macroeconomic goals--and there are very good reasons why monetary policy decisions are typically made in committees whose structure allows them to assess the varying conditions of different regions and economic sectors, as well as to reflect different beliefs about the working of the economy.\n\nReferences\nAndo, Albert (1981). \"On a Theoretical and Empirical Basis of Macroeconometric Models,\" in J. Kmenta and J.B. Ramsey, eds., Large-Scale Macro-Econometric Models: Theory and Practice. New York: North-Holland, pp. 329-68.\n\nBlinder, Alan S., and John Morgan (2005). \"Are Two Heads Better Than One? Monetary Policy by Committee,\" Journal of Money, Credit, and Banking, vol. 37 (October), pp. 789-811.\n\nBoard of Governors of the Federal Reserve System (2017). \"Minutes of the Federal Open Market Committee, December 13-14, 2016,\" press release, January 4.\n\nCooper, J. Phillip, and Stanley Fischer (1972). \"Stochastic Simulation of Monetary Rules in Two Macroeconomic Models,\" Journal of the American Statistical Association, vol. 67 (December), pp. 750-60.\n\nCurrie, David, and Paul Levine (1987). \"Does International Macroeconomic Policy Coordination Pay and Is It Sustainable? A Two-Country Analysis,\" Oxford Economic Papers, vol. 39 (March), pp. 38-74.\n\nDeRosa, Paul, and Gary H. Stern (1977). \"Monetary Control and the Federal Funds Rate,\" Journal of Monetary Economics, vol. 3 (April), pp. 217-30.\n\nDewald, William G., and Harry G. Johnson (1963). \"An Objective Analysis of the Objectives of American Monetary Policy, 1952-61,\" in Deane Carson, ed., Banking and Monetary Studies. Homewood, Ill.: R.D. Irwin, pp. 171-89.\n\nDornbusch, Rudiger, and Stanley Fischer (1978). Macroeconomics. New York: McGraw-Hill.\n\n-------- (1979). The Determinants and Effects of Changes in Interest Rates: A Study Prepared for the Trustees of the Banking Research Fund. Chicago: Association of Reserve City Bankers.\n\nEngen, Eric M., Thomas Laubach, and David Reifschneider (2015). \"The Macroeconomic Effects of the Federal Reserve's Unconventional Monetary Policies (PDF),\" Finance and Economics Discussion Series 2015-005. Washington: Board of Governors of the Federal Reserve System, February.\n\nFederal Open Market Committee (2017). Statement on Longer-Run Goals and Monetary Policy Strategy (PDF), amended effective January 31 (original version adopted effective January 24, 2012).\n\nFischer, Stanley (1994). \"Modern Central Banking,\" in Forrest Capie, Charles Goodhart, Stanley Fischer, and Norbert Schnadt, eds., The Future of Central Banking: The Tercentenary Symposium of the Bank of England. New York: Cambridge University Press, pp. 262-308.\n\n-------- (2017a). \"'I'd Rather Have Bob Solow Than an Econometric Model, But . . . ,'\" speech delivered at the Warwick Economics Summit, Coventry, United Kingdom, February 11.\n\n-------- (2017b). \"Monetary Policy: By Rule, by Committee, or by Both?\" speech delivered at the 2017 U.S. Monetary Policy Forum, sponsored by the Initiative on Global Markets at the University of Chicago Booth School of Business, New York, March 3.\n\nFlemming, John (1993). \"Money, Interest and Consumption in the General Theory,\" in Haim Barkai, Stanley Fischer, and Nissan Liviatan, eds., Monetary Theory and Thought: Essays in Honour of Don Patinkin. London: Macmillan, pp. 74-83.\n\nFriedman, Milton (1972). \"The Case for a Monetary Rule,\" Newsweek, February 7, p. 67.\n\nHenderson, Dale W., and Warwick J. McKibbin (1993). \"A Comparison of Some Basic Monetary Policy Regimes for Open Economies: Implications of Different Degrees of Instrument Adjustment and Wage Persistence,\" Carnegie-Rochester Conference Series on Public Policy, vol. 39 (December), pp. 221-317.\n\nKeynes, John Maynard (1930). A Treatise on Money, 2 vols. New York: Harcourt, Brace and Company.\n\nKohn, Donald L. (1999). \"Comment,\" in John B. Taylor, ed., Monetary Policy Rules. Chicago: University of Chicago Press, pp. 192-99.\n\nLevin, Andrew T., and John C. Williams (2003). \"Robust Monetary Policy with Competing Reference Models,\" Journal of Monetary Economics, vol. 50 (July), pp. 945-75.\n\nLombardelli, Clare, James Proudman, and James Talbot (2005). \"Committees versus Individuals: An Experimental Analysis of Monetary Policy Decision Making,\" International Journal of Central Banking, vol. 1 (May), pp. 181-205.\n\nLowenstein, Roger (2015). America's Bank: The Epic Struggle to Create the Federal Reserve. New York: Penguin Press.\n\nMcCallum, Bennett T. (1981). \"Price Level Determinacy with an Interest Rate Policy Rule and Rational Expectations,\" Journal of Monetary Economics, vol. 8 (November), pp. 319-29.\n\n-------- (1988). \"Robustness Properties of a Rule for Monetary Policy,\" Carnegie-Rochester Conference Series on Public Policy, vol. 29 (Autumn), pp. 173-203.\n\nMeade, James E. (1951). The Theory of International Economic Policy, vol. 1: The Balance of Payments. New York: Oxford University Press.\n\nMundell, Robert A. (1960). \"The Monetary Dynamics of International Adjustment under Fixed and Flexible Exchange Rates,\" Quarterly Journal of Economics, vol. 74 (May), pp. 227-57.\n\nOrphanides, Athanasios (2003). \"The Quest for Prosperity without Inflation,\" Journal of Monetary Economics, vol. 50 (April), pp. 633-63.\n\nReifschneider, David (2016). \"Gauging the Ability of the FOMC to Respond to Future Recessions (PDF),\" Finance and Economics Discussion Series 2016-068. Washington: Board of Governors of the Federal Reserve System, August.\n\nSargent, Thomas J., and Neil Wallace (1975). \"'Rational' Expectations, the Optimal Monetary Instrument, and the Optimal Money Supply Rule,\" Journal of Political Economy, vol. 83 (April), pp. 241-54.\n\nSayers, R.S. (1958). Central Banking after Bagehot, rev. ed. Oxford, United Kingdom: Clarendon Press.\n\nTaylor, John B. (1993). \"Discretion versus Policy Rules in Practice,\" Carnegie-Rochester Conference Series on Public Policy, vol. 39 (December), pp. 195-214.\n\n--------, ed. (1999a). Monetary Policy Rules. Chicago: University of Chicago Press.\n\n-------- (1999b). \"The Robustness and Efficiency of Monetary Policy Rules as Guidelines for Interest Rate Setting by the European Central Bank,\" Journal of Monetary Economics, vol. 43 (June), pp. 655-79.\n\nWarsh, Kevin M. (2016). \"Institutional Design: Deliberations, Decisions, and Committee Dynamics,\" in John H. Cochrane and John B. Taylor, eds., Central Bank Governance and Oversight Reform. Stanford, Calif.: Hoover Institution Press, pp. 173-93.\n\nWicksell, Knut (1936). Interest and Prices: A Study of the Causes Regulating the Value of Money, trans. R.F. Kahn. London: Macmillan.\n\nWoodford, Michael (2003). Interest and Prices: Foundations of a Theory of Monetary Policy. Princeton, N.J.: Princeton University Press.\n\nYellen, Janet L. (2017). \"The Economic Outlook and the Conduct of Monetary Policy,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford, Calif., January 19.\n\n1. Views expressed in this presentation are my own and not necessarily the views of the Federal Reserve Board or the Federal Open Market Committee. I am grateful to Ed Nelson of the Federal Reserve Board for his assistance. Return to text\n\n2. See, for example, Cooper and Fischer (1972). Return to text\n\n3. There was, however, a long tradition of monetary analysis in the United Kingdom and continental Europe that was centered on the authorities' use of the interest rate as an instrument. See especially Keynes (1930) and Wicksell (1936). In the post-World War II decades, this tradition continued in the U.K. research literature on monetary policy: Examples include Currie and Levine (1987) and Flemming (1993). In addition, an interest rate was the policy instrument in some key contributions to open-economy monetary theory, such as Meade (1951) and Mundell (1960). These traditions likely reflected the long-standing use of Bank Rate as a policy instrument in the United Kingdom and the fact that, for most of the period from the Treasury/Federal Reserve Accord of 1951 until the 1990s, central banks in countries other than the United States tended to be more explicit than the Federal Reserve chose to be about their use of short-term interest rates as their primary policy instrument. Even in the U.S. context, however, there was a certain amount of research on interest rate policies. For example, it was common practice among builders of large econometric models to consider different Federal Reserve interest rate strategies (see Ando, 1981). In addition, the empirical and simulation properties of the Federal Reserve's interest rate reaction function were the concern of such studies as Dewald and Johnson (1963), DeRosa and Stern (1977), Dornbusch and Fischer (1979), and Henderson and McKibbin (1993), while Sargent and Wallace (1975) and McCallum (1981) examined the analytical properties of interest rate rules. A later magisterial study of the analytics of interest rate rules was Woodford (2003). Return to text\n\n4. See McCallum (1981). I should add that when we presented work based on Cooper and Fischer (1972), we were urged by several economists to focus on the interest rate as the monetary policy instrument. Among these economists were Albert Ando and Franco Modigliani, who were then working with others on building the MPS (MIT-Pennsylvania-Social Science Research Council) model. Return to text\n\n5. See Taylor (1993). Return to text\n\n6. For my earlier speeches in this area, see Fischer (2017a, 2017b). Return to text\n\n7. See Kohn (1999). At the time, Donald Kohn was director of the Division of Monetary Affairs at the Federal Reserve Board. The conference proceedings were published as Taylor (1999a). Return to text\n\n8. The Federal Reserve Board's website (https://www.federalreserve.gov/monetarypolicy/fomc_historical_year.htm) provides downloadable copies of the briefing books (the Greenbook and Bluebook, which were replaced in 2010 by the Tealbook) distributed to FOMC members and other participants ahead of each FOMC meeting. At present, the most recent year for which these materials are available on the site is 2011. The \"Monetary Policy Strategies\" portion of the Bluebook (and, later, the Tealbook) contains prescriptions from interest rate rules. Return to text\n\n9. See Kohn (1999, p. 195). The first of these functions of policy rule prescriptions was one I also had highlighted. In Fischer (1994, p. 289), when considering McCallum's (1988) proposed rule for monetary base growth, I described it as \"a useful benchmark against which to judge policy.\" Return to text\n\n10. Searchable transcripts of FOMC meetings up to 2011 are available on the Board's website at https://www.federalreserve.gov/monetarypolicy/fomc_historical.htm. Return to text\n\n11. See Yellen (2017). Return to text\n\n12. See especially Engen, Laubach, and Reifschneider (2015). Because the federal funds rate was at its effective lower bound from late 2008 to late 2015, policy choices about that rate largely involved decisions concerning the forward guidance provided by the FOMC. These decisions in turn rested on judgments regarding the period over which the rate should remain at its lower bound, as well as about the pace and magnitude of the subsequent policy firming. Return to text\n\n13. See, for example, Board of Governors (2017). Return to text\n\n14. Indeed, Milton Friedman's advocacy of a policy rule consisting of constant monetary growth rested in part on the existence of uncertainty, as he suggested that economists lacked the knowledge about economic relationships required to improve on that simple rule. See Friedman (1972) for a concise version of his case for the rule and Dornbusch and Fischer (1978, pp. 278-80, 516) for a textbook account of Friedman's rule that emphasized the uncertainty aspect of his argument for the rule. Of course, the fact that a policy rule is simple far from guarantees that the rule will generate satisfactory economic outcomes in the face of uncertainty and economic change. For example, Friedman's rule would likely perform poorly in an environment in which the trend rate of growth of monetary velocity underwent a major shift, while the Taylor rule could perform unsatisfactorily if the assumption about potential-output behavior embedded in the rule proved to be badly mistaken. The latter possibility was stressed in Orphanides (2003). Return to text\n\n15. See Sayers (1958, p. 7). Return to text\n\n16. I discussed some of the literature on monetary policy committees in Fischer (2017b). Return to text\n\n17. See Lowenstein (2015). Return to text\n\n18. See Federal Open Market Committee (2017). Return to text\n\n19. The existing literature on monetary policy committees has found that committee decisions tend to be better than decisions made by a sole policymaker. See, for example, Blinder and Morgan (2005); Lombardelli, Proudman, and Talbot (2005); and Warsh (2016). Return to text"
    },
    {
        "title": "Where Do Banks Fit in the Fintech Stack?",
        "date": "April 28, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170428a.htm",
        "content": "April 28, 2017\n\nGovernor Lael Brainard\n\nAt the Northwestern Kellogg Public-Private Interface Conference on \"New Developments in Consumer Finance: Research & Practice\"\n\nWe can learn a lot from the evolution of smartphones as we try to envisage where the fintech ecosystem--and banks' role within it--might be heading in the future. Smartphones have ushered in an age when different companies can easily work with each other's products to seamlessly provide services to consumers. Today I want to reflect on what we might learn from that model about the increasingly interconnected world of financial services.\n\nOn the 10th anniversary of the iPhone, a Wired.com article revealed that even Steve Jobs hadn't predicted the smartphone's potential as a platform.1 Apple was just trying to design an iPod that made phone calls. Today, the average American spends five hours a day on their phone, unlocking it an average of 80 times daily.2 Even the Supreme Court has noted that smartphones are now \"such a pervasive and insistent part of daily life that the proverbial visitor from Mars might conclude they were an important feature of human anatomy.\"3\n\nOf course, we aren't using these appendages primarily to make phone calls. Instead, we mainly use our smartphones to access applications (apps).4 In June of last year, Apple announced that over 2 million apps were available on its App Store.5 For the most part, these apps were not created or even envisaged by Apple. These apps have been downloaded 130 billion times, generating over $50 billion in revenue for third-party developers.6\n\nThe iPhone is a key platform on which that app ecosystem operates. How did that happen? Apple essentially made the smartphone a toolkit for third-party developers to experiment, innovate, build, and scale new apps. It did so by investing heavily in developing open application programming interfaces (APIs) that provided third-party developers clear instructions and open access to the iPhone platform. This strategy enabled those outside developers to build new applications that delivered Apple's customers additional value by taking advantage of the existing functionality of the iPhone. Specifically, this open architecture makes available to outside developers clear instructions that enable them to use the iPhone's various sensors, processors, displays, and other interfaces in combination with their own code to develop new products.\n\nOn top of that, a robust secondary layer of developers use the APIs of other developers in their technology stacks to quickly assemble new business models. Take ride-sharing services, for instance. They have built multibillion-dollar businesses that are, in large part, dependent on combinations of APIs from different companies. They may use Google Maps' APIs for location services, Stripe or Braintree's APIs for payments, Twilio's APIs for text messaging, and Amazon Web Services' or IBM's APIs for computing power. All of these products, and more, work seamlessly together in real time to provide products that are so ubiquitous that we now use them as verbs for how we navigate the world. We \"Uber\" to the store or \"Snapchat\" a friend.\n\nRisks and Opportunities in an Increasingly Interconnected World\nThere is every reason to expect financial services to make a similar transition to an increasingly interconnected digital world. By now, we've all heard estimates of the thousands of fintech companies that have launched in the past few years and the billions of investment dollars that are flooding into this sector.7 But for all of the talk of \"disruption,\" I want to underscore an important point: More often than not, there is a banking organization somewhere in the fintech stack. Just as third-party app developers rely on smartphone sensors, processors, and interfaces, fintech developers need banks somewhere in the stack for such things as: (a) access to consumer deposits or related account data, (b) access to payment systems, (c) credit origination, or (d) compliance management.8 For instance, account comparison services rely on access to data from consumers' bank accounts. Savings and investment apps analyze transactions data from bank accounts to understand how to optimize performance and manage the funds consumers hold in those accounts. Digital wallets draw funds from payment cards or bank accounts. Marketplace loans most often depend on loan origination by a bank partner. And payment innovations often \"settle up\" over legacy payment rails, like the automated clearinghouse system.9 In short, the software stacks of almost all fintech apps point to a bank at one layer or another.\n\nSo as fintech companies and banks are catching up to the interconnected world, the various players are sorting out how best to do the connecting. Much of the work so far has been focused on the technical challenges, which are notable. Most banks' core systems are amalgams of computing mainframes built decades ago before the Internet or cloud computing were widely available and, in many cases, stitched together over the course of mergers and consolidations.10 It takes a lot of investment to securely convert that infrastructure to platforms that can operate in real-time with ready access for Internet-native third-party developers.\n\nBut important policy, regulatory, and legal questions also demand attention. And that is where the smartphone analogy loses its power. On balance, bank activities are much more highly regulated than smartphones. Those regulations enable consumers to trust their banks to secure their funds and maintain the integrity of their transactions. While \"run fast and break things\" may be a popular mantra in the technology field, it is ill suited to an arena where a serious breach could undermine confidence in the payments system. Indeed, some of the key underpinnings of consumer protection and safety and soundness in the banking world--that consumers should be exceptionally careful in granting account access, that in certain conditions banks could be presumed to bear liability for unauthorized charges, and that banks can be held responsible for ensuring that service providers and vendors do right by their customers--sit uneasily alongside the requisites of openness, connectivity, and data access that enable today's app ecosystem.11 For instance, before entering an outsourcing arrangement, a bank is expected to consider whether the service provider's internal processes or systems (or even human error at the outside party) could expose the bank and its customers to potential losses or expose the bank's customers to fraud and the bank to litigation; whether the service provider complies with applicable laws and regulation; and whether poor performance by that outside party could materially harm the bank's public reputation.\n\nThe smartphone app ecosystem developed without the regulations or associated guardrails pertaining to institutions that people trust to hold their life savings. For instance, when Pokémon Go was first launched, its creator, Niantic, used an outdated Google API to verify consumer identities. This created confusion about whether millions of consumers had unwittingly granted Niantic full access to their e-mails, contact lists, and calendars.12 However, it did not stand in the way of Pokémon Go subsequently being downloaded a half billion times.13 In contrast, these kinds of mistakes in the banking sector could raise grave concerns about consumer data privacy and security and the integrity of consumer transactions data. That's why banks are expected to conduct extensive risk assessments and due diligence of their service providers, extending even to operations and internal controls, among other requirements.14 While that helps ensure a safe and sound banking system, that also makes it more challenging for both the banks and fintech companies to harness safely the interconnectivity that has powered other parts of the digital world.\n\nDifferent Approaches to the Fintech Stack\nBecause of the high stakes, fintech firms, banks, data aggregators, consumer groups, and regulators are all still figuring out how best to do the connecting. There are a few alternative approaches in operation today, with various advantages and drawbacks.\n\nA number of large banks have developed or are in the process of developing interfaces to allow outside developers access to their platforms under controlled conditions. Similar to Apple opening the APIs of its phones and operating systems, these financial companies are working to provide APIs to outside developers, who can then build new products on the banks' platforms.15 It is worth highlighting that platform APIs generally vary in their degree of openness, even in the smartphone world. If a developer wants to use a Google Maps API to embed a map in her application, she first must create a developer account with Google, agreeing to Google's terms and conditions. This means she will have entered a contract with the owner of the API, and the terms and conditions may differ depending on how sensitive the particular API is. Google may require only a minimum amount of information for a developer that wants to use an API to display a map. Google may, however, require more information about a developer that wants to use a different API to monitor the history of a consumer's physical locations over the previous week. And in some cases, the competitive interests of Google and a third-party app developer may diverge over time, such that the original terms of access are no longer acceptable.16\n\nThe fact that it is possible and indeed relatively common for the API provider--the platform--to require specific controls and protections over the use of that API raises complicated issues when imported to the banking world. As banks have considered how to facilitate connectivity, the considerations include not only technical issues and the associated investment, but also the important legal questions associated with operating in a highly regulated sector. The banks' terms of access may be determined in third-party service provider agreements that may offer different degrees of access. These may affect not only what types of protections and vetting are appropriate for different types of access over consumers' funds and data held at a bank in order to enable the bank to fulfill its obligations for data security and other consumer protections, but also the competitive position of the bank relative to third-party developers.\n\nThere is a second broad type of approach in which many banks have entered into agreements with specialized companies that essentially act as middlemen, frequently described as \"data aggregators.\" These banks may lack the budgets and expertise to create their own open APIs or may not see that as a key element in their business strategies. Data aggregators collect consumer financial account data from banks, on the one hand, and then provide access to that data to fintech developers, on the other hand.17 Data aggregators organize the data they collect from banks and other data sources and then offer their own suite of open APIs to outside developers. By partnering with data aggregators, banks can open their systems to thousands of developers, without having to invest in creating and maintaining their own open APIs. This also allows fintech developers to build their products around the APIs of two or three data aggregators, rather than 15,000 different banks and other data sources. And, if agreements between data aggregators and banks are structured as data aggregators performing outsourced services to banks, the bank should be able to conduct the appropriate due diligence of its vendors, whose services to those banks may be subject to examination by safety and soundness regulators.18\n\nSome banks have opted for a more \"closed\" approach to fintech developers by entering into individual agreements with specific technology providers or data aggregators.19 These agreements often impose specific requirements rather than simply facilitating structured data feeds. These banks negotiate for greater control over their systems by limiting who is accessing their data--often to a specific third party's suite of products. Likewise, many banks use these agreements to limit what types of data will be shared. For instance, banks may share information about the balances in consumers' accounts but decline to share information about fees or other pricing. While recognizing the legitimate need for vetting of third parties for purposes of the banks fulfilling their responsibilities, including for data privacy and security, some consumer groups have suggested that the standards for vetting should be commonly agreed to and transparent to ensure that banks do not restrict access for competitive reasons and that consumers should be able to decide what data to make available to third-party fintech applications.20\n\nA third set of banks may be unable or unwilling to provide permissioned access, for reasons ranging from fears about increased competition to concerns about the cost and complexity of ensuring compliance with underlying laws and regulations. At the very least, banks may have reasonable concerns about being able to see, if not control, which third-party developers will have access to the banking data that is provided by the data aggregators. Accordingly, even banks that have previously provided structured data feeds to data aggregators may decide to limit or block access.21 In such cases, however, data aggregators can still move forward to collect consumer data for use by fintech developers without the permission or even potentially without the knowledge of the bank. Instead, data aggregators and fintech developers directly ask consumers to give them their online banking logins and passwords. Then, in a process commonly called \"screen scraping,\" data aggregators log onto banks' online consumer websites, as if they were the actual consumers, and extract information. Some banks report that as much as 20 to 40 percent of online banking logins is attributable to data aggregators. They even assert that they have trouble distinguishing whether a computer system that is logging in multiple times a day is a consumer, a data aggregator, or a cyber attack.\n\nFor community banks with limited resources, the necessary investments in API technology and in negotiating and overseeing data-sharing agreements with data aggregators and third-party providers may be beyond their reach, especially as they usually rely on service providers for their core technology. Some fintech firms argue that screen scraping--which has drawn the most complaints about data security--may be the most effective tool for the customers of small community banks to access the financial apps they prefer--and thereby necessary to remain competitive until more effective broader industry solutions are developed.\n\nClearly, getting these connectivity questions right, including the need to manage the consumer protection risks, is critically important. It could make the difference between a world in which the fintech wave helps community banks become the platforms of the future, on the one hand, or, on the other hand, a world in which fintech instead further widens the gulf between community banks and the largest banks.\n\nTradeoffs\nThe different approaches to integrating banks into the fintech stack represent different risks and tradeoffs. Connectivity solutions that require intermediaries such as data aggregators and rely on screen scraping potentially create repositories of consumer credentials for hackers to target. Banks argue that if such a repository is breached, thousands of banks could be impacted.22 Further complicating things, because screen scrapers operate without contractual relationships with the banks from which they pull information, banks have little leverage or ability to vet the security of the screen scrapers' systems and methods or their overall risk. In these circumstances, some commentators have noted that if a data aggregator or third-party developer is breached, it may not be clear who would bear responsibility for any losses--the bank, the data aggregator, the fintech developer, or the consumer. Some third-party developers have included terms and conditions that specifically limit their liability to consumers.23 It is not clear the extent to which many consumers understand the risks involved with sharing their banking credentials, the more limited liability accepted by many third-party developers relative to their bank or credit card issuer, and the fact that the third-party developers may in turn provide those credentials to others in some instances.\n\nOn the other side of the debate, fintech companies are concerned that banks could use their control over consumer data access in the context of bilateral contracts with data aggregators to leverage their position in order to impede competition elsewhere in the stack. This argument about access and competition echoes similar concerns in the smartphone arena.24\n\nFurther, third-party developers argue that open standards for data access can help banks meet consumers' expectations for mobile banking by providing access to the fintech apps that best serve their needs. The relatively open architecture of the iPhone platform means that Apple profits from outside developers' products without having to design or invest in them directly. For instance, Apple didn't include a home-grown mapping app during the first few years of the iPhone.25 Instead, it relied on Google to provide that important function for its smartphones before trying to build its own mapping tool--a process that took a number of iterations before getting it right. Open platform strategies may mean that banks can essentially outsource product development to fintech firms.26 This could be a boon--particularly for small community banks that would not have to worry about developing the best consumer interface, mobile app, digital wallet, or lending product. The bank would only have to worry about getting the connections to an open API right and then reap the benefits of the innovation by third parties.\n\nRegulatory Developments\nAs regulators, we have a responsibility to ensure that the institutions subject to our supervision are operated safely and soundly and that they comply with applicable statutes and regulations. More broadly, we have a strong interest in permitting socially beneficial innovations to flourish, while ensuring the risks that they may present are appropriately managed, consistent with the legal requirements. We do not want to unnecessarily restrict innovations that can benefit consumers and small businesses through expanded access to financial services or greater efficiency, convenience, and reduced transaction costs. Nor do we want to drive these activities away from regulated banks and toward less governed spaces in the financial system.\n\nRegulators in the United Kingdom and continental Europe have recently outlined new approaches to facilitate connectivity in financial services, while attempting to mitigate the associated risks. In August 2016, the UK Competition & Markets Authority (CMA) released a package of mandates aimed at increasing competition for consumer and small business current accounts (akin to U.S. checking accounts).27 This year nine of the country's largest banks were required to create open APIs to share nonsensitive, non-consumer-specific information, like pricing, fees, terms, and conditions as well as branch and automated teller machine locations.28 This initial limited sharing of information has started communication and collaboration across the industry on areas like data standards and organizational governance, which will facilitate work on more contentious questions. Before March 2018, the CMA is scheduled to enforce a broader package of reforms, including mandating that the nine banks create APIs that allow third-party banks and nonbanks to access consumer accounts for reading transaction data and payment initiation.\n\nIn the European Union, beginning in 2018, member states will be required to start implementing the European Parliament's revised Payment Services Directive (PSD2).29 Among other elements, PSD2 created licensing regimes for third parties that access bank accounts for purposes of initiating payment orders or consolidating information with consumers' consent.30 The directive mandates that banks allow these licensed third parties to access their consumer accounts (with consumer permission) without premising such access on contractual agreements with the banks. Indeed, PSD2 requires that credit institutions not block or hinder access to payment accounts and that licensed third parties have access to credit institutions' payment accounts services in an objective, nondiscriminatory, and proportionate manner. When credit institutions do reject access, they are required to provide the relevant authorities detailed reasoning for the rejection.\n\nThe directive attempts to mitigate the attendant data-security and consumer-protection risks with a number of measures that, by and large, are not readily available policy options in the United States. Importantly, third parties that access bank accounts will be subject to licensing and registration requirements, as well as associated capital and insurance requirements. Moreover, the directive envisions that electronic payments will be authorized by two-factor authentication--for example \"something you know\" and \"something you are.\"31\n\nThe United States is likely to address these issues in a different way, at least initially, given that regulatory authorities are more broadly distributed, and the relevant statutory language predates these technological developments. The Consumer Financial Protection Bureau (CFPB) issued a Request for Information last fall to explore issues surrounding consumers' granting access to account information to third parties.32 Of course, safety and soundness regulation--and with it, concerns about data security, cyber security, and vendor risk management--is distributed among a number of regulators. For instance, there may be value to examining the vendor risk management guidance so that it facilitates banks connecting more securely and efficiently with the fintech apps that consumers prefer.33 Similarly, it could be useful to periodically assess whether and how authority under the Bank Service Company Act might pertain to developments in the fast evolving fintech sector. In addition, the private sector is continuing to actively experiment with a variety of different approaches to the connectivity question and may itself move toward one or more widely accepted standards. Accordingly, efforts to craft approaches that enhance connectivity while mitigating the associated risks will likely benefit from the engagement of multiple agencies, along with input from the private sector and other stakeholders.\n\nSeparately, the Office of the Comptroller of the Currency (OCC), which is responsible for administering national bank charters, has announced that it is exploring offering \"special purpose national bank charters\" to fintech companies.34 As envisioned by the OCC, obtaining a special purpose charter would have the practical effect of allowing certain fintech companies (companies that make loans, make payments, or accept deposits) to potentially bypass the need for connecting to a bank for certain purposes in favor of becoming licensed as banks themselves. The OCC's proposal raises interpretive and policy issues for the Federal Reserve regarding whether charter recipients would become Federal Reserve members or have access to Federal Reserve accounts and services, such as direct access to payment systems. If the OCC proposal is finalized, the Federal Reserve would have to closely analyze these issues with respect to any fintech firms that express an interest in moving forward with an application.\n\nWhen Apple launched the iPhone in 2007, who could have predicted that it would net billions from a game like Pokémon Go, which involved no investment, development, or advertising on Apple's part beyond opening its platform to developers? It is still too early to have any confidence that we know which fintech innovations will prove to be the most long-lasting or widely adopted. By the same token, the fintech industry is still figuring out the fundamental questions of the best ways to make the necessary connections to the banking platforms to facilitate consumers' ability to better monitor and manage their financial lives, while providing the level of data security and protection they have come to rely on from their banks.35 Change is surely coming, as financial products and services move onto interconnected platforms. As the sector evolves, it's important that all parties involved pay close attention not only to the technical questions, but to the requisite regulatory, policy, and legal considerations to ensure continued trust and confidence in the financial system.\n\n \n\nI am grateful to Kelvin Chen for his assistance in preparing this text.\n\n1. David Pierce, \"Even Steve Jobs Didn't Predict the iPhone Decade,\" Wired, January 9, 2017, www.wired.com/2017/01/apple-iphone-10th-anniversary/. Return to text\n\n2. Mary Meeker, Internet Trends 2016—Code Conference, June 1, 2016, www.slideshare.net/kleinerperkins/2016-internet-trends-report/109-KPCB_INTERNET_TRENDS_2016_PAGE109Average (slide 109); and Ben Bajarin, \"Apple's Penchant for Consumer Security,\" TechOpinions, April 18, 2016, https://techpinions.com/apples-penchant-for-consumer-security/45122. Return to text\n\n3. See Riley v. California, 134 S. Ct.2473, 2484 (2014), www.supremecourt.gov/opinions/13pdf/13-132_8l9c.pdf. Return to text\n\n4. For instance, the average American now spends nearly an hour a day on Facebook's mobile platforms alone. See, e.g., James B. Stewart, \"Facebook Has 50 Minutes of Your Time Each Day. It Wants More,\" New York Times, May 5, 2016, www.nytimes.com/2016/05/06/business/facebook-bends-the-rules-of-audience-engagement-to-its-advantage.html. This count includes Facebook, Messenger, and Instagram, but not WhatsApp. Return to text\n\n5. See, e.g., Jordan Golson, \"Apple's App Store Now Has over 2 Million Apps,\" The Verge, June 13, 2016, www.theverge.com/2016/6/13/11922926/apple-apps-2-million-wwdc-2016. Return to text\n\n6. See, e.g., Sarah Perez, \"Apple's App Store hits 2M apps, 130B downloads, $50B paid to developers,\" TechCrunch June 13, 2016, https://techcrunch.com/2016/06/13/apples-app-store-hits-2m-apps-130b-downloads-50b-paid-to-developers/. On August 3, 2016, Apple CEO Tim Cook noted on Twitter that the $50 billion figure had been surpassed. Tim Cook, Twitter, Aug. 3, 2016, https://twitter.com/tim_cook/status/760929629226041345 (last accessed April 4, 2017). Return to text\n\n7. In 2015 KPMG estimated that global investment in fintech had risen six-fold in the prior three years. KPMG, \"'Fintech 100'--Announcing the World's Leading Fintech Innovators for 2015,\" December 2015, https://home.kpmg.com/xx/en/home/media/press-releases/2015/12/fintech-announcing-the-world-leading.html. In the lending sector alone, Goldman Sachs estimates that $11 billion of annual profit is at risk of leaving the banking system. Ryan M. Nash and Eric Beardsley, The Future of Finance Part 1: The Rise of the New Shadow Bank (New York: Goldman Sachs, March 3, 2015), www.betandbetter.com/photos_forum/1425585417.pdf. McKinsey & Company estimates that there are over 2,000 fintech startups, which have attracted nearly $23 billion of venture capital and growth equity over the past five years. See Miklos Dietz, Somesh Khanna, Tunde Olanrewaju, and Kausik Rajgopal, \"Cutting Through the Noise around Financial Technology,\" McKinsey & Company, February, 2016, www.mckinsey.com/industries/financial-services/our-insights/cutting-through-the-noise-around-financial-technology. Return to text\n\n8. See Miklos Dietz, Somesh Khanna, Tunde Olanrewaju, and Kausik Rajgopal, \"Cutting Through the Noise around Financial Technology,\" McKinsey & Company, February, 2016, www.mckinsey.com/industries/financial-services/our-insights/cutting-through-the-noise-around-financial-technology. Return to text\n\n9. While Bitcoin is a notable exception, many consumers still rely on connecting their bank accounts with Bitcoin exchanges to convert their fiat currency to virtual currency and vice-versa. Return to text\n\n10. See, e.g., Bryan Yurcan, \"Is a Turning Point Near for Core Systems?\" American Banker, April 20, 2016, www.americanbanker.com/news/is-a-turning-point-near-for-core-systems (noting survey findings that 70 percent of U.S. bankers do not feel that their current processes can quickly adapt to market changes, and that 53 percent of survey respondents identified new products/innovation as the top benefit of investing in new core systems); Tom Groenfeldt, \"Updating, Replacing, Surrounding Core Banking System,\" Forbes, July 21, 2015, www.forbes.com/sites/tomgroenfeldt/2015/07/21/updating-replacing-surrounding-core-banking-system/#2e019cd61282. Return to text\n\n11. See, e.g., 12 CFR §1005.1(b); appendix C to 12 CFR part 1005, comment 2(m)-2 (\"If a consumer furnishes an access device and grants authority to make transfers to a person (such as a family member or co-worker) who exceeds the authority given, the consumer is fully liable for the transfers unless the consumer has notified the financial institution that transfers by that person are no longer authorized.\"); Division of Banking Supervision and Regulation and Division of Consumer and Community Affairs, Board of Governors of the Federal Reserve System, \"Guidance on Managing Outsourcing Risk (PDF),\" December 5, 2013. Return to text\n\n12. See, e.g., Olivia Solon, \"Have You Given Pokémon Go Full Access to Everything in Your Google Account?\" Guardian, July 12, 2016, www.theguardian.com/technology/2016/jul/11/pokemon-go-privacy-security-full-access-google-account. (\"The discovery sparked a wave of fear that playing the game might allow its developers, Niantic Labs, to read and send email, access, edit and delete documents in Google Drive and Google Photos, and access browser and maps histories. In fact, both Google and Niantic Labs, say that 'full access' counterintuitively means nothing of the sort, a claim backed up by independent security researchers. The issue appears to stem from the fact that Niantic Labs uses an outdated version of Google's shared sign-on service.\") Return to text\n\n13. See, e.g., Ben Gilbert, \"Pokémon Go Has Been Downloaded over 500 Million Times,\" Business Insider, September 7, 2016, www.businessinsider.com/pokemon-go-500-million-downloads-2016-9. Return to text\n\n14. See, e.g., Division of Banking Supervision and Regulation and Division of Consumer and Community Affairs, Board of Governors of the Federal Reserve System, \"Guidance on Managing Outsourcing Risk (PDF),\" December 5, 2013. Return to text\n\n15. See, e.g., Citigroup, \"Citi Launches Global API Developer Hub to Enable Open Banking,\" press release, November 10, 2016, www.citigroup.com/citi/news/2016/161110b.htm; BBVA, \"BBVA API Market, the Platform for Financial Innovators,\" press release, May 4, 2016, www.bbva.com/en/news/general/bbva-api-market-platform-financial-innovators/; Mark Boyd, \"Capital One Launches First True Open Banking Platform in U.S., Programmable Web,\" March 11, 2016, www.programmableweb.com/news/capital-one-launches-first-true-open-banking-platform-us/2016/03/11; Penny Crosman, \"Fintech Glasnost: Why U.S. Banks are Opening Up APIs to Outsiders,\" American Banker, July 8, 2015, www.americanbanker.com/news/fintech-glasnost-why-us-banks-are-opening-up-apis-to-outsiders; see also Pymnts.com, \"Mastercard Turns Up the API Volume,\" September 28, 2016, www.pymnts.com/mastercard/2016/mastercard-turns-up-the-api-volume/; Visa Inc., \"Visa Opens its Global Network with Launch of Visa Developer,\" press release, February 4, 2016, www.businesswire.com/news/home/20160204006175/en/Visa-Opens-Global-Network-Launch-Visa-Developer. Indeed, over five years ago, French bank Credit Agricole used open APIs to launch an app store of its own. The bank even connects its customers with developers, using message boards so that customers (or even other banks) can post ideas for developers to build. See, e.g., Karen Epper Hoffman, \"Open API for Bank Apps: Can Credit Agricole's Model Work Here?\" American Banker, July 29, 2013; CA Store, www.creditagricolestore.fr/catalogue-d-applications.html (last visited April 4, 2017) (as of April 2017, the site features 47 apps and 62 ideas); Mary Wisniewski, \"Will Banks Become App Stores? This De Novo Wants To,\" American Banker, February 18, 2016, www.americanbanker.com/news/will-banks-become-app-stores-this-de-novo-wants-to. Return to text\n\n16. The Financial Times reported that Uber will invest half a billion dollars into developing its own mapping software as it continues its push into driverless cars, thereby reducing its reliance on Google Maps. Leslie Hook, \"Uber to Pour $500m into Global Mapping Project,\" Financial Times, July 31, 2016, www.ft.com/cms/s/0%2Fe0dfa45e-5522-11e6-befd-2fc0c26b3c60.html?ft_site=falcon&desktop=true#axzz4G0M5oyu8. Return to text\n\n17. For example, one major data aggregator reports that about 70 percent of the data it collects from over 15,000 sources is collected via \"structured feeds\" under contractual agreements with financial institutions. See Envestnet, Inc., 2016 Annual Report, at 28, March 24, 2016. Return to text\n\n18. See, e.g., 12 USC §§ 1861-67; Division of Banking Supervision and Regulation and Division of Consumer and Community Affairs Federal Reserve System, \"Guidance on Managing Outsourcing Risk (PDF),\" December 5, 2013; Steven Boms, \"Yodlee Response to Consumer Financial Protection Bureau Request for Information Regarding Consumer Access to Financial Records,\" Docket No. CFPB 2016-0048, February 21, 2017. (\"Yodlee . . . has complied with hundreds of bank audits and with examinations by the Office of the Comptroller of the Currency throughout its history.\") Return to text\n\n19. See, e.g., \"Finicity and Wells Fargo Ink Data Exchange Deal,\" press release, April 4, 2017, www.finicity.com/press-release-finicity-wells-fargo-ink-data-exchange-deal/; Wells Fargo & Co., \"Intuit Signs New Data-Exchange Agreement with Wells Fargo,\" press release, February 3, 2017, www.wellsfargo.com/about/press/2017/intuit-agreement_0203/; Intuit, \"Chase, Intuit to Give Customers Greater Control of Their Information,\" press release, January 25, 2017, www.intuit.com/company/press-room/press-releases/2017/Chase-Intuit-to-Give-Customers-Greater-Control-of-Their-Information/; Wells Fargo & Co., \"Wells Fargo, Xero Agree on New Data-Exchange Method,\" press release, June 7, 2016, www.wellsfargo.com/about/press/2016/new-dataexchange-method_0607/; Silicon Valley Bank, \"Xero and Silicon Valley Bank Partner to Offer Innovative Companies Next-Generation Financial Management,\" press release, July 16, 2014, www.svb.com/News/Company-News/Xero-and-Silicon-Valley-Bank-Partner-to-Offer-Innovative-Companies-Next-Generation-Financial-Management/. Return to text\n\n20. See, e.g., Center for Financial Services Innovation, \"Consumer Data Sharing Principles: A Brief on the Framework for Industry-Wide Collaboration,\" October 20, 2016. Indeed, many of the developers that make use of the bank data obtained by data aggregators are actually other banks. Steven Boms, \"Yodlee Response to Consumer Financial Protection Bureau Request for Information Regarding Consumer Access to Financial Records,\" Docket No. CFPB 2016-0048, February 21, 2017. (\"Over our almost two-decade history, Yodlee has built a client base that includes 12 of the 20 largest banks in the United States and the largest banks in more than 20 countries.\") Return to text\n\n21. See, e.g., Envestnet, Inc., 2016 Annual Report, March 24, 2016. (\"[O]ne or more of our current customers could decide to limit or block our access to the data feeds we currently have in place with these customers due to factors outside of our control such as more burdensome regulation of our or our customers' industry, increased compliance requirements or changes in business strategy. If the sources from which we obtain information that is important to our solutions limit or restrict our ability to access or use such information, we may be required to attempt to obtain the information, if at all, through end user-permissioned data scraping or other means that could be more costly and time-consuming, and less effective or efficient. . . . The legal environment surrounding data scraping and similar means of obtaining access to information on third-party websites is not completely clear and is evolving, and one or more third parties could assert claims against us seeking damages or to prevent us from accessing information in that manner.\") Return to text\n\n22. According to one banking trade organization, \"[t]his is a rich reward for a single hack, either of an aggregated database of personally identifiable information or of a single consumer's multiple accounts, makes data aggregators an attractive target for criminals. [Hackers would] obtain the key not to just a single room, but the key ring with keys to all the rooms.\" The Clearing House, \"Comment Letter to Bureau-2016-0048 Request for Information Regarding Consumer Access to Financial Records (PDF),\" February 21, 2017. Return to text\n\n23. See, e.g, \"Personal Capital Terms of Use\" (last updated February 22, 2017), www.personalcapital.com/content/terms-of-use/ (last visited April 16, 2017). (\"TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, THE LIABILITY OF PERSONAL CAPITAL, ITS AFFILIATES, LICENSORS AND AGENTS TO YOU SHALL NOT EXCEED ONE HUNDRED U.S. DOLLARS ($100).\") Further, Personal Capital requires that consumers submit to pre-dispute arbitration agreements and waive any rights to pursue relief in a class action proceeding as part of its terms of use. This would mean that if a data breach were to occur, each affected consumer would have to seek relief on his own, with a maximum possible recovery of $100. In addition, Personal Capital's terms and conditions specify that the arbitrator can require that the consumer pay Personal Capital's legal fees, if Personal Capital is to prevail. Return to text\n\n24. When the iPhone first launched, for instance, one phone provider paid a premium for exclusive access to the smartphone. This meant that, for several years, consumers that wanted the iPhone also had to enter relationships with the only Internet service provider platform that offered the phone. See, e.g., Saul Hansell, \"Why AT&T Wants to Keep the iPhone Away from Verizon,\" New York Times, April 22, 2009, https://bits.blogs.nytimes.com/2009/04/22/why-att-wants-to-keep-the-iphone-away-from-verizon/ (\"AT&T is paying Apple an unusually high subsidy on top of the $199 and $299 paid by iPhone buyers. But it appears to be getting quite a return on that investment.\") At the same time, Apple has used its own iPhone platform to affect the development of products further up the stack. While much of the iPhone is an open platform for third-party developers, developers do not have access to the iPhone's secure element and Near Field Communication (NFC) antenna--key components of digital wallet technologies. This means that Apple Pay is the only \"tap-to-pay\" NFC digital wallet available for iPhones--and that Apple Pay competitors, like Android Pay and Samsung Pay, are unable to access 40 percent of the smartphones in the United States. See, e.g., Philip Elmer-DeWitt, \"About Apple's 40% Share of the U.S. Smartphone Market,\" Fortune, February 11, 2016, http://fortune.com/2016/02/11/apple-iphone-ios-share/. When a group of Australia's largest banks recently petitioned the country's antitrust authority to allow them to band together to require Apple to unlock access to the NFC antenna, for use by their digital wallets, their request was denied. See, e.g., Simon Sharwood, \"Banking Group Denied Access to iPhones' NFC Chips for alt.Apple.Pay,\" Register, April 3, 2017, www.theregister.co.uk/2017/04/03/banking_group_denied_access_to_iphones_nfc_chips_for_altapplepay/. Return to text\n\n25. See, e.g., Chance Miller, Apple Maps Now Used 3x as Often as Google Maps on iOS, Serving 5B Requests per Week, 9to5Mac, December 7, 2015, https://9to5mac.com/2015/12/07/apple-maps-usage-numbers/. Return to text\n\n26. For example, small business lender Kabbage, Inc. has entered agreements with large banks, where Kabbage licenses its data analysis-heavy customer acquisition platform to banking partners who then go on to originate, fund, and service the underlying loans. See, e.g., Kabbage Inc., \"Kabbage and Santander UK Partner to Accelerate SMB Growth,\" press release, April 3, 2016, www.kabbage.com/blog/kabbage-santander-uk-partner-accelerate-smb-growth/. Return to text\n\n27. UK Competition & Markets Authority, \"CMA Paves the Way for Open Banking Revolution,\" press release, August 9, 2016. (\"[O]lder and larger banks do not have to compete hard enough for customers' business, and smaller and newer banks find it difficult to grow. This means that many people are paying more than they should and are not benefiting from new services. To tackle these problems, the CMA is implementing a wide-reaching package of reforms. Central to the CMA's remedies are measures to ensure that customers benefit from technological advances and that new entrants and smaller providers are able to compete more fairly.\"); UK Competition & Markets Authority, \"Retail Banking Market Investigation: Final Report (PDF),\" August 9, 2016. Return to text\n\n28. The nine banks include the five largest banks in Great Britain (Lloyd's Banking Group, Royal Bank of Scotland, HSBC Group, Barclays, and Santander UK plc); three leading banks in Northern Ireland (Allied Irish Bank, Bank of Ireland, and Danske Bank) and the largest UK building society, Nationwide Building Society. Return to text\n\n29. Directive (EU) 2015/2366 of the European Parliament and of the Council, November 25, 2015, http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A32015L2366 (last visited Feb. 1, 2017). Return to text\n\n30. Specifically, Payment Initiation Service Providers (PISPs) initiate payment orders at the request of a user with respect to funds held in another entity's bank account; Account Information Service Providers (AISPs) are online services that consolidate information, with consumers' consent, from those consumers' accounts at other entities. Return to text\n\n31. With limited exceptions, such as for de minimis transactions. Return to text\n\n32. Richard Cordray, \"Prepared Remarks of CFPB Director Richard Cordray\" at the Lendit USA Conference, March 6, 2017; Richard Cordray, \"Prepared Remarks of CFPB Director Richard Cordray\" at Money 20/20, October 23, 2016; Consumer Financial Protection Bureau, \"Request for Information Regarding Consumer Access to Financial Records,\" Federal Register, November 22, 2016. Return to text\n\n33. See, e.g., Lael Brainard, \"The Opportunities and Challenges of Fintech\" at the Conference on Financial Innovation at the Board of Governors of the Federal Reserve System, December 2, 2016. Return to text\n\n34. See Office of the Comptroller of the Currency, \"Exploring Special Purpose National Bank Charters for Fintech Companies (PDF),\" December 2016. Return to text\n\n35. See, e.g., Jennifer Booton, \"Apple Will Make $3 Billion Playing Pokémon Go,\" MarketWatch, July 21, 2016, www.marketwatch.com/story/apple-stands-to-make-billions-from-pokemon-go-2016-07-20 (citing report by analyst Lauren Martin). Return to text"
    },
    {
        "title": "Brief Remarks",
        "date": "April 20, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170420a.htm",
        "content": "April 20, 2017\n\nGovernor Jerome H. Powell\n\nat The Global Finance Forum, Washington, D.C.\n\nThank you for inviting me to speak here today.1 I will begin by looking back at the global financial crisis and the great recession, which were arriving on the horizon at about this time 10 years ago. For the United States and many other countries, this would turn out to be the most painful economic crisis since the Great Depression. The fact that we had a severe recession but not another depression is a tribute to the aggressive response of those who were in a position to act at that time.2\n\nIn the event, the financial system avoided collapse but incurred severe damage and proved incapable, for a time, of performing its key functions. That was true of the largest investment and commercial banks, several of which either failed or required taxpayer support to survive. It was also true of the many pieces of the financial market infrastructure whose structural weaknesses contributed to the crisis, such as the triparty repurchase agreement (repo) market, the over-the-counter derivative market, and prime money market funds.\n\nThe financial turmoil caused heavy damage to the real economy. Payroll employment declined by almost 9 million; over 7 million people lost their homes.3 Many young people entered a terrible job market; research shows that this may adversely affect their careers for many years. Many experienced workers who lost their jobs may suffer permanently lower income prospects.4\n\nThe nation faced two big tasks after the crisis. We had to get the economy growing again so people could get back to work and rebuild their financial lives. And we had to return the financial system to good health and address the many structural weaknesses that had become apparent.\n\nToday, the first of those tasks is well along. We have gone eight years without a subsequent recession--one of the longest recoveries on record. Employment is now almost 7 million jobs higher than its pre-crisis peak, with all of the net gains coming from the private sector. And with unemployment at 4.5 percent, we are at or close to full employment.\n\nBut all is not well. Although job growth has been strong, gross domestic product has increased only about 2 percent annually since the crisis, held down by the weakest sustained period of labor productivity growth since World War II. Labor productivity--the increase in output per hour--has increased only 1/2 percent per year since 2011, about a quarter of its post-war average. The productivity slowdown has profound implications for our national well-being. This slowdown is a worldwide phenomenon, so it is likely that there are global forces at work. The slowdown has been associated with weak investment and a decline in output gains from technological innovation.\n\nWe need a national focus on increasing the sustainable growth rate of our economy.5 That means investing in our workforce to give them the skills and aptitudes they need to compete in the global economy. It means policies that reward work, and policies that support investment and research. For the most part, these policies are not in the purview of the Federal Reserve.\n\nWhat about the second goal? As with the economy, we have made great progress toward our goals. Today, our financial system is without a doubt far stronger than it was before the crisis. The largest financial institutions now hold much higher levels of higher-quality capital. They hold higher levels of liquidity as well and are much less reliant on runnable short-term funding. They are subject to rigorous, forward-looking capital stress tests that recognize the dynamic nature of financial risks. And they have submitted several rounds of resolution plans that are helping to ensure that they could be safely reorganized should all these other safeguards prove insufficient.\n\nOur financial market infrastructures are also much stronger. The amount of intraday credit extended in the triparty repo market has been drastically reduced. Last year, the Securities and Exchange Commission implemented reforms that address weaknesses in the structure of prime money funds. And about 75 percent of interest rate and credit default swaps are now centrally cleared, which allows for greater transparency and more consistent risk management.6 While the move to central clearing has made the system safer, we need to make sure that the central counterparties have the resources and risk-management practices to withstand plausible but severe shocks.7\n\nMany of the statutory provisions and regulations put in place to effect these changes were novel; it is not likely that we would have gotten everything exactly right on the first attempt. This is a good time to step back and ask what changes have worked and where adjustments should be made. Indeed, along with the other financial regulatory agencies, the Federal Reserve is contributing to just such an exercise by the Treasury Department. As I share some of my views on these issues, I should emphasize that I speak for myself and not for my Board colleagues or for the new colleagues who will soon join us.\n\nA few themes can guide us in this next phase. First, after years of raising capital and liquidity standards, and of stress tests and living wills, our financial system is much stronger now. We should protect these core reforms and avoid a return to the highly vulnerable system that existed before the crisis. Second, in too many cases new regulation has been inappropriately applied to small and medium-sized institutions. We need to go back and broadly raise thresholds of applicability and look for other ways to reduce burden on smaller firms. Third, the new rule book is excessively complex. We need to look for ways to simplify the rules so that they support our goals but also improve the efficiency of regulation. For example, we need to allow boards of directors and management to spend a smaller portion of their time on technical compliance exercises and more time focusing on the activities that support sustainable economic growth. Fourth, we need to continue to strive to provide an appropriate level of transparency to supervised firms and the public regarding our expectations.\n\nSome aspects of the new regulatory program are proving unnecessarily burdensome and should be better tailored to meet our objectives. Some provisions may not be needed at all given the broad scope of what we have put in place. I support adjustments designed to enhance the efficiency and effectiveness of regulation without sacrificing safety and soundness or undermining macroprudential goals.\n\nOne example where some adjustments are warranted is our supervisory relationship with the boards of directors of banking firms. After the crisis, there was a broad increase in supervisory expectations for these boards. But it is important to acknowledge that the board's role is one of oversight, not management. We need to ensure that directors are not distracted from conducting their key functions by an overly detailed checklist of supervisory process requirements. Rather, boards of directors need to be able to focus on setting the overall strategic direction of the firm, while overseeing and holding senior management accountable for operating the business profitably, but also safely, soundly, and in compliance with applicable laws. We are currently reassessing whether our supervisory expectations for boards need to change to ensure that these principles, and not an ever-increasing checklist, are the basis of our supervisory work related to boards.\n\nI am sure that there are other areas where laws, regulations, and supervisory practices could be adjusted in a way that preserves the gains in safety and soundness but helps financial institutions devote as much of their resources as possible to supporting economic growth. I look forward to our discussion.\n\n1. The views I express here are my own and not those of the Federal Reserve. Return to text\n\n2. Ben S. Bernanke, The Courage to Act: A Memoir of a Crisis and Its Aftermath (New York: Norton, 2015). Return to text\n\n3. Source: CoreLogic, completed foreclosures. Return to text\n\n4. See, for example, Lisa B. Kahn, \"The Long-Term Labor Market Consequences of Graduating from College in a Bad Economy,\" Labour Economics 17(2) (April 2010): 303-16. Return to text\n\n5. Jerome H. Powell, \"Recent Economic Developments and Longer-Run Challenges\" (speech delivered at the Economic Club of Indiana, Indianapolis, November 29, 2016). Return to text\n\n6. Timothy Massad, \"Remarks before the 2016 P.R.I.M.E. Finance Annual Conference\" (The Hague, the Netherlands, January 25, 2016). Return to text\n\n7. The Alternative Reference Rates Committee is working to strengthen another key segment of the financial infrastructure. The Committee will select its preferred alternative to U.S. dollar London Interbank Offered Rate (or, LIBOR) and is expected to complete its plans to promote the use of this rate this year. Return to text"
    },
    {
        "title": "International Effects of Recent Policy Tightening",
        "date": "April 19, 2017",
        "speaker": "Vice Chairman Stanley Fischer",
        "url": "https://www.federalreserve.gov/newsevents/speech/fischer20170419a.htm",
        "content": "April 19, 2017\n\nVice Chairman Stanley Fischer\n\nAt The IBRN-IMF conference: The Transmission of Macroprudential and Monetary Policies Across Borders, Washington, D.C.\n\nI appreciate your invitation to participate in this afternoon's panel discussion. In my remarks, I will discuss how U.S. monetary policy actions affect our foreign trading partners, with particular focus on how foreign economies have responded to the Federal Open Market Committee's (FOMC) ongoing normalization of policy rates.1\n\nSpillovers from the Fed's Unconventional Policies\nExtensive empirical research on spillovers--including by Federal Reserve and International Monetary Fund (IMF) staff members--indicates that spillovers from the actions of major central banks occur through several important channels.2 While the exchange rate is a key channel of transmission and gets a great deal of attention in the public debate about monetary spillovers, it is not the only channel. U.S. monetary policy also affects foreign economies by influencing U.S. domestic demand and by affecting global financial conditions.\n\nMy reading of the evidence is that the Fed's highly accommodative monetary policy during the Global Financial Crisis and its aftermath probably raised foreign gross domestic product (GDP) overall.3 While U.S. monetary easing caused the dollar to depreciate, which reduced foreign GDP by shifting demand toward cheaper U.S. goods, foreign economies benefited from a stronger expansion in U.S. domestic demand. Moreover, U.S. monetary easing also stimulated foreign GDP by depressing foreign bond yields and raising the prices of risky assets.\n\nOf course, there were considerable differences in how foreign economies were affected by the Fed's policies. Because the advanced foreign economies (AFEs) also experienced slow growth after the financial crisis, their central banks adopted similar policies. By contrast, the Fed's accommodative policies put further upward pressure on asset prices and currencies in some emerging market economies (EMEs) that were already experiencing rapid output growth. Thus, EME central banks had to navigate between tightening policy more--and hurting exports through a bigger exchange rate appreciation--and maintaining an accommodative stance closer to the Fed's, but with a higher risk of overheating.4 These tradeoffs faced by EME central banks underscore some of the challenges posed by monetary policy divergence with the United States--a tradeoff with which I am personally very familiar.\n\nSpillovers from Recent Policy Tightening\nMonetary policy divergence remains a familiar theme today, but the focus has obviously shifted to the consequences of tighter U.S. monetary policy for the global economy. Policy divergence is an ongoing concern given that most AFEs and many EMEs have continued to pursue highly accommodative monetary policies that remain appropriate in light of their weaker cyclical positions and subdued levels of underlying inflation. Many observers point to the \"taper tantrum\" in 2013 as illustrating how monetary tightening by the Federal Reserve can potentially have strong contractionary effects on foreign financial conditions. Subsequently, the expectation that a steadily improving U.S. labor market would call for tighter U.S. monetary policy--and hence imply greater monetary divergence with our trading partners--helped drive a sharp appreciation of the dollar between the middle of 2014 and the end of last year that was accompanied by capital outflows from many EMEs.\n\nAgainst this backdrop and the concerns it raises, the reaction in financial markets to the FOMC's decisions to increase the target range for the federal funds rate following its December 2016 and March 2017 meetings--by a cumulative total of 50 basis points--seems benign. The yields on risky foreign bonds, especially in EMEs, have continued to decline to below historical norms, and global stock prices have risen. The dollar has depreciated since mid-December, especially against EMEs, and the EMEs have experienced capital inflows.\n\nIn my view, this favorable reaction partly reflects a view by market participants that the rate hikes are a signal of the FOMC's confidence in the underlying prospects for the U.S. economy that in turn has increased confidence in the global outlook: A strong U.S. economy is a major plus for the global economy. But the main reason for the positive market reaction is that foreign output expansions appear more entrenched, and downside risks to those economies noticeably smaller than in recent years. In Europe, unemployment has fallen steadily; inflation and inflation expectations are moving toward central bank targets; and, while Brexit entails many unknowns, so far it has not resulted in significant financial market disruptions. China's economy also appears to be on a more solid footing, which has helped stabilize the renminbi as well as support growth in other EMEs.\n\nThe IMF staff has taken these developments into account in the April 2017 World Economic Outlook (WEO) and forecasts that world GDP growth will be noticeably higher over the next two years than in 2016--a slight upward revision relative to the October 2016 WEO.5 There may well even be some chance that foreign economies kick into gear enough that U.S. and foreign business conditions become reasonably well aligned, as occurred during the U.S. monetary tightening cycles that began in 1999 and in 2004. In both of those episodes, U.S. exports grew substantially against the backdrop of a brisk expansion in foreign activity and a stable or even slightly depreciating dollar.\n\nOf course, it is hard to predict whether foreign economies continue to strengthen so that the global economy will move more in sync--as I hope--or if a substantial gap will remain between the business cycle positions of the United States and our foreign trading partners. However, even if monetary policy divergence remains substantial, there is good reason to think that spillovers to foreign economies will be manageable. First, I expect that the Fed's removal of accommodation will be driven by a continued expansion of the U.S. economy; thus, foreign economies are likely to benefit from the developments that induce the FOMC to tighten. Second, most foreign central banks should be able to mitigate an undesirable tightening of their own financial conditions through appropriate policy actions. An important lesson of the taper tantrum was that effective communication and actions by major central banks, including the European Central Bank and the Bank of England, were helpful in quickly pushing bond yields down to levels that these central banks regarded as appropriate to their economic situation. Third, many EMEs have markedly improved fundamentals--including smaller current account deficits and more anchored inflation expectations--that should allow them to better withstand the effects of U.S. tightening, though some vulnerabilities remain.\n\nFinally, I expect that U.S. policy normalization will be gradual under likely scenarios for the evolution of output and inflation. A gradual and ongoing removal of accommodation seems likely both to maximize the prospects of a continued expansion in the U.S. economy and to mitigate the risk of undesirable spillovers abroad.\n\n \n\nReferences\n\nAmmer, John, Michiel De Pooter, Christopher Erceg, and Steven Kamin (2016). \"International Spillovers of Monetary Policy,\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System, February 8.\n\nBernanke, Ben S. (2015). \"Federal Reserve Policy in an International Context (PDF),\" Mundell-Fleming lecture presented at the 16th Jacques Polak Annual Research Conference, International Monetary Fund, Washington, November 5.\n\nFischer, Stanley (2016). \"U.S. Monetary Policy from an International Perspective,\" speech delivered at the 20th Annual Conference of the Central Bank of Chile, Santiago, November 11.\n\nFratzscher, Marcel, Marco Lo Duca, and Roland Straub (2013). \"On the International Spillovers of U.S. Quantitative Easing (PDF),\" Working Paper Series 1557. Frankfurt: European Central Bank (June).\n\nInternational Monetary Fund (2017). World Economic Outlook. Washington: IMF, April.\n\nNeely, Christopher J. (2015). \"Unconventional Monetary Policy Had Large International Effects,\" Journal of Banking and Finance, vol. 52 (March), pp. 101-11.\n\nRogers, John H., Chiara Scotti, and Jonathan H. Wright (2014). \"Evaluating Asset-Market Effects of Unconventional Monetary Policy: A Multi-Country Review,\" Economic Policy, vol. 29 (October), pp. 749-99.\n\nSahay, Ratna, Vivek Arora, Thanos Arvanitis, Hamid Faruqee, Papa N'Diaye, Tommaso Mancini-Griffoli, and an IMF Team (2014). \"Emerging Market Volatility: Lessons from the Taper Tantrum (PDF),\" IMF Staff Discussion Note SDN/14/09. Washington: International Monetary Fund, September.\n\n1. The views expressed are mine and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. I am grateful to Chris Erceg for his assistance. Return to text\n\n2. There is a large empirical literature assessing the spillovers from Federal Reserve policy actions, including those from unconventional policies such as large-scale asset purchases--for example, Fratzscher, Lo Duca, and Straub (2013); Rogers, Scotti, and Wright (2014); Neely (2015); and Sahay and others (2014). Return to text\n\n3. My November 11, 2016, speech (Fischer, 2016) provides a more detailed discussion of spillovers from U.S. monetary policy, including some quantitative estimates that draw on the analysis of Ammer and others (2016). Return to text\n\n4. For a more detailed discussion, see Fischer (2016) and Bernanke (2015). Return to text\n\n5. See International Monetary Fund (2017). Return to text"
    },
    {
        "title": "Monetary Policy Expectations and Surprises",
        "date": "April 17, 2017",
        "speaker": "Vice Chairman Stanley Fischer",
        "url": "https://www.federalreserve.gov/newsevents/speech/fischer20170417a.htm",
        "content": "April 17, 2017\n\nVice Chairman Stanley Fischer\n\nAt the Columbia University School of International and Public Affairs, New York, New York\n\nI will address the topic of central bank communications, with a particular emphasis on those times when financial markets and the central bank have different expectations about what a central bank decision will be. Such situations lead to surprises and often to market volatility.\n\nOf course, not all surprises are equal. For one, communications that shift or solidify expectations that are diffuse or not strongly held are less likely to be disruptive than communications that run counter to strongly held market beliefs. Further, there are worse things than surprises. The central bank must provide its views regarding the likely evolution of monetary policy, even when this view is not shared by market participants. A concern for surprising the market should not be a constraint on following or communicating the appropriate path of monetary policy. That said, there are good reasons to avoid unintended surprises in the conduct of policy.1\n\nWhy should central banks avoid surprising financial markets? In recent decades, it has been increasingly acknowledged that monetary policy implementation relies importantly on the management of market expectations.2 In theory, clarity about the central bank's reaction function--that is, how the central bank adjusts the stance of monetary policy in response to changing economic conditions--allows the market to alter financial conditions smoothly. This typically helps meet the bank's policy targets, with the result that the markets are working in alignment with the policymaker's goals. Under this theory, repeated market surprises that raise questions about the central bank's reaction function could threaten to disrupt the relationship between the central bank and the markets, making the central bank's job more difficult in the future.3\n\nHow can the Fed avoid surprising markets? Clear communication of the Federal Open Market Committee's (FOMC's) views on the economic outlook and the likely evolution of policy is essential in managing the market's expectations. The Committee has a number of communication outlets, including the policy statement, the Chair's news conference, and the Summary of Economic Projections (SEP). The SEP in particular has been useful in providing information on policymakers' assessments of the potential growth rate of the economy and r*, the equilibrium real interest rate, both of which help guide the market's expectations of the eventual path of policy.\n\nHowever, avoiding unintended market reactions has not always been easy. The example that immediately comes to mind is the taper tantrum of mid-2013. To recap, over the course of May and June in 2013, the yield on 10-year Treasury securities increased almost 1 percentage point amid increased market discussion of the eventual tapering of Fed asset purchases and some key communications on the topic (figure 1).4 In particular, the 10-year yield rose about 10 basis points after then Chairman Bernanke discussed tapering in public for the first time during the question-and-answer session of his Joint Economic Committee testimony on May 22, commenting that the FOMC could reduce the pace of purchases \"in the next few meetings\" if it saw continued improvement in the labor market that it was confident would be sustained.5 Yields rose even more sharply after the June FOMC meeting, when, during his postmeeting press conference, Chairman Bernanke noted that if the economy evolved as expected, the FOMC anticipated reducing the pace of purchases in the latter part of 2013 and halting purchases altogether by the middle of 2014.6\n\nInformation gathering is an important part of managing market expectations--for the simple reason that you do not know if you are going to surprise the market unless you have a good estimate of what the market is expecting. A remarkable feature of the taper tantrum is that it was a surprise that should not have been a surprise, at least from the perspective of the information the FOMC had at the time.\n\nIn assessing market expectations for policy, the FOMC reviews a variety of market indicators and also draws heavily on the Federal Reserve Bank of New York's Survey of Primary Dealers, whose respondents are the market makers in government securities and the New York Fed's trading counterparties. This survey, conducted about one week prior to each FOMC meeting, gauges primary dealers' expectations about the economy, monetary policy, and financial market developments.7\n\nIn the June 2013 primary dealer survey, the median expectation was for tapering to start in December 2013, with purchases ending in June 2014, a path not significantly different from that laid out by Chairman Bernanke in his postmeeting press conference. Thus, one could view Chairman Bernanke's remarks during his June 2013 press conference as consistent with \"market expectations.\"\n\nWhy did markets react so sharply to the apparent confirmation of the median expectation? One simple possibility is that the median expectation of the primary dealers was not reflective of the median expectation of a wider range of market participants. Respondents to the primary dealer survey are more likely to be Fed watchers and therefore more likely in tune with Fed thinking than the average market participant. For example, as seen in figure 2, a comparison of the June 2013 primary dealer survey with the contemporaneous Blue Chip Economic Indicators survey, which draws from a wider sample of forecasters, reveals that Blue Chip respondents were more likely to expect a later start of tapering and thus more likely to have been surprised by Chairman Bernanke's communications.\n\nIn a related argument, former Federal Reserve Board Governor Jeremy Stein gave an insightful speech in May 2014 addressing how diversity in market expectations could have contributed to the taper tantrum.8 Jeremy pointed out that it is unhelpful to view the \"market\" as a single individual, a theme that has been explored by Hyun Song Shin of the Bank for International Settlements.9 Rather, the market is a collection of agents that can have widely divergent but perhaps strongly held beliefs at the individual level. Jeremy attributes the taper tantrum to the existence of highly leveraged quantitative easing optimists--in other words, individuals who expected the Federal Reserve to continue to accumulate assets much longer than the median expectation and who put little weight on the median market expectation. Once Chairman Bernanke affirmed the median expectation, these optimists had to quickly unwind their trades, with consequent sharp movements in asset prices.\n\nWhere does that leave us? The problem, to quote Jeremy at length, \"is that in some circumstances there are very real limits to what even the most careful and deliberate communications strategy can do to temper market volatility. This is just the nature of the beast when dealing with speculative markets, and to suggest otherwise--to suggest that, say, 'good communication' alone can engineer a completely smooth exit from a period of extraordinary policy accommodation--is to create an unrealistic expectation.\"10\n\nJeremy was speaking about ending the accumulation of assets onto the Fed's balance sheet. As reported in the minutes for the March 2017 meeting, the FOMC is now discussing a different inflection point, the phasing out of reinvestment and the shrinking of the balance sheet.11 Question: How concerned should we be about a repeat of the taper tantrum as we move through this new inflection point?\n\nWe should start answering such a question by recognizing that there is always a chance of some market volatility. Nonetheless, we need to take into account that the New York Fed's Open Market Desk enhanced its information-gathering efforts after and, in part, as a response to the experience of the taper tantrum along two important dimensions. First, in 2014, the Desk augmented its Survey of Primary Dealers with a Survey of Market Participants, going some way to addressing concerns that primary dealers alone were not providing sufficient coverage of market beliefs.12 Second, more recently, questions have been added to the surveys to identify uncertainty about reinvestment policy for each individual survey respondent and not just the dispersion of beliefs about the expected change across respondents.\n\nStarting with the market participant survey, as I noted earlier, one informational constraint that complicated the Fed's understanding of market dynamics around the taper tantrum was the possible divergence of beliefs between the primary dealers, who were surveyed, and the market at large. The differences between the expectations of the primary dealers and those of the panel for the Blue Chip Economic Indicators, shown in figure 2, provide some support for the view that the primary dealers' views may well have differed from those of a wider range of market participants, but it would have been preferable to have a poll of market participants rather than forecasters. Not long after the taper tantrum, in January 2014, the Desk began its separate Survey of Market Participants. The survey panel currently consists of 30 so-called buy-side firms, including hedge funds and asset managers.\n\nTurning now to measures of individual uncertainty, in the April 2013 primary dealer survey, just prior to the taper tantrum, dealers were mostly questioned on their point estimates regarding the timing and conditions under which tapering would commence. Respondents were asked to provide their expectation for the monthly pace of asset purchases after each of several upcoming policy meetings. They were also asked to provide point estimates, or estimates of single particular values, for the quarter and year during which they expected asset purchases in Treasury and agency mortgage-backed securities to be completed. While these questions did provide some notion of the variation in beliefs across respondents, they did not provide much information on how strongly these beliefs were held by the individual respondents, nor on the extent to which their individual beliefs might have been reflected in the size of their market positions and, in particular, the amount of leverage underlying those positions.13\n\nIn contrast, the most recent primary dealer and market participant surveys, conducted prior to the March 2017 FOMC meeting, asked survey participants to indicate their view of their own uncertainty over several different aspects of policy. For example, in addition to their point estimates, participants were asked to indicate the percent chance they assigned to the federal funds rate being at various levels when the FOMC first announces a change to the reinvestment policy. They were also asked to assign probabilities to different dates for the first announced change in reinvestment policy.\n\nWhy is this information important? To go back to Jeremy Stein's argument about the taper tantrum, Jeremy pointed out that market participants' expectations for tapering varied widely, but he conjectured that some of the participants were very certain in their expectations and that it was primarily their reaction that fueled the taper tantrum. When the surveys reported only point estimates, we had a measure of dispersion across market participants, but we were in the dark on how firmly held these beliefs were. By asking participants to provide a distribution of outcomes, we also obtained a measure of how certain they are of a particular outcome.\n\nTo highlight some results from the March 2017 surveys, as shown in figure 3, the primary dealers' median projection for the level of the target federal funds rate when the FOMC first announces a change in its reinvestment policy was reported to be 1.63 percent. The 25th percentile of the distribution across respondents was 1.38 percent, and the 75th percentile was 1.88 percent, suggesting a fairly tight range around the median expectation. The reported range was even tighter for the market participants around a median projection of 1.63 percent.\n\nHowever, it would be a mistake to infer from the narrowness of these ranges a firmness in expectations. As shown in figure 4, when respondents of each survey were asked to indicate the percent chance assigned to different fed funds target levels when the change in policy is announced, the average of all of their reported distributions was wide and flat. The primary dealer survey places roughly equal weight on rates between 1.26 and 2.00 percent. In the underlying nonpublic data for the individual responses, the reported distributions were somewhat narrower but still reflected significant uncertainty, with no primary dealer placing more than 50 percent probability on any particular target range. Like the dealers, the market participants also report wide individual distributions of beliefs.\n\nLikewise, when primary dealers were asked about the timing of the announced change in reinvestment policy, the average of their responses was a relatively flat distribution of possible dates, with almost equal probability on the announcement occurring in the fourth quarter of 2017, the first two quarters of 2018, or the second half of 2018 (figure 5). Again, the individual distributions were narrower but still showed a significant amount of uncertainty. Highlighting the usefulness of also surveying market participants, expectations in the market survey are distinctly shifted toward an early announcement date relative to the expectations of the primary dealers.\n\nThe surveys reveal that while beliefs are dispersed across participants, importantly individual survey participants are also significantly uncertain--in other words, any given participant does not appear to have firmly decided on the likely path of policy. The general point is that while we often measure and report differences in views across individuals, the uncertainty that individuals feel internally is also relevant. Recent survey results that show that market participants assign a positive probability to a wide range of outcomes also suggest that the factors that exacerbated the taper tantrum--dispersed but firmly held beliefs--may be less pronounced in current circumstances than they were at the time of the taper tantrum.\n\nThe market reaction to the release of the minutes of the March 2017 FOMC meeting supports this interpretation of the interaction of uncertainty and Fed policy communications. The minutes reported that, \"provided that the economy continued to perform about as expected, most participants anticipated that gradual increases in the federal funds rate would continue and judged that a change to the Committee's reinvestment policy would likely be appropriate later this year.\"14 As was shown in figure 5, in the March 2017 surveys, respondents placed the most weight, 71 percent for the primary dealers and 57 percent for the market participants, on an announced change in reinvestment policy not occurring until 2018 at the earliest. Presumably, the April survey will reveal a shift in these distributions.\n\nIt is noteworthy, however, that even though the statement in the minutes of the March FOMC meeting regarding Committee members' expectations for announcing changes in the reinvestment policy was not aligned with market expectations, there was only a muted market reaction.15 Perhaps in part, that is because the market participant survey actually revealed a considerable amount of weight, though not the majority, on an announcement occurring this year. Or it is also possible that the diffuse expectations on timing prior to the release of the minutes were a factor in tamping down market volatility as market participants adjust their expectations.16\n\nMy tentative conclusion from market responses to the limited amount of discussion of the process of reducing the size of our balance sheet that has taken place so far is that we appear less likely to face major market disturbances now than we did in the case of the taper tantrum. But, of course, as we continue to discuss and eventually implement policies to reduce our balance sheet, we will have to continue to monitor market developments and expectations carefully.\n\nI would like to conclude by briefly discussing two issues. First, a question: Can the Fed be too predictable? And, second, I will add a short comment on the SEP, the quarterly Summary of Economic Projections of the participants in the FOMC.\n\nWith regard to whether the Fed can be too predictable, it is hard to argue that predictability in our reaction to economic data could be anything but positive. To reference the beginning of my talk, clarity about the Fed's reaction function allows markets to anticipate Fed actions and smoothly adjust along with the path of policy.\n\nBut there is a circumstance where it might be reasonable to argue that the Fed could be too predictable--in particular, if the path of policy is not appropriately responsive to the incoming economic data and the implications for the economic outlook. Standard monetary policy rules suggest that the policy rate should respond to the level of economic variables such as the output gap and the inflation rate. As unexpected shocks hit the economy, the target level of the federal funds rate should adjust in response to those shocks as the FOMC adjusts the stance of policy to achieve its objectives. Indeed, it is these unexpected economic shocks that give rise to the range of uncertainty around the median federal funds rate projection of FOMC participants, represented through fan charts, which was recently incorporated into the SEP. The Federal Reserve could be too predictable if this type of fundamental uncertainty about the economy does not show through to uncertainty about the monetary policy path, which could imply that the Federal Reserve was not being sufficiently responsive to incoming data bearing on the economic outlook.\n\nLet me conclude with a few words on the SEP results as portrayed in the dot plots. The SEP is a highly useful vehicle for providing information to market participants and others for whom Fed actions are important. But we need to remind ourselves that the SEP data for an individual show that person's judgment of the appropriate path of future fed funds rates and the corresponding paths of other variables for which the SEP includes forecasts.\n\nThus, one may say that the SEP shows the basis from which each participant in the FOMC discussion is likely to start. But the task of moving from that information to an interest rate decision is not simple and requires a great deal of analysis and back-and-forth among FOMC participants at each meeting.\n\n \n\nReferences\n\nBernanke, Ben S. (2004). \"The Logic of Monetary Policy,\" speech delivered at the National Economists Club, Washington, December 2.\n\n-------- (2013a). \"Communication and Monetary Policy,\" speech delivered at the National Economists Club Annual Dinner, Herbert Stein Memorial Lecture, Washington, November 19.\n\n-------- (2013b). \"Statement of Hon. Ben Bernanke, Chairman of the Board of Governors of the Federal Reserve System, Washington, DC (PDF),\" in The Economic Outlook, hearing before the Joint Economic Committee, Congress of the United States, May 22, Senate Hearing 113-62, 113 Cong. Washington: Government Printing Office.\n\n-------- (2013c). \"Transcript of Chairman Bernanke's Press Conference (PDF),\" June 19.\n\nBoard of Governors of the Federal Reserve System (2017). \"Minutes of the Federal Open Market Committee, March 14-15, 2017,\" press release, April 5.\n\nShin, Hyun Song (2017). \"How Much Should We Read into Shifts in Long-Dated Yields?\" speech delivered at the U.S. Monetary Policy Forum, New York, March 3.\n\nSpicer, Jonathan (2017). \"Fed Could Promptly Begin Shedding Bonds This Year: Dudley,\" U.S. News, March 31, http://money.usnews.com/investing/news/articles/2017-03-31/fed-could-begin-trimming-bond-portfolio-this-year-dudley.\n\nStein, Jeremy C. (2014). \"Challenges for Monetary Policy Communication,\" speech delivered at the Money Marketeers of New York University, New York, May 6.\n\nWoodford, Michael (2005). \"Central Bank Communication and Policy Effectiveness (PDF),\" in The Greenspan Era: Lessons for the Future, proceedings of a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., Aug. 25-27. Kansas City, Mo.: Federal Reserve Bank of Kansas City, pp. 399-474.\n\n1. I am grateful to Joseph Gruber and Don Kim of the Federal Reserve Board for their assistance. The views expressed are mine and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. Bernanke (2004, 2013a) and Woodford (2005) underscore how central bank efforts to shape market expectations can enhance policy effectiveness. The critical role of market expectations in determining asset prices and reactions to policy changes has long been recognized; it is the explicit recognition of this link in formal models and the analysis of policy that is the recent major achievement. Return to text\n\n3. Historically, there have been times when central banks have preferred to surprise markets--most notably, when changing the value of exchange rate pegs during the era of fixed exchanges. Indicating that a change in the peg was coming would invite an immediate run on the currency, at a significant cost to the central bank's foreign reserves--even in economies with extensive capital controls. Return to text\n\n4. Also notably, Eurodollar futures rates and OIS (overnight index swap) forward rates for intermediate horizons rose sharply, likely in part because some investors who were surprised by the tapering news also revised their expectations about the path of the policy rate. Return to text\n\n5. See Bernanke (2013b), p. 11. Return to text\n\n6. See Bernanke (2013c). Return to text\n\n7. The responses to the survey are received by the Federal Reserve Bank of New York's Markets Group typically by the penultimate Monday before the FOMC meeting. At the time of the taper tantrum, there were 21 primary dealer participants. Currently, there are 23 primary dealers. Past survey results can be found on the Federal Reserve Bank of New York's website at https://www.newyorkfed.org/markets/primarydealer_survey_questions.html. Return to text\n\n8. See Stein (2014). Return to text\n\n9. For a recent example, see Shin (2017). Shin suggests using caution when extrapolating \"market\" expectations from movements in asset prices, pointing to examples where technical factors likely complicate the interaction of market participants' actions relative to their expectations. Return to text\n\n10. See Stein (2014), paragraph 12. Return to text\n\n11. See Board of Governors (2017). Return to text\n\n12. Past market participant surveys can be found on the Federal Reserve Bank of New York's website at https://www.newyorkfed.org/markets/survey_market_participants.html. Return to text\n\n13. Participants in the April 2013 survey were asked for their probability distribution across the total holdings of the System Open Market Account portfolio at year-end 2013 and year-end 2014, providing some, though incomplete, indication of the extent of uncertainty among market participants. Return to text\n\n14. See Board of Governors (2017), p. 3. Return to text\n\n15. The immediate reaction in yields was a slight rise, but the action quickly reversed, and yields ended the afternoon down 3 to 4 basis points. Return to text\n\n16. Of note, Federal Reserve Bank of New York President William Dudley's comments on March 31, mentioning \"sometime later this year or sometime in 2018\" (as quoted in Spicer (2017), paragraph 2)) for the timing of a reinvestment policy change, may also have been a factor behind the muted market reaction to the March FOMC minutes. Return to text"
    },
    {
        "title": "Welcoming Remarks",
        "date": "April 05, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170405a.htm",
        "content": "April 05, 2017\n\nGovernor Jerome H. Powell\n\nAt \"Expanding the Impact: Increasing Capacity and Influence,\" the 2017 Interagency Minority Depository Institution and Community Development Financial Institution Bank National Conference, Los Angeles, California\n\nThank you, Donna. Good morning and welcome to the Federal Reserve. We are honored to have you here today as we host the biennial Interagency Minority Depository Institution (MDI) and Community Development Financial Institution Bank Conference. My colleagues from the Federal Reserve Bank of San Francisco and I are especially honored to be hosting you in Los Angeles. As you probably know, all of the previous Interagency MDI conferences have been held on the East Coast, mainly in Washington, D.C. However, because the largest concentration of minority banks is located here in Southern California, it seemed natural to bring this conference west.\n\nThe Federal Reserve seeks to support MDIs in a number of ways, including our Partnership for Progress, our program for outreach and technical assistance to MDIs. Both the Office of the Comptroller of the Currency and Federal Deposit Insurance Corporation share our goal of preserving and promoting MDIs because you are critical institutions to the communities you serve and the larger U.S. economy. And I note that Congress has also recognized your importance, mandating our respective agencies to help support MDIs. From the perspective of someone who sits on the Federal Open Market Committee, I see many ways that the Federal Reserve can not only support MDIs but is itself also supported by them, and I would like to talk about four of these ways today.\n\nFirst, half of our monetary policy mandate is maximum sustainable employment. That means that we need to be aware of employment trends across all communities in America, not just the top-line averages, since unemployment rates vary significantly across races and geographies. For the first time, last year, we put into our Monetary Policy Report to Congress a section that detailed how post-recession economic gains have been distributed across races.1 You, as MDIs, are committed to understanding and serving these diverse communities. I know that, for example, your small business loans to minority business owners make a difference in the employment rates of minority communities. I thank you for that work, and we will continue to work closely with you to better understand the employment dynamics of underserved and minority communities.\n\nSecond, the Fed is unique as a research institution. We have many economists on staff and therefore have the ability to engage in wide-ranging research that may be useful to your firms and communities. Specific to MDIs, we commissioned two new research papers for this conference to better understand trends in the MDI banking field. In addition, we have two new research papers on MDIs out of the Chicago Fed, one that explores MDI primary markets, and one that looks at MDI small business lending. Tomorrow you'll have an opportunity to hear about and discuss this new research, which will be finalized later this year.\n\nThird, we have a great deal of expertise in community banks, which I know most of you are. Of the 829 state member banks that the Federal Reserve directly supervises, 97 percent are community banks. Therefore, we spend a good deal of time thinking about the issues facing community banks and how to help them be competitive in today's economy. I recognize that as MDIs you share many of the same issues as other community banks, and also some issues that are unique to your sector. We want to work with you to better understand those issues and to help you, where possible, to better serve your communities.\n\nFourth, and last, the Fed has a unique Community Development function that seeks to mobilize ideas, networks, and approaches that address a wide range of community and economic development challenges. One thing that makes our Community Development function unique is that we have deep geographic coverage at the 12 Reserve Banks and their Branch locations. Last year, we combined the resources of our Supervision and Regulation division with those of our Community Development department to staff our Partnership for Progress. By bringing in Community Development, we brought in a new perspective, one that has an explicit focus on low- and moderate-income communities. We know that you serve many of these same individuals and communities, and we are asking our Community Development staff around the country to reach out to you to gather your perspectives on the communities you serve to identify emerging issues of which we should be aware.\n\nIn closing, your institutions are important to the American economy and our understanding of that economy. Therefore, on behalf of the Federal Reserve, I'd like to once again thank you for the work you do in your communities and welcome you to Los Angeles.\n\n1. Board of Governors of the Federal Reserve System, Monetary Policy Report (Washington: Board of Governors, June 21, 2016), www.federalreserve.gov/monetarypolicy/files/20160621_mprfullreport.pdf. Return to text"
    },
    {
        "title": "Departing Thoughts",
        "date": "April 04, 2017",
        "speaker": "Governor Daniel K. Tarullo",
        "url": "https://www.federalreserve.gov/newsevents/speech/tarullo20170404a.htm",
        "content": "April 04, 2017\n\nGovernor Daniel K. Tarullo\n\nAt The Woodrow Wilson School, Princeton University, Princeton, New Jersey\n\nTomorrow is my last day at the Federal Reserve. So in this, my final official speech, it seems appropriate to offer a broad perspective on how financial regulation changed after the crisis. In a moment, I shall offer a few thoughts along these lines. Then I am going to address in some detail the capital requirements we have put in place, including our stress testing program. Eight years at the Federal Reserve has only reinforced my belief that strong capital requirements are central to a safe and stable financial system. It is important for the public to understand why this is so, especially at a moment when there is so much talk of changes to financial regulation.\n\nThe Post-Crisis Regulatory Response\nTo understand the regulatory changes made in response to the 2007 to 2009 financial crisis, it is useful to recall the circumstances with which regulators and legislators were confronted. First, of course, was the sheer magnitude of the impact on the economy, which suffered its worst recession since the Great Depression. Second was the dramatic freezing up of many parts of the financial market, risking successive waves of fire sales that would send asset values plummeting anew. Third was the rapid deterioration of financial firms. Hundreds of smaller banks eventually failed. Bear Stearns, Merrill Lynch, Wachovia, and Countrywide were all close to failure when they were acquired by other financial firms with one or more forms of government support or assistance. American International Group was rescued directly by the government. Lehman Brothers did fail, which set off the most acute phase of the crisis.\n\nThe impact of Lehman's bankruptcy seemed to confirm fears that failure of the largest financial firms risked the complete implosion of the financial system. This, of course, is the too-big-to-fail problem: government officials may feel compelled to save private financial firms with public (that is, taxpayer) capital. Meanwhile, financing markets had nearly frozen up. Hence the extraordinary government actions that followed. Public capital was injected into all of the nation's largest remaining banking firms following congressional enactment of the Troubled Assets Relief Program (TARP). The Federal Reserve and the Department of the Treasury provided financing and backstops, respectively, for money market funds and various forms of securitized assets. The Federal Deposit Insurance Corporation extended its guarantees to bank deposits and the senior debt of banks.\n\nThese and other measures ultimately proved successful in placing a floor under the downward spiral of the financial system. But it was against the backdrop of the need for massive taxpayer-backed assistance--to firms and to markets more generally--that Congress and financial regulators developed responses to the woefully inadequate capital levels of prudentially regulated firms; the systemic consequences of stress at previously non-prudentially regulated firms such as the free-standing investment banks; the widespread failures of risk management within these firms; the parallel failures in supervision of these firms; and the fragility of a financial system that had become characterized by large amounts of runnable short-term funding.\n\nThe first and, to my mind, still the most important element of regulatory strengthening was to increase the amount of capital held by banks to ensure they remained viable financial intermediaries that could finance economic activity. In fact, this effort began as part of the emergency stabilization efforts in early 2009, when we conducted a stress test of the 30 largest banking firms. Where we determined a firm did not have enough capital, we required that it either raise equity in the public markets or take some of the remaining government TARP capital.\n\nThe quick action in assessing the firms, recapitalizing them where needed, and sharing the results of the stress tests with the public stands as one of the turning points in the crisis. From there, we pursued a strategy of gradually strengthening ongoing capital requirements. With a few exceptions, the approach we took from the fall of 2009 onward allowed the banks to use retained earnings to build their capital. We also began development of the first quantitative liquidity regulations to be used in prudential regulation by the U.S. banking agencies. This initiative was, of course, a direct response to the liquidity squeezes encountered during the crisis itself.\n\nThe capital and liquidity efforts were well underway by the time Congress passed the Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank Act) in mid-2010. And Congress was, of course, aware of these efforts. So it is perhaps not surprising that the provisions of the Dodd-Frank Act relating to capital set some important qualitative standards for capital regulation rather than addressing capital levels as such.\n\nA law as long and wide-ranging as the Dodd-Frank Act cannot be reduced to a single key premise or concern, excepting its general focus on financial stability and systemic risk.1 However, with respect to the too-big-to-fail problem, I do think it fair to say--on the basis of both the text itself and its legislative history--that a pivotal choice was to make tighter the prudential regulation of the practices and activities of large banking organizations the presumptive approach to taming too-big-to-fail problems.\n\nThe alternative, much discussed at the time and since, would have been a structural approach. One such approach could have been something like the old Glass-Steagall Act separation of commercial banking from investment banking, which prohibited rather than simply regulated certain activities in different types of firms. Another structural approach would have been outright size limitation resulting in the breakup of some of the largest financial firms. The Dodd-Frank Act does give regulators authority to require divestitures by firms posing risks to financial stability. But these authorities, which contain only the most general of standards, seem intended to be used only if the panoply of other measures in the legislation have failed to contain the too-big-to-fail problem.\n\nThus, at least in the first instance, the Dodd-Frank Act forgoes structural solutions, which might have been cleaner conceptually, but perhaps much more complicated as a practical matter. Instead, it imposes a host of restrictions and requirements. So we have counterparty credit limits, risk retention requirements, incentive compensation constraints, resolution planning requirements, and others. These new statutory measures were meant to, and do, coexist with the capital and liquidity requirements put in place by the banking agencies under their pre-existing authority, as enhanced by the Dodd-Frank Act. An important corollary of this basic approach was that the Dodd-Frank Act requires that many of these regulations be progressively more stringent as applied to firms of greater systemic importance.\n\nFrom this perspective, then, it is not surprising that the Dodd-Frank Act implementation has been a major undertaking, that banks (and sometimes supervisors) feel overwhelmed by the breadth of the resulting compliance effort, and that there is some overlap among some of the regulations. This outcome was, in effect, the price of the largest banks not being subject to a direct structural solution such as breakup.\n\nNone of this is to say that the Dodd-Frank Act got the mix of restrictions just right. To the contrary, it would have been surprising for such a major piece of legislation passed in the immediate aftermath of the crisis to have done so. Usually, a law like the Dodd-Frank Act would have been followed some months later by another law denominated as containing technical corrections, but also usually containing some substantive changes deemed warranted by analysis and experience. But partisan divisions prevented this from happening. And the novelty of many of the forms of regulations adopted by financial regulators, either in implementing the Dodd-Frank Act or under existing authorities, almost assures that some recalibration and reconsiderations will be warranted on the basis of experience.\n\nSo there are clearly some changes that can be made without endangering financial stability. Foremost among these are the various bank size thresholds established in the Dodd-Frank Act or in agency regulations for the application of stricter prudential requirements. For example, as I have said for several years now, we have found that the $50 billion in assets threshold established in the Dodd-Frank Act for banks to be \"systemically important,\" and thus subject to a range of stricter regulations, was set too low. Similarly, the $10 billion asset threshold for banks to conduct their own required stress tests seems too low. And the fact that community banks are subject at all to some of the Dodd-Frank Act rules seems unnecessary to protect safety and soundness, and quite burdensome on the very limited compliance capabilities of these small banks.\n\nBeyond the thresholds issue, though, are there statutory provisions or regulations whose substance could be adjusted to better match economic or compliance costs with financial stability benefits? Again, it would be very surprising if this did not prove to be the case over time. It would also be surprising if we did not find areas in which rules needed to be strengthened in order to achieve financial stability goals, particularly as financial markets change. Generally, I think it is a bit early to judge the balance of costs and benefits of many of the new rules. Some are not yet fully implemented. Firms are still in the process of adjusting to the new rules. And it is still somewhat difficult to determine, for example, what should be considered \"normal\" levels of liquidity or lending, insofar as the pre-crisis period was one in which high levels of both lending and liquidity proved unsustainable. Moreover, given the healthy increases in lending over the last several years and the record levels of commercial bank profits recorded in 2016, it would seem a substantial overreach to claim that the new regulatory system is broadly hamstringing either the banking industry or the economy.\n\nBut there are areas where I think the case for change has become fairly strong. The Volcker rule is one. During the debates on what became the Dodd-Frank Act, former Chairman Paul Volcker offered a fairly straightforward proposal: no insured depository institution or affiliate thereof should be permitted to engage in proprietary trading. It seemed then, and seems now, like an idea that could contribute to the safety and soundness of large financial firms. However, several years of experience have convinced me that there is merit in the contention of many firms that, as it has been drafted and implemented, the Volcker rule is too complicated. Achieving compliance under the current approach would consume too many supervisory, as well as bank, resources relative to the implementation and oversight of other prudential standards. And although the evidence is still more anecdotal than systematic, it may be having a deleterious effect on market making, particularly for some less liquid issues.\n\nThere are three problems--two in the statute and one in the regulatory approach--that I think are related. The first statutory problem is that five different agencies are involved. While the statute does not require a single regulation agreed upon by all five, it understandably calls for coordination and consistency in rulemaking and implementation. The joint or parallel rulemaking among multiple agencies required in various parts of the Dodd-Frank Act has advantages and disadvantages that differ across subject matter. Here, though, the disadvantages seem to dominate. Because almost any effort to distinguish market making from proprietary trading, for example, is impossible to sensibly reduce to a formula or precise rule across all traded instruments, there is ongoing and substantial need for context-specific, data-heavy judgment. Efforts to achieve consistency in treatment across agencies have been both time-consuming and, at times, unsuccessful.\n\nThe second problem is that the approach taken in the regulation in pursuit of consistency was one that essentially contemplated an inquiry into the intent of the bankers making trades to determine, for example, whether the trades were legitimate market making. The agencies knew this approach would be complicated when we adopted it, but it seemed the best way to achieve consistency, at least over time. I think the hope was that, as the application of the rule and understanding of the metrics resulting from it evolved, it would become easier to use objective data to infer subjective intent. This hasn't happened, though. I think we just need to recognize this fact and try something else.\n\nHad there been an obviously better approach, we would have taken it five years ago. My suspicion is that it lies in reviewing and monitoring the trading limits established on all trading desks. As contemplated in the statute, capital requirements might also be used as a complementary tool, such as by requiring progressively higher amounts of capital as trading inventories age--a pretty good indicator that market making is morphing into proprietary trading. Whether a consistent approach can be developed while five agencies continue to be involved is not clear, but it is certainly worth trying.\n\nThe third problem, also in the statute, is that the Volcker rule applies to a much broader group of banks than is necessary to achieve its purpose. As I have said before, the concerns underlying the Volcker rule are simply not an issue at community banks.2 Many regional banks have few or no trading assets of any sort, so proprietary trading is obviously not a concern there either. While the regulatory agencies have tried to tailor the rules so as to avoid burdening these banks, even the process of figuring out that the rules do not constrain them is a compliance cost that should be eliminated. One approach would be to exempt all banks with less than $10 billion in assets and other banks that report less than some nominal amount of trading assets.\n\nCapital Regulation\nLet me now turn to capital. The history of financial regulation over the last several decades is in many respects defined by an increasing emphasis on capital requirements and, specifically, higher minimum ratios based on a more rigorous definition of what constitutes loss-absorbing capital. This tendency can be explained by the fact that capital is a particularly supple prudential tool. As activity and affiliation restrictions on banks have been loosened, and as the integration of traditional lending with capital markets has created new financial products at a rapid pace, capital requirements can provide a buffer against losses from any activities.\n\nNo single measure of capital is sufficient to ensure an adequate buffer however. Simple leverage ratios are a good check on banks becoming too debt dependent, but they encourage more risk-taking, insofar as they impose the same capital charge for every asset, no matter how risky. Standardized risk-based capital ratios implement the intuitively appealing notion that a bank's capital should depend on the riskiness of its assets. But the grouping of individual loans and securities into necessarily broad categories of risk weights (e.g., residential mortgages) can be arbitraged. And a firm holding lots of assets that look very low-risk in normal times can be vulnerable if its total leverage is high during stress periods. Models-based capital requirements can better distinguish among risks to some degree, and they can be made more forward-looking than static leverage or risk-based ratios. But, to the extent that banks' internal models are used, it is difficult to monitor whether banks are intentionally or unintentionally running models that understate their risks. And, of course, they are subject to the usual limitations of models that are based only on past experience and correlations.\n\nIn the post-crisis period, we have continued the previous U.S. practice of using complementary leverage ratio and standardized risk-weighted capital requirements, though at higher levels and with more reliance on common equity as the preferred measure of true capital strength on a going concern basis. We have added a stress test, now based on a supervisory model. We, along with some other jurisdictions that are home to banks of global systemic importance (G-SIBs), have also applied surcharges to the leverage and risk-weighted requirements of such banks. The rationale for this feature of our capital regime is that the potential negative externalities caused by the stress or failure of a G-SIB warrant a higher level of capital.3 Graduated capital surcharges have the additional policy benefit of providing these firms with an incentive to reduce the size and scope of their activities so as to present lesser risk to the financial system.\n\nThe U.S. banking agencies based post-crisis capital requirements on historical loss experiences so as to require banks to have a capital buffer that could absorb losses associated with a significant economic downturn and remain viable financial intermediaries in the eyes of customers, counterparties, and financial markets.4 But our researchers, like those at some other official-sector entities, have been using more formal economic analysis to estimate the level of capital requirements that best balances the benefits associated with reduced risk of financial crisis with the costs of banks funding with capital rather than debt. A recent study by three Federal Reserve Board researchers concludes that the tier 1 capital requirement5 that best achieves this balance is somewhere in the range of 13 percent to 26 percent, depending on reasonable choices made on some key assumptions.6 By this assessment, current requirements for the largest U.S. firms are toward the lower end of this range, even when one takes account of the de facto capital buffers imposed on most firms in connection with the stress test.\n\nThis assessment, when added to our original historically-based approach and the methodology used in developing the capital surcharges, suggests strongly that a reduction in risk-based capital requirements for the U.S. G-SIBs would be ill-advised. In fact, one might conclude that a modest increase in these requirements--putting us a bit further from the bottom of the range--might be indicated. This conclusion is strengthened by the finding that, as bank capital levels fall below the lower end of ranges of the optimal trade-off, the chance of a financial crisis increases significantly, whereas no disproportionate increase in the cost of bank capital occurs as capital levels rise within this range. In other words, in trying to avoid a future financial crisis, it is wise to err somewhat toward the higher end of the range of possible required capital levels for this group of firms.\n\nOn the other hand, it seems reasonably apparent that the increased granularity of the standardized risk-weighted capital requirements put in place after the crisis, while necessary to deal with the range of risks in larger banks, is unduly complicated for community banks. It's not that these requirements have increased appreciably the amount of capital community banks hold, but more that the complexity of compliance and reporting imposes costs that are disproportionately much greater for these banks, given that they have much smaller balance sheets over which to amortize the associated costs. For this reason, I believe we should be moving toward a much simpler capital regime for community banks. The federal banking agencies have already taken some steps in this direction, and they can take a few more. But it may be helpful to amend the law so as to make clear that the agencies would have the flexibility to create a simple capital regime applicable only to community banks.\n\nThere has been much discussion of late of the leverage ratio requirement, from multiple perspectives. There are proposals to make a higher leverage ratio requirement either mandatory or optional for banks, which would then be relieved of risk-weighted capital requirements and many other prudential regulations. There are also those who have questioned the relative cost-benefit tradeoff of the \"enhanced supplementary leverage ratio,\" the 2 percent surcharge applicable to all eight U.S. G-SIBs.\n\nIncreasing the current 4 percent or 5 percent leverage ratio requirement to, say, 10 percent would certainly yield a very well-capitalized set of banks based on the current balance sheets of large banks. But one needs to look at the dynamic effects of such a requirement. Since a higher leverage ratio would also make banks less profitable, and with the constraints of risk-based capital and liquidity requirements lifted, they would be strongly incentivized to change the composition of their balance sheets dramatically, shedding safer and more liquid assets like Treasuries in exchange for riskier but higher-yielding assets.7 After all, with a leverage ratio as the only significant constraint, the regulatory cost of holding a short-term Treasury bill is identical to that of a junk bond. It is this very limitation of a leverage ratio that led to the creation of a complementary risk-based capital requirement in the 1980s. To truly assure the safety and soundness of the financial system, a leverage ratio serving as the sole or dominant form of prudential regulation would probably have to be set considerably higher, at a level where the impact on financial intermediation could be quite substantial.\n\nAs to the impact of the 2 percent enhanced supplementary leverage ratio, our experience leads me to believe that it may be worth changing to account for the quite different business operations of the G-SIBs, particularly those in the custody business. The complementarity of risk-based capital requirements and leverage ratios suggests that there should be some proportionality between the two. This is, of course, the current situation with respect to the standards applicable to non-systemic banks, with the leverage ratio requirement being sensibly set somewhat below the risk based requirement. However, with the additional standards applicable only to the eight systemically important firms, we have a sliding scale of risk-based surcharges but an across-the-board 2 percent leverage ratio surcharge.\n\nIn practical terms, the asymmetry is most significant for the two banks that are dominantly custodial and transactional in nature, rather than lending and trading firms. These banks have had the lowest risk-based surcharges of the eight G-SIBs--currently 1-1/2 percent--but their leverage surcharge is 2 percent. This is especially problematic for their operations, since they prudently reinvest custody customer deposits into safe and liquid assets.\n\nI think it would be sensible for the banking agencies to consider altering the enhanced supplementary leverage ratio requirement so that it would be set with an eye toward the risk-based surcharge. One, but certainly not the only, way to do this would be for the enhanced supplemental leverage ratio to be 1 percent for the firms with a 1 percent to 1-1/2 percent risk-based surcharge, 1-1/2 percent for those with a 2 percent or 2-1/2 percent risk-based surcharge, and 2 percent for those at 3 percent or above.\n\nAn alternative approach to mitigating the distortionary effects of the leverage ratio requirements is to exclude certain \"riskless\" assets from the denominator. Some central bankers around the world have been arguing to exclude central bank reserves from the leverage ratio denominator, on the ground that they are \"safe\" and that including them may make monetary policy harder to execute in a period of unusually large central bank balance sheets. But this would defeat the whole purpose of a leverage ratio, which is to place a cap on total leverage, no matter what the assets on the other side of the balance sheet may be. Cash holdings, for example, are not excluded. This proposal would also create a classic slippery slope risk, which was illustrated during a discussion in which I participated last year. When a central banker raised the idea of excluding reserves, a finance ministry official mused aloud that perhaps sovereign debt should also be excluded.\n\nStress Testing\nRaising the minimum ratios in leverage and risk-based capital standards, requiring that qualifying regulatory capital be truly loss absorbing, and setting higher requirements for the most systemically important banks have been important steps toward the goal of a well-capitalized, and thus safer, financial system. But the stress testing system begun during the crisis, and continually refined since, has been the key innovation in capital regulation and supervision and makes those other measures more effective. The success of the 2009 stress test in restoring confidence in the financial system during the crisis encouraged Congress to make stress testing a required and regular feature of large-firm prudential regulation.\n\nAs the term suggests, stress tests evaluate the capacity of banks to absorb losses that may be associated with major economic adversity and remain not only technically solvent, but also viable financial intermediaries. They are explicitly forward-looking, in that they involve creating unlikely but plausibly severe economic scenarios and then modeling the likely impact of those scenarios on bank assets and earnings. The Federal Reserve has tied the results of stress tests into capital regulation by requiring that bank capital distributions be consistent with maintaining viability in the event the severe scenario were to materialize. That is, dividends and share repurchases cannot bring the bank's capital level below the sum of minimum capital requirements and the amount of losses that could be sustained in the stress event. By looking at the impact of such scenarios on the considerable part of the financial industry accounted for by the larger bank holding companies subject to the requirement, the Federal Reserve's approach gives insight into how substantial economic or financial shocks would affect the financial system and the real economy.\n\nOne virtue of stress testing is that it allows a forward-looking assessment of potential losses that is customized to the portfolios and business models of each bank, while still being consistent across the banks. The Federal Reserve uses independent supervisory models to estimate losses and revenues under stress, both to achieve more comparability across the results for different banks and to preclude any temptation for banks to game their own models. This linkage of stress testing to bank capital requirements has been a good way for regulators to regularize exercise of their broad statutory discretion to set individual capital requirements on a bank-by-bank basis.8 Banks subject to the supervisory stress tests have generally found it to be their binding capital constraint. This is as it should be, insofar as stress testing is meant to help set capital requirements for when they will most be needed--that is, in a serious economic downturn.\n\nFrom the first stress test performed in the winter of 2009, the Federal Reserve has publicly disclosed progressively more information about its supervisory model, the scenarios, and the results. During the crisis, disclosure was intended to help restore confidence in the banking system. Our continuation and expansion of disclosure helps market participants, analysts, academics, and the public better evaluate both the condition of the banks and the rigor of supervisory oversight. It thus serves the dual purpose of market discipline and government agency accountability.\n\nTo serve its important financial stability purpose, stress testing must never become static. As the financial system evolves, with the creation of new products and new correlations among asset price movements, the supervisory model must account for these changes. And as salient risks to the financial system arise, the scenarios must test for these new risks. Apart from the inherent need for adaptation, though, there is one respect in which the Federal Reserve's stress testing program is incomplete and other respects in which it is still in transition from a crisis and post-crisis measure to a permanent and central feature of prudential oversight.\n\nThe significant way in which the stress testing program is incomplete is that it has only limited features with which to assess the condition of participating banks from a macroprudential perspective.9 For example, it generally does not directly take account of second-round effects of stress on the financial system, such as the possible fire sale of assets by financial firms in need of capital or funding, which can further depress asset values of other firms below levels resulting from the initial economic or financial shock.10 These effects are harder to model but very important for a stress test designed to achieve financial stability objectives. The Federal Reserve has begun a research program to try to develop, over the next few years, sound macroprudential elements to incorporate into the stress test alongside some of the countercyclical features that have already been added.\n\nThe transition of stress testing from crisis program to a permanent feature of prudential oversight is unfinished in both Federal Reserve regulations and supervisory practice. The de facto capital requirements produced by the stress test have not been fully integrated into, and reconciled with, other applicable capital rules. Thus, for example, our stress testing program assumes that a firm will continue to make its planned capital distributions during a stress period even though the regulatory capital rules now include a capital conservation buffer to limit such distributions. As to supervision--because the failure of a firm to meet Federal Reserve expectations with respect to its capital risk-management and planning processes can lead to a \"qualitative\" objection to its capital distribution plans--firms (and, at times, perhaps supervisors) have placed more emphasis on these matters than on other issues raised in the supervisory process throughout the year.\n\nIt is probably worth noting at this juncture that one of the features of the stress testing program that some banks have found most troubling is that it culminates in the annual announcements of whether the Federal Reserve objects to each participating bank's capital plan--an event that still garners considerable investor and public attention.11 The potential for embarrassing, public objections to their plans has been disconcerting to some banks, which pointed out that--by design--they were not given the supervisory model for calculating post-stress minimum capital levels and that they might not be able to predict when supervisory concerns with some aspects of their capital planning processes would ripen into a public objection.\n\nIt is certainly the case that this feature of our stress testing program was intended to, and has, focused the minds of banks' senior management on their capital positions and capital planning processes. Motivating management with the stress test was appropriate in a time when capital needed to be built up and when serious shortcomings of pre-crisis risk management at many large U.S. banks needed to be remedied. To be honest, I was stunned in my first few months at the Federal Reserve to find out that many of these banks were unable to aggregate their total exposure to particular counterparties across the many parts of the bank in anything like a reasonable time. Some firms did not have ready access to basic information about the location and value of collateral that they held. As recently as a couple of years ago, we were still seeing some significant problems with data and modelling reliability in banks' internal risk-management processes.\n\nStill, the question was always how long we would need this highly focused set of annual determinations. Several years ago we took a first step to reduce the potential for a quantitative objection by giving any bank whose planned distributions would have brought it below the post-stress minimum capital requirements a short time in which to adjust its plan.12 Last fall, I gave a speech in which I previewed the Board's additional thinking on this subject, following the Board's year-long review of the stress testing program.13 One point was our intention to remove the \"qualitative\" part of the annual stress testing exercise for participating banks with less than $250 billion in assets. We have since done just that, in recognition of the fact that these firms had generally met the supervisory expectations for capital planning and risk management put in place after the crisis. In that speech I also indicated that the Board of Governors was considering a significant revision to our stress testing program that would both integrate it into other applicable capital requirements and begin to reduce the amount of attention directed at the annual announcement of stress test results.\n\nThe proposal for what our staff has called a \"stress capital buffer\" (SCB) would simplify our capital regime by replacing the existing 2.5 percent fixed capital conservation buffer applicable to all banks with a buffer requirement equal to the maximum decline in a firm's common equity ratio under the severely adverse scenario of the stress test.14 This change would, of course, apply only to the roughly 30 banks that participate in the supervisory stress test. This buffer would be recalculated after every year's stress test. Then, through the succeeding year, a bank would have to observe the constraints on capital distributions written into our point-in-time capital requirements if its capital ratio fell below the sum of our minimum capital requirement and the applicable stress capital buffer.\n\nBecause the capital surcharge on the eight G-SIBs already exists as a part of our regular capital rules, the stress capital buffer approach would effectively add the surcharge to our estimates of the amount of capital needed under stress. The surcharges were put in place because the material distress or failure of a G-SIB would have an adverse impact on the financial system as a whole that is far greater than the impact on the financial system of the distress or failure of a non-G-SIB firm.15 Accordingly, G-SIBs should face capital surcharges that compel internalization of those external costs. Because the difference in the external costs of the distress or failure of a G-SIB as compared to a non-G-SIB is likely to be at least as high during times of macroeconomic and financial market stress as during ordinary times, there is no reason why the G-SIB surcharge should not be a part of the post-stress capital regime. A complementary point is that the extra buffer required by the G-SIB surcharge reflects the fact that even the best-conceived annual stress scenarios cannot capture all tail risks in the financial system.16\n\nThe SCB proposal would thus raise somewhat the capital requirements of the eight G-SIBs. This outcome is consistent with analysis of the costs and benefits of capital requirements that I discussed earlier, as well as the rationale for surcharges.17 It is also consistent with the intuition, itself having some analytic backing, that because Congress decided against fundamental structural measures to deal with the too-big-to-fail problem, we should err somewhat on the side of higher capital requirements for these firms. Indeed, there are some academics and others who continue to make a case for even higher capital requirements.\n\nThe inclusion of the surcharges would allow the Federal Reserve to relax some of the conservative assumptions currently made in the stress test without lowering the overall post-stress capital requirements for G-SIBs.18 While conservative assumptions were appropriate coming out of the financial crisis in the early days of the stress test, the SCB and its inclusion of the surcharges would offer an opportunity to update these assumptions without reducing the overall capital requirements for G-SIBs. At the same time, relaxing these assumptions would result in a modest decline in the effective capital requirements of the non-G-SIB participating banks when, as I hope and expect, the Board of Governors moves forward with a rulemaking implementing the SCB idea.19\n\nAdoption of the SCB should remove a bit more of the drama originally associated with the annual announcement of the stress test results. But some would remain, particularly given the possibility of a qualitative objection, even where the supervisory model shows that the firm would have enough capital to remain a viable intermediary in the event something like the severely adverse scenario came to pass. Although the largest firms, unlike those with less than $250 billion in assets, are not yet generally meeting all supervisory expectations around stress testing and capital planning, they have each made substantial progress since 2009. With a few exceptions, the issues observed during recent Comprehensive Capital Analysis and Review (CCAR) cycles are less fundamental than those we were seeing even a few years ago. So I think the time may be coming when the qualitative objection in CCAR should be phased out, and the supervisory examination work around stress testing and capital planning completely moved into the normal, year-round supervisory process, even for the G-SIBs.\n\nCoupled with adoption of the SCB, and the changes in modeling and assumptions associated with that proposal, the elimination of the qualitative objection process would integrate the process and substance of stress testing into the rest of the Federal Reserve's prudential oversight activities. In doing so, it should alleviate the apprehension of banks that they may be subject to objections to their capital plans that are both very public and hard to fully anticipate. The SCB itself would continue the Federal Reserve's efforts to tier prudential requirements even among larger banks, with the G-SIBs having somewhat higher capital requirements commensurate with the damage their failure would inflict on the broader economy, and the regional banks subject to modestly lower requirements than those that effectively apply at present.\n\nHaving just described some good directions for the evolving stress testing regime, let me comment on what I regard as some ill-advised ideas circulating in current policy discussions. One is to detach the stress test from any limitations on capital distributions. This would, in effect, make the stress test simply an informational exercise for supervisors and markets and would, accordingly, presumably be treated less seriously by all concerned. Were we to do so, the very virtues of the stress test that I recounted earlier would be lost, as we would return to using only general, backward-looking risk weights. Of course, it would also reduce capital requirements for the largest banks, which may be one of the motivations for the idea.\n\nI have heard two arguments for this idea. One is that Congress did not require that the stress test be used to limit capital distributions. The other is that it is somehow an unacceptable encroachment on the prerogatives of bank boards of directors to limit their discretion to declare dividends or authorize stock repurchases.\n\nWhile Congress did not explicitly call for stress tests to be used to assure adequate capital levels in larger banks, it did call for increasingly stringent capital measures as the systemic importance of banks increased. Section 165 of the Dodd-Frank Act, which contains the stress testing requirement, is singularly focused on achieving financial stability objectives. Moreover, as I noted earlier, Congress in the 1980s gave the federal banking agencies authority--within their discretion--to set capital requirements individually for specific banks. Again, as noted earlier, using stress tests to do so is not only wholly within that discretion. It is a more regularized way of doing so than an ad hoc judgment on a bank-by-bank basis.\n\nThe argument that bank boards should not be constrained in making capital distributions amounts to an argument that there should be no capital regulation, since even traditional capital regulations limited boards from, say, declaring a dividend that would take the bank below minimum capital levels. And those who make this argument seem to have forgotten that some banks continued to pay dividends in 2007 and 2008 even as their situations became increasingly precarious.\n\nAnother unwise idea would be to give the supervisory model to the banks. Some have argued that it is only fair to do so, because otherwise banks cannot know exactly what their capital requirements will be. For example, if a bank doesn't know with precision what capital charge will effectively be applied to a certain class of home equity loans, it will be handicapped in deciding how many such loans to offer, and on what terms.\n\nIn fact, observation of the stress test results over time has given the banks--as well as analysts and other outside parties--a reasonable idea of the loss functions and other elements of the supervisory model. And the Federal Reserve has increased over time the amount of information it discloses about its stress test models. But there are very good reasons not to publish the model itself. In the first place, remember why this exercise is called a stress test. This is not a case of using a model to set a regulation that stands on its own as a constraint, and then testing to see if there is compliance with the rule. There, the model is essentially the reasoning by which the regulation was set. Even in a case where the test is independent of the regulatory end, risks exist, as we saw in the Volkswagen case, where the company is said to have designed its cars to pass the required emissions test but not to actually achieve the regulatory goal of reduced emissions.\n\nIn the financial area, the dangers of disclosure are much greater. We are trying to evaluate what may happen to a bank's assets under stress. If a bank has the model, it will be able to optimize its balance sheet for the day on which the stress test is to apply by shifting into assets for which relatively lower loss functions apply. But it can then shift those assets back over succeeding days or weeks. Thus, the test will give a misleading picture of the actual vulnerabilities of the firm. In this and other ways, banks would use the models to guide changes in their behavior that do not change the risk they pose to financial stability, but do change the measured results of the stress test. Regulators and academics have long recognized that this type of behavior by banks, known as regulatory capital arbitrage, has been a persistent threat to financial stability. Additionally, giving the firms the model will likely encourage increased correlations in asset holdings among the larger banks--a trend that increases systemic risk, since everyone will be exposed should those asset classes suffer reversals.20\n\nReleasing the computer code used in the model projections would repeat a serious error made a quarter century ago. In 1992, Congress established revised capital standards for the Federal National Mortgage Association (Fannie Mae) and the Federal Home Loan Mortgage Corporation (Freddie Mac), the centerpiece of which was a stress test. However, for reasons that foreshadowed many of the arguments adduced today, all the details of the model were made public and any changes went through the standard notice and comment process. As a result, the government-sponsored enterprises (GSEs) and the public clearly understood the model. With the model in the hands of the GSEs, even a scenario of the severity of the 2006 to 2008 experience produced only mild losses for them. Of course, this result stands in stark contrast to the actual losses, which were sufficient to drive them into conservatorship in September 2008.\n\nIn short, we should recognize that what might appear to be a reasonable transparency measure in publishing the models will in fact result in less protection for the financial system. Thus, if the model were to be published, I would suggest that the minimum required capital levels would need to be materially increased in order to take account of the dynamics I just described.21\n\nThere are a couple of ways to respond to bank concerns without courting these dangers. One would be to add some granularity in the definition of asset categories subject to a specific loss function. At times, some banks have felt that the breadth of certain categories of assets used by the supervisory model means there is a good bit of divergence in the risks associated with assets within the same category. The other would be for the Federal Reserve to publish a set of hypothetical portfolios with the model-implied losses on these portfolios. To that end, staff have been working on \"control portfolio\" level disclosures. These would permit a fairly accurate inference of the expected losses on any given set of assets. At the same time, they would not permit participants to game the models by scrutinizing them for the precise points where they were weakest.22\n\nConclusion\nMuch as I would have liked to touch upon important topics such as the need for credible resolution mechanisms for large banks and for adaptable regulatory processes to respond to new forms of shadow banking, I needed to be selective in drafting this speech. I concentrated on capital regulation because it is the single most important element of prudential financial regulation. The new features of G-SIB surcharges and stress testing help guard against a severe new financial crisis and contain the too-big-to-fail problem. As proposals for regulatory change swirl about, it is crucial that the strong capital regime be maintained, especially as it applies to the most systemically important banks. Neither regulators nor legislators should agree to changes that would effectively weaken that regime, whether directly or indirectly. It would be tragic if the lessons of the financial crisis were forgotten so quickly.\n\n1. See Daniel K. Tarullo (2012), \"Financial Stability Regulation,\" speech delivered at the Distinguished Jurist Series, University of Pennsylvania Law School, Philadelphia, PA, October 10. Return to text\n\n2. See Daniel K. Tarullo (2014), \"A Tiered Approach to Regulation and Supervision of Community Banks,\" speech delivered at the Community Bank Symposium, Chicago, IL November 7. Return to text\n\n3. As implemented in the United States, the surcharge for G-SIBs was calibrated to provide a sufficient amount of additional capital to sufficiently reduce the chances of a G-SIB's failure so that the impact of its failure, discounted by the probability of that failure occurring, would approximately equal the impact of the failure of a large bank holding company that is not a G-SIB, discounted by the somewhat higher probability of its failure (because its capital ratio is lower without a surcharge). For a fuller explanation of this \"expected impact\" approach, see Board of Governors of the Federal Reserve System (2015), \"Calibrating the G-SIB Surcharge (PDF),\" white paper (Washington: Board of Governors of the Federal Reserve System, July 20). Return to text\n\n4. See, for example, Daniel K. Tarullo (2011), \"The Evolution of Capital Regulation,\" speech delivered at The Clearing House Business Meeting and Conference, New York, NY, November 9. Return to text\n\n5. The post-crisis amendments to the banking agencies' capital regulations strengthened the definition of tier 1 capital by having at its core common equity tier 1 capital, the most loss-absorbing form of capital comprised primarily of common equity and related surplus, retained earnings, accumulated other comprehensive income, and limited amounts of common equity tier 1 minority interest. Specifically, tier 1 capital consists of common equity tier 1 capital plus additional tier 1 capital instruments which include qualifying non-cumulative preferred stock, related surplus, and limited additional amounts of tier 1 minority interest. Return to text\n\n6. Simon Firestone, Amy Lorenc and Ben Ranish (2017), \"An Empirical Economic Assessment of the Costs and Benefits of Bank Capital in the U.S. (PDF),\" Finance and Economic Discussion Series 2017-034 (Washington: Board of Governors of the Federal Reserve System). Return to text\n\n7. Some market observers and participants believe that current capital requirements have impinged somewhat on market liquidity for Treasuries. While this claim is hard to prove with existing data, particularly given the difficulties of determining optimal levels of liquidity, it seems reasonable to assume that a very high leverage ratio would seriously constrict market making in Treasuries. Return to text\n\n8. See 12 USC 3907(a) (1). Return to text\n\n9. The stress testing program does have some macroprudential elements, which have been modestly enhanced in recent years. For example, we vary the market shock over time to reduce the incentive for firms to correlate their asset holdings or adopt correlated hedging strategies that are treated relatively favorably under one particular market shock scenario. Return to text\n\n10. See, for example, Fernando Duarte and Thomas M. Eisenbach (2013), \"Fire-Sale Spillovers and Systemic Risk (PDF),\" Federal Reserve Bank of New York Staff Report no. 645 (New York: Federal Reserve Bank of New York, October). Return to text\n\n11. An objection can be forthcoming either because the bank's proposals for capital distributions would leave it with less capital than our modeling determines is necessary were the severely adverse scenario to be realized or because our supervisors have found substantial flaws in a bank's capital planning and capital risk-management processes. Return to text\n\n12. This change did not lead to any reduction in the post-stress capital requirements. It simply gave the firm an opportunity to reduce its planned capital distributions so that they would not lead to a quantitative objection. Return to text\n\n13. For more information on the Federal Reserve's recent review of the Comprehensive Capital Analysis and Review (CCAR) program, see Daniel K. Tarullo (2016), \"Next Steps in the Evolution of Stress Testing,\" speech delivered at the Yale University School of Management Leaders Forum, New Haven, CT, September 26. Return to text\n\n14. The SCB would be floored at 2.5 percent such that if a firm's maximum common equity tier 1 capital ratio decline under the severely adverse scenario is less than 2.5 percent, its SCB would be 2.5 percent. Return to text\n\n15. Board of Governors, \"Calibrating the G-SIB Surcharge.\" Return to text\n\n16. An argument against inclusion of the G-SIB surcharge offered by some is that macroprudential risks facing G-SIBs are lower in the aftermath of a financial crisis. We looked into this argument and concluded that experience actually shows that there is no lower probability of another serious reversal in a year following an initial serious reversal. Return to text\n\n17. Some have argued that incorporating the G-SIB surcharge into post-stress capital expectations is not warranted because doing so would be duplicative of the stress test's global market and counterparty default shocks, which apply only to G-SIBs, and because post-crisis resolvability measures have lessened the likelihood that a G-SIB would fail. The first argument reflects a misunderstanding of CCAR's shocks, which apply only to G-SIBs because G-SIBs are the only firms in CCAR for which these exposures are material and are not designed to capture the adverse impact that a G-SIB failure would have on the financial system as a whole, as the G-SIB surcharge is. The second argument fails to acknowledge that making the largest firms more resolvable and strengthening their resiliency are two separate goals. Return to text\n\n18. This would likely include replacing the supervisory model's current assumption that a firm's balance sheet increases during the severely adverse scenario with a simpler assumption under which a balance sheet and risk-weighted assets remain constant and relaxing the assumption that all of a firm's planned dividends and share repurchases would proceed during CCAR's two-year planning horizon. Instead, given the SCB's continuous constraint on distributions, we would assume a firm will maintain its dividends for one year while reducing its share repurchases. Return to text\n\n19. Based upon data from the 2015 and 2016 CCAR exercises, Federal Reserve staff estimates that the SCB would reduce by at least $10 billion the aggregate amount of common equity tier 1 capital the non-G-SIBs would need to maintain to avoid limitations on capital distributions. Return to text\n\n20. Incentives toward greater asset correlations can be a concern even with a non-disclosed supervisory stress test model, since banks can approximate relevant risk loss functions based on their experience and observation of supervisory results. That is why the stress test and scenarios need to be regularly modified to take account of changing risks and correlations. It is also another reason why development of macroprudential features of the stress test is important. Finally, it is a reason to continue to require firms to conduct their own internal stress tests. Return to text\n\n21. Some have also suggested that the stress tests have caused banks to change the way they allocate credit to various types of borrowers. At one level, this could be said of any risk-based capital standard including the old Basel I standards. However, this criticism fundamentally mischaracterizes the nature and purpose of stress tests, which is to determine whether a bank can remain a going concern and continue to make loans through a severe recession, like the one we experienced from 2007 to 2009. To achieve these goals, the Federal Reserve's projections of stressed losses are highly sensitive to the full range of risks posed by the underlying assets, especially the risk that the asset will perform poorly during a downturn. The standard in stress testing is therefore whether lending practices are sustainable during tough times or not, as was the case in the 2007 to 2009 recession and other credit crises. Return to text\n\n22. The negative effects of such a disclosure regime are exemplified by the now-infamous cutoff of many securitization programs at FICO scores of 620. Because of the transparency of the pre-crisis models used by credit rating agencies, loan originators understood that by getting their riskiest borrowers to improve their credit scores to 620, they could be included in various securitization programs. Return to text"
    },
    {
        "title": "America's Central Bank: The History and Structure of the Federal Reserve",
        "date": "March 28, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170328a.htm",
        "content": "March 28, 2017\n\nGovernor Jerome H. Powell\n\nAt the West Virginia University College of Business and Economics Distinguished Speaker Series, Morgantown, West Virginia\n\nI am delighted to have this opportunity to speak at West Virginia University. Thanks to Brian Cushing for inviting me here today.1\n\nGathered in this part of West Virginia, we are located in the Fifth Federal Reserve District, which stretches down from here to South Carolina and east to the Atlantic Ocean (figure 1). More than 100 years ago, the organizers of the Federal Reserve System divided the country into 12 of these Districts, each with its own Federal Reserve Bank. Together, the Board of Governors in Washington and the 12 Reserve Banks are the key elements of the Federal Reserve System.\n\nToday I will discuss how the Federal Reserve came to have this unique structure. The Fed's organization reflects a long-standing desire in American history to ensure that power over our nation's monetary policy and financial system is not concentrated in a few hands, whether in Washington or in high finance or in any single group or constituency. Rather, Americans have long desired that decisions about these matters be influenced by a diverse set of voices from all parts of the country and the economy. The structure of the Federal Reserve was designed to achieve this broad representation and promote a stronger financial system to build resiliency against the sort of periodic financial crises that had repeatedly damaged the country in the 19th and early 20th centuries. This structure was forged from compromise; the result of that compromise was a vitally needed central bank whose decisions take into account a broad range of perspectives.\n\nBefore the Federal Reserve\nThe question of how to structure our nation's financial system arose in the early years of the republic. In 1791, Congress created an institution known as the Bank of the United States, often considered a forerunner of the Federal Reserve. The Bank was created in part to assist the federal government in its financial transactions, a typical responsibility of central banks at that time. It was also designed to help America's financial system meet the needs of a growing economy--the same purpose behind the founding of the Federal Reserve more than 100 years later. The most famous proponent of the Bank was Alexander Hamilton, who has recently achieved the central banker's dream of being the subject of a hit Broadway musical (figure 2).\n\nCongress gave the Bank of the United States unique powers--its notes were accepted for making payments to the federal government and it was the only bank able to branch across state lines (figure 3). The Bank could affect the ebb and flow of credit around the country.2 People in different regions of the country came to have distinct views about the Bank. Borrowers in the western areas--in those times, the West meant places like Ohio--desired cheap and abundant loans but were also wary of lenders. These borrowers grew opposed to the power of the Bank in the credit market. Northern business interests favored the Bank's contribution to the country's industrial development, but at times disagreed with actions taken by the Bank to constrain credit. Southern agriculturalists viewed the Bank with suspicion but supported its occasional actions to constrain credit to non-agricultural businesses.3 The Bank's private ownership, intended to give it independence from government control, was a source of unpopularity. Ultimately, these disagreements undermined the Bank's political support. After 20 years, Congress chose not to renew the Bank's charter. A second Bank of the United States met a similar fate in 1836 when President Andrew Jackson vetoed a bill to extend its life (figure 4).\n\nThese two short-lived experiments illustrate a theme in American history--of Americans from different regions holding distinct views about the structure and development of the financial system. People in the newer western parts of the country saw themselves as starved of access to credit and viewed higher interest rates in their areas as reflecting the scarcity of funds. Regional interest rate differentials persisted until around the time of World War I and helped shape the attitudes of Americans living in western areas toward the nation's financial system.4\n\nThese regional differences gave rise to a major political movement in the latter part of the 19th century, as western farm borrowers increasingly demanded a reform of the U.S. monetary system. Their chief complaints included the high interest rates they faced as well as the burdens placed on them by deflation that increased the real value of their debts. Indeed, the economy experienced 1 to 2 percent deflation annually in the years leading up to the 1890s. The country's currency was linked to gold, and deflation reflected the growing scarcity of gold relative to the amount of economic activity. The \"free silver\" movement grew in response to these economic forces. Its most famous advocate, William Jennings Bryan, the Democratic presidential nominee in 1896, sought an increase in the money supply--by the coining of silver in addition to gold--as a solution to reversing this deflation (figure 5).5\n\nThe Founding of the Fed\nBy the beginning of the 20th century, the debate about monetary policy and the nation's financial system had been going on for over a century. Increasingly, the shortcomings of the existing system were causing too much harm to ignore. Like a drumbeat, the country experienced one serious financial crisis after another, with major crises in 1839, 1857, 1873, 1893, and finally in 1907.6 These panics paralyzed the financial system and led to deep and extended contractions in the economy.\n\nThese episodes exposed the weakness of our 19th century financial system, which repeatedly failed to supply the money and credit needed to meet the economy's demands. The financial system came under severe stress when the demand for liquidity surged.7 A financial system strained in such a manner is like dry kindling in danger of being exposed to a spark. That spark could come from losses at a well-known bank, from a disappointing harvest, or from mere rumors. In response, depositors or other investors would seek the return of their funds, which would force financial institutions to sell assets quickly to generate the necessary cash (figure 6). That liquidation could lead banks to cut credit and force borrowers to repay debt sooner than expected.\n\nSimply put, the monetary system did not meet the country's needs. It was a system in crisis, boiling over repeatedly, harming the country.\n\nCentral banks are designed in part to help the financial system meet occasional liquidity strains. When demands for liquidity rise, central banks can respond by increasing the supply of money and thus adding liquidity to the system. Central banks have a particularly important role in avoiding or mitigating extreme demands for liquidity during financial crises. They do this by making loans to solvent financial institutions so they can meet their liquidity demands and avoid forced sales of their assets. These ideas about central banks' lending role were developed over the course of the 19th century but not yet implemented in the United States, which at the time remained without a central bank.8 By the beginning of the 20th century, the United States was behind the game.\n\nThe final catalyst leading to the creation of the Federal Reserve was the severe Panic of 1907, which caused inflation-adjusted gross national product to decline by 12 percent, more than two times the decline recorded during the Great Recession of 2007 to 2009.9 After the panic ended, there was a broad sense that reform was needed, although consensus on the exact nature of that reform was elusive. Some called for an institution similar in structure to the Bank of England at the time, with centralized power, owned and operated by the banking system. Some wanted control to be lodged with the federal government in Washington instead. Others proposed that power be distributed to regional bodies with no central or coordinating board. Still others resisted any sort of central bank.10 This debate reflected the many and diverse interests in the United States--farmers, laborers, businessmen, small-town bankers, big-city bankers, technocrats, populists, and more--that experienced different conditions across a large geographic expanse.\n\nThe resulting institution was a compromise, created by the Federal Reserve Act in 1913. The Federal Reserve was not structured to be entirely private in its ownership and operation. It was also not structured to have a single headquarters in Washington or New York with branches across the country, a structure that was proposed but failed to attract enough political support. Instead, a more federated system was created, establishing the Federal Reserve Board in Washington and the 12 Reserve Banks located around the country.\n\nThe Board was the part of the System intended to be most directly accountable to the public (figure 7). The Board is an independent agency within the federal government, and members of the Board--now called Governors--are appointed by the President and confirmed by the Senate.11 Governors serve 14 year terms that expire at 2-year intervals and are not linked to election cycles. The Federal Reserve Board is charged with general oversight of the Reserve Banks.\n\nThe Reserve Banks combine both public and private elements in their makeup and organization (figure 8). Like the Board of Governors, the Reserve Banks operate with the public interest in mind. Commercial banks that are members of the Federal Reserve System are required to purchase stock in their District's Reserve Bank.12 These shares are nontransferable and yield only limited powers and benefits. Dividends are set by federal law. The commercial bank shareholders elect two-thirds of the directors that oversee the Reserve Banks; the Board in Washington appoints the remaining one-third. Only three bankers can serve on a Reserve Bank's board of directors, and only one of those can be from a large commercial bank in the District. The remaining six directors represent the interests of the public. The Federal Reserve System benefits enormously from the insights and support of the boards of directors of the Reserve Banks and their Branches. Directors include prominent private-sector leaders who represent a wide and growing diversity of backgrounds and views about the economy.13\n\nThe federated structure of the Federal Reserve System earned the endorsement of even the populist hero of the late 19th and early 20th centuries, William Jennings Bryan. The compromise created an institution that could address the shortcomings of the American financial system while assuring that control of the Federal Reserve would be shared widely.14 The structure was different from those of the first and second Banks of the United States, and from those of foreign central banks at the time. Congressman Carter Glass, who worked to win passage of the Federal Reserve Act in Congress, called the Federal Reserve's uniquely American design \"an adventure in constructive finance\" (figure 9).15\n\nThe Modern Federal Reserve\nIn the System's early years, the decentralized structure gave the Reserve Banks considerable scope to make independent decisions that applied to their own Districts, which made it difficult to effect policy. For example, one Bank's purchases of securities could be offset by another Bank's sale, given that the market for securities was national in scope. As a result, the Reserve Banks created a committee to coordinate these \"open market operations.\" But in these years, the Reserve Banks were not bound by that committee's decisions and could derail any attempt at coordinated action.\n\nThis decentralization was thought by some to have undermined the Federal Reserve's response to the Great Depression.16 With that experience in mind, the 1935 Banking Act modified the distribution of power within the Federal Reserve System, giving the Board of Governors 7 of the 12 seats on the Federal Open Market Committee (FOMC) (figure 10).17 The other 5 seats are held by the Reserve Banks. The Federal Reserve Bank of New York has a permanent seat, and the other Reserve Banks share the remaining 4 seats on a rotating basis.18 While FOMC members are free to dissent from the majority decision about open market operations, the Reserve Banks are nevertheless required to adhere to that decision in conducting open market operations.\n\nThe structure set out in 1935 has been essentially unchanged to this day and has served the country well. As intended by the framers, the federal nature of the system has ensured a diversity of views and promotes a healthy debate over policy. My strong view is that this institutionalized diversity of thinking is a strength of our System. In my experience, the best outcomes are reached when opposing viewpoints are clearly and strongly presented before decisions are made.\n\nMembers of the Board of Governors and Presidents of the Reserve Banks arrive at their own independent viewpoints about the economy and the appropriate path for monetary policy. Congress has assigned the FOMC the task of achieving stable prices and maximum employment; however, policymakers may disagree on the best way to achieve those goals.19 The System's structure encourages exploration of a diverse range of views and promotes a healthy policy debate.20 In the modern Federal Reserve System, each Reserve Bank has an independent research department, with its own external publications. In addition, while the members of the Board tend to focus on developments in the nation as a whole, the Reserve Bank Presidents bring specialized information about their regional economies to the FOMC discussion. Before each FOMC meeting, Reserve Bank Presidents consult with their staff of economists as well as their boards of directors, business contacts in their Districts, and market experts to develop their independent views of appropriate monetary policy.\n\nThe FOMC works to achieve a consensus policy by blending inputs from the members of the Board of Governors and from the Reserve Bank Presidents under the leadership of its Chair. By tradition, the Chair of the Board has been chosen as the Chair of the FOMC and has had a central role in setting the agenda for the FOMC and developing consensus among the Committee's members. In addition, the Chair is the most visible public face of the Federal Reserve System.\n\nThe Fed is accountable to Congress and the public for its activities and decisions. Historically, the activities of central banks were shrouded in mystery. Montagu Norman, the famously secretive Governor of the Bank of England from 1920 to 1944, reportedly took as his personal motto, \"Never explain, never excuse\" (figure 11).21\n\nIn the modern era, all that has changed, as central banks have come to see transparency both as a requirement of democratic accountability and as a way of supporting the efficacy of their policies. Over recent decades the Fed has significantly augmented its public communications, as have other major central banks. The Chair testifies before Congress twice each year about the U.S. economy and the FOMC's monetary policy in pursuit of its statutory goals of stable prices and maximum employment (figure 12).22 The Federal Reserve Board prepares a Monetary Policy Report to accompany that testimony.23 The Chair also holds press conferences after four FOMC meetings each year. The FOMC releases statements after its meetings that explain the economic outlook and the rationale for its policy decision. Detailed minutes of the Committee's meetings are published three weeks later.24 Since 2007, FOMC participants have submitted quarterly macroeconomic projections that are published in the Summary of Economic Projections.25 In 2012, the FOMC issued a Statement on Longer-Run Goals and Monetary Policy Strategy, which is reaffirmed every January. This statement discusses the Committee's interpretation of its statutory goals of maximum employment and price stability; it indicates that the Committee judges inflation of 2 percent, as measured by the annual change in the price index for personal consumption expenditures, to be most consistent over the longer run with the Federal Reserve's statutory mandate.26 Transcripts of FOMC meetings are released to the public after a delay of about five years.\n\nFederal Reserve Board Governors and Reserve Bank Presidents contribute to the Federal Reserve's transparency with frequent public speeches and other communications. I believe that support for the Federal Reserve as a public institution is sustained by the public expression of our diverse views.27\n\nThese communications with Congress and the public are critical parts of the Federal Reserve's institutional accountability and transparency, and are essential complements to its independence. It is important that Federal Reserve officials regularly demonstrate that the Fed has been appropriately pursuing its mandated goals. Transparency can also make monetary policy more effective by helping to guide the public's expectations and clarify the Committee's policy intentions.\n\nRecent Changes in Federal Reserve System Governance\nIn recent years, the governance of the Federal Reserve System has continued to evolve. The 2010 Dodd-Frank Wall Street Reform and Consumer Protection Act provided that directors representing financial institutions--the class A directors, of which there are three on each Reserve Bank board--may not participate in the appointment of Reserve Bank presidents and first vice presidents. The Federal Reserve Board has long had policies preventing Reserve Bank directors from participating in supervisory matters or in determining the appointment of any Reserve Bank officer whose primary duties involve supervisory matters. These directors continue to provide highly valuable information about developments in their markets, and take part fully in other roles with the other six directors.\n\nAnother aspect of governance involves the better representation of women and minorities in the Federal Reserve System. Indeed, while I have focused my remarks on the history of geographical diversity in the Federal Reserve System, we also strive to have diversity in gender and race both at the Board and at the Reserve Banks. In recent years, the Reserve Banks' boards of directors have made significant progress along these lines. Women now account for 34 percent of the directors, up from 24 percent five years ago. In addition, minorities now account for 29 percent of directors, up from 19 percent five years ago.\n\nConclusion\nThe long history of political discourse in the United States helps explain the Federal Reserve's unique structure, in which the Board of Governors in Washington and the 12 regional Reserve Banks share power over monetary policy (as shown in figure 1). Throughout our history, Americans have questioned the structure and even, at times, the need for a central bank. Current discussions of Fed reforms echo these past debates. But it is important to understand that history in both advanced and emerging economies across the world has consistently demonstrated the need for a central bank, and both the existence and the structure of the Federal Reserve are products of that historical experience. Our structure is fundamentally a compromise, shaped by American history stretching back to the first Bank of the United States and, later, by the lessons of the Great Depression. It is designed to deliver the United States a vitally needed central bank in a country that has had a long-standing aversion to centralized power over monetary and financial affairs. It preserves diverse regional voices while ensuring that policy can be implemented through a cooperative consensus. The balance between national and regional interests is critical to the spirit of the original compromise that created the Federal Reserve, and to its democratic legitimacy. The structure achieves a practical balance that should not be changed lightly, as it continues to serve the country well.\n\n1. My remarks today reflect my own views and not necessarily those of the Board of Governors of the Federal Reserve System or the Federal Open Market Committee. Return to text\n\n2. The Bank of the United States became a net creditor to state banks by holding the notes issued by those banks. When it presented those notes for redemption, it could affect the funding position of state banks and effectively constrain credit in this manner. Return to text\n\n3. See John H. Wood (2005), A History of Central Banking in Great Britain and the United States (New York: Cambridge University Press). Return to text\n\n4. See Lance E. Davis (1965), \"The Investment Market, 1870-1914: The Evolution of a National Market,\" Journal of Economic History, vol. 25 (September), pp. 355-93. Economic historians have debated the extent to which interest rate differentials reflected market segmentation and supply versus demand in each market. Other factors include higher risk premiums, reflecting higher expected default rates in some areas of the country, and varying levels of monopoly power. Return to text\n\n5. For a sense of the regionalism of this debate, believe it or not, The Wonderful Wizard of Oz has been interpreted as an allegory for 19th century regional monetary problems, though there is little evidence about the intentions of its author, L. Frank Baum, in conveying this allegory. Dorothy was from Kansas, a farm state, but after a cyclone, she found herself in a world dominated by gold, with a yellow brick road and the Land of Oz--the abbreviation for an ounce. The story has four witches--from the West, East, North, and South. Remember that the Wicked Witch of the West ultimately met her demise when she melted on contact with water, a symbol for the end of a drought that contributed to the economic hardships of western farmers. But the most powerful change was brought about by Dorothy's shoes, which were originally owned by the Wicked Witch of the East. Importantly, these shoes were silver in the original book, not red as in the movie, symbolizing the power of bimetallism as a solution to western problems. See Hugh Rockoff (1990), \"The 'Wizard of Oz' as a Monetary Allegory,\" Journal of Political Economy, vol. 98 (August), pp. 739-60. Return to text\n\n6. See Andrew J. Jalil (2015), \"A New History of Banking Panics in the United States, 1825-1929: Construction and Implications,\" American Economic Journal: Macroeconomics, vol. 7 (July), pp. 295-330. Return to text\n\n7. Contemporaries blamed these crises on the seasonality in demand for currency and credit related to planting and harvesting of crops in the spring and fall. Modern scholars place more weight on other sources of financial tightness. Some point to poor harvests that depressed net exports, particularly failed cotton harvests. Net exports were an important source of increases in the money supply in this period. In the context of the gold standard, poor money supply growth in the United States triggered certain expectations by international capital market participants that interest rates in the United States would rise relative to the rest of the world. As a result, interest rates on American commercial paper (a key rate affected by international financial conditions) rose following poor harvests, stock and bond prices fell, and deposits flowed out of the New York banking system. Industrial production decreased as well, with a lag. This set of effects created tight financial conditions of the sort that could lead to financial crises. (See Christopher Hanes and Paul W. Rhode (2013), \"Harvests and Financial Crises in Gold Standard America,\" Journal of Economic History, vol. 73 (March), pp. 201-46.) Other scholars focus on business cycle downturns as creating conditions favorable to financial crises, as depositors viewed the downturns as affecting the solvency prospects of their banks, leading to withdrawals and panics. (See Gary Gorton (1988), \"Banking Panics and Business Cycles,\" Oxford Economic Papers, vol. 40 (December), pp. 751-81.) Return to text\n\n8. See Walter Bagehot ([1873] 1897), Lombard Street: A Description of the Money Market (New York: Charles Scribner's Sons). Return to text\n\n9. See Nathan S. Balke and Robert J. Gordon (1989), \"Appendix B: Historical Data,\" in Robert J. Gordon, ed., The American Business Cycle: Continuity and Change (Chicago: University of Chicago Press), pp. 781-850. See also Jon R. Moen and Ellis W. Tallman (2015), \"The Panic of 1907,\" Federal Reserve History. Return to text\n\n10. See Roger Lowenstein (2015), America's Bank: The Epic Struggle to Create the Federal Reserve (New York: Penguin Press); and Allan H. Meltzer (2003), A History of the Federal Reserve, Volume 1: 1913-1951 (Chicago: University of Chicago Press). Return to text\n\n11. As originally enacted, Section 10 of the Federal Reserve Act required that the President, in nominating Board members, \"have due regard to a fair representation of the different commercial, industrial and geographical divisions of the country\" (see Federal Reserve Act, ch. 6, § 10, 38 Stat. 260 (1913), p. 12, www.federalreservehistory.org/Media/Material/Event/10-58). In 1922, this representational requirement was expanded to its current form, which provides, in Section 10(1), that the President \"have due regard to a fair representation of the financial, agricultural, industrial, and commercial interests, and geographical divisions of the country\" (see Federal Reserve Act, 12 U.S.C. § 241 as amended by an act of June 3, 1922 (42 Stat. 620), paragraph on appointment and qualification of members, https://www.federalreserve.gov/aboutthefed/section%2010.htm). In addition, Section 10(1) provides that no two members of the Board may be from the same Reserve Bank District. Return to text\n\n12. All national banks chartered by the Comptroller of the Currency are required to be members of the Federal Reserve System, and state-chartered banks may choose to become members. Return to text\n\n13. Directors are chosen, according to Sections 4(11) and 4(12) of the Federal Reserve Act, \"with due but not exclusive consideration to the interests of agriculture, commerce, industry, services, labor and consumers\" (see Federal Reserve Act, 12 U.S.C. § 302 as amended by an act of Nov. 16, 1977 (91 Stat. 1388), paragraphs on class B and class C directors, https://www.federalreserve.gov/aboutthefed/section4.htm). Return to text\n\n14. Authors Jeremy Atack and Peter Passell write, \"Throughout much of American history there has been a deep and abiding mistrust of bankers and a widespread fear of a 'money monopoly'--a fear that those needing to borrow would be taken advantage of by those able to lend. Such questions had figured prominently in the debates over the fates of the First Bank and Second Bank of the United States, and they played a role in the popular support of free banking legislation. They had also led to the almost universal adoption of usury ceilings on interest rates (typically 6 percent) that were more honored in name than reality. These concerns were the subject of congressional inquiries, the most famous of which were the Pujo hearings into the Money Trust in the wake of the 1907 panic.\" See Jeremy Atack and Peter Passell (1994), A New Economic View of American History: From Colonial Times to 1940, 2nd ed. (New York: Norton), p. 510. See also Milton Friedman and Anna Jacobson Schwartz (1963), A Monetary History of the United States, 1867-1960 (Princeton, N.J.: Princeton University Press), p. 48. Return to text\n\n15. See Carter Glass (1927), An Adventure in Constructive Finance (Garden City, N.Y.: Doubleday, Page). Return to text\n\n16. For a discussion of these issues, see David C. Wheelock (2000), \"National Monetary Policy by Regional Design: The Evolving Role of the Federal Reserve Banks in Federal Reserve System Policy,\" in Jürgen von Hagen and Christopher J. Waller, eds., Regional Aspects of Monetary Policy in Europe (Boston: Kluwer Academic), pp. 241‑74. Return to text\n\n17. The FOMC was created by the Banking Act of 1933 but was restructured in 1935 to include members of the Board of Governors. Return to text\n\n18. The Federal Reserve Bank of New York was made a permanent member of the FOMC in 1942. From 1935 to 1942, it alternated annually with the Federal Reserve Bank of Boston as a member. Return to text\n\n19. For a discussion of the Federal Reserve's dual mandate, see the FOMC's Statement on Longer-Run Goals and Monetary Policy Strategy, which the Committee first issued in January 2012 and reaffirms annually, in note 26. In addition, for a discussion of how the FOMC prepares for its meetings, see Elizabeth A. Duke (2010), \"Come with Me to the FOMC,\" speech delivered at the Money Marketeers of New York University, New York, October 19. Return to text\n\n20. For a discussion of these issues, see Marvin Goodfriend (1999), \"The Role of a Regional Bank in a System of Central Banks,\" Carnegie-Rochester Conference Series on Public Policy, vol. 51 (December), pp. 51-71. Return to text\n\n21. Ben Bernanke, former Chairman of the Federal Reserve Board, referenced the motto in a 2007 speech. See Ben S. Bernanke (2007), \"Federal Reserve Communications,\" speech delivered at the Cato Institute 25th Annual Monetary Conference, Washington, November 14. Return to text\n\n22. The statutory mandate was added in the Federal Reserve Reform Act of 1977. Return to text\n\n23. The Monetary Policy Report is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/mpr_default.htm. Return to text\n\n24. FOMC statements and the minutes of FOMC meetings are available on the Board's website at https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm. Return to text\n\n25. Since 2012, the Summary of Economic Projections (SEP) has included each individual FOMC participant's assessment of appropriate monetary policy in the form of an interest rate \"dot plot.\" The SEP is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm. Return to text\n\n26. The most recent statement is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/files/fomc_longerrungoals.pdf. Return to text\n\n27. See Jon Faust (1996), \"Whom Can We Trust to Run the Fed? Theoretical Support for the Founders' Views,\" Journal of Monetary Economics, vol. 37 (April), pp. 267-83; Jon Faust (2016), \"Oh, What a Tangled Web We Weave: Monetary Policy Transparency in Divisive Times,\" Hutchins Center Working Paper 25 (Washington: Brookings Institution, November); and Jerome H. Powell (2016), \"A View from the Fed,\" speech delivered at \"Understanding Fedspeak,\" an event cosponsored by the Hutchins Center on Fiscal and Monetary Policy at the Brookings Institution and the Center for Financial Economics at Johns Hopkins University, Washington, November 30. Return to text"
    },
    {
        "title": "Addressing Workforce Development Challenges in Low-Income Communities",
        "date": "March 28, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20170328a.htm",
        "content": "March 28, 2017\n\nChair Janet L. Yellen\n\nAt \"Creating a Just Economy,\" the 2017 annual conference of the National Community Reinvestment Coalition, Washington, D.C.\n\nThank you for this opportunity to be part of the National Community Reinvestment Coalition's annual conference. It is a pleasure to address a group of organizations committed to improving the lives of low- and moderate-income Americans and strengthening communities. I am especially pleased to be with you in 2017, which marks the 40th anniversary of the Community Reinvestment Act (CRA).\n\nAs you know, the CRA requires banks to help meet the credit needs of the communities they are chartered to serve, including low- and moderate-income neighborhoods. Since its enactment, the CRA has helped channel capital into communities and, in the process, supported innovative and effective approaches to community development.\n\nWe at the Federal Reserve take our CRA responsibilities seriously. We evaluate the CRA performance of the state-chartered banks we supervise and make the ratings and written evaluations public.1 We currently are improving our examination procedures and examiner training. We also work with our fellow bank regulators to continually improve our implementation of the law. And, as many of you know, we recently revised our interagency guidance to clarify how various community development activities are considered in assessing CRA performance, among them workforce development, which is my topic today.2\n\nWorkforce Development Initiatives and Challenges\nWorkforce development is a bit of a catchall phrase encompassing different types of initiatives that help prepare people for jobs by providing them with training, placement assistance, and other support. Organizations dedicated to providing workforce development are interested not just in helping people secure any jobs, but jobs that pay well, provide benefits, offer opportunities for advancement, and are less likely to be eliminated during economic downturns. Significant job market changes in recent years, brought about by global competition and technological advances--and the new and shifting skills that these changes demand--make workforce development more important than ever before.\n\nAs community development practitioners, you know that good-paying, stable jobs are not only important to workers and their families, but also are the foundation of strong neighborhoods. As part of our CRA responsibilities, the Federal Reserve, together with the Federal Deposit Insurance Corporation and the Office of the Comptroller of the Currency, has made it clear that banks will receive CRA recognition for lending to, investing in, and providing services to workforce development initiatives. In fact, two Federal Reserve Banks recently published a framework describing how workforce development initiatives can fit within a bank's broader CRA strategy.3\n\nWhile the job market for the United States as a whole has improved markedly since the depths of the financial crisis, the persistently higher unemployment rates in lower-income and minority communities show why workforce development is so essential. For instance, unemployment rates averaged 13 percent in low- and moderate-income communities from 2011 through 2015, compared with 7.3 percent in higher-income communities.4\n\nThe challenges for workers in minority communities are even greater. The average unemployment rate across all census tracts where minorities made up a majority of the population averaged 14.3 percent from 2011 through 2015. Also, a much smaller share of the prime working-age population in these areas is employed--67.7 percent during this period, which is nearly 9 percentage points lower than in communities with smaller minority populations.5 These elevated unemployment rates and depressed employment-to-population ratios underscore the strong need for effective workforce development options for these communities.\n\nEducation as a Workforce Development Strategy\nProbably the most important workforce development strategy is improving the quality of general education. The rapid rise in U.S. education levels in the 20th century, facilitated by the growing availability of high school education in the first part of the century and the rapid expansion of public universities after World War II, contributed enormously to the broad-based economic gains associated with that period.6 But, unfortunately, for a wide variety of reasons that are beyond the scope of this talk, education levels have historically lagged in low- and moderate-income communities, particularly communities of color. Between 2011 and 2015, the average proportion of adults in low- and moderate-income communities who had dropped out of high school was 23.5 percent, which is more than double the 10.9 percent rate in higher-income communities during that period.7\n\nWhen students from low- and moderate-income families do complete high school, they are less likely to pursue a college degree. And when they do attend college, those students are less likely to graduate.8 Among the reasons for the disparity are a lack of money to pay for college and the burden of family responsibilities.9 As a result, the proportion of adults in low- and moderate-income communities from 2011 through 2015 who had a four-year college degree or graduate degree was about half the share in higher-income communities--17.6 percent versus 34 percent.10\n\nThis educational disparity matters because, among many reasons, people with less education experience both higher unemployment and lower average earnings. In December 2016, for example, the unemployment rate for people aged 25 and older with a bachelor's or higher degree was only 2.6 percent. However, the rate was nearly double, 5.1 percent, for workers in this age group with only a high school diploma and about triple, 7.9 percent, for those without a high school degree.11\n\nWhile high school graduates earn somewhat more than people who did not finish high school, the big payoff comes with a four-year college or advanced degree.12 The advantages of higher education, evidenced by lower unemployment rates and higher earnings, are clear across the spectrum but are greater for non-Hispanic whites than for African Americans and Hispanics.\n\nImproving educational levels in low- and moderate-income communities is a long-term task. At least partially because of a lack of early childhood education and the sometimes lower quality of schools, children in these neighborhoods score substantially lower on standardized tests and drop out of high school at higher rates.13 Thus, a starting point is to improve access to quality education in early childhood and improve the quality of primary and secondary schooling.\n\nWe must also recognize and address the barriers faced by low- and moderate-income students trying to attain higher levels of education--barriers not typically faced by their more well-off peers. First, these students often do not have friends or family who have achieved higher educational levels, which matters because students whose parents did not attend college are much less likely to pursue a college degree themselves.14 Even so, these students can benefit from high school counselors or other mentors who can assist them in choosing schools that provide the financial and counseling support that will help them complete their degrees. And they can benefit from help in picking majors and degrees that lead to higher earnings.15\n\nSecond, lower-income students often pursue their education while working to support themselves and family members. Educational programs that help students balance these competing responsibilities go a long way to improving completion rates. In recognition of this fact, the U.S. Department of Education is offering competitive grants to postsecondary institutions to support or establish campus-based childcare programs primarily serving the needs of low-income students.16\n\nI want to reiterate that addressing the particular barriers standing in the way of lower-income students attending college and earning a degree requires a long-term strategy. However, not every student wants a two- or four-year degree or will have the financial wherewithal to pursue and complete a postsecondary degree. To support programs aimed at students not bound for college, in 2015, the Federal Reserve Banks of Philadelphia, Cleveland, and Atlanta identified occupations with above-average wages for workers without a bachelor's degree in the country's 100 largest metropolitan areas.17 The Reserve Banks made this information available to workforce development providers online and in workshops. Educational programs and training that lead to better paying and more steady work are crucial for people without college degrees, particularly lower-income workers.\n\nWorkforce Development Programs in Action\nIn the rest of my remarks, I would like to highlight some examples of successful initiatives that illustrate key features of effective workforce development.18 As you know, within our community affairs offices, the Federal Reserve devotes considerable effort to studying and promoting effective workforce development, so I am able to draw on the knowledge and experience of our staff. In discussing the examples, I would like to make five points.\n\nFirst, it is crucial for younger workers to establish a solid connection to employment early in their work lives. The Federal Reserve's 2013 Survey of Young Workers found that 18- to 30-year-olds with early work experience were more likely to emerge from the recent recession with a permanent job.19 Other studies have found that students who worked 20 hours per week in their senior year of high school earned higher wages later in life than those who did not, and that summer youth employment programs improved participants' attitudes toward their communities, raised their academic aspirations, and boosted their job readiness skills.20 The findings point to some of the reasons that the Boston Fed decided to lend technical support to a pilot program called Pocket Change, which aims to reduce unemployment among low-income 18- to 24-year-olds in Somerville, Massachusetts, through internships, training in job skills, and reinforcement of important soft skills such as punctuality and effective communication. In its first two years, the initiative trained 53 low-income young people and placed 20 of them in jobs. The results of this modest program indicate the promise of efforts that focus on first-time work experiences, and Somerville is now seeking to expand the initiative.21\n\nMy second observation is that career and technical education (CTE) programs, which have seen a revival in recent years, have considerable potential. For some time, vocational education had fallen out of favor or was in decline in the United States, as it was associated with the deleterious practice of \"tracking\" less advantaged students that denied them the opportunity for the best education. But more recently, CTE has been refined and has made a comeback as an effective way to help non-college-bound workers gain valuable skills and obtain a foothold in a labor market that increasingly requires technical proficiency. These programs teach the skills needed to pursue careers in fields such as construction, manufacturing, health care, information technology, hospitality, and financial services.\n\nThis point brings me to my third observation, which is that effective CTE programs and other workforce development initiatives are able to match education and training to good-paying jobs when they actively engage employers in the training process. WorkAdvance, a regional sector-specific program, is a good example. It delivers an array of aligned services to meet local business needs and provide jobs for unemployed and low-income adults in multiple cities.22 An evaluation of the program last year in Tulsa, New York City, and northeast Ohio found it was especially effective because it offered training for in-demand skills and industry-recognized certifications, and it focused on jobs that have clear paths for advancement.23\n\nA fourth observation is that apprenticeships, which are more common in other countries, could play a larger role for low- and moderate-income individuals in our country as part of broader career and technical education efforts. For instance, a state-run program in South Carolina, Apprenticeship Carolina, helps employers develop apprenticeships at no cost to them. Businesses receive a $1,000 annual tax credit per apprenticeship, and the program assists them with information and technical needs, paperwork, and the integration of classroom learning at local technical colleges. The program has led to sizable job gains at a modest cost to the state.24 Similarly, Washington State registered apprenticeship programs contributed to substantial long-term increases in employment rates and hourly wages.25\n\nMy fifth and final observation is that promoting entrepreneurship could play a greater role in workforce development. Entrepreneurship is a fundamental strength of the American economy, and owning your own business or working for yourself can offer income, a means of building wealth, and, sometimes, greater flexibility for balancing job and family commitments. Yet we see less self-employment in low- and moderate-income communities.26 Moreover, when businesses are owned by minorities, they are less likely to have paid employees.27 These findings speak to the opportunities that could be realized by helping people start their own businesses and then helping them grow their businesses. Programs that equip people with the management skills and knowledge they need to start and operate a successful small business can help. Relevant and effective training can reduce the failure rate of businesses by helping owners make better decisions and avoid costly mistakes.28 These programs are especially critical in low-income and rural communities where other resources to support small business development may be scarce.\n\nAs part of their community affairs work, several Federal Reserve Banks have small business development initiatives. The Federal Reserve Bank of New York organized a small business protection and education series last year in partnership with the Brooklyn Chamber of Commerce and a local development corporation. Participants learned about capital resources available to small businesses, online credit alternatives for small businesses, and the risks of handling large volumes of cash. In another example, the Federal Reserve Bank of Kansas City developed a guide to help rural and smaller metropolitan communities promote conditions favorable to growing local businesses rather than relying only on efforts to attract large companies.29\n\nOf course, in addition to training, small business owners need financing. But, as many of you know, factors such as lack of a credit history or a poor credit history and limited collateral--for example, home equity--make it difficult for the owners of small enterprises to access traditional business credit. This situation is true for many minority, women, and low-income borrowers.30 Nontraditional lenders, including more than 1,000 Community Development Financial Institutions around the country, help fill the gap.31\n\nConclusion\nTo conclude, while the economy overall is recovering and the job market has improved substantially since the recession, pockets of persistently high unemployment, as well as other challenges, remain. Fortunately, programs such as the ones I have highlighted today can help address these challenges in more targeted ways than the Federal Reserve is equipped to do through monetary policy. I want you to know that we applaud your work, and we thank you for doing all that you do to serve the needs of lower-income communities across the country. Whether you work to provide affordable housing, homeownership counseling, small business credit and technical support, or workforce development, I hope you know that you have a partner in the Federal Reserve. In the ways we can, with the different tools we each have, our aim is the same: to make the economy work for the benefit of all Americans. This goal is of utmost importance, and I am glad to work alongside you in striving to achieve it.\n\n1. CRA information is available on the Board's website at https://www.federalreserve.gov/apps/crape/BankRating.aspx. Return to text\n\n2. See the Federal Financial Institutions Examination Council's CRA webpage \"Interagency Questions and Answers\" available at https://www.ffiec.gov/cra/qnadoc.htm. Return to text\n\n3. See Elizabeth Sobel Blum and Steven Shepelwich (2017), Engaging Workforce Development: A Framework for Meeting CRA Obligations (PDF), Federal Reserve Banks of Dallas and Kansas City (Dallas: FRB Dallas, January). Return to text\n\n4. Low- and moderate-income communities are census tracts with a family median income under 80 percent of the area median income. Higher-income communities are census tracts with median incomes of 80 percent of the area median income or greater. Statistics represent the average of census tract unemployment rates rather than the unemployment rate across all individuals in these tracts combined. Return to text\n\n5. Prime-age workers are those who are aged 25 to 54. Statistics are from the American Community Survey (ACS) data releases from 2011 through 2015, available on the U.S. Census Bureau's website at https://www.census.gov/programs-surveys/acs. Return to text\n\n6. See Claudia Goldin (2001), \"The Human-Capital Century and American Leadership: Virtues of the Past,\" Journal of Economic History, vol. 61 (June), pp. 263-92. Return to text\n\n7. Adults are defined here as individuals aged 25 and older. Statistics are from the ACS data releases from 2011 through 2015; see note 5. Return to text\n\n8. Following a cohort of high school sophomores in 2002, 96 percent of students from a high socioeconomic-status family pursued at least some higher education and 60 percent completed a bachelor's degree. Among students from a low socioeconomic-status family, 72 percent pursued higher education and 14 percent completed a bachelor's degree. Socioeconomic status is based on family income and parents' education. See National Center for Education Statistics (2015), \"Postsecondary Attainment: Differences by Socioeconomic Status (PDF),\" in The Condition of Education 2015 (Washington: NCES). Return to text\n\n9. Many people who did not enroll for or did not complete a degree also gave as a reason that they wanted to work, which may also reflect budget constraints that made pursuing or completing a higher education difficult. See Board of Governors of the Federal Reserve System (2016), Report on the Economic Well-Being of U.S. Families in 2015 (PDF) (Washington: Board of Governors, May). Return to text\n\n10. See note 7. Return to text\n\n11. Moreover, \"over 95 percent of jobs created during the recovery have gone to workers with at least some college education, while those with a high school diploma or less are being left behind\" (as quoted from the introduction on the webpage for Anthony P. Carnevale, Tamara Jayasundera, and Artem Gulish (2016), America's Divided Recovery: College Haves and Have-Nots (Washington: Georgetown University Center for Education and the Workforce), https://cew.georgetown.edu/cew-reports/americas-divided-recovery).\n\nAlso see Bureau of Labor Statistics (2017), \"The Employment Situation--February 2017,\" news release, March 10, Table A-4: Employment Status of the Civilian Population 25 Years and over by Educational Attainment; and BLS (2017), \"Labor Force Statistics from the Current Population Survey,\" March 10, Table A-10: Unemployment Rates by Age, Sex, and Marital Status, Seasonally Adjusted. Return to text\n\n12. The median weekly earnings for men with a high school degree but no college was $779, and for women it was $603. These amounts compare with median weekly earnings of $1,501 for men and $1,117 for women with a bachelor's or higher degree. Return to text\n\n13. See Sean F. Reardon (2016), School District Socioeconomic Status, Race, and Academic Achievement, paper, Stanford Center for Education Policy Analysis (Stanford: Stanford CEPA); Motoko Rich, Amanda Cox, and Matthew Bloch (2016), \"Money, Race and Success: How Your School District Compares,\" New York Times, April 29, http://www.nytimes.com/interactive/2016/04/29/upshot/money-race-and-success-how-your-school-district-compares.html; and Geoffrey T. Wodtke, David J. Harding, and Felix Elwert (2011), \"Neighborhood Effects in Temporal Perspective,\" American Sociological Review, vol.76 (October), pp. 713-36. Return to text\n\n14. For example, 65 percent of young adults (aged 25 to 34) with a parent who received a bachelor's degree completed one themselves, compared with 16 percent of young adults whose parents completed no education beyond high school. See Board of Governors of the Federal Reserve System (2016), Report on the Economic Well-Being of U.S Households in 2015 (PDF) (Washington: Board of Governors, May). Return to text\n\n15. See Brad Hershbein and Melissa S. Kearney (2014), Major Decisions: What Graduates Earn over Their Lifetimes, Hamilton Project (Washington: Brookings Institution), figure 2; and Anthony P. Carnevale, Ban Cheah, and Andrew R Hanson (2015), The Economic Value of College Majors (PDF) (Washington: Georgetown University Center on Education and the Workforce). Return to text\n\n16. For more information, see the Department of Education's webpage on its Child Care Access Means Parents in School Program at https://www2.ed.gov/programs/campisp/index.html. Return to text\n\n17. Top occupations noted across all MSAs included the following: registered nurses; first-line supervisors of office and administrative support workers; sales representatives, wholesale and manufacturing; business operations specialists, sales representative services; general and operations managers; computer system analysts; automotive service technicians and mechanics; first-line supervisors of construction trades and extraction work; plumbers, pipefitters, and steamfitters; first-line supervisors of mechanics, installers; and construction laborers. See Keith Wardrip, Kyle Fee, Lisa Nelson, and Stuart Andreason, Identifying Opportunity Occupations in the Nation's Largest Metropolitan Economies, Federal Reserve Banks of Philadelphia, Cleveland, and Ohio (Cleveland: FSB of Cleveland), available at https://www.clevelandfed.org/newsroom-and-events/publications/special-reports/sr-20150909-identifying-opportunity-occupations.aspx. Return to text\n\n18. For a broad summary of recent research and policy issues related to workforce development, see the 2015 publication Transforming U.S. Workforce Development Policies for the 21st Century (available at https://www.kansascityfed.org/publications/community/transformworkforce) developed by the Federal Reserve Banks of Atlanta and Kansas City in partnership with the John J. Heldrich Center for Workforce Development at Rutgers University. In addition, all Reserve Banks and the Board of Governors are currently engaged in a System workforce development initiative that will gather up-to-date perspectives from employers and organizations engaged in worker training and education. This initiative will include a series of regional Reserve Bank meetings, a publication on effective investments and outcomes, and a capstone conference in October in Austin, Texas. Return to text\n\n19. The survey found that 82 percent of workers who had worked for pay during high school had a permanent job--4 percentage points higher than for all workers combined. See Board of Governors of the Federal Reserve System (2014), In the Shadow of the Great Recession: Experiences and Perspectives of Young Workers (PDF) (Washington: Board of Governors, November). Return to text\n\n20. Baum and Ruhm (2016) do observe, however, that these gains from employment during the senior year of high school have diminished substantially relative to earlier cohorts. See Charles L. Baum and Christopher J. Ruhm (2016), \"The Changing Benefits of Early Work Experience,\" Southern Economic Journal, vol. 83 (October), pp. 343-63. Return to text\n\n21. For more information on Pocket Change, see the Federal Reserve Bank of Boston's Working Cities Challenge webpage at https://www.bostonfed.org/workingcities/massachusetts/round1/cities/somerville.html. Return to text\n\n22. Aligned services may include intensive screening, occupational skills training, job development and placement services, and retention and advancement services. Return to text\n\n23. For more on the WorkAdvance program, see the MDRC website at www.mdrc.org/project/workadvance#overview, and for information on that program in Northeast Ohio, see the Towards Employment website at http://towardsemployment.org/strategic-initiatives/workadvance. Return to text\n\n24. See Harry J. Holzer and Robert I. Lerman (2014), Work-Based Learning to Expand Jobs and Occupational Qualifications for Youth (PDF) (Washington: Center on Budget and Policy Priorities, April). Return to text\n\n25. Kevin Hollenbeck and Wei-Jang Huang (2014), \"Net Impact and Benefit-Cost Estimates of the Workforce Development System in Washington State,\" Upjohn Institute Technical Report 13-029 (Kalamazoo, Mich.: W.E. Upjohn Institute for Employment Research). Return to text\n\n26. From 2011 through 2015, only 8 percent of households in low- and moderate-income communities reported self-employment income, compared with 11 percent of all households (see ACS data releases in note 5). Return to text\n\n27. Only 4 percent of African American-owned firms and 9 percent of Hispanic-owned firms have paid employees, compared with 22 percent of non-minority-owned firms; see U.S. Department of Commerce, Minority Business Development Agency (2016), \"U.S. Minority-Owned Firms (PDF),\" fact sheet (Washington: MBDA, January). Return to text\n\n28. See Glenn Muske and Nancy Stanforth (2000), \"The Educational Needs of Small Business Owners: A Look into the Future,\" Journal of Extension, vol. 38 (December). Return to text\n\n29. Grow Your Own Guide: Entrepreneurship-Based Economic Development is available on the Federal Reserve Bank of Kansas City's website at https://www.kansascityfed.org/publicat/community/gyo/gyo-guide.pdf. Return to text\n\n30. See Joyce A. Klein (2017), Bridging the Divide: How Business Ownership Can Help Close the Racial Wealth Gap (Washington: Aspen Institute, January). Return to text\n\n31. To find certified Community Development Financial Institutions (CDFIs) in different geographies, see a list on the CDFI Fund's website available at https://www.cdfifund.gov/programs-training/certification/cdfi/Pages/default.aspx. Return to text"
    },
    {
        "title": "Welcoming Remarks",
        "date": "March 23, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20170323a.htm",
        "content": "March 23, 2017\n\nChair Janet L. Yellen\n\nAt \"Strong Foundations: The Economic Futures of Kids and Communities,\" the 10th Biennial Federal Reserve System Community Development Research Conference, Washington, D.C.\n\nI would like to welcome all of you and thank you for joining us to discuss a set of topics of considerable importance to our country. This is the Federal Reserve's 10th biennial community development research conference, dedicated as always to issues of significance to people and communities around the country. The conference is cosponsored by, and includes substantive contributions from, the community development offices of all 12 Federal Reserve Banks as well as the Board of Governors. That united effort and level of commitment reflects how consequential we consider these issues to be. This conference is intended to present and highlight rigorous research that I am confident will inform how you think about your own work, whether from the perspective of policymaking, community development practice, or research.\n\nOur last conference, two years ago, explored various aspects of economic mobility, largely among adults. This year, we gather to discuss \"The Economic Futures of Kids and Communities,\" and, in part, I see this topic as an extension of that earlier conversation about mobility.\n\nToday and tomorrow, we focus on research about the foundation or building blocks for economic success that are laid even before young people enter the workforce and assume responsibility for their own finances.\n\nWe will hear from leading experts on a range of issues related to how children, youths, and young adults are shaped in ways that may ultimately affect their ability later to productively contribute to the economy and manage their finances. We can learn from what the data and analysis tell us, and our hope is that making use of this information will lead to more effective programs and policies and thus better outcomes.\n\nConsiderable evidence shows that growing up poor makes it harder to succeed as an adult, and new research by the Fed likewise shows the strong connection between the typical experiences of poverty in childhood and economic challenges later as an adult. The data come from the Board's latest Survey of Household Economics and Decisionmaking (SHED), which will be published later this spring.1 In the most recent survey, we asked some of the younger respondents--aged 25 to 39--to think about their childhoods. We asked those young adults whether, during their childhoods, they found themselves worrying about having enough food to eat, having a stable caregiver, or about their personal safety. About 10 percent said they regularly worried about one or more of these concerns, and an additional 19 percent said they sometimes worried about them.\n\nWe were then able to compare responses about their experiences in childhood to what these young adults told us about their current circumstances. Some pretty clear patterns emerged. Of those young adults who regularly had one or more of these childhood concerns growing up, more than one-half say that they are currently facing challenges in getting by financially. This fraction compares to just over one-fourth of those who said they never, or only rarely, worried about these concerns as children that now experience this level of financial challenge. Young adults who regularly or sometimes worried when they were children about their care, safety, or having enough to eat are also less likely to be employed, less likely to have consistent income month-to-month, and less likely to be able to pay all of their current monthly bills in full, compared with those who never or rarely worried about these concerns as children.2\n\nBroadly speaking, children who grow up in insecure circumstances, those often experienced in poverty, seem disproportionately likely to experience financial insecurity as adults. This conference is about understanding what kinds of environments and resources can best help children meet with economic success after they reach adulthood. There has been a lot of discussion in the aftermath of the Great Recession about how to best connect people with steady jobs. But research presented over the next two days makes a compelling case that there is a need to also think longer term about how to prepare people for success in the labor market. In fact, this research underscores the value of starting young to develop basic work habits and skills, like literacy, numeracy, and interpersonal and organizational skills. These habits and skills help prepare people for work, help them enter the labor market sooner, meet with more success over time, and be in a position to develop the more specialized skills and obtain the academic credentials that are strongly correlated with higher and steadier earnings. Indeed, a growing body of economic and education literature has focused on the relative efficiency of addressing workforce development challenges through investments in early childhood development and education compared with interventions later in life.\n\nI believe that data, evidence, and research can help policymakers and practitioners think more clearly about the implications for improving economic and life outcomes for everyone. To this end, the speakers at this conference will focus on three broad issues. I would like to briefly mention each, highlighting some of the questions that I believe can be informed by the research that will be presented here.\n\nFirst, this morning's panel will address early childhood development and education. In recent years, medicine and social science has revealed more than we ever have known before about which factors and experiences in childhood can make a difference later in life. However, many questions demand further attention. A fundamental one is how positive developmental outcomes can be promoted among those who were not born into families with socioeconomic advantages. While we do know there are advantages to good quality early childhood education, we should strive to better understand what kind of returns on investment this education provides and how to maximize these returns. The answers to these questions may influence thinking about how programs and interventions meant to assist kids and their families should be structured for maximum effectiveness to help put kids on the road to economic success.\n\nSecond, researchers have explored the effects of neighborhoods and community conditions on the development of young people. Some presenters at this conference will share their understanding of how physical surroundings influence personal development. For instance, how do the form and quality of community institutions such as schools, community centers, and libraries play a role? What other kinds of community characteristics--such as public safety, transportation, and environmental quality--might help or hinder general education and financial skill development? A particularly important question is how kids' home environments affect them in ways that matter for their future economic success. It is also critically important to ask, what kinds of interventions have proven track records, and are these programs scalable?\n\nThird, and finally, other presenters will explore issues around skill development of youths and young adults, workforce outcomes, and the implications for the broader economy. They will ask how we understand which formative experiences most affect the ability of young people to successfully move to the next chapter in their lives, whether that means college, a job, or other paths such as self-employment. What role does a range of programs--starting with early childhood education all the way through youth vocational or apprenticeship training--play in affecting job readiness? How effective are different approaches, and what are the returns on investment? We should also pay attention to how well young people form the sorts of \"soft skills\"--things like teamwork, communication, and the ability to handle conflict--that are so valued by employers. And, for young people whose paths become difficult, such as those who get caught up in the juvenile justice system, what effect do such experiences have on their futures as workers and consumers, and what are the most promising approaches to foster a course correction?\n\nI hope that the data and other evidence presented today and tomorrow are of use to you in your work. Community development professionals attending this conference may consider how the design and implementation of their programs may be improved. Policymakers may look more closely at how kids are affected--purposefully or unintentionally--by public policies. And researchers may encounter ideas that spark new work that can shed further light on these important topics.\n\nI think it is important that we better understand these issues, and I applaud you for taking the time to be here to share your knowledge and to learn. Our young people are the future, and we all want them to have the support they need for successful and fulfilling lives. As a central banker, I recognize the benefits to the broader economy when more people are better prepared for work and for managing their finances. In short, ensuring that all of our kids have \"strong foundations\" will help build a similarly strong foundation for the U.S. economy.\n\n1. Board of Governors of the Federal Reserve System (forthcoming), 2016 Survey of Household Economics and Decisionmaking (Washington: Board of Governors). Past SHED surveys are available on the Board's website at https://www.federalreserve.gov/communitydev/shed.htm, which is also where the 2016 survey will be posted when completed. Return to text\n\n2. See note 1. Return to text"
    },
    {
        "title": "From Adding Accommodation to Scaling It Back",
        "date": "March 03, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20170303a.htm",
        "content": "March 03, 2017\n\nChair Janet L. Yellen\n\nAt The Executives' Club of Chicago, Chicago, Illinois\n\nI am pleased to join you today to discuss the U.S. economy and the Federal Reserve's monetary policy. I strongly believe that my colleagues and I should explain, as clearly as we can, both the reasons for our decisions and the fundamental principles that underlie our strategy.\n\nToday I will review the conduct of monetary policy during the nearly 10 years since the onset of the financial crisis. Although the Federal Reserve's policy strategy for systematically pursuing its congressionally mandated goals of maximum employment and price stability has not changed during this period, the Federal Open Market Committee (FOMC) has made significant tactical adjustments along the way. I will spend most of my time today discussing the rationale for the adjustments the Committee has made since 2014, a year that I see as a turning point, when the FOMC began to transition from providing increasing amounts of accommodation to gradually scaling it back.\n\nThe process of scaling back accommodation has so far proceeded at a slower pace than most FOMC participants anticipated in 2014. Both unexpected economic developments and deeper reevaluations of structural trends affecting the U.S. and global economies prompted us to reassess our views on the outlook and associated risks and, consequently, the appropriate stance of monetary policy, both in the near term and the longer run. Looking ahead, we continue to expect the evolution of the economy to warrant further gradual increases in the target range for the federal funds rate. However, given how close we are to meeting our statutory goals, and in the absence of new developments that might materially worsen the economic outlook, the process of scaling back accommodation likely will not be as slow as it was in 2015 and 2016.\n\nI should note that I will discuss the process of scaling back accommodation mostly from the perspective of our interest rate decisions, which my FOMC colleagues and I see as our primary tool for actively adjusting the stance of monetary policy when our actions are not constrained by the zero lower bound on short-term interest rates.1\n\nAssessing the Degree of Monetary Policy Accommodation\nIn our monetary policy deliberations, the FOMC always faces two fundamental questions: First, how do we assess the current stance of monetary policy? Second, what are the strategic and tactical considerations that underpin our decisions about the appropriate stance of monetary policy going forward? These questions are difficult because the interactions between monetary policy and the economy are complex. Policy affects the economy through many different channels, and, in turn, many factors influence the appropriate course of policy.\n\nGauging the current stance of monetary policy requires arriving at a judgment of what would constitute a neutral policy stance at a given time. A useful concept in this regard is the neutral \"real\" federal funds rate, defined as the level of the federal funds rate that, when adjusted for inflation, is neither expansionary nor contractionary when the economy is operating near its potential. In effect, a \"neutral\" policy stance is one where monetary policy neither has its foot on the brake nor is pressing down on the accelerator. Although the concept of the neutral real federal funds rate is exceptionally useful in assessing policy, it is difficult in practical terms to know with precision where that rate stands. As a result, and as I described in a recent speech, my colleagues and I consider a wide range of information when assessing that rate.2 As I will discuss, our assessments of the neutral rate have significantly shifted down over the past few years.\n\nIn the Committee's most recent projections last December, most FOMC participants assessed the longer-run value of the neutral real federal funds rate to be in the vicinity of 1 percent.3 This level is quite low by historical standards, reflecting, in part, slow productivity growth and an aging population not only in the United States, but also in many advanced economies. Moreover, the current value of the neutral real federal funds rate appears to be even lower than this longer-run value because of several additional headwinds to the U.S. economy in the aftermath of the financial crisis, such as subdued economic growth abroad and perhaps a lingering sense of caution on the part of households and businesses in the wake of the trauma of the Great Recession.\n\nIt is difficult to say just how low the current neutral rate is because assessments of the effect of post-recession headwinds on the current level of the neutral real rate are subject to a great deal of uncertainty. Some recent estimates of the current value of the neutral real federal funds rate stand close to zero percent.4 With the actual value of the real federal funds rate currently near minus 1 percent, a near-zero estimate of the neutral real rate means that the stance of monetary policy remains moderately accommodative, an assessment that is consistent with the fact that employment has been growing at a pace--around 180,000 net new jobs per month--that is notably above the level estimated to be consistent with the longer-run trend in labor force growth--between 75,000 and 125,000 per month.5 As I will explain, this policy stance seems appropriate given that the underlying trend in inflation appears to be still running somewhat below 2 percent. But as that gap closes, with labor market conditions now in the vicinity of our maximum employment objective, the Committee considers it appropriate to move toward a neutral policy stance.\n\nMy colleagues and I generally anticipate that the neutral real federal funds rate will rise to its longer-run level over the next few years. This expectation partly underlies our view that gradual increases in the federal funds rate will likely be appropriate in the months and years ahead: Those increases would keep the economy from significantly overheating, thereby sustaining the expansion and maintaining price stability.\n\nPost-Crisis Period: Same Strategy, New Tactics\nI will now examine the strategic and tactical considerations that go into FOMC deliberations by discussing past monetary policy decisions in the context of our mandate from the Congress to pursue maximum employment and price stability.\n\nThe FOMC's monetary policy strategy is based on three basic principles. First, our monetary policy must be goal driven. We must take care to ensure that our decisions over time are consistent with our commitment to achieve the Federal Reserve's congressionally mandated goals of maximum employment and price stability, and that the public understands and has confidence in that commitment. Second, our monetary policy must be forward looking because our decisions tend to influence economic activity and inflation with a substantial lag. Among other things, this implies looking through short-term and transitory developments and focusing on the medium-term outlook--roughly two or three years out--when making policy decisions. Third, our monetary policy must be risk sensitive. Because the outlook is uncertain, we must assess appropriate policy with an eye toward the risk that our expectations about the economy turn out to be significantly wrong.\n\nWe have followed this basic strategy for decades and, in 2012, the FOMC formalized it in our \"Statement on Longer-Run Goals and Monetary Policy Strategy.\"6 The Committee has reaffirmed this commitment annually. But the challenges brought about by the financial crisis, and the very deep recession and painfully slow recovery that followed, compelled us to adjust our tactics for carrying out our policy strategy. In particular, once the Committee had cut the federal funds rate to near zero in late 2008, it became necessary to deploy new tools to supply the considerable monetary accommodation required by the extremely weak state of the job market and persistently low inflation.7 Those tools--especially our large-scale securities purchases and increasingly explicit forward guidance pertaining to the likely future path of the federal funds rate--enabled the Federal Reserve to provide necessary additional support to the U.S. economy by pushing down longer-term interest rates and easing financial conditions more generally.\n\nMuch has been written and said already about the provision of additional accommodation between 2008 and 2014, when the FOMC completed its latest round of large-scale securities purchases, so I will turn now to our policy stance since 2014, when the FOMC's main focus started to shift from providing additional accommodation to scaling it back.8\n\n2014: A Turning Point for Monetary Policy\nBy late 2013, the FOMC concluded that the economy had made sufficient progress, and the outlook was sufficiently favorable, that it should reduce the pace of its large-scale securities purchases. But we reiterated that these purchases would continue until the outlook for the labor market had improved substantially. The U.S. economy made notable progress toward the FOMC's statutory goals during 2014, with the unemployment rate dropping to close to 6 percent by mid-year--well below its Great-Recession peak of 10 percent--and other measures of labor market conditions also showing improvement: Payroll gains were solid; job openings had risen significantly; and the number of workers voluntarily quitting their jobs--a sign of confidence in the labor market--was rising back toward pre-crisis levels. We were also seeing progress on achieving our price stability goal: Total inflation as measured by changes in the headline personal consumption expenditures (PCE) price index reached about 1-3/4 percent by mid-2014 after hovering around 1 percent in the fall of 2013. Inflation seemed to be moving toward the FOMC's 2 percent objective, a level that the FOMC judges to be consistent with price stability because it is low enough that it does not need to figure prominently into people's and businesses' economic decisions but high enough to serve as a buffer against deflation and provide greater scope for monetary policy to address economic weakness.\n\nThe progress seen during 2014 indicated to the FOMC that it was no longer necessary to provide increasing amounts of support to the U.S. economy by continuing to add to the Federal Reserve's holdings of longer-term securities. Accordingly, the Committee continued to reduce the pace of asset purchases over the course of the year, ending its purchases in October. That step, however, did not mark an immediate shift toward tighter monetary policy because we also indicated then that we did not expect to raise interest rates for a considerable time after the end of our securities purchases. Moreover, as the Committee explained in a set of \"normalization principles\" issued that September, the intention was to maintain the overall size of the Federal Reserve's balance sheet at an elevated level until sometime after the FOMC had begun to raise its target for the federal funds rate.9 We decided that maintaining a highly accommodative stance of monetary policy remained appropriate because, while the U.S. economy was stronger and closer to meeting our statutory goals, we saw significant room for improvement. In particular, the unemployment rate still stood above our assessment of its longer-run normal level--that is, the unemployment rate that we expect to prevail when the economy is operating at maximum employment--and inflation remained below the 2 percent objective.\n\nBecause my colleagues and I expected that labor market conditions would continue to improve and that inflation would move back to 2 percent over the medium term, we anticipated that the time was approaching when the economy would be strong enough that we should start to scale back our support. Indeed, the FOMC's June 2014 Summary of Economic Projections (SEP) reported that nearly all FOMC participants saw a higher federal funds rate as appropriate in the next calendar year. In contrast, only two participants in December 2013 thought that it would be appropriate to start raising that rate in the next calendar year.\n\nUneven Progress in 2015 and into 2016\nIn 2015, the unemployment rate fell significantly faster than we generally had anticipated in 2014. However, a series of unanticipated global developments beginning in the second half of 2014--including a prolonged decline in oil prices, a sizable appreciation of the dollar, and financial market turbulence emanating from abroad--ended up having adverse implications for the outlook for inflation and economic activity in the United States, prompting the FOMC to remove monetary policy accommodation at a slower pace than we had anticipated in mid-2014.\n\nU.S. gross domestic product (GDP) growth generally surprised to the downside in 2015, reflecting, in part, weak economic activity abroad, the earlier appreciation of the dollar, and the effect of falling oil prices on business fixed investment. This unanticipated slowing in the pace of the economic recovery caused us to worry about the sustainability of ongoing improvements in employment and, thus, of likely progress toward our maximum employment goal. Our worry was reinforced by our assessment that, with the federal funds rate still near zero, there would likely be only limited scope for us to respond by lowering short-term rates if the weakening in economic activity turned out to be persistent. In contrast, if the weakening proved transitory and the economy instead began to overheat, threatening to push inflation to an undesirably high level, the FOMC would have ample scope to respond through tighter monetary policy.\n\nInflation also was lower than expected, with headline PCE prices rising less than 1 percent over the course of 2015, instead of around 1-3/4 percent as we had anticipated in June 2014. Much of this shortfall reflected the effects of falling oil prices and the appreciation of the dollar. My colleagues and I typically look through the effects on inflation of fluctuations in oil prices and the dollar because these effects tend to be transitory. However, we became concerned in 2015 about the risk that part of the decline in inflation could prove to be longer lasting, especially given that inflation had already been running below our 2 percent objective for quite some time.10 These various considerations, along with our reassessment of longer-run economic conditions--which I will discuss shortly--explain why the Committee ended up raising the target range for the federal funds rate only 1/4 percentage point in 2015, substantially less than the full percentage point increase suggested by the median projection of FOMC participants reported in June 2014.\n\n2016 also brought some unexpected economic developments that led us to proceed cautiously. During the first half of the year, mixed readings on the job market, along with additional disappointing data on real GDP growth, suggested again that progress toward the achievement of our maximum employment goal could be slowing markedly. Meanwhile, inflation hovered just below 1 percent as dollar appreciation continued to exert downward pressure on import prices, and financial market turbulence emanating from abroad--associated with concerns about the Chinese economy and the Brexit referendum--posed new risks to U.S. economic activity and inflation. Moreover, even as payroll gains turned solid again in the second half of 2016, the unemployment rate remained relatively flat, suggesting that perhaps there was more room for improvement in the job market than we had previously thought. Those unanticipated developments were part of the reason why the Committee again opted to proceed more slowly in removing accommodation than had been anticipated at the start of the year. We ended up increasing the target range for the federal funds rate by only 1/4 percentage point over the course of 2016, rather than the full percentage point suggested by our December 2015 projections.\n\nReassessing Longer-Run Conditions\nThe slower-than-anticipated increase in our federal funds rate target in 2015 and 2016 reflected more than just the inflation, job market, and foreign developments I mentioned. During that period, the FOMC and most private forecasters generally lowered their assessments of the longer-run neutral level of the real federal funds rate. Indeed, at our October 2015 meeting, the FOMC had a comprehensive discussion of neutral real interest rates and was impressed by the breadth of evidence suggesting that those rates had declined both here and abroad, and that the decline had been going on for some time. In response to this growing evidence, the median assessment by FOMC participants of the longer-run level of the real federal funds rate fell from 1-3/4 percent in June 2014 to 1-1/2 percent in December 2015 and then to 1 percent in December 2016. These reassessments reflected, in part, the persistence of surprisingly sluggish productivity growth--both in the United States and abroad--and suggested that fewer federal funds rate increases would be necessary than previously thought to scale back accommodation.\n\nPartly in response to persistently slow wage growth, FOMC participants and private forecasters have in recent years lowered their estimates of the normal longer-run rate of unemployment. The median projection of FOMC participants of the longer-run level of the unemployment rate fell from about 5-1/4 percent in June 2014 to approximately 4-3/4 percent in December 2016. Other things being equal, a lower longer-run level of the unemployment rate suggests that the economy has greater scope to create jobs without generating too much inflation.11 Thus, the downward revisions to FOMC participants' views on the unemployment rate over the longer run contributed to our assessment that monetary policy could stay accommodative longer than we had anticipated in 2014.\n\nFurther Progress since Mid-2016\nThe U.S. economy has exhibited remarkable resilience in the face of adverse shocks in recent years, and economic developments since mid-2016 have reinforced the Committee's confidence that the economy is on track to achieve our statutory goals. Job gains have remained quite solid, and the unemployment rate, at 4.8 percent in January, is now in line with the median of FOMC participants' estimates of its longer-run normal level. On the whole, the prospects for further moderate economic growth look encouraging, particularly as risks emanating from abroad appear to have receded somewhat. The Committee currently assesses that the risks to the outlook are roughly balanced.\n\nMoreover, after remaining disappointingly low through mid-2016, inflation moved up during the second half of 2016, mainly because of the diminishing effects of the earlier declines in energy prices and import prices. More recently, higher energy prices appear to have temporarily boosted inflation, with the total PCE price index rising nearly 2 percent in the 12 months ending in January. Core PCE inflation--which excludes volatile energy and food prices and, therefore, tends to be a better indicator of future inflation--has been running near 1-3/4 percent. Market-based measures of inflation compensation have moved up, on net, in recent months, although they remain low.\n\nWith the job market strengthening and inflation rising toward our target, the median assessment of FOMC participants as of last December was that a cumulative 3/4 percentage point increase in the target range for the federal funds rate would likely be appropriate over the course of this year. In light of current economic conditions, such an increase would be consistent with the Committee's expectation that it will raise the target range for the federal funds rate at a gradual pace and would bring the real federal funds rate close to some estimates of its current neutral level. However, partly because my colleagues and I expect the neutral real federal funds rate to rise somewhat over the longer run, we projected additional gradual rate hikes in 2018 and 2019.\n\nOur individual projections for the appropriate path for the federal funds rate reflect economic forecasts that generally envision that economic activity will expand at a moderate pace in coming years, labor market conditions will strengthen somewhat further, and inflation will be at or near 2 percent over the medium term. In short, we currently judge that it will be appropriate to gradually increase the federal funds rate if the economic data continue to come in about as we expect. Indeed, at our meeting later this month, the Committee will evaluate whether employment and inflation are continuing to evolve in line with our expectations, in which case a further adjustment of the federal funds rate would likely be appropriate.\n\nNonetheless, as we have said many times--and as my discussion today demonstrates--monetary policy cannot be and is not on a preset course. As in 2015 and 2016, the Committee stands ready to adjust its assessment of the appropriate path for monetary policy if unanticipated developments materially change the economic outlook.\n\nMonetary Policy Is Not a Panacea\nThe U.S. economy has shown great improvement and is close to meeting our congressionally mandated goals of maximum employment and price stability, but we of course recognize that important challenges remain. For instance, as we noted in our latest Monetary Policy Report to the Congress, the ongoing expansion has been the slowest since World War II, with real GDP growth averaging only about 2 percent per year.12 This subdued pace reflects, in part, slower growth in the labor force in recent years--compared with much of the post-World War II period--and disappointing productivity growth both in the United States and abroad.\n\nOur report also noted that, despite a notable pickup in 2015, real incomes for the median family were still a bit lower than they were prior to the Great Recession, and the gains during this economic recovery have been skewed toward the top of the income distribution, as has been the case for quite some time. Families at the 10th percentile of the income distribution earned about 4 percent less in 2015 than they did in 2007, whereas families at the 90th percentile earned about 4 percent more. In addition, the economic circumstances of blacks and Hispanics, while improved since the depths of the recession, remain worse, on average, that those of whites or Asians.\n\nThese unwelcome developments unfortunately reflect structural challenges that lie substantially beyond the reach of monetary policy. Monetary policy cannot, for instance, generate technological breakthroughs or affect demographic factors that would boost real GDP growth over the longer run or address the root causes of income inequality. And monetary policy cannot improve the productivity of American workers. Fiscal and regulatory policies--which are of course the responsibility of the Administration and the Congress--are best suited to address such adverse structural trends.\n\nConclusion\nTo conclude, we at the Federal Reserve must remain squarely focused on our congressionally mandated goals. The economy has essentially met the employment portion of our mandate and inflation is moving closer to our 2 percent objective. This outcome suggests that our goal-focused, outlook-dependent approach to scaling back accommodation over the past couple of years has served the U.S. economy well.\n\nThis same approach will continue to drive our policy decisions in the months and years ahead. With that in mind, our policy aims to support continued growth of the American economy in pursuit of our congressionally mandated objectives. We do that, as I have noted, with an eye always on the risks. To that end, we realize that waiting too long to scale back some of our support could potentially require us to raise rates rapidly sometime down the road, which in turn could risk disrupting financial markets and pushing the economy into recession. Having said that, I currently see no evidence that the Federal Reserve has fallen behind the curve, and I therefore continue to have confidence in our judgment that a gradual removal of accommodation is likely to be appropriate. However, as I have noted, unless unanticipated developments adversely affect the economic outlook, the process of scaling back accommodation likely will not be as slow as it was during the past couple of years.\n\nReferences\nBoard of Governors of the Federal Reserve System (2017). Monetary Policy Report (PDF). Washington: Board of Governors, February.\n\nD'Amico, Stefania, William English, David Lopez-Salido, and Edward Nelson (2012). \"The Federal Reserve's Large-Scale Asset Purchase Programmes: Rationale and Effects,\" Economic Journal, vol. 122 (November), pp. F415-46.\n\nEngen, Eric M., Thomas Laubach, and David Reifschneider (2015). \"The Macroeconomic Effects of the Federal Reserve's Unconventional Monetary Policies (PDF),\" Finance and Economics Discussion Series 2015-005. Washington: Board of Governors of the Federal Reserve System, February.\n\nHolston, Kathryn, Thomas Laubach, and John C. Williams (2016). \"Measuring the Natural Rate of Interest: International Trends and Determinants (PDF),\" Finance and Economics Discussion Series 2016-073. Washington: Board of Governors of the Federal Reserve System, September.\n\nYellen, Janet (2016). \"The Federal Reserve's Monetary Policy Toolkit: Past, Present, and Future,\" speech delivered at \"Designing Resilient Monetary Policy Frameworks for the Future,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 26.\n\n-------- (2017). \"The Economic Outlook and the Conduct of Monetary Policy,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford University, Stanford, Calif., January 19.\n\n1. When the federal funds rate was near zero and we felt the economy still needed more support, the FOMC acted, beginning in 2008, to purchase longer-term securities. Although we stopped increasing the size of our securities portfolio in 2014, we have been reinvesting principal payments from our securities holdings ever since. We have said that we expect to maintain this policy until normalization of the level of the federal funds rate is well under way. We have also said that, when it becomes appropriate to reduce the size of our balance sheet, we will do so primarily by letting maturing assets run off our balance sheet. Return to text\n\n2. See Yellen (2017). Return to text\n\n3. This estimate of the neutral real federal funds rate is based on the difference between the medians of the longer-run projections for the federal funds rate and inflation submitted by individual FOMC participants for the December 2016 FOMC meeting. The most recent Summary of Economic Projections, an addendum to the minutes of that meeting, is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/fomcminutes20161214ep.htm. Return to text\n\n4. See, for instance, Holston, Laubach, and Williams (2016). Return to text\n\n5. The estimate of the actual value of the real federal funds rate (around minus 1 percent) is based on the difference between the current value of the effective federal funds rate (close to 0.66 percent) and the latest reading on inflation as measured by the 12-month change in the price index for personal consumption expenditures excluding energy and food items (1-3/4 percent). Return to text\n\n6. The Statement on Longer-Run Goals and Monetary Policy Strategy is available on the Board's website at https://www.federalreserve.gov/monetarypolicy/files/FOMC_LongerRunGoals.pdf (PDF). Return to text\n\n7. See Yellen (2016). Return to text\n\n8. For a discussion of our monetary policy during the 2008-14 period, see, for instance, Engen, Laubach, and Reifschneider (2015). Return to text\n\n9. The FOMC's Policy Normalization Principles and Plans are available on the Board's website at https://www.federalreserve.gov/newsevents/press/monetary/20140917c.htm.\n\nSeveral studies support the notion that maintaining the size of the Federal Reserve's balance sheet at an elevated level is consistent with keeping a highly accommodative policy stance, particularly when short-term interest rates are close to zero, as it was the case in 2014--see, for instance, D'Amico and others (2012) and many of the references in Engen, Laubach, and Reifschneider (2015). Large Federal Reserve holdings of longer-term securities reduce the total amount of such securities available for purchase by the public, exerting upward pressure on their prices and, thus, depressing their yields and contributing to lower borrowing costs for American families and businesses. Return to text\n\n10. These concerns were reinforced somewhat by a decline in market-based measures of inflation compensation. Return to text\n\n11. The assessment that there was perhaps more room for improvement in the labor market than previously thought was reinforced by data showing that the labor force participation rate remained relatively stable in 2016, rather than declining as many had expected. Return to text\n\n12. See Board of Governors (2017). Return to text"
    },
    {
        "title": "Monetary Policy: By Rule, By Committee, or By Both?",
        "date": "March 03, 2017",
        "speaker": "Vice Chairman Stanley Fischer",
        "url": "https://www.federalreserve.gov/newsevents/speech/fischer20170303a.htm",
        "content": "March 03, 2017\n\nVice Chairman Stanley Fischer\n\nAt the 2017 U.S. Monetary Policy Forum, sponsored by the Initiative on Global Markets at the University of Chicago Booth School of Business, New York, New York\n\nIn recent years, reforms in the monetary policy decisionmaking process in central banks have been in the direction of an increasing number of monetary policy committees and fewer single decisionmakers‑‑the lone governor model.1 We are only a few months away from the 20th anniversary of the introduction of the Bank of England's Monetary Policy Committee, just a few years after the 300th birthday of the venerable Old Lady of Threadneedle Street. The Bank of Israel moved from a single policymaker to a monetary policy committee in 2010, while I was governor there; more recently, central banks in India and New Zealand have handed over monetary policy to committees.\n\nThe Federal Reserve is not part of this recent shift, however. The Federal Open Market Committee (FOMC) has been responsible for monetary policy decisions in the United States since it was established by the Banking Act of 1935, two decades after the founding of the Fed itself.2 \n\nThe movement toward committees reflects the advantages of committees in aggregating a wide range of information, perspectives, and models. Despite the prevalence and importance of committees in modern central banking, the role of committees in the formulation of policy has not attracted nearly as much academic attention as has the research on monetary policy rules.3 \n\nThe literature on monetary policy rules stretches back to at least Adam Smith and includes important contributions from David Ricardo, Knut Wicksell, and Milton Friedman.More recently, John Taylor has moved the research agenda forward with his eponymous rule, and a large number of academic papers have been written examining the effectiveness and robustness of policy rules.4 In contrast, as noted, study of the role of committees in making monetary policy has been fairly light, notwithstanding the insightful work of Alan Blinder and others.5 \n\nCommittees and rules may appear to be in opposition as approaches to policymaking. One might even argue that if a central bank ever converged on a single monetary rule, there would be no need for a monetary policy committee. In practice, the Fed operates through a committee structure and considers the recommendations of a variety of monetary rules as we make monetary policy decisions. Our decision is typically whether to raise or reduce the federal funds rate or to leave it unchanged. Committees can aggregate large amounts of diverse information--not just data, but also anecdotes and impressions that would be hard to quantify numerically. Good committees also offer a variety of perspectives and underlying economic models for interpreting the economy. In contrast, a policy rule, strictly defined, is numerical and constrained to a single perspective on the economy.\n\nCommittees and rules each have their advantages. Committees embody a wider range of information and have a capacity for innovation. Rules can simplify central bank communications, a particularly important feature in forward-looking models of the economy. In contrast, the diversity of views that makes a committee work can sometimes pose a communications challenge, as the frequent complaints about the cacophony of messages coming out of the FOMC illustrate.6 \n\nIn the remainder of my discussion, I would like to elaborate on some of the features of committees that have contributed to their prevalence in monetary policymaking. I will then discuss monetary policy rules and some of the difficulties in developing robust rules for policy.\n\nWhy Do Almost All Central Banks Make Their Monetary Policy Decisions in a Committee?\nLet us turn to central bank decisionmaking. One of the striking facts about the Fed is that it is the third central bank of the United States. Whereas the long-lived central banks of Europe‑‑the Riksbank and the Bank of England‑‑have survived for more than three centuries, the Fed has only recently become a centenarian.\n\nRoger Lowenstein's book America's Bank convinces the reader that it was no easy matter to establish this third central bank. It also establishes for those coming to the issue for the first time that the major issues related to the Fed's structure were political. That is, underlying the disagreements about the establishment of the Federal Reserve was the concern that the central bank not upset the balance of economic power within the U.S. economy. Indeed, it was not until 1935 that the present structure of the FOMC was established, in which the 7 members of the Federal Reserve Board in Washington, D.C., who are nominated by the President and confirmed by the Senate, vote along with 5 of the 12 Reserve Bank presidents at any given meeting.7 \n\nSo, why policy committees? What makes them so special? There are several reasons to prefer decisionmaking by committee: For one thing, each committee member brings to the table his or her own perspective or view of the world, as well as valuable information that others on the committee haven't heard. Moreover, committees are less likely to take extreme positions‑‑discussion, deliberation, and voting tends to drive policy outcomes toward compromise. Committees also tend to be less volatile or activist, imparting an inertia to policymaking that could be desirable‑‑or perhaps undesirable when activism is required.8 Finally, academic studies have shown that a combination of forecasts is more accurate, over time, than a single forecast.9 Putting it all together, committees are, on average, likely to make better monetary policy decisions than individuals‑‑an assertion that has received support from academic experiments in which undergraduate students played a part.\n\nNotwithstanding the shift toward monetary policy committees, each central bank and its institutional structure reflects the politics and culture of the country that it serves (or \"countries\" in the case of the European Central Bank). The Federal Reserve is no exception, as Lowenstein's book demonstrates. In the years before 1913, the United States suffered through a series of financial crises culminating in the Panic of 1907. That panic convinced many important stakeholders‑‑William Jennings Bryan, the leader of the Populist movement; Paul Warburg, a prominent financier; Nelson Aldrich, a powerful Republican senator; and Carter Glass, the Democratic chair of the House Committee on Banking and Currency‑‑that America needed a central bank. Our unique structure with the Board of Governors in Washington and the 12 Reserve Banks scattered around the country reflected a years-long struggle to balance a variety of competing interests: farmers in the heartlands and financiers on Wall Street; populists and federalists; and creditors and debtors. Our central bank and its policy committee importantly reflect the deal the Fed's founders struck to resolve those competing interests and create an institution representing America's economic and geographic diversity.10 \n\nI should add that I find the regional balance created by the membership of the FOMC to be a valuable feature of its structure. In the first round of policymaker discussion at a typical FOMC meeting, most of the presidents of the Reserve Banks start their presentations with a description of economic developments in their Federal Reserve District.11 From these presentations, one understands what a massive and diverse economy the United States is and why the politicians who established the Fed were right to require its decisions to be made by a committee.\n\nRobust Rules for Monetary Policy\nI turn now to economic models and monetary policy rules. I recently gave a lecture at the University of Warwick entitled \"I'd Rather Have Bob Solow Than an Econometric Model, But...,\" with the punch line quote from Paul Samuelson saved for the end: \"I'd rather have Bob Solow than an econometric model, but I would rather have Bob Solow with an econometric model than without one.\"12 To summarize, the speech discussed the important role that models and policy rules play in FOMC discussions and decisionmaking.\n\nShortly after the speech, I received an e-mail from an old and esteemed colleague, Professor Athanasios Orphanides, with the subject line \"I'd rather have Bob Solow with a model and a rule (following a careful evaluation process).\" What does a careful evaluation process entail? I will paraphrase my correspondent at length.13 \n\nProfessor Orphanides's recommendation is that the FOMC adopt a reference rule, based on a rigorous evaluation and paying particular emphasis to (1) robustness to model uncertainty, (2) robustness to natural rate uncertainty, (3) robustness to expectations formation, (4) robustness to the size of shocks and the effective lower bound, and (5) whatever else the Fed staff has identified as a gap in our knowledge that may matter in evaluation. He suggested that, ultimately, the FOMC could arrive at a simple rule that would serve as a good benchmark to guide policy.\n\nMy colleague certainly lays out an impressive work program for the Board's cadre of Ph.D. economists. However, I tend to agree with John Taylor and my Fed colleague John Williams when they write that \"the search for better and more robust policy rules is never done.\"14 \n\nMy take is that rules are extremely useful reference tools, but they are likely to work best as inputs into a committee decision. Why? Let me reiterate some points I made in Warwick. First, the economy is very complex, and models that attempt to approximate that complexity can sometimes let us down. A particular difficulty is that expectations of the future play a critical role in determining how the economy reacts to a policy change. Moreover, the economy changes over time-‑this means that policymakers need to be able to adapt their models promptly and accurately in real time. And, finally, no one model or policy rule can capture the varied experiences and views brought to policymaking by a committee. All of these factors and more recommend against accepting the prescriptions of any one model, policy rule, or policymaker.\n\nReferences\nBlinder, Alan S. (1998). Central Banking in Theory and Practice. Cambridge, Mass.: MIT Press.\n\n-------- (2004). The Quiet Revolution: Central Banking Goes Modern. New Haven, Conn.: Yale University Press.\n\nBlinder, Alan S., and John Morgan (2005). \"Are Two Heads Better Than One? Monetary Policy by Committee,\" Journal of Money, Credit, and Banking, vol. 37 (October), pp. 789-811.\n\nBordo, Michael D. (2016). \"Some Historical Reflections on the Governance of the Federal Reserve,\" in John H. Cochrane and John B. Taylor, eds., Central Bank Governance and Oversight Reform. Stanford, Calif.: Hoover Institution Press.\n\nChappell, Henry W. Jr, Rob Roy McGregor, and Todd Vermilyea (2005). Committee Decisions on Monetary Policy: Evidence from Historical Records of the Federal Open Market Committee. Cambridge, Mass.: MIT Press.\n\nFaust, Jon (2016). \"Oh, What a Tangled Web We Weave: Monetary Policy Transparency in Divisive Times,\" paper prepared for \"Understanding Fedspeak,\" an event cosponsored by the Hutchins Center on Fiscal and Monetary Policy at the Brookings Institution and the Center for Financial Economics at Johns Hopkins University, held at the Brookings Institution, Washington, November 30, available at https://www.brookings.edu/research/oh-what-a-tangled-web-we-weave-monetary-policy-transparency-in-divisive-times.\n\nFischer, Stanley (2017). \"I'd Rather Have Bob Solow Than an Econometric Model, But . . . ,\" speech delivered at the Warwick Economics Summit, Coventry, United Kingdom, February 11.\n\nGerlach-Kristen, Petra (2004). \"Is the MPC's Voting Record Informative about Future UK Monetary Policy?\" Scandinavian Journal of Economics, vol. 106 (June), pp. 299-313.\n\nHendry, David F., and Michael P. Clements (2004). \"Pooling of Forecasts,\" Econometrics Journal, vol. 7 (1), pp. 1-31.\n\nLombardelli, Clare, James Proudman, and James Talbot (2005). \"Committees versus Individuals: An Experimental Analysis of Monetary Policy Decision Making,\" International Journal of Central Banking, vol. 1 (May), pp. 181-205.\n\nLowenstein, Roger (2015). America's Bank: The Epic Struggle to Create the Federal Reserve. New York: Penguin Press.\n\nMeade, Ellen E., and David Stasavage (2008). \"Publicity of Debate and the Incentive to Dissent: Evidence from the US Federal Reserve,\" Economic Journal, vol. 118 (April), pp. 695‑717.\n\nOrphanides, Athanasios, and John C. Williams (2002). \"Robust Monetary Policy Rules with Unknown Natural Rates,\" Brookings Papers on Economic Activity, no. 2, pp. 63-118.\n\nPowell, Jerome H. (2016). \"A View from the Fed,\" speech delivered at \"Understanding Fedspeak,\" an event cosponsored by the Hutchins Center on Fiscal and Monetary Policy at the Brookings Institution and the Center for Financial Economics at Johns Hopkins University, held at the Brookings Institution, Washington, November 30.\n\nRuge-Murcia, Francisco, and Alessandro Riboni (2010). \"Monetary Policy by Committee: Consensus, Chairman Dominance, or Simple Majority?\" Quarterly Journal of Economics, vol. 125 (February), pp. 363-416.\n\n-------- (forthcoming). \"Collective versus Individual Decision-Making: A Case Study of the Bank of Israel Law,\" European Economic Review.\n\nTaylor, John B. (1979). \"Estimation and Control of a Macroeconomic Model with Rational Expectations,\" Econometrica, vol. 47 (September), pp. 1267-86.\n\n-------- (1993). \"Discretion versus Policy Rules in Practice,\" Carnegie-Rochester Conference Series on Public Policy, vol. 39 (December), pp. 195-214.\n\n-------- (1999). Monetary Policy Rules. Chicago: University of Chicago Press.\n\nTaylor, John B., and John C. Williams (2011). \"Simple and Robust Rules for Monetary Policy,\" in Benjamin M. Friedman and Michael Woodford, eds., Handbook of Monetary Economics, vol. 3B. Amsterdam: North-Holland, pp. 829-59.\n\nWalsh, Carl E. (2009). \"Using Monetary Policy to Stabilize Economic Activity (PDF),\" speech delivered at a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 20-22, pp. 245-96.\n\nWarsh, Kevin M. (2016). \"Institutional Design: Deliberations, Decisions, and Committee Dynamics,\" in John H. Cochrane and John B. Taylor, eds., Central Bank Governance and Oversight Reform. Stanford, Calif.: Hoover Institution Press.\n\nWheelock, David C. (2000). \"National Monetary Policy by Regional Design: The Evolving Role of the Federal Reserve Banks in Federal Reserve System Policy,\" in Jürgen von Hagen and Christopher J. Waller, eds., Regional Aspects of Monetary Policy in Europe. Boston: Kluwer Academic, pp. 241-74.\n\nWilliams, John C. (2003). \"Simple Rules for Monetary Policy (PDF),\" Federal Reserve Bank of San Francisco, Economic Review, pp. 1-12.\n\n1. I am grateful to Joseph Gruber and Ellen Meade of the Federal Reserve Board for their assistance. The views expressed are mine and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. Although the Federal Reserve was created in 1913, the institutional structure and governance that we have today date from 1935. See Bordo (2016) and Wheelock (2000). Return to text\n\n3. It is true, though, that popular books on prominent central banks typically relate more frequently to the outstanding governors or presidents of the central banks than they do to the organizational structure of those banks. Return to text\n\n4. See Taylor (1979), Taylor (1993), Taylor (1999). A few other notable papers from the vast literature on monetary policy rules include Orphanides and Williams (2002), Walsh (2009), and Williams (2003). Return to text\n\n5. See Blinder (1998) and Blinder (2004). Other important contributions to the literature on monetary policy committees include Blinder and Morgan (2005); Chappell, McGregor, and Vermilyea (2005); Gerlach-Kristin (2004); Meade and Stasavage (2008); Ruge-Murcia and Riboni (2010); and Warsh (2016). Return to text\n\n6. For a discussion of the cacophony issue, see Faust (2016) and Powell (2016). Return to text\n\n7. The president of the Federal Reserve Bank of New York is a permanent member of the FOMC. Four votes rotate annually among the remaining 11 Reserve Bank presidents. Return to text\n\n8. In an experimental study in which undergraduates played a monetary policy game by themselves and in groups of five, Lombardelli, Proudman, and Talbot (2005) found group decisions to be more inertial than individual decisions but closer to that of a policy rule, although Blinder and Morgan (2005) found that groups were no different from individuals in terms of policy activism. A recent study by Ruge-Murcia and Riboni (forthcoming) of Bank of Israel policy before and after its change from a single governor to a committee found that committee decisions were more inertial than individual ones. Return to text\n\n9. See, for example, Hendry and Clements (2004). Return to text\n\n10. In addition, in more recent times, the Federal Reserve System has placed greater emphasis on other aspects of diversity. Return to text\n\n11. While only a subset of Reserve Bank presidents vote at any given FOMC meeting, all of them offer their views in our discussions of the economy and of monetary policy. Return to text\n\n12. See Fischer (2017). Return to text\n\n13. The direct quotation from Professor Orphanides is as follows: \"My recommendation had been that the FOMC should adopt a reference rule, based on rigorous evaluation, using the technology the Fed staff has developed over the past couple of decades and paying particular emphasis on various aspects of robustness: (1) robustness to model uncertainty, (FRB/US (various vintages), EDO, SIGMA (again various vintages) and others), (2) robustness to natural rate uncertainty, u*, r*, Q*, fx* and so on, (3) robustness to expectations formation (mode[l] consistent, learning, partial learning by businesses/households, etc.), (4) robustness to the size of shocks and the ZLB [zero lower bound] (given that certainty equivalence does not hold), (5) whatever else the staff research has identified as a gap in our knowledge that may matter in evaluation. The evaluation should allow for forecast-based rules as well as outcome-based rules and could be updated on an annual basis to incorporate new information. But ultimately, the FOMC could arrive at a simple rule that would be, in the Committee's judgment, a good benchmark to guide policy.\" Return to text\n\n14. See Taylor and Williams (2011), p. 855. Return to text"
    },
    {
        "title": "Innovation, Technology, and the Payments System",
        "date": "March 03, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170303a.htm",
        "content": "March 03, 2017\n\nGovernor Jerome H. Powell\n\nAt Blockchain: The Future of Finance and Capital Markets? The Yale Law School Center for the Study of Corporate Law, New Haven, Connecticut\n\nNew technology and innovative businesses increasingly affect our daily financial lives. Mobile devices, high-speed data communication, and online commerce are creating expectations that convenient, secure, real-time payment and banking capabilities should be available whenever and wherever they are needed. At the same time, disruptive new technologies suggest that traditional financial service providers must innovate and adapt or be left behind.\n\nAgainst this backdrop of technological change and heightened expectations, it is worth remembering our broad public policy objectives, which are driven by the fundamental importance of the payments system in our society. Today, I will lay out those objectives as we see them at the Federal Reserve, and focus in particular on their application in three specific areas where technological innovation is driving change: creating a real-time retail payments system, using distributed ledger technology to develop new clearing and settlement services, and the issuance of digital currencies by central banks.\n\nPublic Policy Objectives for the Payments System\nWe trust financial intermediaries to hold and transfer funds in a safe and secure manner to meet the needs of commerce. The payments system provides financial institutions and their customers a variety of ways to transfer funds, but the goal is essentially the same in all cases: to move money from one individual or business to another in a reliable, secure, low-cost, and convenient manner.\n\nThe Federal Reserve and other central banks have adopted broad public policy objectives to guide the development and oversight of the payments system. At the Fed, we have identified efficiency and safety as our most fundamental objectives, as set forth in our Policy on Payment System Risk.1\n\nAn efficient payments system provides the infrastructure needed to transfer money in low-cost and convenient ways. Efficient systems are innovative in improving the quality of services in response to changing technology and changing demand. Efficient systems are also broadly accessible through means that are convenient for consumers, businesses, and financial institutions around the country. Safe payment systems are built from proven technology and operate reliably and with integrity. Safe systems address a range of well-known risks, including legal, operational, security, and financial risks. Information security and privacy have become particularly important in recent years. Overall, the payments system must be innovative, while also addressing risks, supporting financial stability, and maintaining public confidence.\n\nFaster and More Secure Retail Payment Systems\nThe development of real-time retail payments has been gaining momentum globally. The UK has had a system in place since 2008. Australia is actively developing a new nationwide system. The European Central Bank, the Bank of Japan, and several other central banks have also been acting as catalysts to promote real-time payments initiatives. The broad emergence of real-time systems throughout the world reflects the growing demand for such systems, and the need for the payments system to keep up with evolving technology.2\n\nIn the United States, our traditional bank-centric payments system, sometimes operating on decades-old infrastructure, has adjusted slowly to the evolving demands for greater speed and safety. Innovators have built new systems and services that ride on top of the old rails but with mixed results, and over time, our system has grown more fragmented. Our payments system is large and diverse, with a wide array of financial institutions, systems, and service providers; it will take coordinated action to make fundamental and successful nationwide improvements. The Federal Reserve has often helped address problems of this nature by convening stakeholders in the payments system and encouraging them to identify key issues and to work together to make fundamental improvements.\n\nWith this in mind, the Federal Reserve has in recent years been working with a wide range of stakeholders to improve the speed, efficiency, and safety of the U.S. payments system. Significant dialogue and public responses to a consultation paper in 2013 indicated that stakeholders would welcome a broad initiative to work for change. In response, in 2015, the Federal Reserve launched several initiatives including a Faster Payments Task Force and a Secure Payments Task Force.\n\nI spoke about the payments security initiative on another occasion.3 The Secure Payments Task Force has been advancing important work, including outlining ways for the industry to improve payment identity management practices, crafting guidance on standardizing fraud and risk data, and developing a framework for protecting sensitive payment data. You can expect to see the results of these efforts later this year.\n\nToday, however, I will focus on the Faster Payments Task Force. In forming the task force, we committed to an inclusive and transparent approach that would ensure representation of diverse stakeholder interests. The group is comprised of over 300 representatives from financial institutions, technology companies, consumer advocates, and others.4 The role of the task force is to identify and assess alternative approaches for implementing safe, ubiquitous, faster payment capabilities in the United States.\n\nTo support that mission, the task force developed a framework, called the \"Faster Payments Effectiveness Criteria,\" to provide guidance to the wider payments community on the desired attributes of a future payments system. The framework identified 36 \"effectiveness criteria\" that a faster payments system should meet, covering six broad areas: ubiquity, efficiency, safety and security, speed, legal framework, and governance. Task force members and others have widely embraced the effectiveness criteria. Our hope is that the criteria will serve as a lasting blueprint for payments service providers in designing innovative future products.\n\nThe task force also established a process through which its members could submit proposals for faster payments capabilities and have them assessed against the effectiveness criteria by a qualified independent assessment team. The task force encouraged members to submit proposals reflecting both products under development and conceptual designs. There was overwhelming enthusiasm around the process, and the task force ultimately completed reviews of 19 faster payments proposals. Collectively, the proposals represent a broad range of creative and innovative ways to deliver real-time payments. Some are based on current designs and established technology. Others leverage the latest innovative ideas and technologies.\n\nIn 2017, the task force has been working on a final report. Part 1 of the report--the background and motivation for pursuing faster payments--was published in January.5 Part 2 will include the proposals themselves and their assessments, along with task force recommendations for moving the U.S. payments system forward in implementing faster payments. Part 2 will be released around the middle of this year. Until then, the proposals remain confidential to the task force.\n\nThe role of the task force is not to select one or more proposals for implementation, but rather to assess the proposals against the task force criteria. It will be the job of the financial industry to take these proposals forward as they see fit. I strongly encourage the industry and other stakeholders to continue the work of bringing ubiquitous real-time payments systems and services to the U.S. market. It will be important that we keep end users in mind as the new real-time environment evolves, emphasizing inclusion, safety and trust, and consumer education and protections. End users will ultimately determine the success of new payment services and the future direction of faster payments in this country.\n\nDistributed Ledger Technologies\nLet's turn to another type of new technology that may have important implications for the payments and financial systems: distributed ledger technology, or DLT. Bitcoin helped bring this technology to public attention. Using blockchain technology--which employs a form of DLT--and an open architecture, Bitcoin allows for the transfer of value (bitcoins) between participants connected to its ecosystem without reliance on banks or other trusted intermediaries. This feature has led some to predict that DLT will in the long run render parts of the banking and payments system obsolete, as the intermediation of funds through the banking system will become unnecessary.\n\nFaced with these dramatic predictions, we have seen banks and market infrastructures collaborate with technology firms to explore the use and further development of DLT. In 2016, there was widespread experimentation. Efforts by financial institutions often focused on evaluating the technology, identifying potential uses, and conducting proofs of concept. Prominent examples included the use of distributed ledgers to store transactional data and records in tamper-proof ways, as well as the use of the technology as a primary means to hold and transfer money or assets. By the end of 2016, a few major U.S. clearing organizations had announced plans to use distributed ledger technology in limited ways.\n\nAs we have followed developments over the past year, a few lessons have come into better focus.6 First, in contrast to Bitcoin's open architecture, work by the financial industry has focused on the development of \"permissioned\" systems, which establish criteria to determine who is permitted access to particular systems, ledgers, functions, or information. In the near term, this approach seems more likely than fully open systems to provide the needed governance and management to address operational, security, and financial risks. Indeed, access is typically permissioned in situations that require the protection of systems and information in the financial and other industries. Even in permissioned systems, some key issues will remain, including whether finality of settlement is to be determined by a central trusted party or by a majority of participants, and whether participants are able to view information on other parties' transactions. Some argue that movement away from open systems undermines the potential efficiency and the spirit of DLT. At least for now, in payment, clearing, and settlement, safety and confidence must also weigh in the balance.\n\nSecond, firms are still grappling with the business case for upgrading and streamlining payment, clearing, settlement, and related functions with DLT. Promoters of DLT offer a vision of streamlined processes that lead to faster processing, reduced reconciliation, and lower long-run operating costs. Some argue that in certain markets, faster and more predictable processing will also reduce the capital and liquidity costs of operations. But upgrades are often costly, lengthy, and risky, particularly if the technology is still being proven, as is the case for DLT. Network effects can also affect adoption, since multiple firms may all need to adopt a particular implementation of DLT in order to justify its use in a specific market.\n\nThird, technical issues remain. Practical issues such as whether a particular version of DLT will work for the intended purpose are still being explored. Issues of reliability, scalability, and security remain very important. Beyond these issues, standardization and interoperability across different versions of DLT will need to be addressed to allow technology integration and avoid market fragmentation. In general, industry members and technology providers recognize these important issues and have taken initial steps to address problems. It will be important to keep these challenges firmly in mind as we move beyond experimentation and into the development and deployment of new products and processes.\n\nFourth, governance and risk management will be critical. For individual firms or clearing houses that adopt DLT as an internal technology upgrade, the governance and risk-management processes are likely to be internalized within existing organizations and be akin to other technology upgrades. However, if new networks of bilateral payment, clearing, and settlement are established, the new technology may involve tightly coupled protocols and operations. The safety of the overall design will depend on a highly interdependent framework. If automated risk management, smart contracts, and similar tools are deployed across a network, cascades of rapid and hard-to-control obligations and liquidity flows could propagate across a network and the financial system in response to events. This interdependence will likely call for creative organizational thinking to address the need for governance and strong risk management.\n\nFinally, the legal foundations supporting DLT will need attention. Deployments of DLT will involve firms, perhaps in different jurisdictions, with systems that record and transfer information and assets under existing legal frameworks. Which bodies of law apply to the particular firms, assets, and activities will determine the associated rights and responsibilities when transfers are made, cleared, and settled. For example, whether and how banking, payments, securities, or commodities laws apply in a given context are likely to be important in designing systems and services and understanding their properties. And, as with any new technology, things may go wrong. We will need a thorough analysis of how DLT fits into current legal frameworks and what gaps need to be filled by contractual agreements or new laws and regulations. A robust legal basis that provides certainty across relevant jurisdictions is essential for building strong governance, risk management, and operations.\n\nDigital Currencies Issued by Central Banks to the General Public\nMy last topic is the potential use of DLT or other technologies by central banks to issue a digital currency to the general public. In a sense, the idea of a digital currency is merely a 21st century analog of paper currency. While this is a fascinating idea, there are significant policy issues that need to be analyzed.7\n\nFirst, there are meaningful technical challenges. We should have serious reservations about our ability to keep a generally circulating digital currency safe and secure over the long run. A digital currency issued by a central bank would be a global target for cyber attacks, cyber counterfeiting, and cyber theft. The threats could significantly exceed historical experience with paper currency.\n\nA digital currency would also be a prime target as a potential vehicle for global criminal activities, including money laundering. Central banks could face difficult trade-offs between strengthening security and enabling illegal activity. Advanced cryptography could reduce vulnerability to cyber attacks but make it easier to hide illegal activity. To the extent we relax strong cryptography to make it easier for authorities to monitor illegal activity, we could simultaneously weaken security. Growing computer power over time could be used to increase security but could also increase threats.\n\nSecond, privacy issues must be seriously considered. Central banks would have to maintain records of digital currency issuance and might need to maintain records of individual transactions in order to authenticate those transactions and to combat cyber risks and illegal activity. In today's environment, commercial banks maintain extensive records for individual debit and credit card transactions and increasingly monitor patterns of behavior for fraud. Such records in the hands of a central bank or government entity, however, could raise serious privacy concerns by users and might limit public appeal. Again, there may be important trade-offs between privacy and risk.\n\nAny central bank actively considering issuing its own digital currency would need to carefully consider the full range of the payments system and other policy issues, which do seem substantial, as well as the potential societal benefits. To my mind, they should also consider whether the private sector can substantially meet the same needs.\n\nPrivate-sector products and systems already exist or are being developed that will fulfill demands that central-bank-issued digital currencies might otherwise seek to meet. Prepaid cards grew out of the wave of retail payments innovation in the mid-1990s and are now in widespread use. And as I mentioned earlier, new private-sector-led faster payments initiatives are coming. In the United States, a faster payments system that operates around the clock and provides the capability to hold and transfer deposits insured by the Federal Deposit Insurance Corporation in real time would go a long way toward providing the low-risk and flexible payment arrangements that paper currency historically provided. Indeed, I would expect private-sector systems to be more forward leaning than central banks in providing new features to the public through faster payments systems as they compete to attract retail customers. A central bank issued digital currency would compete with these and other innovative private-sector products and may stifle innovation over the long run.\n\nConclusion\nWe live in a time of extraordinary technological change. We should be open to the new ideas and innovations that will drive economic growth and improvements in our financial system. At the same time, the public rightfully expects that authorities will do whatever it takes to keep their money safe. Those of us in the public sector will insist on safety and security, while also working to assure that our citizens benefit from payments system innovation.\n\n1. See Board of Governors of the Federal Reserve System, \"The Federal Reserve Policy on Payment System Risk (PDF)\" (Washington: Board of Governors, 2016). See also Board of Governors of the Federal Reserve System, The Federal Reserve System Purposes & Functions, 10th edition (Washington: Board of Governors, 2016), and Federal Reserve System, \"Strategies for Improving the U.S. Payment System (PDF)\" (Washington: Board of Governors and Federal Reserve System, 2015). Return to text\n\n2. For a broad discussion of international developments and issues in faster payments, see Committee on Payments and Market Infrastructures, \"Fast Payments--Enhancing the Speed and Availability of Retail Payments (PDF)\" (Basel, Switzerland: Bank for International Settlements, November 2016). Return to text\n\n3. See Jerome H. Powell, \"Building a Safer Payment System\" (speech delivered at the Federal Reserve Bank of Kansas City Conference, \"The Puzzle of Payments Security: Fitting the Pieces Together to Protect the Retail Payments System,\" Kansas City, Missouri, June 25, 2015). Return to text\n\n4. Information about the Faster Payments Task Force and the companion Secure Payments Task Force is available at https://fedpaymentsimprovement.org/. Return to text\n\n5. See \"The U.S. Path to Faster Payments, Final Report Part One: The Faster Payments Task Force Approach (PDF),\" Faster Payments Task Force (2017). Return to text\n\n6. See David Mills, Kathy Wang, Brendan Malone, Anjana Ravi, Jeff Marquardt, Clinton Chen, Anton Badev, Timothy Brezinski, Linda Fahy, Kimberley Liao, Vanessa Kargenian, Max Ellithorpe, Wendy Ng, and Maria Baird, \"Distributed Ledger Technology in Payments, Clearing, and Settlement (PDF),\" Finance and Economics Discussion Series 2016-095 (Washington: Board of Governors of the Federal Reserve System, December 2016). Return to text\n\n7. Several of these and additional issues relating to the issuance of digital currencies by central banks are touched on briefly in Committee on Payments and Market Infrastructure, \"Digital Currencies (PDF)\" (Basel, Switzerland: Bank for International Settlements, November 2015). Return to text"
    },
    {
        "title": "Transitions in the Outlook and Monetary Policy",
        "date": "March 01, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170301a.htm",
        "content": "March 01, 2017\n\nGovernor Lael Brainard\n\nAt the John F. Kennedy School of Government, Harvard University, Cambridge, Massachusetts\n\nThe economy appears to be at a transition. We are closing in on full employment, inflation is moving gradually toward our target, foreign growth is on more solid footing, and risks to the outlook are as close to balanced as they have been in some time. Assuming continued progress, it will likely be appropriate soon to remove additional accommodation, continuing on a gradual path.1\n\nAs normalization of the federal funds rate gets further under way, monetary policy too is approaching a transition, prompting increased focus on the balance sheet. How the federal funds rate and the balance sheet should be adjusted individually and in combination depends on the degree to which they are substitutes, their relative precision, and the degree to which their effects on the economy are well understood.\n\nLet me start with the outlook and then turn to policy.\n\nProgress at Home and Abroad\nOver the past several quarters, we have seen improvement in inflation and activity both at home and abroad following a period when the drag on domestic activity from abroad was considerable. Between the middle of 2014 and 2016, a combination of notable fragilities and risks in large foreign economies, elevated sensitivity of the dollar to policy divergence, a sharp decline in oil prices, and financial markets' heightened sensitivity to these downside risks slowed progress in the U.S. economy and the adjustment of monetary policy to an extent few had anticipated. After being an important constraint in the past few years, the external environment currently appears more benign than it has been for some time, even though risks remain.\n\nNear-term risks to the United States from abroad appear to have diminished. Recoveries are gaining traction in China, Europe, and Japan in part reflecting greater confidence in their respective policy environments. The improvement in the global risk outlook was also helped by the continued economic progress and the gradual pace of monetary policy adjustment in the United States last year.\n\nIn recent quarters, market participants appear more confident that China has the will and capacity to maintain its exchange rate regime, while achieving its growth targets, although there is a tension with high credit growth that will eventually need to be addressed. Early last year, China's gross domestic product (GDP) growth, which had averaged nearly 8 percent over the previous five years, was only a little above an annual rate of 5 percent in the first quarter, according to official data, and many observers believe that actual growth was weaker. Relatively large discrete declines in the renminbi against the dollar and a surge in private-sector investment outflows led to considerable volatility in foreign exchange markets and financial markets more broadly.\n\nIn response, Chinese authorities boosted the supply of credit, ramped up fiscal stimulus, initiated new communications regarding the exchange rate, and clamped down on capital outflows. These actions appear to have stabilized growth and calmed fears of financial instability stemming from a sudden large devaluation in the renminbi. GDP growth rebounded to an average annual pace of over 7 percent in the final three quarters of the year. The exchange value of the renminbi has remained relatively constant against the central bank's designated basket of currencies, and it has depreciated against the dollar at a more gradual pace. Capital outflows, while still significant, have moderated.\n\nIn Europe, the recovery has proven to be increasingly resilient. Monetary policy has continued to provide crucial support. As a result, several challenges--including referendums in the United Kingdom and Italy and liquidity and capital stresses faced by German and Italian banks--have so far been navigated without significant damage to growth, financial stability, or inflation expectations. Fiscal policy has ceased being a drag on demand growth and, in some cases, has turned moderately expansionary. Overall euro-area GDP increased at an annual rate of 1-3/4 percent last year, sufficiently in excess of potential output growth to bring the unemployment rate down nearly 1 percentage point. Despite some instances of heightened volatility, financial markets have functioned reasonably well, and risk spreads have stayed contained, although uncertainty about upcoming elections has likely led to some increase in French and Italian sovereign spreads in recent months. Fears of disinflation also appear to have abated: Measures of inflation compensation based on 5-to-10-year-ahead inflation swaps, which fell to 1-1/4 percent in the middle of last year, have recently moved up to 1-3/4 percent.\n\nActivity in Japan has also picked up recently, with GDP increasing 1-1/2 percent last year--noticeably above the estimated rate of potential growth--and the unemployment rate declining 1/4 percentage point to 3 percent, as monetary policy has remained supportive.\n\nOf course, concerns regarding the medium to longer run remain. In China, the price of near-term stability has been an increase in leverage, particularly in the corporate sector. China's overall debt-GDP ratio is elevated for an emerging market economy, especially considering that Chinese growth is likely to slow noticeably in coming years. In Japan, core consumer price inflation is close to zero--well below the central bank's 2 percent target--and scope for additional monetary policy accommodation is limited, leaving the economy vulnerable to adverse demand shocks. In the euro area, growth and inflation may remain low for some time, which could pose challenges for banks with low capital or high amounts of nonperforming loans and for highly-indebted sovereigns. Political events in Europe also raise some uncertainty. Going forward, it will be important to continue to monitor these and other foreign developments carefully.\n\nHere at home, the economy is at a transition. The past few months have seen continued progress in the labor market. Monthly gains in payroll employment have maintained a pace sufficient to continue eroding labor market slack, and wage growth appears to be moving higher on balance. Compensation per hour in the business sector, the most comprehensive measure of wages, increased at a 3 percent pace the past two years, noticeably above the pace earlier in the recovery.\n\nWe appear to be closing in on full employment. The unemployment rate--after remaining relatively flat from the third quarter of 2015 to the third quarter of 2016--fell 1/4 percentage point last quarter to 4-3/4 percent. In addition, the labor force participation rate has been about flat, on net, over the past 2-1/2 years, which indicates considerable ongoing cyclical improvement, given the declining demographic trend. Even so, there may be some room for further improvement. The prime-age employment-to-population ratio remains depressed relative to pre-crisis levels; the share of employees working part time who would prefer full-time work remains elevated; and some measures of wage growth, such as the employment cost index, have increased relatively little in recent years.\n\nMost recently, we are also seeing welcome signs of progress on the second leg of our dual mandate after a protracted period of shortfalls from the FOMC target of 2 percent inflation. Recent months have seen a step-up in longer-run inflation compensation, which had dropped to worrisomely low levels last year raising concerns about a softening of inflation expectations to the downside. Both market- and some survey-based measures of inflation expectations remain somewhat low, but there has been some movement in the right direction in the past few months. Inflation has moved up lately as the effect of past increases in the dollar and declines in energy prices have faded. The 12-month change in headline personal consumption expenditures (PCE) prices was 1.9 percent in January, although this partly reflects a temporary boost from energy prices. Core PCE inflation--which strips out volatile food and energy prices and is a good gauge of future inflation--has also increased. At 1.7 percent in January, the 12-month change is 0.1 percentage point higher than a year ago. Still, core inflation has been below our 2 percent target for almost all of the past eight years, and further progress is necessary to reach and sustain our symmetric inflation goal.\n\nRecent indicators of aggregate spending suggest we will continue to edge closer to our goals in the months ahead. Consumption growth has been encouraging, supported by continued job gains, rising wealth, and greater confidence. Business investment changed little the past two years, but there are currently signs of renewed growth. The contrast with the situation a year ago is sharp. Then, risk spreads on corporate bonds had risen noticeably--often a precursor to downturns--measures of business sentiment were relatively depressed, and corporate profits had declined over 10 percent. In recent quarters, the environment has become more favorable. Risk spreads have moved back down to more normal levels, business sentiment has rebounded, economic profits look to have turned up, and new orders for capital goods are moving higher. The partial rebound in oil prices has also given a boost to drilling activity. However, some crosscurrents could weigh on aggregate demand this year. The recent increases in longer-term interest rates could restrain housing activity as well as other interest-sensitive areas of demand, and some further pickup in the dollar could weigh on net exports and business investment.\n\nRecent months have seen an increase in the upside risks to domestic demand. Sentiment has increased along with equity prices, which are up around 10 percent since October. Increased optimism could lead to faster growth in consumption and business investment, although the spending data, thus far, do not suggest a noticeable acceleration. Some of the increase in sentiment and changes in asset prices could be tied to expectations of more expansive fiscal policy, another upside risk. In addition, the progress that we have made over the past year, with the economy closer to meeting full employment and inflation objectives, has contributed to the favorable shift in the balance of risks. The increase in upside risks to domestic demand and the diminution of foreign risks together suggest that risks to the outlook are more balanced today than they had been for the preceding two years.\n\nNonetheless, the neutral real rate of interest--or the level of the real federal funds rate that is consistent with output growing close to its potential rate with full employment and stable inflation--is expected to remain low both in the near term and in the longer run, and inflation is only slowly recovering from a protracted period of low levels. The nominal neutral interest rate--which adjusts the real neutral rate for the level of inflation--is likely to remain below its historical average even once it reaches its new longer-run normal level. The lower rate environment means there will be less room to cut the federal funds rate, so that if the economy experiences adverse shocks similar in severity and frequency to those in the past the likelihood of returning to and operating near the effective lower bound will remain elevated relative to historical experience. Prudent risk management suggests that policy should take into account the asymmetry in risks posed by the greater likelihood of the economy being at the effective lower bound, where conventional policy is constrained.\n\nWhat about the Balance Sheet?\nGiven the progress we have seen and the positive momentum in the incoming data, continued gradual removal of accommodation is likely to be appropriate. But unlike in previous tightening cycles, the Federal Open Market Committee currently has two tools to remove accommodation: the balance sheet as well as the federal funds rate.\n\nIn December 2015, the Committee indicated that it would continue to reinvest principal payments until normalization of the level of the federal funds rate is \"well under way.\"2 The decision to rely solely on the federal funds rate to remove accommodation initially until normalization is well under way serves an important purpose, in my view.3 With asymmetry in the scope for conventional monetary policy to respond to shocks, there is a benefit to enabling the federal funds rate to rise more quickly than would be possible with a shrinking balance sheet and sooner reach a level that allows for significant reductions if economic conditions deteriorate.4\n\nEven so, recognizing that the median of the Committee projections places the long-run value of the federal funds rate around 3 percent--a very low level by historical standards--some could judge normalization to be well under way before too long. Thus, monetary policy too may be approaching a transition.\n\nOnce the short-term rate is comfortably distant from its effective lower bound, there are broadly two types of policy strategies that could be contemplated. Many central banks around the world may contemplate similar choices in the coming years, while the Bank of Japan has already grappled with these issues in the past.5 One type of \"complementarity\" strategy might actively deploy the balance sheet as an independent second tool, complementary to the short-term rate. Under this strategy, both tools would be actively used to help achieve the Committee's goals. This strategy would seek to take advantage of the ways in which the balance sheet might affect certain aspects of the economy or financial markets differently than the short-term rate. Any differences in effects might derive from the fact that the balance sheet more directly, though not necessarily more precisely, affects term premiums on longer-term securities, while the short-term rate more directly affects money-market rates.\n\nAlthough it may be tempting, in theory, to operate with the balance sheet as a complementary, additional tool to the federal funds rate, we have virtually no experience with how such an approach would work in practice away from the effective lower bound. For that reason, one might instead prefer a \"subordination\" strategy that would prioritize the federal funds rate as the sole active tool away from the effective lower bound, effectively subordinating the balance sheet. Once federal funds normalization meets the test of being well under way, triggering an end to the current reinvestment policy, the balance sheet would be set on autopilot, shrinking in a gradual, predictable way until a \"new normal\" has been reached, and then increasing in line with trend increases in the demand for currency thereafter.6 Under this strategy, the balance sheet might be used as an active tool only if adverse shocks push the economy back to the effective lower bound.\n\nThe case for the subordination strategy is straightforward and compelling. This strategy recognizes that the two policy tools are broadly similar in the ways they affect the economy by indirectly changing the level of interest rates used to finance purchases by households and businesses. These interest rate changes also have effects on asset prices, and thereby on household wealth, as well as on the exchange value of the dollar and, thereby, on net exports and core import prices.7 However, relative to balance sheet policies, the influence of the short-term rate is far better understood and extensively tested: There have been several decades and many business cycles over which to measure and analyze how the federal funds rate affects financial markets and real activity. In contrast, experience using the balance sheet as an active tool has been very limited and largely confined to a highly unusual period around the Global Financial Crisis, when short-term interest rates were constrained by the zero lower bound. Predictability, parsimony, precision, and clarity of communications all would seem to argue in favor of focusing policy on a single active tool that is most familiar. In short, it makes sense to focus policy on the tool whose effects are better understood by both policymakers and the public in circumstances where the tools are largely substitutes for one another.\n\nEven with this subordination strategy, however, there may be limited circumstances in which the balance sheet might be employed in a manner that is supportive of the short-term rate. Most obviously, during the period when the balance sheet is running down, if the economy encounters adverse shocks, it may be appropriate to commence the reinvestment of principal payments again in order to preserve conventional policy space if the federal funds rate were to drop below some threshold level, perhaps similar to the \"well under way\" threshold.\n\nMore broadly, although the two tools can achieve roughly similar effects, they are different, and we cannot rule out that there may be special circumstances in which these differences may be particularly valuable. In particular, these differences may be an important consideration in circumstances when the transmission of changes in the short-term rate to long-term rates and other financial market variables and the real economy is impeded. In addition to directly affecting longer-term interest rates, changes to the balance sheet could serve to reinforce policy communication associated with the short-term rate. Some observers believe that such signaling was an important contributor to the effect of the balance sheet on the economy during and after the Global Financial Crisis.8 Thus, the subordination strategy will likely be appropriate in most circumstances, but we cannot completely rule out special circumstances in which the complementary use of both tools may prove compelling.\n\nAssuming that a subordination strategy is adopted, and the balance sheet is set to shrink passively and predictably once reinvestment ceases or is phased out, there is some uncertainty around the size of the balance sheet when it returns to normal, which the Committee has described as \"no larger than necessary for the efficient and effective implementation of monetary policy.\"\n\nThere are good reasons to expect a normalized balance sheet to be considerably smaller than its current size but larger than its pre-crisis level. Most obviously, trend growth in the demand for currency gradually pushes up the size of the balance sheet over time, but there are also other reasons to expect the post-crisis new normal to be larger than pre-crisis levels. The structural demand for reserves may be considerably larger now than prior to the financial crisis because of a number of changes, including new regulations that favor safe liquid assets and changes in financial institutions' attitudes toward risk.9 If the demand curve for reserve balances has shifted out, then a greater supply of reserves will be needed to attain a given interest rate target. Moreover, the supply of reserves will need to be set far enough above the structural level of demand to accommodate unexpected shocks to the demand and supply of reserves. To accomplish this, the Committee could choose to implement policy by adjusting the supply of reserves to offset such shocks. Or, the Committee could decide to maintain the current floor system, in which a buffer of reserves, sufficient to accommodate any sizable shocks to reserves demand and supply, is maintained, thereby obviating the need for high-frequency adjustments to the supply of reserves. The Committee's normalization principles suggest that any buffer would be the minimum amount needed to efficiently and effectively implement policy.10\n\nBecause of changes in structural and short-term factors since the crisis, it is difficult to know with any precision how low reserves can be allowed to drop while still maintaining effective interest rate control. Thus, as the balance sheet gradually declines, it will be important to carefully monitor money markets for indications that any further reduction in the supply of reserves will begin to put upward pressure on money market rates. At that point, the amount of reserves will likely be close to the minimum amount necessary to satisfy demand at the target rate.11\n\nConclusion\nTo conclude, recent developments suggest that the macro economy may be at a transition. With full employment within reach, signs of progress on our inflation mandate, and a favorable shift in the balance of risks at home and abroad, it will likely be appropriate for the Committee to continue gradually removing monetary accommodation. As the federal funds rate continues to move higher toward its expected longer-run level, a transition in balance sheet policy will also be warranted. These transitions in the economy and monetary policy are positive reflections of the fact that the economy is gradually drawing closer to our policy goals. How the Committee should adjust the size and composition of the balance sheet to accomplish its goals and what level the balance sheet should be in normal times are important subjects that I look forward to discussing with my colleagues.\n\nI am grateful to Jim Clouse and Andrew Figura for their assistance in preparing this text.\n\n1. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. See, for example, Board of Governors of the Federal Reserve System (2017), \"Federal Reserve Issues FOMC Statement,\" press release, February 1. This approach is consistent with the Committee's Policy Normalization Principles and Plans, available on the Board's website at https://www.federalreserve.gov/newsevents/press/monetary/20140917c.htm. Return to text\n\n3. This is the rationale in Lael Brainard (2015), \"Normalizing Monetary Policy When the Neutral Interest Rate is Low,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford, Calif., December 1. Return to text\n\n4. The Bank of England has stated that it is unlikely that it will reduce the size of its balance sheet until the Bank Rate has reached a level of around 2 percent; see Bank of England (2015), Inflation Report (PDF)(London: BOE, November), p. 34. Return to text\n\n5. In 2006, the Bank of Japan reduced the size of its balance sheet by allowing short-term security holdings to run off and without relying on asset sales; see Kazuo Ueda (2010), \"The Bank of Japan's Experience with Non-Traditional Monetary Policy (PDF),\" paper presented at \"Revisiting Monetary Policy in a Low Inflation Environment,\" a conference held at the Federal Reserve Bank of Boston, October 16. Return to text\n\n6. The Committee has indicated that it intends to reduce the Federal Reserve's securities holdings in a gradual and predictable manner primarily by ceasing to reinvest repayments of principal on securities held in the System Open Market Account; see Federal Open Market Committee, Policy Normalization Principles and Plans, in note 2. Return to text\n\n7. There may be differences in the specific ways changes in short-term rates and the balance sheet transmit to different asset prices and the exchange rate, although estimates are limited and lack precision. Return to text\n\n8. See, for example, Michael Woodford (2012), \"Methods of Policy Accommodation at the Interest-Rate Lower Bound (PDF),\" paper presented at \"The Changing Policy Landscape,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 30-September 1. Return to text\n\n9. In addition, the Federal Reserve now remunerates reserve balances held by depository institutions. Return to text\n\n10. For a discussion of floor systems and other frameworks for implementing monetary policy, see the November FOMC minutes, available at Board of Governors of the Federal Reserve System (2016), \"Minutes of the Federal Open Market Committee, November 1-2, 2016,\" press release, November 23. Return to text\n\n11. Some experts have made financial stability arguments in favor of maintaining a level of reserves that is somewhat larger than needed for monetary control alone. In the past, the demand for safe short-term assets has sometimes been met by an increased supply of private-sector short-term debt, which has been associated with increased leverage and maturity and liquidity transformation. Some argue that a greater supply of safe short-term public debt could help prevent these potentially destabilizing developments from occurring. See Robin Greenwood, Samuel G. Hanson, and Jeremy C. Stein (2016), \"The Federal Reserve's Balance Sheet as a Financial-Stability Tool (PDF),\" paper presented at \"Designing Resilient Monetary Policy Frameworks for the Future,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 25-27, and Ben S. Bernanke (2017), \"Shrinking the Fed's Balance Sheet,\" Ben Bernanke's Blog, January 26. Return to text"
    },
    {
        "title": "The Economic Outlook and Monetary Policy",
        "date": "February 22, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170222a.htm",
        "content": "February 22, 2017\n\nGovernor Jerome H. Powell\n\nAt the Forecasters Club of New York Luncheon, New York, New York\n\nThank you for this invitation to speak here today. I will begin by taking stock of the progress of the U.S. economy. I will then discuss longer-term challenges for the economy and wrap up with a discussion of monetary policy. As usual, my comments reflect my own views and not necessarily those of my colleagues on the Federal Open Market Committee (FOMC).\n\nThe Current State of the Economy\nThe Congress has tasked the Federal Reserve with achieving stable prices and maximum employment--the dual mandate. The FOMC has set a longer-term price stability objective of 2 percent annual inflation, as measured by the PCE (personal consumption expenditures) price index.1 This is a symmetric objective, meaning that the Committee would be concerned if inflation were running persistently above or below 2 percent. Until early last year, inflation was running substantially below our 2 percent objective, largely reflecting declines in energy prices during late 2014 and early 2015. However, because prices of energy and food commodities are often volatile, a core measure that excludes these components provides a better indication of where overall inflation is headed. While core inflation has also run consistently below 2 percent in recent years, it has been gradually rising, with the most recent 12-month reading at 1.7 percent, three-tenths higher than a year ago (the black line in figure 1). Market-based measures of inflation compensation have moved well above their lows of mid-2016 but remain below pre-crisis levels, and survey measures have stayed relatively well anchored. Overall, inflation seems to be on track to reach the 2 percent objective over the next couple of years. Although inflation is currently below our objective, core inflation has generally been close to 2 percent over the past 20 years. This outcome reflects the success of monetary policy in anchoring inflation expectations.\n\nMany indicators show that we have also made significant progress toward maximum employment. Since 2010, payroll employment has increased by almost 16 million jobs, and the unemployment rate has fallen from 10 percent to 4.8 percent--in line with most estimates of the longer-run normal level (or natural rate) of unemployment and with the median estimate by FOMC participants in the December 2016 Summary of Economic Projections (SEP). Accordingly, the red line in the figure indicates that the unemployment rate gap has essentially been closed.2\n\nA variety of other measures also suggest that we are close to maximum employment. Surveys of household sentiment about the availability of jobs and of business sentiment regarding the difficulty of filling jobs have now reached levels seen in prior periods of full employment. Moreover, although the pace of wage increases is slower than during pre-crisis periods of full employment, wages have been increasing faster than both output per hour (productivity) and inflation, and labor's share of income has begun to move up after a long decline.\n\nAll in all, we appear to be close to our employment objective, and are nearing our inflation objective. While the pace of progress has at times been frustratingly slow, this outcome is a better one than that achieved by most other advanced economies. Even so, it is worth remembering that the current and future states of the economy are always uncertain, and today is no exception. Our discussions of the economy may sometimes ring in the ears of the public with more certainty than is appropriate. Take the concept of \"maximum employment,\" which requires an estimate of both the natural rate of unemployment for those who are in the labor force and the sustainable level of labor force participation.3 The natural rate of unemployment is not directly observed, and the record suggests that it could be materially lower or higher than current estimates.4 There is also uncertainty about the underlying trend level of labor force participation. Participation has been declining since about 2000 because of the aging of our population and other secular trends, and analysts generally agree that participation will continue to decline over time for these reasons (figure 2). A canonical paper by a group of Fed economists estimates a trend rate of decline of about 0.3 percentage point per year.5 After declining sharply and dipping well below the prior trend in the years following the crisis, participation has been roughly flat since late 2013. Relative to this estimate of the declining trend, three years of flat participation implies a cyclical improvement of roughly 1 percentage point. But there is a range of views on the underlying trend and whether we can expect a bit more near-term cyclical improvement in participation. The Congressional Budget Office estimates that participation is currently 0.7 percentage point below its trend rate, which suggests remaining upside potential. By contrast, other recent work does not find a strong case for a meaningful further slack.6 The issue has important implications, since changes in participation can have material effects on the unemployment rate: Holding the level of employment constant, a 25 basis point change in the participation rate would lead roughly to a corresponding 40 basis point change in the unemployment rate.\n\nLonger-Run Issues\nProductivity and growth\nOur economy is strong and operating near its capacity. But we face important challenges when it comes to the longer-term growth rate of the economy. Long-term economic growth depends mainly on nonmonetary factors such as population growth and workforce participation, the skills and aptitudes of our workforce, the tools at their disposal, and the pace of technological advance. Fiscal and regulatory policies can have important effects on these factors. The main long-run contribution monetary policy can make is to provide a stable macroeconomic and financial environment. The level of potential growth does have important implications for monetary policy.\n\nOne of the surprising features of this expansion has been that 2 percent growth in real gross domestic product (GDP) has been enough to create solid job gains and unexpectedly large declines in unemployment. During much of the recovery, forecasters have been overly optimistic about growth but too pessimistic on job creation and the decline in the unemployment rate. In 2007, the average expectation for long-run GDP growth from the Blue Chip survey of 50 forecasters was 2.9 percent (figure 3). The consensus estimate has moved down steadily since then and is now at 2.1 percent. Other forecasters have also lowered their estimates over time, including those sampled by the Survey of Professional Forecasters and, yes, FOMC participants.7 Yet, as this figure shows, unemployment has declined faster than expected.\n\nMore than the expected number of workers have been required to produce less than the expected amount of output. The implication is that trend productivity and, ultimately, potential growth are lower than expected. The decline in estimates of potential growth has been driven largely by unexpectedly weak productivity growth. Labor productivity has increased only 1/2 percent per year, on average, since 2011--the worst performance over such a period since World War II (figure 4). As this figure shows, productivity growth moves around significantly over time and has averaged about 2 percent since 1970. One factor behind the decline since the financial crisis is the relatively slow increase in the capital stock per worker, as weak demand and uncertainty about the future have held back business investment. But the more important factor has been the marked decline in total factor productivity (TFP), which represents the part of productivity that is not explained by capital increases or increases in the skills of the labor force. TFP is thought to be mainly a function of technological innovation and efficiency gains. The decline in TFP growth has been widespread across advanced economies, suggesting that global trends are at play.8\n\nThere is no consensus about the future direction of productivity growth.9 Some argue that the important paradigm-changing innovations are behind us, while others think that this slowdown is only a passing phase. One thing on which all agree is that the future prospects for productivity growth and potential GDP are highly uncertain. I hope there is also broad agreement on the need for policies that maximize potential growth and spread prosperity as widely as possible. We need policies that encourage labor force participation and investment in education and training, in infrastructure, and in businesses. These policies are, of course, mostly outside the authority of the Federal Reserve.\n\nLow interest rates\nAnother unanticipated feature of this recovery has been the low level of both short- and longer-term interest rates. At 2.4 percent, the yield on the 10-year Treasury is far below levels typically seen before the financial crisis (figure 5). Of course, Fed policy is a factor in holding down longer-term yields. But longer-term rates have been declining for more than 30 years, for several reasons. Much of the decline is due to significantly lower long-term expectations of inflation, as well as reduced term premiums, likely reflecting both lower inflation risk and the fact that, with anchored inflation expectations, nominal bonds have become an attractive hedge against market risk. Regulatory changes have raised demand for safe assets. Lower potential growth implies lower returns and therefore lower rates. Changes in savings and investment demand owing to demographics and other factors have put downward pressure on yields as well.\n\nAs a result, the real federal funds rate that is neither contractionary nor expansionary when the economy is operating near its potential--the so-called neutral real rate or r*--has declined significantly. We cannot directly observe the neutral rate but can only infer it from the evolution of the economy--it \"is seen by its works.\"10 The neutral rate changes significantly over time, and estimates of its level entail substantial uncertainty.11 Before the crisis, the longer-run neutral real rate was generally thought to be roughly stable at around 2.25 percent. Since the crisis, estimates have declined steadily. For example, the median estimate implied by FOMC participants stood at 1.0 percent in the December 2016 SEP. Many analysts believe that the neutral rate is even lower than that today and will only return to its longer-run value over time.12 One important implication is that today's low rates are not as stimulative as they may seem--consider that, despite historically low rates, inflation has run consistently below target.\n\nMonetary Policy amid Uncertainty\nI'd like to turn now to monetary policy. I expect the economy to continue broadly along its current path, which implies further labor market tightening and inflation edging closer to 2 percent. On this path, unemployment would decline modestly below current estimates of the natural rate and remain there for some time. I see that as a desirable outcome and do not see data suggesting that we are behind the curve. In recent years, the economy has faced significant downside risks, particularly from weak global conditions. The Committee has been quite patient, and I believe that has served us well. But risks now seems to me to be more in balance. Going forward, I see it as appropriate to gradually tighten policy as long as the economy continues to behave roughly as expected. As always, the actual path could be faster or slower than expected and will depend on developments in the economy.\n\nBefore concluding, I would like to turn briefly to a discussion of how policy decisions are made, including the role of simple monetary policy rules. Since the 1990s, central banks have grown ever more communicative about their monetary policy decisions. A central tenet that underlies this increase in transparency is that monetary policy is more effective when the public understands how the central bank will respond to changing conditions, and can calibrate expectations accordingly.13 That means that the Committee must have a clearly communicated, systematic way of responding to changes in economic conditions and the outlook. In that spirit, the FOMC takes a forward-looking approach to policymaking, whereby each policy decision the FOMC makes is grounded not just in current assessments of the economy but also in expectations for how the economy will evolve relative to our goals. Individual participants develop their own forecasts of the economy's evolution. The Committee then makes a collective decision, embodied in the postmeeting statement, setting monetary policy to achieve those goals.14 Over time, incoming information and shocks to the economy inevitably alter views of the appropriate path for monetary policy. One way of seeing this is through the SEP forecasts of individual FOMC participants. These forecasts tend to converge over time to the Committee's 2 percent inflation objective and to each individual's interpretation of maximum employment, because each individual explicitly writes down a path for policy that is intended to achieve those outcomes. Accordingly, revisions to the projections tend to show up in the path for the federal funds rate that each individual sees as appropriate to achieve those objectives.15\n\nIn preparing for FOMC meetings, policymakers routinely review alternative policy paths prescribed by several simple policy rules that are in wide usage.16 Decades of research have produced many variations of these rules, which are typically derived from differing but valid insights and which yield different rate paths. For example, economists at the Federal Reserve Bank of Cleveland regularly update on the Bank's website an analysis of seven different rules and their prescriptions.17\n\nA good way to see the range of possibilities is through a generalized form of a Taylor-type rule (figure 6).18 As you can see, this rule is based on key factors for monetary policy, such as the neutral real rate of interest, or r*, and deviations of inflation and output or unemployment from their longer-run values. While these are often called \"simple\" rules, application of a rule requires a significant number of important choices. It is necessary to pick a value or a path for r*. The rule also calls for an estimate of the output or unemployment rate gap. There is particularly high uncertainty about measuring the deviation of output from its potential; our real-time estimates of this gap are often revised substantially in hindsight. To reduce that uncertainty, we often use the unemployment gap rather than the output gap in these rules.19 We also need to pick values for the coefficients a and b, whether they are the values John Taylor posited in his seminal 1993 article or other values from the vast literature that has come since.20\n\nThere are still other choices to make. Traditional policy rules are backward looking in the sense that they use available data about inflation and output. But monetary policy needs to be forward looking, as I discussed, and there are rules that rely on forecasts of inflation and output. Finally, many have advanced the view that, when times are particularly uncertain, monetary policy should react cautiously to incoming information.21 That insight leads to rules that incorporate inertia, thereby slowing down the movement of rates over time. Each of these insights has some validity, and each has important implications for the prescriptions of a policy rule.\n\nFigure 7 shows the prescriptions of three simple policy rules since 2000.22 While the rules often diverged, all of them called for a substantial reduction in the federal funds rate around the time of the financial crisis, and all of them prescribed easing well below the effective lower bound (ELB).23 Faced with the impossibility of providing more accommodation at the ELB through deeply negative policy rates, the Committee turned instead to two unconventional monetary policy tools--large-scale securities purchases and forward guidance.\n\nFigure 8 shows the Taylor (1993) rule for different values of r* layered over the \"dots\" from the December 2016 SEP, with a black horizontal line at the median value for each year.24 The red solid line shows the rule prescriptions when the intercept is set equal to 2 percent, as in Taylor's original formulation. If we replace that intercept with the median of the longer-run r* from the December 2016 SEP, which is 1 percent (the blue dashed line), we see that the rule prescribes policy interest rates lower than the unadjusted rule. However, many observers believe that the neutral real interest rate is currently well below its longer-run value. The language that has appeared in the Committee's postmeeting statement since December 2015 that \"the federal funds rate is likely to remain, for some time, below levels that are expected to prevail in the longer run\" is consistent with this view. Some estimates put the current value of r* close to zero, which leads to the purple dashed-dotted line in figure 8.25\n\nFigure 9 provides prescriptions from the policy rules shown in figure 7 that vary along dimensions other than the neutral real rate. The first-difference rule shown by the purple dashed-dotted line incorporates forecasts by prescribing changes to the federal funds rate based on projected inflation relative to its objective and the projected change in the output gap.26 The insight behind this rule is that it does not require estimates of the neutral real rate or the level of the output gap.27 The green dashed line shows the policy prescription from an inertial version of the \"balanced approach\" rule with an intercept of 1 percent, which includes a lagged value of the nominal interest rate.28 This rule does not go as far as the first-difference rule in eliminating the level of r* from the policy prescription, but it does prescribe that policy move only slowly toward its longer-run level, which places less weight in the short-run on the estimate of r*. This rule prescription is closer to FOMC participants' assessments of appropriate monetary policy. Although many FOMC participants believe that r* has fallen, they also believe that it will rise toward a longer-term level of 1 percent over time, and the better fit of the inertial rule in part captures this assessment.\n\nI would offer several takeaways from this overview. There is general agreement that these simple policy rules do provide interesting and useful insights into policy. To gain the benefit of those insights, it is helpful to look at a range of rules. But there is no consensus that any one rule is best, let alone that it would be desirable to require the FOMC to pick and mechanically follow one rule to the exclusion of others.29\n\nSimple rules also leave out critical considerations for the path of policy. One such consideration of great importance is that, with the secular decline in interest rates over the past 35 years, policy is now far more likely to hit the ELB than had been thought, which may present severe challenges. Research suggests that, as a precautionary matter, policy should be more aggressive in providing accommodation as rates move closer to the ELB.30 But there is no consensus today on whether or how to incorporate ELB-related risks into a simple policy rule of the type that I have discussed here. Another such consideration is that simple policy rules include no consideration of financial stability. But monetary policy may sometimes face tradeoffs between macroeconomic objectives and financial stability. Recent business cycles show that instability can emerge when inflation is under control. Some have argued for inclusion of a financial stability term into policy rules, but the issue is far from settled.31\n\nTo conclude, I think it's fair to say that simple policy rules are widely thought to be both interesting and useful, but to represent only a small part of the analysis needed to assess the appropriate path for policy. I am unable to think of any critical, complex human activity that could be safely reduced to a simple summary equation. In particular, no major central bank uses policy rules in a prescriptive way, and it is hard to predict the consequences of requiring the FOMC to do so, as some have proposed. Policy should be systematic, but not automatic.\n\n \n\n1. See the FOMC's Statement on Longer-Run Goals and Monetary Policy Strategy, available in Board of Governors of the Federal Reserve System (2017), Monetary Policy Report (PDF) (Washington: Board of Governors, February). Return to text\n\n2. Figure 1 reports the unemployment rate gap using the Congressional Budget Office (CBO) estimates because they extend further back in time than projections from the SEP. The CBO's estimate of the natural rate for 2017 is 4.7 percent. Return to text\n\n3. The labor force is made up of people who have jobs as well as people who are jobless but are looking for a job and are available to work. See Bureau of Labor Statistics, \"Labor Force Participation,\" webpage (accessed February 17, 2017). Return to text\n\n4. Confidence intervals around statistical estimates of the natural rate are routinely estimated to be quite wide, reflecting both uncertainty about the correct model specification as well as uncertainty about the parameter estimates given the model. The canonical paper by Staiger, Stock, and Watson puts the 95 percent confidence interval at 1-1/2 percentage points on either side of the point estimate. See Douglas Staiger, James H. Stock, and Mark W. Watson (1997), \"How Precise Are Estimates of the Natural Rate of Unemployment?\" in Christina D. Romer and David H. Romer, eds., Reducing Inflation: Motivation and Strategy (Chicago: University of Chicago Press). Return to text\n\n5. See Stephanie Aaronson, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014), \"Labor Force Participation: Recent Developments and Future Prospects (PDF),\" Brookings Papers on Economic Activity, Fall, pp. 197-275. Return to text\n\n6. See Congressional Budget Office (2017), The Budget and Economic Outlook: 2017 to 2027 (PDF) (Washington: CBO, January); and Alan B. Krueger (2016), \"Where Have all the Workers Gone? (PDF)\" paper presented at the Federal Reserve Bank of Boston's 60th Economic Conference, held at the Federal Reserve Bank of Boston, Boston, October 4. Return to text\n\n7. The history of longer-run forecasts for real GDP growth from the SEP is shown in figure 4 of Jerome H. Powell (2016), \"A View from the Fed,\" speech delivered at the Brookings Institution, Washington, November 30. Return to text\n\n8. There may also be a role for homegrown factors, such as the decrease in business dynamism. See Jerome H. Powell (2016), \"Recent Economic Developments, Monetary Policy Considerations, and Longer-Term Prospects,\" speech delivered at the Chicago Council on Global Affairs, Chicago, June 28. The worldwide nature of the slowdown is documented in Organisation for Economic Co-operation and Development (2016), \"New OECD Indicators Trace Productivity Growth Slowdown Pre- and Post-Crisis,\" webpage, OECD. For a discussion of the effects of dynamism on productivity, see Lucia Foster, John Haltiwanger, and C.J. Krizan (2001), \"Aggregate Productivity Growth: Lessons from Microeconomic Evidence,\" in Charles R. Hulten, Edwin R. Dean, and Michael J. Harper, eds., New Developments in Productivity Analysis (Chicago: University of Chicago Press). Return to text\n\n9. On the pessimistic end of the spectrum are analysts such as Robert J. Gordon (2016), The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War (Princeton, N.J.: Princeton University Press). Among the optimists are Erik Brynjolfsson and Andrew McAfee (2014), The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies (New York: W.W. Norton & Company). Return to text\n\n10. See John H. Williams (1931), \"The Monetary Doctrines of J. M. Keynes,\" Quarterly Journal of Economics, vol. 45 (August), pp. 547-87. Return to text\n\n11. See Jerome H. Powell (2016), \"Discussion of the Paper 'Language after Liftoff: Fed Communication Away from the Zero Lower Bound,'\" speech delivered at the 2016 U.S. Monetary Policy Forum, New York, February 26. See also Michael Feroli, David Greenlaw, Peter Hooper, Frederic Mishkin, and Amir Sufi (2016), \"Language after Liftoff: Fed Communication Away from the Zero Lower Bound,\" paper presented at the 2016 U.S. Monetary Policy Forum, a conference sponsored by the University of Chicago Booth School of Business, held in New York, February 26. Return to text\n\n12. See, for example, Kathryn Holston, Thomas Laubach, and John C. Williams (2016), \"Measuring the Natural Rate of Interest: International Trends and Determinants (PDF) ,\" Federal Reserve Bank of San Francisco Working Paper Series 2016-11 (San Francisco: Federal Reserve Bank of San Francisco, August); Benjamin K. Johannsen and Elmar Mertens (2016), \"The Expected Real Interest Rate in the Long Run: Time Series Evidence with the Effective Lower Bound,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, February 9); and Michelle Bongard and Benjamin K. Johannsen (2016), \"The Neutral Rate and the Summary of Economic Projections,\" FEDS Notes (Washington: Board of Governors of the Federal Reserve System, November 28). Return to text\n\n13. See Michael Woodford (2001), \"Monetary Policy in the Information Economy (PDF),\" paper presented at \"Economic Policy for the Information Economy,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., Aug. 30-Sept. 1, pp. 297-370; and Alan S. Blinder, Michael Ehrmann, Marcel Fratzscher, Jakob De Haan, and David-Jan Jansen (2008), \"Central Bank Communication and Monetary Policy: A Survey of Theory and Evidence,\" Journal of Economic Literature, vol. 46 (December), pp. 910-45. Return to text\n\n14. See Janet L. Yellen (2017), \"The Economic Outlook and the Conduct of Monetary Policy,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford, Calif., January 19. Return to text\n\n15. The SEP is not a \"consensus\" forecast of the Committee, and the interest rate projections in the SEP are each individual participant's assessment of appropriate monetary policy. Thus, the Committee's forward-looking approach to policymaking is not the same as the forecast-targeting approach advocated by Svensson (2005) and others. See Lars E.O. Svensson (2005), \"Monetary Policy with Judgment: Forecast Targeting,\" International Journal of Central Banking, vol. 1 (June), pp. 1-54. Return to text\n\n16. For another discussion of simple rules and their role in the Committee's policy process, see Stanley Fischer (2017), \"I'd Rather Have Bob Solow Than an Econometric Model, But...,\" speech delivered at the Warwick Economics Summit, Coventry, United Kingdom, February 11. Return to text\n\n17. See Federal Reserve Bank of Cleveland (2017), \"Simple Monetary Policy Rules,\" webpage, Federal Reserve Bank of Cleveland. Return to text\n\n18. See John B. Taylor and John C. Williams (2010), \"Simple and Robust Rules for Monetary Policy,\" in Benjamin M. Friedman and Michael Woodford, eds., Handbook of Monetary Economics, vol. 3 (Amsterdam: Elsevier), pp. 829-59. Return to text\n\n19. In general, the unemployment rate is more informative of the state of the business cycle than GDP because of the difficulties in estimating potential output. See Charles A. Fleischman and John M. Roberts (2011), \"From Many Series, One Cycle: Improved Estimates of the Business Cycle from a Multivariate Unobserved Components Model (PDF),\" Finance and Economics Discussion Series 2011-46 (Washington: Board of Governors of the Federal Reserve System, October). Return to text\n\n20. See John B. Taylor (1993), \"Discretion versus Policy Rules in Practice,\" Carnegie-Rochester Conference Series on Public Policy, vol. 39 (December), pp. 195-214. Return to text\n\n21. See William Brainard (1967), \"Uncertainty and the Effectiveness of Policy,\" American Economic Review, vol. 57 (May), pp. 411-25. In discussing the effects of uncertainty on monetary policy, Blinder (1998, p. 11) notes that policymakers \"should compute the direction and magnitude of their optimal policy move...and then do less.\" See Alan S. Blinder (1998), Central Banking in Theory and Practice (Cambridge, Mass.: MIT Press). Others have suggested that inertia may be a feature of making decisions by committee; see Clare Lombardelli, James Proudman, and James Talbot (2005), \"Committees versus Individuals: An Experimental Analysis of Monetary Policy Decision Making,\" International Journal of Central Banking, vol. 1 (June), pp. 181-205; and Francisco Ruge-Murcia and Alessandro Riboni (forthcoming), \"Collective versus Individual Decision-making: A Case Study of the Bank of Israel Law,\" European Economic Review. Return to text\n\n22. These are static simulations and do not incorporate feedback from the policy rule to real activity or inflation. Return to text\n\n23. Ben Bernanke finds that a \"balanced approach\" rule estimated using real-time data closely tracks the federal funds rate from 1996 through 2008. See Ben S. Bernanke (2015), \"The Taylor Rule: A Benchmark for Monetary Policy?\" Ben Bernanke's Blog, April 28. Return to text\n\n24. Figure 2 of the SEP provides each individual FOMC participant's assessment of \"appropriate monetary policy\" in the form of a dot plot. \"Appropriate monetary policy\" is defined as the future path of policy that each participant deems most likely to foster outcomes for economic activity and inflation that best satisfy his or her individual interpretation of the Federal Reserve's objectives of maximum employment and price stability. The policy prescriptions are derived using the median projections for core PCE price inflation, the unemployment rate, and the longer-run normal unemployment rate from the December 2016 SEP. Return to text\n\n25. See Kathryn Holston, Thomas Laubach, and John C. Williams (2016), \"Measuring the Natural Rate of Interest: International Trends and Determinants (PDF),\" Finance and Economics Discussion Series 2016-073 (Washington: Board of Governors of the Federal Reserve System, September). Return to text\n\n26. Orphanides (2003) proposed a rule that sets changes in the nominal interest rate equal to deviations in nominal income growth relative to target, ΔR = β [ (π + Δy) -(π* + Δy*) ], where y is real GDP. The forecast-based version employed here substitutes the change in the unemployment gap for the change in the output gap (using an Okun's law coefficient of 2) and sets β to 0.5, yielding ΔR = 0.5 (π-π*) -Δu. When implemented using forecasts, inflation is the 4-quarter inflation rate 3 quarters ahead, and Δu is the 4-quarter change in the unemployment rate 3 quarters ahead. See Athanasios Orphanides (2003), \"Historical Monetary Policy Analysis and the Taylor Rule,\" Journal of Monetary Economics, vol. 50 (July), pp. 983-1022. Return to text\n\n27. While the natural rate of interest may be changing over time and the first-difference rule does not take these changes into account, Orphanides and Williams (2007) argue that rules like the first-difference rule can deliver good economic performance even when there is uncertainty about those changes. See Athanasios Orphanides and John C. Williams (2007), \"Robust Monetary Policy with Imperfect Knowledge,\" Journal of Monetary Economics, vol. 54 (July), pp. 1406-35. Return to text\n\n28. Chair Yellen has called this rule the \"balanced-approach\" rule. See Janet L. Yellen (2012), \"Perspectives on Monetary Policy,\" speech delivered at the Boston Economic Club Dinner, Boston, June 6. This rule has also been considered by others. For example, see John B. Taylor (1999), \"A Historical Analysis of Monetary Policy Rules,\" in John B. Taylor, ed., Monetary Policy Rules (Chicago: University of Chicago Press), p. 319-341. Return to text\n\n29. Eisenhardt and Sull proposed the use of simple rules by corporations. See Kathleen M. Eisenhardt and Donald Sull (2001), \"Strategy as Simple Rules,\" Harvard Business Review, January. Among the companies they site positively as having employed simple rules were Enron, AOL, and Yahoo. Return to text\n\n30. See Charles Evans, Jonas Fisher, Francois Gourio, and Spencer Krane (2015), \"Risk Management for Monetary Policy Near the Zero Lower Bound (PDF),\" Brookings Papers on Economic Activity, BPEA Conference Draft, March 19-20. Return to text\n\n31. See Tobias Adrian and Nellie Liang (2014), \"Monetary Policy, Financial Conditions, and Financial Stability (PDF),\" Federal Reserve Bank of New York Staff Reports 690 (New York: Federal Reserve Bank of New York, September; revised December 2016). Return to text\n\n31. See Tobias Adrian and Nellie Liang (2014), \"Monetary Policy, Financial Conditions, and Financial Stability (PDF),\" Federal Reserve Bank of New York Staff Reports 690 (New York: Federal Reserve Bank of New York, September; revised December 2016). Return to text"
    },
    {
        "title": "\"I'd Rather Have Bob Solow Than an Econometric Model, But ...\"",
        "date": "February 11, 2017",
        "speaker": "Vice Chairman Stanley Fischer",
        "url": "https://www.federalreserve.gov/newsevents/speech/fischer20170211a.htm",
        "content": "February 11, 2017\n\nVice Chairman Stanley Fischer\n\nAt the Warwick Economics Summit, Coventry, United Kingdom\n\nIntroduction: Econometric Models and a Eureka Moment\nEureka moments are rare in all fields, not least in economics.1 One such moment came to me when I was an undergraduate at the London School of Economics in the 1960s. I was talking to a friend who was telling me about econometric models. He explained that it would soon be possible to build a mathematical model that would accurately predict the future course of the economy. It was but a step from there to realize that the problems of policymaking would soon be over. All it would take was a bit of algebra to solve for the policies that would produce the desired values of the target variables.\n\nIt was a wonderful prospect, and it remains a wonderful idea. But it has not yet happened. I want to talk about why not and about some of the consequences for policymaking.\n\nHow the Fed Makes Monetary Policy\nLet me begin with how we make monetary policy at the Fed. The Federal Reserve System has both centralized and regional characteristics. The System comprises the Board of Governors, located in Washington, D.C., and 12 regional Reserve Banks in cities across the United States (Figure 1). The members of the Board of Governors are appointed by the President, subject to confirmation by the U.S. Senate. In contrast, the president of each Reserve Bank is selected by that Reserve Bank's board of directors, subject to the approval of the Board of Governors. This scheme was designed both to insulate the Federal Reserve from day-to-day political pressures and to ensure that all parts of the country have a voice in the central bank.\n\nOur monetary policy committee--the Federal Open Market Committee (FOMC)--meets eight times a year at the Federal Reserve Board in Washington to make decisions about whether to change the short-term policy rate and other aspects of monetary policy.2 Sitting around the massive conference table will be the policymakers of the Fed--the members of the Board of Governors and the 12 Reserve Bank presidents. The Board has a maximum of seven members, but at present, two slots are empty. All of the Federal Reserve Bank presidents take part in the discussion, although only five of them have the vote at any one time.3 \n\nEach Board member or Reserve Bank president has his or her own way of preparing for those meetings. In the case of the Reserve Bank presidents, these preparations can include consultations with their boards of directors, business contacts in their Districts, market experts, and other sources. Written materials are distributed to all FOMC participants in advance of the meeting.4 The most extensive of these materials is called the Tealbook, a two-part document prepared by the Board's staff and distributed to Board members and Reserve Bank presidents.5 \n\nThe first part of the Tealbook contains a summary and analysis of recent economic and financial developments in the United States and foreign economies, the Board staff's economic forecast, and dozens of tables and figures. The Board staff's baseline forecast of the most likely path for the economy over the next several years is a judgmental one, built by staff economists using their expertise on particular sectors together with econometric models and other inputs.\n\nIn addition to this baseline judgmental forecast, the staff provides model-based simulations of a number of alternative scenarios or risks--for instance, if the price of oil were to be lower, the U.S. dollar stronger, or wage growth higher than envisioned in the baseline projection. These scenarios are generated using one or more of the Board's macroeconomic models. The Tealbook also includes computations of policy paths derived from a range of policy rules and model-based estimates of optimal policy. That is to say, before our FOMC meetings, we examine analyses and forecasts produced by our staff as well as empirical results from a range of models--and, of course, material that each participant in the FOMC has gathered from his or her own research and experience.\n\nThe second part of the Tealbook includes the specific policy options that we consider at the meeting. Typically, there are three policy alternatives--A, B, and C--ranging from dovish to hawkish, with a centrist one in between. This part of the Tealbook includes an analysis of each alternative and a draft of the associated public statement that the FOMC would release after the conclusion of its meeting.\n\nFour times a year, before the March, June, September, and December FOMC meetings, Board members and Reserve Bank presidents submit their own projections for real gross domestic product (GDP) growth, the unemployment rate, inflation, and the Committee's policy rate target, the federal funds rate. These forecasts are released to the public shortly after the FOMC meeting in the Summary of Economic Projections (SEP), and they receive a good deal of scrutiny by financial market participants and journalists.6 \n\nOne important but underappreciated aspect of the SEP is that its projections are based on each individual's assessment of appropriate monetary policy. Each FOMC participant writes down what he or she regards as the appropriate path for policy. They do not write down what they expect the Committee to do.7 Yet the public often misinterprets the interest rate paths we write down as a projection of the Committee's policy path or a commitment to a particular path.\n\nModels and the Modeling of Monetary Policy\nNow, that is a lot of talk about the process of monetary policymaking. Let me turn to some of the machinery behind that process--in particular, to macroeconomic models and their role in assisting the FOMC's decisionmaking. The Board staff maintains several models; I will focus on the FRB/US model, the best known and most used of the models the Board staff has at its disposal.8 FRB/US is an estimated, large-scale, general-equilibrium, New Keynesian model.9 \n\nEach of the adjectives is noteworthy, so I will briefly cover each in order. First, for models to be of use to guide monetary policy, they need to be estimated such that they do a reasonable job of fitting the data; only under such circumstances can their quantitative predictions be taken as useful.10 Of course, they do not fit the data perfectly. The economy is an extremely complicated mechanism, and every macroeconomic model is a vast simplification of reality.\n\nSecond, the large scale of FRB/US is an advantage in that it can perform a wide variety of computational \"what if\" experiments. It is often the case that two macroeconomic phenomena happen at the same time--an increase in the value of equity shares and an appreciation of the dollar, for example--and it is an obvious benefit if the combination of the two can be analyzed within the same modeling framework.11 \n\nThird, the general-equilibrium structure of the model is also important: It is helpful to be able to understand, for example, if a hypothetical appreciation of the dollar might have something to do with an increase in equity share values or whether an independent causal force is at work. Finally, the New Keynesian nature of the model implies that wages and prices are sticky and that markets adjust slowly to their longer-run equilibria.\n\nMuch of the usefulness of the FRB/US model stems from its careful modeling of the monetary transmission mechanism and the key role that the expectations of households, workers, firms, and investors play in that mechanism. The monetary policy transmission mechanism is the means through which changes in a central bank's policy instrument affect the economy. In the FRB/US model, the usual policy instrument--the federal funds rate--plays no direct role in the economy.12 Rather, an increase in the federal funds rate affects expectations of future values of that rate, which in turn affect interest rates on longer-term bonds, equity prices, and the exchange value of the U.S. dollar.13 Households and firms are forward looking in that the adjustment costs just mentioned oblige households to set out a plan--a contingency plan--for consumption, savings, and employment for the future. Increases in interest rates influence these plans, as they do the investment and hiring plans of firms. All of those decisions, in turn, shape employment, output, and inflation.\n\nSo the expectations of decisionmakers, be they households, firms, or investors, are at the center of how monetary policy works--both in the real world and in FRB/US. At the same time, the economy is subject to economic shocks that perturb the plans of economic agents and alter their expectations, as well as the plans and expectations of policymakers. The role of monetary policymakers is to respond to economic shocks in as efficient a manner as possible, and thereby influence economic outcomes and expectations, in order to achieve the central bank's assigned goals. Indeed, the conduct of monetary policy is often described as a matter of expectations management.14 \n\nHow might policymakers best respond to economic disturbances and influence expectations in order to achieve their policy objectives? To help FOMC policymakers answer that question, the Tealbook for each meeting provides monetary policy prescriptions from a variety of simple policy rules, including John Taylor's famous rule (or family of rules).15 Economic conditions and the outlook change from meeting to meeting, and, not surprisingly, the prescriptions of simple policy rules change with them.\n\nThe Tealbook from the April 2011 meeting provides an example of the role of policy rules in the FOMC's discussions. The reason I focus on a meeting so long ago is that materials from FOMC meetings in 2011--including the transcripts and Tealbooks--have recently been released to the public, following the usual five-year lag.16 \n\nAt the time of the April 2011 meeting, the federal funds rate had been near zero for almost 2-1/2 years; moreover, the FOMC had been indicating in its post-meeting statements that it expected to keep the funds rate target at exceptionally low levels \"for an extended period.\"\n\nFigure 2 reproduces panels from the April 2011 Tealbook that show the staff's baseline forecast--the solid black line--as well as prescriptions from three simple policy rules that were generated using the FRB/US model.17 The panel on the left shows the paths for the federal funds rate, while the panels on the right show the implications of those policy prescriptions for the unemployment rate and core PCE (personal consumption expenditures) price inflation, respectively.18 \n\nEach of the rules is regarded as mainstream. Note that there are substantial differences in the prescribed policy paths, both in terms of how long the interest rate remains near zero as well as how gradual or rapid is the pace of tightening once the interest rate begins to increase. Those differences produce different outcomes for unemployment and inflation, as can be seen in the two panels on the right of figure 2.\n\nThe first-difference rule is the most hawkish in figure 2: It raises the federal funds rate more rapidly than the other three rules whose results are shown. Correspondingly, in the panels to the right of figure 2, the unemployment rate is higher on the broken green line than on the other paths for unemployment that are associated with lower interest rates. And you can figure out why the broken green line for core PCE inflation is lower than for the other paths in the panel on the right-hand side of figure 2.\n\nHow does the FOMC choose its interest rate decision? Fundamentally, it uses charts like those shown in figure 2 as an important input into the discussion. And in their discussion, members of the FOMC explain their policy choices, and try to persuade other members of the FOMC of their viewpoints.\n\nOne Monetary Policy Decision: August 2011\nAs an example of such a process, I want to discuss the important decision taken at the August 2011 meeting. At the time policymakers gathered in Washington for the meeting, the FOMC's target for the federal funds rate had been set to nearly zero for more than 2-1/2 years. And although the economy had improved from the depths of the Great Recession, the unemployment rate was still above 9 percent.\n\nOver the summer, the economic outlook darkened considerably. In response, in August, the staff's Tealbook forecast projected that the federal funds rate would remain near zero three quarters longer than what the staff had expected in June. Figure 3, taken from the August 2011 Tealbook, illustrates how the change in the economic outlook affected FRB/US simulations of optimal monetary policy.19 As you know, an optimal policy is a path for the policy instrument that minimizes the shortfalls in economic outcomes relative to policymakers' goals; in this case, the optimal policy path is computed using the FRB/US model and takes the staff's baseline outlook as given.20 In principle, optimal policy simulations deliver better outcomes than simple policy rules, but those outcomes are conditional on some strong assumptions.21 \n\nThe black line in figure 3 shows the optimal policy path in the August 2011 Tealbook conditional on interest rates being constrained to remain above zero. Comparing the black line with its counterpart from the Tealbook prepared for the previous FOMC meeting in June--the red dotted line--you can see that the date at which the policy rate was expected to rise above zero had moved out by about a year. Even an optimal policy path (the blue dashed line) that was not constrained by the zero lower bound--and was therefore infeasible--did not cross into positive territory until mid-2014. Thus, the prescriptions of optimal policy were saying not only that the Committee's interest rate should remain at zero for some time to come, but also that that period of time should be considerably longer than previously thought.\n\nAt the August 2011 FOMC meeting, most members agreed that the economic outlook had deteriorated by enough to warrant a response. Some of them judged that additional stimulus was called for because they thought the economy would not get back to full employment without it.22 These policymakers argued that a strengthening of the language in the Committee's post-meeting statement about how long they expected the federal funds rate to remain exceptionally low would be appropriate. They judged that this response would influence expectations and thus longer-term interest rates, and would help the public understand the Committee's intentions.23 \n\nThe change that was proposed, and eventually adopted, replaced the phrase that characterized how long the Committee expected the federal funds rate would remain low‑‑\"for an extended period\"‑‑with \"at least through mid-2013.\" As shown in figure 4, this subtle but important change in language in the FOMC's post-meeting statement induced a decline in interest rates across the term structure.\n\nHow was the decision to change the forward-guidance language reached? Ultimately, the decision required the adept leadership of Chairman Ben Bernanke, lengthy deliberations of Board members and Reserve Bank presidents, and staff briefings and forecasts. The decision was a joint product, reflecting the experience of policymakers and the implicit or explicit models or views of the world they had brought with them to the FOMC table, statistical models, an understanding of historical episodes that offered instructive and relevant parallels, and other information gleaned from the outside world.\n\nAnd what do I take from this episode? The interest rate decision taken in August 2011 was unusual in that a decision was made about the likely path of future interest rates. Most often, the FOMC is deciding what interest rate to set at its current meeting. Either way, in reaching its decision, the Committee will examine the prescriptions of different monetary rules and the implications of different model simulations. But it should never decide what to do until it has carefully discussed the economic logic that underlies its decision. A monetary rule, or a model simulation, or both, will likely be part of the economic case supporting a monetary policy decision, but they are rarely the full justification for the decision. Sometimes a monetary policy committee will make a decision that is not consistent with the prescriptions of standard monetary rules--and that may well be the right decision. Further, in modern times, the policy statement of the monetary policy committee will seek to explain why the committee is making the decision it is announcing. The quality of those explanations is a critical part of the policy process, for good decisions and good explanations of those decisions help build the credibility of the central bank--and a credible central bank is a more effective central bank.\n\nThe Bottom Line\nAs the August 2011 meeting illustrates, the eureka moment I thought I had 50‑plus years ago was a chimera. Why is that? First, the economy is very complex, and models that attempt to approximate that complexity can sometimes let us down. A particular difficulty is that expectations of the future play a critical role in determining how the economy reacts to a policy change. Moreover, the economy changes over time--this means that policymakers need to be able to adapt their models promptly and accurately in real time. And, finally, no one model or policy rule can capture the varied experiences and views brought to policymaking by a committee. All of these factors and more recommend against accepting the prescriptions of any one model or policy rule at face value.\n\nAnd now to the bottom line: The title of my speech is an incomplete quotation of something Paul Samuelson once said. What Samuelson said was this, \"I'd rather have Bob Solow than an econometric model, but I'd rather have Bob Solow with an econometric model than without one.\" And Samuelson, who was a shameless eclectic, would almost certainly have said essentially the same thing about policy rules.\n\nThank you.\n\nReferences\nBernanke, Ben S. (2007). \"Inflation Expectations and Inflation Forecasting,\" speech delivered at the Monetary Economics Workshop of the National Bureau of Economic Research Summer Institute, Cambridge, Mass., July 10.\n\nBrayton, Flint, Eileen Mauskopf, David Reifschneider, Peter Tinsley, and John Williams (1997). \"The Role of Expectations in the FRB/US Macroeconomic Model (PDF),\" Federal Reserve Bulletin, vol. 83 (April), pp. 227-45.\n\nBrayton, Flint, Thomas Laubach, and David Reifschneider (2014a). \"The FRB/US Model: A Tool for Macroeconomic Policy Analysis,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, April 3.\n\n-------- (2014b). \"Optimal-Control Monetary Policy in the FRB/US Model,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, November 21.\n\nDuke, Elizabeth A. (2010). \"Come with Me to the FOMC,\" speech delivered at the Money Marketeers of New York University, New York, October 19.\n\nHendry, David F., and Michael P. Clements (2004). \"Pooling of Forecasts,\" Econometrics Journal, vol. 7 (1), pp. 1-31.\n\nReifschneider, David, Robert Tetlow, and John Williams (1999). \"Aggregate Disturbances, Monetary Policy, and the Macroeconomy: The FRB/US Perspective (PDF),\" Federal Reserve Bulletin, vol. 85 (January), pp. 1-19.\n\nSvensson, Lars E.O., and Robert J. Tetlow (2005). \"Optimal Policy Projections,\" International Journal of Central Banking, vol. 1 (December), pp. 177-207.\n\nTaylor, John B. (1993). \"Discretion versus Policy Rules in Practice,\" Carnegie-Rochester Conference Series on Public Policy, vol. 39, pp. 195-214.\n\nYellen, Janet L. (2012). \"Revolution and Evolution in Central Bank Communications,\" speech delivered at the Haas School of Business, University of California, Berkeley, Berkeley, Calif., November 13.\n\n-------- (2017). \"The Economic Outlook and the Conduct of Monetary Policy,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford University, Stanford, Calif., January 19.\n \n\n1. I am grateful to Ellen Meade and Robert Tetlow of the Federal Reserve Board staff for their assistance. Views expressed are mine and not necessarily those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. For example, the FOMC has discussed unconventional monetary policies (large-scale asset purchases and forward guidance), its plans for the withdrawal of monetary policy accommodation and reducing the size of the Federal Reserve's balance sheet (termed \"normalization\"), and the operational framework used to implement monetary policy. Return to text\n\n3. The president of the Federal Reserve Bank of New York has a permanent vote on the FOMC, and 4 of the remaining 11 Reserve Bank presidents serve one-year terms on a rotating basis. Return to text\n\n4. For additional details on the preparations for and organization of FOMC meetings, see Duke (2010). Return to text\n\n5. Before June 2010, the Tealbook was two separate books known as the Greenbook and the Bluebook, corresponding roughly to the first and second parts of the Tealbook, respectively. Return to text\n\n6. The SEP was introduced in 2007 and expanded on forecasts that FOMC participants had already been making twice each year since 1979 in the Monetary Policy Report prepared for the Congress. Since 2011, the Federal Reserve Chair has held a press conference following each FOMC meeting with an SEP, in part to discuss the projections. Return to text\n\n7. \"Appropriate monetary policy\" is Fedspeak for a policy that delivers on the Committee's interpretation of its legislated mandate. The fact that FOMC participants' forecasts are conditional on each participant's conception of the appropriate monetary policy has at least three noteworthy implications. First, it means that their forecasts will tend to converge over time to the Committee's 2 percent inflation objective and to each individual's interpretation of maximum employment. Second, revisions to the SEP tend to manifest themselves in the path for the federal funds rate deemed to be appropriate to achieve those objectives. And third, the paths for the federal funds rate that deliver on those objectives will often differ from one participant to the next. Return to text\n\n8. In addition to the FRB/US model, Board staff maintain EDO, a dynamic stochastic general equilibrium (DSGE) model of the U.S. economy, and SIGMA, a multicountry DSGE model. Staff members at the Reserve Banks also maintain and use a number of DSGE models. Information on the FRB/US model, the EDO model, and the SIGMA model is available on the Board's website at, respectively, https://www.federalreserve.gov/econresdata/frbus/us-models-about.htm, https://www.federalreserve.gov/econresdata/edo/edo-models-about.htm, and https://www.federalreserve.gov/pubs/ifdp/2005/835/ifdp835r.pdf. Return to text\n\n9. One reason why the FRB/US model is well known is that it is in the public domain and is regularly updated for public use, including the provision of a database that is constructed using the median projections from the most recent SEP. See Brayton, Laubach, and Reifschneider (2014a) for a broad description of the model and Reifschneider, Ttlow, and Williams (1999) for a description and explanation of model properties. Brayton and others (1997) provides an accessible summary of the role and importance of expectations formation in the FRB/US model. Return to text\n\n10. The FRB/US model is unfashionable by current academic standards in that it is not a DSGE model. The difference that is relevant in this context is that the empirical fit of FRB/US is allowed to show through more explicitly because the modeling structure of the model is less restrictive than with a DSGE model. Even so, FRB/US has limitations, which it shares with other models of its class, including a relatively primitive financial sector with no theoretically grounded determination of term premiums. Return to text\n\n11. Of course, it is also advantageous to solicit from several models the implications of a particular macroeconomic phenomenon of interest. For this reason, among others, the staff across the Federal Reserve System builds and maintains a number of models. Return to text\n\n12. In this speech, I do not talk about the effects of so-called unconventional monetary policies--balance sheet policies, forward guidance, and the like--except to note that many of the same elements of the monetary policy transmission mechanism are in force when the central bank uses such policies; in particular, expectations formation continues to play a key role. Return to text\n\n13. There is also an effect on term premiums, which influence Treasury bond rates and, in turn, the rates on other financial instruments. Return to text\n\n14. Bernanke (2007) discusses the role the central bank plays in managing inflation expectations. Return to text\n\n15. See Taylor (1993). Return to text\n\n16. I was not a member of the Board of Governors or the FOMC in 2011. The materials associated with FOMC meetings in 2011 are available on the Board's website at https://www.federalreserve.gov/monetarypolicy/fomchistorical2011.htm. Return to text\n\n17. The three rules are the Taylor (1993) rule, the Taylor (1999) rule (also known as the \"balanced approach rule\"), and the first-difference rule. The Taylor (1993) rule is\nR=\nr\n∗\n+π+0.5⋅(π−\nπ\n∗\n)+0.5⋅y\n, where\nR\nis the nominal federal funds rate;\nr\n∗\nis the equilibrium real interest rate;\nπ\nis the four-quarter PCE price inflation rate;\nπ\n∗\nis the inflation objective, 2 percent; and\ny\nis the output gap, defined as the percentage difference between actual GDP and potential GDP. The Taylor (1999) rule is identical to the Taylor (1993) rule except that the coefficient of 0.5 on the output gap is replaced by a coefficient of 1.0; see Yellen (2017) for a brief discussion. The first-difference rule is\nR=\nR\nt−1\n+0.50⋅(\nπ\nt+3|t\n−\nπ\n∗\n)+0.5⋅\nΔ\n4\ny\nt+3|t\n, where\nΔ\n4\nrepresents a four-quarter change in the variable that follows and\nt+j|t\nindicates the\nj\n-period-ahead forecast of the variable that precedes, given information that is available at date\nt\n. The first-difference rule is seen as a robust alternative to other simple rules because it does not rely on estimates of the natural rate of interest or the level of potential GDP. The appendix to the April 2011 Tealbook provides details on each of these rules. Return to text\n\n18. In the end, the unemployment rate and inflation did not turn out to be greatly different from what is shown in figure 2, although the shocks borne by the economy required a more accommodative stance of policy to bring about those outcomes. For an explanation of how the FOMC interprets its statutory goals, see the Statement on Longer-Run Goals and Monetary Policy Strategy,\" which the Committee first issued in January 2012 and reaffirms each year. The 2016 statement is available on the Board's website at https://www.federalreserve.gov/newsevents/press/monetary/20160127b.htm. Return to text\n\n19. I rely on optimal policy simulations here because the August 2011 Tealbook did not include a figure like that shown in figure 2. Return to text\n\n20. More formally, optimal policies are the solution to an optimal control problem in which a search procedure is used to solve for the path of the federal funds rate that minimizes the value of an assumed loss function, conditional on a baseline outlook and on allowing for feedback of differences in the federal funds rate from its baseline to real activity and inflation. See, for example, Svensson and Tetlow (2005). For a concise description of its computation in conjunction with the FRB/US model, see Brayton, Laubach, and Reifschneider (2014b); for an exposition of the use of optimal control, see Yellen (2012). Return to text\n\n21. Optimal policy simulations assume that policymakers do not doubt their model or the baseline outlook. In addition, the particular optimal policy shown in figure 3 is known as a \"commitment policy,\" meaning that it is assumed that policymakers can bind themselves and future committees to follow the strategy--but not necessarily the precise policy rule prescriptions--that comprises the optimal plan. The restrictiveness of these assumptions is one reason why optimal policy simulations are best considered in conjunction with other forms of policy advice such as prescriptions from simple rules. Return to text\n\n22. At the time of the August meeting, total PCE price inflation on a 12-month basis was running above the Committee's 2 percent objective, boosted by transitory factors that were expected to dissipate; the staff forecast was for inflation to slow to 1.5 percent in 2012. Return to text\n\n23. A few policymakers believed that recent economic developments justified a more substantial move, but they were willing to accept the stronger forward-guidance language as a useful step. However, a few other policymakers preferred to leave the statement unchanged, citing a variety of reasons, including that weakness in the real economy largely reflected nonmonetary factors; that the economic situation had improved since the Committee had undertaken its second large-scale asset purchase program in November 2010, and no additional monetary accommodation was appropriate; and that the reference to 2013 might be misinterpreted as suggesting that monetary policy was no longer contingent on how the economic outlook evolved. Return to text\n\n "
    },
    {
        "title": "The Economic Outlook and the Conduct of Monetary Policy",
        "date": "January 19, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20170119a.htm",
        "content": "January 19, 2017\n\nChair Janet L. Yellen\n\nAt the Stanford Institute for Economic Policy Research, Stanford University, Stanford, California\n\nWatch live\n\nIt is a privilege to be here today to discuss how the Federal Reserve is conducting monetary policy to promote a healthy economy. For more than 30 years, research from the Stanford Institute for Economic Policy Research has informed economic policy, and events such as this one have helped foster debate among scholars, policymakers, business leaders, and members of the public on critical economic issues facing our nation. I appreciate the opportunity to participate.\n\nIn my remarks today, I will review the considerable progress the economy has made toward the attainment of the two objectives that the Congress has assigned to the Federal Reserve--maximum employment and price stability. The upshot is that labor utilization is close to its estimated longer-run normal level, and we are closing in on our 2 percent inflation objective. I will then discuss the prospects for adjusting monetary policy in the manner needed to sustain a strong job market while maintaining low and stable inflation. Determining how best to adjust the federal funds rate over time to achieve these objectives will not be easy. For that reason, in the balance of my remarks, I will discuss some considerations that will help inform our decisions, including the guidance provided by simple policy rules. I will conclude by touching on some key uncertainties affecting the outlook.\n\nProgress to Date\nMy assessment of progress to date will begin with the labor market. Since the depths of the Great Recession, about 15-1/2 million jobs have been added to the U.S. economy, on net. In 2016, job gains averaged about 180,000 per month, well above the pace of 75,000 to 125,000 per month that is probably consistent with keeping the unemployment rate stable over the longer run.1 The unemployment rate is now close to estimates of its longer-run normal level, and other measures of labor utilization have improved appreciably. As shown in figure 1, a broader measure of labor underutilization--the U-6 measure, which includes not only the unemployed but also people working part time who would like full-time employment and those who would like a job but are not actively looking--has retraced nearly all of the steep run-up that occurred as a result of the recession.2\n\nOther indicators also support the view that the labor market has largely recovered from the severe downturn that occurred in the wake of the financial crisis. As illustrated by the red dashed line in figure 2, the quits rate--an indicator of workers' confidence about leaving an existing job to pursue new opportunities--is nearly back to its pre-recession level. And some indicators, such as small businesses' assessments of the difficulty of hiring, shown by the solid black line, as well as the average length of time it takes firms to fill vacancies and the job openings rate, even suggest that the labor market is a bit tighter than before the financial crisis. Of course, both the labor force participation rate and the employment-to-population ratio are still much lower than they were a decade ago. But the cyclical element in these declines looks to have largely disappeared, and what is left seems to mostly reflect the aging of the population and other secular trends.3 Based on this array of labor market indicators, I judge labor utilization to be reasonably close to its normal longer-run level while also recognizing that estimates of the sustainable levels of the unemployment rate and the employment-to-population ratio are inherently imprecise.4\n\nIn the coming months, I expect some further strengthening in labor market conditions as the economy continues to expand at a moderate pace--a view that is shared by most of my colleagues on the Federal Open Market Committee (FOMC).5 Overall economic growth has been driven by consumer spending, which has been bolstered by substantial gains in household income and wealth. Business investment, in contrast, has been soft. But recent readings on business sentiment and new orders for equipment are consistent with the view that capital spending will likely strengthen modestly this year; another positive factor is that oil drilling, which plummeted after oil prices fell sharply back in late 2014, has recently begun to pick up. As we look to broader trends, gross domestic product (GDP) growth has been restrained in recent years by a variety of forces depressing both supply and demand, including slow labor force and productivity growth, weak growth abroad, and lingering headwinds from the financial crisis. Although I am cautiously optimistic that some of these forces will abate over time, I anticipate that they will continue to restrain overall growth over the medium term, likely holding down the level of interest rates consistent with stable labor market conditions.\n\nTurning to inflation, we are now much closer to the FOMC's 2 percent objective than we were just a year ago. Prices, as measured by the index for personal consumption expenditures (PCE), rose nearly 1-1/2 percent in the 12 months ending in November, as compared with only 1/2 percent during 2015. Moreover, core PCE inflation--a better indicator of the underlying inflation trend--picked up 1/4 percentage point, to a little over 1-1/2 percent. This rise in inflation was anticipated and largely represents a fading of the effects of earlier declines in energy prices and the prices of non-energy imports. In addition, slack in labor and product markets is no longer placing downward pressure on inflation, in contrast to the situation only a few years ago when the unemployment rate was still quite elevated. Barring future major swings in oil prices and the foreign exchange value of the dollar, inflation is likely to move up to 2 percent over the next couple of years, aided by a strong labor market.\n\nIn light of the progress that has been achieved toward our employment and inflation objectives and the Committee's assessment of the outlook, the FOMC raised the target range for the federal funds rate at its December meeting by 25 basis points, to between 50 and 75 basis points. The Committee judges, however, that the stance of monetary policy remains modestly accommodative, and so policy should support some further strengthening in labor market conditions and thus the return of inflation to our 2 percent goal.\n\nMaintaining Sustainable Growth in a Context of Price Stability\nWith the unemployment rate near its longer-run normal level and likely to move a bit lower this year, a natural question is whether monetary policy has fallen behind the curve. The short answer, I believe, is \"no.\" It is true that many employers report difficulties in finding qualified workers in selected occupations, and that more workers are comfortable quitting jobs to take or look for better positions. But this is to be expected in a healthy labor market and not evidence that the economy as a whole is experiencing a serious worker shortage.\n\nThe recent behavior of wages provides additional evidence pertaining to the degree of labor market slack. As shown in figure 3, increases in average hourly earnings, the employment cost index, and compensation per hour remain subdued, picking up only modestly of late.6 Again, these data do not seem consistent with an overheated labor market. Moreover, signs of overheating in the broader economy are also scarce. For example, capacity utilization in the manufacturing sector is well below its historical average. Most importantly, although core inflation is rising gradually from a low level, this increase mainly reflects the waning of the effects of earlier movements in the dollar, not upward pressure from resource utilization.\n\nOf course, even if the labor market is not overheated currently, one might worry that overheating could rapidly emerge as labor market conditions strengthen further, causing inflation to surge. I consider this unlikely for several reasons. First, the pace of labor market improvement has slowed appreciably in the past couple of years: For example, average payroll gains moderated from 250,000 per month in 2014 to 180,000 last year, and the unemployment rate declined 1-3/4 percentage points cumulatively over 2014 and 2015, compared with only 1/4 percentage point last year.7 Second, economic growth more broadly seems unlikely to pick up markedly in the near term given the ongoing restraint from weak foreign demand and other factors that I mentioned, particularly in an environment in which monetary policy is likely to become gradually less accommodative. Finally, figure 4 illustrates the relationship over the past several decades between labor market pressures and core inflation. Note that during periods when the unemployment rate fell below the Congressional Budget Office's estimate of its normal long-run level, shown by the yellow shaded regions, core inflation, the solid red line, rose little, if at all. This stability is especially marked since inflation expectations became anchored during the mid-to-late 1990s.8\n\nThat said, I think that allowing the economy to run markedly and persistently \"hot\" would be risky and unwise. Waiting too long to remove accommodation could cause inflation expectations to begin ratcheting up, driving actual inflation higher and making it harder to control. The combination of persistently low interest rates and strong labor market conditions could lead to undesirable increases in leverage and other financial imbalances, although such risks would likely take time to emerge.9 Finally, waiting too long to tighten policy could require the FOMC to eventually raise interest rates rapidly, which could risk disrupting financial markets and pushing the economy into recession. For these reasons, I consider it prudent to adjust the stance of monetary policy gradually over time--a strategy that should improve the prospects that the economy will achieve sustainable growth with the labor market operating at full employment and inflation running at about 2 percent.\n\nEvaluating the Appropriate Stance of Monetary Policy\nAchieving these goals could prove challenging, however, even if the economy manages to avoid being hit with adverse shocks over the next few years. To sustain a strong job market with inflation at our 2 percent objective, policy must gradually shift toward a neutral stance, where \"neutral\" is defined as a level of the federal funds rate that is neither expansionary nor contractionary when the economy is operating near its potential. But what level of the federal funds rate is neutral at the present time? How quickly should the funds rate target move up to this neutral level? And how will the neutral rate itself evolve over time?\n\nTo help answer such questions, the FOMC considers a voluminous amount of information concerning many factors, including financial markets and credit availability, labor market conditions and overall economic activity, wages and prices, and foreign economic developments. The FOMC also evaluates forecasts from a range of economic models, assessments of key risks to the outlook, and detailed analyses of how different monetary policy strategies would affect projected outcomes and risks. Among the strategies routinely considered by the Committee are the recommendations of a variety of simple monetary policy rules. In addition, FOMC participants prepare individual projections on a quarterly basis of the most likely paths of key macroeconomic variables under their own assessments of \"appropriate monetary policy,\" together with their estimates of the normal longer-run values of the federal funds rate, the unemployment rate, and GDP growth.10Armed with this wealth of information, the Committee as a whole then decides on the most appropriate policy action to adopt at each of its meetings. Such a comprehensive, forward-looking approach to policymaking is similar to that employed at other central banks.11\n\nFigure 5 shows a plot of FOMC participants' most recent assessments of the appropriate path for the federal funds rate through 2019. The black solid lines show the median value of the federal funds rate at the end of each year. To understand the considerations that likely underlay these judgments, I will contrast participants' assessments with the recommendations of some simple policy rules commonly used to help gauge the appropriate stance of policy. As I noted, the Committee routinely reviews policy recommendations from a variety of benchmark rules, and I believe that their prescriptions can be helpful in providing broad guidance about how the federal funds rate should be adjusted over time in response to movements in real activity and inflation. That said, I will emphasize that the use and interpretation of such prescriptions require careful judgments about both the measurement of the inputs to these rules and the implications of the many considerations the rules do not take into account.\n\nConsider first the well-known Taylor rule, which embodies key principles of good monetary policy. The rule calls for systematic adjustments in the federal funds rate relative to its expected longer-run neutral level in response to movements in inflation and the output gap, defined as the percentage difference between actual output and the economy's productive potential.12 To implement the rule, one must decide on the appropriate definition and measurement of its inputs. Should inflation be defined using the latest noisy quarterly reading on headline PCE inflation or a measure intended to smooth through transitory price movements? What technique should be used to approximate the output gap, given that different approaches often yield materially different estimates? And what assumption should be made about the neutral value of the federal funds rate in the longer run?\n\nThe Taylor rule is often implemented by assuming that the real, or inflation-adjusted, value of the longer-run neutral interest rate--which I will call R* for convenience--is equal to 2 percent, roughly the average historical value of the real federal funds rate prior to the financial crisis. For inflation, we can use the 12-month change in core PCE prices, a measure of the current underlying rate of inflation. And the output gap can be reasonably approximated as twice the difference between the estimated longer-run normal rate of unemployment and the actual unemployment rate.13 The dashed red line in figure 5 shows the resulting recommendations for policy over the medium term, based on the medians of the unemployment and inflation projections submitted by FOMC participants in December but assuming--in contrast to the median of participants' December assessments--that R* equals 2 percent. As figure 5 shows, this version of the Taylor rule prescribes a much higher path for the federal funds rate than the median of participants' assessments of appropriate policy.\n\nOne important factor explaining this divergence is the FOMC's growing recognition that the longer-run neutral level of the real federal funds rate has likely declined below 2 percent, contrary to what is often assumed in implementations of the Taylor rule. As illustrated by the left-hand panel of figure 6, since 2000, both FOMC participants and respondents to the Blue Chip survey have markedly reduced their projections of the level of real short-term interest rates expected to prevail in the longer run. Presumably, these revisions were made in response to accumulating evidence that lower real interest rates than those seen on average in the past would be needed permanently to keep the economy operating on an even keel. In addition, the right-hand panel shows considerable changes over time in estimates of the normal longer-run rate of unemployment, with corresponding implications for estimates of the economy's productive potential and the output gap. Such revisions would imply shifts in the level of the Taylor rule's prescriptions by as much as 1-1/4 percentage points, holding other factors constant.14 Clearly, sensible implementation of policy rules requires adjustments to take such changes into account, as a failure to do so would result in poor monetary policy decisions and poor economic outcomes.15\n\nFigure 7 illustrates the policy implications of alternative revised assessments of the longer-run neutral real rate of interest. As before, the short-dashed red line shows the prescriptions of the Taylor rule using the standard 2 percent assumption for R*. The solid red line, however, shows the rule's prescriptions with R* equal to 1 percent, the median of the longer-run projections of the real federal funds rate made by FOMC participants last month. This adjustment appreciably reduces the rule's policy prescriptions.\n\nEven with this downward adjustment of the longer-run neutral rate, however, the Taylor rule's prescriptions are arguably still too restrictive. The problem is that the rule ignores the likelihood that it will likely take many years before the forces now restraining the economy dissipate to the degree envisioned in participants' estimates of the longer-run normal level of the real federal funds rate. Because overall growth has been quite moderate over the past few years despite an accommodative stance of monetary policy, some recent estimates of the current value of the neutral real federal funds rate stand close to zero.16 If the neutral rate were to remain quite low over the medium term, as would be expected if the global economy does not materially strengthen and productivity growth remains anemic, then the appropriate setting for R* in the Taylor rule would arguably be zero, yielding a yet lower path for the federal funds rate, as shown by the long-dashed red line. These considerations illustrate that there is now no obvious \"right\" setting for R* because we do not know how rapidly the forces restraining the economy will abate, and there is a significant risk that it could be very slow. When the economy has been hit with unusually persistent shocks, the Taylor rule, for this reason, provides a problematic benchmark.\n\nSimple policy rules also typically neglect information with potentially important implications for the economic outlook because they focus only on where conditions are today. For example, simple rules ignore such important factors as fiscal policy, trends affecting global growth, structural developments influencing the supply of credit, and overall financial conditions. One special factor at the moment pertains to the Federal Reserve's balance sheet. The downward pressure on longer-term interest rates that the Fed's asset holdings exert is expected to diminish over time--a development that amounts to a \"passive\" removal of monetary policy accommodation. Other things being equal, this factor argues for a more gradual approach to raising short-term rates.17\n\nLastly, simple rules ignore important risk-management considerations that have influenced the Committee's decisions in recent years. With the federal funds rate still near zero, the Committee recognizes that, should the economy unexpectedly weaken in the next year or two, there would likely be only limited scope to respond by lowering short-term rates. But if the economy instead began to overheat, threatening to push inflation to an undesirably high level, the FOMC would have ample scope to respond through tighter monetary policy. Such asymmetric risks arguably call for a more gradual path of rate increases than indicated by the prescriptions of a simple policy rule.\n\nThe academic literature on policy rules has studied many alternatives to the Taylor rule, and the FOMC regularly reviews a number of them.18 These rules embed differing but valuable perspectives, and there is no consensus among central bankers or academics about the relative utility of various rules. One such alternative is the \"balanced approach\" rule, illustrated by the purple short-dashed line in figure 8. This rule differs from the Taylor rule by being twice as responsive to movements in resource utilization.19 The prescriptions of the balanced-approach rule in this figure, as with the solid red Taylor-rule plot, assume that R* equals 1 percent, consistent with the medians of the latest FOMC projections. Because participants on average anticipate a modest undershooting of the unemployment rate below its estimated longer-run level, the balanced-approach rule calls for a slightly faster pace of tightening over the next several years than the Taylor rule.\n\nFigure 8 also reports results for a \"change\" rule, shown as the green long-dashed line. As its name implies, this rule does not prescribe a particular level of the federal funds rate at a given time but rather how the existing rate should change from quarter to quarter based on two gaps--the difference between inflation and its desired level as well as the difference between the unemployment rate and its longer-run normal level.20 In contrast to the other two rules, the change rule does not take a stand on the value of the longer-run neutral level of the real federal funds rate, thus avoiding a potential source of error. Instead, it moves interest rates up and down until both gaps close, an approach that in theory enables it to perform well when the true value of R* is unknown. Because both gaps are relatively modest at the moment and are projected to remain so, the change rule calls for fairly gradual adjustments in the stance of monetary policy over the next few years given the current outlook.\n\nThe FOMC, for reasons that I have discussed, does not base its decisions on the prescriptions of any specific policy rule. Nevertheless, the three benchmarks I have described--the Taylor rule, the balanced-approach rule, and the change rule, appropriately calibrated--have historically provided useful guidance about appropriate adjustments in the general direction of monetary policy over time. This guidance is illustrated by figure 9, which compares the path of the federal funds rate since 2000 with the prescriptions of the three rules, based on the actual rates of inflation and unemployment observed at each point in time, along with contemporaneous Blue Chip projections of the longer-run unemployment rate and R*.\n\nAs the figure shows, the rules clearly signaled that a major reduction in the federal funds rate was appropriate in 2008 given the marked deterioration in economic conditions. In addition, all three rules signaled that monetary policy needed to provide more stimulus during the recession and the subsequent recovery than could be provided by keeping short-term interest rates near zero. For this reason, the Committee turned to asset purchases to help make up for the shortfall by putting additional downward pressure on longer-term interest rates. The FOMC also sought to compensate for its inability to push the federal funds rate below zero by indicating that the funds rate would need to stay unusually low for longer than would otherwise be expected and simple policy rules would prescribe.21 Under this \"make up\" strategy, and taking into account the reasons for deviating from the Taylor rule that I discussed a moment ago, the Committee kept the federal funds rate near zero for longer than two of the rules would have prescribed. But as labor market conditions continued to improve over time, the rising trajectories for the federal funds rate prescribed by all three rules signaled that the time was drawing near to begin gradually reducing monetary accommodation. Consistent with this advice, the FOMC suspended its asset purchase program in mid-2014 and began raising the federal funds rate in late 2015.22\n\nTo sum up, simple policy rules can serve as useful benchmarks to help assess how monetary policy should be adjusted over time. However, their prescriptions must be interpreted carefully, both because estimates of some of their key inputs can vary significantly and because the rules often do not take into account important considerations and information pertaining to the outlook. For these reasons, the rules should not be followed mechanically, since doing so could have adverse consequences for the economy.\n\nConclusion\nMy remarks have focused on the policy trajectory that the Committee now considers likely to be appropriate to sustain the economic expansion while keeping inflation close to our 2 percent goal. In concluding, it is important to emphasize the considerable uncertainty that attaches to such assessments and the need to constantly update them.\n\nIn particular, the path of the neutral federal funds rate, which plays an important role in determining the appropriate policy path, is highly uncertain. For example, productivity growth is a key determinant of the neutral rate, and while most forecasters expect productivity growth to pick up from its recent unusually slow pace, the timing of such a pickup is highly uncertain. Indeed, there is little consensus among researchers about the causes of the recent slowdown in productivity growth that has occurred both at home and abroad.23 The strength of global growth will also have an important bearing on the neutral rate through both trade and financial channels, and here, too, the scope for surprises is considerable. Finally, I would mention the potential for changes in fiscal policy to affect the economic outlook and the appropriate policy path. At this point, however, the size, timing, and composition of such changes remain uncertain.24 However, as this discussion highlights, the course of monetary policy over the next few years will depend on many different factors, of which fiscal policy is just one.\n\nReferences\nAaronson, Stephanie, Tomaz Cajner, Bruce Fallick, Felix Galbis-Reig, Christopher Smith, and William Wascher (2014). \"Labor Force Participation: Recent Developments and Future Prospects (PDF),\" Brookings Papers on Economic Activity, Fall, pp. 197-255.\n\nBrynjolfsson, Erik, and Andrew McAfee (2014). The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies. New York: W.W. Norton.\n\nDecker, Ryan A., John Haltiwanger, Ron S. Jarmin, and Javier Miranda (2016). \"Declining Business Dynamism: What We Know and the Way Forward,\" American Economic Review, vol. 106 (May), pp. 203-07.\n\n--------- (forthcoming). \"Where Has All the Skewness Gone? The Decline of High-Growth (Young) Firms in the U.S.,\" European Economic Review.\n\nEngen, Eric M., Thomas Laubach, and David Reifschneider (2015). \"The Macroeconomic Effects of the Federal Reserve's Unconventional Monetary Policies (PDF),\" Finance and Economics Discussion Series 2015-005. Washington: Board of Governors of the Federal Reserve System, January.\n\nFernald, John, and Bing Wang (2015). \"The Recent Rise and Fall of Rapid Productivity Growth (PDF),\" FRBSF Economic Letter 2015-04. San Francisco: Federal Reserve Bank of San Francisco, February 9.\n\nGolden, Lonnie (2016). Still Falling Short on Hours and Pay: Part-Time Work Becoming the New Normal (PDF), Economic Policy Institute. Washington: EPI, December.\n\nGordon, Robert J. (2016). The Rise and Fall of American Growth: The U.S. Standard of Living since the Civil War. Princeton, N.J.: Princeton University Press.\n\nHolston, Kathryn, Thomas Laubach, and John C. Williams (2016). \"Measuring the Natural Rate of Interest: International Trends and Determinants (PDF),\" Finance and Economics Discussion Series 2016-073. Washington: Board of Governors of the Federal Reserve System, August.\n\nIhrig, Jane, Elizabeth Klee, Canlin Li, Brett Schulte, and Min Wei (2012). \"Expectations about the Federal Reserve's Balance Sheet and the Term Structure of Interest Rates (PDF),\" Finance and Economics Discussion Series 2012-57. Washington: Board of Governors of the Federal Reserve System, July.\n\nLi, Canlin, and Min Wei (2013). \"Term Structure Modeling with Supply Factors and the Federal Reserve's Large-Scale Asset Purchase Programs,\" International Journal of Central Banking, vol. 9 (March), pp. 3-39.\n\nNechio, Fernanda, and Glenn D. Rudebusch (2016). \"Has the Fed Fallen behind the Curve This Year? (PDF)\" FRBSF Economic Letter 2016-33. San Francisco: Federal Reserve Bank of San Francisco, November 7.\n\nReifschneider, David L., and John C. Williams (2000). \"Three Lessons for Monetary Policy in a Low-Inflation Era,\" Journal of Money, Credit and Banking, vol. 32 (4), 936-66.\n\nSvensson, Lars E.O. (2005). \"Monetary Policy with Judgment: Forecast Targeting,\" International Journal of Central Banking, vol. 1 (May), pp. 1-54.\n\nTaylor, John B. (1993). \"Discretion versus Policy Rules in Practice,\" Carnegie-Rochester Conference Series on Public Policy, vol. 39, pp. 195-214.\n\n--------- (1999). \"A Historical Analysis of Monetary Policy Rules,\" in John B. Taylor, ed., Monetary Policy Rules. Chicago: University of Chicago Press, pp. 319-41.\n\nTaylor, John B., and John C. Williams (2010). \"Simple and Robust Rules for Monetary Policy,\" in Benjamin M. Friedman and Michael Woodford, eds., Handbook of Monetary Economics, vol. 3. Amsterdam: Elsevier, pp. 829-59.\n\nWerning, Ivan (2012). \"Managing a Liquidity Trap: Monetary and Fiscal Policy (PDF),\" working paper, Massachusetts Institute of Technology, March.\n\nWoodford, Michael (2012). \"Methods of Policy Accommodation at the Interest-Rate Lower Bound (PDF),\" paper presented at \"The Changing Policy Landscape,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 30-September 1, pp. 185-288.\n\nYellen, Janet (2016). \"The Federal Reserve's Monetary Policy Toolkit: Past, Present, and Future,\" speech delivered at \"Designing Resilient Monetary Policy Frameworks for the Future,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 26.\n\n1. The sustainable longer-run pace of payroll employment growth depends on a number of a factors, such as the growth rate of the working-age population, trend movements in labor force participation, and the prevalence of self-employment and multiple job holdings, so it cannot be predicted with precision. Return to text\n\n2. The normal level of the U-6 measure may now be somewhat higher than it was prior to the financial crisis because of a trend toward greater reliance on part-time workers in many sectors. See Golden (2016). Return to text\n\n3. See Aaronson and others (2014). Return to text\n\n4. In addition, a persistently strong labor market could potentially lead some firms to rely less on part-time workers, or might encourage some people to rejoin the labor force who would otherwise sit on the sidelines. However, evidence on these sorts of endogenous supply-side effects is rather limited, as I noted in a recent speech (see Yellen, 2016). Return to text\n\n5. A summary of the projections submitted by Committee participants for the December 2016 FOMC meeting can be found at www.federalreserve.gov/monetarypolicy/fomcprojtabl20161214.htm. Return to text\n\n6. An exception to this pattern is the Atlanta Fed's Wage Growth Tracker (WGT), which does show a noticeable acceleration in hourly wages as self-reported in the Current Population Survey. Like average hourly earnings, the WGT excludes benefits costs and so is less comprehensive than the ECI or business-sector compensation per hour (CPH). In addition, the WGT is based on a smaller sample than the measures shown in Figure 3 and it only covers a sub-set of the workforce--specifically, employed individuals who were also employed a year ago, and whose earnings are less than $150,000 per year. Finally, because average hourly earnings and business-sector CPH are measured as total wages divided by total hours, an increase in wages for high earners has a larger effect in those measures than a similarly proportioned increase for lower-wage workers, and this is not so for the WGT. Return to text\n\n7. Many other labor market indicators also improved more slowly in 2016 relative to the pace seen in the prior two years, including the U-6 measure of labor utilization, the rates of job openings, hiring and quits, survey readings on net hiring plans and the difficulty of filling vacancies, and the average duration of unemployment. A notable exception to this general pattern is the labor force participation rate, which declined fairly steadily from 2007 through 2015 but then flattened out last year despite continuing downward pressure from the aging of the population and other factors. However, improvements in labor market conditions along this dimension arguably reflect an increase in potential output, and so they are probably not a source of inflationary pressures. Return to text\n\n8. During the late 1960s through the 1970s, however, inflation did rise noticeably whenever the unemployment rate moved below its longer-run normal level, primarily because the Federal Reserve did not adequately check persistent movements in inflation by tightening monetary policy, thereby allowing inflation expectations to drift. This experience illustrates the importance of keeping inflation expectations anchored through systematic policy actions. Return to text\n\n9. The Federal Reserve closely monitors a wide range of indicators of financial stability, which currently provide little evidence of significant increases in leverage or rapid growth in credit. However, some asset valuations, particularly for commercial real estate, are high. With regard to the linkages between labor utilization and financial stability, my interpretation of the historical evidence is that undesirable increases in leverage or the emergence of asset bubbles are not the inevitable consequence of tight labor markets per se. Return to text\n\n10. These individual projections are published quarterly in the Summary of Economic Projections that accompanies the release of the minutes from the March, June, September and December meetings of the FOMC. Return to text\n\n11. The FOMC's procedures share many of the features of forecast targeting, an approach to monetary policymaking advocated by Svensson (2005), among others. However, while the Committee publishes participants' projections--including policy paths--in the SEP, it does not publish a \"consensus\" forecast, in contrast to some other central banks. Return to text\n\n12. Formally, the rule originally published by Taylor (1993) can be written as\nR\nt\n=\nR\n∗\n+\nπ\nt\n+0.5(\nπ\nt\n−\nπ\n∗\n)+0.5\nY\nt\n, where\nR\nis the federal funds rate,\nR\n∗\nis the level of the real federal funds rate that on average is expected to be consistent with sustaining maximum employment and stable inflation in the longer run,\nπ\nis current inflation,\nπ\n∗\nis the central bank's inflation objective (2 percent, in the case of the Federal Reserve), and\nY\nis the output gap, defined as the difference between the current level of real GDP and what it would be if the economy was operating at maximum employment. Importantly, the rule embodies three key principles that central banks take into account when setting policy to stabilize inflation and the overall economy. First, a persistent movement in inflation requires a more than one-for-one response of the policy rate to stabilize inflation. Second, monetary policy should raise real interest rates above their normal longer-run level whenever inflation is above its desired level and resource utilization is higher than normal, and lower them when the opposite holds. (Note that implementing this latter principle requires estimates of both the economy's productive potential and the longer-run level of the real policy rate that would be consistent with keeping the economy operating on an even keel.) And, finally, policymakers should respond in a systematic manner to changes in economic conditions in order to help financial market participants and others better understand how policy is likely to respond over time to current and future events, thereby influencing expectations in a way that promotes economic stability. Return to text\n\n13. Historically, percent deviations of real GDP from statistical estimates of its long-run trend are roughly twice as large on average as deviations of the unemployment rate from its estimated long-run value--a relationship known as Okun's law. Return to text\n\n14. Additional complications arise in the measurement of economic slack because the difference between the unemployment rate and its estimated normal level is not always a complete gauge of overall labor utilization. Such was the case in the current expansion until recently because the labor force participation rate was unusually low and involuntary part-time employment unusually high, given the level of the unemployment rate. Moreover, although movements in resource utilization for the economy as a whole are generally proportional to changes in labor utilization, the relationship varies somewhat over time. Partly as a result, contemporaneous estimates of the output gap can deviate markedly from subsequent estimates for the same period calculated using revised data. For example, in early 2010, the Congressional Budget Office (CBO) estimated that the output gap in 2009:Q2 was negative 7.7 percent, but the CBO has since lowered it to negative 6.3 percent--a large revision with important implications for assessments of the deviation of actual policy from the prescriptions of simple policy rules. Return to text\n\n15. If monetary policy persistently followed the prescriptions of a Taylor rule that assumed that R* was 2 percent when it was in fact 1 percent, then employment would run persistently below its maximum sustainable level and inflation would run persistently below 2 percent. Under such circumstances, inflation expectations might begin to fall, creating a risk of deflation. Return to text\n\n16. For example, see Holston, Laubach, and Williams (2016). Return to text\n\n17. Based on estimates generated using the term-structure model developed by Li and Wei (2013) and the procedure discussed in Ihrig and others (2012) and extended by Engen, Laubach, and Reifschneider (2015), the Federal Reserve's holdings of Treasury securities and agency mortgage-backed securities continue to put considerable downward pressure on longer-term interest rates. However, this pressure is estimated to be gradually easing as the average maturity of the portfolio declines and the end-date for reinvestment draws closer. Over the course of 2017, this easing could increase the yield on the 10-year Treasury note by about 15 basis points, all else being equal. Based on the estimated co-movement of short-term and long-term interest rates, such a change in longer-term yields would be similar to that which, on average, has historically accompanied two 25 basis point hikes in the federal funds rate. Return to text\n\n18. For example, prescriptions from seven different rules, calculated using forecasts of economic activity and inflation from different sources, are regularly posted by the Federal Reserve Bank of Cleveland at https://www.clevelandfed.org/our-research/indicators-and-data/simple-monetary-policy-rules.aspx. Return to text\n\n19. The balanced-approach rule is\nR\nt\n=\nR\n∗\n+\nπ\nt\n+0.5(\nπ\nt\n−\nπ\n∗\n)+1.0\nY\nt\n, where all terms are defined as in the Taylor rule. (See note 12 for details.) As noted by Taylor (1999), research suggests that this rule may do a better job than the Taylor rule in stabilizing real activity and inflation. Return to text\n\n20. The change rule is\nR\nt\n=\nR\nt−1\n+1.2(\nπ\nt\n−2)+2.0(\nU\n∗\n−\nU\nt\n)\n, where\nR\nis the federal funds rate,\nπ\nis four-quarter rate of core PCE inflation,\nU\n∗\nis the projected longer-run unemployment rate, and\nU\nis the current unemployment rate. In computing the prescriptions for the change rule shown in figure 8, the midpoint of the target range for the federal funds rate prior to the December 2016 FOMC meeting, 0.38 percent, is used as the starting point. For a discussion of this rule (and of policy rules in general), see Taylor and Williams (2010). Return to text\n\n21. For example, the FOMC advised in the statement released after its December 2012 meeting that conditions would likely warrant keeping the funds rate near zero at least as long as the unemployment rate was above 6-1/2 percent--a threshold that was not passed until mid-2014. As discussed by Reifschneider and Williams (2000), Werning (2012), and Woodford (2012), this type of lower-for-longer guidance can help compensate for the constraint on monetary policy created by the zero lower bound on nominal interest rates. Engen, Laubach, and Reifschneider (2015) find that the FOMC's guidance, together with its asset purchases, provided significant economic stimulus in the years following the financial crisis. Return to text\n\n22. For a closer look at the FOMC's policy actions in 2016 and their relationship to previous forecasts and subsequent changes in economic conditions, see Nechio and Rudebusch (2016). Return to text\n\n23. To sample some of the different views about the sources of the recent slowdown in productivity growth and the prospects for faster growth in the future, see Gordon (2016), Fernald and Wang (2015), Brynjolfsson and McAfee (2014), and Decker and others (2016, forthcoming). Return to text\n\n24. A related source of uncertainty is the limited ability of economists to predict the effects of specific changes in tax policy or government spending on the overall economy. In part, this uncertainty arises because the net effect depends to some extent on the response of financial markets; in addition, estimates vary considerably on the economic effects of changes in marginal tax rates or different types of spending. Return to text"
    },
    {
        "title": "The Goals of Monetary Policy and How We Pursue Them",
        "date": "January 18, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20170118a.htm",
        "content": "January 18, 2017\n\nChair Janet L. Yellen\n\nAt the Commonwealth Club, San Francisco, California\n\nWatch on-demand: https://www.youtube.com/watch?v=ktBgb4xHKGY\n\nAudio\n\nGood afternoon. It is a pleasure to join all of you at the Commonwealth Club today, not the least because the club and the Federal Reserve have a few things in common. Both organizations, as it happens, have a board of governors and a chair. And both the club's and the Fed's histories extend back more than a century. The club, as many here know, was founded in 1903, and the Federal Reserve a decade later. Perhaps because of our shared origins in the Progressive Era, a period of reform in American life, we hold certain values in common. According to your website, the club is nonpartisan and dedicated to the impartial discussion of issues important to your community and the nation. At the Fed, we too are nonpartisan and focused squarely on the public interest. We strive to conduct our deliberations impartially and base our decisions on factual evidence and objective analysis. This afternoon I will discuss some challenges we've faced in our recent deliberations and may face in the next few years.\n\nPerhaps, though, it is best to start by stepping back and asking, what is--and, importantly, what isn't--our job as the nation's central bank? And how do we go about trying to accomplish it? The Federal Reserve has an array of responsibilities. I'll mention our principal duties and then focus on one--monetary policy, the responsibility that gets the most public attention.\n\nIn addition to monetary policy, we--in collaboration with other regulatory agencies at both the federal and state levels--oversee banks and some other financial institutions to ensure they operate safely and soundly and treat their customers fairly. We monitor the financial system as a whole and promote its stability to help avoid financial crises that could choke off credit to consumers and businesses. We also reliably and safely process trillions of dollars of payments for the nation's banks and the federal government and ensure that banks have an ample supply of currency and coin to meet the demands of their depositors. And we work with communities, nonprofit organizations, lenders, educators, and others to encourage financial and economic literacy, promote equal access to credit, and advance economic and community development.\n\nBut, as I noted, monetary policy draws the most headlines. What is monetary policy, exactly? Simply put, it consists of central bank actions aimed at influencing interest rates and financial conditions more generally. Its purpose is to help foster a healthy economy. But monetary policy cannot, by itself, create a healthy economy. It cannot, for instance, educate young people, generate technological breakthroughs, make workers and businesses more productive, or address the root causes of inequality. Fundamentally, the energy, ingenuity, and know-how of American workers and entrepreneurs, along with our natural resources, create prosperity. Regulatory policy and fiscal policy--the decisions by the Administration and the Congress about how much and how the government spends, taxes, and borrows--can influence these more fundamental economic pillars.\n\nI've said what monetary policy cannot do. But what can it do? It can lean against damaging fluctuations in the economy. Nearly 40 years ago, the Congress set two main guideposts for that task--maximum employment and price stability. We refer to these assigned goals as our dual mandate. When the economy is weak and unemployment is on the rise, we encourage spending and investing by pushing short-term interest rates lower. As you may know, the interest rate that we target is the federal funds rate, the rate banks charge each other for overnight loans. Lowering short-term rates in turn puts downward pressure on longer-term interest rates, making credit more affordable--for families, for instance, to buy a house or for businesses to expand. Similarly, when the economy is threatening to push inflation too high down the road, we increase interest rates to keep the economy on a sustainable path and lean against its tendency to boom and then bust.\n\nBut what exactly do the terms \"maximum employment\" and \"price stability\" mean? Does maximum employment mean that every single person who wants a job has a job? No. There are always a certain number of people who are temporarily between jobs after having recently lost a job or having left one voluntarily to pursue better opportunities. Others may have just graduated and have started looking for a job or have decided to return to working--for instance, when their child starts school. This so-called frictional unemployment is evident even in the healthiest of economies.\n\nThen there is structural unemployment--a difficult problem both for the people affected and for policymakers trying to address it. Sometimes people are ready and willing to work, but their skills, perhaps because of technological advances, are not a good fit for the jobs that are available. Or suitable jobs may be available but are not close to where they and their families live. These are factors over which monetary policy has little influence. Other measures--such as job training and other workforce development programs--are better suited to address structural unemployment.\n\nAfter taking account of both frictional and structural unemployment, what unemployment rate is roughly equivalent to the maximum level of employment that can be sustained in the longer run? The rate can change over time as the economy evolves, but, for now, many economists, including my colleagues at the Fed and me, judge that it is around 4-3/4 percent. It's important to try to estimate the unemployment rate that is equivalent to maximum employment because persistently operating below it pushes inflation higher, which brings me to our price stability mandate.\n\nDoes price stability mean having no inflation whatsoever? Again, the answer is no. By \"price stability,\" we mean a level of inflation that is low and stable enough that it doesn't need to figure prominently into people's and businesses' economic decisions. Based on research and decades of experience, we define that level as 2 percent a year--an inflation objective similar to that adopted by most other major central banks.1 Individual prices, of course, move up and down by more than 2 percent all the time. Such movements are essential to a well-functioning economy. They allow supply and demand to adjust for various goods and services. By \"inflation,\" we mean price changes as a whole for all of the various goods and services that households consume.\n\nNo one likes high inflation, and it is easy to understand why. Although wages and prices tend to move in tandem over long periods, inflation erodes household purchasing power if it is not matched with similar increases in wages, and it eats away the value of households' savings. So, then, why don't we and other central banks aim for zero inflation? There are several technical reasons, but a more fundamental reason is to create a buffer against the opposite of inflation--that is, deflation. Deflation is a general and persistent decline in the level of prices, a phenomenon Americans last experienced during the Great Depression of the 1930s and one that Japan has confronted for most of the past two decades. Deflation can feed on itself, leading to economic stagnation or worse. It puts pressure on employers to either cut wages or cut jobs. And it can be very hard on borrowers, who find themselves repaying their loans with dollars that are worth more than the dollars they originally borrowed. I am sure we all remember learning in school about farm families in the Great Depression who couldn't pay their mortgages and lost their homes and their livelihoods when crop prices fell persistently.\n\nAnother important reason to maintain a modest inflation buffer is that too low inflation impairs the ability of monetary policy to counter economic downturns. When inflation is very low, interest rates tend to be very low also, even in good times. And when interest rates are generally very low, the Fed has only limited room to cut them to help the economy in bad times.\n\nIn a nutshell, the Fed's goal is to promote financial conditions conducive to maximum employment and price stability. And I have offered broad-brush definitions of each of those objectives. So where is the economy now, in relationship to them? The short answer is, we think it's close. The economy has come a long way since the financial crisis. As you know, the crisis marked the start of a very deep recession. It destroyed nearly 9 million jobs, and it's been a long, slow slog to recover from it. Unemployment peaked at 10 percent late in 2009, a level unseen for more than 25 years, and didn't move below 8 percent for nearly three years. Falling home prices put millions of homeowners \"underwater,\" meaning they owed more on their mortgages than their homes were worth. And the stock market plunged, slashing the value of 401(k) retirement nest eggs.\n\nThe extraordinarily severe recession required an extraordinary response from monetary policy, both to support the job market and prevent deflation. We cut our short-term interest rate target to near zero at the end of 2008 and kept it there for seven years. To provide further support to American households and businesses, we pressed down on longer-term interest rates by purchasing large amounts of longer-term Treasury securities and government-guaranteed mortgage securities. And we communicated our intent to keep short-term interest rates low for a long time, thus increasing the downward pressure on longer-term interest rates, which are influenced by expectations about short-term rates.\n\nNow, it's fair to say, the economy is near maximum employment and inflation is moving toward our goal. The unemployment rate is less than 5 percent, roughly back to where it was before the recession. And, over the past seven years, the economy has added about 15-1/2 million net new jobs. Although inflation has been running below our 2 percent objective for quite some time, we have seen it start inching back toward 2 percent last year as the job market continued to improve and as the effects of a big drop in oil prices faded. Last month, at our most recent meeting, we took account of the considerable progress the economy has made by modestly increasing our short-term interest rate target by 1/4 percentage point to a range of 1/2 to 3/4 percent. It was the second such step--the first came a year earlier--and reflects our confidence the economy will continue to improve.\n\nNow, many of you would love to know exactly when the next rate increase is coming and how high rates will rise. The simple truth is, I can't tell you because it will depend on how the economy actually evolves over coming months. The economy is vast and vastly complex, and its path can take surprising twists and turns. What I can tell you is what we expect--along with a very large caveat that our interest rate expectations will change as our outlook for the economy changes. That said, as of last month, I and most of my colleagues--the other members of the Fed Board in Washington and the presidents of the 12 regional Federal Reserve Banks--were expecting to increase our federal funds rate target a few times a year until, by the end of 2019, it is close to our estimate of its longer-run neutral rate of 3 percent.\n\nThe term \"neutral rate\" requires some explaining. It is the rate that, once the economy has reached our objectives, will keep the economy on an even keel. It is neither pressing on the gas pedal to make the car go faster nor easing off so much that the car slows down. Right now our foot is still pressing on the gas pedal, though, as I noted, we have eased back a bit. Our foot remains on the pedal in part because we want to make sure the economic expansion remains strong enough to withstand an unexpected shock, given that we don't have much room to cut interest rates. In addition, inflation is still running below our 2 percent objective, and, by some measures, there may still be some room for progress in the job market. For instance, wage growth has only recently begun to pick up and remains fairly low. A broader measure of unemployment isn't quite back to its pre-recession level. It includes people who would like a job but have been too discouraged to look for one and people who are working part time but would rather work full time.\n\nNevertheless, as the economy approaches our objectives, it makes sense to gradually reduce the level of monetary policy support. Changes in monetary policy take time to work their way into the economy. Waiting too long to begin moving toward the neutral rate could risk a nasty surprise down the road--either too much inflation, financial instability, or both. In that scenario, we could be forced to raise interest rates rapidly, which in turn could push the economy into a new recession.\n\nThe factors I have just discussed are the usual sort that central bankers consider as economies move through a recovery. But a longer-term trend--slow productivity growth--helps explain why we don't think dramatic interest rate increases are required to move our federal funds rate target back to neutral. Labor productivity--that is, the output of goods and services per hour of work--has increased by only about 1/2 percent a year, on average, over the past six years or so and only 1-1/4 percent a year over the past decade. That contrasts with the previous 30 years when productivity grew a bit more than 2 percent a year. This productivity slowdown matters enormously because Americans' standard of living depends on productivity growth. With productivity growth of 2 percent a year, the average standard of living will double roughly every 35 years. That means our children can reasonably hope to be better off economically than we are now. But productivity growth of 1 percent a year means the average standard of living will double only every 70 years.\n\nEconomists do not fully understand the causes of the productivity slowdown. Some emphasize that technological progress and its diffusion throughout the economy seem to be slower over the past decade or so. Others look at college graduation rates, which have flattened out after rising rapidly in previous generations. And still others focus on a dramatic slowing in the creation of new businesses, which are often more innovative than established firms. While each of these factors has likely played a role in slowing productivity growth, the extent to which they will continue to do so is an open question.2\n\nWhy does slow productivity growth, if it persists, imply a lower neutral interest rate? First, it implies that the economy's usual rate of output growth, when employment is at its maximum and prices are stable, will be significantly slower than the post-World War II average. Slower economic growth, in turn, implies businesses will see less need to invest in expansion. And it implies families and individuals will feel the need to save more and spend less. Because interest rates are the mechanism that brings the supply of savings and the demand for investment funds into balance, more saving and less investment imply a lower neutral interest rate. Although we can't directly measure the neutral interest rate, it is something that can be estimated in retrospect. And, as we have increasingly realized, it has probably been trending down for a while now. Our current 3 percent estimate of the longer-run neutral rate, for instance, is a full percentage point lower than our estimate just three years ago.\n\nYou might be thinking, what does this discussion of rather esoteric concepts such as the neutral rate mean to me? If you are a borrower, it means that, although the interest rates you pay on, say, your auto loan or mortgage or credit card likely will creep higher, they probably will not increase dramatically. Likewise, if you are a saver, the rates you earn could inch higher after a while, but probably not by a lot. For some years, I've heard from savers who want higher rates, and now I'm beginning to hear from borrowers who want lower rates. I can't emphasize strongly enough, though, that we are not trying to help one of those groups at the expense of the other. We're focused very much on that dual mandate I keep mentioning. At the end of the day, we all benefit from plentiful jobs and stable prices, whether we are savers or borrowers--and many of us, of course, are both.\n\nEconomics and monetary policy are, at best, inexact sciences. Figuring out what the neutral interest rate is and setting the right path toward it is not like setting the thermostat in a house: You can't just set the temperature at 68 degrees and walk away. And, because changes in monetary policy affect the economy with long lags sometimes, we must base our decisions on our best forecasts of an uncertain future. Thus, we must continually reassess and adjust our policies based on what we learn.\n\nThat point leads me to repeat what I said when I began: Like the Commonwealth Club, the Federal Reserve was created more than a century ago during an era of government reform to serve the public interest. The structure established for the Federal Reserve back then intentionally insulates us from short-term political pressures so we can focus on what's best for the American economy in the longer run. I promise you, with the sometimes imperfect information and evidence we have available, we will do just that by making the best decisions we can, as objectively as we can.\n\nThank you. I welcome your questions.\n\n1. Our objective is 2 percent inflation as measured by the annual change in the price index for personal consumption expenditures published by the Commerce Department's Bureau of Economic Analysis. Return to text\n\n2. Other factors depressing the neutral rate include housing construction and lackluster exports. Housing still hasn't fully recovered from the financial crisis, in part because mortgage-qualification standards remain tight. Weak growth abroad in Europe, China, and elsewhere, some of which is related to their own productivity challenges, has hurt sales of U.S. goods. Return to text"
    },
    {
        "title": "Monetary Policy in a Time of Uncertainty",
        "date": "January 17, 2017",
        "speaker": "Governor Lael Brainard",
        "url": "https://www.federalreserve.gov/newsevents/speech/brainard20170117a.htm",
        "content": "January 17, 2017\n\nGovernor Lael Brainard\n\nAt the Brookings Institution, Washington, D.C.\n\nWatch\n\nThere are many sources of uncertainty affecting the trajectory of the U.S. economy and, by extension, the appropriate path of monetary policy. In particular, there has been speculation about significant changes to fiscal policy of late, although the magnitude, composition, and timing of any fiscal changes are as yet unknown and will depend on the incoming Administration and the new Congress as well as the vicissitudes of the budgeting process. Even once any changes are enacted, uncertainty will remain about their effects on the overall economy. It thus seems possible that monetary policy could be affected for some time by uncertainty surrounding fiscal policy and its effects on the economy.1\n\nMacroeconomic Outcomes Are Difficult to Predict\nBefore I turn to the possible effects of fiscal policy, it is helpful to remind ourselves of the immense uncertainty that accompanies any attempt to forecast future economic developments. Many possible surprises could materially affect the future path of the U.S. economy, such as shocks to the price of oil, the foreign economic outlook, the rate of productivity growth, the sentiment of households and businesses, financial stability, and fiscal policy, to name a few. The resulting uncertainty makes it difficult to predict the future path of activity, unemployment, and inflation.\n\nBy statute, the Federal Reserve is mandated to conduct monetary policy to promote the long run goals of maximum employment and stable prices. In today's framework, the Federal Open Market Committee (FOMC) has defined stable prices to mean 2 percent inflation. The FOMC adjusts the stance of policy in light of incoming economic information and its implications for the outlook. Uncertainty about future employment and inflation naturally translates into uncertainty about the path of future monetary policy.\n\nOne useful measure of uncertainty is the magnitude of forecast errors, or the extent to which macroeconomic outcomes have differed from professional economic forecasters' expectations.2 Over the past 30 years, outside forecasts of the unemployment rate four quarters ahead have missed the actual unemployment rate by more than 3/4 percentage point in either direction one-third of the time. Since notable departures from forecast values of unemployment and inflation occur with some frequency, it should not be surprising that the associated forecasts of interest rates have a similar track record. One-third of the time over the past 30 years, outside forecasts of the level of short-term interest rates four quarters ahead have been above or below the actual level by more than 1-1/4 percentage points.3 Thus, it is important to keep in mind that all macro forecasts and projections of monetary policy are subject to considerable uncertainty, as they are based on information at a point in time, and actual developments could well evolve much differently.\n\nFiscal Policy Considerations\nAmong the many factors that can affect the aggregate economy and, by extension, monetary policy, a possible shift in fiscal policy has attracted the attention of both economic forecasters and financial markets of late. Among forecasters surveyed by Blue Chip Economic Indicators, for 2017, 44 percent indicated that they had raised their forecast of inflation and 47 percent had raised their forecast of gross domestic product (GDP) growth because of the recent U.S. election results, although on average forecast changes were modest. Markets have also reacted, and many have interpreted these changes as reflecting expectations of more expansionary fiscal policy in the coming years than previously expected.\n\nIn thinking about fiscal scenarios, forecasters have several historical episodes on which to draw. For example, following the 1980 elections, tax cuts were enacted, and defense spending rose. Federal fiscal deficits, adjusted for the cyclical state of the economy, increased by roughly 2-1/2 percentage points of GDP from the period before the elections to six years following the elections, federal debt held by the public increased from about 25 percent of GDP to nearly 40 percent, and the current account deficit widened.4Following the 2000 elections, similar fiscal changes resulted in an increase in the fiscal deficit of close to 3 percentage points of GDP over the first six years of the new Administration on a cyclically adjusted basis. Of course, there are important differences in today's conditions relative to these historical settings, including the economy's cyclical position, current and projected levels of indebtedness, the relative position of the global economy, and monetary policy settings.\n\nAs of today, there is substantial uncertainty about the magnitude, timing, and composition of any possible change in the stance of fiscal policy. It is instructive to contemplate the important dimensions along which fiscal policy and its effects might vary as well as their implications for monetary policy. In addition to the critical size and timing issues, there are four key dimensions: (1) the composition of policy changes and their relative effects on aggregate demand and aggregate supply, (2) the distance of the economy from full employment and 2 percent inflation, (3) the divergence in the cyclical position of the U.S. economy relative to foreign economies, and (4) the amount of fiscal policy space.\n\nDifferent types of policies can generate very different economic responses and have implications regarding both the amount of aggregate economic stimulus per fiscal dollar and also whether the effect is predominantly to raise aggregate demand or also to expand the supply potential of the economy. Generally, fiscal stimulus that expands spending and investment directly or is targeted to households and businesses that have the greatest propensity to spend rather than save can be expected to generate the largest response in aggregate demand.5\n\nFocusing first on policies that affect only aggregate demand, temporary demand-based fiscal expansions can speed recovery when the economy is some distance from full employment and target inflation, particularly if conventional monetary policy is constrained by the effective lower bound. But when the economy is either close to or at full employment and inflation is converging to or at its target, additional fiscal demand will more likely result in inflationary pressures. Thus, fiscal expansions that affect only aggregate demand and are enacted when the economy is near full employment and 2 percent inflation are relatively less likely to sustainably boost economic activity and relatively more likely to be accompanied by increases in interest rates.\n\nThe current nominal neutral interest rate--or the level of the federal funds rate that is consistent with output growing close to its potential rate with full employment and stable inflation--is quite low at present.6 Adjusting for inflation, most estimates of the neutral rate are currently close to zero, compared with about 2 percent for the quarter-century prior to the financial crisis.7 A low neutral rate implies that conventional monetary policy has less room to respond when the economy is hit by adverse shocks. With conventional monetary policy constrained in the vicinity of the lower bound, it is more difficult for the economy to recover and for inflation to move back to target.8\n\nPolicies that persistently raise aggregate demand alone can lift the neutral rate, but that may come at substantial cost. Because these policies do not affect the economy's long-term growth potential but do result in persistent fiscal deficits, they can lead to substantial increases in the debt-to-GDP ratio. The greater space for monetary policy to respond to adverse shocks provided by a higher neutral rate comes at the expense of reducing the space for fiscal policy to stabilize the economy in the event of future adverse shocks.\n\nIn this regard, it matters importantly whether increased fiscal deficits predominantly raise aggregate demand or also expand the supply potential of the economy more broadly. Changes in fiscal policy that raise the level or growth rate of productivity or that induce greater labor force participation and higher levels of skill and education in the workforce raise the nation's productive capacity and result in more sustainable increases in output and living standards. The higher productivity and workforce levels engendered by these policies would likely increase investment opportunities and raise expectations of future income growth, sustainably boosting the levels of investment and consumption and, as a result, the longer-run neutral rate. Such policies are more likely to be sustainable because the boost to GDP that they provide continues to accumulate over time, limiting increases in the debt-to-GDP ratio and preserving fiscal space.\n\nIn addition, the effects of fiscal policy depend importantly on the relative strength of the broader global economy. In recent years, major foreign economies have been contending with a deficiency of domestic demand. At a time when the U.S. economy has made important progress on employment and inflation, in both Europe and Japan output or inflation, or both, remain well below desired levels. As a result, forecasters expect short-term yields in these economies to remain near zero for years to come. Moreover, growth in many emerging market economies, including importantly China, has slowed in recent years, and financial conditions in some emerging economies appear fragile. Against the backdrop of deficient demand abroad, if more expansionary fiscal policy here at home raises expectations of a growing divergence between the United States and other economies, upward pressure on the exchange rate will likely result, as we have seen recently with the renewed increase in the dollar. The result could be cross-border spillovers from the increase in U.S. domestic demand, reducing the effect on U.S. real activity and inflation and potentially contributing to external imbalances. In the past few years, the effect on the dollar of increased expectations about divergence between U.S. and foreign interest rates has been especially strong.9 The nearly 20 percent increase in the dollar over 2014 and 2015 coincided with falling real exports and import prices in the United States. Net exports subtracted more than 1/2 percentage point from GDP growth in both 2014 and 2015, while falling non-oil import prices likely subtracted 1/4 percentage point from the annual rate of core inflation.10\n\nFinally, the trajectory of federal government debt relative to GDP and views regarding the debt's sustainability can also influence the effects of fiscal policy. Research suggests that increases in the debt-to-GDP ratio cause long-term interest rates to rise.11 All else being equal, higher long-term interest rates reduce spending on interest-sensitive goods, possibly damping the direct effect of fiscal expansion on economic activity. The experiences of foreign economies suggest that the relationship between debt and interest rates is complex and likely non-linear, with the influence of greater debt on interest rates rising as the debt-to-GDP ratio reaches a trajectory at which investors have concerns about its sustainability. In this light, it is notable that the current ratio of debt to GDP is substantially larger than it was preceding the fiscal expansions in the early 1980s and early 2000s and has already been projected to increase further based on demographic trends.12\n\nGuideposts for Monetary Policy\nWith any future change in fiscal policy quite uncertain, monetary policy will be guided by the current state of the economy, the underlying momentum of economic activity and inflation, the level of the neutral rate, and the balance of macroeconomic risks. In recent quarters, the data have painted a consistent picture of a resilient and gently improving U.S. economy. Following a year in which the unemployment rate remained stable while labor force participation increased, we have seen in the past quarter a further reduction in the unemployment rate. Overall, I am pleased to see that full employment is within reach and could prove sustainable with the right policy mix. Payroll growth has remained sufficiently strong to continue eroding slack, increasingly along margins that had previously seemed stubbornly elevated--including the long-term unemployed, those on the margins of the labor force, and most recently those who are working part time but would prefer full-time work. Moreover, wage growth appears to be picking up gradually in a further sign that slack continues to be taken up. While the employment cost index was up only 2.3 percent over the 12 months ending in September, still well below pre-crisis norms, average hourly earnings have accelerated more noticeably, increasing by 2.9 percent on a 12-month basis in December. Even so, some slack may remain: Relative to pre-crisis levels, the prime-age employment-to-population ratio remains low and the share of employees working part time for economic reasons remains elevated.\n\nFollowing a long period of stubbornly below-target inflation, I have been encouraged by recent signs of gradual progress toward our inflation target, as the effects of earlier dollar appreciation and oil price declines appear to be waning. Over the 12-month period ending in November, core personal consumption expenditures prices increased 1.6 percent. This rate is still noticeably below 2 percent, but it is up 1/4 percentage point from a year earlier.13 In addition, market measures of longer-run inflation compensation based on nominal and inflation-protected Treasury yields have improved about 40 basis points relative to the very depressed levels prevailing through much of the preceding year, although, even with this increase, inflation compensation remains well below historical norms.\n\nIn sum, the economy continues to make gradual progress toward our goals. How quickly remaining slack is utilized and inflation returns to target depends on future growth in activity. Real GDP appears to have increased by about 2 percent last year, the same pace as the year before. Consumer spending has been relatively robust--rising at more than a 3 percent annual rate in the three months ending in November--but business fixed investment has been sluggish--increasing only 1-1/2 percent in the third quarter--and has changed little, on net, since the middle of 2014. However, measures of both business and consumer sentiment have moved up noticeably recently, potentially signaling a stronger pace of investment and consumer spending in the months ahead. Meanwhile, changes in financial conditions have been somewhat offsetting since early November, with equity prices rising 7 percent, while 10-year Treasury yields are up 50 basis points, and the dollar is up 4 percent. Based on recent spending indicators, we might expect progress to continue to be gradual and steady. However, if fiscal policy changes lead to a more rapid elimination of slack, policy adjustment would, all else being equal, likely be more rapid than otherwise, with the conditions the FOMC has set for a cessation of reinvestments of principal payments on existing securities holdings being met sooner than they otherwise would have been.\n\nWhen the economy eventually returns to full employment and 2 percent inflation, the appropriate level of the federal funds rate will depend on the level of the neutral rate, which is expected to move up only modestly in coming years from its current low level.14On the one hand, if progress on employment and inflation occurs more quickly than I anticipate, foreign risks recede, and the fiscal impulse rises, the neutral rate might rise more rapidly. On the other hand, global economic conditions may somewhat offset the effect on the neutral rate. With weak domestic demand abroad, further tightening of financial conditions through the exchange rate could lead to some spillover of demand across borders, weighing on U.S. exports, investment, and manufacturing activity and potentially constraining the neutral rate.\n\nFinally, how strongly monetary policy should react to signs of further progress toward full employment and 2 percent inflation naturally depends on the balance of risks. Given the recent improvement in unemployment and inflation and the possibility of increased fiscal stimulus, risks in the domestic economy are closer to being balanced than they have been for some time. While great uncertainty regarding the path of fiscal policy and its economic effects will remain for some time, with the economy getting closer to full employment, the prospect of a material increase in fiscal stimulus over a sustained period could reasonably be expected to shift somewhat greater probability toward stronger inflation outcomes. But risks outside our borders are still tilted to the downside. In particular, despite recent progress, policy space in Japan and the euro area is perceived to be very limited, and the euro-area banking sector remains fragile. Downside risks are also present in emerging market economies such as China, which faces capital outflow pressures and high and rapidly growing corporate indebtedness. With a low U.S. neutral rate, conventional U.S. monetary policy does not have as much room as it did prior to the financial crisis to counter adverse shocks from abroad.\n\nConclusion\nSpeculation has increased of late about the possibility of a significant fiscal policy shift on the horizon. The effects will depend on the timing, magnitude, and composition of the policies, the extent to which the policies boost aggregate supply relative to aggregate demand, the cyclical position of the economy, and the responses of the dollar and longer-term interest rates, given the fragile global economic environment and projections for the U.S. debt-to-GDP ratio. Against this uncertain backdrop, monetary policy will continue to be guided by actual and expected progress toward our goals, the level of the neutral rate, and the balance of risks. A gradual approach will remain appropriate as long as inflationary pressures remain muted, the economy remains short of our objectives, the neutral rate remains low, and downside risks from abroad remain, although this will depend on the fiscal trajectory, as it evolves, and its uncertain effects on the economy and financial markets.\n\nReferences\nBoard of Governors of the Federal Reserve System, Division of Research and Statistics (2014). \"Updated Historical Forecast Errors (4/9/2014) (PDF),\" memorandum.\n\nBongard, Michelle, and Benjamin K. Johannsen (2016). \"The Neutral Rate and the Summary of Economic Projections,\" FEDS Notes. Washington: Board of Governors of the Federal Reserve System, November 28.\n\nBrainard, Lael (2015). \"Normalizing Monetary Policy When the Neutral Interest Rate Is Low,\" speech delivered at the Stanford Institute for Economic Policy Research, Stanford, Calif., December 1.\n\nCongressional Budget Office (2015). Estimated Impact of the American Recovery and Reinvestment Act on Employment and Economic Output in 2014 (PDF). Washington: CBO, February.\n\nCongressional Budget Office (2016). The Budget and Economic Outlook: 2016 to 2026 (PDF). Washington: CBO.\n\nCucuru, Stephanie (forthcoming). \"The Sensitivity of the USD Exchange Rate to Changes in Monetary Policy Expectations,\" IFDP Notes. Washington: Board of Governors of the Federal Reserve System.\n\nEngen, Eric, and R. Glenn Hubbard (2005). \"Federal Government Debt and Interest Rates,\" in Mark Gertler and Kenneth Rogoff, eds., NBER Macroeconomics Annual 2004, Volume 19. Cambridge, Mass.: MIT Press, pp. 83-160.\n\nEvans, Charles, Jonas Fisher, Francois Gourio, and Spencer Krane (2015). \"Risk Management for Monetary Policy Near the Zero Lower Bound (PDF),\" Brookings Papers on Economic Activity, Spring, pp. 141-214.\n\nGruber, Joseph, Andrew McCallum, and Robert Vigfusson (2016). \"The Dollar in the U.S. International Transactions (USIT) Model,\" IFPD Notes. Washington: Board of Governors of the Federal Reserve System, February 8.\n\nLaubach, Thomas (2009). \"New Evidence on the Interest Rate Effects of Budget Deficits and Debt,\" Journal of the European Economic Association, vol. 7 (June), pp. 858-85.\n\nLaubach, Thomas, and John Williams (2015). \"Measuring the Natural Rate of Interest Redux (PDF),\" Working Paper Series 2015-16. San Francisco: Federal Reserve Bank of San Francisco, October.\n\nReifschneider, David, and Peter Tulip (2007). \"Gauging the Uncertainty of the Economic Outlook from Historical Forecast Errors (PDF),\" Financial and Economic Discussion Series 2007-60. Washington: Board of Governors of the Federal Reserve System, November.\n\nI am grateful to Eric Engen, Andrew Figura, and Glenn Follette for their assistance in preparing this text.\n\n1. These remarks represent my own views, which do not necessarily represent those of the Federal Reserve Board or the Federal Open Market Committee. Return to text\n\n2. The analysis of forecast errors presented here uses data from 1986 to 2015 from the Federal Reserve Bank of Philadelphia's November Survey of Professional Forecasters. For more on the construction of forecast errors, see Reifschneider and Tulip (2007) and Board of Governors (2014). Return to text\n\n3. The short-term interest rate used in this analysis is the three-month Treasury bill rate. Return to text\n\n4. Annual data on cyclically adjusted federal deficits can be found in table C-2 of the Congressional Budget Office (2016, p. 126) report The Budget and Economic Outlook: 2016 to 2026. The analysis takes a three-year centered moving average of the CBO's estimates of the cyclically adjusted federal deficit, which can be quite volatile from year to year, and compares this average for the year prior to the new Administration to the average in the sixth year of the new Administration. Return to text\n\n5. For example, see table 3 in the Congressional Budget Office (2015, p. 6) report Estimated Impact of the American Recovery and Reinvestment Act on Employment and Economic Output in 2014. Return to text\n\n6. See Brainard (2015). Return to text\n\n7. See Laubach and Williams (2015). For the most up-to-date Laubach-Williams estimates of the natural rate of interest, a concept closely related to the neutral rate, see www.frbsf.org/economic-research/files/Laubach_Williams_updated_estimates.xlsx. Also see the most recent median estimates of the real neutral rate from the New York Federal Reserve Bank's Survey of Primary Dealers (https://www.newyorkfed.org/markets/primarydealer_survey_questions.html) and Survey of Market Participants (https://www.newyorkfed.org/markets/survey_market_participants.html). For estimates of the real neutral rate based on the Summary of Economic Projections, see Bongard and Johannsen (2016). Return to text\n\n8. For an analysis of macroeconomic behavior near the zero lower bound, see Evans and others (2015). Return to text\n\n9. See Cucuru (forthcoming). Return to text\n\n10. For estimates of the effect of exchange rate changes on inflation and GDP growth, see Gruber, McCallum, and Vigfusson (2016). Return to text\n\n11. See Laubach (2009) and Engen and Hubbard (2005). Return to text\n\n12. I am referring to the level of federal government debt held by the public. Return to text\n\n13. Oil is an important input in the production and distribution of many consumer goods and services, such as transportation services. As a result, when the price of oil drops, production costs decline, and at least some of these cost reductions are typically passed on to consumers over time in the form of lower prices. Return to text\n\n14. Of course, the neutral rate is not directly observable, and we will only be able to gauge its level by observing the momentum of economic activity and the extent to which the momentum is putting upward pressure on resource constraints and inflation. The median FOMC participant's estimate of the longer-run real neutral rate in the December 2016 Summary of Economic Projections was 1 percent. The median projected level of the real neutral rate at the end of 2019 in the December 2016 New York Federal Reserve Bank's Survey of Market Participants was also 1 percent. Return to text"
    },
    {
        "title": "Welcoming Remarks",
        "date": "January 12, 2017",
        "speaker": "Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20170112a.htm",
        "content": "January 12, 2017\n\nChair Janet L. Yellen\n\nAt the Conversation with the Chair: A Teacher Town Hall Meeting, Washington, D.C.\n\nThank you, and thank you to all the educators who have come to the Board this evening or travelled to one of the Fed's regional Reserve Banks to watch and listen via the webcast.\n\nI am very much looking forward to hearing from you about teaching economics, and I am eager to respond to your questions. For that reason, and also because I expect that school starts very early tomorrow for many of you, I will try to keep my remarks brief. But I do have a message to impart about the work you do, which is vitally important not only to your students, but also, I believe, to the world they will soon inherit and even to the mission of the Federal Reserve.\n\nFirst and foremost, of course, like all teachers, you are helping prepare your students for successful and rewarding lives. The knowledge you impart and the intellect and talents you help develop are powerful tools your students can use to build those lives. Like some other subjects students encounter in school, economics teaches analytical and critical thinking skills that can aid in the development and success of anyone. Part of success for your students is economic success--as capable, creative, and productive members of the workforce and as consumers adept at managing their finances. Economics provides knowledge and skills of practical use in college and in the workplace, and it also provides skills to plan and make wise financial decisions, which are some of the most important and consequential that we face in life.\n\nYour students benefit very directly from this education, but so does everyone else in society. Everyone is engaged in and depends on the economy, and nothing is more critical to a healthy and growing economy than the capability, creativity, and productiveness of its workforce. Whenever I am asked what policies and initiatives could do the most to spur economic growth and raise living standards, improving education is at the top of my list.\n\nIn addition to the role you play in preparing students for jobs and careers, you also help prepare them to be responsible consumers. The economy needs productive workers, and it also depends on consumers, whose individual spending decisions, as most of you surely have taught in class, collectively account for two-thirds of economic activity. Consumers skilled in managing their finances are better prepared to weather bad times, and stronger household finances overall can help sustain growth, stabilize the economy, and mitigate an economic downturn.\n\nStabilizing the economy and mitigating a downturn, of course, also happen to be among the Federal Reserve's primary responsibilities. When successful, monetary policy can be a powerful and effective tool to these ends, but its capabilities are dwarfed by larger factors such as the productivity of the workforce and the strength of household finances. By educating students and directly supporting their contributions to the economy as producers and consumers, all teachers, especially teachers of economics, are effectively furthering our mission at the Fed, so let me offer my thanks for making that job a little easier.\n\nTo help support your important work as teachers, the Federal Reserve Board and the 12 Reserve Banks conduct programs, organize events, and publish books and other materials to spread knowledge of the role of the Fed--and economics in general--and to promote financial literacy. Before I get to those events and programs, let me say a word about what is probably the most important pedagogical aid that the Fed produces--the 182-page book called The Federal Reserve System: Purposes and Functions. The 10th edition of Purposes and Functions, published in October of last year, offers a detailed and comprehensive account of what, why, and how the Fed carries out its different responsibilities. I think it is a wonderful resource for teaching about the Fed, and copies are available via the Board's website.1\n\nEach of the Fed's Reserve Banks has community outreach and educational initiatives in the areas of the country they serve, and the outreach to economics teachers is coordinated by the group chaired by Amy Hennessy, the Federal Reserve System Economic Education Group.\n\nAt the Board, we have for some years operated a program called FedEd, which sends Fed employees into schools throughout the Washington, D.C., metropolitan area and sponsors events for students here at the Eccles Building.2 FedEd's outreach to schools depends on the time and sacrifice of several dozen research assistants, who are typically recent college graduates who work for two or three years at the Board. Research assistants who volunteer for FedEd visit schools; help teach about the Fed, economics, and finance; and answer questions about work opportunities at the Board. The Federal Reserve is committed to promoting diversity in our ranks and in the economics profession, and FedEd has furthered these goals by making sure to include schools with significant numbers of minority students.\n\nThis past school year, FedEd sent research assistants into nine different schools and FedEd volunteers have visited 38 different schools since 2012. FedEd was back in schools last fall, drawing from 48 research assistants who volunteered to participate. FedEd also sponsors several speaker events a year that bring students into this Board Room. Students recently heard a presentation from Scott Alvarez, who oversees the Board's Legal Division, and, in February, Vice Chairman Stanley Fischer will speak to students at another event. FedEd is overseen by two research assistants, Caroline Shinkle and Jamie Lenney, along with Karen Pence, who is an economist at the Board. All three are with us this evening and prepared to answer further questions about the program.\n\nOnline resources for teachers can be found on the Board's website at federalreserve.gov, and additional resources available throughout the System are at federalreserveeducation.org. The websites include videos in which policymakers and the staff describe the Fed's functions. Also, the sites include historical materials and a wealth of information related to the financial crisis and the Fed's response.\n\nLet me leave it there, and again thank teachers for participating in this town hall, and offer my thanks, on behalf of the Board of Governors, for the valuable work you do every day. I would be very happy to respond to your questions.\n\n1. Purposes and Functions is available on the Board's website at https://www.federalreserve.gov/pf/pf.htm. Return to text\n\n2. More information about FedEd is available on the Board's website at https://www.federalreserve.gov/aboutthefed/educational-tools/fed-education.htm. Return to text"
    },
    {
        "title": "Low Interest Rates and the Financial System",
        "date": "January 07, 2017",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20170107a.htm",
        "content": "January 07, 2017\n\nGovernor Jerome H. Powell\n\nAt the 77th Annual Meeting of the American Finance Association, Chicago, Illinois\n\nThank you for this invitation to discuss low interest rates and the financial system. The framing of this topic raises the question of whether low interest rates have somehow undermined the stability and functioning of the financial system. I will argue that \"low for long\" interest rates have supported slow but steady progress to full employment and stable prices, which has in turn supported financial stability. Indeed, by many measures the U.S. financial system is much stronger than before the crisis. That said, there are difficult tradeoffs to manage. Over time, low rates can put pressure on the business models of financial institutions. And low rates can lead to excessive leverage and broadly unsustainable asset prices--things that we watch carefully for and do not observe at this point. I will begin by focusing briefly on the macroeconomic effects of low interest rates. I will then turn to the condition of the financial system--in particular, its interplay with low rates. As always, the views I express here today are mine alone.\n\nHighly Accommodative Monetary Policy\nThe financial crisis and the Great Recession posed the most significant macroeconomic challenges for the United States in a half-century, leaving behind high unemployment and below-target inflation and calling for highly accommodative monetary policies. Isolating the effects of these policies is challenging, but studies generally show that they lowered rates across the curve and moved other asset prices as well.1 It is even more challenging to evaluate their effects on aggregate demand. Low rates and higher asset prices should support household and business spending and investment through various channels. But low rates may also perversely induce some households to save more in order to meet their targets for retirement. And low rates have clearly not produced a boom in corporate investment, although standard accelerator models suggest that investment has largely been consistent with the weak pace of economic growth. Nonetheless, there is good reason to think that low rates have provided significant support for demand, and my view is that they have done so.2 As you can see in slide 1, we are now close to meeting our dual mandate--a reasonable summary statistic for the effects of policy. While growth has been frustratingly slow, employment gains have been solid. This is a reasonably good outcome considering the scope of the crisis and the relatively poorer performance of other major advanced economies.\n\nOther Factors Are Holding Down Rates\nThere are also many factors other than monetary policy that are holding down long-term interest rates. Long-term nominal and real rates have been declining for over 30 years. The next slide decomposes long-term nominal yields into expected future short-term real rates, expected future inflation, and a term premium. These estimates are based on one of the Board's workhorse term structure models.3 All three components have contributed to the downward trend in long-term nominal yields.\n\nThe downward trend in nominal term premiums likely reflects both lower inflation risk and the fact that, with inflation expectations anchored, nominal bonds have become an increasingly good hedge against market risk. That has made bonds a more attractive investment and reduced the term premium.4 As shown in the next slide, a regression of the 10-year term premium on measures of 10-year inflation expectations and a rolling beta of Treasury returns with respect to equity returns (to proxy for the hedging value of bonds) shows that these two factors can account for a large part of the decline in the term premium.\n\nRegulations now require many financial institutions to hold more safe, high-quality liquid assets, which likely has pushed down term premiums further. Global factors may have put downward pressure on term premiums because of anxiety about the foreign outlook, which may have increased demand for U.S. assets, or because low rates abroad have depressed U.S. term premiums through a global portfolio balance channel.5 And real rates are quite low globally, reflecting the step-down of productivity growth over the past 10 years as well as shifts in savings and investment demand due to demographic change.6\n\nThe Core of the Financial System Is Much Stronger\nBefore turning to the interplay between low rates and the financial system, I will simply point out that both improved risk management at the largest, most systemically important financial institutions (SIFIs) and stronger regulation have made the core of the system much stronger and more resilient than before the crisis.7 The SIFIs have more stable funding, hold much more capital and liquidity, are more conscious of their risks, and are far more resolvable should they fail. Many aspects of our financial market infrastructure, including the triparty repurchase agreement (or repo) market, central counterparties (CCPs), and money market funds are more robust as well.\n\nLow Rates Can Mean Tradeoffs\nSo far, I have argued that low rates have supported aggregate demand and brought us very close to full employment and 2 percent inflation; that forces other than monetary policy have been pushing rates lower for more than 30 years; and that the core of the financial system is now much stronger and more resilient than before the crisis. All of that said, I would also agree that monetary policy may sometimes face tradeoffs between macroeconomic objectives and financial stability. Indeed, it would be a divine coincidence if that were not the case. There are times when all of these objectives are aligned. For example, the Fed's initial unconventional policies supported both market functioning and aggregate demand. More broadly, post-crisis monetary policy supported asset values, reduced interest payments, and increased both employment and income. All of these effects are likely to have limited defaults and foreclosures and bolstered the balance sheets of households, businesses, and financial intermediaries, leaving the system more robust.\n\nBut at times there will be tradeoffs. Low-for-long interest rates can have adverse effects on financial institutions and markets through a number of plausible channels, as listed on the next slide.8 After all, low interest rates are intended to encourage some risk-taking.9The question is whether low rates have encouraged excessive risk-taking through the buildup of leverage or unsustainably high asset prices or through misallocation of capital. That question is particularly important today. Historically, recessions often occurred when the Fed tightened to control inflation. More recently, with inflation under control, overheating has shown up in the form of financial excess. Core PCE inflation remained close to or below 2 percent during both the late-1990s stock market bubble and the mid-2000s housing bubble that led to the financial crisis. Real short- and long-term rates were relatively high in the late-1990s, so financial excess can also arise without a low-rate environment. Nonetheless, the current extended period of very low nominal rates calls for a high degree of vigilance against the buildup of risks to the stability of the financial system.\n\nIf we look at the channels listed here, the picture is mixed, but the bottom line is that there has not been an excessive buildup of leverage, maturity transformation, or broadly unsustainable asset prices.\n\nLow long-term interest rates have weighed on profitability in the financial sector, although firms have so far coped with those pressures. As shown in the next slide, net interest margins (NIMs) for most banks have held up surprisingly well. NIMs have moved down for the largest banks. Return on assets, shown to the right for both groups, has recovered but remains below pre-crisis levels. Life insurers have substantially underperformed the broader equity market since 2007, suggesting that investors see the low-rate environment as a drag on profitability for the industry. Even so, data on asset portfolios do not suggest that life insurers have increased risk-taking. The same is true for banks. Both the regulatory environment and banks' own attitudes toward risk following the financial crisis have helped ensure that the largest banks have not taken on excessive credit or duration risks relative to their capital cushions.\n\nLow rates have provided support for asset valuations--indeed, that is part of their design. But I do not see valuations as significantly out of line with historical experience. Equity prices have recently increased considerably, pushing the forward price-earnings ratio further above its historical median (slide). And equity premiums (right)--the expected return above the risk-free rate for taking equity risk-- have declined, but are not out of line with historical experience.\n\nIn the nonfinancial sector, valuation pressures are most concerning when leverage is high, particularly in real estate markets. Residential real estate valuations have been in line with rents and household incomes in recent years, and the ratio of mortgage debt to income is well below its pre-crisis peak and still declining. In contrast, valuations in commercial real estate are high in some markets.10 And in the nonfinancial corporate sector, gross leverage is high by historical standards. Low long-term rates have encouraged corporate debt issuance at the same time that some regulations, particularly the Volcker rule, have discouraged banks from holding and making markets in such debt. High-risk corporate debt (the sum of high-yield bonds and leveraged loans) grew rapidly in 2013 and 2014 (slide), although growth has declined sharply since then.11 However, firms also are holding high levels of liquid assets, so net leverage is not elevated. Firms have also lengthened their maturity profiles, and interest coverage ratios are high. As the next slide shows, Greenwood and Hanson's measure of the share of high-yield debt in overall issuance is at a relatively low level.12 And this debt is now held more by unlevered investors. Overall, I do not see leveraged finance markets as posing undue financial stability risks. And if risk-taking does not threaten financial stability, it is not the Fed's job to stop people from losing (or making) money.\n\nAs I said, a mixed picture. Low interest rates have encouraged risk-taking and higher leverage in some sectors and have weighed on profitability in others, but the areas where there are signs of excess are isolated.\n\nConclusion\nTo sum up, low interest rates have supported economic activity and gradually brought us back to full employment and 2 percent inflation. Better regulation and risk management have so far minimized the tradeoffs between our macroeconomic objectives, on the one hand, and financial stability, on the other. Still, a period of low rates for a long time could present significant challenges for monetary policy. It could also put pressure on the business models of some financial institutions. Ultimately, the only way to get sustainably higher interest rates is to improve the broader environment for growth, by adopting policies designed to increase productivity and potential output over the long term--policies that are mainly outside the scope of our work at the Federal Reserve.13\n\nReferences\nAdrian, Tobias, and Nellie Liang (2014). \"Monetary Policy, Financial Conditions, and Financial Stability,\" Federal Reserve Bank of New York Staff Reports 690. New York: Federal Reserve Bank of New York, September (revised December 2016).\n\nBekaert, Geert, Marie Hoerova, and Marco Lo Duca (2013). \"Risk, Uncertainty and Monetary Policy,\" Journal of Monetary Economics, vol. 60 (October), pp. 771-88.\n\nD'Amico, Stefania, Don H. Kim, and Min Wei (forthcoming). \"Tips from TIPS: The Informational Content of Treasury Inflation-Protected Security Prices,\" Journal of Financial and Quantitative Analysis.\n\nDell'Ariccia, Giovanni, Luc Laeven, and Gustavo A. Suarez (forthcoming). \"Bank Leverage and Monetary Policy's Risk-Taking Channel: Evidence from the United States,\" Journal of Finance.\n\nEngen, Eric M., Thomas Laubach, and David Reifschneider (2015). \"The Macroeconomic Effects of the Federal Reserve's Unconventional Monetary Policies (PDF),\" Finance and Economics Discussion Series 2015-005. Washington: Board of Governors of the Federal Reserve System, January.\n\nGagnon, Etienne, Benjamin K. Johannsen, and David Lopez-Salido (2016). \"Understanding the New Normal: The Role of Demographics (PDF),\" Finance and Economics Discussion Series 2016-80. Washington: Board of Governors of the Federal Reserve System, October.\n\nGilchrist, Simon, and Egon Zakrajšek (2012). \"Credit Spreads and Business Cycle Fluctuations,\" American Economic Review, vol. 102 (June), pp. 1692-1720.\n\nGreenwood, Robin, and Samuel G. Hanson (2013). \"Issuer Quality and Corporate Bond Returns,\" Review of Financial Studies, vol. 26 (June), pp. 1483-1525.\n\nMian, Atif, Kamalesh Rao, and Amir Sufi (2013). \"Household Balance Sheets, Consumption, and the Economic Slump,\" Quarterly Journal of Economics, vol. 128 (November), pp. 1687-1726.\n\nPowell, Jerome H. (2015). \"Financial Institutions, Financial Markets, and Financial Stability,\" speech delivered at the Stern School of Business, New York University, New York, February 18.\n\nPowell, Jerome H. (2016). \"Recent Economic Developments and Longer-Run Challenges,\" speech delivered at The Economic Club of Indiana, Indianapolis, November 29.\n\nRachel, Lukasz, and Thomas D. Smith (2015). \"Secular Drivers of the Global Real Interest Rate,\" Bank of England Staff Working Paper 571. London: Bank of England, December.\n\nWilliams, John C. (2014). \"Monetary Policy at the Zero Lower Bound: Putting Theory into Practice (PDF),\" Hutchins Center Working Papers. Washington: Hutchins Center on Fiscal and Monetary Policy, Brookings Institution, January.\n\nYellen, Janet L. (2016). \"The Federal Reserve's Monetary Policy Toolkit: Past, Present, and Future,\" speech delivered at \"Designing Resilient Monetary Policy Frameworks for the Future, a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 26.\n\n1. Williams (2014) compiles the results from a range of studies estimating the effect of the Federal Reserve's large-scale asset purchases (LSAPs). While the exact numbers vary and are subject to substantial uncertainty, typical estimates of the effect of a representative $600 billion in Treasury LSAPs on long-term yields are in the range of 15 to 25 basis points, an effect roughly equivalent to that of three or four rate cuts of 25 basis points. Return to text\n\n2. See Engen, Laubach, and Reifschneider (2015). The most interest rate sensitive sectors of the economy, such as consumer durables and residential investment, have exhibited higher growth than other sectors since the second round of quantitative easing by the Federal Reserve. And, for example, Mian, Rao, and Sufi (2013) conclude that the decline in house prices during the recession had a substantial effect on consumption; by the same argument, if low rates supported house prices, then they would have supported consumer spending as well. Return to text\n\n3. See D'Amico, Kim, and Wei (forthcoming). Return to text\n\n4. The changing risk profile of nominal Treasury bonds can be seen from its capital asset pricing model (or CAPM) beta, a measure of the co-movement between returns on longer-term Treasury securities and the equity market. Figure A.1 shows that the estimated rolling beta of the 10-year Treasury note with respect to the S&P 500 turned from positive to negative around 2000, indicating that Treasury bonds are now likely to act as a safe haven, performing well when equity markets do poorly. Return to text\n\n5. Figure A.2 shows the response in daily changes in 10-year U.S. Treasury yields to changes in 10-year German bund yields around European Central Bank (ECB) monetary policy decisions since 2010. The significantly positive regression coefficient is evidence of substantial spillovers from ECB monetary policy to U.S. long-term yields. Return to text\n\n6. See Rachel and Smith (2015) and Gagnon, Johannsen, and Lopez-Salido (2016). Return to text\n\n7. See Powell (2015). Return to text\n\n8. See Adrian and Liang (2014). Return to text\n\n9. See Dell'Ariccia, Laeven, and Suarez (forthcoming), which finds evidence for a risk-taking channel of monetary policy based on supervisory ratings of U.S. bank loans. Bekaert, Hoerova, and Lo Duca (2013) find that accommodative monetary policy shocks lead to a decline in the VIX, a measure of implied volatility, by lowering both expected volatility and the risk premium. Return to text\n\n10. The Federal Reserve, along with the Office of the Comptroller of the Currency and the Federal Deposit Insurance Corporation, issued guidance regarding prudent management of risks from loans secured by commercial real estate (CRE) in late 2015. Of course, the annual stress tests typically feature significant declines in CRE prices, suggesting that banks are capitalized against a deterioration in this sector. Return to text\n\n11. Gilchrist and Zakrajšek's (2012) measure of the corporate bond spread, shown in Figure A.3, is at about its average level, but their estimate of the risk premium in this market is low, so, by this measure, at least pricing is rich. Return to text\n\n12. See Greenwood and Hanson (2013). Return to text\n\n13. See Powell (2016) and Yellen (2016). Return to text"
    }
]