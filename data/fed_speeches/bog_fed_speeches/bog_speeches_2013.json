[
    {
        "title": "Interconnectedness and Systemic Risk: Lessons from the Financial Crisis and Policy Implications",
        "date": "January 04, 2013",
        "speaker": "Vice Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20130104a.htm",
        "content": "January 04, 2013\n\nVice Chair Janet L. Yellen\n\nAt the American Economic Association/American Finance Association Joint Luncheon, San Diego, California\n\nThank you, Claudia, and thanks to the American Economic Association and the American Finance Association for the opportunity to speak to you on a topic of growing interest to our profession and of great importance to understanding the causes and implications of the financial crisis.1\n\nEveryone here today, I'm sure, is familiar with the tumultuous events that introduced many Americans to the concept of systemic risk. To recap briefly, losses arising from leveraged investments caused a few important, but perhaps not essential, financial institutions to fail. At first, the damage appeared to be contained, but the resulting stresses revealed extensive interconnections among traditional banks, investment houses, and the rapidly growing and less regulated shadow banking sector. Market participants lost confidence in their trading partners, and, as the crisis unfolded, the financial sector struggled to cope with a massive withdrawal of liquidity, the collapse of one of its most prominent institutions, and a 40 percent drop in equity prices.2 The effects of the crisis were felt far beyond the financial sector as credit dried up and a mild recession became something far worse. You are also, no doubt, familiar with the political response to that crisis. After considerable debate, the Congress passed sweeping reform legislation designed to place the nation's financial infrastructure on a more solid foundation.\n\nI'm referring, of course, to the banking panic of 1907. The legislation that President Wilson signed in December 1913 created the Federal Reserve, providing the nation with a lender of last resort to respond to such crises.3 As we approach the centennial of the Federal Reserve System, it is striking how many of the challenges of that era remain with us today. In 1907, the correspondent banking networks that helped concentrate reserves in New York and other money centers also made the banking system highly interconnected. Today, our capability to monitor and model financial outcomes is vastly greater, and the tools available to the Federal Reserve are vastly more powerful, than the private capital and moral suasion that financier J. P. Morgan summoned in 1907 to stabilize the banks and trusts. But as we learned during the recent crisis, the financial system has also grown much larger and more complex, and our efforts to understand and influence it have, at best, only kept pace.\n\nComplex links among financial market participants and institutions are a hallmark of the modern global financial system. Across geographic and market boundaries, agents within the financial system engage in a diverse array of transactions and relationships that connect them to other participants. Indeed, much of the financial innovation that preceded the most recent financial crisis increased both the number and types of connections that linked borrowers and lenders in the economy. The rapid growth in securitization and derivatives markets prior to the crisis provides a stark example of this phenomenon. As shown in figure 1, between 2000 and 2007, the notional value of collateralized debt obligations outstanding increased from less than $300 billion to more than $1.4 trillion.4 From 2004, the earliest date for which comprehensive data are available, to 2007, the outstanding notional amount of credit default swap (CDS) contracts increased tenfold, from $6 trillion to $60 trillion.5 This incredible growth in securitization and derivatives markets reflects a significant increase in the number, types, and complexity of network connections in the financial system.\n\nFinancial economists have long stressed the benefits of interactions among financial intermediaries, and there is little doubt that some degree of interconnectedness is vital to the functioning of our financial system. Economists take a well-reasoned and dim view of autarky as the path to growth and stability. Banks and other financial intermediaries channel capital from savers, who often have short-term liquidity demands, into productive investments that typically require stable, long-term funding. Financial intermediaries work with one another because no single institution can hope to access the full range of available capital and investment opportunities in our complex economy. Connections among market actors also facilitate risk sharing, which can help minimize (though not eliminate) the uncertainty faced by individual agents. Yet experience--most importantly, our recent financial crisis--as well as a growing body of academic research suggests that interconnections among financial intermediaries are not an unalloyed good. Complex interactions among market actors may serve to amplify existing market frictions, information asymmetries, or other externalities. The difficult task before market participants, policymakers, and regulators with systemic risk responsibilities such as the Federal Reserve is to find ways to preserve the benefits of interconnectedness in financial markets while managing the potentially harmful side effects. Indeed, new regulations required by the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010 (Dodd-Frank Act) and changes in supervisory practices by the Federal Reserve and other financial regulators are intended to do just that.\n\nIn my remarks, I will discuss a few of the major regulatory and supervisory changes under way to address the potential for excessive systemic risk arising from the complexity and interconnectedness that characterize our financial system. The design of an appropriate regulatory framework entails tradeoffs between costs and benefits, and to illustrate them, I will discuss in some detail proposals currently under consideration to mitigate risk in over-the-counter (OTC) derivatives, which proved to be an important channel for the transmission of risk during the recent crisis. I am quite aware that some reforms in the wake of the financial crisis, including those pertaining to derivatives, have been controversial. In connection with recent rulemakings--and, more broadly, in the arena of public debate--critics have asked whether complexity and interconnectedness should be treated as potential sources of systemic risk. This is a legitimate question that the Federal Reserve welcomes and itself seeks to answer in its roles of researcher, regulator, and supervisor. Let me say at the outset, though, that a lack of complete certainty about potential outcomes is not a justification for inaction, considering the size of the threat encountered in the recent crisis.\n\nResponsible policymakers try to make decisions with the best information available but would always like to know more. With that in mind, I'll begin by briefly surveying research that highlights ways in which network structure and interconnectedness can give rise to or exacerbate systemic risk in the financial system.\n\nThe Economics of Interconnectedness and Systemic Risk\nAcademic research that explores the relationship between network structure and systemic risk is relatively new. Not surprisingly, interest in this field has increased considerably since the financial crisis. A search of economics research focusing on \"systemic risk\" or \"interconnectedness\" since 2007 yields 624 publications, twice as many as were produced in the previous 25 years.6 That's not to say that economists were blind to the importance of networks before the financial crisis. In 2000, Franklin Allen and Douglas Gale, for example, developed an important model of financial networks that provides insight into how networks can influence systemic risk.7\n\nIn the model studied by Allen and Gale, systemic risk arises through liquidity shocks that can have a domino effect, causing a problem at one bank to spread to others, potentially leading to failures throughout the system. In their model, interbank deposits are a primary mechanism for the transmission of liquidity shocks from one bank to another. Allen and Gale compare two canonical network structures: a \"complete\" network, in which all banks lend to and borrow from all other banks, and an \"incomplete\" network, in which each bank borrows from only one neighbor and lends to only one other neighbor. Figure 2, panel A, presents an example of a complete network, and figure 2, panel B, an example of an incomplete network.\n\nIn the case of the complete network, banks benefit from diversified funding streams. A liquidity shock at one bank is less likely to cause the bankruptcy of another bank since the shock can be distributed among all banks in the system. In the incomplete network, funding is not diversified. A liquidity shock at one bank is more likely to cause liquidity problems at other connected banks because the same shock is spread over fewer banks and is therefore larger and more destabilizing. The principle behind this result is familiar and basic to economics: Diversification reduces risk and improves stability. While this idea is compelling, both economic research and the events of the financial crisis suggest that it is incomplete.\n\nIn their classic paper on bank runs, Douglas Diamond and Philip Dybvig showed how rational and prudent actions by individual depositors to limit their own risks may be highly destabilizing to an institution designed to transform short-term liabilities into long-term assets.8 Xavier Freixas, Bruno Parigi, and Jean-Charles Rochet show that a similar kind of collective action problem can arise in a network akin to a modern check-clearing system in which credit extensions among banks allow claims on one institution to be fulfilled by another.9 Such a system is socially useful because it allows depositors to shift funds among banks without forcing banks to sell illiquid assets, thus enabling society as a whole to undertake more productive, long-term investment. But in times of stress or uncertainty, such systems can be subject to coordination failures: A \"gridlock\" equilibrium can arise in which depositors at each bank withdraw funds early in order to avoid losses arising from credit extensions to other banks whose depositors are also expected to force an early liquidation of assets. In Freixas, Parigi, and Rochet (2000), interbank credit extensions, while useful, can result in institutions that are \"too interconnected to fail.\" These models underscore that the pattern of connections throughout a financial network determines the systemwide implications of liquidity shocks or other financial stresses in one part of the network. This finding is one reason why efforts to collect more and better data on the precise linkages among financial institutions are so important. Without such comprehensive and detailed data, it is simply not possible to understand how stress in one part of the network may spread and affect the entire system.\n\nNetworks that are more interconnected are inherently more complex than those in which market participants have fewer links to one another, and complexity can exacerbate the kinds of coordination problems highlighted by Diamond and Dybvig and by Freixas, Parigi, and Rochet. Of course, \"complexity\" is difficult to define in a completely systematic and satisfactory manner, but one way emphasized in recent work by Hyun Song Shin is to consider the number of links required to connect savers to borrowers.10 Shin's analysis of interconnectedness among financial institutions is based on the idea that the ultimate amount of lending and borrowing that can occur in an economy is determined by economic fundamentals such as income growth, which change only slowly over time, whereas interbank claims can grow or contract far more quickly. Of course, claims within the entire financial system net out to zero, but they do affect the leverage of the institutions involved. In Shin's model, financial institutions seek to take on more leverage during a boom, when banks have strong capital positions and risks are perceived to be low, but can increase leverage, in the aggregate, only by borrowing and lending more intensively to each other. This causes the resulting network of intertwining claims to extend further and further. Conversely, when fundamental conditions or market sentiments change and financial institutions prefer to shed risk, they can deleverage in the short term only by withdrawing credit from one another. Such deleveraging can be particularly destabilizing in longer intermediation chains as debt claims that are called by one financial intermediary to shore up its own assets adversely affect the liability sides of other institutions' balance sheets. As deleveraging accelerates and more and more financial institutions hoard liquidity, other institutions may become concerned that their own funding may dry up and may preemptively withdraw funding from others. Fundamentally strong institutions are forced to liquidate assets at fire sale prices, which results in more deleveraging and instability.\n\nMore-complex network structures are likely to be more opaque than less complex ones. For example, as the number of intermediaries standing between borrowers and lenders grows, it becomes increasingly difficult to understand how one member of the network fits into the overall system. The well-publicized difficulties that some mortgage borrowers have had in simply figuring out who owns their mortgages illustrates the extent to which lengthening intermediation chains have increased the complexity of the financial system. Moreover, in many cases, market participants may have strong incentives not to disclose their connections to one another. If a bank has a profitable relationship with a borrower, it may be unwilling to disclose it to other banks for fear that competitors will reduce or eliminate the rents that it earns.\n\nRicardo Caballero and Alp Simsek illustrate how a lack of information can create systemic risk in financial networks.11 In a model that is structurally similar to the incomplete interbank network model of Allen and Gale, Caballero and Simsek examine how banks might respond to news of a liquidity shock when each bank knows the identities of its own counterparties but not the identities of its counterparties' counterparties. The authors posit that banks deal with this uncertainty by appealing to the \"maximin principle\": Each seeks to maximize profits under the assumption that the network is configured in the worst possible manner from its own perspective. Because each behaves as though the network structure is \"stacked against it,\" when banks learn of an adverse liquidity shock, each tends to sell more of its illiquid assets and withdraw more funding from its counterparties than it would if it had access to complete information about the structure of interbank credit relationships. As in Shin's model, this excessive deleveraging can create a vicious cycle, magnifying the effects of the initial shock.\n\nThe four models we've discussed thus far are aimed at exploring general features of financial networks. As such, they are necessarily somewhat abstract. With a few narrow exceptions, they treat all market participants as similar in size and in range of activities, and they use relatively simplistic network structures. In the past few years, research on financial networks has moved beyond stylized models of interbank relationships to examine the propagation of shocks in more-realistic settings. Recent research by Gai, Haldane, and Kapadia and by Cont, Moussa, and Santos examines how shocks propagate in network structures in which some banks are larger and more interconnected than others.12\n\nUsing numerical simulations, Gai, Haldane, and Kapadia show that, in concentrated networks, contagion occurs less frequently and is less severe for low degrees of network connectivity. Contagion is significantly more likely at higher levels of connectivity. In a concentrated financial network with a few key players, and when liquidity shocks are targeted at the most connected institutions, distress at highly connected banks spreads widely through the rest of the system. In this sense, the intuition of Allen and Gale--that highly connected networks are resilient to systemic shocks--can be misleading. In an empirical study of 3,000 Brazilian banks, Cont, Moussa, and Santos find that, not surprisingly, institutions with larger interbank exposures tend to be more systemically important. But, critically, they also find that an institution's position within the financial network plays a significant role. A bank that does business with a large number of relatively weak counterparties may have greater systemic importance than an institution with a similar number of counterparties that are better equipped to manage potential losses.\n\nThe work of Gai, Haldane, and Kapadia and that of Cont, Moussa, and Santos suggest that detailed and comprehensive data on the structure of financial networks is needed to understand the systemic risks facing the financial system and to gauge the contributions to systemic risk by individual institutions. I will describe in a moment how the Federal Reserve is using such data to enhance its understanding of the OTC derivatives market. This line of research suggests that a one-size-fits-all approach to the regulation of financial intermediaries may not be appropriate.\n\nSo, what have we learned from this brief tour through recent research on interconnectedness and systemic risk? We have seen how interconnectedness can be a source of strength for financial institutions, allowing them to diversify risk while providing liquidity and investment opportunities to savers that would not be available otherwise. But more-numerous and more-complex linkages also appear to make it more difficult for institutions to address certain types of externalities, such as those arising from incomplete information or a lack of coordination among market participants. These externalities may do little harm or may even be irrelevant in normal times, but they can be devastating during a crisis.\n\nThe Global Policy Response to Reduce Systemic Risk\nGovernments around the globe have responded to the financial crisis by adopting a strong, multifaceted, and coordinated reform agenda aimed at reducing systemic risk. At a meeting in Pittsburgh in September 2009, governments in the Group of Twenty (G‑20) endorsed work already under way in the Basel Committee on Banking Supervision to improve capital and the management of liquidity risk in the banking system.13 I'll briefly review several Basel Committee initiatives that address interconnectedness and systemic risk, but first, let me focus on one in particular: higher capital requirements for global systemically important banks (GSIBs).\n\nEnhanced capital standards for GSIBs serve to limit the risks undertaken by the largest, most interconnected institutions whose distress has the greatest potential to impose negative externalities on the broader financial system. A framework of higher minimum regulatory capital standards for these institutions was issued by the Basel Committee in November 2011, and indicators of interconnectedness account for a significant proportion of the overall score used to determine whether a bank will be subject to higher standards.14 As shown by Gai, Haldane, and Kapadia, among others, highly interconnected firms can transmit shocks widely, impairing the rest of the financial system and the economy. We saw, for example, that when Lehman Brothers failed, the shock was transmitted through money market mutual funds to the short-term funding and interbank markets. While some participants in each of these sectors had direct exposures to Lehman, many more did not. Moreover, even in cases in which direct exposures to Lehman were manageable, the turmoil caused by Lehman's failure added stress to the system at a particularly unwelcome time. In this way, the failure of a highly interconnected institution such as Lehman imposes costs on society well in excess of those borne by the firm's shareholders and direct creditors. Accordingly, tying enhanced capital requirements to interconnectedness improves the resilience of the system. Of course, higher capital requirements are not costless; they may raise financing costs for some borrowers, and they have the potential to induce institutions to engage in regulatory arbitrage. An important ongoing agenda for research and policy is the design and implementation of data-based measures of interconnectedness to ensure that our understanding of financial system interconnections evolves in tandem with financial innovation.\n\nWhile enhanced capital standards for GSIBs are an important tool for managing systemic risk that arises through interconnectedness, they are not the only tool. The Basel Committee's program contains a number of initiatives that will help manage interconnectedness and systemic risk. These measures include countercyclical capital buffers, liquidity requirements, increased capital charges for exposures to large financial institutions, large exposure rules, and deductions from capital for equity investments in banks.15 These and other initiatives will all play a role in managing the effect of complexity and interconnectedness on financial stability. In fact, the multifaceted nature of the reform program is an important design principle. One of the lessons of the recent financial crisis was that capital alone is not sufficient to prevent or stem a crisis. Multiple channels for reform initiatives will enhance systemic stability.\n\nManaging Tradeoffs between Reducing Systemic Risk and Increasing Costs: OTC Derivatives Market Reforms\nIn addition to the banking reforms I just discussed, the G-20 also committed to reduce risk in OTC derivatives markets by enacting reforms to improve transparency and decrease counterparty exposures among market participants. These policies must be considered carefully, as they are apt to increase the cost of financial intermediation and that of hedging risk. To illustrate the tradeoffs policymakers and regulators must manage when crafting such policies, I'll next discuss in some detail a set of initiatives currently being implemented by prudential, market, and systemic risk regulators around the world to address weaknesses in OTC derivatives markets.\n\nAn OTC derivative is a privately negotiated contract between a pair of counterparties to exchange future cash flows that depend on the performance of an underlying asset or benchmark index. Unlike an immediate purchase or sale of assets, OTC derivatives require one or both sides of the transaction to make payments in the future. Counterparty risk is therefore a key element of OTC derivatives transactions. The scale and significance of counterparty risks in the OTC derivatives markets are large and, as we saw, can have economy-wide implications. The prudent management, regulation, and oversight of these risks are critical to ensuring that derivatives markets serve to diversify, rather than exacerbate, systemic risk.\n\nSignificant problems with the functioning, regulation, and oversight of derivatives markets became apparent during the financial crisis. These problems are perhaps best exemplified by the widespread effects of large losses by American International Group, Inc. (AIG), on its OTC structured finance and credit derivatives positions. In the absence of government intervention, AIG's failure would have exposed its counterparties to substantial losses at a time of significant financial stress and uncertainty for them and the financial system. Indeed, for a time, the prospect of AIG's failure exacerbated the already impaired functioning in important segments of the OTC market, and, as that happened, it became more costly or even impossible for firms to manage financial risks. Derivatives positions originally undertaken by some firms to hedge risk could not be unwound and instead became sources of risk. AIG's failure revealed, in stark and spectacular fashion, systemic problems inherent in the structure and functioning of OTC derivatives markets that had increased the fragility of the financial system, exposing the rest of the economy to unnecessary systemic risks. Central clearing mandates, minimum margin standards, and data reporting requirements are among the tools that regulators now intend to use to mitigate counterparty risk and improve transparency, thus reducing uncertainty.\n\nThe September 2009 commitment of the G-20 to require that standardized OTC derivatives be cleared through central counterparties is directly aimed at reducing systemic risk by changing the structure of the network of derivatives counterparty exposures.16 In the absence of a central counterparty, the network of counterparty exposures associated with a class of OTC contracts might look something like panel A in figure 3. Each market participant has counterparty risk exposures to one or more other market participants. Although each participant knows its own risk exposure, it is unlikely to have complete information on its counterparties' exposures to others. Such opacity can engender the kind of information-related gridlock that we observed in the fall of 2008 and that is explored in the research of Caballero and Simsek. Moreover, because market participants commonly have partially or fully offsetting positions with multiple counterparties, a fully bilateral network is inefficient from a risk-management standpoint: Gains in the value of positions with one counterparty cannot be netted against losses in the value of positions with other counterparties.\n\nBy taking one side of every trade, a central counterparty serves to transform the mesh network shown in panel A of figure 3 into something that looks more like the hub-and-spoke network illustrated in panel B. This network structure has no effect on the exposure of individual market participants to the assets or indexes underlying the derivatives contracts in question, but it dramatically simplifies and improves the transparency of the network of counterparty risk exposures.17\n\nCentral clearing can yield important advantages over a fully bilateral market structure. The simpler hub-and-spoke network structure is more transparent, and the central counterparty is well positioned to impose common margin requirements on all market participants. Central clearing facilitates the netting of gains and losses across multiple market participants, which has the potential to significantly reduce each participant's aggregate counterparty risk exposure. Rather than managing its counterparty risk exposure to all other trading partners, a market participant needs to manage only its exposure to the central counterparty. The central counterparty acts as a pure intermediary and takes no net position in any of the underlying contracts that it clears, so it can experience losses only when a clearing member defaults and has posted insufficient margin to cover the cost of replacing its open positions. Central counterparties are typically designed to distribute any losses they do incur in a relatively predictable way across all clearing members. In this way, central clearing provides for a transparent mutualization of counterparty risks among participants.\n\nCentral counterparties are designed to be narrowly focused on intermediation and not the provision of credit and liquidity. This structure improves the chances that, in the event of a significant market stress, market functioning will not be threatened by the failure of market infrastructure itself.\n\nOf course, the other side of this coin is that adding a central counterparty introduces a single point of failure for the network, making it critical that the central counterparty itself be well managed and well regulated. To help ensure this result, title VII of the Dodd-Frank Act adopted stronger safeguards than in the past for central counterparties that clear OTC derivatives. Title VIII aimed at strengthening the supervision of financial market utilities, including central counterparties designated as systemically important, by requiring annual examinations as well as ex ante reviews of material rule and operational changes. In April 2012, the international organizations that set standards for financial market infrastructures such as central counterparties published new and stronger standards for these entities. U.S. regulators, including the Federal Reserve, participated actively in this work and are expected to make formal proposals for incorporating the new standards into U.S. regulations as soon as possible.\n\nMore fundamentally, however, a central counterparty's ability to manage risk is determined by its ability to accurately value the contracts it clears on a frequent and possibly real-time basis and to rapidly replace open positions at or near current prices in the event that a clearing member defaults. Requiring less-liquid and highly customized derivatives to be cleared would likely increase systemic risks, as clearinghouses would not be well positioned to manage the complex risks of such derivatives. The G-20 mandate explicitly recognizes this important limitation on the benefits of central clearing, and it requires only that standardized OTC derivatives be centrally cleared. Accordingly, the G-20 commitment has effectively managed the costs and benefits of central clearing in establishing a global clearing mandate.\n\nHowever, limiting central clearing to standardized derivatives means that a significant proportion of less standardized OTC contracts will continue to be written on a bilateral basis without the benefit of a central counterparty. The International Monetary Fund estimates that one-third of interest rate and credit derivatives and two-thirds of equity, commodity, and foreign exchange derivatives will not be suited to standardization and will remain non-centrally cleared.18 As more-standardized derivatives migrate to central clearing, it will be important to remain vigilant in managing the risks from non-centrally-cleared derivatives exposures.19 One important tool for managing the systemic risks of non-centrally-cleared derivatives is margin requirements.20 Globally, regulators have been working on standards for margin requirements on non-centrally-cleared derivatives that would provide for harmonized rules and a level playing field, which is crucial given the global nature of derivatives markets. In July, the Basel Committee and the International Organization of Securities Commissions proposed a framework for margin requirements on non-centrally-cleared derivatives.21 The finalized framework will inform rulemakings of the Federal Reserve and other U.S. regulators.\n\nThe proposed framework would require financial firms and systemically important nonfinancial firms to collect two types of margin. First, they would be obligated to collect variation margin on a regular basis, so if a derivative loses market value, the party experiencing a loss must realize the loss immediately. This requirement codifies current best market practice, since the largest derivatives dealers already exchange variation margin daily. However, and importantly, the framework extends this prudent risk-management practice to other derivatives counterparties. Requiring timely payment of variation margin will go a long way toward ensuring that an AIG-like event will not happen again, since current exposures will not be allowed to build over time to unmanageable levels.22 Moreover, variation margin requirements will ensure that market participants will know that counterparties that they deal with will not be carrying large uncollateralized exposures that could impair their ability to perform in the future. Those requirements diminish the likelihood of the kind of information gridlock explored by Caballero and Simsek.\n\nMore controversially, the proposed framework requires the collection of initial margin. While variation margin collateralizes current derivatives losses, initial margin collateralizes future losses that could occur in the event of a counterparty's default. In essence, initial margin is a kind of performance bond. In the event that a counterparty does not perform as required, the initial margin is used to replace the position with a new counterparty.\n\nIt is here that some of the most significant policy tradeoffs arise, because higher initial margin requirements will make it more costly for market participants to use derivatives to hedge risk. Liquid resources that are set aside as initial margin cannot be deployed for other purposes. Given the sheer size and scope of derivatives markets, requiring initial margin on all derivatives transactions could result in significant opportunity and liquidity costs. In a public comment letter to the Federal Reserve and other regulators, the International Swaps and Derivatives Association estimated that initial margin requirements could lock up as much as $1.7 trillion in liquid assets globally.23 This number is eye opening, to say the least. In an effort to better gauge the liquidity costs of initial margin requirements, the Federal Reserve, as part of the international group of prudential and market regulators that issued the July proposal, has conducted a detailed impact study to quantify the liquidity costs associated with initial margin requirements. The results of this study, as well as comments received on the proposal, will help ensure that in the final framework, the need to reduce systemic risk is appropriately balanced against the resulting liquidity costs.\n\nEven in light of the significant costs of initial margin, it seems clear that some requirements are needed. The current use and application of initial margin is inconsistent, and a more robust and consistent margin regime for non-centrally-cleared derivatives will not only reduce systemic risk, but will also diminish the incentive to tinker with contract language as a way to evade clearing requirements. Robust and consistent initial margin requirements will help prevent the kind of contagion that was sparked by AIG: They would serve, in effect, to limit the effects of interconnectedness within the financial network. The failure of a financial counterparty could be contained in the manner described by Allen and Gale. As I noted in connection with variation margins, initial margin requirements would also improve transparency because derivative market participants will know that their counterparties are at least partially insulated from defaults. Of course, these benefits need to be appropriately balanced against the burdens imposed by initial margin. But it seems highly unlikely that the status quo is consistent with achieving the goals of the G‑20 to reduce the potential for systemic risk in the OTC derivatives markets that could threaten the financial system.\n\nFinally, let me turn to data requirements. Both the research that I have highlighted today and practical experience demonstrate that market, prudential, and systemic risk authorities need detailed information on derivatives transactions and bilateral positions to assess evolving market risks and to execute their financial stability responsibilities. Indeed, the Federal Reserve has already used preliminary information from the Depository Trust & Clearing Corporation's Trade Information Warehouse to construct network graphs of the CDS market such as the one illustrated in figure 4. The data enable identification, for example, of firms, such as A and B in figure 4, that are large net sellers of protection. Such information can play a valuable role in supervision. Moreover, the analyses for monitoring and measuring systemic risks suggested and described by Gai, Haldane, and Kapadia and by Cont, Moussa, and Santos require this kind of detailed data to gain a holistic view of systemic risk.\n\nTitle VII of the Dodd-Frank Act requires that data on U.S. swaps transactions be reported to swaps data repositories regulated by the Commodity Futures Trading Commission or to securities-based swaps data repositories regulated by the Securities and Exchange Commission. Similar European regulations impose trade reporting requirements on swaps transacted in Europe. But there is still no guarantee, due to confidentiality concerns and legal barriers to data sharing, that the data reported into these trade repositories will ultimately be accessible to all of the regulators who require the data to obtain a holistic view of the derivatives market. Given that the derivatives market is global in scope, access to those data is essential for authorities with systemic risk responsibilities, such as the Federal Reserve, to monitor and respond to risks. To make this point concrete, it is unclear whether we will be able, on a regular and comprehensive basis, to produce the sort of analysis illustrated by figure 4. In order to effectively monitor market developments and systemic risks, it is crucial that regulators across jurisdictions and countries share data on a consistent and regular basis.\n\nWhile better data and more transparency are important for monitoring and responding to the buildup of systemic risks, we do, of course, also recognize the confidentiality concerns. Information is a valuable resource to most financial market participants, and unnecessarily burdensome or overly revealing information disclosures could compromise the position of market participants and reduce incentives for trade, thus decreasing liquidity and market efficiency. Dodd-Frank's real-time reporting requirements for swaps transactions recognize this important point by allowing for delayed reporting of large \"block trades\" where immediate reporting could reveal and undermine a participant's position and ultimately discourage market transactions, depth, and liquidity. In this way, enhanced reporting and transparency requirements are being set to provide the public and regulators with useful information without compromising market integrity. Moreover, while market integrity and appropriate confidentiality are important considerations, the events of the financial crisis have clearly shown that effective systemic risk management demands more, and not less, data disclosure.\n\nConcluding Remarks\nI began this talk by describing the events surrounding the banking panic of 1907 and the founding of the Federal Reserve. A lesson from that episode, as relevant today as it was then, was that financial stability is essential to sustained economic growth and prosperity. Just as the banking panic of 1907 revealed fundamental weaknesses in our financial system, so, too, did the financial crisis of 2007 and 2008. The recent crisis showed that some financial innovations, over time, increased the system's vulnerability to financial shocks that could be transmitted throughout the entire economy with immediate and sustained consequences that we are still working through today. Some of these vulnerabilities were a consequence of innovations that increased the complexity and interconnectedness of aspects of the financial system. In response to the crisis and the weaknesses it revealed, governments around the globe are acting to improve financial stability and reduce the risks posed by a highly interconnected financial system. These efforts, of course, must account for the costs of new rules and ensure that these costs are clearly outweighed by the benefits. I am confident that the policies I have described today will make the economy more resilient to financial shocks and help reduce the risk of another crisis, while properly balancing these important benefits against the necessary costs.\n\nIn striking this balance, government has been guided by new research that has added to our understanding of systemic risk. And this work continues. I have no doubt that some of you here today will perform that research and make those discoveries. So, allow me to close by offering my thanks, in advance, for those contributions. I hope my talk today has made it clear that the work of safeguarding our financial system will depend on these efforts and insights, which will empower policymakers to make the right decisions.\n\nReferences\nAllen, Franklin, and Douglas Gale (2000). \"Financial Contagion,\" Journal of Political Economy, vol. 108 (February), pp. 1-33.\n\nBank for International Settlements (2009). Revisions to the Basel II Market Risk Framework. Basel, Switzerland: BIS, July.\n\n--------- (2010). The Basel Committee's Response to the Financial Crisis: Report to the G-20 (PDF). Basel, Switzerland: BIS, October.\n\n--------- (2011). Global Systemically Important Banks:  Assessment Methodology and the Additional Loss Absorbency Requirement. Basel, Switzerland: BIS, November.\n\n--------- (2012a). Margin Requirements for Non-Centrally-Cleared Derivatives. Basel, Switzerland: BIS, July.\n\n--------- (2012b). \"Semiannual OTC Derivatives Statistics at End-June 2012,\" BIS, November, (accessed December 18, 2012).\n\nCaballero, Ricardo J., and Alp Simsek (2011). \"Fire Sales in a Model of Complexity,\" Massachusetts Institute of Technology Department of Economics Working Paper 09-28. Cambridge, Mass.: MIT, April.\n\nCont, Rama, Amal Moussa, and Edson Bastos e Santos (forthcoming). \"Network Structure and Systemic Risk in Banking Systems,\" in Jean-Pierre Fouque and Joe Langsam, eds., Handbook of Systemic Risk. New York: Cambridge University Press.\n\nDiamond, Douglas W., and Philip H. Dybvig (1983). \"Bank Runs, Deposit Insurance, and Liquidity,\" Journal of Political Economy, vol. 91 (June), pp. 401-19.\n\nDow Jones & Company (2012). \"Dow Jones Industrial Average,\" via Federal Reserve Bank of St. Louis, FRED Economic Data, \"Dow Jones Averages\" data release, (accessed December 18, 2012).\n\nDuffie, Darrell, and Haoxiang Zhu (2011). \"Does a Central Clearing Counterparty Reduce Counterparty Risk?\" Review of Asset Pricing Studies, vol. 1 (December), pp. 74-95.\n\nFinancial Crisis Inquiry Commission (2011). The Financial Crisis Inquiry Report (PDF). Washington: Government Printing Office.\n\nFreixas, Xavier, Bruno M. Parigi, and Jean-Charles Rochet (2000). \"Systemic Risk, Interbank Relations, and Liquidity Provision by the Central Bank,\" Journal of Money, Credit and Banking, vol. 32 (August), pp. 611-38.\n\nGai, Prasanna, Andrew Haldane, and Sujit Kapadia (2010). \"Complexity, Concentration and Contagion,\" Journal of Monetary Economics, vol. 58 (July), pp. 453-70.\n\nGroup of Twenty (2009). Leaders' Statement: The Pittsburgh Summit, item 13 under \"Strengthening the International Financial Regulatory System.\" Pittsburgh, Pa.: G-20, September.\n\nInternational Monetary Fund (2010). Global Financial Stability Report: Meeting New Challenges to Stability and Building a Safer System.Washington: IMF, April.\n\nInternational Swaps and Derivatives Association (2012). Comment letter from Robert Pickel on the Federal Reserve's proposed rule on margin and capital requirements for covered swap entities (Docket No. R-1415) (PDF), November 26.\n\nSecurities Industry and Financial Markets Association (2012). \"Statistics,\" SIFMA, (accessed December 18, 2012).\n\nShin, Hyun Song (2009). \"Financial Intermediation and the Post-Crisis Financial System (PDF),\" paper presented at the Eighth Bank for International Settlements Annual Conference, held at the Bank for International Settlements, Basel, Switzerland, June 25-26.\n\n \n\n1. The views expressed here are my own and not necessarily those of my colleagues in the Federal Reserve System. I am indebted to members of the Board staff--Celso Brunetti, Cecilia Caglio, Sean Campbell, Erik Heitfield, and John Maggs--who contributed to the preparation of these remarks. Return to text\n\n2. The level of the Dow Jones industrial average dropped 43.8 percent between November 15, 1906 (94.25), and November 15, 1907 (53.00). See Dow Jones & Company (2012). Return to text\n\n3. See Federal Reserve Act, ch. 6, 38 Stat. 251 (1913). Return to text\n\n4. See Securities Industry and Financial Markets Association (2012). Collateralized debt obligations (CDOs) are a general class of securitized products consisting of bonds that represent claims on the future cash flows generated by a variety of financial assets, including corporate debt and mortgage-backed securities. Growth in notional amounts of CDOs is indicative of the growth in economic exposure. Return to text\n\n5. A CDS is a derivative contract in which one party, the protection \"seller,\" agrees to insure another party, the protection \"buyer,\" from default on an underlying bond or index of bonds in exchange for a fee. Notional amounts do not reflect the economic exposure in these markets, which is a small fraction of the notional value, but the growth noted here is indicative of the growth in exposure. See Bank for International Settlements (2012b). Return to text\n\n6. A search for either \"interconnectedness\" or \"systemic risk\" in article abstracts of academic research cataloged by EconLit results in 311 entries from 1988 to 2006. The same search conducted for the period from 2007 through the present yields 624 entries. Restricting the search to articles that have appeared in peer-reviewed journals reduces the number of entries between 1988 and 2006 to 186 and the number of entries between 2007 and the present to 375. Return to text\n\n7. See Allen and Gale (2000). Return to text\n\n8. See Diamond and Dybvig (1983). Return to text\n\n9. See Freixas, Parigi, and Rochet (2000). Return to text\n\n10. See Shin (2009). Return to text\n\n11. See Caballero and Simsek (2011). Return to text\n\n12. See Gai, Haldane, and Kapadia (2010) and Cont, Moussa, and Santos (2012). Return to text\n\n13. See Group of Twenty (2009). Return to text\n\n14. See Bank for International Settlements (2011). It should also be noted that while the assessment methodology depends on interconnectedness, the specific measures employed will be continually reviewed and updated as appropriate.Return to text\n\n15. For a description of these and related regulatory initiatives, see Bank for International Settlements (2010). Return to text\n\n16. See Group of Twenty (2009), \"Improving Over-the-Counter Derivatives Markets\" (in item 13). Return to text\n\n17. For clarity, figure 3, panel B, illustrates an idealized centrally cleared network in which only one central counterparty clears all trades. In practice, it is entirely possible that more than one central counterparty may accept a given class of contracts for clearing. Research by Darrell Duffie and Haoxiang Zhu, among others, shows that central clearing exhibits significant economies of scale and scope (Duffie and Zhu, 2011). As in other economic enterprises that exhibit strong positive network effects, the potential efficiency gains from consolidation in central clearing need to be appropriately weighed against the countervailing benefits afforded by greater competition among central counterparties. Return to text\n\n18. See International Monetary Fund (2010). Return to text\n\n19. For example, participants and their supervisors will need to closely monitor the risk positions flowing from non-centrally-cleared derivatives to ensure that removing centrally cleared derivatives from existing bilateral netting arrangements will not inadvertently lead to significant growth in risk concentrations from non-centrally-cleared derivatives. Return to text\n\n20. In addition to margin standards, enhanced capital standards prescribed by Basel 2.5 will serve as an important tool for managing systemic risk. See Bank for International Settlements (2009). Return to text\n\n21. See Bank for International Settlements (2012a). Return to text\n\n22. As documented by the Financial Crisis Inquiry Commission, from 1998 to 2007, AIG, through its subsidiary AIG Financial Products, built up huge indirect exposures to real-estate-backed debt by writing OTC credit protection on structured finance products, including mortgage-backed securities and collateralized debt obligations that were in many cases ultimately backed by mortgages. Importantly, because AIG enjoyed a credit rating of AAA for much of this period, its derivatives counterparties did not typically require it to post collateral at the time that new contracts were written. Rather, AIG agreed to post collateral only if contracts fell in market value and AIG itself was downgraded. AIG was first downgraded to AA in the spring of 2005. It faced its first margin calls for credit default swaps covering mortgage-backed collateralized debt obligations in mid-2007. Initially, AIG was able to delay or minimize the collateral it had to post by disputing the contract valuations proposed by its counterparties. But as the bonds it had insured continued to fall in value and AIG was further downgraded, it faced increasing and ultimately insurmountable collateral demands from its derivatives counterparties. For more information, see Financial Crisis Inquiry Commission (2011). Return to text\n\n23. See International Swaps and Derivatives Association (2012). Return to text"
    },
    {
        "title": "The Future of Community Banking",
        "date": "February 05, 2013",
        "speaker": "Governor Elizabeth A. Duke",
        "url": "https://www.federalreserve.gov/newsevents/speech/duke20130205a.htm",
        "content": "February 05, 2013\n\nGovernor Elizabeth A. Duke\n\nAt the Southeastern Bank Management and Directors Conference, University of Georgia, Terry College of Business, Duluth, Georgia\n\nI would like to thank the Terry College of Business at the University of Georgia for the opportunity to discuss the future of community banking at this annual conference for bank officers and directors. Community banks play an important role in our nation's financial system, and I believe that the future of community banking is bright. But that is not to say that it will be easy. Success, as always, will require energetic and engaged managers and board members who are sensitive to the financial needs of their communities, vigilant to economic conditions, and adaptive to changing regulatory requirements.\n\nI hear from a lot of community bankers who are concerned that the community banking model might not survive. Many paint a picture so bleak that they see only personal retirement or sale of the bank as viable strategies. I completely understand how tiring it is to fight a financial crisis and survive a deep recession followed by a weak recovery only to confront what seems to be a tsunami of new regulations.\n\nI felt all of those same emotions in 1991. I was a community banker then. We had survived the savings and loan crisis with some bruises, but we were still standing. The Financial Institutions Reform, Recovery and Enforcement Act of 1989 (FIRREA) had been followed by the Federal Deposit Insurance Corporation Improvement Act (FDICIA) in 1991. I had more new regulations stacked on my desk than I had employees in the bank. My bank had just reached the $100 million mark in total assets through the purchase of two branches from a failing thrift. Even more daunting for me personally, was the sudden death of my bank's chief executive officer (CEO), leaving me as the new CEO. Frankly, I didn't know how I was going to tackle all that lay in front of us. But those dark days in 1991 were followed by 15 years of exceptionally strong performance for all banks, including my own. And those experiences--the good and the bad--give me confidence in predicting a bright future for community banking today.\n\nJust as the seeds of a crisis are often sown in earlier boom times, strength can be forged during the tough times that follow a crisis. As we did in the early 1990s, bankers and regulators today have learned from the lessons of the crisis and are determined not to repeat the mistakes of the past.\n\nCredit metrics are now improving in most banks as problem loans have been addressed and resolved and new credit underwriting has been quite restrictive for a number of years. Deposit growth has outpaced loan demand and reliance on wholesale funding has been reduced. Capital positions are stronger. The interest margin pressure banks face today is partly due to low interest rates and partly due to weak loan demand, both of which are consequences of a sluggish economy. As the economic recovery gains momentum, however, both of these conditions should reverse and give bankers the opportunity to deploy the liquidity and capital they have amassed to the benefit of their shareholders and their local economies.\n\nCommunity Bankers Are Being Heard\nEven as they anticipate economic recovery, however, community bankers worry that the burden of new regulations may inhibit their ability to lend in their communities or prohibitively increase the costs of such lending. We certainly understand this concern. Federal Reserve research over the years has confirmed that the burden of regulations falls disproportionately on smaller banks.\n\nSupervisors at the Federal Reserve Bank of Minneapolis have recently tried to quantify this effect. To do so, they used survey data to estimate the relative number of new employees that banks of different sizes might need to hire in response to the same regulatory requirement. Using Call Report data from 2011, they estimated in their preliminary analysis that hiring one additional employee would reduce the return on assets by 23 basis points for the median bank in the group of smallest banks, those with total assets of $50 million or less. To put this estimate in perspective, such a decline could cause about 13 percent of the banks of that size to go from profitable to unprofitable. As a comparison, given the same increase in regulation, they assume banks between $500 million and $1 billion would hire three employees and experience a decline of about 4 basis points in return on assets for the median bank. While this is still a significant effect, very few banks in this group would go from being profitable to unprofitable as a result of the regulatory burden.\n\nRegulatory overreaction to a crisis is always a risk. But this time, I think community bankers have been more successful than they realize in making the case against \"one-size-fits-all\" regulation. I can't remember a time when I have seen more regulatory proposals drafted that differentiate between banks based on size or complexity. I urge you to continue to identify the regulatory requirements that are the most onerous to your business model, and continue to suggest alternatives to achieve those regulatory objectives in a less intrusive way.\n\nIn fact, most of the regulations required by the Dodd-Frank Wall Street Reform and Consumer Protection Act (the Dodd-Frank Act) are directed primarily at larger, systemically important banks, and many of the Act's provisions specifically exempt community banks. For example, banks with less than $10 billion in total assets were exempted from a number of the debit interchange restrictions, and early studies indicate that those exemptions are working. In addition, formal stress testing was required only for banks with total assets of $10 billion or more. In implementing these requirements for the larger banks, the bank regulatory agencies specifically indicated that capital stress testing would not be required for community banks.1 This does not mean that community banks are exempted from prudent risk management, but rather that smaller banks should think about the negative shocks that could affect their business in the future and tailor their risk-management procedures to the risks and complexities of their individual business models.\n\nThe Consumer Financial Protection Bureau (CFPB) recently released final rules defining \"qualified mortgages\" that include safe harbors for mortgages that meet specific loan term and pricing criteria, including certain balloon loans made by community banks in rural or underserved areas.2 At the same time, they issued a new proposal that contains additional community bank exceptions, as well as a question about the treatment of loans to refinance balloon payments on mortgages that community banks may already have on their books.3 Noting that smaller institutions have already demonstrated that they generally do a good job of servicing the loans they originate and that the investments necessary to meet the requirements would be unduly onerous for institutions that service a small number of loans, the CFPB also exempted most community banks from many of the provisions of new servicing requirements.4 I think such exceptions are especially important because, as I discussed in a recent speech and will touch upon later in my remarks, Federal Reserve research has shown that (1) community banks are important lenders in the mortgage market, (2) those mortgage loans represent a significant portion of community bank lending, and (3) community banks are quite responsible in their practices.5 \n\nAt the Federal Reserve, we have formalized our process for considering the unique characteristics of community banks as we craft regulatory and supervisory policies. A few years ago, we created a subcommittee of the Board, which I chair, that makes recommendations about matters related to community bank supervision and regulation. This subcommittee reviews all regulatory proposals and supervisory guidance with an eye toward the possible effects on community banks. Remembering the days when I had to find time to read all those new regulations stacked up on my desk, I have insisted that all new proposals and rules start with a clear statement of their applicability to community banks so that bankers can spend their time on the rules and guidance that apply to them.\n\nThis approach was put into practice in a different way last year, when the banking agencies issued proposals for capital regulations that incorporated requirements of the Dodd-Frank Act and the Basel agreement.6 To help community banks identify the provisions that affected them and submit their comments more easily, the proposal included a short summary of the provisions that were most likely to affect community banks. We received more than 2,000 comments, many from community banks, and we are reviewing them. It's too early in the process to know how we and the other agencies are going to address the issues raised, or when final rules may be released. But what I can promise is that before we issue final capital rules, we will do everything possible to address the concerns that have been expressed by community bankers and still achieve the goal of having strong levels of high-quality capital--built up over a reasonable and realistic transitional period--in banks of all sizes, including community banks.\n\nCommunity Bank Research\nTo help us better understand community bank issues, our subcommittee established an informal working group of economists from both the research and supervision functions in the Federal Reserve System. The group is focused on understanding the factors that influence the viability and performance of community banks including, importantly, the effect of regulatory changes and their associated costs and benefits. Members of this working group are exploring a number of interesting topics that I hope will help us to better understand the issues that affect community banks and, where appropriate, have a practical impact on how we supervise these banks.\n\nDeterminants of Community Bank Profitability\nFor example, a recent study undertaken by two Federal Reserve Board economists explores the determinants of community bank profitability from 1992 through 2010.7 The findings indicate that a number of bank characteristics are strongly correlated with performance, including relative bank size, portfolio composition, and management quality. Within the group of banks with less than $1 billion in total consolidated assets included in this study, larger bank size is associated with significantly higher profitability. Community banks with higher portfolio shares of real estate loans earn significantly lower profits, while those with higher portfolio shares of construction loans earn higher profits through most of the study period. But, perhaps not surprisingly, the latter relationship does not hold for 2008 through 2010, when greater reliance on construction lending is associated with lower profitability. Managerial quality, as measured by the management component of the banks' regulatory ratings, is strongly related to bank profitability. Moreover, the strength of the relationship increases during and immediately after the financial crisis, confirming that management quality is particularly important during times of economic stress.\n\nFactors outside the control of bank management, however, are also importantly related to profitability, particularly over the past several years. For instance, it is not surprising that community banks operating in markets experiencing high unemployment rates have been less profitable since the financial crisis. Perhaps less obvious is that in urban markets, community bank profitability tends to decrease as the size of the market increases. One might suspect that this relationship derives from a more competitive landscape in larger urban areas; however, no relationship between market concentration and profits is evident in urban markets. In contrast, in rural areas, higher market concentration is associated with higher community bank profitability throughout most of the study period. In addition, the study finds that community banks operating in rural markets consistently earn higher average rates of return than do community banks operating in urban markets.\n\nIn a separate analysis of deposit market competition that may form the basis for a new research paper, one researcher has documented the competitive strength of community banks, especially in rural markets. Although the nationwide share of total deposits held by banks with assets less than $10 billion has declined over the past decade, in rural markets, their deposit market share has increased slightly. Moreover, banks with assets less than $10 billion retained their share of rural market deposits throughout the recent recession and recovery. At a more micro level, banks with assets less than $10 billion gained market share in more than two-thirds of rural banking markets and in nearly half of urban markets between 2003 and 2012.\n\nExpansion of deposit insurance during the crisis likely helped all banks retain deposits and may have changed competition somewhat. Deposit insurance has now been permanently increased from $100,000 to $250,000 per depositor, but the unlimited deposit insurance for noninterest-bearing transaction accounts was allowed to expire at the end of 2012. We are watching deposit movement carefully, but so far have seen little evidence of deposits moving out of the banking system or, as some had feared, moving from smaller banks to larger banks perceived as \"too big to fail.\" My own expectation is that, given all of the enhanced regulatory requirements that apply to larger banks, those larger banks will focus their efforts on large urban markets and that community banks will be even more competitive and more vital to the economic well-being of rural, suburban, and small urban markets.\n\nCharacteristics of Thriving Community Banks\nResearchers at the Federal Reserve Bank of St. Louis took a different approach to measuring community bank success.8 Studying banks with total assets less than $10 billion, the researchers attempted to identify the differences between banks that they classified as \"thriving\" and those that they classified as \"surviving.\" Banks were identified as \"thriving\" if they maintained the highest supervisory rating, a composite CAMELS \"1,\" continuously from 2006 through the end of 2011.9 Approximately 700 banks met this condition. The roughly 4,500 banks in the study that did not qualify as thriving and did not fail or merge out of existence during the period were classified as \"surviving.\"\n\nAfter categorizing the banks, the first phase of analysis looked at the location and size of the thriving banks. Thriving banks were found in 40 of the 50 states but were concentrated in states with larger economic contributions from agriculture and energy, which held up relatively well during the downturn. The fewest thriving banks were found on the West Coast and in the Southeast, where real estate values fell the most. This pattern is consistent with previous Federal Reserve studies, which found that bank performance is heavily affected by the local economy, but I think it is important to note that even in states with high unemployment rates or sharp declines in property values, some community banks were able to thrive.\n\nThe St. Louis study did not find the thriving banks to be concentrated in any particular size range. Many had total assets less than $50 million as of December 2011, but others had total assets between $1 billion and $10 billion. And thriving banks did more than just rate well with supervisors--the thriving banks outperformed the surviving banks on a wide range of performance indicators, including return on assets, return on equity, loan losses, provision expense, efficiency ratio, asset growth, net interest margin, and net noninterest margin.\n\nLooking at balance sheet structure, when the researchers compared the characteristics of thriving banks with surviving banks, they found that the thriving banks had lower levels of loans-to-total-assets and were more reliant on core deposits. Thriving banks also had lower concentrations in commercial real estate (CRE) lending and much lower concentrations in construction and land development loans. Instead, thriving banks were slightly more concentrated in one- to four-family mortgage loans held in portfolio, as well as consumer loans. Despite these overall balance sheet findings, the researchers also noted the wide diversity of business models that they found among the thriving banks.\n\nRecognizing that a large part of good performance comes from factors that are more difficult to measure statistically, the researchers examined a sample of comments in examination reports and found that thriving banks benefited from a strong and localized customer service focus with high visibility in the community, conservative underwriting, and products that were profitable and met customer needs. They supplemented their review of examination reports by interviewing management at some of the thriving banks. The bankers they interviewed attributed their success to strong ties to the community, relationship banking, conservative underwriting, and a focus on products and markets they understood. These results were strikingly similar to the results of interviews in separate studies at the Federal Reserve Bank of Kansas City10 and the Federal Reserve Bank of Richmond.11 \n\nThese studies confirm what experience has already taught me: Community banks that have deep ties to the community, engaged managers and directors, conservative underwriting, and strong risk management can not only survive, but thrive, even in adverse conditions.\n\nUsing Research to Shape Supervisory Guidance on Lending\nWhile much of our regulatory work recently has involved implementing the requirements of the Dodd-Frank Act, we are also continuing to review the lessons we learned during the crisis and the results of our recent research. In most cases, this work is more likely to result in supervisory guidance than regulation. Supervisory guidance is commonly viewed as a means to restrict activity but, in fact, during the crisis much of the guidance we issued actually directed bankers and bank examiners to take a balanced approach. For example, we issued guidance urging banks to continue to make loans to all qualified borrowers and, in particular, to continue lending to creditworthy small businesses.12 We also issued detailed guidance about commercial real estate workouts to encourage prudent modifications of real estate loans.13 \n\nLending is the primary source of income for most community banks and also the greatest source of risk. As you develop your business plans, some of the most important decisions you will make relate to lending. In the planning process, banks should define the portion of the lending portfolio they plan to allocate to different loan categories, the investments they are willing to make to develop expertise and to manage credit and compliance risk, and the levels of credit and interest rate risk they are willing to assume. So I thought it might be helpful to review some recent developments in loan types that are at the core of community bank lending.\n\nResidential Mortgage Lending\nResidential mortgage lending was at the heart of the financial crisis and has been the target of extensive new regulation and supervisory attention, including the rules issued by the CFPB that I discussed earlier. I think community banks are in an especially difficult position with respect to residential mortgage lending. On the one hand, community banks do not appear to have engaged in many of the more problematic practices that led to the crisis. And their rate of seriously delinquent residential mortgage loans is significantly lower than the overall rate of serious delinquencies on such loans made to prime borrowers, indicating that community banks largely have managed their existing portfolios responsibly. On the other hand, residential mortgage loans made by community banks do frequently share some characteristics, such as higher rates and balloon payments, with the subprime lending that proved to be so disastrous. At the same time, mortgage lending, which averages about one-fourth of community bank loan portfolios, is an important product line for community banks. Further, Federal Reserve research indicates that the residential mortgage loans made by community banks make up a small but vital part of credit availability in the housing market.\n\nThe challenge for regulators is to design mortgage regulations to address practices that have proved harmful to consumers or financial stability without inhibiting lending to creditworthy borrowers. The challenge for community bankers is to review the full body of new regulations covering mortgage lending and to develop the expertise and control systems necessary to comply with these regulations while remaining active in this important market.\n\nI think it is unfortunate when I hear some bankers say that they will stop offering mortgages if they can't make them the same way that they always have. While I certainly understand their frustration, I still believe that community bankers can respond within the new environment by creating products that are profitable and meet the needs of their customers, while still managing their interest rate and funding risks.\n\nEven with some regulatory exceptions, compliance with new mortgage regulations likely will require changes to processing systems and extensive staff training. But it is also possible that the systems and expertise necessary to make qualified mortgages for the bank's books could also be used to originate loans for sale. For many community banks, this could represent a new revenue opportunity and a new alternative to offer the bank's customers.\n\nCommercial Real Estate Lending\nFor community banks, it was CRE lending--in particular, lending for construction and land development--that caused the most problems during the crisis. As you may know, in 2006 the federal banking agencies issued supervisory guidance that set forth screening criteria based on certain types of CRE concentrations and rapid growth of CRE portfolios.14 These guidelines contained specific numerical thresholds for the ratios of construction and total CRE lending to an institution's total capital, as well as for identifying rapid growth of such lending.15 These criteria were never intended to result in hard caps, but were instead meant to trigger conversations between a bank and its supervisors about the bank's ability to manage the risks arising from these concentrations.\n\nAfter our experience in the financial crisis, especially considering the severe problems in commercial real estate markets, we were interested in understanding how community banks were affected by the guidance and whether the screening criteria set forth in the guidance were effective indicators of risk. In that regard, Federal Reserve staff has worked with our counterparts at the Office of the Comptroller of the Currency to analyze how banks' holdings of CRE loans have evolved since the guidance was issued.16 \n\nWe have learned a few interesting things based on the findings of this research. For example, the number of institutions that exceed at least one of the two screening criteria has declined substantially from 2006 to the present. While much of this decline seems to have resulted from the contraction of construction portfolios in the wake of the crisis, banks that exceeded the criteria when the guidance was issued appear to have experienced a bigger decline in total CRE loans than can be explained by the adverse economic environment alone. This finding could indicate that the thresholds are indeed being interpreted as hard caps. Moreover, it was apparent that banks that exceeded the criterion for construction and land development were far more likely to have failed over the period from 2007 to 2011 than were those banks that exceeded the criterion for overall CRE exposures and portfolio growth. We now recognize the importance of the rapid growth criterion, which may have received less attention than the criteria for construction and overall CRE lending concentrations. We intend to use the findings of this research to help clarify our communication and training for examiners and bankers around CRE lending concentrations.\n\nSmall Business Lending\n\nThere is probably no loan category in which community bankers' local knowledge and deep ties to the community are more important than small business lending. The Federal Reserve System has a project under way to try to improve our understanding of small business credit markets, which would of course include community banks. One challenge we have faced is that it is difficult to measure lending to small businesses precisely. For one thing, small business owners frequently tap their personal home equity, credit cards, or loans secured by commercial real estate that they own to finance their business operations,17 which means such borrowing is not reported as small business lending. But there is also no definition of small business borrowers for the reporting of small business lending as a loan category.\n\nHowever, small loans to businesses--commercial and industrial loans and CRE loans with original principal amounts of less than $1 million--are reported separately and can be used as a proxy for small business lending. Using this measure, we can estimate the importance of small business lending to community banks and the importance of community banks to small businesses. As of September 2012, banks with $10 billion or less in assets accounted for more than 98 percent of all commercial banking institutions, but they held less than 20 percent of banking industry assets. However, they held more than half of outstanding small loans to businesses. For such institutions, these small loans to businesses represent nearly 20 percent of their total domestic lending and slightly more than 40 percent of their total commercial lending. Small business lending is likely even more important to smaller banks than these statistics show because these loans are identified by the size of the loan rather than the size of the borrower. I believe it is probable that many of the larger business loans made by these smaller banks were also made to small business borrowers.\n\nAt the other end of the spectrum, banking organizations with more than $50 billion in assets accounted for less than one percent of institutions, but held 75 percent of the assets. Holding almost 40 percent of outstanding small loans to businesses, these large banks are important small business lenders, but small loans to businesses were not a significant segment of large bank loan portfolios. They represented less than five percent of these banks' total domestic lending.\n\nThese statistics demonstrate the importance of community banks to small business and the corresponding importance of small business lending to the community banking business model. In developing policies for small business lending, I think it is critically important for bank boards of directors to insist on appropriate risk management that retains the flexibility to use the bankers' knowledge of their customers' business to their best advantage. And it is equally critical that supervisors develop tools to measure the overall effectiveness of risk management in small business lending without being overly prescriptive for individual loans.\n\nConclusion\nI would like to end where I began. I think the future for community banking is bright. I recognize that the regulatory changes underway are not without cost to community banks. But I also know that we at the Federal Reserve are doing our best to avoid adding to regulatory burden wherever possible as we respond to the worst excesses of the financial crisis and make the U.S. financial system more resilient. Research is helpful in this effort but it is also important to maintain an ongoing dialogue with community bankers and to actively solicit comment on regulatory proposals. So I urge you to continue to communicate about the challenges that regulations pose for community banks.\n\nMore importantly, I know that the natural advantages found in community banks--deep community ties, daily interaction between senior managers of banks and their customers, and the dexterity to customize financial solutions--have not been diminished in any way. Yes, the regulatory environment is challenging and the economy remains weak in many areas. But all our research shows that with creative, engaged bankers and strong risk-management processes, community banks can continue to not only survive but to thrive.\n\nThank you very much for your attention, and I would be interested in hearing your thoughts.\n\n \n\n1. See Board of Governors of the Federal Reserve System, Federal Deposit Insurance Corporation, and Office of the Comptroller of the Currency (2012), \"Agencies Clarify Supervisory Expectations for Stress Testing by Community Banks,\" press release, May 14. Return to text\n\n2. See Consumer Financial Protection Bureau (2013), \"Ability-to-Repay and Qualified Mortgage Standards Under the Truth in Lending Act (Regulation Z),\" final rule, Federal Register, vol. 78 (January 30), pp. 6408-6620. Return to text\n\n3. See CFPB (2013), \"Ability to Repay Standards Under the Truth in Lending Act (Regulation Z),\" notice of proposed rulemaking, Federal Register, vol. 78 (January 30), pp. 6622-6672. Return to text\n\n4. See CFPB (2013), \"Mortgage Servicing Rules under the Real Estate Settlement Procedures Act (Regulation X), final rule; and CFPB (2013), \"Mortgage Servicing Rules under the Truth in Lending Act (Regulation Z), \" final rule (accessed January 31, 2013). Return to text\n\n5. See Elizabeth A. Duke (2012), \"Community Banks and Mortgage Lending,\" speech delivered at the Community Bankers Symposium, Chicago, IL, November 9. Return to text\n\n6. See Board of Governors of the Federal Reserve System, Federal Deposit Insurance Corporation, and Office of the Comptroller of the Currency (2012), \"Agencies Seek Comment on Regulatory Capital Rules and Finalize Market Risk Rule,\" press release, June 12. Return to text\n\n7. Dean F. Amel and Robin A. Prager (2010), \"Performance of Community Banks in Good Times and Bad Times,\" unpublished paper, Board of Governors of the Federal Reserve System, Division of Research and Statistics, May. The study defines community banks as those with total organizational banking assets less than $1 billion in constant 2005 dollars and at least 70 percent of deposits derived from a single metropolitan area or rural county. Return to text\n\n8. See R. Alton Gilbert, Andrew P. Meyer, and James W. Fuchs (2013), \"The Future of Community Banks: Lessons from the Banks that Thrived during the Recent Financial Crisis,\" unpublished paper, Federal Reserve Bank of St. Louis, January. Return to text\n\n9. CAMELS is the supervisory rating system for banks and other depository institutions, used by federal and state banking agencies to communicate to financial institutions their assessment of the institution and to identify institutions that raise concern or require special attention. CAMELS is an acronym for the six components of the rating system that examiners evaluate and take into account when assigning an overall composite rating: capital adequacy, asset quality, management, earnings, liquidity, and sensitivity to market risk. See Board of Governors of the Federal Reserve System (1996), Supervision and Regulation Letter 96-38, \"Uniform Financial Institutions Rating System,\" December 27. Return to text\n\n10. See Forest Myers and Kenneth Spong (2003), \"Community Bank Performance in Slower Growing Markets: Finding Sound Strategies for Success (PDF),\" Federal Reserve Bank of Kansas City, Financial Industry Perspectives. Return to text\n\n11. See Ray Brastow, Bob Carpenter, Susan Maxey, and Mike Riddle (2012), \"Weathering the Storm: A Case Study of Healthy Fifth District State Member Banks Over the Recent Downturn ,\" Federal Reserve Bank of Richmond, S&R Perspectives, Summer. See also Community Banking Connections (2012) , Federal Reserve System, Fourth Quarter. Return to text\n\n12. See Board of Governors of the Federal Reserve System, Federal Deposit Insurance Corporation, Office of the Comptroller of the Currency, and Office of Thrift Supervision (2008), \"Interagency Statement on Meeting the Needs of Creditworthy Borrowers,\" press release, November 12; and Board of Governors of the Federal Reserve System, Federal Deposit Insurance Corporation, National Credit Union Administration, Office of the Comptroller of the Currency, Office of Thrift Supervision, and Conference of State Bank Supervisors (2010), \"Regulators Issue Statement on Lending to Creditworthy Small Businesses\" press release, February 5. Return to text\n\n13. See Board of Governors of the Federal Reserve System (2009), Supervision and Regulation letter 09-7, \"Prudent Commercial Real Estate Loan Workouts,\" October 30. Return to text\n\n14. See Board of Governors of the Federal Reserve System, Office of the Comptroller of the Currency, and Federal Deposit Insurance Corporation (2006), \"Concentrations in Commercial Real Estate Lending, Sound Risk Management Practices,\"final guidance, Federal Register, vol. 71 (December 12), pp 74580-88. See also Board of Governors of the Federal Reserve System (2007), Supervision and Regulation Letter 07-1, \"Interagency Guidance on Concentrations in Commercial Real Estate,\" January 4. Return to text\n\n15. Specifically, the guidance indicated that examiners would give heightened supervisory scrutiny to banks where (1) total construction and land development loans represented 100 percent or more of the institution's total capital, or (2) total CRE loans represented 300 percent or more of the institution's total capital and the institution's CRE loan portfolio had increased by 50 percent or more during the prior 36 months. This second criteria is calculated excluding holdings of owner-occupied CRE loans. Return to text\n\n16. Keith Friend, Harry Glenos, and Joseph B. Nichols (2013), \"An Analysis of the Impact of the Commercial Real Estate Concentration Guidance,\" unpublished paper, Board of Governors of the Federal Reserve System, Division of Banking Supervision and Regulation, and Office of the Comptroller of the Currency, January; and William Bassett and W. Blake Marsh (2012), \"Cause or Effect: Supervisory Guidance and the Collapse of Commercial Real Estate,\" unpublished paper, Board of Governors of the Federal Reserve System Division of Monetary Affairs, October. Return to text\n\n17. In the Federal Reserve's 2010 Survey of Consumer Finances, 18 percent of households reported personally guaranteeing or collateralizing loans to their family businesses, and 15 percent of households reported lending money to their family businesses. See Jesse Bricker, Arthur B. Kennickell, Kevin B. Moore, and John Sabelhaus (2012), \"Changes in U.S. Family Finances from 2007 to 2010: Evidence from the Survey of Consumer Finances (PDF),\" Federal Reserve Bulletin, vol. 98, no. 2 (June). See also the Federal Reserve public website for the Survey of Consumer Finances. Return to text"
    },
    {
        "title": "Overheating in Credit Markets: Origins, Measurement, and Policy Responses",
        "date": "February 07, 2013",
        "speaker": "Governor Jeremy C. Stein",
        "url": "https://www.federalreserve.gov/newsevents/speech/stein20130207a.htm",
        "content": "February 07, 2013\n\nGovernor Jeremy C. Stein\n\nAt the \"Restoring Household Financial Stability after the Great Recession: Why Household Balance Sheets Matter\" research symposium sponsored by the Federal Reserve Bank of St. Louis, St. Louis, Missouri\n\nThank you very much. It's a pleasure to be here. The question I'd like to address today is this: What factors lead to overheating episodes in credit markets?1 In other words, why do we periodically observe credit booms, times during which lending standards appear to become lax and which tend to be followed by low returns on credit instruments relative to other asset classes?2 We have seen how such episodes can sometimes have adverse effects on the financial system and the broader economy, and the hope would be that a better understanding of the causes can be helpful both in identifying emerging problems on a timely basis and in thinking about appropriate policy responses.\n\nTwo Views of the Overheating Mechanism\nI will start by sketching two views that might be invoked to explain variation in the pricing of credit risk over time: a \"primitive preferences and beliefs\" view and an \"institutions, agency, and incentives\" view. While the first view is a natural starting point, I will argue that it must be augmented with the second view if one wants to fully understand the dynamics of overheating episodes in credit markets.\n\nAccording to the primitives view, changes in the pricing of credit over time reflect fluctuations in the preferences and beliefs of end investors such as households, where these beliefs may or may not be entirely rational. Perhaps credit is cheap when household risk tolerance is high--say, because of a recent run-up in wealth.3 Or maybe credit is cheap when households extrapolate current good times into the future and neglect low-probability risks.4 \n\nThe primitives view is helpful for understanding some aspects of the behavior of the aggregate stock market, with the 1990s Internet bubble being one illustration. It seems clear that the sentiment of retail investors played a prominent role in inflating this bubble.5 More generally, research using survey evidence has shown that when individual investors are most optimistic about future stock market returns, the market tends to be overvalued, in the sense that statistical forecasts of equity returns are abnormally low.6 This finding is consistent with the importance of primitive investor beliefs.\n\nBy contrast, I am skeptical that one can say much about time variation in the pricing of credit--as opposed to equities--without focusing on the roles of institutions and incentives. The premise here is that since credit decisions are almost always delegated to agents inside banks, mutual funds, insurance companies, pension funds, hedge funds, and so forth, any effort to analyze the pricing of credit has to take into account not only household preferences and beliefs, but also the incentives facing the agents actually making the decisions. And these incentives are in turn shaped by the rules of the game, which include regulations, accounting standards, and a range of performance-measurement, governance, and compensation structures.\n\nAt an abstract level, one can think of the agents making credit decisions and the rulemakers who shape their incentives as involved in an ongoing evolutionary process, in which each adapts over time in response to changing conditions. At any point, the agents try to maximize their own compensation, given the rules of the game. Sometimes they discover vulnerabilities in these rules, which they then exploit in a way that is not optimal from the perspective of their own organizations or society. If the damage caused is significant enough, the rules themselves adapt, driven either by internal governance or by political and regulatory forces. Still, it is possible that at different times in this process, the rules do a better or worse job of managing the incentives of the agents.\n\nTo be more specific, a fundamental challenge in delegated investment management is that many quantitative rules are vulnerable to agents who act to boost measured returns by selling insurance against unlikely events--that is, by writing deep out-of-the-money puts. An example is that if you hire an agent to manage your equity portfolio, and compensate the agent based on performance relative to the S&P 500, the agent can beat the benchmark simply by holding the S&P 500 and stealthily writing puts against it, since this put-writing both raises the mean and lowers the measured variance of the portfolio.7 Of course, put-writing also introduces low-probability risks that may make you, as the end investor, worse off, but if your measurement system doesn't capture these risks adequately--which is often difficult to do unless one knows what to look for--then the put-writing strategy will create the appearance of outperformance.\n\nSince credit risk by its nature involves an element of put-writing, it is always going to be challenging in an agency context, especially to the extent that the risks associated with the put‑writing can be structured to partially evade the relevant measurement scheme. Think of the AAA-rated tranche of a subprime collateralized debt obligation (CDO), where the measurement scheme is the credit risk model used by the rating agency. To the extent that this model is behind the curve and does not fully recognize the additional structural leverage and correlational complexities embedded in a second-generation securitization like the CDO, as opposed to a first-generation one, it will be particularly vulnerable to the introduction of a second-generation product.8 \n\nThese agency problems may be exacerbated by competitive pressures among intermediaries and by the associated phenomenon of relative performance evaluation. A leading example here comes from the money market fund sector, where even small increases in a money fund's yield relative to its competitors can attract large inflows of new assets under management.9 And if these yield differentials reflect not managerial skill but rather additional risk-taking, then competition among funds to attract assets will only make the underlying put-writing problem worse.\n\nBut it is not all that satisfying--either intellectually or from a policy perspective--to simply list all of the ways that the delegation of credit decisions to agents inside big, complicated institutions can lead things astray. It must be the case that, on average over long periods of time, these agency problems are contained tolerably well by the rules of the game--by some combination of private governance and public policy--or else our credit markets would not be as large and as well developed as they are. A more interesting set of questions has to do with time-series dynamics: Why is it that sometimes, things get out of balance, and the existing set of rules is less successful in containing risk-taking? In other words, what does the institutions view tell us about why credit markets sometimes overheat?\n\nLet me suggest three factors that can contribute to overheating. The first is financial innovation. While financial innovation has provided important benefits to society, the institutions perspective warns of a dark side, which is that innovation can create new ways for agents to write puts that are not captured by existing rules. For this reason, policymakers should be on alert any time there is rapid growth in a new product that is not yet fully understood. Perhaps the best explanation for the existence of second-generation securitizations like subprime CDOs is that they evolved in response to flaws in prevailing models and incentive schemes.10 Going back further, a similar story can be told about the introduction of payment-in-kind (PIK) interest features in the high-yield bonds used in the leveraged buyouts (LBOs) of the late 1980s. I don't think it was a coincidence that among the buyers of such PIK bonds were savings and loan associations, at a time when many were willing to take risks to boost their accounting incomes.\n\nThe second closely related factor on my list is changes in regulation. New regulation will tend to spur further innovation, as market participants attempt to minimize the private costs created by new rules. And it may also open up new loopholes, some of which may be exploited by variants on already existing instruments.\n\nThe third factor that can lead to overheating is a change in the economic environment that alters the risk-taking incentives of agents making credit decisions. For example, a prolonged period of low interest rates, of the sort we are experiencing today, can create incentives for agents to take on greater duration or credit risks, or to employ additional financial leverage, in an effort to \"reach for yield.\"11 An insurance company that has offered guaranteed minimum rates of return on some of its products might find its solvency threatened by a long stretch of low rates and feel compelled to take on added risk.12 A similar logic applies to a bank whose net interest margins are under pressure because low rates erode the profitability of its deposit-taking franchise.\n\nMoreover, these three factors may interact with one another. For example, if low interest rates increase the demand by agents to engage in below-the-radar forms of risk-taking, this demand may prompt innovations that facilitate this sort of risk-taking.\n\nWhy the Distinction Matters\nTo summarize the argument thus far, I have drawn a distinction between two views of risk-taking in credit markets. According to the primitives view, changes over time in effective risk appetite reflect the underlying preferences and beliefs of end investors. According to the institutions view, such changes reflect the imperfectly aligned incentives of the agents in large financial institutions who do the investing on behalf of these end investors. But why should anybody care about this distinction?\n\nOne reason is that your view of the underlying mechanism shapes how you think about measurement. Consider this question: Is the high-yield bond market currently overheated, in the sense that it might be expected to offer disappointing returns to investors? What variables might one look at to shape such a forecast? In a primitives-driven world, it would be natural to focus on credit spreads, on the premise that more risk tolerance on the part of households would lead them to bid down credit spreads; these lower spreads would then be the leading indicator of low expected returns.\n\nOn the other hand, in an institutions-driven world, where agents are trying to exploit various incentive schemes, it is less obvious that increased risk appetite is as well summarized by reduced credit spreads. Rather, agents may prefer to accept their lowered returns via various subtler nonprice terms and subordination features that allow them to maintain a higher stated yield. Again, the use of PIK bonds in LBOs is instructive. A long time ago, Steve Kaplan and I did a study of the capital structure of 1980s-era LBOs.13 What was most noteworthy about the PIK bonds in those deals was not that they had low credit spreads. Rather, it was that they were subject to an extreme degree of implicit subordination. While these bonds were not due to get cash interest for several years, they stood behind bank loans with very fast principal repayment schedules, which in many cases required the newly leveraged firm to sell a large chunk of its assets just to honor these bank loans. Simply put, much of the action--and much of the explanatory power for the eventual sorry returns on the PIK bonds--was in the nonprice terms.\n\nIt is interesting to think about recent work by Robin Greenwood and Sam Hanson through this lens.14 They show that if one is interested in forecasting excess returns on corporate bonds (relative to Treasury securities) over the next few years, credit spreads are indeed helpful, but another powerful predictive variable is a nonprice measure: the high-yield share, defined as issuance by speculative-grade firms divided by total bond issuance. When the high-yield share is elevated, future returns on corporate credit tend to be low, holding fixed the credit spread. Exhibit 1 provides an illustration of their finding. One possible interpretation is that the high-yield share acts as a summary statistic for a variety of nonprice credit terms and structural features. That is, when agents' risk appetite goes up, they agree to fewer covenants, accept more-implicit subordination, and so forth, and high-yield issuance responds accordingly, hence its predictive power.\n\nA second implication of the institutions view is what one might call the \"tip of the iceberg\" caveat. Quantifying risk-taking in credit markets is difficult in real time, precisely because risks are often taken in opaque ways that escape conventional measurement practices. So we should be humble about our ability to see the whole picture, and should interpret those clues that we do see accordingly. For example, I have mentioned the junk bond market several times, but not because this market is necessarily the most important venue for the sort of risk-taking that is likely to raise systemic concerns. Rather, because it offers a relatively long history on price and nonprice terms, it is arguably a useful barometer. Thus, overheating in the junk bond market might not be a major systemic concern in and of itself, but it might indicate that similar overheating forces were at play in other parts of credit markets, out of our range of vision.\n\nRecent Developments in Credit Markets\nWith these remarks as a prelude, what I'd like to do next is take you on a brief tour of recent developments in a few selected areas of credit markets. This tour draws heavily on work conducted by the Federal Reserve staff as part of our ongoing quantitative surveillance efforts, under the auspices of our Office of Financial Stability Policy and Research.\n\nThe first stop on the tour is the market for leveraged finance, encompassing both the public junk bond market and the syndicated leveraged loan market. As can be seen in exhibit 2, issuance in both of these markets has been very robust of late, with junk bond issuance setting a new record in 2012. In terms of the variables that could be informative about the extent of market overheating, the picture is mixed. On the one hand, credit spreads, though they have tightened in recent months, remain moderate by historical standards. For example, as exhibit 3 shows, the spread on nonfinancial junk bonds, currently at about 400 basis points, is just above the median of the pre-financial-crisis distribution, which would seem to imply that pricing is not particularly aggressive.15 \n\nOn the other hand, the high-yield share for 2012 was above its historical average, suggesting--based on the results of Greenwood and Hanson--a somewhat more pessimistic picture of prospective credit returns.16 This notion is supported by recent trends in the sorts of nonprice terms I discussed earlier (exhibit 4). The annualized rates of PIK bond issuance and of covenant-lite loan issuance in the fourth quarter of 2012 were comparable to highs from 2007. The past year also saw a new record in the use of loan proceeds for dividend recapitalizations, which represents a case in which bondholders move further to the back of the line while stockholders--often private equity firms--cash out.17 Finally, leverage in large LBOs rose noticeably, though less dramatically, in the third and fourth quarters of 2012.\n\nPutting it all together, my reading of the evidence is that we are seeing a fairly significant pattern of reaching-for-yield behavior emerging in corporate credit. However, even if this conjecture is correct, and even if it does not bode well for the expected returns to junk bond and leveraged-loan investors, it need not follow that this risk-taking has ominous systemic implications. That is, even if at some point junk bond investors suffer losses, without spillovers to other parts of the system, these losses may be confined and therefore less of a policy concern.\n\nIn this regard, one lesson from the crisis is that it is not just bad credit decisions that create systemic problems, but bad credit decisions combined with excessive maturity transformation. A badly underwritten subprime loan is one thing, and a badly underwritten subprime loan that serves as the collateral for asset-backed commercial paper (ABCP) held by a money market fund is something else--and more dangerous. This observation suggests an idealized measurement construct. In principle, what we'd really like to know, for any given asset class--be it subprime mortgages, junk bonds, or leveraged loans--is this: What fraction of it is ultimately financed by short-term demandable claims held by investors who are likely to pull back quickly when things start to go bad? It is this short-term financing share that creates the potential for systemic spillovers in the form of deleveraging and marketwide fire sales of illiquid assets.\n\nThis short-term financing share is difficult to measure comprehensively, but exhibit 5 presents one graph that gives some comfort. The graph shows dealer financing of corporate debt securities, much of which is done via short-term repurchase agreements (repos). This financing rose rapidly in the years prior to the crisis, then fell sharply, and remains well below its pre-crisis levels today. So, on this score, there appears to be only modest short-term leverage behind corporate credit, which would seem to imply that even if the underlying securities were aggressively priced, the potential for systemic harm resulting from deleveraging and fire sales would be relatively limited.\n\nNevertheless, I want to urge caution here and, again, stress how hard it is to capture everything we'd like. As I said, ideally we would total all of the ways in which a given asset class is financed with short-term claims. Repos constitute one example, but there are others. And, crucially, these short-term claims need not be debt claims. If relatively illiquid junk bonds or leveraged loans are held by open-end investment vehicles such as mutual funds or by exchange-traded funds (ETFs), and if investors in these vehicles seek to withdraw at the first sign of trouble, then this demandable equity will have the same fire-sale-generating properties as short-term debt.18 One is naturally inclined to look at data on short-term debt like repo, given its prominence in the recent crisis. But precisely because it is being more closely monitored, there is the risk that next time around, the short-term claims may take another form.\n\nWith this caveat in mind, it is worth noting the pattern of inflows into mutual funds and ETFs that hold high-yield bonds, shown in exhibit 6. Interestingly, the picture here is almost the reverse of that seen with dealer financing of corporate bonds. Assets under management in these vehicles were essentially flat in the years leading up to the crisis, but they have increased sharply in the past couple of years.19 This observation suggests, albeit only loosely, that there may be some substitutability between different forms of demandable finance. And it underscores the importance of not focusing too narrowly on any one category.\n\nContinuing on with the theme of maturity transformation, the next brief stop on the tour is the agency mortgage real estate investment trust (REIT) sector. These agency REITs buy agency mortgage-backed securities (MBS), fund them largely in the short-term repo market in what is essentially a levered carry trade, and are required to pass through at least 90 percent of the net interest to their investors as dividends. As shown in exhibit 7, they have grown rapidly in the past few years, from $152 billion at year-end 2010 to $398 billion at the end of the third quarter of 2012.\n\nOne interesting aspect of this business model is that its economic viability is sensitive to conditions in both the MBS market and the repo market. If MBS yields decline, or the repo rate rises, the ability of mortgage REITs to generate current income based on the spread between the two is correspondingly reduced.\n\nAnother place where the desire to generate yield can show up is in commercial banks' securities holdings. In recent work, Sam Hanson and I documented that the duration of banks' non-trading-account securities holdings tends to increase significantly when the short rate declines.20 We hypothesized that this pattern was due to a particular form of agency behavior--namely, that given the conventions of generally accepted accounting principles, a bank can boost its reported income by replacing low-yielding short-duration securities with higher-yielding long-duration securities.\n\nSomething along these lines seems to be happening today: The maturity of securities in banks' available-for-sale portfolios is near the upper end of its historical range. This finding is noteworthy on two counts. First, the added interest rate exposure may itself be a meaningful source of risk for the banking sector and should be monitored carefully--especially since existing capital regulation does not explicitly address interest rate risk. And, second, in the spirit of tips of icebergs, the possibility that banks may be reaching for yield in this manner suggests that the same pressure to boost income could be affecting behavior in other, less readily observable parts of their businesses.\n\nThe final stop on the tour is something called collateral transformation. This activity has been around in some form for quite a while and does not currently appear to be of a scale that would raise serious concerns--though the available data on it are sketchy at this point. Nevertheless, it deserves to be highlighted because it is exactly the kind of activity where new regulation could create the potential for rapid growth and where we therefore need to be especially watchful.\n\nCollateral transformation is best explained with an example. Imagine an insurance company that wants to engage in a derivatives transaction. To do so, it is required to post collateral with a clearinghouse, and, because the clearinghouse has high standards, the collateral must be \"pristine\"--that is, it has to be in the form of Treasury securities. However, the insurance company doesn't have any unencumbered Treasury securities available--all it has in unencumbered form are some junk bonds. Here is where the collateral swap comes in. The insurance company might approach a broker-dealer and engage in what is effectively a two-way repo transaction, whereby it gives the dealer its junk bonds as collateral, borrows the Treasury securities, and agrees to unwind the transaction at some point in the future. Now the insurance company can go ahead and pledge the borrowed Treasury securities as collateral for its derivatives trade.\n\nOf course, the dealer may not have the spare Treasury securities on hand, and so, to obtain them, it may have to engage in the mirror-image transaction with a third party that does--say, a pension fund. Thus, the dealer would, in a second leg, use the junk bonds as collateral to borrow Treasury securities from the pension fund. And why would the pension fund see this transaction as beneficial? Tying back to the theme of reaching for yield, perhaps it is looking to goose its reported returns with the securities-lending income without changing the holdings it reports on its balance sheet.\n\nThere are two points worth noting about these transactions. First, they reproduce some of the same unwind risks that would exist had the clearinghouse lowered its own collateral standards in the first place. To see this point, observe that if the junk bonds fall in value, the insurance company will face a margin call on its collateral swap with the dealer. It will therefore have to scale back this swap, which in turn will force it to partially unwind its derivatives trade--just as would happen if it had posted the junk bonds directly to the clearinghouse. Second, the transaction creates additional counterparty exposures--the exposures between the insurance company and the dealer, and between the dealer and the pension fund.\n\nAs I said, we don't have evidence to suggest that the volume of such transactions is currently large. But with a variety of new regulatory and institutional initiatives on the horizon that will likely increase the demand for pristine collateral--from the Basel III Liquidity Coverage Ratio, to centralized clearing, to heightened margin requirements for noncleared swaps--there appears to be the potential for rapid growth in this area. Some evidence suggestive of this growth potential is shown in exhibit 8, which is based on responses by a range of dealer firms to the Federal Reserve's Senior Credit Officer Opinion Survey on Dealer Financing Terms.21 As can be seen, while only a modest fraction of those surveyed reported that they were currently engaged in collateral transformation transactions, a much larger share reported that they had been involved in discussions of prospective transactions with their clients.\n\nPolicy Implications\nLet me turn now to policy implications. The question of how policymakers should respond to different manifestations of credit market overheating is a big and difficult one, and I won't attempt to deliver a set of specific prescriptions here. However, I would like to provoke some discussion around one specific aspect of the question--namely, what are the respective roles of traditional supervisory and regulatory tools, on the one hand, versus monetary policy, on the other, in addressing the sorts of market-overheating phenomena that we have been talking about? To lend a little concreteness and urgency to this issue, imagine that it is 18 months from now, and that with interest rates still very low, each of the trends that I identified earlier has continued to build--to the point where we believe that there could be meaningful systemic implications. What, if any, policy measures should be contemplated?\n\nIt is sometimes argued that in such circumstances, policymakers should follow what might be called a decoupling approach. That is, monetary policy should restrict its attention to the dual mandate goals of price stability and maximum employment, while the full battery of supervisory and regulatory tools should be used to safeguard financial stability. There are several arguments in favor of this approach. First, monetary policy can be a blunt tool for dealing with financial stability concerns. Even if we stipulate that low interest rates are part of the reason for, say, a worrisome boom in one segment of credit markets, they are unlikely to be the whole story. So, would one really want to raise rates, and risk choking off economic activity, in an effort to rein in that one part of the market? Wouldn't it be better to use a more narrowly focused supervisory or regulatory approach, with less potential for damage to the economy?\n\nA related concern is that monetary policy already has its hands full with the dual mandate, and that if it is also made partially responsible for financial stability, it will have more objectives than instruments at its disposal and won't do as well with any of its tasks.22 These are important points to bear in mind. In some cases, supervisory and regulatory tools are clearly better targeted and more likely to be effective than monetary policy could be. For example, the Federal Reserve's supervisory responsibilities for the banking sector put it in the right position to carefully monitor duration risk in banks' securities portfolios and to take corrective action if necessary.\n\nNevertheless, as we move forward, I believe it will be important to keep an open mind and avoid adhering to the decoupling philosophy too rigidly. In spite of the caveats I just described, I can imagine situations where it might make sense to enlist monetary policy tools in the pursuit of financial stability. Let me offer three observations in support of this perspective. First, despite much recent progress, supervisory and regulatory tools remain imperfect in their ability to promptly address many sorts of financial stability concerns. If the underlying economic environment creates a strong incentive for financial institutions to, say, take on more credit risk in a reach for yield, it is unlikely that regulatory tools can completely contain this behavior. This, of course, is not to say that we should not try to do our best with these tools--we absolutely should. But we should also be realistic about their limitations. These limitations arise because of the inherent fallibility of the tools in a world of regulatory arbitrage; because the scope of our regulatory authority does not extend equally to all parts of the financial system; and because risk-taking naturally tends to be structured in a nontransparent way that can make it hard to recognize. In some cases, regulatory tools may also be difficult to adjust on a timely basis--if, for example, doing so requires extended interagency negotiation.\n\nSecond, while monetary policy may not be quite the right tool for the job, it has one important advantage relative to supervision and regulation--namely that it gets in all of the cracks. The one thing that a commercial bank, a broker-dealer, an offshore hedge fund, and a special purpose ABCP vehicle have in common is that they all face the same set of market interest rates. To the extent that market rates exert an influence on risk appetite, or on the incentives to engage in maturity transformation, changes in rates may reach into corners of the market that supervision and regulation cannot.23 \n\nThird, in response to concerns about numbers of instruments, we have seen in recent years that the monetary policy toolkit consists of more than just a single instrument. We can do more than adjust the federal funds rate. By changing the composition of our asset holdings, as in our recently completed maturity extension program (MEP), we can influence not just the expected path of short rates, but also term premiums and the shape of the yield curve. Once we move away from the zero lower bound, this second instrument might continue to be helpful, not simply in providing accommodation, but also as a complement to other efforts on the financial stability front.\n\nTo see why, recall the central role that maturity transformation--the funding of long-term assets with short-term, run-prone liabilities--can play in propagating systemic instabilities. Moreover, as illustrated by the mortgage REIT sector that I described earlier, the economic appeal of maturity transformation hinges on the shape of the yield curve--in that particular case, on the spread between the yield on agency MBS and the so-called general collateral (GC) repo rate at which these securities can be funded on a short-term basis. And it would appear that our policies have at times put pressure on this spread from both sides. Our purchases of long-term Treasury securities and agency MBS have clearly helped reduce long-term yields, and a number of observers have suggested that an unintended byproduct of our MEP--and the associated sales of short-term Treasury securities--was to exert an upward influence on GC repo rates.\n\nThis sort of compression of term spreads is the twist in Operation Twist. And you can see the financial stability angle as well as a possible response to concerns over numbers of instruments. Suppose that, at some point in the future, once we are away from the zero lower bound, our dual mandate objectives call for an easing in policy. Also suppose that, at the same time, there is a general concern about excessive maturity transformation in various parts of the financial system, and that we are having a hard time reining in this activity with conventional regulatory tools. It might be that the right combination of policies would be to lower the path of the federal funds rate--thereby effectuating the needed easing--while at the same time engaging in MEP-like asset swaps to flatten the yield curve and reduce the appeal of maturity transformation.\n\nConclusion\nI hope you will take this last example in the spirit in which it was intended--not as a currently actionable policy proposal, but as an extended hypothetical meant to give some tangible substance to a broader theme. That broader theme is as follows: One of the most difficult jobs that central banks face is in dealing with episodes of credit market overheating that pose a potential threat to financial stability. As compared with inflation or unemployment, measurement is much harder, so even recognizing the extent of the problem in real time is a major challenge. Moreover, the supervisory and regulatory tools that we have, while helpful, are far from perfect.\n\nThese observations suggest two principles. First, decisions will inevitably have to be made in an environment of significant uncertainty, and standards of evidence should be calibrated accordingly. Waiting for decisive proof of market overheating may amount to an implicit policy of inaction on this dimension. And, second, we ought to be open-minded in thinking about how to best use the full array of instruments at our disposal. Indeed, in some cases, it may be that the only way to achieve a meaningfully macroprudential approach to financial stability is by allowing for some greater overlap in the goals of monetary policy and regulation.\n\nThank you very much.\n \n\nReferences\n\nAmromin, Gene, and Steve Sharpe (2012). \"From the Horse's Mouth: How do Investor Expectations of Risk and Return Vary with Economic Conditions? (PDF) ,\" Federal Reserve Bank of Chicago Working Paper 2012-08.\n\nBernanke, Ben S., and Mark Gertler (1989). \"Agency Costs, Net Worth, and Business Fluctuations,\" American Economic Review, vol. 79 (March), pp. 14-31.\n\nBorio, Claudio, and Mathias Drehmann (2009). \"Financial Instability and Macroeconomics: Bridging the Gulf,\" paper prepared for the Twelfth Annual International Banking Conference, \"The International Financial Crisis: Have the Rules of Finance Changed?\" held at the Federal Reserve Bank of Chicago, Chicago, September 24-25.\n\nCampbell, John Y., and John H. Cochrane (1999). \"By Force of Habit: A Consumption-Based Explanation of Aggregate Stock Market Behavior,\" Journal of Political Economy, vol.107 (April), pp. 205-51.\n\nCoval, Joshua, Jakub Jurek, and Erik Stafford (2009). \"The Economics of Structured Finance,\" Journal of Economic Perspectives, vol. 23 (Winter), pp. 3-25.\n\nDeMarzo, Peter M. (2005). \"The Pooling and Tranching of Securities: A Model of Informed Intermediation,\" Review of Financial Studies, vol. 18 (Spring), pp. 1-35.\n\nDeMarzo, Peter, and Darrell Duffie (1999). \"A Liquidity-Based Model of Security Design,\" Econometrica, vol. 67 (January), pp. 65-99.\n\nGennaioli, Nicola, Andrei Shleifer, and Robert Vishny (2012). \"Neglected Risks, Financial Innovation, and Financial Fragility,\" Journal of Financial Economics, vol. 104 (June), pp.452‑68.\n\nGorton, Gary, and George Pennacchi (1990). \"Financial Intermediaries and Liquidity Creation,\" Journal of Finance, vol. 45 (March), pp. 49-71.\n\nGreenwood , Robin, and Samuel G. Hanson (2012). \"Issuer Quality and Corporate Bond Returns (PDF) ,\" unpublished paper, Harvard University, September.\n\nGreenwood, Robin, and Andrei Shleifer (2012). \"Expectations of Returns and Expected Returns (PDF) ,\" unpublished paper, Harvard University, October.\n\nGriffin, John M., Jeffrey H. Harris, Tao Shu, and Selim Topaloglu (2011). \"Who Drove and Burst the Tech Bubble?\" Journal of Finance, vol. 66 (August), pp. 1251-90.\n\nHanson, Samuel G., and Jeremy C. Stein (2012). \"Monetary Policy and Long-Term Real Rates,\" Finance and Economics Discussion Series 2012-46. Washington: Board of Governors of the Federal Reserve System, July.\n\nJensen, Michael C., and William H. Meckling (1976). \"Theory of the Firm: Managerial Behavior, Agency Costs and Ownership Structure,\" Journal of Financial Economics, vol. 3 (October), pp. 305-60.\n\nJurek, Jakub W., and Erik Stafford (2011). \"The Cost of Capital for Alternative Investments (PDF) ,\" Working Paper Series 12-013. Cambridge, Mass.: Harvard Business School, September.\n\nKacperczyk, Marcin, and Philipp Schnabl (2012). \"How Safe Are Money Market Funds? (PDF) \" unpublished paper, New York University, June.\n\nKaplan, Steven, and Jeremy C. Stein (1993). \"The Evolution of Buyout Pricing and Financial Structure in the 1980s,\" Quarterly Journal of Economics, vol. 108 (May), pp.313-57.\n\nMerton, Robert C. (1974). \"On the Pricing of Corporate Debt: The Risk Structure of Interest Rates,\" Journal of Finance, vol. 29 (May), pp. 449-70.\n\nRajan, Raghuram G. (2006). \"Has Finance Made the World Riskier?\" European Financial Management, vol. 12 (September), pp. 499-533.\n\nShleifer, Andrei, and Robert W. Vishny (1997). \"The Limits of Arbitrage,\" Journal of Finance, vol. 52 (March), pp. 35-55.\n\nTinbergen, Jan (1952). Contributions to Economic Analysis, vol. 1: On the Theory of Economic Policy (Amsterdam: North-Holland).\n \n\n1. The thoughts that follow are my own and do not necessarily reflect the views of my colleagues on the Board of Governors or the Federal Open Market Committee. I am grateful to Burcu Duygan-Bump, Matt Eichner, Jon Faust, Michael Kiley, Nellie Liang, Fabio Natalucci, and Bill Nelson for numerous helpful conversations and suggestions. Return to text\n\n2. I am using the term \"overheating\" in an asset-pricing sense, so when I say that the market for a particular class of credit instruments is overheated, I mean that forecasted returns on this class of instruments, in excess of those on riskless Treasury bills, are abnormally low, or even negative, over some horizon. This usage contrasts with models in the genre pioneered by Bernanke and Gertler (1989), where time-variation in collateral values can lead to large changes in the supply of certain types of credit but where expected returns on credit are constant over time. Return to text\n\n3. Habit-formation models have this property. See, for example, Campbell and Cochrane (1999). Return to text\n\n4. See Gennaioli, Shleifer, and Vishny (2012). Return to text\n\n5. For example, Griffin and others (2011) document that during the run-up of the Internet bubble, from January 1997 to March 2000, individual investors were substantial net buyers of tech stocks, via both direct purchases as well as investments in tech-sector-specific mutual funds. Return to text\n\n6. See Amromin and Sharpe (2012), and Greenwood and Shleifer (2012). Return to text\n\n7. Jurek and Stafford (2012) argue that implicit put-writing of this sort accounts for much of the apparent measured alpha in hedge funds. Return to text\n\n8. To be clear on terminology: A subprime CDO is a securitization where the collateral is composed of the mezzanine tranches of residential mortgage-backed securities (RMBS), as opposed to a collection of the underlying mortgages. Thus, in this case, the RMBS is the first-generation securitization, and the CDO, which takes as its input a specific tranche of the RMBS, is the second-generation product. See Coval, Jurek, and Stafford (2009) for an analysis of the relative risks and modeling uncertainties of first and second-generation securitizations. Return to text\n\n9. See Kacperczyk and Schnabl (2012). Return to text\n\n10. To be clear, I do not intend this critique to apply to first-generation securitizations, such as RMBS, asset-backed securities collateralized by auto and credit card loans, or collateralized loan obligations (where the collateral pool is composed of bank loans). As a number of academic studies have emphasized, the basic pooling-and-tranching structure of these securitizations can help reduce adverse selection problems in markets, and thereby increase liquidity and reduce financing costs. See, for example, Gorton, and Pennacchi (1990), DeMarzo and Duffie (1999), and DeMarzo (2005). Return to text\n\n11. See Rajan (2006) for an early exposition of the reach-for-yield phenomenon. Return to text\n\n12. This mechanism is the classic risk-shifting effect described by Jensen and Meckling (1976).Return to text\n\n13. See Kaplan and Stein (1993). Return to text\n\n14. See Greenwood and Hanson (2012). Return to text\n\n15. To be precise, the spread was at 397 basis points as of January 28, 2013, as compared to a median value of 388 basis points over the period January 1997 to July 2007, and a mean of 447 basis points over the same period. Return to text\n\n16. See Greenwood and Hanson (2012). Return to text\n\n17. One factor that complicates the interpretation is that, in late 2012, one might have expected an increase in dividend-recap loans even absent any change in investor risk appetite, based on the anticipation of future dividend tax increases. Return to text\n\n18. Indeed, Shleifer and Vishny's (1997) classic treatment of fire sales is based not on a leverage mechanism, but on rapid performance-based flows out of open-end funds. Return to text\n\n19. Some observers point to the significant increase in collateralized loan obligation (CLO) issuance in 2012 as a further symptom of \"leverage\" in the market. While demand for leveraged loans from CLOs may play a role in driving loan issuance, pricing and loan structure, it should be noted that CLO equity does not represent a form of demandable short-term financing and hence does not have the potential to contribute to fire-sale dynamics in the same way as, say, repo financing. Return to text\n\n20. See Hanson and Stein (2012). Return to text\n\n21. The Senior Credit Officer Opinion Survey on Dealer Financing Terms is available on the Federal Reserve's website. Return to text\n\n22. This concern is sometimes related to the \"Tinbergen principle\" (Tinbergen (1952)), which states that if the number of policy targets exceeds the number of instruments, then some targets may not be hit. However in a world with multiple instruments, the Tinbergen principle does not imply anything about decoupling. That is, it does not imply that each instrument must be dedicated to a single target. Return to text\n\n23. A similar argument is made by Borio and Drehmann (2009), who write: \"But in sophisticated and open financial systems, in which the scope for regulatory arbitrage is high, the interest rate has the merit of setting the universal price of leverage. It reaches parts that other instruments cannot reach.\" Return to text"
    },
    {
        "title": "A Painfully Slow Recovery for America's Workers: Causes, Implications, and the Federal Reserve's Response",
        "date": "February 11, 2013",
        "speaker": "Vice Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20130211a.htm",
        "content": "February 11, 2013\n\nVice Chair Janet L. Yellen\n\nAt the \"A Trans-Atlantic Agenda for Shared Prosperity\" conference sponsored by the AFL-CIO, Friedrich Ebert Stiftung, and the IMK Macroeconomic Policy Institute, Washington, D.C.\n\nThank you for the opportunity to speak to you today about the Federal Reserve's efforts to strengthen the recovery and pursue a goal that it shares with the labor movement: maximum employment.1 \n\nAs an objective of public policy, maximum employment doesn't appear in the U.S. Constitution, in any presidential decree, or even in the mission statement of the Labor Department. A law passed in 1946 made it a general goal for the U.S. government, but so far the Federal Reserve is the only agency assigned the job of pursuing maximum employment. The 1977 law spelling out that responsibility also assigned the goal of stable prices, and we call this combination of objectives the Federal Reserve's dual mandate.2 \n\nWith so many people today unable to find work, it might seem odd to highlight such an ambitious and distant goal for employment. I do so because the gulf between maximum employment and the very difficult conditions workers face today helps explain the urgency behind the Federal Reserve's ongoing efforts to strengthen the recovery. My colleagues and I are acutely aware of how much workers have lost in the past five years. In response, we have taken, and are continuing to take, forceful action to increase the pace of economic growth and job creation.\n\nIn the three years after the Great Recession ended, growth in real gross domestic product (GDP) averaged only 2.2 percent per year. In the same span of time following the previous 10 U.S. recessions, real GDP grew, on average, more than twice as fast--at a 4.6 percent annual rate.3 So, why has the economy's recovery from the Great Recession been so weak?\n\nThe slow recovery was preceded, of course, by the deepest recession since the end of the Second World War. The bursting of an unprecedented housing bubble, together with the financial crisis that followed, dealt a huge blow to demand. These developments robbed homeowners of wealth built over a generation, impaired their access to credit, decimated retirement savings, and shattered the confidence of consumers. Businesses slashed capital spending and payrolls, and real GDP contracted by 4.7 percent, more than twice the average for the 10 other recessions since World War II. The Great Recession was also the longest postwar recession--it lasted 18 months, compared with an average of 10 months for the others.\n\nThe experience of the United States and other advanced economies suggests that deeper recessions are usually followed by stronger-than-average recoveries. While it's also true that longer recessions tend to result in weaker recoveries, even after accounting for this factor, this recovery has been significantly weaker than past experience would have predicted.\n\nThe dashed line in exhibit 1 shows how real GDP would have been expected to increase in this recovery, based on the experience of the United States and other advanced economies and given the depth and duration of the Great Recession.4 The gap between the actual and the predicted path of real output gives a sense of how much economic performance has lagged in this recovery. But the implications of this result may seem a little abstract, so let me illustrate the same idea in a way that tries to show the burden that workers continue to bear in this slow recovery.\n\nExhibit 2 shows how employment has declined and recovered following several previous recessions. The employment measure attempts to control for the fact that demographic changes and other factors have altered the trend, or potential, workforce over the years. For example, in the 1970s, the pool of potential workers was expanding as baby boomers and an increasing share of women moved into the labor force, such that employment needed to rise relatively quickly just to absorb these additional workers. More recently, the aging of the population has put downward pressure on labor force participation, so employment hasn't had to grow as quickly to keep pace with the potential workforce.\n\nEven after making this adjustment, however, the Great Recession stands out both for the magnitude of the job losses that attended the downturn and for the weak recovery in employment that occurred after the recession ended.\n\nIn trying to account for why this recovery has been so weak, it is helpful to first consider several important factors that have in the past supported most economic recoveries. By this I don't mean everything that contributes to economic growth, but rather those things that typically play a key role when the U.S. economy is recovering from recession. Think of these as the tailwinds that usually promote a recovery.\n\nThe first tailwind I'll mention is fiscal policy. History shows that fiscal policy often helps to support an economic recovery. Some of this fiscal stimulus is automatic, and intended to be. The income loss that individuals and businesses suffer in a recession is partly offset when their tax bills fall as well. Government spending on unemployment benefits and other safety-net programs rises in recessions, helping individuals hurt by the downturn and also supporting consumer spending and the broader economy by replacing lost income. These automatic declines in tax collections and increases in government spending are often supplemented with discretionary fiscal action--tax rate cuts, spending on infrastructure and other goods and services, and extended unemployment benefits. These discretionary fiscal policy actions are typically a plus for growth in the years just after a recession. For example, following the severe 1981-82 recession, discretionary fiscal policy contributed an average of about 1 percentage point per year to real GDP growth over the subsequent three years.5 \n\nHowever, discretionary fiscal policy hasn't been much of a tailwind during this recovery. In the year following the end of the recession, discretionary fiscal policy at the federal, state, and local levels boosted growth at roughly the same pace as in past recoveries, as exhibit 3 indicates. But instead of contributing to growth thereafter, discretionary fiscal policy this time has actually acted to restrain the recovery. State and local governments were cutting spending and, in some cases, raising taxes for much of this period to deal with revenue shortfalls. At the federal level, policymakers have reduced purchases of goods and services, allowed stimulus-related spending to decline, and have put in place further policy actions to reduce deficits. I was relieved that the Congress and the Administration were able to reach agreement on avoiding the full force of the \"fiscal cliff\" that was due to take effect on January 1. While a long-term plan is needed to reduce deficits and slow the growth of federal debt, the tax increases and spending cuts that would have occurred last month, absent action by the Congress and the President, likely would have been a headwind strong enough to blow the United States back into recession. Negotiations continue over the extent of spending cuts now due to take effect beginning in March, and I expect that discretionary fiscal policy will continue to be a headwind for the recovery for some time, instead of the tailwind it has been in the past.\n\nA second tailwind in most recoveries is housing. Residential investment creates jobs in construction and related industries. Before the Great Recession, housing investment added an average of 1/2 percentage point to real GDP growth in the two years after each of the previous four recessions, considerably more than its contribution to growth at other times.6 \n\nDuring this recovery, in contrast, residential investment, on net, has contributed very little to growth since the recession ended. The reasons are easy to understand, given the central role that housing played in the Great Recession. Following an extended boom in construction driven in large part by overly loose mortgage lending standards and unrealistic expectations for future home price increases, the housing market collapsed--sales and prices plunged and mortgage credit was sharply curtailed. Tight mortgage credit conditions are continuing to make it difficult for many families to buy homes, despite record-low mortgage interest rates that have helped make housing very affordable. I'm encouraged by recent improvement in the residential sector, but the contribution of housing investment to overall economic activity remains considerably below the average seen in past recoveries, as exhibit 4 shows.\n\nBeyond the direct effects on residential investment, the extraordinary collapse in house prices resulted in a huge loss of household wealth--at last count, net home equity is still down 40 percent, or about $5 trillion, from 2005.7 This loss of wealth has weighed on the finances and spending of many homeowners. Households are less able to tap their home equity to deal with economic shocks, fund their children's education, or start new businesses. For some households, the collapse in house prices has left them underwater on their mortgages, and thus less able to refinance or sell their homes.\n\nAnother important tailwind in most economic recoveries is one that tends to be taken for granted--the faith most of us have, based on history and personal experience, that recessions are temporary and that the economy will soon get back to normal. Even during recessions, households' expectations for income growth tend to be reasonably stable, which provides support for overall spending. In the most recent recession, however, surveys suggest that consumers sharply revised down their prospects for future income growth and have only partially adjusted up their expectations since then (exhibit 5).\n\nThe recovery has also encountered some unusual headwinds. The fiscal and financial crisis in Europe has resulted in a euro-area recession and contributed to slower global growth. Europe's difficulties have blunted what had been strong growth in U.S. exports earlier in the recovery by sapping demand worldwide.\n\nLet me say a few words now, and more later, about the role of monetary policy in this recovery. The Federal Reserve typically plays a large role in promoting recoveries by reducing the federal funds rate and keeping it low until the economy is again on a solid footing. Reducing the federal funds rate tends to reduce other interest rates and boost asset prices, thus encouraging spending and investment throughout the economy.\n\nAs it has before, the Federal Open Market Committee (FOMC) in 2007 started reducing the federal funds rate at the first signs of economic weakness and made sharper rate cuts as the recession deepened. As in some past recoveries that were disappointingly slow, the FOMC has kept rates low well after the end of the recession.\n\nBut unlike the past, by December 2008 the Committee had reduced the federal funds rate effectively to zero. Because that rate, for practical purposes, cannot be cut further, this level is referred to as the effective lower bound. Without the option of using its conventional policy tool, and with the recession getting worse, the FOMC decided to employ unconventional tools to further ease monetary policy, even though the efficacy of these tools was uncertain and it was recognized that their use might carry some potential costs. The better known of these tools is the purchase of large amounts of longer-term government securities, which is commonly referred to as quantitative easing. The other unconventional tool is known as forward guidance--providing information about the future path of short-term interest rates anticipated by the Committee. Both of these approaches are intended to address a gap caused by the effective lower bound. This gap is the shortfall between what the FOMC likely would do in current economic circumstances, were it able to reduce the federal funds rate below zero, and the reality that the rate can't be cut further.\n\nI believe that the Federal Reserve's asset purchases and other unconventional policy actions have helped, and are continuing to help, fill this gap and thus shore up aggregate demand. The evidence suggests that the FOMC's actions have lowered short- and longer-term private borrowing rates and boosted asset prices.8 However, while this contribution has been significant, lower interest rates may be doing less to increase spending than in past recoveries because of some unusual features of the Great Recession and the current recovery. For example, as I noted, the housing crisis left many homeowners with high loan-to-value ratios and damaged credit records, creating barriers to their access to credit, while the financial crisis led many banks to lend only to borrowers with higher credit scores. As a consequence, the proportion of households that have been able to take advantage of declining rates to refinance their mortgages or to borrow to purchase new homes has probably been lower than in past recoveries. In addition, pronounced uncertainty about economic conditions has weighed on capital spending decisions and may have blunted the normal effect of lower interest rates on business investment.\n\nThese are the major reasons why I believe this recovery has been so slow. After a lengthy recession that imposed great hardships on American workers, the weak recovery has made the past five years the toughest that many of today's workers have ever experienced.\n\nThe unemployment rate now stands at 7.9 percent. To put this number in perspective, while that's a big improvement from the 10 percent reached in late 2009, it is now higher than unemployment ever got in the 24 years before the Great Recession. Moreover, the government's current estimate of 12 million unemployed doesn't include 800,000 discouraged workers who say they have given up looking for work. And, as exhibit 6 shows, 8 million people, or 5.6 percent of the workforce, say they are working part time even though they would prefer a full-time job. A broader measure of underemployment that includes these and other potential workers stands at 14.4 percent.\n\nThe effects of the recession and the subsequent slow recovery have been harshest on some of the most vulnerable Americans. The poverty rate has risen sharply since the onset of the recession, after a decade in which it had been relatively stable, and stands at 15 percent of the population, significantly above the average of the past three decades.9 Even those today who are fortunate enough to hold jobs have seen their hourly compensation barely keep pace with the cost of living over the past three years, while labor's share of income--as measured by the percent of production by nonfinancial corporations accruing to workers as compensation--remains near the postwar low reached in 2011 (exhibit 7). Compared with the 7.9 percent unemployment rate for all workers, the unemployment rate for African Americans is 13.8 percent. The unemployment rate for those without a high school diploma is 12 percent. For young people--workers 16 to 19 years old--the unemployment rate is 23.4 percent, little changed from the end of the recession. Among African Americans in that age group, 38 percent of those in the labor force can't find a job.\n\nAnother gauge of the effect that this slow recovery has had on workers is how long it is taking to find a job. At its worst point in the 1980s, the median length of unemployment for those looking for a job was 12 weeks, but the median since the Great Recession has averaged 20 weeks and now stands at 16 weeks. Three million Americans have been looking for work for one year or more; that's one-fourth of all unemployed workers, which is down from 2011's peak but far larger than was seen before the Great Recession.\n\nThese are not just statistics to me. We know that long-term unemployment is devastating to workers and their families. Longer spells of unemployment raise the risk of homelessness and have been a factor contributing to the foreclosure crisis. When you're unemployed for six months or a year, it is hard to qualify for a lease, so even the option of relocating to find a job is often off the table. The toll is simply terrible on the mental and physical health of workers, on their marriages, and on their children.10 \n\nLong-term unemployment is also a great concern because it has the potential to itself become a headwind restraining the economy. Individuals out of work for an extended period can become less employable as they lose the specific skills acquired in their previous jobs and also lose the habits needed to hold down any job. Those out of work for a long time also tend to lose touch with former co‑workers in their previous industry or occupation--contacts that can often help an unemployed worker find a job. Long-term unemployment can make any worker progressively less employable, even after the economy strengthens.\n\nA factor contributing to the high level of long-term unemployment in the current recovery is the relatively large proportion of workers who have permanently lost their previous jobs, as opposed to being laid off temporarily. For example, in past recessions, a considerable share of jobs lost in construction has been temporary, but that isn't the case this time. Construction employment fell from its peak of 7.7 million in 2006 to a low of 5.4 million in 2011. Only about 300,000 of those 2.3 million jobs have returned and most won't, at least for many years.\n\nIn general, individuals who permanently lose their previous jobs take longer to become reemployed than do those on temporary layoff, are more likely to have to change industries or occupations to find a new job, and earn significantly less when they become reemployed.11 \n\nThe greater amount of permanent job loss seen in the recent recession also suggests that there might have been an increase in the degree of mismatch between the skills possessed by the unemployed and those demanded by employers. This possibility and the unprecedented level and persistence of long-term unemployment in this recovery have prompted some to ask whether a significant share of unemployment since the recession is due to structural problems in labor markets and not simply a cyclical shortfall in aggregate demand. This question is important for anyone committed to the goal of maximum employment, because it implicitly asks whether the best we can hope for, even in a healthy economy, is an unemployment rate significantly higher than what has been achieved in the past.\n\nFor the Federal Reserve, the answer to this question has important implications for monetary policy. If the current, elevated rate of unemployment is largely cyclical, then the straightforward solution is to take action to raise aggregate demand. If unemployment is instead substantially structural, some worry that attempts to raise aggregate demand will have little effect on unemployment and serve only to stoke inflation.\n\nThis question is frequently discussed by the FOMC.12 I cannot speak for the Committee or my colleagues, some of whom have publicly related their own conclusions on this topic. However, I see the evidence as consistent with the view that the increase in unemployment since the onset of the Great Recession has been largely cyclical and not structural.\n\nFor example, the rise in unemployment during the recession was accompanied by a dramatic decline in job vacancies and was widespread across industry and occupation groups. Job losses in the construction and financial services industries were particularly large--hardly surprising given the collapse in these sectors in 2008 and 2009--but manufacturing and other cyclically sensitive industries were hit hard as well, and employment in these industries has likewise recovered slowly. Moreover, if skills mismatch in the labor market has led to an excess supply of workers in some sectors and a shortage of workers in others, then we would expect to see an atypical amount of variation in the balance between job openings and unemployment across sectors. Based on this insight, researchers Ed Lazear and Jim Spletzer constructed quantitative measures of mismatch across industries and occupations.13 They found that their mismatch indexes were indeed elevated at the end of the Great Recession, as exhibit 8 shows. But these measures have fallen over the course of the recovery to near pre-recession levels. In addition, widespread mismatch between job vacancies and workers across different sectors might be expected to cause wage rates to rise relatively quickly in sectors with many job openings and relatively slowly in sectors with an excess supply of available workers. But work by Jesse Rothstein fails to uncover evidence of such a pattern.14 \n\nThis and related research suggests to me, first, that a broad-based cyclical shortage of demand is the main cause of today's elevated unemployment rate, and, second, that whatever problems there may be today with labor market functioning are likely to be substantially resolved as the broader economy improves and bolsters the demand for labor.\n\nI don't mean to suggest that there aren't some workers who have been stranded by structural changes in the economy. More can and should be done to help dislocated workers acquire new skills to transition from industries and occupations with fewer opportunities. But making this transition will be much easier in a healthy economy, which is one reason why I am encouraged by the evidence that elevated unemployment is indeed largely cyclical. I will now describe what the Federal Reserve is doing to try to raise demand and create jobs.\n\nI have described the two unconventional policy tools that the FOMC has employed since it reduced the target federal funds rate in 2008 to its effective lower bound. The first is large-scale asset purchases, intended to lower long-term interest rates to encourage borrowing for spending and investment. Between 2008 and mid-2011, the FOMC purchased agency-guaranteed mortgage-backed securities (MBS), agency debt, and Treasury securities totaling $2.3 trillion. In 2011, the FOMC began the maturity extension program, under which it reduced its holdings of short-term Treasury securities and used the proceeds to purchase an equivalent amount of longer-term Treasury securities.\n\nHowever, as the scheduled endpoint of that program approached, it became clear that the economy remained weak, and the FOMC took a series of steps to provide further impetus to the recovery. In June 2012, the Committee extended its maturity extension program until the end of the year. Then in September, it made a major new commitment to asset purchases. Unlike its past purchase programs, which were fixed in size, this time the FOMC stated its determination to continue the program, provided that inflation remains well contained, until it judges that there has been a substantial improvement in the outlook for the labor market. The Committee currently intends to purchase MBS and Treasury debt at a pace that will add about $85 billion per month of such securities to the Federal Reserve's balance sheet. In determining the size, pace, and composition of these purchases over time, the Committee will also take into account ongoing assessments of their efficacy and costs.\n\nThe second unconventional policy tool that the FOMC has used is forward guidance, in the form of more-explicit and more-detailed information about the future path of monetary policy. The longer-term interest rates that most profoundly influence housing demand, capital spending, and asset prices depend on current and expected future levels of short-term interest rates, such as the federal funds rate that has been the Fed's conventional monetary policy tool. Signaling the future path of the federal funds rate can therefore directly affect interest rates today on auto loans, home mortgages, and bonds issued by companies and state and local governments, even when the current level of the federal funds rate cannot be lowered.\n\nThe FOMC has substantially expanded its forward guidance in recent years. In 2009, the Committee stated that economic conditions \"are likely to warrant exceptionally low levels of the federal funds rate for an extended period.\"15 In 2011, the FOMC said this period would likely last \"at least through mid-2013,\" and extended this date guidance several times.16 \n\nA disadvantage of this calendar-based approach was that it might not be clear whether changes in the date reflect changes in the FOMC's outlook for growth, for inflation, or a shift in the desired stance of policy. In December 2012, the FOMC therefore replaced the date with greater detail on the economic conditions that would warrant maintaining the federal funds rate at its present, exceptionally low level. Specifically, it stated that near-zero rates would likely remain appropriate for a considerable time after the asset purchase program ends and \"at least as long as the unemployment rate remains above 6-1/2 percent, inflation between one and two years ahead is projected to be no more than a half percentage point above the Committee's 2 percent longer-run goal, and longer-term inflation expectations continue to be well anchored.\"17 \n\nIt deserves emphasis that a 6-1/2 percent unemployment rate and inflation one to two years ahead that is 1/2 percentage point above the Committee's 2 percent objective are thresholds for possible action, not triggers that will necessarily prompt an immediate increase in the FOMC's target rate. In practical terms, it means that the Committee does not expect to raise the federal funds rate as long as unemployment remains above 6‑1/2 percent and inflation one to two years ahead is projected to be less than 1/2 percentage point above its 2 percent objective. When one of these thresholds is crossed, action is possible but not assured.\n\nMoreover, these thresholds for possible action do not reflect any change in the Committee's longer-run goals. With respect to maximum employment, most FOMC participants continue to estimate that the longer-run normal unemployment rate lies in a range of 5.2 to 6 percent, and the Committee continues to believe an inflation rate of 2 percent (as measured by the annual change in the price index for personal consumption expenditures) is most consistent with the Federal Reserve's dual mandate. Indeed, the Committee reaffirmed these longer-run goals, first adopted in January 2012, just last month.18 Of course, our control over the economy is imperfect, and so temporary deviations from the FOMC's specific longer-term goals will sometimes occur. Importantly, these quantitative goals are neither ceilings nor floors for inflation and unemployment, and the Committee will take a balanced approach to returning both measures to their objectives over time.\n\nI believe the policy steps we have taken recently are in accord with this balanced approach. With employment so far from its maximum level and with inflation currently running, and expected to continue to run, at or below the Committee's 2 percent longer-term objective, it is entirely appropriate for progress in attaining maximum employment to take center stage in determining the Committee's policy stance.\n\nWhile the Committee's longer-term goals remain unchanged, what has changed is that the FOMC is now providing more information about how it expects to pursue its inflation and employment goals. In particular, we will employ our policy tools, as appropriate, to raise aggregate demand and employment in the context of continued price stability, consistent with our balanced approach. That's good news for workers, because I believe that these steps will increase demand, and more demand means more jobs.\n\nIt will be a long road back to a healthy job market. It will be years before many workers feel like they have regained the ground lost since 2007. Longer-term trends, such as globalization and technological change, will continue to pose challenges to workers in many industries.\n\nLet me close with some words of encouragement. The job market is improving. The progress has been too slow, but there is progress. My colleagues and I at the Federal Reserve are well aware of the difficulties faced by workers in this slow recovery, and we're actively engaged in continuing efforts to promote a stronger economy, more jobs, and better conditions for all workers.\n\nThank you for the opportunity to speak to you today.\n\n \n\n1. The views expressed here are my own and not necessarily those of my colleagues in the Federal Reserve System. I am indebted to members of the Board staff--John Maggs, Karen Pence, Jeremy Rudd, and William Wascher--who contributed to the preparation of these remarks, and to Board staff members Sejla Karalic and Christopher Nekarda for assistance with the exhibits. Return to text\n\n2. The law calls on the Federal Reserve to \"promote effectively the goals of maximum employment, stable prices, and moderate long-term interest rates.\" See section 2A of the Federal Reserve Act (12 U.S.C. §225a as added by act of Nov. 16, 1977 (91 Stat. 1387) and amended by acts of Oct. 27, 1978 (92 Stat. 1897); Aug. 23, 1988 (102 Stat. 1375); and Dec. 27, 2000 (114 Stat. 3028)). Return to text\n\n3. The average for other postwar recoveries would be even higher if one were to exclude the three-year periods following the 1957-58 and 1980 recessions, which included at least part of subsequent recessions. Return to text\n\n4. The results in the figure are derived from a model that relates GDP growth in recoveries to recession depth and duration. See Greg Howard, Robert Martin, and Beth Anne Wilson (2011), \"Are Recoveries from Banking and Financial Crises Really So Different?\" International Finance Discussion Papers 1037 (Washington: Board of Governors of the Federal Reserve System, November). Return to text\n\n5. These calculations are based on Federal Reserve Board estimates of fiscal impetus, which measures the boost to aggregate demand from increased government purchases as well as the effects of changes in tax and entitlement policies on consumer and business spending. See Glenn Follette and Byron Lutz (2010), \"Fiscal Policy in the United States: Automatic Stabilizers, Discretionary Fiscal Policy Actions, and the Economy,\" Finance and Economics Discussion Series 2010-43 (Washington: Board of Governors of the Federal Reserve System, June). Return to text\n\n6. See Michael W. McCracken (2011), \"Housing's Role in a Recovery (PDF) ,\" Federal Reserve Bank of St. Louis, Economic Synopses, no. 6 (February), pp. 1-2. Return to text\n\n7. See Board of Governors of the Federal Reserve System, Statistical Release Z.1, \"Flow of Funds Accounts of the United States,\" table B.100, line 49 (Owners' Equity in Household Real Estate). Return to text\n\n8. See Ben S. Bernanke (2012), \"Monetary Policy since the Onset of the Crisis,\" speech delivered at \"The Changing Policy Landscape,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 30-September 1. Return to text\n\n9. Mean annual poverty rate for all people, U.S. Bureau of the Census. Return to text\n\n10. See Steven J. Davis and Till Von Wachter (2011), \"Recessions and the Costs of Job Loss,\" Brookings Papers on Economic Activity, Fall, pp.1-72. Return to text\n\n11. See Louis S. Jacobson, Robert J. LaLonde, and Daniel G. Sullivan (1993), \"Earnings Losses of Displaced Workers,\" American Economic Review, vol. 83 (September), pp. 685-709. Return to text\n\n12. See, for example, the minutes of several recent FOMC meetings held on December 11-12, 2012; September 12-13, 2012; and July 31-August 1, 2012: Board of Governors of the Federal Reserve System (2013), \"Minutes of the Federal Open Market Committee, December 11-12, 2012,\" press release, January 3; Board of Governors of the Federal Reserve System (2012), \"Minutes of the Federal Open Market Committee, September 12-13, 2012,\" press release, October 4; and Board of Governors of the Federal Reserve System (2012), \"Minutes of the Federal Open Market Committee, July31-August 1, 2012,\" press release, August 22. Return to text\n\n13. See Edward P. Lazear and James R. Spletzer (2012), \"The United States Labor Market: Status Quo or a New Normal?\" NBER Working Paper Series 18386 (Cambridge, Mass.: National Bureau of Economic Research, September). See also Ayșegül Șahin, Joseph Song, Giorgio Topa, and Giovanni L. Violante (2012), \"Mismatch Unemployment,\" NBER Working Paper Series 18265 (Cambridge, Mass.: National Bureau of Economic Research, August). Return to text\n\n14. See Jesse Rothstein (2012), \"The Labor Market Four Years into the Crisis: Assessing Structural Explanations,\" Industrial and Labor Relations Review, vol. 65 (July), pp. 467-500. Return to text\n\n15. For example, see Board of Governors of the Federal Reserve System (2009), \"FOMC Statement,\" press release, March 18. Return to text\n\n16. For example, see Board of Governors of the Federal Reserve System (2011), \"FOMC Statement,\" press release, August 9. Return to text\n\n17. See Board of Governors of the Federal Reserve System (2012), \"FOMC Statement,\" press release, December 12. Return to text\n\n18. The FOMC's Statement on Longer-Run Goals and Monetary Policy Strategy (PDF), as amended effective on January 29, 2013, is available on the Board's website. Return to text"
    },
    {
        "title": "International Cooperation in Financial Regulation",
        "date": "February 22, 2013",
        "speaker": "Governor Daniel K. Tarullo",
        "url": "https://www.federalreserve.gov/newsevents/speech/tarullo20130222a.htm",
        "content": "February 22, 2013\n\nGovernor Daniel K. Tarullo\n\nAt the Cornell International Law Journal Symposium: The Changing Politics of Central Banks, New York, New York\n\nNext month marks the fifth anniversary of the failure of Bear Stearns--in retrospect, the beginning of the most acute phase of the financial crisis. The cross-border dimensions of the crisis itself and the global effects of the Great Recession that followed provoked a major effort to strengthen international cooperation in financial regulation. While a good deal has already been accomplished, this evening I will suggest the next steps that would be most useful in advancing global financial stability.\n\nOf course, the fashioning of an international agenda requires a clear understanding of the overall regulatory aims of participating national authorities. Here is where international regulatory cooperation links to the subject of this conference--if not quite the changing politics of central banks, then at least their changing policy goals in the wake of the financial crisis. Almost by definition, systemic crises reveal failures across the financial system, from breakdowns in risk management at many financial firms to serious deficiencies in government regulation of financial institutions and markets. While the recent crisis was no exception, it has presented particular challenges to the policy foundations of central banks, especially those like the Federal Reserve that carry out regulatory mandates alongside their monetary policy missions. So I begin with some remarks on the nature of those challenges, before turning to a discussion of how changes in approach should inform international cooperation in financial regulation.\n\nCentral Banks and the Financial Crisis\nIn surveying the failings of financial authorities, both here and abroad, one can certainly identify some specific characteristics of pre-crisis regulation that look today to have been significantly misguided, rather than the advances they were formerly thought to be. So, for example, regulators became prone to place too much confidence in the capacity of firms to measure and manage their risks. Indeed, the decade or so prior to the crisis had seen an acceleration of the shift from a dominantly regulatory approach to achieving prudential aims--one that rests on activities and affiliation restrictions, and other reasonably transparent rules‑‑toward greater emphasis on a supervisory approach, which relies on a more opaque, firm-specific process of watching over banks' own risk-management and compliance systems.\n\nYet the breadth and depth of the financial breakdown suggest that it has much deeper roots. In many respects, this crisis was the culmination of fundamental shifts in both the organization and regulation of financial markets that began in the 1970s. The New Deal reforms of financial regulation, themselves spawned by a systemic crisis, had separated commercial banking from investment banking, cured the problem of commercial bank runs by providing federal deposit insurance, and brought transparency and investor protections to trading and other capital markets activities. This regulatory approach fostered a commercial banking system that was, for the better part of 40 years, quite stable and reasonably profitable, though not particularly innovative in meeting the needs of depositors and borrowers.\n\nIn the 1970s, however, turbulent macroeconomic developments combined with technological and business innovations to produce an increasingly tight squeeze on the traditional commercial banking business model. The squeeze came from both the liability side of banks' balance sheets, in the form of more attractive savings vehicles such as money market funds, and from the asset side, with the growth of public capital markets and international competition. The large commercial banking industry that saw both its funding and its customer bases under attack sought removal or relaxation of the regulations that confined bank activities, affiliations, and geographic reach. While supervisors differed with banks on some important particulars, they were sympathetic to this industry request, in part because of the potential threat to the viability of the traditional commercial banking system.\n\nThe period of relative legal and industry stability that had followed the New Deal thus gave way in the 1970s to a nearly 30-year period during which many prevailing restrictions on banks were relaxed. A good number were loosened through administrative action by the banking agencies, but important statutory measures headed in the same direction. This legislative trend culminated in the Gramm-Leach-Bliley Act of 1999, which consolidated and extended the administrative changes that had allowed more extensive affiliations of commercial banks with investment banks, broker-dealers, private equity firms, and other financial entities. But in sweeping away the remnants of one key element of the New Deal regulatory system, neither Gramm-Leach-Bliley nor financial regulators substituted new regulatory mechanisms to match the wholesale changes in the structure of the financial services industry and the dramatic growth of novel financial instruments.\n\nIn fact, I would generalize this last observation to say that the need to address the consequences of the progressive integration of traditional lending, trading activities, and capital markets lies at the heart of three post-crisis challenges to the policy foundations of the Federal Reserve and, to a greater or lesser degree, many other central banks.\n\nMicroprudential Regulation. The first challenge posed by the crisis was to traditional, microprudential regulation, which focuses on the safety and soundness of each prudentially regulated firm. Not all central banks have microprudential regulatory authority, of course, and‑‑as in the United States--those that do sometimes share it with other agencies. But the shortcomings of pre-crisis regulatory regimes have been of concern to all central banks. Most notably, capital requirements for banking organizations, particularly the large ones that might be regarded as too-big-to-fail, simply were not strong enough. Risk-weights were too low for certain traded assets that had proliferated as credit and capital markets integrated more thoroughly. In some cases, the arbitrage opportunities presented by existing capital requirements were an incentive for securitization and other capital markets activities. The exposures created by off-balance-sheet activities such as structured investment vehicles (SIVs) were badly underweighted. Minimum capital ratios were not high enough and, in meeting even those inadequate requirements, firms were allowed to count liabilities that did not really provide the ability to absorb losses and still maintain the firms as viable, functioning intermediaries.\n\nThere has already been a substantial response to this challenge. With the support of the Federal Reserve and other U.S. bank regulators, the Basel Committee on Banking Supervision has strengthened capital requirements by raising risk-weightings for traded assets and improved the quality of loss-absorbing capital through a new minimum common equity ratio. The committee also has created a capital conservation buffer and introduced an international leverage ratio. These Basel 2.5 and Basel III reforms either have been, or soon will be, implemented in the United States and most other countries that are home to internationally active banking firms. Also, the Basel Committee has just recently adopted the Liquidity Coverage Ratio (LCR), a first step in addressing liquidity problems.\n\nIn the United States, some important additional steps have been taken. Beginning at the peak of the crisis, the Federal Reserve has conducted stress tests of large banking organizations, making capital requirements more forward-looking by estimating the effect of an adverse economic scenario on firm capital levels in a manner less dependent on firms' internal risk-measurement infrastructure. And the provision of the Dodd-Frank Act popularly known as the Collins Amendment ensures that banking organizations cannot use models-based approaches to reduce their minimum capital below generally applicable, more standardized risk-based ratios.\n\nMacroprudential Regulation. A second challenge for central banks is that the crisis revealed the need for a much more active set of macroprudential monitoring and regulatory policies--that is, a reorientation toward safeguarding financial stability through the containment of systemic risk. The failure to attend to, or even recognize, financial stability risks was perhaps the most glaring public sector deficiency in the pre-crisis period. This was a fault by no means limited to central banks. On the contrary, systemic risk had also come to seem more theoretical than real to many academics and financial market participants. Even most of those inside and outside the official sector who argued for stronger capital or other prudential standards did not appreciate the degree to which the secondary mortgage market had turned into a house of cards. Still, regardless of formal mandates, central banks are better positioned than most other government agencies to see and evaluate the emergence of asset bubbles, excessive leverage, and other signs of potential systemic vulnerability.\n\nIn some respects this second challenge is an extension of the first, since the safety and soundness of large institutions must take account of the relative correlation of their asset holdings, interconnectedness, common liquidity constraints, and other characteristics of large banking organizations as a group. Similarly, systemic risks and too-big-to-fail problems can increase if large, highly leveraged firms may operate outside the perimeter of statutory microprudential oversight, as was the case prior to 2008 with the large, free-standing investment banks in the United States. And market discipline will be badly compromised if financial market participants believe that an insolvent counterparty cannot be resolved in an orderly fashion and thus is likely to receive government assistance under stress.\n\nHere again, domestic and international efforts have already produced significant reform programs, though implementation of some of these programs is less advanced than Basel 2.5 and Basel III. Domestically, the Federal Reserve's annual stress tests examine the effects of unexpected macroeconomic shocks on asset classes held within all major regulated firms. The Dodd-Frank Act gave the Financial Stability Oversight Council (FSOC) authority to bring systemically important firms that are not already bank holding companies within the perimeter of Federal Reserve regulation and supervision. The FSOC is actively considering several firms for possible designation. Finally, the Dodd-Frank Act gave the Federal Deposit Insurance Corporation orderly liquidation authority for systemically important financial firms, thereby creating an alternative to the Hobson's choice of bailout or bankruptcy that authorities faced in 2008.\n\nInternationally, the Basel Committee has agreed to a regime of capital surcharges for large banks based on their systemic importance. There is also an initiative to parallel U.S. efforts to identify non-bank systemically important firms. The Basel Committee and the Financial Stability Board have developed international principles for resolution authority, though most of the rest of the world is behind the United States in actually implementing those principles.\n\nBut meeting the macroprudential challenge will require measures beyond a more comprehensive, cross-firm approach to microprudential regulation. Much academic and policy work of the past several years has revived and elaborated the previously somewhat heterodox view that financial instability is endogenous to the financial system, or at least the kind of financial system we now have. Consider, for example, how the intertwining of traditional lending and capital markets gave rise to what has become known as the shadow banking system. Shadow banking, which refers to credit intermediation partly or wholly outside the limits of the traditional banking system, involves not only sizeable commercial and investment banks, but many firms of varying sizes across a range of markets. While some of the more notorious pre-crisis components of the shadow banking system are probably gone forever, current examples include money market funds, the triparty repo market, and securities lending.\n\nFrom the perspective of financial stability, the parts of the shadow banking system of most concern are those that create assets thought to be safe, short-term, and liquid--in effect, cash equivalents. For a variety of reasons, demand for such assets has grown steadily in recent years, and is not likely to reverse direction in the foreseeable future. Yet these are the assets whose funding is most likely to run in periods of stress, as investors realize that their resemblance to cash or insured deposits in normal times has disappeared in the face of uncertainty about their underlying value. And, as was graphically illustrated during the crisis, the resulting forced sales of assets whose values are already under pressure can accelerate an adverse feedback loop, in which all firms with similar assets suffer mark-to-market losses, which, in turn, can lead to more fire sales. This kind of contagion lay at the heart of the financial stresses of 2007 and 2008.\n\nAs already noted, pre-crisis shortcomings at the intersection of microprudential and macroprudential regulation have motivated a variety of reforms, many explicitly directed at the problem of too-big-to-fail institutions. While some of these reforms remain unfinished, and some additional measures are needed, there has been considerable progress. Unfortunately, the same cannot be said with respect to shadow banking and, more generally, the vulnerabilities associated with wholesale short-term funding. These vulnerabilities involve both large, prudentially regulated institutions, and thus too-big-to-fail concerns, and the broader financial system. Except for the liquidity requirements agreed to in the Basel Committee, however, the liability side of the balance sheets of financial firms has barely been addressed in the reform agenda. Yet here is where the systemic problems of interconnectedness and contagion are most apparent. And, as evidenced by the funding stresses experienced by a number of European banks prior to the stabilizing measures taken by the European Central Bank, these problems are still very much with us.\n\nWithin the United States, reform efforts are underway in some discrete, but important, areas. The provisions of Dodd-Frank requiring more central clearing of derivatives and minimum margins for those that remain uncleared are designed to provide more systemic stability. As to shadow banking itself, the FSOC recently proposed options to address the structural vulnerabilities in money market mutual funds, with an eye toward recommending action by the Securities and Exchange Commission. And the Federal Reserve has begun using its supervisory authority to press for a reduction in intraday credit risk in the triparty repo market. But these measures are incomplete, and do not extend to all forms of short-term funding that can pose run risks, a universe that is likely to expand as prudential constraints begin to apply to large existing shadow banking channels.\n\nMonetary Policy. While the first two policy challenges are shared among regulatory and financial agencies, the third lies solely with central banks. In the wake of the crisis, we need to consider carefully the view that central banks should assess the effect of monetary policy on financial stability and, in some instances, adjust their policy decisions to take account of these effects. The dramatic rise in housing prices, and the associated high amounts of leverage taken on by both households and investors, occurred during an extended period of low inflation. Some have suggested that, by not raising rates because inflation remained subdued, monetary policy in the United States and elsewhere may have contributed to the magnitude of the housing bubble. Whatever the merits of that much-contested point, it seems wise to address this issue as we face what could well be another extended period of low inflation and low interest rates.\n\nIt is important to note that incorporating financial stability considerations into monetary policy decisions need not imply the creation of an additional mandate for monetary policy. The potentially huge effect on price stability and employment associated with bouts of serious financial instability gives ample justification.\n\nHere I want to mention some comments by my colleague Jeremy Stein a couple of weeks ago.1 After reviewing the traditional arguments against using monetary policy in response to financial stability concerns and relying instead on supervisory policies, Governor Stein offered several reasons for keeping a more open mind on the subject. First, regulation has its own limits, not the least of which is the opportunity for arbitrage outside the regulated sector. Second, whatever its bluntness, monetary policy has the advantage of being able to \"get in all the cracks\" of the financial system, an attribute that is especially useful if imbalances are building across the financial sector and not just in a particular area. Finally, by altering the composition of its balance sheet, central banks may have a second policy instrument in addition to changing the targeted interest rate. So, for example, it is possible that a central bank might under some conditions want to use a combination of the two instruments to respond to concurrent concerns about macroeconomic sluggishness and excessive maturity transformation by lowering the target (short-term) interest rate and simultaneously flattening the yield curve through swapping shorter duration assets for longer-term ones.\n\nTo be clear, I do not think that we are at present confronted with a situation that would warrant these kinds of monetary policy action. But for that very reason, it seems that now is a good time to discuss these issues more actively, so that if and when we do face financial stability concerns associated with asset bubbles backed by excessive leverage, we will have a well-considered view of the role monetary policy might play in mitigating those concerns.\n\nAdvancing the International Reform Agenda\nLet me turn now to the way in which our shifts in policy approach should inform the agenda for international cooperation in financial regulation. For obvious reasons, the monetary policy issues are not directly related to this agenda, though our understanding of these issues may profit from discussions with our central bank colleagues from around the world. It is equally obvious that the other two sets of policy changes are quite closely related to the international agenda.\n\nMore than in most other areas, the financial sphere suffers from a basic lack of congruence between the authority to regulate and the object of regulation. Thus we have a significantly internationalized financial system, in which shocks are quickly transmitted across borders, but a nationally-based structure of regulation. Within countries, responsibilities may be divided between prudential regulators and market regulators, among regulators with similar mandates, or both. Central banks may have exclusive prudential authority, share it with other agencies, or have none at all.\n\nInternational arrangements both reflect, and try to compensate for, this web of divided and overlapping domestic authority. Thus there are sectoral standards setters like the Basel Committee, the International Organization of Securities Commissions (IOSCO), and the International Association of Insurance Supervisors (IAIS) on the one hand, but also broader groupings such as the Group of Twenty, the Financial Stability Board (FSB), and the International Monetary Fund on the other. In addition, under the umbrella of the international home of central bankers, the Bank for International Settlements, numerous other committees work across fields also covered by one or more of the groups I have just mentioned.\n\nThere are some obvious weaknesses with such an assortment of international arrangements, notably the difficulty of coordinating initiatives where more than one group is working on an issue. This kind of coordination challenge can be further complicated by the participation in international discussions of various national officials without domestic authority in a particular area. The sheer proliferation of international arrangements, each with its own staff, has at times also led to a proliferation of studies and initiatives that become burdensome to the national regulators and supervisors who have been overtaxed at home since the onset of the crisis and ensuing domestic reform efforts.\n\nYet there are also some strengths derived from the crowded international field of organizations and committees. One such virtue is that issues not falling squarely within the remit of a particular kind of standards setter can nonetheless be dealt with internationally. This, in fact, has been the experience with the ongoing international effort to agree on minimum margin requirements for derivatives that are not centrally cleared. Another is that different perspectives are frequently brought to bear on a single set of problems.\n\nAt some point, it likely will be beneficial to rationalize somewhat the overlapping, sometimes competing efforts of these various international arrangements. For the near to medium term, though, it is important to have some principles for deciding upon the international agenda that should govern the efforts of these arrangements as a whole.\n\nFirst, initiatives should be prioritized. One point of emphasis should be completing, and ensuring implementation of, the internationally agreed-upon framework for containing the too-big-to-fail risks associated with systemically important firms. Another should be distilling the various ideas relating to short-term funding vulnerabilities into a few that have promise as discrete, relatively near-term initiatives, while continuing study of other, more comprehensive measures.\n\nA second, related principle is that initiatives should be focused and manageable, reflecting not only the limited capacity of participating national authorities, but also the desirability of reaching at least a temporary equilibrium at which firms can get on with the business of planning their strategies in a clearer regulatory environment, and regulators can begin to take stock of the cumulative effects and effectiveness of the changes that have taken place in that environment.\n\nA third principle is that, in most instances at least, international efforts to develop new regulatory mechanisms or approaches should build on experience derived from national practice in one or more jurisdictions. The challenges encountered during the initial effort to devise an LCR in the Basel Committee, with little or no precedent of national quantitative liquidity requirements from which to learn, should counsel caution in trying to construct new regulatory mechanisms from scratch at the international level. There will doubtless be exceptions to this general principle, such as where the transnational arbitrage incentives of a regulatory measure are so strong as to make national efforts difficult to initiate and sustain without substantial loss of financial activity to other countries. And, in the immediate aftermath of the crisis, there was a need to harness the broad-based demands for reform and move forward on some priority reforms without benefit of learning from national initiatives. On the other hand, there may also be areas where, notwithstanding the importance of a particular regulatory objective for international financial stability, it may be preferable to maintain a variety of approaches to achieving that objective.\n\nBearing in mind both these principles and the key areas for policy change at central banks and other financial regulators, let me now suggest some specific subjects for near-term emphasis. As to the framework for systemically important financial institutions (SIFIs), I would urge that two ongoing initiatives be completed over the next year and two ideas that have been in the discussion stage be developed into concrete proposals.\n\nFirst, the proposal for a capital surcharge for systemically important banking organizations is nearing completion. The Basel Committee continues to refine the methodology to be used in identifying the firms and calibrating the surcharge amount--perhaps a byproduct of the fact that this methodology had to be developed in the Basel Committee without benefit of prior precedent. But I have confidence that this work will be successfully completed.\n\nThe second ongoing initiative--work on designating non-bank SIFIs--has to date been pursued mostly in the IAIS and thus has concentrated on insurance companies. It is important to take the time to evaluate carefully the actual systemic risk associated with these companies, and to understand the amount of such risk relative to other financial firms, before fixing on a list of firms and surcharges. But this seems to me a realistic goal over the next six months.\n\nThird, we should build on the very good analytic work in the Basel Committee, both on simplifying capital requirements for credit risk and on fashioning standardized capital requirements for market risk, to apply standardized credit and market risk capital measures to all internationally active banking firms. As I mentioned earlier, the United States has already adopted such a requirement for capital requirements on credit risk. These standardized measures serve as a floor to guard against the potential for models-based capital measures to understate capital needs under some circumstances. They are also substantially less opaque than, for example, the advanced internal ratings-based approach of Basel II, and thus would provide more comparable measures that are also more amenable to international monitoring.\n\nFourth, I would hope to see a requirement proposed for large internationally active financial institutions to have minimum amounts of long-term unsecured debt, which would be available to absorb losses in the event of insolvency. As I mentioned earlier, work on resolution continues, albeit at different paces in different jurisdictions. Given the complexities arising from the independent, often differing national bankruptcy and insolvency laws, the goal of achieving a fully integrated resolution regime for internationally active financial firms may take a good deal of time. But a minimum long-term debt requirement would at least provide national authorities with sufficient equity and long-term debt in these firms to bear all losses in the event of insolvency, and thereby counteract the moral hazard associated with taxpayer bailouts without risking disorderly failure. This requirement would not break brand new regulatory ground, since it would really be a modification of existing Tier 2 gone-concern capital concepts, and would complement the requirement for minimum equity levels included in Basel III.\n\nAs implied in my identification of short-term funding vulnerabilities as a priority area, the best way forward here is considerably less easy to specify. Short-term initiatives on money market funds and triparty repo are both possible and desirable. In truth, though, because money market funds are largely American and, to a somewhat lesser extent, European, the United States and the European Union together have the ability to address the global run risks associated with these products. I think we also have the responsibility to do so, but not necessarily in identical ways. Accordingly, I would hope that both the United States and the European Union would each take effective action to counter the run risk, tailored as appropriate to their regulatory environments, and then explain those actions at IOSCO and the FSB, where their efficacy can be reviewed. Similarly, since the settlement process for triparty repo that remains of concern is centered at two institutions, both of which are regulated American banks, the United States can take effective action without need of an international agreement\n\nAs to broader initiatives, proposals to require minimum haircuts for all securities financing transactions have been tentatively discussed in the FSB. This is certainly a ripe subject for discussion, insofar as securities financing transactions facilitate leverage, enable maturity transformation, and produce the kind of interconnectedness that can spawn runs and contagion. At present, no set of generally applicable prudential standards governs these activities. Even within regulated firms, microprudential risk-weighted capital standards have little effect, since they are calibrated against credit risk and most such transactions are short-term and fully (or over) collateralized. Thus requirements that would attach to instruments and transactions, as opposed to firms that happen to be prudentially regulated for other reasons, have considerable attraction.\n\nOn the other hand, universal haircut requirements are the type of regulatory innovation that I suggested earlier was best developed internationally following some experience within financially significant countries. One may, for example, have significant concern about some of the unintended consequences that would ensue. My instinct, then, is that the analysis of this idea should continue within the FSB and, one hopes, in other venues both in and out of the official sector. There should also be concerted efforts internationally to gather relevant data, some of which is at present uncollected. But we are not going to be in a position to establish an international securities transaction financing regime in the near term.\n\nHowever, one proposal already on the international agenda might be reconsidered, so as to address more directly the short-term funding problem. Following completion of the LCR earlier this year, the Basel Committee is turning its attention back to the Net Stable Funding Ratio (NSFR), a proposal that was intended to complement the LCR by regulating liquidity levels beyond the 30-day LCR horizon. Like the LCR, the NSFR proposal raised many questions even among those favoring robust measures to deal with the liability side of firm balance sheets. There is some appeal to moving forward with this complementary measure fairly quickly by simply making some incremental changes to the NSFR while keeping its current structure. But I think we may be better advised to take the opportunity of this review to examine whether there are approaches that might address more directly the vulnerabilities for the financial system created by large non-deposit, short-term funding dependence at major financial institutions. I do not mean to prejudge the outcome of such an examination, or the degree to which we might build on measures being considered in various jurisdictions to address these vulnerabilities. But I do think it worth the effort.\n\nConclusion\nResponses to what I have described as the three challenges to pre-crisis central bank policies will continue to evolve. So will the reenergized international agenda for cooperation in international financial regulation. My aim tonight has not been to lay out a comprehensive program for either, but to suggest that these changing agendas are neither completely correlated nor completely independent. In suggesting some concrete next steps, I have tried to define some useful and important points of intersection between the two.\n\n1. See Jeremy C. Stein (2013), \"Overheating in Credit Markets: Origins, Measurement, and Policy Responses,\" speech delivered at the \"Restoring Household Financial Stability after the Great Recession: Why Household Balance Sheets Matter,\" a research symposium sponsored by the Federal Reserve Bank of St. Louis, held in St. Louis, Mo., February 7. Return to text"
    },
    {
        "title": "Discussion of \"Crunch Time: Fiscal Crises and the Role of Monetary Policy\"",
        "date": "February 22, 2013",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20130221a.htm",
        "content": "February 22, 2013\n\nGovernor Jerome H. Powell\n\nAt the \"U.S. Monetary Policy Forum\" conference sponsored by the University of Chicago Booth School of Business, New York, New York\n\nThe issue of fiscal sustainability and its interaction with monetary policy is certainly timely.1 Many advanced economies are in an extended period of slow growth and high deficits, and face long-term fiscal pressures from aging populations.\n\nI agree with much in this broad-ranging paper.2 In particular, the authors join others in finding that accommodative monetary policy is often associated with successful fiscal consolidations. They conclude that a \"tough love\" alternative, which would call for the Federal Reserve to withhold monetary accommodation until fiscal policymakers enact legislation to reduce budget imbalances, is likely to be counterproductive. Indeed, I would argue that the tough love approach also would require the Fed to deviate from the dual mandate that the Congress has assigned it, while assuming a role in influencing fiscal policy that the Congress has not assigned it.\n\nI find myself in disagreement, however, with the paper's assessment that the current fiscal policy challenges might interfere in the near-term with the conduct of monetary policy in the United States.\n\nThree important propositions underlie the authors' argument on this issue:\n\nI believe all of these statements to be true. They are also widely, if not universally, accepted. However, based on these points and, importantly, on their empirical findings, the authors set out to show that fiscal difficulties present a near-term threat to the conduct of monetary policy. The paper argues that rising fiscal pressures, exacerbated by Federal Reserve losses on asset sales and low remittances to the Treasury, could lead the Federal Reserve to delay balance sheet normalization and to fail to remove monetary accommodation as needed to keep inflation expectations stable and inflation in check. In that case, the market could perceive the onset of fiscal dominance, thus setting off a vicious cycle of rising inflation expectations, increasing interest rates, and ever greater fiscal unsustainability.\n\nIn my view, this proposition seems highly unlikely. At a minimum, it is premature.\n\nU.S. Fiscal Position\nThe paper led me to look back over the past century of U.S. sovereign debt history. On two prior occasions, federal debt as a percentage of gross domestic product (GDP) increased significantly--during the Great Depression-World War II era and, to a smaller extent, the two decades ending in the mid-1990s.3 \n\nAfter each of these high-debt periods, fiscal policy responded by running sustained primary surpluses and reducing debt to levels below 40 percent of GDP. In a recent paper, Henning Bohn observed that \"the foundation of U.S. debt policy is the promise of safety for bondholders backed by primary surpluses only in response to a high debt-GDP ratio.\"4 That nicely captures our recent history and suggests a principal reason why the federal debt of the United States still has the market's trust.\n\nThe Great Recession has generated a third substantial increase in federal debt, from about 35 percent of GDP in 2007 to around 75 percent at the end of this fiscal year, an increase that is consistent with other increases in sovereign debt for advanced economies after severe financial crises during the post-World War II period.5 History and common sense suggest that the federal government should again run primary surpluses sufficient over time to reduce debt to pre-crisis levels of perhaps 35 to 40 percent of GDP. That would leave fiscal space to address the coming wave of health and pension costs, as well as unexpected new shocks.\n\nIn the past two years, spending cuts and tax increases totaling about $3.5 trillion over the next 10 years have been enacted. Assuming these measures are not rolled back--in particular, that the spending sequestration either takes effect or is replaced by equivalent deficit-reducing measures--a reasonable \"current policy\" projection is that the ratio of debt to GDP will be roughly stable at around 75 percent through about 2020.6 After that, under current policy, health-care costs and, to a much lesser extent, pension costs will produce a sharp, sustained increase in the ratio of debt to GDP.\n\nFiscal Sustainability and Monetary Policy\nThe authors review empirical evidence of sovereign borrowing costs for 20 advanced economies. They join others in finding a statistically significant relationship between sovereign debt levels and borrowing costs.7 They also find nonlinear increases in borrowing costs beginning at debt-to-GDP ratios of around 80 percent. But the nonlinearities they find are driven to a great extent by the experience of smaller euro-zone nations that, of course, borrow in euros. The United States borrows in its own currency--the world's primary reserve currency. That difference is crucial for investors, along with the fact that the United States economy remains the world's largest and most productive. The United Kingdom and Japan are also high-debt countries that borrow in their own currencies; neither shows any detectable rate increase, let alone a nonlinear one. These countries present a serious problem for the authors' case.\n\nOf course, the United States is not exempt from concerns about the potential long-term effects of an unsustainable fiscal path. There is almost certainly a level of debt at which the United States would be at risk of an interest rate spike. However, we should expect that level to be substantially above one identified based on the experience of smaller euro-zone nations.\n\nThe argument also has a serious timing problem. The Federal Reserve's balance sheet likely will be normalized by late this decade, before the federal debt-to-GDP ratio even increases materially from today's level. Under the reasonable projection mentioned above, the debt-to-GDP ratio will remain roughly stable until 2020 before rising significantly in the next decade.8 That's not a favorable longer-term forecast, all the more so because it is importantly the result of demographic changes that have been expected for decades. But the forecast doesn't support the authors' claim that fears of fiscal dominance could materialize in the United States within the next five to seven years, during the period when the Fed is normalizing its balance sheet.\n\nNo current market signal suggests that the United States is near the point of losing the market's confidence. In my view, nothing in the Congressional Budget Office debt forecasts or the authors' empirical findings provides grounds for such an event during this decade. The market has every reason to believe--and apparently still does believe--that the United States will continue the difficult task of fiscal consolidation until the job is done.\n\nTerribly difficult fiscal adjustments lie ahead. Although there is still time to make them, delay will sharply increase the pain of adjustment. The time to act is now. In my view, the problem is not principally one of economics or fiscal policy; it is one of governance. The real threat to the fiscal standing of the United States is that of inaction caused by a long period of political polarization and dysfunction. That would be a self-inflicted wound. And that is a problem that can't be derived from the traditional fiscal metrics.\n\nWe may have more room than other economies around the globe, but I do not intend to project any sense of complacency around this topic. The authors' basic message seems just right to me: We don't know where the tipping point is; wherever it is, we are clearly getting closer to it, and the costs of misestimating its location are enormous and one-sided. The benefits to long-term fiscal consolidation--conducted at the right pace, and without jeopardizing the near-term economic recovery--would be substantial.\n\nBalance Sheet Losses and Remittances\nThe authors' work on Federal Reserve income and remittances to the Treasury overlaps with a paper published last month by Federal Reserve Board staff members Seth Carpenter, Jane Ihrig, Beth Klee, Daniel Quinn, and Alexander Boote.9 Both papers provide a basis for public discussion of these matters, which is a highly positive development. Some of the assets acquired through the Federal Reserve's large-scale asset purchases (LSAPs) may be sold at a loss, and it is important to be transparent about this possibility.\n\nThus far, the Federal Reserve's asset purchases have greatly increased our income and remittances to the Treasury. Indeed, remittances have run at an annual level of about $80 billion from 2010 to 2012. Both papers show that remittances are likely to decline substantially from these elevated levels as interest rates rise and the Fed balance sheet normalizes, and there may be a period of zero remittances. If so, the balance sheet would show a deferred asset representing a flow of future income to be retained and not remitted to the Treasury. Nonetheless, we expect that the LSAPs, which began in late 2008, will result in a net increase in remittances over the life of these programs. Moreover, any temporary losses should be weighed against the expected social benefits of the increased economic growth generated by the LSAPs, which would include higher tax revenue from increased output.\n\nGreenlaw and his coauthors also note that we have the flexibility to normalize the balance sheet more slowly. For example, a \"no asset sale\" plan--under which assets would simply run off as they mature--would push out the date of normalization by only a year or so. That approach would also address concerns over potential market disruption from the sale of off-the-run agency mortgage-backed securities. And it would also smooth remittances.\n\nRemittances averaged about $25 billion per year, or 0.2 percent of GDP, over the decade before the crisis. After the balance sheet is normalized, these remittances should return to a similar, modest share of GDP. From the standpoint of the sustainability of federal fiscal policy, remittances are not a first-order concern. That said, an extended period of zero remittances could certainly bring the Federal Reserve under criticism from the public and the Congress. The question is whether the Federal Reserve would permit inflation and thereby abandon its post in the face of such criticism. There is no reason to expect that to happen.\n\nThe Federal Reserve was created as an independent agency, and a broad consensus has emerged among policymakers, academics, and other informed observers around the world that better overall economic performance is achieved when the conduct of monetary policy is free from political control.10 Of course, we are accountable to the Congress and the American people. The Congress has given us a job to do, and as long as I am a member of the Federal Reserve Board, I will do my utmost to carry out our mandate.\n\nOther Observations\nThe authors note that Federal Reserve asset purchases shorten the duration of debt held by the public, by the issuance of reserves to fund purchases of long-term securities. And shortening the maturity of the public debt does make any government more susceptible, in theory, to fiscal dominance. There is also a general assumption that under fiscal dominance any government has a strong incentive to allow inflation to reduce the real value of the debt. In the case of the United States, there is less to that than one might expect. By shortening the duration of debt held by the public, asset purchases have also reduced any benefit to the government of an unexpected inflation. More fundamentally, the liabilities that matter in the long term for the federal budget are those associated with health care and pension costs. These liabilities are not nominal but real, and cannot be inflated away.\n\nConclusion\nI am not suggesting, and I do not expect, that the path ahead for monetary policy will be an easy one. There are legitimate concerns associated with the costs and benefits of continuing asset purchases. We may face challenges related to financial stability, as well as market function and inflation expectations. I do not personally see fiscal dominance as high on the list of near term risks.\n\nI thank the authors for their interesting work.\n\n1. The views expressed here are my own and not necessarily those of my colleagues in the Federal Reserve System. I am indebted to members of the Board staff--Eric Engen, Edward Nelson, David Lopez-Salido, and Jon Faust--who contributed to the preparation of these remarks. Return to text\n\n2. See David Greenlaw, James D. Hamilton, Peter Hooper, and Frederic S. Mishkin (2013), \"Crunch Time: Fiscal Crises and the Role of Monetary Policy,\" paper written for \"U.S. Monetary Policy Forum,\" a conference sponsored by the University of Chicago Booth School of Business, held in New York, February 22. Return to text\n\n3. Figure 1 shows federal debt held by the public and primary budget surpluses--that is, the difference between federal revenues and federal noninterest outlays--as a percent of nominal GDP from fiscal year 1912 through fiscal 2012. Return to text\n\n4. See quote on p. 290 in Henning Bohn (2011), \"The Economic Consequences of Rising U.S. Government Debt: Privileges at Risk,\" FinanzArchiv/Public Finance Analysis, vol. 67 (September), pp. 282-302. Return to text\n\n5. See Carmen M. Reinhart and Kenneth S. Rogoff (2009), \"The Aftermath of Financial Crises,\" American Economic Review, vol. 99 (May), pp. 466-72. Return to text\n\n6. See Loren Adler, Shai Akabas, and Brian Collins (2013), \"Key Takeaways from the 2013-2023 CBO Budget and Economic Outlook,\" Bipartisan Beat Blog, Bipartisan Policy Center, February 7. Numbers are modified to assume that the spending sequestration either takes effect or is replaced by equivalent deficit reducing measures. Return to text\n\n7. For example, see Eric Engen and R. Glenn Hubbard (2005), \"Federal Government Debt and Interest Rates,\" in Mark Gertler and Kenneth Rogoff, eds., NBER Macroeconomics Annual 2004, vol. 19 (Cambridge, Mass.: MIT Press), pp. 83-138; Thomas Laubach (2009), \"New Evidence on the Interest Rate Effects of Budget Deficits and Debt,\" Journal of the European Economic Association, vol. 7 (June), pp. 858-85; and Joseph W. Gruber and Steven B. Kamin (2012), \"Fiscal Positions and Government Bond Yields in OECD Countries,\" Journal of Money, Credit and Banking, vol. 44 (December), pp. 1563-87. Return to text\n\n8. This is the alternative baseline scenario presented in Adler, Akabas, and Collins, \"Key Takeaways,\" in note 6. Return to text\n\n9. See Seth B. Carpenter, Jane E. Ihrig, Elizabeth C. Klee, Daniel W. Quinn, and Alexander H. Boote (2013), \"The Federal Reserve's Balance Sheet and Earnings: A Primer and Projections,\" Finance and Economics Discussion Series 2013-01 (Washington: Board of Governors of the Federal Reserve System, January). Return to text\n\n10. Among many studies, see, for example, Alex Cukierman (1992), Central Bank Strategy, Credibility, and Independence: Theory and Evidence (Cambridge, Mass.: MIT Press); Alberto Alesina and Lawrence H. Summers (1993), \"Central Bank Independence and Macroeconomic Performance: Some Comparative Evidence,\" Journal of Money, Credit and Banking, vol. 25 (May), pp. 151-62; and Alex Cukierman, Pantelis Kalaitzidakis, Lawrence H. Summers, and Steven B. Webb (1993), \"Central Bank Independence, Growth, Investment, and Real Rates,\" Carnegie-Rochester Conference Series on Public Policy, vol. 39 (December), pp. 95-140. Return to text\n\n"
    },
    {
        "title": "Reflections on Reputation and its Consequences",
        "date": "February 28, 2013",
        "speaker": "Governor Sarah Bloom Raskin",
        "url": "https://www.federalreserve.gov/newsevents/speech/raskin20130228a.htm",
        "content": "February 28, 2013\n\nGovernor Sarah Bloom Raskin\n\nAt the 2013 Banking Outlook Conference at the Federal Reserve Bank of Atlanta, Atlanta, Georgia\n\nGood afternoon. I want to thank the Federal Reserve Bank of Atlanta for inviting me to join you for today's 2013 banking outlook discussion. There are a number of interesting and very relevant topics on your agenda, most of which are rightly focused on the financial and regulatory environment. I would like to share some thoughts this afternoon on a broader topic, however, that may be due for a refreshed look: the relevance of a bank's reputation.\n\nLet's start in an elementary way in constructing a concept of reputation: We know that reputation is not entirely a moral trait. We understand that there is a distinction between character and reputation. When we say that someone shows good character, we are usually referring to something at the core of their being or personality. On the other hand, when we refer to a person's reputation, we recognize that reputation is our perception of the person, that it is externally derived and not necessarily intrinsic to that individual. In other words, we understand that a person may not have complete control over the perception that has been created. Reputation, through no fault of one's own, can be tarnished. In the same way, one's reputation can be golden, even though nothing was done to earn it. But like the notion of character, reputation can be earned and it can be a type of stored value for when challenges to one's own reputation come later.\n\nNow let's bring this distinction into the context of banks: Many bankers have a sterling character, and they operate financial institutions with sterling reputations that reflect that basic character. At the same time, there are bankers who, regardless of their personal character, manage financial institutions with reputations that have been tarnished. Their banks' reputations could have been tarnished by almost anything, but likely most tarnish is attributable to the subprime mortgage meltdown and the ensuing financial crisis that cost the economy trillions of dollars; left millions of Americans bankrupted, jobless, underemployed, or homeless; triggered massive litigation; and shook the confidence of our nation to the core.\n\nMany of the darkest manifestations of the financial crisis have finally begun to diminish: the boarded-up homes with overgrown lawns, the half-built skyscrapers, the \"We Buy Houses Cheap\" signs planted at exit ramps, the eviction notices nailed to front doors. But even as the economy comes back to life, our memory of these events is still sharp and the reputational damage suffered by U.S. financial institutions during the crisis endures. To be blunt, a lot of people have negative feelings about banks, which they distrust and blame for the huge infusions of taxpayer money into the financial system that were deemed necessary during the crisis. \n\nThese reputational consequences--whether justified or not--are to be expected. Sociologists and economists have long remarked upon the central role that social trust plays in healthy markets. Market transactions depend on a whole series of assumptions that people must be able to rely on, including the soundness of money, the enforceability of contracts, the good will of their partners, the integrity of the legal system, and the common meanings of language. Social trust is the glue that holds markets and societies together. In the context of banking, social trust and reputation are related concepts. \n\nBanks themselves--in crisis or not--are particularly vulnerable to reputational consequences because of their public role. The principal social value of financial institutions is their ability to facilitate the efficient deployment of funds held by investors (and entities that pool these funds) to productive uses.1  This value is maximized when the cost to the entity putting capital to work is close to the price demanded by the entity that seeks a return on its investment. In traditional banking, this means that financial intermediation occurs most effectively when the interest rate charged for use of funds in lending is close to the interest rate paid for deposits. As the difference between the two grows (which would be attributable to amounts extracted by intermediaries as compensation for essential intermediation), the costs of borrowing for the purposes of creating productive projects become higher than they should be, with arguably negative reputational consequences.\n\nGiven these particular reputational dimensions associated with financial institutions, might financial regulators have an interest in considering reputational harms analytically? Could there be benefits to understanding the ways that an individual financial institution's reputation--or that of the financial industry as a whole--might have particular effects on, for example, safety and soundness, financial inclusion, or financial innovation?\n\nIn my remarks today, I want to consider various aspects of how reputational harm manifests itself in banks and begin a dialogue with you about how we might refresh our thinking about this category of risk. I will start with a description of some factors that can affect a bank's reputation, especially in the wake of the financial crisis. Next, I will talk about ways in which reputation matters, including how supervisors can use their unique ability to see inside the institutions that they examine to uncover some early indicators of reputational problems. I will then turn to other reasons why policymakers may want to think about reputation. One reason involves possible consequences regarding financial inclusion; that is, a customer's ability to have a relationship with his or her bank that puts them in the position to save, access credit in a sustainable way, and understand the nature of the financial transactions in which they participate. Reputation also may help or hinder a bank's ability to innovate, so I will introduce this topic next. Finally, I want to frame a discussion around the recent cybersecurity threats that banks are facing and place them in the context of reputational risk so that they too can be discussed constructively.\n\nOf course, I preface these remarks with the admonition that these views are my own and may not be representative of those of the Federal Reserve Board.\n\nThe Financial Crisis and the Reputation of Financial Institutions\nIt has been more than five years since this country began experiencing a financial crisis that reverberated well beyond Wall Street. This crisis was unique, and many of its marks on individuals and communities remain. It was a crisis in which significant numbers of both subprime and prime mortgage defaults quickly spread across whole cities and regions until the impact was felt throughout the country. The devastation was magnified by waves of foreclosures, significant drops in house values, job losses, and, ultimately, significant reductions in household wealth, which have been responsible, in part, for the slow recovery we confront today.\n\nThe causes of the crisis and the subsequent devastation are myriad, but to large swaths of the American public who have experienced the devastation, the causes rest squarely on the shoulders of financial institutions, especially the largest institutions. Further, many Americans direct their anger at not only banks, but policymakers as well. Because the economy pulled back from the brink of depression only through a massive and unprecedented infusion of public dollars, American taxpayers feel that they were forced into a position of accepting that the government had to put a lot on the line to save the financial system from ruin. And many of those taxpayers are still unhappy about such a massive government intervention that seemed to aid banks that were not held to account, while distressed households were left to pay the price.2 \n\nUnfortunately, in the public's view, little has happened to restore their trust and confidence in financial institutions. Since the crisis, the public's views of banks have been informed--for better or worse--by their experiences and those of their families and neighbors, who may have lost their homes, their jobs, or their household wealth. Many attempted unsuccessfully to modify their underwater mortgages, even when they were current on their payments. Against this backdrop, the public's lack of trust and confidence has been magnified by, among other things, the Occupy Wall Street movement, payday loans, overdraft fees, rate-rigging settlements in London Interbank Offered Rate (LIBOR) cases, executive compensation and bonuses that seem to bear no relationship to performance or risk, failures in the foreclosure process, and a drumbeat of civil litigation. \n\nIn the Internet age, the impact of consumer distrust is amplified: anyone can easily, cheaply, and anonymously create, organize, and participate in a protest. Participants do not have to gather physically to make their action felt. A recent survey found that\n\nTake, for example, the impact of the consumer backlash that erupted in late 2011 when one of the nation's largest banks attempted to charge a $5 monthly fee for its debit card. A California woman, frustrated with the bank's decision to impose the fee, created a Facebook event, dubbed \"Bank Transfer Day,\" and invited her friends to join her in transferring their money from large banks to credit unions on that day. In the five weeks leading up to Bank Transfer Day, this Facebook event received extensive press coverage and resulted in billions of dollars in deposits reportedly shifting out of large banks. The bank targeted by the Facebook protest ultimately reversed itself and declined to assess the monthly fee.\n\nHow Reputational Risk May Be Relevant \nFinancial institutions of all sizes have shared in the fall-out--fairly or unfairly--from a general decline in their industry's reputation among the public. Moreover, the steady stream of litigation against financial institutions since the crisis has further harmed the reputations of specific firms among their customers. \n\nConsider that in today's financial institution sector, a substantial portion of a bank's enterprise value comes from intangible assets such as brand recognition and customer loyalty that may not appear on the balance sheet but are nevertheless critical to the bank's success. Also consider that at the end of 2012, deposits at commercial banks reached a record $10 trillion. At the same time, the share of each deposit dollar that banks lent out hit a post-financial crisis low in the third quarter, which means that banks' net interest margins have fallen sharply. Across the industry, loan-to-deposit ratios are going down. In 2007, banks' aggregate loan-to-deposit ratio was 91 percent. This ratio currently stands at 70 percent. In such a context, achieving higher earnings is a challenge.\n\nIf bank profitability is going to improve in a context of low interest rates and higher compliance costs, lending income may remain low. Profits will need to come from elsewhere. One source of profits would be products that are not interest-rate dependent, but fee-dependent. \n\nIn other words, compressed net interest margins mean that many banks may look to new fee-generating products and trading activity to enhance profits. The pressure to generate enhanced profits through high fees is palpable, and banks may choose to move aggressively down these paths. But when a bank already suffers from a poor reputation--either deservedly or as a knock-on effect of broader discontent with the financial industry--it likely will face difficulties in introducing new fee-generating products or activities without inviting further criticism and damage to its reputation. So an evaluation of the effects of the new product or activity on the bank's reputation prior to launch is arguably necessary. \n\nReputational Risk and Supervision\nThe effects of the financial crisis, combined with the power of the Internet to broadly and quickly publicize information--whether factually accurate or not--should alert banks to how they are managing their reputations. And supervisors have a duty to see that all risks are fully understood, even those risks that, like reputational risk, are unquantifiable or have not fully emerged. I believe this is an area where supervision can add value. To the extent possible, supervision can unveil hidden loss exposures that may be building up through the accumulation of reputational risk elements. If we were better able to identify and monitor such free-floating risk, and in so doing, to push bank boards of directors and senior management to pay more attention to reputational risk, we could help reduce the underpricing of these risks.\n\nMany have argued, and I think it's a compelling argument, that ineffective supervision and enforcement of existing laws and regulations contributed to the financial crisis. By tolerating reduced transparency of risk in balance sheets and in complex institutional portfolios, as well as arbitrage around capital requirements and other prudential measures, supervision may have encouraged the underpricing of risk. And the sudden correction of this underpricing of risk,4 in turn, accelerated the crisis. The crisis punished investors who accepted more risk than they thought they had taken on, it punished consumers who overleveraged themselves, it punished Americans who lost their jobs and homes, and it contributed to the decline of once-vibrant neighborhoods and towns.\n\nTo mitigate the chances of such a crisis occurring again, supervisors need to redouble their efforts toward promoting greater transparency of risks and early confrontation of potential loss exposures. We should view these efforts as a set of responsibilities for both banks and regulators that are aligned to assure the public and markets that risks can be fully understood and accurately estimated and priced.\n\nIn some ways, this perspective is not new territory for bank regulators. The Federal Reserve, for example, issued supervisory guidance in 1995 that identified the six primary risks that remain the focus of its supervisory program, and reputational risk is among them.5  Having said that, it is still a risk that both banks and supervisors should learn how to identify ex ante rather than ex post.6 \n\nSo, while reputational risk is not a new concept by any means, it is an area that is ripe for additional work. For example, the enterprise risk management framework of the Committee of Sponsoring Organizations of the Treadway Commission--the so-called \"COSO standard\"--does not address reputational risk. Likewise, the Basel capital frameworks exclude reputational risks from regulatory capital requirements.7 \n\nAccordingly, the current approach to managing reputational risk is largely reactive rather than proactive. Banks and examiners tend to focus their energies on handling the threats to their reputations that have already surfaced. This is not risk management; it is crisis management--a reactive approach aimed at limiting the damage. Instead, we should think about a supervisory approach that incentivizes bank managers to sufficiently contemplate, quantify if necessary, and control the factors that affect the level of such risks before they fully emerge in an unmitigated form.\n\nThe way that the Federal Reserve supervises banking organizations may help identify risks sooner. For all banking organizations, the supervisory program here does not simply rely on an annual onsite examination. The Federal Reserve supplements its regular examination activities with a program of continuous monitoring between examinations. One of the key objectives of this program is to identify emerging risks and communicate with other regulators and the banks an updated risk assessment and supervisory strategy based on these risks. \n\nWhen we contemplate a supervisory approach that illuminates reputational risk, we might be able to more fully uncover the interconnection of risks that certain activities could impose on investors, creditors, counterparties, and taxpayers. In this approach, we would first and foremost need to encourage banks to assess the potential riskiness of particular operations, investments, products, and decisions to their reputations and, ultimately, to their enterprise value. As supervisors, one objective as we work with financial institutions to extract such information would be to try to develop ways of measuring the value of the risks that banks shift onto the financial safety net. \n\nReputation and Financial Inclusion\nThere is also a relationship between reputation and financial inclusion, by which I mean the extent to which consumers can participate in a financial marketplace that consists of competitive providers of credit, savings vehicles, and sources of enabling financial information. As policymakers, we must address the perceived trustworthiness of those financial institutions that interact with the public and move the millions of Americans lingering in the margins of the financial marketplace into relationships that provide them with sustainable access to banking and credit, an understanding of how mortgages and credit work, and an understanding of how to create savings.\n\nData from the Federal Reserve's Survey of Consumer Finances and the Federal Deposit Insurance Corporation's survey of the unbanked and underbanked show that the percentage of families earning $15,000 per year or less who reported that they have no bank account has been increasing steadily for the past five years, resulting in more than 28 percent of these families being unbanked as of 2011.8  Families slightly further up the income distribution scale, earning between $15,000 and $30,000 per year, are also financially marginalized: 12 percent reported being unbanked and almost 26 percent reported being underbanked in 2011.9 \n\nThere are several potential reasons for these impediments to inclusion. When we examine barriers that individual consumers face in becoming financially included, we uncover trustworthiness and reputation. A Federal Reserve analysis of the most recent Survey of Consumer Finances suggests that the primary reason individuals do not have a transaction account is a simple dislike of dealing with financial institutions.10  If that dislike emanates from the reputation of the particular bank, or the reputation of the banking industry as a whole, policymakers and financial institutions will not be able to enhance financial inclusion without addressing the reputational context.\n\nReputation and Innovation\nI'd like to imagine how the public's sense of well-being might be enhanced by their interactions with financial institutions. If we paid attention to the experiences of consumers as they interact with various segments of the financial marketplace, what could we learn? If we see rigidities or imperfections in that interactive experience, what innovation might we imagine that would not only reduce reputational risk but create something new and potentially advantageous? \n\nTechnological innovation was the subject of a recent award ceremony in San Francisco. The winners were companies with names like SoundCloud, GitHub, MakerBot, Techmeme, and Snapchat, all of which presumably do amazing things, although I don't understand exactly what.11  But, evidently, the real buzz at the ceremony was over something much more mundane that I for one have no problem understanding. That buzz was around a pedestrian item--a new and improved coffee cup lid.12  This lid, called FoamAroma, reportedly provides exactly the right set of openings to maximize aroma and recyclability, while minimizing the effects of coffee spurting out too fast. The point here is that the innovator noticed something simple that others had not: many coffee shop employees don't drink their coffee from cups with plastic lids like their customers do, so there was a market need that had not been recognized and then addressed.\n\nHere I am not just talking about the mixed miracle of mobile banking and mobile payments or being able to take a picture of a check with a smart phone and it appearing in my checking account. That's a topic that is amazing in its own right and worthy of a separate speech. I am talking about encouraging banks to pay attention to the banking experiences of their customers and finding process improvements or service elements that may lead to something seemingly mundane but valuable nonetheless.\n\nSome innovators see reputation itself as not just something to be managed, but as a product in and of itself. With buyers and sellers repeatedly and constantly interacting on the Internet, there are \"reputation trails\" that are being created that, when compiled, give an alternative set of markers about how trustworthy a particular buyer or seller may be. These reputation trails--gathered when you evaluate a product you've bought online or when you deliver the product that you've promised--create a picture of trust that some have argued has value that can be shaped.13 \n\nReputational Risks and Cybersecurity\nPerhaps reputation will one day transform commerce. But in the meantime, I would like to mention one set of reputational issues that the banking industry is confronting as we speak. As is the case for reputation trails, it too involves the Internet, but this use of the Internet is not being done in the spirit of cooperation and enhancement of public trust. This set of reputational issues comes in response to the recent substantial increase in cyberattacks, all of which have the potential to undermine the fundamental trust that the public puts into financial institutions. \n\nCyberattacks on banks are occurring with increasing frequency, and concerted cooperative work between government and financial institutions is underway. Customers are increasingly being affected by the cybersecurity threats that banks face. Recently, distributed denial-of-service attacks have caused temporary disruptions of some web services. In September, the websites of several large banks were rendered inaccessible for several hours from attacks now attributed to possible foreign state-sponsored hackers. One of the greatest threats facing not just banks but many businesses and government agencies is hacking--and the possible theft of proprietary data and personal information about customers.\n\nThis cybersecurity threat is increasing at a time when more and more bank customers depend on electronic and mobile banking. Workers are using their own laptops and smart phones or working remotely from home computers, and this increases the entry points to the systems that need to be protected. In addition, customers and vendors are linking their systems, enhancing efficiency, but also creating more opportunities for potential intrusions.\n\nBut even beyond the potential theft of data and disruption of service, cyberattacks can represent significant reputational risk because they have the potential to create dissatisfaction among many customers or, even more chilling, total loss of consumer confidence.\n\nCooperative work between government and industry is underway. Through the Department of the Treasury, many of the affected institutions have requested and received technical assistance from the Department of Homeland Security, which has been helpful in mitigating the attacks. Some institutions are researching new technologies for defense against cyberattacks through their Internet service providers or security vendors, and others are reviewing their incident response processes to better manage recovery time and communications among information technology, employees, vendors, media, and customers.\n\nThe Financial and Banking Information Infrastructure Committee, the Financial Services Information Sharing and Analysis Center, and the Financial Services Sector Coordinating Council are serving as the forum through which the financial services sector shares important information and develops critical infrastructure protection policies. Through their coordination, affected institutions and law enforcement agencies can share threat information and mitigation techniques.\n\nIn addition, a recent Executive Order issued by the President represents a continued commitment to enhancing the security and resiliency of the nation's critical infrastructure to meet future threats.14 \n\nConclusion\nIn closing, these have been some of my reflections on reputation as it applies to the business of banks. The concept of trust is relevant to how bankers engage in a business that is of benefit to the public and provides meaningful innovation to the core function of financial intermediation, as well as to how we as supervisors can engage in a process of observation that is forward-looking and of benefit to both the public and the institutions that we regulate.  \n\nThank you for your attention today. I look forward to taking your questions.\n\n \n\n1. See Sarah Bloom Raskin, Federal Reserve Board Governor (2012), \"How Well is our Financial System Serving Us? Working Together to Find the High Road,\" speech delivered at the Graduate School of Banking at Colorado, Boulder, Colorado, July 23. See also Wallace C. Turbeville (2012), \"Cracks in the Pipeline: Restoring Efficiency to Wall Street and Value to Main Street ,\" Demos, Financial Pipeline Series, December 5. Return to text\n\n2. The public also remains angry at policymakers for actions taken since the crisis. The erosion of public trust extends beyond financial institutions to the government officials that oversee them. For example, an American Banker reader poll conducted from December 17–23, 2012, found that a mere 8 percent of readers who responded thought authorities took the right course in the case of enforcement against HSBC for money laundering violations. As many as 47 percent said the Justice Department should have prosecuted the bank, while another 45 percent said authorities should have gone after the individuals responsible for the violations. Return to text\n\n3. See Lee Rainie, Aaron Smith, Kay Lehman Schlozman, Henry Brady, and Sidney Verba (2012), \"Social Media and Political Engagement (PDF) ,\" Pew Internet & American Life Project (Washington, DC: Pew Research Center, October 19). Return to text\n\n4. The reasons for ineffective supervision can be explored separately; they are beyond the scope of my remarks today. It is worth considering, however, whether the reputation of large banks would be enhanced by a belief that \"regulatory capture\" and other manifestations of ineffective supervision could be minimized. Return to text\n\n5. See Board of Governors of the Federal Reserve System, Division of Banking Supervision and Regulation (1995), \"Rating the Adequacy of Risk Management Processes and Internal Controls at State Member Banks and Bank Holding Companies,\" Supervision and Regulation Letter 95-51 (SUP) (November 14). Return to text\n\n6. Other regulators consider reputation risk as part of their supervisory programs. The Public Company Accounting Oversight Board (PCAOB) has integrated reputational risk into its guidance on how an auditor should evaluate a company's internal controls and corporate governance environment. Other PCAOB standards include reputational risk as it relates to executive compensation structures. Return to text\n\n7. Pillar 2 of the Basel II capital framework, however, does note that internationally active banks are expected to hold sufficient capital to address all significant risks, including reputational risk, as part of their internal capital adequacy assessment processes. Return to text\n\n8. See Federal Deposit Insurance Corporation (2012), 2011 FDIC National Survey of Unbanked and Underbanked Households (PDF). See also Brian K. Bucks, Arthur B. Kennickell, Traci L. Mach, and Kevin B. Moore (2009), \"Changes in U.S. Family Finances from 2004 to 2007: Evidence from the Survey of Consumer Finances (PDF),\" Federal Reserve Bulletin, v. 95 (February), pp. A1–A55. Return to text\n\n9. See Federal Deposit Insurance Corporation (2012). Return to text\n\n10. See Jesse Bricker, Arthur B. Kennickell, Kevin B. Moore, and John Sabelhaus (2012), \"Changes in U.S. Family Finances from 2007 to 2010: Evidence from the Survey of Consumer Finances (PDF),\" Federal Reserve Bulletin, v. 98 (June), pp. 1-80. Return to text\n\n11. See http://techcrunch.com/events/crunchies-2012/winners/. Return to text\n\n12. See Holly Finn (2013), \"Modest Miracles of Invention,\" Wall Street Journal, February 8, available at http://online.wsj.com/article/SB10001424127887323807004578285943330078754.html. Return to text\n\n13. See Rachel Botsman (2012), \"The currency of the new economy is trust,\" speech delivered at TEDGlobal 2012 in Edinburgh, Scotland, June, available at http://www.ted.com/talks/rachel_botsman_the_currency_of_the_new_economy_is_trust.html. Return to text\n\n14. Executive Office of the President (2013), \"Improving Critical Infrastructure Cybersecurity, Executive Order 13636,\" Federal Register, vol. 78 (February 19), pp.11737-44. Return to text"
    },
    {
        "title": "Long-Term Interest Rates",
        "date": "March 01, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20130301a.htm",
        "content": "March 01, 2013\n\nChairman Ben S. Bernanke\n\nAt the Annual Monetary/Macroeconomics Conference: The Past and Future of Monetary Policy, sponsored by Federal Reserve Bank of San Francisco, San Francisco, California\n\nI will begin my remarks by posing a question: Why are long-term interest rates so low in the United States and in other major industrial countries?\n\nAt first blush, the answer seems obvious: Central banks in those countries are pursuing accommodative monetary policies to boost growth and reduce slack in their economies. However, while central banks certainly play a key role in determining the behavior of long-term interest rates, theirs is only a proximate influence. A more complete explanation of the current low level of rates must take account of the broader economic environment in which central banks are currently operating and of the constraints that that environment places on their policy choices.\n\nLet me start with a brief overview of the recent history of long-term interest rates in some key economies. Chart 1 shows the 10-year government bond yields for five major industrial countries: Canada, Germany, Japan, the United Kingdom, and the United States. Note that the movements in these yields are quite correlated despite some differences in the economic circumstances and central bank mandates in those countries. Further, with the notable exception of Japan, the levels of the yields have been very similar--indeed, strikingly so, with long-term yields declining over time and currently close to 2 percent in each case. The similar behavior of these yields attests to the global nature of the economic and financial developments of recent years, as well as to the broad similarity in how the monetary policymakers in the advanced economies have responded to these developments. Of course, Japanese yields are clearly a case apart, as Japan has endured an extended period of deflation, while inflation in the other four countries has been positive and generally close to the stated objectives of the monetary authorities. But even Japanese yields have shown some tendency to fluctuate along with other benchmark yields, and they have also declined over the period shown.\n\nIn my comments, I will delve more deeply into the reasons why these long-term interest rates have fallen so low. This examination may be useful both for understanding the current stance of policy and also for thinking about how rates may evolve. In short, we expect that as the economy recovers, long-term rates will rise over time to more normal levels. A return to more normal conditions in financial markets would, of course, be most welcome. Many commentators have noted, however, that both an extended period of low rates and the transition back toward normal levels may pose risks to financial stability. In the final portion of my remarks, I will discuss some aspects of how the Federal Reserve is approaching these risks.\n\nWhy Are Long-Term Interest Rates So Low?\nSo, why are long-term interest rates currently so low? To help answer this question, it is useful to decompose longer-term yields into three components: one reflecting expected inflation over the term of the security; another capturing the expected path of short-term real, or inflation-adjusted, interest rates; and a residual component known as the term premium. Of course, none of these three components is observed directly, but there are standard ways of estimating them. Chart 2 displays one version of this decomposition of the 10-year U.S. Treasury yield based on a term structure model developed by Federal Reserve staff.1  The broad features I will emphasize are similar to those found by other authors using a variety of methods.2 \n\nAll three components of the 10-year yield have declined since 2007. The decomposition attributes much of the decline in the yield since 2010 to a sharp fall in the term premium, but the expected short-term real rate component also moved down significantly. Let's consider each component more closely.\n\nThe expected inflation component has drifted gradually downward for many years and has become quite stable. In large part, the downward trend and stabilization of expected inflation in the United States are products of the increasing credibility of the Federal Reserve's commitment to price stability. In January 2012, the Federal Open Market Committee (FOMC) underscored this commitment by issuing a statement--since reaffirmed at its January 2013 meeting--on its longer-run goals and policy strategy, which included a longer-run inflation target of 2 percent.3  The anchoring of long-term inflation expectations near 2 percent has been a key factor influencing long-term interest rates over recent years. It almost certainly helped mitigate the strong disinflationary pressures immediately following the crisis. While I have not shown expected inflation for other advanced economies, the pictures would be very similar--again, except for Japan.\n\nWith the expected inflation component of the 10-year rate near 2 percent and the rate itself a bit below 2 percent recently, it is clear that the combination of the other two components--the expected path of short-term real interest rates and the term premium--must make a small net negative contribution.\n\nThe expected path of short-term real interest rates is, of course, influenced by monetary policy, both the current stance of policy and market participants' expectations of how policy will evolve. The stance of monetary policy at any given time, in turn, is driven largely by the economic outlook, the risks surrounding that outlook, and at times other factors, such as whether the zero lower bound on nominal interest rates is binding. In the current environment, both policymakers and market participants widely agree that supporting the U.S. economic recovery while keeping inflation close to 2 percent will likely require real short-term rates, currently negative, to remain low for some time. As shown in chart 2, the expected average of the short-term real rate over the next 10 years has gradually declined to near zero over the past few years, in part reflecting downward revisions in expectations about the pace of the ongoing recovery and, hence, a pushing out of expectations regarding how long nominal short-term rates will remain low.4  \n\nAs the persistence of the effects of the crisis have become clearer, the Federal Reserve's communications have reinforced the expectation that conditions are likely to warrant highly accommodative policy for some time: Most recently, the FOMC indicated that it expects to maintain an exceptionally low level of the federal funds rate at least as long as the unemployment rate is above 6.5 percent, projected inflation between one and two years ahead is no more than a half percentage point above the Committee's 2 percent target, and long-term inflation expectations remain stable.5 \n\nIn discussing the role of monetary policy in determining the expected future path of real short-term rates, I have cheated a little: What monetary policy actually controls is nominal short-term rates. However, because inflation adjusts slowly, control of nominal short-term rates usually translates into control of real short-term rates over the short and medium term. In the longer term, real interest rates are determined primarily by nonmonetary factors, such as the expected return to capital investments, which in turn is closely related to the underlying strength of the economy. The fact that market yields currently incorporate an expectation of very low short-term real interest rates over the next 10 years suggests that market participants anticipate persistently slow growth and, consequently, low real returns to investment. In other words, the low level of expected real short rates may reflect not only investor expectations for a slow cyclical recovery but also some downgrading of longer-term growth prospects.6 \n\nChart 3, which displays yields on inflation-indexed, long-term government bonds for the same five countries represented in chart 1, shows that expected real yields over the longer term are low in other advanced industrial economies as well. Note again the strong similarity in returns across these economies, suggesting once again the importance of common global factors. While indexed yields spiked up around the end of 2008, reflecting market stresses at the height of the crisis that undercut the demand for these bonds, these effects dissipated in 2009. Since that time, inflation-indexed yields have declined steadily and now stand below zero in each country.7  Apparently, low longer-term real rate expectations are playing an important role in accounting for low 10-year nominal rates in other industrial countries, as well as in the United States.\n\nThe third and final component of the long-term interest rate is the term premium, defined as the residual component not captured by expected real short-term rates or expected inflation. As I noted, the largest portion of the downward move in long-term rates since 2010 appears to be due to a fall in the term premium, so it deserves some special discussion.\n\nIn general, the term premium is the extra return investors expect to obtain from holding long-term bonds as opposed to holding and rolling over a sequence of short-term securities over the same period. In part, the term premium compensates bondholders for interest rate risk--the risk of capital gains and losses that interest rate changes imply for the value of longer-term bonds. Two changes in the nature of this interest rate risk have probably contributed to a general downward movement of the term premium in recent years. First, the volatility of Treasury yields has declined, in part because short-term rates are pressed up against the zero lower bound and are expected to remain there for some time to come. Second, the correlation of bond prices and stock prices has become increasingly negative over time, implying that bonds have become more valuable as a hedge against risks from holding other assets.8 \n\nBeyond interest rate risk, a number of other factors also affect the term premium in practice. For example, during periods of financial turmoil, the prices of longer-term Treasury securities are often driven up by so-called safe-haven demands of investors who place special value on the safety and liquidity of Treasury securities. Indeed, even during more placid periods, global demands for safe assets increase the value of Treasury securities. Many foreign governments and central banks, particularly those with sustained current account surpluses, hold substantial international reserves in the form of Treasuries. Foreign holdings of U.S. Treasury securities currently amount to about $5‑1/2 trillion, roughly half of the total amount of marketable Treasury debt outstanding. The global economic and financial stresses of recent years--triggered first by the financial crisis, and then by the problems in the euro area--appear to have significantly elevated the safe-haven demand for Treasury securities at times, pushing down Treasury yields and implying a lower, or even a negative, term premium.9 \n\nFederal Reserve actions have also affected term premiums in recent years, most prominently through a series of Large-Scale Asset Purchase (LSAP) programs. These programs consist of open market purchases of agency debt, agency mortgage-backed securities, and longer-term Treasury securities. To the extent that Treasury securities and agency-guaranteed securities are not perfect substitutes for other assets, Federal Reserve purchases of these assets should lower their term premiums, putting downward pressure on longer-term interest rates and easing financial conditions more broadly. Although estimated effects vary, a growing body of research supports the view that LSAPs are effective at bringing down term premiums and thus reducing longer-term rates.10  Of course, the Federal Reserve has used this unconventional approach to lowering longer-term rates because, with short-term rates near zero, it can no longer use its conventional approach of cutting the target for the federal funds rate.11  Accordingly, this portion of the decline in the term premium might ultimately be attributed to the sluggish economic recovery, which prompted additional policy action from the Federal Reserve.\n\nLet's recap. Long-term interest rates are the sum of expected inflation, expected real short-term interest rates, and a term premium. Expected inflation has been low and stable, reflecting central bank mandates and credibility as well as considerable resource slack in the major industrial economies. Real interest rates are expected to remain low, reflecting the weakness of the recovery in advanced economies (and possibly some downgrading of longer-term growth prospects as well). This weakness, all else being equal, dictates that monetary policy must remain accommodative if it is to support the recovery and reduce disinflationary risks. Put another way, at the present time the major industrial economies apparently cannot sustain significantly higher real rates of return; in that respect, central banks--so long as they are meeting their price stability mandates--have little choice but to take actions that keep nominal long-term rates relatively low, as suggested by the similarity in the levels of the rates shown in chart 1. Finally, term premiums are low or negative, reflecting a host of factors, including central bank actions in support of economic recovery. Thus, while the current constellation of long-term rates across many advanced countries has few precedents, it is not puzzling: It follows naturally from the economic circumstances of these countries and the implications of these circumstances for the policies of their central banks.\n\nHow Are Long-Term Rates Likely to Evolve?\nSo, how are long-term rates likely to evolve over coming years? It is worth pausing to note that, not that long ago, central bankers would have carefully avoided this topic. However, it is now a bedrock principle of central banking that transparency about the likely path of policy, in general, and interest rates, in particular, can increase the effectiveness of policy. In the present context, I would add that transparency may mitigate risks emanating from unexpected rate movements. Thus, let me turn to prospects for long-term rates, starting with the expected path of rates and then turning to deviations from the expected path that may arise.\n\nIf, as the FOMC anticipates, the economic recovery continues at a moderate pace, with unemployment slowly declining and inflation expectations remaining near 2 percent, then long-term interest rates would be expected to rise gradually toward more normal levels over the next several years. This rise would occur as the market's view of the expected date at which the Federal Reserve will begin the removal of policy accommodation draws nearer and then as accommodation is removed. Some normalization of the term premium might also contribute to a rise in long-term rates.\n\nTo illustrate possible paths, Chart 4 displays four different forecasts of the evolution of the 10-year Treasury yield over coming years. The black line is the forecast reported in the December 2012 Blue Chip Financial Forecasts survey. The green line gives the Congressional Budget Office forecast published in February, and the blue line presents the median from the Survey of Professional Forecasters, as reported in the first quarter of this year. Finally, the purple line shows a forecast based on the term structure model used for the decomposition of the 10‑year yield in chart 2.12  While these forecasts embody a wide range of underlying models and assumptions, the basic message is clear--long-term interest rates are expected to rise gradually over the next few years, rising (at least according to these forecasts) to around 3 percent at the end of 2014. The forecasts in chart 4 imply a total increase of between 200 and 300 basis points in long-term yields between now and 2017.\n\nOf course, the forecasts in chart 4 are just forecasts, and reality might well turn out to be different. Chart 5 provides three complementary approaches to summarizing the uncertainty surrounding forecasts of long-term rates. The dark gray bars in the chart are based on the range of forecasts reported in the Blue Chip Financial Forecasts, the blue bars are based on the historical uncertainty regarding long-term interest rates as reflected in the Board staff's FRB/US model of the U.S. economy, and the orange bars give a market-based measure of uncertainty derived from swaptions. These three different measures give a broadly similar picture about the upside and downside risks to the forecasts of long-term rates. Rates 100 basis points higher than the expected paths in chart 4 by 2014 are certainly plausible outcomes as judged by each of the three measures, and this uncertainty grows to as much as 175 basis points by 2017. Note, though, that while the risk of an unexpected rise in interest rates has drawn much attention, the level of long-term interest rates also could prove to be lower than forecast. Indeed, by the measures shown in chart 5, the upside and downside risks to the level of rates are roughly symmetric as of 2017.\n\nWe also have some historical experience with increases in rates during tightening cycles to consider. For example, in 1994, 10-year Treasury yields rose about 220 basis points over the course of a year, reflecting an unexpected quickening in the pace of economic growth and signs of building inflation pressures. This increase in long-term rates appears to have reflected a mix of a pronounced rise in the expected path of the policy interest rate and some increase in the term premium.13  A rise of more than 200 basis points in a year is at the upper end of what is implied by the mean paths and uncertainty measures shown in charts 4 and 5, but these measures still admit a substantial probability of higher--and lower--paths.\n\nOverall, then, we anticipate that long-term rates will rise as the recovery progresses and expected short-term real rates and term premiums return to more normal levels. The precise timing and pace of the increase will depend importantly on how economic conditions develop, however, and is subject to considerable two-sided uncertainty.\n\nManaging Risks Associated with the Future Course of Long-Term Interest Rates\nAs I noted when I began my remarks, one reason to focus on the timing and pace of a possible increase in long-term rates is that these outcomes may have implications for financial stability. Commentators have raised two broad concerns surrounding the outlook for long-term rates. To oversimplify, the first risk is that rates will remain low, and the second is that they will not. In particular, in an environment of persistently low returns, incentives may grow for some investors to engage in an unsafe \"reach for yield\" either through excessive use of leverage or through other forms of risk-taking. My Board colleague Jeremy Stein recently discussed how this behavior may arise in some financial markets, including credit markets.14  Alternatively, we face a risk that longer-term rates will rise sharply at some point, imposing capital losses on holders of fixed-income instruments, including financial institutions. Of course, the two risks may very well be mutually reinforcing: Taking on duration risk is one way investors may reach for yield, and the losses resulting from a sharp rise in longer-term rates will be greater if investors have done so.15 \n\nOne might argue that the right response to these risks is to tighten monetary policy, raising long-term interest rates with the aim of forestalling any undesirable buildup of risk. I hope my discussion this evening has convinced you that, at least in economic circumstances of the sort that prevail today, such an approach could be quite costly and might well be counterproductive from the standpoint of promoting financial stability. Long-term interest rates in the major industrial countries are low for good reason: Inflation is low and stable and, given expectations of weak growth, expected real short rates are low. Premature rate increases would carry a high risk of short-circuiting the recovery, possibly leading--ironically enough--to an even longer period of low long-term rates. Only a strong economy can deliver persistently high real returns to savers and investors, and the economies of the major industrial countries are still in the recovery phase.\n\nSo how can financial stability concerns--which the Federal Reserve takes very seriously--be addressed? Our strategy, undertaken in cooperation with other regulators and central banks, has a number of elements.\n\nFirst, we have greatly increased our macroprudential oversight, with a particular focus on potential systemic vulnerabilities, including buildups of leverage and unstable funding patterns as well as interest rate risk.16  Under the umbrella of our interdisciplinary Large Institutions Supervision Coordinating Committee, we pay special attention to developments at the largest, most complex financial firms, making use of information gathered in our supervision of the institutions and drawn from financial market indicators of their health and systemic vulnerability. We also monitor the shadow banking sector, especially its interaction with regulated institutions; in this work, we look for factors that may leave the system vulnerable to an adverse \"fire sale\" dynamic, in which declining asset values could force leveraged investors to sell assets, depressing prices further. We exchange information regularly with other regulatory agencies, both directly and under the auspices of the Financial Stability Oversight Council. Throughout the Federal Reserve System, work in these areas is conducted by experts in banking, financial markets, monetary policy, and other disciplines, and at the Federal Reserve Board we have established our Office for Financial Stability Policy and Research to help coordinate this work. Findings are presented regularly to the Board and to the FOMC for use in its monetary policy deliberations.\n\nSecond, recognizing that our monitoring of the financial sector will always be imperfect, we are using regulatory and supervisory tools to help ensure that financial institutions are sufficiently resilient to weather losses and periods of market turmoil arising from any source. Indeed, reflecting expectations embodied in the new Basel III and Dodd-Frank standards, the largest and most complex financial firms have substantially increased both their capital and their liquidity in recent years. Our current round of stress testing of the largest bank holding companies, to be completed early this month, examines whether the largest banking firms have sufficient capital to come through a seriously adverse economic downturn and still have the capacity to perform their roles as providers of credit. In a related exercise, we are also asking banks to stress-test the adequacy of their capital in the face of a hypothetical sharp upward shift in the term structure of interest rates.\n\nThird, our approach to communicating and implementing monetary policy provides the Federal Reserve with new tools that could potentially be used to mitigate the risk of sharp increases in interest rates. In 1994--the period discussed earlier in which sharp increases in interest rates strained financial markets--the FOMC's communication tools were very limited; indeed, it had just begun issuing public statements following policy moves. By contrast, in recent years, the Federal Reserve has provided a great deal of additional information about its expectations for the path of the economy and the stance of monetary policy. Most recently, as I mentioned, the FOMC announced unemployment and inflation thresholds characterizing conditions that will guide the timing of the first increase in the target for the federal funds rate. Further, the FOMC stated that a highly accommodative stance of monetary policy is likely to remain appropriate for a considerable time after our current asset purchase program ends. By providing greater clarity concerning the likely course of the federal funds rate, FOMC communication should both make policy more effective and reduce the risk that market misperceptions of the Committee's intentions would lead to unnecessary interest rate volatility.\n\nIn addition, the Federal Reserve could, if necessary, use its balance sheet tools to mitigate the risk of a sharp rise in rates. For example, the Committee has indicated its intention to sell its agency securities gradually once conditions warrant. The Committee also noted, however, that the pace of sales could be adjusted up or down in response to material changes in either the economic outlook or financial conditions. In particular, adjustments to the pace or timing of asset sales could be used, under some circumstances, to dampen excessively sharp adjustments in longer-term interest rates.\n\nConclusion\nLet me finish with some thoughts on balancing the risks we face in the current challenging economic environment, at a time when our main policy tool, the federal funds rate, is near its effective lower bound. On the one hand, the Fed's dual mandate has led us to provide strong support for the recovery, both to promote maximum employment and to keep inflation from falling below our price stability objective. One purpose of this support is to prompt a return to the productive risk-taking that is essential to robust growth and to getting the unemployed back to work. On the other hand, we must be mindful of the possibility that sustained periods of low interest rates and highly accommodative policy could lead to excessive risk-taking in some financial markets. The balance here is not an easy one to strike. While the recent crisis is vivid testament to the costs of ill-judged risk-taking, we must also be aware of constraints posed by the present state of the economy. In light of the moderate pace of the recovery and the continued high level of economic slack, dialing back accommodation with the goal of deterring excessive risk-taking in some areas poses its own risks to growth, price stability, and, ultimately, financial stability. Indeed, as I noted, a premature removal of accommodation could, by slowing the economy, perversely serve to extend the period of low long-term rates.\n\nFor these reasons, we are responding to financial stability concerns with the multipronged approach I summarized a moment ago, which relies primarily on monitoring, supervision and regulation, and communication. We will, however, be evaluating these issues carefully and on an ongoing basis; we will be alert for any developments that pose risks to the achievement of the Federal Reserve's mandated objectives of price stability and maximum employment; and we will, of course, remain prepared to use all of our tools as needed to address any such developments.\n\n \n\nReferences\nAdrian, Tobias, Daniel Covitz, and Nellie Liang (forthcoming). \"Financial Stability Monitoring,\" Finance and Economics Discussion Series. Washington: Board of Governors of the Federal Reserve System.\n\nBoard of Governors of the Federal Reserve System (2012), \"Federal Reserve Issues FOMC Statement,\" press release, December 12.\n\nCampbell, John Y., Adi Sunderam, and Luis M. Viceira (2009). \"Inflation Bets or Deflation Hedges? The Changing Risks of Nominal Bonds,\" NBER Working Paper Series 14701. Cambridge, Mass.: National Bureau of Economic Research, February.\n\nD'Amico, Stefania, William English, David López-Salido, and Edward Nelson (2012). \"The Federal Reserve's Large-Scale Asset Purchase Programmes: Rationale and Effects,\" Economic Journal, vol. 122 (November), pp. F415-F446.\n\nD'Amico, Stefania, Don H. Kim, and Min Wei (2010). \"Tips from TIPS: The Informational Content of Treasury Inflation Protected Security Prices,\" Finance and Economics Discussion Series 2010-19. Washington: Board of Governors of the Federal Reserve System, December 2009.\n\nGagnon, Joseph, Matthew Raskin, Julie Remache, and Brian Sack (2011). \"The Financial Market Effects of the Federal Reserve's Large-Scale Asset Purchases,\" International Journal of Central Banking, vol. 7 (March), pp. 3-43.\n\nHamilton, James D., and Jing Cynthia Wu (2012). \"The Effectiveness of Alternative Policy Tools in a Zero Lower Bound Environment,\" Journal of Money, Credit and Banking, vol. 44 (February supplement), pp. 3-46.\n\nHancock, Diana, and Wayne Passmore (2012). \"The Federal Reserve's Portfolio and Its Effects on Mortgage Markets (PDF),\" Finance and Economic Discussion Series 2012-22. Washington: Board of Governors of the Federal Reserve System.\n\nKrishnamurthy, Arvind, and Annette Vissing-Jørgensen (2011). \"The Effects of Quantitative Easing on Interest Rates: Channels and Implications for Policy,\" Brookings Papers on Economic Activity, Fall, pp. 215-65.\n\nLi, Canlin, and Min Wei (2012). \"Term Structure Modelling with Supply Factors and the Federal Reserve's Large Scale Asset Purchase Programs,\" Finance and Economics Discussion Series 2012-37. Washington: Board of Governors of the Federal Reserve System, May.\n\nRosa, Carlo (2012). \"How 'Unconventional' Are Large-Scale Asset Purchases? The Impact of Monetary Policy on Asset Prices (PDF) ,\" Federal Reserve Bank of New York Staff Reports 560. New York: Federal Reserve Bank of New York, May.\n\nStein, Jeremy C. (2013). \"Overheating in Credit Markets: Origins, Measurement, and Policy Responses,\" speech delivered at \"Restoring Household Financial Stability after the Great Recession: Why Household Balance Sheets Matter,\" a symposium sponsored by the Federal Reserve Bank of St. Louis, St. Louis, February 5-7.\n\n \n\n1. Estimates are based on the model of D'Amico, Kim, and Wei (2010). That model employs the \"arbitrage-free\" term structure framework and jointly models real yields, nominal yields, and inflation as functions of four underlying latent factors. Historical data on nominal yields, real yields, and inflation can be used to estimate these underlying factors and the relationship of real and nominal yields to the factors. Based on this information, the model can be used to produce estimates of the components of nominal yields shown in chart 2. Note that inflation in chart 2 is measured by the consumer price index; inflation measured by this index is close to but on average slightly higher than inflation as measured by the price index for personal consumption expenditures, the measure to which the Federal Open Market Committee's 2 percent inflation objective refers. Return to text\n\n2. For example, this decomposition as estimated based on expectations as reported in the Blue Chip Financial Forecasts gives broadly similar results, as do many standard term structure models. Return to text\n\n3. See Statement on Longer-Run Goals and Monetary Policy Strategy (PDF), as amended effective on January 29, 2013. Return to text\n\n4. Real interest rates are not constrained by the zero bound, and the fact that expected average real short-term interest rates are near zero reflects that the nominal rate is expected, on average, to run close to the expected inflation rate, which is near 2 percent. Return to text\n\n5. See the FOMC's December statement at Board of Governors (2012). Return to text\n\n6. Between April 2009 and October 2012, expectations for average growth over the next 10 years, as reported in Consensus Forecasts, have fallen about 0.2 percentage points for the United States. This reduction in growth expectations is a broad phenomenon: Between April 2009 and October 2012, the average prediction for growth over the next 10 years for Canada, Germany, Japan, and the United Kingdom has fallen between 0.1 and 0.6 percentage points. Return to text\n\n7. It is important to note that these indexed yields are likely being pushed down by term premiums akin to the term premiums in nominal rates discussed in this speech. Return to text\n\n8. See, for example, Campbell, Sunderam, and Viceira (2009). Return to text\n\n9. There are some additional more technical features of the Treasury market that push down the term premium. For example, the Treasury term premium is likely also depressed by the global demand for Treasury securities for use as collateral or margin in funding or derivatives markets. Return to text\n\n10. See, for example, Gagnon, Raskin, Remache, and Sack (2011); Li and Wei (2012); Hamilton and Wu (2012); D'Amico, English, López-Salido, and Nelson (2012); Rosa (2012); Krishnamurthy and Vissing-Jørgensen (2011); and Hancock and Passmore (2012). Return to text\n\n11. Term premiums, calculated using similar methods, have also declined fairly sharply recently in Canada, Germany, and the United Kingdom; somewhat less so in Japan. This result is notable in that the central banks of these economies, with the exception of the Bank of England, have not pursued large-scale purchases of longer-term securities. Return to text\n\n12. This projection assumes that two key components of the 10-year Treasury yield shown in chart 2--the expected average real short-rate and the term premium--revert to their respective mean levels over the period 2000 to 2006 during the next 5 years; the expected average inflation component is assumed to remain constant near the 2 percent level prevailing at the end of 2012. Return to text\n\n13. The two components were intertwined, as measures of uncertainty about the path of policy moved up sharply, likely contributing to a rise in term premiums. Notably, in this episode, the rise in rates created some stress in financial markets but did not lead to serious financial instability, nor did it significantly impair economic activity. However, one would not want to conclude from that one case that sharp rises in rates do not pose risks. Return to text\n\n14. See Stein (2013). Return to text\n\n15. On the other hand, some risk-taking--such as when an entrepreneur takes out a loan to start a new business or an existing firm expands capacity--is a necessary element of a healthy economic recovery. Moreover, although accommodative monetary policies may increase certain types of risk-taking, in the present circumstances they also serve in some ways to reduce risk in the system, most importantly by strengthening the overall economy, but also by encouraging firms to rely more on longer-term funding, and by reducing debt service costs for households and businesses. Return to text\n\n16. See Adrian, Covitz, and Liang (forthcoming). Return to text"
    },
    {
        "title": "Ending \"Too Big to Fail\"",
        "date": "March 04, 2013",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20130304a.htm",
        "content": "March 04, 2013\n\nGovernor Jerome H. Powell\n\nAt the Institute of International Bankers 2013 Washington Conference, Washington, D.C.\n\nToday I will discuss \"too big to fail\" and the ongoing work since the financial crisis to end it.1   More than three years into this effort, there have been sweeping reforms to the regulation of large financial organizations in the United States and around the world. Substantial proportions of the new rules are designed to end the practice of bailing out such firms with taxpayer money. The too-big-to-fail reform project is massive in scope. In my view, it holds real promise. But the project will take years to complete. Success is not assured.\n\nIn the meantime, some urge the adoption of more intrusive reforms, such as a return to Glass-Steagall-style activity limits, more stringent limits on size or systemic footprint, or a requirement that the largest institutions break up into much smaller pieces. I believe that public discussion and evaluation of these ideas is important. At a minimum, we need to thoroughly understand these alternatives in case the existing reform project falters.\n\nIt is worth noting that too big to fail is not simply about size. A big institution is \"too big\" when there is an expectation that government will do whatever it takes to rescue that institution from failure, thus bestowing an effective risk premium subsidy. Reforms to end too big to fail must address the causes of this expectation. \n\nIn broad terms, these reforms seek to eliminate the expectation of bailouts in two ways--by significantly reducing the likelihood of systemic firm failures, and by greatly limiting the costs to society of such failures. When failures are unusual and the costs of such a failure are modest, the expectation at the heart of too big to fail will be substantially eliminated. My focus today is principally on the second of these two aspects of reform--containing the costs and systemic risks from failures, a goal being advanced by work to create a credible resolution authority.\n\nI hope you won't mind if I draw today on some of my own experiences over the years with too big to fail, beginning with my service at the Treasury Department during the Administration of President George H.W. Bush. I joined the Administration only a few years after the rescue of Continental Illinois, which is sometimes said to have codified the practice of too big to fail. \n\nIn my years at Treasury, we faced a wave of well over 1,000 savings and loan and bank failures. That included the failure of the Bank of New England Corp., then the third largest bank failure in U.S. history.2   It happened in January 1991, at a time of great stress in the financial system and the broader economy, and only days after 45 depository institutions in the region had been closed and 300,000 deposit accounts frozen.3   My Treasury colleagues and I joined representatives of the Federal Deposit Insurance Corporation (FDIC) and the Federal Reserve Board in a conference room on a Sunday morning. We came to understand that either the FDIC would protect all of the bank's depositors, without regard to deposit insurance limits, or there would likely be a run on all the money center banks the next morning--the first such run since 1933.  We chose the first option, without dissent.4 \n\nIn the summer of 1991, we faced the Salomon Brothers crisis. Salomon, a global investment bank, was one of the largest financial institutions in the United States, and the largest dealer in U.S. government securities. The firm came under severe market pressure after some of its traders were caught submitting phony bids in Treasury bond auctions.  As recounted in harrowing detail in the book \"The Snowball,\" Salomon came within hours of failure over a weekend in late August.5   Salomon was clearly understood to be outside the safety net, and I recall no discussion of a government rescue. But the firm's failure would almost certainly have caused massive disruption in the markets. To this day, I am grateful that we resolved that crisis with neither a bailout nor a failure. \n\nOver 20 years later, both these events still frame the too big to fail reform agenda. Faced with the failure of a large commercial bank, we chose to extend the safety net rather than run the very real risk of a systemic depositor run. Our \"near miss\" with Salomon in 1991 presaged the enormous damage that would result from the failure of Lehman Brothers, another investment bank, in 2008. In fact, the dimension of the problem grew substantially over the years. Since 1991, the ratio of U.S. banking assets to annual gross domestic product in the United States has more than doubled, from 55 percent to 126 percent. Meanwhile, the percentage of those assets held by the largest three institutions has increased from 14 to 32 percent. \n\nBailouts may have been more tolerable in the early 1990s when they were rare and their use for a failing bank was uncertain. That is no longer the case. Recent years have seen large and numerous bailouts as a result of the financial crisis. The public, the regulatory community, and large financial institutions themselves all agree now that too big to fail must end. \n\nAs I said earlier, reforms to end too big to fail must wage the fight on two fronts. First, we need enhanced regulation to make large financial institution failures much less likely. Second, we need a credible mechanism to manage the failure of even the largest firms, without causing or amplifying a systemic crisis.  \n\nLet's survey what has been proposed and implemented thus far in that two-front war on too big to fail. \n\nThe U.S. and Global Efforts to Address Too Big to Fail\n\nReducing the Probability of Default of Systemic Financial Firms\nMuch has been done since the crisis to strengthen the regulation of large banking organizations. The highlights would begin with the Basel III capital and liquidity reforms, including the graduated risk-based capital surcharges for globally systemic financial firms. These reforms are in the process of implementation in the United States and elsewhere.  In addition, the Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank) imposes on the largest financial institutions enhanced prudential standards and also requires central clearing of derivatives.  And banking regulators have implemented enhanced supervisory measures such as stress testing and recovery planning. \n\nWhile these measures are not the primary focus of my remarks today, I believe that they collectively constitute a broad and well-structured agenda to strengthen the resilience of the financial system. The Federal Reserve and the rest of the regulatory community are working diligently to implement that agenda. \n\nToday, risk-based capital and leverage ratios for banks of all sizes have improved materially since 2009 and are significantly above their levels in the years preceding the crisis. The banking sector overall also has substantially improved its liquidity position over the past few years. The system is undeniably stronger than before the crisis.6 \n\nReducing the Systemwide Loss Given Default of Systemic Financial Firms   \nIt is neither possible nor desirable to regulate large financial institutions so that they literally cannot fail. But regulation can limit the systemwide impact of such a failure. Let's review what has been done since the crisis to reduce the damage to the system from the failure of one of the very largest firms.\n\nUnder Dodd-Frank, nearly all financial institution failures, including those of large, complex institutions, will continue to be addressed as they were before passage of the new law. The holding company will be resolved in bankruptcy. Operating subsidiary failures will continue to be treated either under bankruptcy or, where applicable, under specialized resolution schemes, including the Federal Deposit Insurance Act for banks and the Securities Investor Protection Act for securities firms. \n\nDodd-Frank eliminated the authority used by the Federal Reserve and other regulators to bail out individual institutions during the crisis, including Bear Stearns, Citicorp, Bank of America and AIG. But Congress also recognized that there may be rare instances in which the failure of a large financial firm could threaten the financial stability of the United States. To empower regulators to handle such a failure without destabilizing the financial system or exposing taxpayers to loss, Dodd-Frank created two important new regulatory tools.  \n\nFirst, the Act requires large bank holding companies and nonbank financial firms designated by the Financial Stability Oversight Council to submit a resolution plan or \"living will\" for their rapid and orderly resolution under the Bankruptcy Code. Second, the Act created a new Orderly Liquidation Authority (OLA) as a backup to resolution in an ordinary bankruptcy.\n\nThe largest bank holding companies submitted their first annual \"living wills\" to the Federal Reserve and the FDIC last summer. The initial round has yielded valuable information that is being used to identify and assess key challenges to resolvability under the Bankruptcy Code (Title I plans). The Title I plans will help to focus firm efforts to mitigate those challenges so that bankruptcy may be a viable resolution strategy for large institutions.  These plans will also support development of the FDIC's backup resolution plans under OLA (Title II plans). \n\nThe resolution plan process is iterative by design. There is still much work to be done by firms, domestic and foreign regulators, and national governments. We remain committed to ensuring that this work is done quickly but responsibly in the coming years.\n\nThat brings us to the question of special resolution regimes. In October 2011, immediately before I was nominated to the Federal Reserve Board, I helped design a public simulation of the failure of a large financial institution under OLA. The cast included former senior government officials as well as leading experts from the private sector. The FDIC, the Federal Reserve, and the industry offered their assistance as we developed the simulation.\n\nFrom the outset, my earlier experience had led me to be skeptical about the possibility of resolving one of the largest financial companies without destabilizing the financial system. Today's global financial institutions are of staggering size and complexity. I believed that an attempt to resolve one of these firms--a firm with multiple business lines carried out through countless legal entities, across many jurisdictions and different legal systems--could easily spin out of control. The result could be greatly increased uncertainty for creditors and counterparties, which could trigger or accelerate a run on the failed institution that could quickly spread and destabilize the whole system.\n\nAs we developed the simulation, however, I came around to the view that it is possible to resolve a large, global financial institution. What changed my mind was the FDIC's innovative \"single-point-of-entry\" approach, which was just coming into focus in 2011. This approach is a classic simplifier, making theoretically possible something that seemed impossibly complex. \n\nUnder single point of entry, the FDIC will be appointed receiver of only the top-tier parent holding company of the failed financial group. Promptly after the parent holding company is placed into receivership, the FDIC will transfer the assets of the parent company (primarily its investments in subsidiaries) to a bridge holding company. Equity claims of the failed parent company's shareholders will be wiped out, and claims of its unsecured debt holders will be written down as necessary to reflect any losses in the receivership that the shareholders cannot cover. To capitalize the bridge holding company and the operating subsidiaries, and to permit transfer of ownership and control of the bridge company back to private hands, the FDIC will exchange the remaining claims of unsecured creditors of the parent for equity and/or debt claims of the bridge company. If necessary, the FDIC would provide temporary liquidity to the bridge company until the \"bail-in\" of the failed parent company's creditors can be accomplished.\n\nIt is crucial to recognize how this approach addresses the problem of runs. Single point of entry is designed to focus losses on the shareholders and long-term debt holders of the failed parent and to produce a well-capitalized bridge holding company in place of the failed parent. The critical operating subsidiaries would be well capitalized, and would remain open for business. There would be much reduced incentives for creditors or customers of the operating subsidiaries to pull away, or for regulators to ring-fence or take other extraordinary measures. If the process can be fully worked out and understood by market participants, regulators, and the general public, it should work to resolve even the biggest institution without starting or accelerating a run, and without exposing taxpayers to loss.\n\nSingle point of entry has important features in common with Chapter 11 bankruptcy reorganization. The principal differences in favor of OLA are the greater speed at which a firm can be placed into a resolution process and stabilized, the ability to avoid disruptive creditor actions, and the availability of temporary backup liquidity support to continue critical operations.\n\nSome have proposed changes to adapt the Bankruptcy Code to the purpose of handling the failure of a large financial institution--for example, to allow the government to provide debtor in possession (DIP) financing, or to allow a firm's primary regulator to initiate a bankruptcy filing.7   At a minimum, these proposals would further limit the need for OLA to the rarest of cases.\n\nAs the development of the single-point-of-entry approach continues, it is important to continue to reduce the uncertainties that creditors and other market participants would face in connection with their potential treatment in OLA. Questions remain about how the FDIC will apply its broad statutory discretion. For example: How will the FDIC exercise its discretion to dissimilarly treat creditors of the same class? How will a creditor's \"minimum right of recovery\" be determined? And how will the FDIC value the failed firm?  Stability demands that market participants have a reasonable degree of certainty about their treatment in OLA ex ante. This is an important concern. \n\nTo reduce uncertainty, the FDIC is working to provide market participants as much clarity as is feasible regarding its contemplated approach to the failure of a systemic U.S. firm. Regulators will always need to maintain some degree of flexibility to manage the evolving failure of a systemic financial firm. But greater clarity would increase the predictability of this new process, and thus reduce the likelihood that creditors, counterparties, and customers would pull away from even a well-capitalized institution in OLA. I strongly support these efforts to provide more clarity to market participants.\n\nTwo remaining challenges loom large: ensuring that all systemic financial firms have sufficient unsecured long-term debt at the parent level to recapitalize a bridge holding company in OLA; and mitigating cross-border impediments to resolution of a multinational financial firm.\n\nIn consultation with the FDIC, the Federal Reserve is considering the pros and cons of a regulatory requirement that systemic U.S. financial firms maintain a minimum amount of long-term unsecured debt. Such a requirement would help ensure that equity and long-term debt holders of a systemic firm can bear potential future losses at the firm and sufficiently capitalize a bridge holding company.  \n\nThe cross-border activities of large institutions present another set of challenges to an orderly resolution. OLA is limited in its applicability to U.S.-chartered entities. Subsidiaries and bank branches of a U.S.-based systemic firm chartered in other countries could be ring-fenced or wound down separately under the insolvency laws of those countries, if foreign authorities did not have full confidence that local interests would be protected. Certain OLA stabilization mechanisms, including the one-day stay provision with respect to over-the-counter derivatives and other qualified financial contracts, may not apply outside the United States. Accordingly, counterparties to qualified financial contracts with the foreign subsidiaries and branches of a U.S. firm may have contractual rights and substantial economic incentives to terminate their transactions as soon as the U.S. parent enters an OLA resolution. Today, regulators and the industry are focused on the potential for addressing this concern through modifications to contractual cross-default practices and other means. \n\nFurther progress on these cross-border challenges will require significant coordination among U.S. regulators and the key foreign central banks and supervisors for the largest financial firms. For example, the FDIC and the Bank of England are deeply engaged in this important work, as recently described in their joint paper applying the single-point-of-entry framework to the resolution of a globally active, U.S. - or U.K.-headquartered banking firm.8   The FDIC also has an active dialogue with the European Commission. These challenges will also require foreign jurisdictions to have national resolution regimes consistent with the Financial Stability Board's \"Key Attributes.\"9 \n\nAssessing Progress on Too Big to Fail\nIt seems to me that efforts by U.S. and global regulators to fight too big to fail are generally on the right track. The Basel III and Dodd-Frank reforms designed to reduce the probability of failure of large banking firms are sensible and, for the most part, targeted at the causes of the crisis. They are being implemented thoughtfully and effectively.  And I believe that those Financial Stability Board and Dodd-Frank reforms designed to permit the resolution of systemic firms without taxpayer exposure or undue disruption are very promising. That said, much of the work lies ahead.\n\nThe critics also deserve a fair hearing. \n\nCriticism of the current U.S. and global anti-too-big-to-fail policies generally takes one of two tacks. Some of the criticism argues that Dodd-Frank--particularly the OLA mechanism-- enshrines taxpayer bailouts. I do not believe that it does. OLA requires by its terms that the losses of any financial company placed into FDIC receivership be borne by the private sector stockholders and creditors of the firm. Single point of entry can work without exposing taxpayers to loss. \n\nAlthough the FDIC has authority to provide temporary liquidity to a failed firm, any costs incurred by the FDIC in resolving the firm must be recovered completely from either the assets of the firm or assessments on the financial industry. The failed firm's investors, and, if necessary, other large financial firms, will bear any costs. That is \"bail-in,\" not \"bailout.\"\n\n Another strand of criticism argues that reforms do not go far enough and calls for more activity limits on banking firms, for limiting their size or systemic footprint, or for simply breaking them up. \n\nActivity Limits\nSome have urged the resurrection of the 1930s-era Glass-Steagall prohibitions--that is, preventing the affiliation of commercial banks with investment banks. This proposal seems neither directly related to the causes of the financial crisis, nor likely to help end too big to fail. The systemic run that led to the financial crisis began with traditional investment banks, such as Bear Stearns and Lehman Brothers. The activities of these firms were, of course, not affected by the repeal of Glass-Steagall. Commercial banking firms now engage in activities traditionally associated with investment banking, such as securities underwriting. The combination of these activities under a single corporate umbrella did not contribute meaningfully to the financial crisis. In my view, losses at the commercial banks were more importantly a consequence of bad credit underwriting and the failure of risk management systems to keep up with innovation and the explosive growth in securitization--developments that were not fundamentally driven by the repeal of Glass-Steagall.\n\nSize Limits\nThere are also calls to further limit the size or systemic footprint of financial firms. Limits of this nature require, and deserve, careful analysis. \n\nTwo provisions of existing law already impose size caps on U.S. banking firms. One limits acquisitions of banks by any bank holding company that controls more than 10 percent of the total insured deposits in the United States, and a second, added by Dodd-Frank, forbids acquisitions by any financial firm that controls more than 10 percent of the total liabilities of financial firms in the United States. In addition, Dodd-Frank added a new requirement that banking regulators consider \"risk to the stability of the U.S. banking or financial system\" in evaluating any proposed merger or acquisition by a bank or bank holding company. Critics argue that these restrictions are inadequate and subject to exceptions that continue to allow even the largest firms to grow, both organically and through acquisitions.\n\nThe simplest forms of this idea would put a further absolute limit on the amount of balance sheet assets or liabilities, or on the risk-weighted assets of a financial firm. Capping the size or systemic footprint of each financial firm would limit the adverse systemic effects of the failure of any single firm. Smaller, simpler financial firms should be easier to manage and supervise in life, and easier to resolve in death. One option would be to impose a cap on a large U.S. banking firm's short-term non-deposit liabilities as a fraction of U.S. GDP. This form of proposal would allow such a firm to continue to increase assets and diversify its activities to achieve potentially available economies of scale and scope, so long as the firm finances expansion through more stable forms of funding.10 \n\nAny new size limits should be designed to limit systemic footprint while minimizing costs to efficiency.  This will be a challenging task. The question of whether the benefits of further size limits would exceed any losses in scale economies and other efficiencies is the subject of ongoing research and debate.11 \n\nBreak-up\nSome critics want to get right to the business of breaking up the big banks into smaller, more manageable, more easily resolvable pieces.12   At the heart of this proposal is the thought that no financial institution should be so large or complex that it cannot be allowed to fail, like any other private business, with losses to its equity holders and creditors, and consequences for senior management.  If the largest institutions were too big to fail during the financial crisis, why not make them smaller?\n\nToday, the market still appears to provide a subsidy, of changing and uncertain amount, to very large banks to account for the possibility of a government bailout in the event of failure.13   This subsidy, in the form of lower funding costs, may encourage \"too-bigness.\" There would be substantial externalities to a large bank failure as well. \n\nThe market needs to believe--and it needs to be the case--that every private financial institution can fail and be resolved under our laws without imposing undue costs on society. The current reform agenda is designed to accomplish just that, through two channels. First, it is intended to substantially reduce the likelihood of failure through a broad range of stronger regulation, including higher capital and liquidity standards, stress tests and recovery planning among other reforms. Second, it is intended to minimize the externalities from failure by making it possible to resolve a large financial institution without taxpayer exposure and without uncontainable disruption. If these reforms achieve their purpose, in my view they would be preferable to a government-imposed break-up, which would likely involve arbitrary judgments, efficiency losses, and a difficult transition. \n\nConclusion\nToday, few ideas can be less controversial than ending too big to fail. The question is \"How?\", and there are differing opinions on that. In Titles I and II of Dodd-Frank, Congress has given the regulators a game plan for ending too big to fail. The regulators, including the Federal Reserve, are forcefully implementing the plan we have been given.  \n\nMy own view is that the framework of current reforms is promising, and should be given time to work. In any case, too big to fail must end, even if more intrusive measures prove necessary in the end.\n\nThank you very much.\n\n \n\n1. The thoughts that follow are my own and do not necessarily reflect the views of my colleagues on the Board of Governors. I am grateful to Felton Booker, Barbara Bouchard, Michael Gibson, John Maggs, and Mark Van Der Weide for numerous helpful conversations and suggestions. Return to text\n\n2. Ranked by total assets at the time of failure, in 1991 Bank of New England Corp. ($21.7 billion) was the largest U.S. bank failure following Continental Illinois National Bank and Trust ($40 billion; 1984) and First Republic Bank ($32.5 billion; 1988). Return to text\n\n3. See Thomas E. Pulkkinen and Eric S. Rosengren (1993), \"Lessons from the Rhode Island Banking Crisis (PDF),\" Federal Reserve Bank of Boston, New England Economic Review, May/June. Return to text\n\n4. See FDIC (1997), \"Bank of New England Corp. (PDF),\" in Managing the Crisis: The FDIC and RTC Experience, Part II. Return to text\n\n5. Alice Schroeder (2008), The Snowball: Warren Buffett and the Business of Life (New York: Bantam Books). Return to text\n\n6. See Ben S. Bernanke (2012), \"Banks and Bank Lending: The State of Play,\" speech delivered at the 48th Annual Conference on Bank Structure and Competition, Chicago, Illinois (via satellite), May 10. Return to text\n\n7. See Kenneth E. Scott and John B. Taylor, eds. (2012), Bankruptcy Not Bailout: A Special Chapter 14 (Stanford, Calif.: Hoover Institution Press). Return to text\n\n8. Federal Deposit Insurance Corporation and the Bank of England (2012), \"Resolving Globally Active, Systemically Important, Financial Institutions (PDF)\" (December 10). Return to text\n\n9. The Key Attributes of Effective Resolution Regimes for Financial Institutions (PDF) (Key Attributes) were adopted by the Financial Stability Board in November 2011 as a new international standard that sets out the core elements of an effective special resolution regime for systemically significant financial firms. Return to text\n\n10. See Daniel K. Tarullo (2012), \"Industry Structure and Systemic Risk Regulation,\" speech delivered at the Brookings Institution Conference on Structuring the Financial Industry to Enhance Economic Growth and Stability, Washington, D.C., December 4. Return to text\n\n11. See Joseph P. Hughes and Loretta J. Mester (2011), \"Who Said Large Banks Don't Experience Scale Economies? Evidence from a Risk-Return-Driven Cost Function (PDF),\" Working Paper 11-27 (Philadelphia: Federal Reserve Bank of Philadelphia); Richard Davies and Belinda Tracey (2012), \"Too Big to be Efficient? The Impact of Implicit Funding Subsidies on Scale Economies in Banking (PDF),\" Bank of England, June; David C. Wheelock and Paul W. Wilson (2009), \"Do Large Banks have Lower Costs? New Estimates of Returns to Scale for U.S. Banks,\" Working Paper Series 2009-054E (St. Louis: Federal Reserve Bank of St. Louis, October); Andrew G. Haldane (2012), \"On Being the Right Size (PDF),\" speech delivered at the Institute of Economic Affairs' 22nd Annual Series, The Beesley Lectures, London, October 25 Return to text\n\n12. See Dean Baker (2010), \"Why We Must Break Up the Banks,\" The Guardian, April 7; and Bruno J. Navarro (2012), \"Neil Barofsky: Breaking Up Big Banks ‘Necessary' (http://www.cnbc.com/id/48328948/Neil_Barofsky_Breaking_Up_Big_Banks_lsquoNecessaryrsquo),\" CNBC, July 25 (accessed September 11, 2012). See also, Richard W. Fisher (2013), \"Ending ‘Too Big to Fail': A Proposal for Reform Before it's Too Late (With Reference to Patrick Henry, Complexity and Reality),\" speech delivered to the Committee for the Republic, Washington, D.C., January 16, which sets forth a proposal to limit banks to traditional commercial banking activities, restrict access to the Federal safety net to banks, and require affiliates of a bank to disclose to their customers that they are outside the Federal safety net. Return to text\n\n13. See Joseph Noss and Rhiannon Sowerbutts (2012), \"The Implicit Subsidy of Banks (PDF),\" Bank of England Financial Stability Paper No. 15. Return to text\n\n \n\n "
    },
    {
        "title": "Challenges Confronting Monetary Policy",
        "date": "March 04, 2013",
        "speaker": "Vice Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20130302a.htm",
        "content": "March 04, 2013\n\nVice Chair Janet L. Yellen\n\nAt the 2013 National Association for Business Economics Policy Conference, Washington, D.C.\n\nThank you. I'm delighted to address the National Association for Business Economics (NABE), a group that has done so much to promote understanding of the economy and the appropriate role of policy.\n\nMy topic today is the challenges confronting monetary policy in what has been an unusually weak recovery from a severe recession. I will discuss the Federal Reserve's ongoing efforts in these circumstances to speed the U.S. economy's return to maximum employment in a context of price stability.1 \n\nAs you know, the Federal Open Market Committee (FOMC) has recently taken new steps to achieve this objective. In September, the Committee approved a new program of agency-guaranteed mortgage-backed securities (MBS) purchases, pledging to continue the program--contingent on favorable ongoing evaluations of its efficacy and costs--until there has been a substantial improvement in the outlook for the labor market.2  Most recently, in December the Committee announced that it would purchase longer-term Treasury securities after completion of the maturity extension program. At the same time, it revamped its forward guidance for the federal funds rate, explicitly linking the path of that rate to quantitative measures of economic performance.3 \n\nMy goal today is to explain these policies and why I consider them appropriate under current conditions. With respect to the asset purchase program, I will discuss several economic indicators that I plan to consider in evaluating the outlook for the labor market and then offer my perspective at present on the program's efficacy and costs, an assessment I will continue updating in light of experience.\n\nThe Outlook for the Labor Market and Inflation\nThe Committee's recent actions are shaped by the fact that the labor market is still far from healed from the trauma of the Great Recession. Despite some welcome improvement, employment remains well below its pre-recession peak, reflecting an economy that is still operating far short of its potential. At 7.9 percent in January, the unemployment rate has declined from its recent peak of 10 percent in October 2009. But that's still higher than unemployment ever reached in the 24 years prior to the recent recession and well above the 5.2 to 6 percent that is the central tendency of FOMC participants' estimates of the longer-run normal rate of unemployment. With economic activity constrained by fiscal consolidation, the lingering effects from the financial crisis, and the added headwinds of Europe's recession and debt problems, most FOMC participants reported in December that they expected only a gradual decline in unemployment over the next two years, to about 7 percent by the end of 2014.4 \n\nThe official estimate of 12 million currently unemployed does not include 800,000 more discouraged workers who say they have given up looking for work.5  In addition, nearly 8 million people, or 5.6 percent of the workforce, say they are working part time even though they would prefer full-time jobs. A broader measure of underemployment that includes these and others who want a job stands at 14.4 percent, nearly double the 7.9 percent \"headline\" rate that is most commonly reported in the media.6 \n\nThe large shortfall of employment relative to its maximum level has imposed huge burdens on all too many American households and represents a substantial social cost. In addition, prolonged economic weakness could harm the economy's productive potential for years to come. The long-term unemployed can see their skills erode, making these workers less attractive to employers. If these jobless workers were to become less employable, the natural rate of unemployment might rise or, to the extent that they leave the labor force, we could see a persistently lower rate of labor force participation. In addition, the slow recovery has depressed the pace of capital accumulation, and it may also have hindered new business formation and innovation, developments that would have an adverse effect on structural productivity.\n\nIn contrast to the large gap between actual and maximum employment, inflation, apart from fluctuations due to energy and other commodity prices, has been running for some time now a little below the rate of 2 percent per year that the Committee judges to be consistent with the Federal Reserve's dual mandate. The Committee anticipates that inflation will continue to run at or below 2 percent over the medium term. Moreover, expectations for inflation over the next 5 to 10 years remain well anchored, according to surveys of households and professional forecasters.\n\nWith employment so far from its maximum level and with inflation running below the Committee's 2 percent objective, I believe it's appropriate for progress in the labor market to take center stage in the conduct of monetary policy. Let me therefore turn to the FOMC's recent actions and describe how I see them promoting this important goal.\n\nForward Guidance for the Federal Funds Rate\nI'll begin with the Committee's forward guidance for the federal funds rate. The FOMC has employed such forward guidance since 2003 but has relied more heavily on it since December 2008, when the target for the federal funds rate was reduced to its effective lower bound. In current circumstances, forward guidance can lower private-sector expectations regarding the future path of short-term rates, thereby reducing longer-term interest rates on a wide range of debt instruments and also raising asset prices, leading to more accommodative financial conditions. In addition, given the FOMC's stated intention to sell assets only after the federal funds rate target is increased, any outward shift in the expected date of liftoff for the federal funds rate suggests that the Federal Reserve will be holding a large stock of assets on its balance sheet longer, which should work to further increase accommodation.7 \n\nStarting in March 2009, the FOMC's postmeeting statements noted that \"economic conditions are likely to warrant exceptionally low levels of the federal funds rate for an extended period,\" and in November of the same year added \"low rates of resource utilization, subdued inflation trends, and stable inflation expectations\" as justification for this stance.\"8  In August 2011, the Committee substituted \"at least through mid-2013\" for the words \"for an extended period.\"9  This date was moved further into the future several times, most recently last September, when it was shifted to mid-2015.10 Also in September, the Committee changed the language related to that commitment, dropping the reference to \"low rates of resource utilization and a subdued outlook for inflation.\" Instead, it emphasized that \"a highly accommodative stance of monetary policy will remain appropriate for a considerable time after the economic recovery strengthens,\" clarifying the Committee's intention to continue to provide support well into the recovery.11 \n\nFinally, last December, the Committee recast its forward guidance for the federal funds rate by specifying a set of quantitative economic conditions that would warrant holding the federal funds rate at the effective lower bound. Specifically, the Committee anticipates that exceptionally low levels for the federal funds rate will be appropriate \"at least as long as the unemployment rate remains above 6-1/2 percent, inflation between one and two years ahead is projected to be no more than a half percentage point above the Committee's 2 percent longer-run goal, and longer-term inflation expectations continue to be well anchored.\"12 \n\nAn important objective of these changes in forward guidance is to enhance the public's understanding of the Committee's policy strategy and its \"reaction function\"--namely, how the FOMC anticipates varying its federal funds rate target in response to evolving economic developments. For example, the Committee's initial, calendar-based guidance did not clearly convey the rationale for the specified date. In particular, when the Committee extended the calendar date, the public was left to infer whether the change reflected a deterioration in the Committee's economic outlook or, instead, a decision to increase policy accommodation.\n\nIn my view, the language now incorporated into the statement affirmatively conveys the Committee's determination to keep monetary policy highly accommodative until well into the recovery. And the specific numbers that were selected as thresholds for a possible change in the federal funds rate target should confirm that the FOMC expects to hold that target lower for longer than would be typical during a normal economic recovery. This improved guidance should help the public to accurately adjust their expectations for the federal funds rate in response to new financial and economic information, which should make policy more effective.13  In addition, I hope that improved guidance will help to boost confidence in the outlook and bolster households' unusually depressed expectations for income gains, which in turn will spur a faster recovery.\n\nA considerable body of research suggests that, in normal times, the evolution of the federal funds rate target can be reasonably well described by some variant of the widely known Taylor rule.14  Rules of this type have been shown to work quite well as guidelines for policy under normal conditions, and they are familiar to market participants, helping them judge how short-term rates are likely to respond to changing economic conditions.\n\nThe current situation, however, is abnormal in two important and related ways. First, in the aftermath of the financial crisis, there has been an unusually large and persistent shortfall in aggregate demand. Second, use of the federal funds rate has been constrained by the effective lower bound so that monetary policy has been unable to provide as much accommodation as conventional policy rules suggest would be appropriate, given the weakness in aggregate demand. I've previously argued that, in such circumstances, optimal policy prescriptions for the federal funds rate's path diverge notably from those of standard rules.15  For example, David Reifschneider and John Williams have shown that when policy is constrained by the effective lower bound, policymakers can achieve superior economic outcomes by committing to keep the federal funds rate lower for longer than would be called for by the interest rate rules that serve as reasonably reliable guides for monetary policy in more normal times.16  Committing to keep the federal funds rate lower for longer helps bring down longer-term interest rates immediately and thereby helps compensate for the inability of policymakers to lower short-term rates as much as simple rules would call for.\n\nI view the Committee's current rate guidance as embodying exactly such a \"lower for longer\" commitment. In normal times, the FOMC would be expected to tighten monetary policy before unemployment fell as low as 6-1/2 percent. Under the new thresholds guidance, the public is informed that tightening is unlikely as long as unemployment remains above 6‑1/2 percent and inflation one to two years out is projected to be no more than a half percentage point above the FOMC's 2 percent longer-run goal.17 The evidence suggests that the evolution I've described in the Committee's forward guidance, particularly the new thresholds, has shifted the market's view of how forceful the FOMC intends to be in supporting the recovery. In the Federal Reserve Bank of New York's Survey of Primary Dealers, for example, participants have repeatedly revised downward the unemployment rate at which they anticipate that tightening will first occur.18 \n\nI mentioned that the FOMC's new forward guidance offers considerable insight into the Committee's likely reaction function, but I should note that the guidance it provides is not complete. For example, the Committee has not specified exactly how it intends to vary the federal funds rate after liftoff from the effective lower bound, although it has stated that \"when the Committee decides to begin to remove policy accommodation, it will take a balanced approach.\"19  This language is consistent with optimal policy prescriptions that call for lower-for-longer considerations to pertain to the path of the federal funds rate both before and after liftoff.\n\nIn addition, the guidance specifies thresholds for possible action, not triggers that will necessarily prompt an increase in the federal funds rate. The FOMC statement therefore notes that \"in determining how long to maintain a highly accommodative stance of monetary policy, the Committee will also consider other information, including additional measures of labor market conditions, indicators of inflation pressures and inflation expectations, and readings on financial developments.\"20 \n\nFor example, the Committee could decide to defer action even after the unemployment rate has declined below 6‑1/2 percent if inflation is running and expected to continue at a rate significantly below the Committee's 2 percent objective. Alternatively, the Committee might judge that the unemployment rate significantly understates the actual degree of labor market slack. A decline in the unemployment rate could, for example, primarily reflect the exit from the labor force of discouraged job seekers. That is an important reason why the Committee will consider a broad range of labor market indicators. I will discuss some of the additional indicators I plan to consider in judging the strength of the labor market in connection with the Committee's current asset purchase program.\n\nThe Federal Reserve's Asset Purchase Program\nTurning next to that program, the Federal Reserve initiated a new asset purchase program last September, extending it in December, under which the Federal Reserve is currently buying agency-guaranteed MBS at a pace of $40 billion per month and longer-term Treasury securities at a pace of $45 billion per month. As with the guidance for the federal funds rate, the Committee tied the new program to labor market conditions, stating that purchases would continue until there is a substantial improvement in the outlook for the labor market in a context of price stability.21 The FOMC's earlier large-scale asset purchase programs, in contrast, were fixed in size and carried out on a specified schedule. The Committee has also noted that, in determining the size, pace, and composition of its asset purchases, it would take appropriate account of the likely efficacy and costs of such purchases. \n\nThe purpose of the new asset purchase program is to foster a stronger economic recovery, or, put differently, to help the economy attain \"escape velocity.\" By lowering longer-term interest rates, these asset purchases are expected to spur spending, particularly on interest-sensitive purchases such as homes, cars, and other consumer durables. Research on the effects of such asset purchases suggests that what matters for the reaction of longer-term interest rates to a purchase program is the extent to which the program leads market participants to change their expectations concerning the entire path of the Federal Reserve's holdings of longer-term securities.22  Other things being equal, the greater the effect that a purchase program has on the expected path of the Federal Reserve's securities holdings, the more substantial should be the downward pressure on the term premium in longer-term interest rates.23  By linking the pace of purchases and how long that pace will be maintained to the outlook for the labor market, the program acts as a sort of automatic stabilizer: As market perceptions of the prospects for the economy vary, so too should expectations of the pace and duration of asset purchases.\n\nIn stating that asset purchases will continue, subject to caveats pertaining to efficacy and costs, until there has been a substantial improvement in the outlook for the labor market, the FOMC established a criterion that differs in three important respects from the forward guidance for the federal funds rate: (1) It is qualitative, not quantitative; (2) it refers to an improvement in the outlook for the labor market rather than an improvement in actual labor market conditions; and (3) it requires the Committee not only to consider progress toward its employment goal, but also to evaluate the efficacy and costs of asset purchases on an ongoing basis. The public is, naturally, eager to understand how the FOMC will approach such complex judgments. I cannot, of course, speak for the Committee on this issue, but I can spell out some of the key factors that will guide my conclusions.\n\nA \"Substantial Improvement in the Outlook for the Labor Market\"\nThe first imperative will be to judge what constitutes a substantial improvement in the outlook for the labor market. Federal Reserve research concludes that the unemployment rate is probably the best single indicator of current labor market conditions. In addition, it is a good predictor of future labor market developments. Since 1978, periods during which the unemployment rate declined 1/2 percentage point or more over two quarters were followed by further declines over the subsequent two quarters about 75 percent of the time.\n\nThat said, the unemployment rate also has its limitations. As I noted before, the unemployment rate may decline for reasons other than improved labor demand, such as when workers become discouraged and drop out of the labor force. In addition, while movements in the rate tend to be fairly persistent, recent history provides several cases in which the unemployment rate fell substantially and then stabilized at still-elevated levels. For example, between the fourth quarter of 2010 and the first quarter of 2011, the unemployment rate fell 1/2 percentage point but was then little changed over the next two quarters. Similarly, the unemployment rate fell 3/4 percentage point between the third quarter of 2011 and the first quarter of 2012, only to level off over the subsequent spring and summer.\n\nTo judge whether there has been a substantial improvement in the outlook for the labor market, I therefore expect to consider additional labor market indicators along with the overall outlook for economic growth. For example, the pace of payroll employment growth is highly correlated with a diverse set of labor market indicators, and a decline in unemployment is more likely to signal genuine improvement in the labor market when it is combined with a healthy pace of job gains.\n\nThe payroll employment data, however, also have shortcomings. In particular, they are subject to substantial revision. When the Labor Department released its annual benchmarking of the establishment survey data last month, it revised up its estimate of employment in December 2012 by 647,000.\n\nIn addition, I am likely to supplement the data on employment and unemployment with measures of gross job flows, such as job loss and hiring, which describe the underlying dynamics of the labor market. For instance, layoffs and discharges as a share of total employment have already returned to their pre-recession level, while the hiring rate remains depressed. Therefore, going forward, I would look for an increase in the rate of hiring. Similarly, a pickup in the quit rate, which also remains at a low level, would signal that workers perceive that their chances to be rehired are good--in other words, that labor demand has strengthened.\n\nI also intend to consider my forecast of the overall pace of spending and growth in the economy. A decline in unemployment, when it is not accompanied by sufficiently strong growth, may not indicate a substantial improvement in the labor market outlook. Similarly, a convincing pickup in growth that is expected to be sustained could prompt a determination that the outlook for the labor market had substantially improved even absent any substantial decline at that point in the unemployment rate.\n\nThe Efficacy of Asset Purchases\nLet me turn next to the efficacy and potential costs of asset purchases, a topic discussed at recent FOMC meetings and that I suspect will be discussed at succeeding meetings as well. I see the currently available evidence as suggesting that our asset purchases have been reasonably efficacious in stimulating spending. There is considerable evidence that these purchases have eased financial conditions, and so have presumably increased interest-sensitive spending.24  Research suggests that our purchases of mortgage-backed securities pushed down MBS yields and that MBS yields pass through, with a lag, to mortgage rates.25  Indeed, I see the recent strength in housing and consumer durables, such as motor vehicle purchases, as partly reflecting the effect of reduced borrowing costs. Plausible, albeit uncertain, estimates of the ultimate economic effect of asset purchases can be obtained from simulations of the Board's FRB/US model. Such simulations suggest that a hypothetical program involving $500 billion in longer-term asset purchases would serve to lower the unemployment rate by close to 1/4 percentage point within three years while keeping inflation close to the Committee's 2 percent objective.\n\nOne issue on which there has been considerable debate is whether low interest rates are doing as much to promote economic growth since the financial crisis as they would have before the financial crisis--whether the interest rate channel of transmission for monetary policy has been attenuated. I agree with those who think this channel has been partially blocked. Individuals who have impaired credit histories, have been unemployed, or hold underwater mortgages are experiencing great difficulty gaining access to credit, whether to buy or refinance a home, finance a small business, or support spending for other needs. Even those with good, but not stellar, credit histories and sufficient income are facing capacity constraints in the mortgage market. However, even if the interest rate channel is less powerful right now than it was before the crisis, asset purchases still work to support economic growth through other channels, including by boosting stock prices and house values. The resulting improvement in household wealth supports greater consumption spending.\n\nThe Costs of Asset Purchases\nTurning to the potential costs of the Federal Reserve's asset purchases, there are some that definitely need to be monitored over time. At this stage, I do not see any that would cause me to advocate a curtailment of our purchase program.\n\nTo address one concern that I have heard, there is no evidence that the Federal Reserve's purchases have impaired the functioning of financial markets, and, while we continue to monitor market function carefully, so long as we pursue our purchases sensibly, I do not expect market functioning to become a problem in the future. Further, I've argued previously, and still judge, that the FOMC has the tools it needs to withdraw accommodation, even if the balance sheet at that time is large. These tools include a new one, approved by the Congress during the financial crisis, which allows the Federal Reserve to pay banks interest on their reserves. A suite of supporting tools, such as reverse repurchase agreements with a wide range of counterparties and the Term Deposit Facility, are routinely tested to make sure that the Federal Reserve is prepared to use them and that they will work as planned.\n\nTwo additional costs have been discussed at recent meetings of the FOMC. First, the expansion of the balance sheet has implications for the Federal Reserve's earnings from its asset holdings and, hence, for its remittances to the Treasury. Second, some have raised the possibility that the Committee's policies could have negative consequences for financial stability.\n\nWith respect to the Federal Reserve's remittances, balance sheet operations are intended to support economic growth and job creation in a context of price stability and not to maximize Federal Reserve income. There is a possibility that the Federal Reserve's earnings from its assets and the remittances of those earnings to the Treasury will decline later in the decade, perhaps even ceasing entirely for some period. It is important to note, however, that any losses that could conceivably occur would not impair the Federal Reserve's conduct of monetary policy.26  Further, even if remittances to the Treasury ceased for a time, it is highly likely that average annual remittances over the period affected by our asset purchases will be higher than the pre-crisis norms.\n\nThough our expanded portfolio of longer-term securities has in recent years translated into substantial earnings and remittances to the Treasury, the Federal Reserve has, to be sure, increased its exposure to interest rate risk by lengthening the average maturity of its securities holdings. As the economic recovery strengthens and monetary policy normalizes, the Federal Reserve's net interest income will likely decline. In particular, the Federal Reserve's interest expenses will increase as short-term interest rates rise, while reserve balances initially remain sizable. In addition, policy normalization may well involve significant sales of the Federal Reserve's agency securities holdings, and losses could be incurred in these sales. A recent study by the Board staff considered the effect of a number of scenarios on Federal Reserve income, based on assumptions about the course of balance sheet normalization that are consistent with the exit strategy principles adopted at the June 2011 FOMC meeting.27 \n\nThe projections resulting from this exercise imply that Federal Reserve remittances to the Treasury will likely decline for a time. In some scenarios, they decline to zero. Once the Federal Reserve's portfolio is normalized, however, earnings are projected to return to their long‐run trend. The study supports the conclusion that the Federal Reserve's purchase programs will very likely prove to have been a net plus for cumulative income and remittances to the Treasury over the period from 2008 through 2025, by which time it is assumed that the balance sheet has been normalized.28 \n\nFocusing only on the ebb and flow of the Federal Reserve's remittances to the Treasury, however, is not, in my view, the appropriate way to evaluate the effect of these purchases on the government's finances. More germane is the overall effect of the program on federal finances. If the purchases provide even a modest boost to economic activity, increased tax payments would swamp any reduction in remittances. By depressing longer-term interest rates, the purchases also hold down the Treasury's debt service costs. These effects can be quantified through simulations of the Board's FRB/US model. In the simulation I described earlier, a hypothetical program involving $500 billion of asset purchases would reduce the ratio of federal debt to gross domestic product (GDP) by about 1.5 percentage points by late 2018. The lower debt-to-GDP ratio mainly reflects stronger tax revenue as a result of more-robust economic activity.\n\nFinally, let me comment on the possibility that our asset purchase program could threaten financial stability by promoting excessive risk-taking, a significant concern that I and my colleagues take very seriously. To put this concern in context, though, remember that during the most intense phase of the financial crisis, risk aversion surged. Even in the aftermath of the crisis, businesses, banks, and investors have been exceptionally cautious, presumably reflecting their concern about future business conditions, uncertainty about economic policy, and the perception of pronounced tail risks relating, for example, to stresses in global financial markets. I see one purpose of the Committee's accommodative policies as promoting a return to prudent risk-taking. Indeed, the return to more normal levels of risk-taking and the associated normalization of credit markets have been vital to recovery from the Great Recession.\n\nOf course, risk-taking can go too far, thereby threatening future economic performance, and a low interest rate environment has the potential to induce investors to take on too much leverage and reach too aggressively for yield. At this stage, there are some signs that investors are reaching for yield, but I do not now see pervasive evidence of trends such as rapid credit growth, a marked buildup in leverage, or significant asset bubbles that would clearly threaten financial stability.29  That said, such trends need to be carefully monitored and addressed, and the Federal Reserve has invested considerable resources to establish new surveillance programs to assess risks in the financial system. In the aftermath of the crisis, regulators here and around the world are also implementing a broad range of reforms to mitigate systemic risk.30  With respect to the large financial institutions that it supervises, the Federal Reserve is using a variety of supervisory tools to assess their exposure to, and proper management of, interest rate risk.\n\nTo the extent that investors are reaching for yield, I see the low interest rate environment and not the FOMC's asset purchases, per se, as a contributing factor. It is true that asset purchases put downward pressure on the term premium component of longer-term rates, and that discontinuing purchases would likely cause term premiums to rise. But ending asset purchases before observing a substantial improvement in the labor market might also create expectations that the amount of accommodation provided would not be sufficient to sustain the improvement in the economy. This weakening in the economic outlook might bring down the expected path of the federal funds rate, with the result that longer-term interest rates might not rise appreciably, on net. Moreover, a weakening of the economic environment could also create significant financial stability risks. That said, financial stability concerns, to my mind, are the most important potential cost associated with the current stance of monetary policy.\n\nConclusion\nIn these remarks, I have reviewed recent FOMC policy actions--actions I have supported because I believe they will help foster a stronger recovery and keep inflation close to the Committee's longer-run target. I recognize that the Federal Reserve's highly accommodative policy entails some costs and risks. It will be important both to monitor them and to continue strengthening our financial system.\n\nHowever, insufficiently forceful action to achieve our dual mandate also entails costs and risks. There is the high cost that unemployed workers and their families are paying in this disappointingly slow recovery. There is the risk of longer-term damage to the labor market and the economy's productive capacity. At present, I view the balance of risks as still calling for a highly accommodative monetary policy to support a stronger recovery and more-rapid growth in employment.\n\nThank you for inviting me to speak to you today at NABE's spring conference.\n \n\nReferences\nBoard of Governors of the Federal Reserve System (2009a). \"FOMC Statement,\" press release, March 18.\n\n------ (2009b). \"FOMC Statement,\" press release, November 4.\n\n------ (2011a). \"FOMC Statement,\" press release, August 9.\n\n------ (2011b). \"Minutes of the Federal Open Market Committee, June 21-22, 2011,\" press release, July 12.\n\n------ (2012a). \"Federal Reserve Issues FOMC Statement,\" press release, September 13.\n\n------ (2012b). \"Federal Reserve Issues FOMC Statement,\" press release, December 12.\n\n------ (2013). \"Minutes of the Federal Open Market Committee, December 11-12, 2012,\" press release, January 3.\n\nBureau of Labor Statistics (2013), \"Employment Situation--January 2013 (PDF),\" press release, February 1.\n\nCarpenter, Seth B., Jane E. Ihrig, Elizabeth C. Klee, Daniel W. Quinn, and Alexander H. Boote (2013). \"The Federal Reserve's Balance Sheet and Earnings: A Primer and Projections,\" Finance and Economics Discussion Series 2013-01. Washington: Board of Governors, January.\n\nClarida, Richard, Jordi Galí, and Mark Gertler (2000). \"Monetary Policy Rules and Macroeconomic Stability: Evidence and Some Theory,\" Quarterly Journal of Economics, vol. 115 (February), pp. 147-80.\n\nD'Amico, Stefania, William English, David López-Salido, and Edward Nelson (2012). \"The Federal Reserve's Large-Scale Asset Purchase Programmes: Rationale and Effects,\" Economic Journal, vol. 122 (November), pp. F415-F446.\n\nD'Amico, Stefania, and Thomas B. King (forthcoming). \"Flow and Stock Effects of Large-Scale Treasury Purchases: Evidence on the Importance of Local Supply,\" Journal of Financial Economics.\n\nGagnon, Joseph, Mathew Raskin, Julie Remache, and Brian Sack (2011). \"The Financial Market Effects of the Federal Reserve's Large-Scale Asset Purchases,\" International Journal of Central Banking, vol. 7 (March), pp. 3-43.\n\nHamilton, James D., and Jing Cynthia Wu (2012). \"The Effectiveness of Alternative Monetary Policy Tools in a Zero Lower Bound Environment,\" Journal of Money, Credit and Banking, vol. 44 (February supplement), pp. 3-46.\n\nHancock, Diana, and Wayne Passmore (2012). \"The Federal Reserve's Portfolio and its Effects on Mortgage Markets,\" Finance and Economics Discussion Series 2012-22. Washington: Board of Governors of the Federal Reserve System, June.\n\nJoyce, Michael A.S., Ana Lasaosa, Ibrahim Stevens, and Matthew Tong (2011). \"The Financial Market Impact of Quantitative Easing in the United Kingdom,\" International Journal of Central Banking, vol. 7 (September), pp. 113-61.\n\nKrishnamurthy, Arvind, and Annette Vissing-Jørgensen (2011). \"The Effects of Quantitative Easing on Interest Rates: Channels and Implications for Policy,\" Brookings Papers on Economic Activity, Fall, pp. 215-65.\n\nReifschneider, David, and John C. Williams (2000). \"Three Lessons for Monetary Policy in a Low-Inflation Era,\" Journal of Money, Credit and Banking, vol. 32 (November, part 2), pp. 936-66.\n\nRudebusch, Glenn D. (2006). \"Monetary Policy Inertia: Fact or Fiction?\" International Journal of Central Banking, vol. 2 (December), pp. 85-135.\n\nStein, Jeremy C. (2013). \"Overheating in Credit Markets: Origins, Measurement, and Policy Responses,\" speech delivered at \"Restoring Household Financial Stability after the Great Recession: Why Household Balance Sheets Matter,\" a symposium sponsored by the Federal Reserve Bank of St. Louis, St. Louis, February 5-7.\n\nSwanson, Eric T. (2011). \"Let's Twist Again: A High-Frequency Event-Study Analysis of Operation Twist and Its Implications for QE2,\" Brookings Papers on Economic Activity, Spring, pp. 151-88.\n\nSwanson, Eric T., and John C. Williams (2013). \"Measuring the Effect of\nthe Zero Lower Bound on Medium- and Longer-Term Interest Rates (PDF),\" Working Papers Series 2012-02. San Francisco: Federal Reserve Bank of San Francisco, January.\n\nTarullo, Daniel K. (2012). \"Financial Stability Regulation,\" speech delivered at the Distinguished Jurist Lecture, University of Pennsylvania Law School, Philadelphia, October 10.\n\nWoodford, Michael (2012). \"Methods of Policy Accommodation at the Interest-Rate Lower Bound (PDF) ,\" paper presented at \"The Changing Policy Landscape,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 31-September 1.\n\nYellen, Janet L. (2012a). \"Perspectives on Monetary Policy,\" speech delivered at the Boston Economic Club Dinner, Boston, June 6.\n\n------ (2012b). \"Revolution and Evolution in Central Bank Communications,\" speech delivered at the Haas School of Business, University of California, Berkeley, Berkeley, Calif., November 13.\n\n------ (2013). \"A Painfully Slow Recovery for America's Workers: Causes, Implications, and the Federal Reserve's Response,\" speech delivered at \"A Trans-Atlantic Agenda for Shared Prosperity,\" a conference sponsored by the AFL-CIO, Friedrich Ebert Stiftung, and the IMK Macroeconomic Policy Institute, held in Washington, February 11.\n \n\n1. The views expressed here are my own and not necessarily those of my colleagues in the Federal Reserve System. I am indebted to members of the Board staff--Stephanie Aaronson, Thomas Laubach, John Maggs, Edward Nelson, Devin Saiki, and William Wascher--who contributed to the preparation of these remarks. Return to text\n\n2. See Board of Governors (2012a). Return to text\n\n3. See Board of Governors (2012b). Return to text\n\n4. In the December 2012 Summary of Economic Projections (SEP), the central tendency of FOMC participants' projections for the unemployment rate in the final quarter of 2013 and 2014 was 7.4 to 7.7 percent and 6.8 to 7.3 percent, respectively. The central tendency omits the three lowest and three highest projections. The SEP is an addendum to the FOMC minutes and is available at Board of Governors (2013). Return to text\n\n5. The most widely reported estimate of those in the labor force who are unemployed--12.3 million in January, rounded to 12 million, from the Bureau of Labor Statistics (BLS)--is seasonally adjusted. (Without seasonal adjustment, the actual estimate of unemployed in January was 13.2 million.) The BLS does not seasonally adjust its estimate of discouraged workers who have left the labor force, an estimate that was 804,000 in January. For more on the employment situation in January, see Bureau of Labor Statistics (2013). Return to text\n\n6. In my view, and as I've argued elsewhere (Yellen, 2013), the evidence indicates that elevated unemployment and the disappointingly slow improvement in the labor market are primarily the result of weak aggregate demand and not an increase in structural unemployment. Return to text\n\n7. Empirical studies of the Committee's date-based forward guidance suggest that changes in that guidance generated an appreciable effect on longer-term yields. See, for example, Swanson and Williams (2012) and Woodford (2012). Return to text\n\n8. See Board of Governors (2009a, 2009b). Return to text\n\n9. See Board of Governors (2011a). Return to text\n\n10. See Board of Governors (2012a). Return to text\n\n11. See Board of Governors (2012a). Return to text\n\n12. See Board of Governors (2012b). Return to text\n\n13. The new guidance should serve as an automatic stabilizer in the face of shifts in the outlook. For example, weaker economic data, suggesting that the thresholds will be reached later than previously anticipated, should lead market participants to push out the expected timing of liftoff, automatically promoting lower longer-term rates and an easing of financial conditions. See, for example, Yellen (2012b). Return to text\n\n14. See, for example, Clarida, Galí, and Gertler (2000) and Rudebusch (2006). Return to text\n\n15. See, for example, Yellen (2012a, 2012b). Return to text\n\n16. See Reifschneider and Williams (2000). Return to text\n\n17. Setting the threshold above the unemployment rate's longer-run normal level recognizes the fact that monetary policy affects real activity and inflation with a lag so that, assuming inflation is near the Committee's long-run target, it will likely be necessary to begin the process of removing accommodation before the longer-run normal rate is reached. Return to text\n\n18. The Survey of Primary Dealers is available on the Federal Reserve Bank of New York's website. Return to text\n\n19. See Board of Governors (2012b). Return to text\n\n20. See Board of Governors (2012b). Return to text\n\n21. The Committee also indicated that it expects the asset purchase program to end well before the target for the federal funds rate is raised. Return to text\n\n22. See Gagnon and others (2011). Return to text\n\n23. Typically, investors demand a higher return as a condition for putting their funds into a longer-term security instead of investing in a series of short-term securities. The difference in expected returns on these two alternative investments is called a term premium. Return to text\n\n24. Empirical studies have drawn on the experience of the Federal Reserve's large-scale asset purchases in recent years, as well as from earlier episodes in the United States and from the experience with asset purchases in the United Kingdom. See, for example, D'Amico and King (forthcoming), D'Amico and others (2012), Gagnon and others (2011), Hamilton and Wu (2012), Joyce and others (2011), Krishnamurthy and Vissing-Jørgensen (2011), and Swanson (2011). Return to text\n\n25. See Hancock and Passmore (2012). Return to text\n\n26. See Carpenter and others (2013). Return to text\n\n27. See Carpenter and others (2013) for the Board study; the exit strategy principles are in Board of Governors (2011b). Return to text\n\n28. The extent of realized capital losses on sales of Federal Reserve assets depends on the precise securities sales policy that the Committee eventually decides to undertake. An increase in longer-term interest rates would lower the market value of the securities in the System Open Market Account (SOMA) portfolio. But the Federal Reserve would continue to receive interest income on those securities for as long as they remained in the SOMA portfolio, and securities held to maturity could roll off the portfolio without the Federal Reserve realizing losses on them. While the authors of the Board staff study used particular assumptions about future securities sales that are consistent with the exit strategy principles outlined by the Committee in June 2011, other strategies for sales that are equally consistent might lead to different results. Return to text\n\n29. In a recent speech, Governor Jeremy Stein (2013) discussed several areas in which a noticeable increase in risk-taking behavior has emerged. Return to text\n\n30. See, for example, a speech on financial stability regulation by Governor Daniel Tarullo (2012). Return to text"
    },
    {
        "title": "Comments on Housing and Mortgage Markets",
        "date": "March 08, 2013",
        "speaker": "Governor Elizabeth A. Duke",
        "url": "https://www.federalreserve.gov/newsevents/speech/duke20130308a.htm",
        "content": "March 08, 2013\n\nGovernor Elizabeth A. Duke\n\nAt the Mortgage Bankers Association Mid-Winter Housing Finance Conference, Avon, Colorado\n\nSince joining the Board in 2008 amid a crisis centered on mortgage lending, I have focused much of my attention on housing and mortgage markets, issues surrounding foreclosures, and neighborhood stabilization. Today I am pleased to provide some comments about the outlook for housing and mortgages. Before I proceed, I should note that the views I express are my own and not necessarily those of my colleagues on the Board of Governors or the Federal Open Market Committee (FOMC).\n\nI think the evidence is pretty clear that a recovery in the housing market is finally under way. National house prices have increased for 13 consecutive months and are now 10 percent higher than at their trough in December 2011.1   Construction activity has also picked up. Housing starts and permits are still far below their peaks but have risen by about one-third over the past year, and homebuilder sentiment has improved notably.2   New and existing home sales have increased. In national surveys, households report that low interest rates and house prices make it a good time to buy a home; they also appear more certain that house price gains will continue.3   And real estate agents report stronger traffic of people shopping for homes.4 \n\nThe open question is whether this positive trend is sustainable. When I look at the factors driving recent improvement and those that have inhibited housing recovery through the downturn, I conclude that recent gains in the housing market will continue and perhaps even strengthen. My main hesitation with this forecast is that mortgage credit conditions remain quite tight for many would-be borrowers, and I suspect that the easing of these conditions will be a slow and gradual process. In particular, I expect demand to come from a pickup in new household formation, but I also recognize that these households may be the very population that faces especially tight credit conditions. I will return to the subject of mortgage credit later in my talk.\n\nHousing Market Overview and Outlook\nLast year's house price gains were achieved in an environment largely defined by historically unusual factors: a large number of underwater homeowners, which have effectively reduced the supply of properties for sale; the fact that foreclosed properties continue to represent an outsized, although gradually decreasing, share of sales transactions; and strong demand on the part of investors. \n\nTurning first to underwater homeowners, although the actual number of these homeowners is unknown--plausible estimates range fairly broadly from 7 million to 14 million--it seems clear that some are unable or unwilling to sell their homes because they lack the funds to carry out the transactions or are reluctant to realize losses. As a result, some potential sellers have not responded to the signs of housing market recovery by putting their properties on the market. The number of single-family homes for sale has fallen to its lowest level in a decade, which has likely contributed to the recent house price gains. Indeed, cities that started 2012 with an outsized share of underwater homeowners have seen some of the largest price increases.\n\nNext, sales of properties from lenders' real estate owned (REO) inventories represented 14 percent of sales transactions in 2012, down from 21 percent in 2010.5   These sales have damped house prices by increasing the supply of homes for sale and, in some areas, by reducing the desirability of a neighborhood as a place to live.6   This effect may be diminishing, as the foreclosure inventory has gradually started to decline. The decline in REO sales has been partly offset by an increase in short sales, but these properties tend to transact at smaller discounts than REO properties.7 \n\nFinally, investors have been attracted to the housing market because of the low prices on REO properties. The properties tend to sell at lower prices because some are damaged and because lenders may be more motivated sellers than the typical homeowner. The combination of a low purchase price, a possible steady stream of rental income, and the potential for significant capital gains has attracted considerable interest from large institutional investors as well as from the mom-and-pop investors who have historically dominated this market. This increase in investor demand has supported house prices so far and may continue to provide a floor for them.\n\nWhat role will these forces play going forward? I think house prices will continue to rise, as the supply of existing homes on the market will remain quite tight. I do not believe that a flood of houses on the market from households that are currently underwater or from bank REO is likely to materialize or to be sufficient to outpace growing demand.\n\nAs house price gains continue, more underwater homeowners will regain a position of positive equity in their homes. House price increases of 10 percent or less would be sufficient for about 40 percent of underwater homeowners to regain positive equity; presumably, some subset of those homeowners will be interested in selling their homes. If the majority of newly above-water sellers exit homeownership, they could create a substantial increase in overall supply and change the trajectory of house prices. But I think it is much more likely that many of them will also purchase a home in the same market, perhaps moving up to a larger home or downsizing to a smaller one. In that case, they would create additional demand as well as supply. And, in any event, the sales would provide more clarity about the level of house prices and increase liquidity in these markets. \n\nThe weight of the shadow inventory--homes in the process of foreclosure or loans 90 days or more past due--on home prices is likely to wane as the number of loans entering the foreclosure pipeline declines and those already in the pipeline resolve. I think the nature and duration of the effect on prices will vary across the country, depending on the location of the shadow inventory and the speed of its resolution. Some evidence of this relationship can be found by comparing the relative performance of house prices in states where foreclosures are processed through the court system (judicial states) with performance in states where foreclosures do not go through the courts (nonjudicial states).\n\nThrough mid-2012, house prices fell further in nonjudicial states than in judicial states, likely in part because the faster nonjudicial foreclosure process boosted the for-sale inventory in those states. Since that time, though, prices have moved back up in nonjudicial states, as the inventory was worked down while prices drifted lower in judicial states as inventory accumulated. Over time, the shadow inventory is becoming more concentrated in states with the slower judicial foreclosure processes and will likely continue to damp house prices in those states. Nonetheless, the specific dynamics going forward will depend on the pace at which these properties are put on the market for sale.\n\nInvestor activity is difficult to predict. As house prices rise, some investors may no longer find purchasing homes to be a profitable enterprise. Other investors may want to lock in their gains and sell properties. The prospect of steady rental income and possible further capital gains, though, will likely continue to be attractive to many investors. In addition, I suspect that the development of large-scale rental of single-family homes as an asset class has gained enough traction with investors to continue in some form.\n\nFor the housing recovery to gain true momentum, however, demand for housing among owner-occupiers must increase. As I noted earlier, household sentiment toward homebuying, as measured by households' assessments of purchasing conditions and by homebuyer traffic, appears to be on an upswing and should gradually strengthen demand. But I expect the strongest impetus to recovery to come from pent-up demand for housing in the form of household formation. Between 2006 and 2011, roughly 550,000 new households formed per year, on net, significantly fewer than the 1.35 million per year over the previous five years. Indeed, household formation from 2006 to 2011 appears to have been far lower than in any other five-year period since at least the mid-1960s.8 \n\nFederal Reserve staff research indicates that this decline in household formation largely reflects the weak labor market, especially among younger adults. If you have an adult son or daughter still living at home because he or she can't find a job, it might not surprise you to know that the number of individuals aged 18 to 30 living with older family members increased between 2006 and 2010 by over 1 million more than would be expected by the demographic trend.9   In this downturn, the unemployment rate among younger adults rose by more than among the population as a whole. And when they are unemployed or have low incomes, younger individuals are particularly likely to live with their parents or older family members rather than moving out on their own. \n\nAs the unemployment rate continues to decline--albeit likely at a slower pace than any of us would like--household formation and housing demand should increase. One model suggests that household formation could increase to 1-1/2 million or more per year. If, as seems likely, however, many of these new households rent rather than buy their homes, the effect on rental housing could be stronger than for owner-occupied homes, and applications for mortgages to purchase homes might recover only slowly.\n\nEvidence to date of an increase in home purchases by owner-occupiers--as opposed to investors--is scarce. The most discouraging evidence comes from purchase mortgage originations. Data collected under the Home Mortgage Disclosure Act (HMDA) indicate that in 2011, purchase mortgage originations hit their lowest level since the early 1990s. According to Federal Reserve staff estimates, purchase originations remained near these subdued levels in 2012 even as mortgage rates hit historic lows.\n\nThe drop in purchase mortgage originations, although widespread, has been most pronounced among borrowers with low credit scores. For example, between 2007 and 2012, purchase originations fell by about 30 percent for borrowers with credit scores above 780, compared with a fall of about 90 percent for borrowers with credit scores between 620 and 680. Originations are virtually nonexistent for borrowers with credit scores below 620.\n\nWhether this pattern stems from tight supply or from weak demand among borrowers with lower credit scores, it has disturbing implications for potential new households. Younger individuals--who have seen the greatest drop in household formation--have, on average, credit scores that are more than 50 points lower than those of older individuals, a difference that existed even before the recession. \n\nStaff analysis comparing first-time homebuying in recent years with historical levels underscores the contraction in credit supply. From late 2009 to late 2011, the fraction of individuals under 40 years of age getting a mortgage for the first time was about half of what it was in the early 2000s.10   The drop was especially pronounced for individuals with low credit scores and remained large even after controlling for local unemployment rates and for measures of the individual's demand for credit--a result indicating that tight credit supply is an important factor.\n\nAs I noted earlier, household formation has been particularly weak among young individuals, who are also a large part of the potential first-time homebuyer population. Many of these young individuals have relatively weak credit records and are more likely to have had a recent spell of unemployment. Our staff analysis highlights how tight credit conditions are for such individuals in the current environment. In the early 2000s, about one-third of first-time homebuyers under the age of 40 had credit scores below 620, and another one-fourth had scores between 620 and 680. Today, many of these individuals would have a difficult time obtaining mortgage credit.\n\nWhy Is Mortgage Credit So Tight?\nWhy are conditions still so tight for these potential first-time homebuyers, and when might they return to normal? As I'll discuss next, the mortgage market is reacting to a variety of economic, market, and regulatory issues that may not be present in other lending markets. So it's difficult to predict what a \"normal\" mortgage market will look like when things settle down. After the crisis we have just experienced, I am pretty sure that we don't want the market to return to the lending environment of the pre-crisis boom times. But I also don't think it would be a good idea to go back to the quite restrictive credit conditions of the early 1980s. \n\nPart of the tightening in mortgage credit standards is the result of lender fears about the economy and the trajectory of house prices. Of respondents who reported tightening mortgage lending standards in the April 2012 Senior Loan Officer Opinion Survey on Bank Lending Practices, more than 80 percent identified concerns about the economy or house prices as a factor in their decision. As the economic recovery continues, lenders should gain confidence that mortgage loans will perform well, and they should expand their lending accordingly.\n\nCredit for potential home purchasers with lower credit scores--in particular, the first-time homebuyers I discussed earlier--has likely also been affected by capacity constraints of mortgage lenders. As most of you know very well, the mortgage industry has been operating near its capacity. Although purchase originations have been subdued, refinancing originations, according to staff estimates, have responded to record-low interest rates by more than doubling from mid-2011 to the end of 2012. \n\nThe ratio of refinance applications to the number of real estate credit employees--a measure of capacity constraints--has been at levels near those seen during the record 2003 refinancing boom. And, at the same time, each loan takes longer to process, as all elements of an application are now fully documented. Capacity may be slow to expand, as hiring and training additional staff takes time and some lenders may judge the boom as likely to be too short lived to justify the cost. Indeed, the number of real estate credit employees, as measured by the Bureau of Labor and Statistics, has only edged up over the past year.\n\nWhen capacity constraints are binding, lenders may manage the surge in refinancing demand by holding mortgage rates high relative to lenders' funding costs. That would explain the pattern observed during refinance booms, such as the one in 2003, when mortgage rates fell more slowly than yields on mortgage-backed securities (MBS). Also, when MBS yields drop sharply, as occurred in September 2012 when the Federal Reserve announced its most recent MBS purchase program, the mortgage rate may take time to adjust as a result of both capacity issues and the need to process loans with rate locks in place.\n\nFurthermore, when refinancing demand is high, lenders have less incentive to pursue harder-to-complete or less profitable loan applications. In the current environment, refinance applications by high-credit-quality borrowers--many of whom may have refinanced repeatedly as rates have fallen over the past couple of years--are likely the easiest to complete. And refinances under the revised Home Affordable Refinance Program, require substantially less documentation than other loans. It is possible that the abundance of these applications may have had the unintended effect of crowding out borrowers with lower credit scores, whose applications may be more time consuming to process. Indeed, staff research suggests that the increase in the refinance workload during the past 18 months appears to be associated with a 50 percent decrease in purchase originations among borrowers with credit scores between 620 and 680 and a 15 percent decrease among borrowers with credit scores between 680 and 720. Purchase originations among borrowers with higher credit scores appear to be affected to only a small degree.\n\nAny crowding-out effect that does exist due to capacity constraints should start to unwind if mortgage rates stay at the current levels or rise, in which case the current refinancing boom will begin to run out of steam. Lenders might then ease credit conditions to fill declining refinance pipelines with additional purchase volume. At the same time, as lenders gain more confidence in the strength of the economic recovery and the upswing in house prices, their outlook for home-purchase originations may brighten, making them more confident in easing standards or increasing capacity. Even so, there are still a number of nonmarket forces at work that could make lenders more cautious than normal. \n\nFor example, lenders remain concerned about the risk that they will be required to repurchase defaulted loans from the government-sponsored enterprises (GSEs)--the so-called putback risk. The ability to hold lenders accountable for poorly underwritten loans is a significant protection for taxpayers. However, if lenders are unsure about the conditions under which they will be required to repurchase loans sold to the GSEs, they may shy away from originating loans to borrowers whose risk profiles indicate a higher likelihood of default. The Federal Housing Finance Agency launched an important initiative last year to clarify the liabilities associated with representations and warranties, but so far, those efforts do not appear to have been sufficient to keep putback risk from weighing on the mortgage market.\n\nMortgage servicing standards, particularly for delinquent loans, are more stringent than in the past due to settlement actions and consent orders. Servicing rules recently released by the Consumer Financial Protection Bureau (CFPB) will extend many of these standards to all lenders. These standards remedy past abuses and provide important protections to borrowers, but they also increase the cost of servicing nonperforming loans. Under current servicing compensation arrangements, servicers receive the same monthly servicing fee for the routine processing of current loans as they do for the more expensive processing of defaulted loans, a model that assumes that the higher profits on routine processing will offset the cost of servicing delinquent loans. However, this compensation model, coupled with higher default servicing costs, may instead make lenders less willing to extend credit to lower-credit-quality borrowers, who are more likely to default. A change to servicer compensation models, especially for default servicing, could alleviate some of the concern about making these loans, albeit at higher costs to some borrowers.\n\nAnother key factor contributing to mortgage lender caution is uncertainty about the ultimate regulatory environment. Regulatory decisions will work individually and collectively to shape the cost and availability of mortgage credit in the future. So it is important for policymakers to think carefully about their individual decisions as well as how those decisions will work within the full constellation of mortgage regulation. Regulatory changes are being implemented to ensure that borrowers have more protections and lenders take into account the costs that imprudent mortgage lending can impose on communities, the financial system, and the economy. The accompanying effect, however, may be tighter credit standards, especially for lower-credit-quality borrowers, than prevailed during most of the past decade. It will be up to policymakers to find the right balance between consumer safety and financial stability, on the one hand, and availability and cost of credit, on the other.\n\nThe CFPB took an important step toward resolving regulatory uncertainty when it released a host of rules in January, including rules on ability-to-repay requirements, the definition of a qualified mortgage (QM), loan officer compensation, and servicing standards.\n\nThe Federal Reserve and other agencies are in the process of moving forward on proposed rulemakings that would implement revised regulatory capital requirements and the requirements for risk retention mandated by the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010, which include an exemption for mortgages that meet the definition of qualified residential mortgages (QRMs). These and other prudential rules, taken together with the CFPB rules, will further shape the economics of mortgage lending. For example, bank capital rules will specify the amount of capital a bank must hold against certain mortgages. The risk retention rule will specify which loans in the QM universe qualify as QRM loans and therefore are not subject to risk retention when securitized. The risk retention rules will also define how securitizers must meet the risk retention requirement for mortgages that are not QRMs, and the cost associated with this requirement may affect mortgage costs. I won't comment today on the rulemakings that are still under way. However, I believe that, as we layer on additional requirements, it is important to think about the implications of the rules that have already been finalized. So I would like to share my assessment of some potential implications of the QM rule.\n\nTo provide a little context, the QM rule is part of a larger ability-to-repay rulemaking that requires lenders to make a reasonable and good faith determination that the borrower can repay the loan. Many of the rules' requirements for verification of income, assets, and other payment obligations are probably standard practice for lenders today. But having the rules in place, reinforced with increased legal risk for lenders that do not meet the rules' requirements, helps ensure that these practices continue, even as the economy improves and competition heats up. Borrowers who cannot afford their loans can sue the lender for violations of the ability-to-repay rules and claim monetary damages. If the original lender sells or securitizes the loan, the borrower can claim these damages at any time in a foreclosure action taken by the lender or any assignee. If the mortgage meets the QM standard, however, the lender receives some degree of protection from such potential lawsuits because it is presumed that the borrower had the ability to repay the loan.\n\nLoans outside the QM box may become more costly for lenders and borrowers for at least three reasons. The first reason is the possible increase in foreclosure losses and litigation costs. Although the expected losses from this litigation are likely to be small, the full extent of the costs and of lenders' legal liability will become known only after the initial round of ability-to-repay suits are settled by the courts. The second reason is that mortgages that do not meet the QM definition also, by definition, will not meet the future QRM standard, and so lenders will be required to retain some of the risk if these loans are securitized. This requirement may increase costs and limit the size of the market. The third reason is that investors may be wary of investing in securities collateralized by non-QM loans because it is difficult to gauge the risks. A borrower's ability to repay a loan that is not a QM may be based on \"soft\" information or on idiosyncratic factors that are difficult for the investor to observe or monitor. Investors may respond to this information asymmetry by requiring a higher risk premium or by refusing to purchase these securities altogether. For all of these reasons, the non-QM market could become small and illiquid, which would further increase the cost of these loans.\n\nLoans eligible to be purchased, insured, or guaranteed by Fannie Mae, Freddie Mac, the Federal Housing Administration (FHA), the U.S. Department of Veterans Affairs, or the U.S. Department of Agriculture are automatically designated as QMs. This provision is slated to end no later than January 2021. As long as such loans remain an outsized share of mortgage originations, the QM rule may have less of an effect on the availability of mortgage credit.\n\nAs more private capital returns to the mortgage market, though, two aspects of the QM rule will have a more significant effect on access to credit: the debt-to-income (DTI) requirement and the provisions that affect interest rates, points, and fees. Turning first to DTI, under the QM definition, borrower payments on all debts and some recurring obligations--such as mortgages, credit card debt, student loans, auto loans, alimony, and child support--must be 43 percent or less of borrower income. To gauge the possible number of borrowers affected by this requirement, the Board staff looked at households in the Survey of Consumer Finances that purchased a home with mortgage credit in the two years preceding the survey. In the 2001, 2004, and 2010 waves of the survey, about 15 to 20 percent of these households had payments that exceeded 43 percent of income, although the share spiked to 40 percent in the 2007 survey.11   The households with high DTIs tended to have lower income, fewer financial assets, and higher mortgage loan-to-value ratios than households with lower payment ratios. Of course, some of these households may be able to reduce their DTIs by purchasing a less expensive house or by delaying home purchase for the time it takes to pay off some existing debt. Nonetheless, the borrowers most affected by this aspect of the rule are likely also those who currently face tight access to credit, such as first-time or less-creditworthy borrowers.\n\n The QM definition may also affect lenders' ability to charge for the risks of originating loans to borrowers who are more likely to default. For example, lenders might compensate for this risk by charging a higher interest rate on the loan. However, if lenders originate a QM with an annual percentage rate (APR) that is 150 basis points or more above the rate available to the highest-quality borrowers (known as a higher-priced loan), lenders receive less protection against lawsuits claiming violation of the ability-to-repay and QM rules. The extent to which this lower level of legal protection (the \"rebuttable presumption of compliance\") will affect lenders' willingness to originate such loans is still unclear.\n\nVery few of these higher-priced loans are being originated currently, reflecting the weak mortgage demand and tight underwriting standards that I discussed earlier. The HMDA data suggest that only 4 percent of mortgages originated in 2011 carried APRs this high. However, as demand picks up and lending standards ease, the number of potentially higher-priced loans may increase. In 2006--admittedly, not one of the best years for prudent mortgage underwriting in this country--about 25 percent of conventional purchase mortgage originations were considered higher priced.12 \n\nLenders who prefer to price for risk through points and fees rather than increases in rates also face constraints in originating QMs. Points and fees on a QM loan may not exceed 3 percent of the loan amount, with higher caps available for loans smaller than $100,000. The \"points and fees\" definition has been expanded from its original definition in the Truth in Lending Act and now includes, for example, compensation paid to the loan originator in the form of a higher interest rate on the loan. Unfortunately, data on points and fees are limited, so it is difficult to determine how many potential borrowers might be affected by this requirement.\n\nTo be clear, many borrowers were overcharged or defrauded by lenders in the past decade, and these abuses were concentrated among the more vulnerable parts of the population. It is a positive development if new regulations make such abuses more difficult. Still, the costs associated with mortgage lending, especially to borrowers more likely to default, have increased, and if lenders cannot charge enough to recoup these costs, they may not be willing to make the loans at all. As a result, the QM-related incentives against charging higher interest rates, points, or fees will likely affect more loans than in the past and may, in turn, have a greater effect on credit availability for higher-risk borrowers.\n\nTo bring this discussion back to the effect on the housing market, I think the ability of newly formed households, which are more likely to have lower incomes or weaker credit scores, to access the mortgage market will make a big difference in the shape of the recovery. Economic improvement will cause household formation to increase, but if credit is hard to get, these will be rental rather than owner-occupied households. And without first-time homebuyers, the move-up market will be sluggish, new and existing home sales will be more subdued, and purchase mortgage volumes will return only slowly.\n\nAs I've noted, credit availability to newly formed households is being affected by a variety of economic, market, and regulatory factors. Some of these factors are likely to ease, whereas others will be more permanent. As a result, this housing recovery may look different than previous ones. In particular, tighter mortgage credit and sustained investor interest in single-family rental properties may result in a lower homeownership rate than in the past. However, the same regulations that could contribute to tighter mortgage credit should also ensure that more of those homeownership experiences succeed.\n\nThe Role of Monetary Policy\nI would like to conclude with a brief discussion of the role of monetary policy in the housing recovery. The fact that mortgage purchase originations have remained nearly flat at a time when interest rates have hit historic lows naturally raises the question of whether monetary policy is effective in stimulating the housing market and thereby the broader economy. As I will explain next, I believe that the answer is yes.\n\nMonetary policy has clearly set the stage for a revival of the housing market. Record-low interest rates have sparked interest in homebuying. Monetary policy has contributed significantly to the recent improvement in the labor market and thereby begun to ease one of the main sources of weak housing demand. Monetary policy has likely also supported investor demand for purchasing houses, as the expected return on an investment in housing is more likely to exceed the low yields available on Treasury securities and other debt instruments. Households may be making the same calculus as investors.\n\nThe interest-rate-sensitive housing market is affected by all of the tools of monetary policy, but purchases of agency MBS have a more direct effect on the mortgage market. So, without delving deeply into monetary policy generally, I would like to make a few observations about the efficacy and costs of MBS purchases specifically. In doing so, I want to reiterate that these are my views and may not be in accord with those of my colleagues on the FOMC.\n\nIn many ways, purchases of MBS have the same downward effect on the general level of long-term interest rates as purchases of other longer-term securities. But, in addition, purchases of agency MBS reduce the spread between Treasury and MBS yields and thus, compared with purchases of Treasury securities, have somewhat larger effects on mortgage rates. This larger effect was especially true in the first round of purchases in 2009 when investor uncertainty about the degree of government support for agency MBS was quite high.13   MBS purchases also influence MBS yields by affecting the cost of hedging the risk (known as convexity risk) that mortgages prepay more quickly when rates decline or more slowly when rates increase, because, unlike some mortgage market investors, the Federal Reserve does not hedge such risk. \n\nLower MBS yields result in lower mortgage rates, which can spur the economy through elevated home-purchase and refinancing activity. But this effect is not yet fully transmitted to the economy, as the difference between MBS yields and mortgage rates is still somewhat wide and, as I discussed earlier, tight credit has prevented many households from accessing the low rates. Any improvement in credit conditions would thus act to improve the efficacy of MBS purchases. Similarly, policies that constrain mortgage lending or increase its cost would reduce efficacy.\n\nI think the additional impetus to housing from MBS purchases is appropriate for at least three reasons. First, the housing market has suffered extraordinary damage during the past few years. Second, even with the recent positive signs, housing investment has contributed far less to economic growth than in a typical recovery. And, third, even as terms and standards on other types of credit have eased, standards for mortgage credit remain quite tight.\n\nWhile the purchase of agency MBS has some special efficacy in supporting housing markets, the peculiarities of the MBS market itself present some potential market functioning issues that bear monitoring. The MBS market is not as deep or as liquid as the Treasury market, and the total size of the market is not growing as quickly. As refinancing activity slows, the gross pace of new MBS issuance could slow as well, and Federal Reserve purchases at the current level could leave an even larger footprint in the secondary mortgage market. So it is entirely possible that it might be appropriate at some point to adjust the pace of MBS purchases in response to developments in primary or secondary mortgage markets. Within the context of the Committee's judgment about the appropriate overall level of monetary accommodation, such an adjustment could result in an increase or decrease in the pace of total asset purchases, or it could lead to a change in the composition of purchases.\n\nFinally, the statement of exit strategy principles provided in the June 2011 FOMC minutes contemplates the sale of MBS once the Committee has begun to remove policy accommodation in order to return the System Open Market Account to an all-Treasury portfolio.14   As our holdings of MBS become larger in both absolute terms and in relation to the overall supply of agency MBS outstanding, we could reach a point where market functioning concerns begin to outweigh the efficacy of such purchases. Or we might conclude that sales of MBS in volumes sufficient to meet the parameters of the exit strategy principles might create significant market disruptions. In either case, I think we should consider alternatives, such as holding the securities for longer or allowing them to roll off more gradually.\n\nConclusion\nIn conclusion, I am optimistic that the housing recovery will continue to take root and expand. While low mortgage rates are helping support the recovery, I believe it will be the pent-up demand of household formation unleashed by improving economic conditions that will provide real momentum. However, the strength of this momentum will be determined by credit availability to these new households, an availability that may be much slower to return as mortgage market participants assess the regulatory, market, and economic environment. I think that if such credit is not readily available, the housing recovery will still continue, but the mix of owner-occupied and rental housing and the level of mortgage originations might be quite different.\n\nThank you very much for your attention this afternoon. I would be happy to take any questions that you might have.\n\n \n\n1. House price information is from staff calculations based on CoreLogic data. Return to text\n\n2. More details on homebuilder sentiment are available on the National Association of Home Builders website. Return to text\n\n3. Household reports are from staff calculations based on results of the Thomson Reuters/University of Michigan Surveys of Consumers. Return to text\n\n4. More details on real estate agent assessments of market conditions are available at the National Association of Realtors website. Return to text\n\n5. A home enters a lender's REO inventory when the lender completes foreclosure proceedings or otherwise obtains legal control of a property. Percentages are from staff calculations based on data provided by CoreLogic. Return to text\n\n6. Elliot Anenberg and Edward Kung (2012), \"Estimating the Size and Source of Price Declines due to Nearby Foreclosures,\" Finance and Economics Discussion Series 2012-84 (Washington: Board of Governors of the Federal Reserve System, October). Return to text\n\n7. The finding is from data provided by CoreLogic. Return to text\n\n8. The finding is from staff calculations based on data from the Housing Vacancy Survey supplement of the Current Population Survey. See U.S. Department of Commerce (2013), \"Housing Vacancy Survey,\" U.S. Census Bureau. Return to text\n\n9. The information is from staff calculations based on data from the American Community Survey. See U.S. Department of Commerce (2013), \"American Community Survey,\" U.S. Census Bureau. Return to text\n\n10. The finding is from staff calculations based on data from Equifax. Return to text\n\n11. Homeowner DTI is measured at the time of the survey, not at the time of loan origination, and may understate the number of affected households if household finances improve after the purchase of a home. A recent study by CoreLogic suggests that 25 percent of mortgages originated in 2010 had DTIs greater than 43 percent. See Sam Khater (2013), \"The Mortgage Market Impact of Qualified Mortgage Regulation (PDF),\" The MarketPulse, vol. 2 (February), pp. 3-6. Return to text\n\n12. The data that would permit the calculation of this share for earlier years are not available. Return to text\n\n13. See, for example, Diana Hancock and Wayne Passmore (2011), \"Did the Federal Reserve's MBS Purchase Program Lower Mortgage Rates?\" Journal of Monetary Economics, vol. 58 (July), pp. 498-514. Return to text\n\n14. The System Open Market Account contains the Federal Reserve's holdings of U.S. Treasury and federal agency securities as well as selected other assets accumulated in the process of implementing monetary policy. For the exit strategy principles, see Board of Governors of the Federal Reserve System (2011), \"Minutes of the Federal Open Market Committee, June 21-22, 2011,\" press release, July 12. Return to text\n\n "
    },
    {
        "title": "Focusing on Low- and Moderate-Income Working Americans",
        "date": "March 22, 2013",
        "speaker": "Governor Sarah Bloom Raskin",
        "url": "https://www.federalreserve.gov/newsevents/speech/raskin20130322.htm",
        "content": "March 22, 2013\n\nGovernor Sarah Bloom Raskin\n\nAt the National Community Reinvestment Coalition Annual Conference, Washington, D.C.\n\nI am delighted to be here at the National Community Reinvestment Coalition (NCRC) Annual Conference today, and to be gathered with so many people who have been working for decades to strengthen communities and the integrity of our nation's economic institutions and financial practices. Those of you involved in community development and community reinvestment know all too well the trauma and hardship experienced by low-income communities over the last several years. You know it in a way that is lost on people whose communities have not been so badly battered by these economic storms. That's why I'm looking forward this morning to sharing with you my perspective on the importance of focusing on the situation and prospects of low- and moderate-income working Americans.\n\nIn my remarks, I will start by discussing the types of jobs being generated in the current recovery. Certainly, the pace of recovery in employment has improved, but it's important to look at the types of jobs that are being created because those jobs will directly affect the fortunes and challenges of households and neighborhoods as well as the course of the recovery. I will then suggest that we think about how the absence of a substantial number of new high-paying jobs, when combined with changes in the landscape for financial services, affects access generally to affordable, sustainable credit. Finally, I will explore some of the monetary, supervisory, and regulatory touchpoints in which the situation and prospects of low- and moderate-income working Americans can be addressed.\n\nChallenges Posed by Labor Market Conditions\nThe Great Recession stands out for the magnitude of job losses we experienced throughout the downturn. These factors have hit low- and moderate-income Americans the hardest. The poverty rate has risen sharply since the onset of the recession, after a decade of relative stability, and it now stands at 15 percent--significantly higher than the average over the past three decades.1 And those who are fortunate enough to have held onto their jobs have seen their hourly compensation barely keep pace with the cost of living over the past three years.2 \n\nWhile today's 7.7 percent unemployment rate is a marked improvement from the 10 percent rate we reached in late 2009, it is still higher than the unemployment rate for the 24 years before the Great Recession, a span of time over which the rate averaged about 6 percent. Moreover, the government's current estimate of 12 million unemployed does not include nearly a million discouraged workers who say they have given up looking for work and 8 million people who say that they are working part time even though they would prefer a full-time job. A broader measure of underemployment that includes these and other potential workers stands at 14.3 percent.\n\nAbout two-thirds of all job losses resulting from the recession were in moderate-wage occupations, such as manufacturing, skilled construction, and office administration jobs. However, these occupations have accounted for less than one-quarter of subsequent job gains. The declines in lower-wage occupations--such as retail sales and food service--accounted for about one-fifth of job loss, but a bit more than one-half of subsequent job gains. Indeed, recent job gains have been largely concentrated in lower-wage occupations such as retail sales, food preparation, manual labor, home health care, and customer service.3 \n\nFurthermore, wage growth has remained more muted than is typical during an economic recovery. To some extent, the rebound is being driven by the low-paying nature of the jobs that have been created. The slow rebound also reflects the severe nature of the crisis, as the slow wage growth especially affects those workers who have become recently re-employed following long spells of unemployment. In fact, while average wages have continued to increase steadily for persons who have remained employed all along, the average wage for new hires have actually declined since 2010.4 \n\nThe faces of low-wage Americans are diverse. They include people of varying employment status, race, gender, immigration status, and other characteristics. Many such Americans are attached to the workforce and are deeply committed to both personal success and to making a contribution to society. For purposes of reference, in 2011, low wage was defined as $23,005 per year or $11.06 per hour.5 \n\nToday, about one-quarter of all workers are considered \"low wage.\" They are sanitation workers, office receptionists, and nursing assistants; they are single mothers of three who worry: How will I be able to send my children to college? What if my landlord raises the rent this year? Tens of millions of Americans are the people who ask themselves these questions every day.\n\nThis diverse group of workers faces numerous barriers when trying to access the labor market or advance in their current positions. Many of these barriers were identified in an initiative that the Federal Reserve's Community Development function launched in 2011. Over the course of a year, Reserve Banks across the country hosted a series of 32 regional discussions aimed at examining the complex factors creating chronic unemployment conditions and identifying promising workforce development solutions.6 The kinds of problems faced by low-wage workers are familiar to all of you and have long been part of the structural conditions of poverty and near-poverty in America.\n\nWe know, for example, that location presents thorny challenges for many low-wage workers. Within metropolitan areas, jobs are not spread out evenly and job creation tends to be depressed in low-income communities. As a result, many low-wage workers face long commutes and serious commuting difficulties due to less reliable transportation and an inadequate transportation infrastructure. Moreover, a number of low-wage employees work non-standard hours, exacerbating both transportation and childcare issues, as well as personal health problems.7 \n\nTraditionally, many workers find jobs through social networks and through personal connections that they have to the labor market. But, because low-income individuals are typically less mobile, more isolated, and less socially connected than other people, they are often left out of the social networks that, in practice, lead to jobs for most Americans.\n\nAddressing These Challenges\nAmong those responding to these challenges are innovative local practitioners who are implementing programs designed to expand job opportunities for low-wage workers. Consider Impact Services in Philadelphia, an organization that builds relationships with the local business community to better understand their hiring needs and then devises programs that supply those firms with appropriately skilled workers from the community.8 The National Fund for Workforce Solutions is another example. This organization works with local communities to organize funding collaboratives to support regional industries.9 \n\nMore Recent Challenges for Low-Wage Workers\nSo progress is being made, thanks to coalitions like these across the country that are working for practical changes at the community level. But the 21st century labor market is increasingly complex; it continues to generate new challenges. For example, growth in sectors such as green industries and advanced manufacturing is creating jobs, but these jobs may demand different skills. Access to reliable information becomes critical for workers who are considering a new job, and must carefully weigh the skills and credentials required by potential employers with the cost of training and the likelihood of gaining employment.\n\nAnd, more and more, employers are requiring post-secondary credentials. Today, a high school diploma alone is less likely to qualify an individual for a job with a path toward meaningful advancement. And, as demand for more credentials increases, workers who lack those credentials will find it increasingly difficult to gain upward mobility in the job market.\n\nContingent Work\nMany employers are looking to make the employment relationship more flexible, and so are increasingly relying on part-time work and a variety of arrangements popularly known as \"contingent work.\" This trend toward a more flexible workforce will likely continue. For example, while temporary work accounted for 10 percent of job losses during the recession, these jobs have accounted for more than 25 percent of net employment gains since the reces­sion ended.10 In fact, tempo­rary help is rapidly approaching a new record, and businesses' use of staffing services continues to increase.11 \n\nContingent employment is arguably a sensible response to today's competitive marketplace. Contingent arrangements allow firms to maximize workforce flexibility in the face of seasonal and cyclical forces. The flexibility may be beneficial for workers who want or need time to address their family needs. However, workers in these jobs often receive less pay and fewer benefits than traditional full-time or \"permanent\" workers, are much less likely to benefit from the protections of labor and employment laws, and often have no real pathway to upward mobility in the workplace.12 \n\nMany workers who hold contingent positions do so involuntarily. Department of Labor statistics tell us that 8 million Americans say they are working part-time jobs but would like full-time jobs.13 These are the people in our communities who are \"part time by necessity.\" As businesses increase their reliance on independent contractors and part-time, temporary, and seasonal positions, workers today bear far more of the responsibility and risk for managing their careers and financial security. Indeed, the expansion of contingent work has contributed to the increasing gap between high- and low-wage workers and to the increasing sense of insecurity among workers.14 \n\nFlexible and part-time arrangements can present great opportunities to some workers, but the substantial increase in part-time workers does raise a number of concerns. Part-time workers are particularly vulnerable to personal shocks due to lower levels of compensation, the absence of meaningful benefits, and even a lack of paid sick or personal days. Not surprisingly, turnover is high in these part-time jobs.\n\nAccess to Credit\nThe economic marginalization that comes with the growth of part-time and low-paying jobs is exacerbated by inadequate access to credit for many working Americans. Ideally, people chronically short of cash would have access to safe and sound financial institutions that could provide reliable and affordable access to credit as well as good savings plans. Unfortunately, many working Americans have no practical access to reasonably priced financial products with safe features, much less the kind of safe and fair credit that is available to wealthier consumers.\n\nWorking Americans have several core financial needs. They need a safe, accessible, and affordable method to deposit or cash checks, receive deposits, pay bills, and accrue savings. They may also need access to credit to tide them over until their next cash infusion arrives. They may be coming up short on paying their rent, their mortgage, an emergency medical expense, or an unexpected car repair. They may want access to a savings vehicle that, down the road, will help them pay for these items and for education or further training, or start a business. And many want some form of non-cash payment method to conduct transactions that are difficult or impossible to conduct using cash.\n\nProducts and services that serve these core financial needs are not consistently available at competitive rates to working Americans. Those with low and moderate incomes may have insufficient income or assets to meet the relatively high requirements needed to establish a credit history. Others may have problems in their credit history that inhibit their ability to borrow on competitive terms.\n\nMany workers simply may not have banks in their communities, or may not have access to banks that actually compete with each other in terms of pricing or customer service. There is a growing trend toward greater concentration of financial assets at fewer banks. In my mind, this raises doubts about whether banking services will continue to be provided at competitive rates to all income levels of customers wherever they may live.\n\nAccording to a study of bank branch locations published by NCRC in 2007, there are more persons per branch in low- and moderate-income census tracts than in moderate- and upper-income census tracts. While branch-building has been on the rise, indications are that the increase in the number of bank offices has not occurred evenly across neighborhoods of varying income.15 \n\nIn fact, a significant number of low- and moderate-income families have become--or are at risk of becoming--financially marginalized. The percentage of families earning $15,000 per year or less who reported that they have no bank account increased between 2007 and 2009 such that more than one in four families was unbanked. Families slightly further up the income distribution, earning between $25,000 and $30,000 per year, are also financially marginalized: 13 percent report being unbanked and almost 24 percent report being underbanked.16 \n\nThis combination of economic insecurity and financial marginalization has incentivized more low- and moderate-income families to seek out alternative financial service providers to meet their financial needs. Some of the providers they find, such as check-cashers and outfits furnishing advance loans on paychecks, can lead unwary workers into very deep financial holes.\n\nIn light of these challenges, I ask questions that have been asked before: What can economic policy do to reduce unemployment, economic marginalization, and the financial vulnerability of millions of lower-income working Americans? There is no simple cure to these conditions, but government policymakers need to focus seriously on the problems, not simply because of notions of fairness and justice, but because the economy's ability to produce a stable quality of living for millions of people is at stake. Our country cannot achieve prosperity without addressing the powerful undertow created by flat wages and tenuous financial security for so many millions of Americans.\n\nThe Role of Monetary Policy\nSo how can the Federal Reserve address these challenges? Let me start with monetary policy. Congress has directed the Federal Reserve to use monetary policy to promote maximum employment and price stability. The Federal Reserve's primary monetary policy tool is its ability to influence the level of interest rates. Federal Reserve policymakers pushed short-term interest rates down nearly to zero as the financial crisis spread and the recession worsened in 2007 and 2008. By late 2008, it was clear that still more policy stimulus was necessary to turn the recession around. The Federal Reserve could not push short-term interest rates down further, but it could--and did--use the unconventional policy tools to bring longer-term interest rates such as mortgage rates down further.\n\nFed policymakers intend to keep interest rates low for a considerable time to promote a stronger economic recovery, a substantial improvement in labor market conditions, and greater progress toward maximum employment in a context of price stability. Both anecdotal evidence and a wide range of economic indicators show that these attempts are working to strengthen the recovery and that the labor market is improving.\n\nNonetheless, and again, the millions of people who would prefer to work full time can find only part-time work. While the Federal Reserve's monetary policy tools can be effective in promoting stronger economic recovery and job gains, they have little effect on the types of jobs that are created, particularly over the longer term. So, while monetary policy can help, it does not address all of the challenges that low- and moderate-income workers are confronting. That said, the existing mandate regarding maximum employment requires policymakers on the Federal Open Market Committee (FOMC) to understand labor market dynamics, which obviously must include an understanding of low- and moderate-income workers.\n\nRegulatory and Supervisory Touchpoints\nIn addition to monetary policy, the Federal Reserve's regulatory and supervisory policies have the potential to address some of the challenges faced by low-income communities and consumers. The Federal Reserve is required by law--by virtue of the Bank Holding Company Act--to approve various applications, such as mergers, acquisitions, and proposals to conduct new activities. This statutory review requires an explicit consideration of public benefits and the effects of the proposed transaction on the convenience and needs of the communities to be served. This assessment is, as many of you know, a critical opportunity for community input and analysis.\n\nIndeed, as people with their feet firmly planted on the ground in communities across America, you probably remember James Q. Wilson's theory of \"broken windows\" in community policing: Move in quickly when vandalism and disorder first start to appear--even if it is only a broken window or graffiti on a stop sign--or else face losing the whole neighborhood as disrespect for the law rapidly spreads.17 \n\nThe \"broken windows\" strategy is every bit as compelling when it comes to addressing the disorder that comes from sloppy practices by financial institutions. If banking practices are undermining the ability of the economically marginalized to become financially included and to access the credit they need in an affordable way, regulators must move in quickly to stop the disorder and repair the broken windows of financial intermediation.\n\nBank supervisors should be prepared to respond to the earliest signs of trouble by requiring operationally challenged banks to address problems quickly and completely. If corrections are made, then the regulators can move on. If not, then the regulators need to escalate enforcement.\n\nSwift and decisive corrective action is not always how federal bank regulators have responded to broken windows in the past. In my view, for example, regulators' response to the rampant, long-running problems in loan-servicing practices at large financial institutions was not swift and was not decisive. The point is that federal regulators must listen carefully to community input and analysis in order to keep track of where windows are breaking and how they are being broken. And they must carefully study and take responsibility for analyzing comments provided by organizations such as the NCRC when considering the public benefit of an application. Both the exam process and the application process must be strengthened as key venues for federal regulators to incorporate the voices of affected communities; I'd like to see us revise and strengthen these processes to include the analysis in these voices.\n\nThe Role of Business\nNow let's shift back to the private sector. In particular, to the question of whether businesses can be competitive in the current marketplace and still provide a pathway out of poverty for their employees. The Hitachi Foundation recently set out to answer this question by identifying firms that provided upward job mobility for their employees. They found that the identified employers showed noteworthy consistency in how they train and educate workers, develop career ladders, and craft supportive human resources policies and other motivators. They also found some evidence to indicate that the companies benefited from strategic and financial returns while their lower-wage workers also benefited from increased earnings and career advancement.18 ,19 \n\n\"Anchor institutions,\" such as hospitals and universities, which are firmly rooted in their locales, can also be powerful engines for job creation in their communities. Anchors may include cultural institutions, health care facilities, community foundations, faith-based institutions, public utilities, and municipal governments. These institutions have the potential to generate local jobs through targeted procurement purchases of food, energy, supplies, and services from local businesses. This can be a substantial, positive development in the local economy. 20 \n\nThe Evergreen Cooperative in Cleveland, Ohio, is an example of a network of worker-owned businesses, launched in low-income neighborhoods, to support local anchor institutions. The cooperatives were initially established to provide services to local hospitals and universities that had agreed to make their purchases locally. This model is effective because it capitalizes on local production, and because it forges a local business development strategy that effectively meets many of the anchor institutions' own needs.21 \n\nRole for Community-Based Organizations\nClearly, the challenges facing low-wage workers are multi-faceted and complex. In addition to the challenges that workforce development and community organizations have addressed for years, structural changes in the economy heighten obstacles, make the stakes higher if we fail to conquer them, and, therefore, require new levels of openness and creativity by policymakers. You are the ideal audience for this message because you know how to link federal policymaking with economic empowerment.\n\nNCRC has grown to an association of more than 600 community-based organizations that promote access to basic banking services to create and sustain affordable housing, jobs, and vibrant communities for America's working families. Community-based organizations like many of those represented in this room will need to consider how to work with low-wage workers to bridge information gaps by expanding workers' networks, providing legitimate information, and identifying new job opportunities.\n\nBut finally, the pressure that community-based organizations exert on financial regulators must continue. Access to credit is an enduring challenge, and the obstacles and problems--all the \"broken windows\" you see on the block--must be reported and explained. They must be understood by the federal policymakers who are responsible for enforcing our country's laws and regulations in the realm of access to credit; by the federal policymakers who engage in the conduct of monetary policy; and by the federal policymakers whose actions contribute to the shaping of the landscape for financial services in this country. Your voices--whether you are reporting, documenting, monitoring, analyzing, proposing, or even protesting--must be heard. Your voices are crucial to alerting policymakers to the significant developments and emerging trends in the nation's communities that must be confronted--and confronted in a swift and decisive way--if we are to make prosperity a national agenda that touches every American.\n\nThank you.\n\n1. Mean annual poverty rate for all people. U.S. Bureau of the Census. Return to text\n\n2. These dynamics have disproportionately hurt the young, the less-educated, and racial and ethnic minorities. The unemployment rate for those without a high school diploma is 11.2 percent. Among workers age 16 to 19, the unemployment rate is 25.1 percent. Compared with the 7.7 percent unemployment rate for all workers, the unemployment rate among African Americans is 13.8 percent, and 9.6 percent among Latinos. Return to text\n\n3. See National Employment Law Project (2012), \"The Low-Wage Recovery and Growing Inequality (PDF),\" Data Brief, August. These patterns were also observed during the recessions of the early 1990s and early 2000's—the so-called \"jobless recoveries\"—but not prior to then. Return to text\n\n4. On average, a person's income remains depressed for decades following job loss, and income losses over one's working life are especially severe when the job loss occurs during a recession. See Steven J. Davis and Till von Wachter (2011), \"Recession and the Costs of Job Loss (PDF),\" Brookings Papers on Economic Activity, September 12. Return to text\n\n5. See Rebecca Thiess (2012). \"The Future of Work: Trends and Challenges for Low-Wage Workers (PDF),\" EPI Briefing Paper, April 27. Return to text\n\n6. See Board of Governors of the Federal Reserve System (2012), \"A Perspective from Main Street: Long-Term Unemployment and Workforce Development (PDF),\" December. Return to text\n\n7. Ibid. Return to text\n\n8. For more information about Impact Services Corporation, go to www.impactservices.org/employment-and-training. Return to text\n\n9. One of the National Fund's collaboratives is the Southwest Alabama Workforce Development Council (SAWDC). This collaborative is working to address a local skills gap by creating a comprehensive workforce development system for the region. This system includes formal feedback from the business community to the educational system about skills that are in high demand. Educators then develop a curriculum that prepares students to access the local job market. During the National Fund's first five years of existence, it worked with more than 3,000 employers to serve more than 42,000 job seekers and workers across 32 communities. For more information about the National Fund for Workforce Solutions, go to www.nfwsolutions.org. Return to text\n\n10. See P. Steven Berchem (2012), \"Structural Shift? (PDF)\" Staffing Success. American Staffing Association.\nThis article cites U.S. Department of Labor, Bureau of Labor Statistics (2012), \"Employment, Hours, and Earnings From the Current Employment Statistics Survey (National),\" August 4. Return to text\n\n11. In a 2011 McKinsey Global Institute U.S. Jobs Survey of 2,000 employers of all sizes and in all sectors, 34 percent of employers indicated that they expect their com­panies to increase temporary and contract workers over the next five years. See James Manyika, Susan Lund, Byron Auguste, Lenny Mendonca, Tim Welsh, and Sreenivas Ramaswamy (2011), \"An Economy That Works: Job Creation and America's Future,\" McKinsey Global Institute, June, www.mckinsey.com/insights/employment_and_growth/an_economy_that_works_for_us_job_creation. Return to text\n\n12. See U.S. Department of Labor and U.S. Department of Commerce (1994), \"Section Five: Contingent Workers,\" in the final report of the Dunlop Commission on the Future of Worker-Management Relations. Return to text\n\n13. See U.S. Department of Labor, Bureau of Labor Statistics. Return to text\n\n14. See U.S. Department of Labor and U.S. Department of Commerce (1994). Return to text\n\n15. See National Community Reinvestment Coalition (2007), \"Are Banks on the Map? An Analysis of Bank Branch Location in Working Class and Minority Neighborhoods (PDF),\" March. Return to text\n\n16. See Federal Deposit Insurance Corporation (2012), \"2011 FDIC National Survey of Unbanked and Underbanked Households,\" September; and Brian K. Bucks, Arthur B. Kennickell, Traci L. Mach, and Kevin B. Moore (2009), \"Changes in U.S. Family Finances from 2004 to 2007: Evidence from the Survey of Consumer Finances (PDF),\" Federal Reserve Bulletin, v. 95 (February), pp. A1–A55. Return to text\n\n17. See George L. Kelling and James Q. Wilson (1982), \"Broken Windows: The police and neighborhood safety\", The Atlantic, March 1, www.theatlantic.com/magazine/archive/1982/03/broken-windows/304465. Return to text\n\n18. For more information about The Hitachi Foundation, go to www.hitachifoundation.org/index.php. Return to text\n\n19. While the common perception may be that businesses do not invest in employee training, a survey by the American Society for Training and Development indicated that employers committed $172 billion in 2011 to employee training. See American Society for Training and Development (2011), \"2011 State of the Industry Report Shows Increased Spending, Commitment for L&D,\" December 20. This investment, however, traditionally funds the highest-educated and highest-paid employees. The Hitachi Foundation has suggested that considering a reallocation of even a small portion of these funds toward frontline workers would offer benefits to both employers and employees. As an example of these employer practices, right here in our backyard, the Community Foundation for the National Capital Region piloted the \"Career Navigators\" program with three hospitals in Maryland's Montgomery County and one in the District of Columbia to help employees navigate a pathway to better jobs with their current employer. These hospitals concluded that investing in training and education for top-performing, entry-level staffers in positions such as housekeeping, food service, and patient transport could provide a pipeline for the skilled employees that the hospitals would rely upon in the future. Employees receive support with literacy and college-readiness training, career coaching, and scholarships. The program also helps hospitals document internal career pathways and train the human resource staff to serve as career coaches. Throughout these efforts, the participating hospitals have reported enhanced employee engagement, reduced errors, and improved performance. Return to text\n\n20. See Ted Howard (2012), \"Owning Your Own Job Is Beautiful Thing: Community Wealth Building in Cleveland, Ohio (PDF),\" in Nancy O. Andrews and David J. Erickson, eds., Investing in What Works for America's Communities (San Francisco: Federal Reserve Bank of San Francisco and Low Income Investment Fund). See also Gar Alperovitz (forthcoming April 2013, Chelsea Green), What Then Must We Do? Return to text\n\n21. The success of the \"Cleveland model\" has spurred new efforts in places as diverse as Amarillo, Texas; Atlanta; Pittsburgh; Richmond, California; and Washington, D.C. See Ted Howard (2012). Return to text"
    },
    {
        "title": "Monetary Policy and the Global Economy",
        "date": "March 25, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20130325a.htm",
        "content": "March 25, 2013\n\nChairman Ben S. Bernanke\n\nAt the Department of Economics and STICERD (Suntory and Toyota International Centres for Economics and Related Disciplines) Public Discussion in Association with the Bank of England, London School of Economics, London, United Kingdom\n\nI'm very pleased to participate in this conference honoring my good friend Mervyn King. As Mervyn noted in a recent speech in New York, we had adjoining offices at MIT as young academics and never imagined that 30 years later we still would be colleagues--as central bankers.1  Now, as then, I value his advice and insight.\n\nThe topic of this session is lessons learned from the financial crisis. For me, perhaps the central insight is that the recent crisis, despite its many exotic features, was in fact a classic financial panic--a systemwide run of \"hot money\" away from assets whose values suddenly became uncertain. In that respect, the crisis was akin to many other financial crises faced by governments and central banks--including that most venerable of central banks, the Bank of England--over the centuries. The response to the crisis likewise followed the classic prescriptions of liquidity provision, liability guarantees, asset evaluation and disposition, and recapitalization where necessary. Although the crisis had classic features, to a significant extent it took place in a novel institutional context, making diagnosis and response more challenging: For example, in the United States, collateralized wholesale funding rather than conventional bank deposits constituted the hot money, and run pressure was experienced not only by banks but by diverse other institutions, such as structured investment vehicles. In addition, the scale and complexity of globalized financial institutions and markets made it difficult to predict how the crisis might spread or to coordinate the response. One of the few positive aspects of this episode was the extraordinary degree of international cooperation achieved among policymakers, including the Bank of England and the Federal Reserve, in responding to the crisis.\n\nBecause I have developed these themes in some detail elsewhere, I thought today I would tackle a different and more recent issue that has arisen in the aftermath of the crisis--the issue of whether, in the widespread easing of monetary policies, we are seeing a competitive depreciation of exchange rates.2  Like other aspects of the crisis, the notion of competitive depreciation has strong classical antecedents, particularly in relation to the global Great Depression of the 1930s. So let me start by briefly revisiting the older discussion and its evolution.\n\nAs my audience knows, on the eve of the Great Depression the exchange rates of most industrial countries were determined by the rules of the international gold standard--or, more technically, by the gold-exchange standard, as foreign exchange (primarily dollars and pounds sterling) was used along with gold as a form of international reserves. The gold standard, which had been suspended during World War I, was painstakingly rebuilt in the 1920s. Unfortunately, the reconstructed gold standard had a number of serious problems. For one, the exchange rates implied by the gold valuations that countries chose for their currencies following World War I were in some cases far from the levels consistent with balanced flows in trade and payments. Notably, as John Maynard Keynes pointed out in his famous pamphlet, The Economic Consequences of Mr. Churchill, the British pound was overvalued under the new gold standard, which disadvantaged British exports and contributed to weak economic conditions in the United Kingdom in the late 1920s.3  One of Mervyn King's predecessors as governor of the Bank of England, Montagu Norman, who presided over both Britain's return to the gold standard and its subsequent exit, said of the ill-fated choice of parity for the pound: \"Only God could tell whether it [the value in gold chosen for the pound sterling] was or was not the correct figure\"; another commentator added, \"But of course the Deity may not be an Economist.\"4 \n\nAnother problem, which became clear as the global economy weakened and financial conditions deteriorated, was that fixed exchange rates under the gold standard were vulnerable to speculative runs. Although runs, or in some cases policy decisions, effectively took a number of countries off the gold standard in the early 1930s, the financial world was shaken to its foundation when the United Kingdom, the unofficial center of the global gold standard, was forced by a speculative attack to leave gold in September 1931. Over the next five years, essentially all of the world's industrial nations left the gold standard, either de facto or de jure. Declines in the value of the departing nation's currency, sometimes very sharp ones, typically followed.\n\nThe uncoordinated abandonment of the gold standard in the early 1930s gave rise to the idea of \"beggar-thy-neighbor\" policies. According to this analysis, as put forth by important contemporary economists like Joan Robinson, exchange rate depreciations helped the economy whose currency had weakened by making the country more competitive internationally.5  Indeed, the decline in the value of the pound after 1931 was associated with a relatively early recovery from the Depression by the United Kingdom, in part because of some rebound in exports. However, according to this view, the gains to the depreciating country were equaled or exceeded by the losses to its trading partners, which became less internationally competitive--hence, \"beggar thy neighbor.\" Over time, so-called competitive depreciations became associated in the minds of historians with the tariff wars that followed the passage of the Smoot-Hawley tariff in the United States. Both types of policies were decried--and in some textbooks, still are--as having prolonged the Depression by disrupting trade patterns while leading to an ultimately fruitless and destructive battle over shrinking international markets.\n\nEconomists still agree that Smoot-Hawley and the ensuing tariff wars were highly counterproductive and contributed to the depth and length of the global Depression. However, modern research on the Depression, beginning with the seminal 1985 paper by Barry Eichengreen and Jeffrey Sachs, has changed our view of the effects of the abandonment of the gold standard.6   Although it is true that leaving the gold standard and the resulting currency depreciation conferred a temporary competitive advantage in some cases, modern research shows that the primary benefit of leaving gold was that it freed countries to use appropriately expansionary monetary policies. By 1935 or 1936, when essentially all major countries had left the gold standard and exchange rates were market-determined, the net trade effects of the changes in currency values were certainly small. Yet the global economy as a whole was much stronger than it had been in 1931. The reason was that, in shedding the strait jacket of the gold standard, each country became free to use monetary policy in a way that was more commensurate with achieving full employment at home. Moreover, and critically, countries also benefited from stronger growth in trading partners that purchased their exports. In sharp contrast to the tariff wars, monetary reflation in the 1930s was a positive-sum exercise, whose benefits came mainly from higher domestic demand in all countries, not from trade diversion arising from changes in exchange rates.\n\nThe lessons for the present are clear. Today most advanced industrial economies remain, to varying extents, in the grip of slow recoveries from the Great Recession. With inflation generally contained, central banks in these countries are providing accommodative monetary policies to support growth. Do these policies constitute competitive devaluations? To the contrary, because monetary policy is accommodative in the great majority of advanced industrial economies, one would not expect large and persistent changes in the configuration of exchange rates among these countries. The benefits of monetary accommodation in the advanced economies are not created in any significant way by changes in exchange rates; they come instead from the support for domestic aggregate demand in each country or region. Moreover, because stronger growth in each economy confers beneficial spillovers to trading partners, these policies are not \"beggar-thy-neighbor\" but rather are positive-sum, \"enrich-thy-neighbor\" actions.\n\nAgain, the distinction between monetary policies aimed at domestic objectives and trade-diverting exchange rate devaluations or other protectionist measures is critical. The former can be mutually beneficial, the latter are not. Indeed, it was this view that prompted the Group of Seven central bankers and finance ministers to issue a statement in February agreeing to refrain from actions focused on achieving competitive advantage by weakening their currencies and reaffirming that fiscal and monetary policies would remain oriented toward meeting domestic objectives using domestic instruments.7 \n\nAmong the advanced economies, the mutual benefits of monetary easing are clear. The case of emerging market economies is more complicated. To a first approximation, industrial countries are most concerned that domestic aggregate demand be set at the level that best fosters price stability and a return to full employment at home. In contrast, many emerging market economies may be concerned not only with the level of domestic demand (as needed to achieve objectives for employment and inflation) but with other considerations as well. First, because in recent decades many of these countries have pursued an export-led strategy for industrialization, they may be leery of expansionary policies in the advanced economies that, all else being equal, tend to cause the currencies of emerging market economies to appreciate, restraining their exports. Second, because many emerging market economies have financial sectors that are small or less developed by global standards but open to foreign investors, they may perceive themselves to be vulnerable to asset bubbles and financial imbalances caused by heavy and volatile capital inflows, including those arising from low interest rates in the advanced economies.\n\nI agree these challenges are significant. However, a few points should be made. Regarding the effects of monetary easing on exchange rates and exports, I would note that trade-weighted real exchange rates of emerging market economies, with some exceptions, have not changed much from their values shortly before the intensification of the financial crisis in late 2008. Moreover, even if the expansionary policies of the advanced economies were to lead to significant currency appreciation in emerging markets, the resulting drag on their competitiveness would have to be balanced against the positive effects of stronger advanced-economy demand. Which of these two effects would be greater is an empirical matter. Simulations of the Federal Reserve Board's econometric models of the global economy suggest that the effects are roughly offsetting, so that accommodative monetary policies in the advanced economies do not appear, on net, to have adverse consequences for output and exports in the emerging market economies.8  A return to solid growth among the advanced economies is ultimately in the interest of advanced and emerging market economies alike.\n\nRegarding capital flows: It is true that interest rate differentials associated with differences in national monetary policies can promote cross-border capital flows as investors seek higher returns. But my reading of recent research makes me skeptical that these policy differences are the dominant force behind capital flows to emerging market economies; differences in growth prospects across countries and swings in investor risk sentiment seem to have played a larger role.9  Moreover, the fact that some emerging market economies have policies that depress the values of their currencies may create an expectation of future appreciation that in and of itself induces speculative inflows.\n\nOf course, heavy capital inflows and their volatility pose challenges to emerging market policymakers, whatever their source. Policymakers do have some tools to address these concerns. In recent years, emerging market nations have implemented macroprudential measures aimed at strengthening their financial systems and reducing overheating in specific sectors, such as property markets. Policymakers have also experimented with various forms of capital controls. Such controls raise concerns about effectiveness, cost of implementation, and possible microeconomic distortions. Nevertheless, the International Monetary Fund has suggested that, in carefully circumscribed circumstances, capital controls may be a useful tool.10  \n\nIn sum, the advanced industrial economies are currently pursuing appropriately expansionary policies to help support recovery and price stability in their own countries. As the modern literature on the Great Depression demonstrates, these policies confer net benefits on the world economy as a whole and should not be confused with zero- or negative-sum policies of trade diversion. In fact, the simultaneous use by several countries of accommodative policy can be mutually reinforcing to the benefit of all.\n\nLet me end these remarks as I began, by paying tribute to Mervyn King. He has been a leader in the central banking community during an extraordinarily difficult period. I wish him the very best in the next stage of his career.\n\n \n\n1. See Mervyn A. King (2012), \"Talk to the Economic Club of New York,\" speech delivered at the Economic Club of New York, December 10, http://econclubny.com/events/Transcript_MervynKing2012.pdf. Return to text\n\n2. See, for example, Ben S. Bernanke (2009), \"Reflections on a Year of Crisis,\" speech delivered at \"Financial Stability and Macroeconomic Policy,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 20-22; and Ben S. Bernanke (2012), \"Some Reflections on the Crisis and the Policy Response,\" speech delivered at \"Rethinking Finance: Perspectives on the Crisis,\" a conference sponsored by the Russell Sage Foundation and The Century Foundation, New York, April 13. See also Ben S. Bernanke (2010), \"Causes of the Recent Financial and Economic Crisis,\" statement before the Financial Crisis Inquiry Commission, September 2. Return to text\n\n3. See John Maynard Keynes (1925), The Economic Consequences of Mr. Churchill (London: Hogarth Press). Return to text\n\n4. As quoted in C.A.E. Goodhart (1972), review of British Monetary Policy 1924-1931: The Norman Conquest of $4.86, by D.E. Moggridge, Economica, vol. 39 (November), pp. 450. Return to text\n\n5. See Joan Robinson (1947), \"Beggar-My-Neighbour Remedies for Unemployment,\" in Essays in the Theory of Employment, 2nd ed. (Oxford, U.K.: Basil Blackwell), pp. 156-70. Return to text\n\n6. See Barry Eichengreen and Jeffrey Sachs (1985), \"Exchange Rates and Economic Recovery in the 1930s,\" Journal of Economic History, vol. 45 (December), pp. 925-46. Return to text\n\n7. For the full text of the Group of Seven statement, see Bank of England (2013), \"G7 Statement,\" press release, February 12, www.forexmg-pt.com/2013/02/12/bank-of-england-publications-news-releases-news-release-g7-statement. Return to text\n\n8. Other work also supports the finding of no adverse spillovers. For example, one that finds strong positive spillovers is Bennett T. McCallum (2003), \"Japanese Monetary Policy, 1991-2001 (PDF) ,\" Federal Reserve Bank of Richmond, Economic Quarterly, vol. 89 (Winter), pp. 1-31. Return to text\n\n9. For example, Fratzscher, Lo Duca, and Straub find that factors other than U.S. monetary policy have been substantially more important as drivers of capital flows to emerging market economies; see Marcel Fratzscher, Marco Lo Duca, and Roland Straub (2012), \"A Global Monetary Tsunami? On the Spillovers of US Quantitative Easing (PDF) ,\" Centre for Economic Policy and Research, Discussion Paper Number 9195 (London: CEPR, October). See also Atish R. Ghosh, Jun Kim, Mahvash S. Qureshi, and Juan Zalduendo (2012), \"Surges (PDF) ,\" IMF Working Paper WP/12/22 (Washington: International Monetary Fund, January); and International Monetary Fund; Strategy, Policy, and Review Department (2011), \"Recent Experiences in Managing Capital Inflow--Cross-Cutting Themes and Possible Policy Framework (PDF) ,\" paper (Washington: IMF, February). Return to text\n\n10. Importantly, such circumstances exclude the use of capital controls to avoid other necessary macroeconomic policy adjustments, such as greater exchange rate flexibility. See, for example, International Monetary Fund (2012), \"The Liberalization and Management of Capital Flows: An Institutional View,\" (Washington: International Monetary Fund). Return to text"
    },
    {
        "title": "Communication in Monetary Policy",
        "date": "April 04, 2013",
        "speaker": "Vice Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20130404a.htm",
        "content": "April 04, 2013\n\nVice Chair Janet L. Yellen\n\nAt the Society of American Business Editors and Writers 50th Anniversary Conference, Washington, D.C.\n\nThank you for inviting me here and for offering me what I consider a perfect opportunity to speak on a topic at the heart of the Federal Reserve's efforts to promote a stronger economy--the vital role and growing use of communication in monetary policy.1 \n\nSome of you cover the Federal Reserve and are familiar with how it sets monetary policy through the Federal Open Market Committee (FOMC). You know that the FOMC pays very close attention to what it says in the statements it issues after each meeting. This communication is supplemented by Chairman Bernanke's postmeeting press conferences and by providing detailed minutes of the Committee's meetings. Getting this message out to the public depends a good deal on the work you do in reporting on the FOMC, analyzing its statements and actions, and explaining its role and objectives. So let me begin by thanking you for those contributions.\n\nBut let me also say why I am particularly pleased to speak to you today. As writers and editors, all of you are prodigious consumers and producers of communication. At first glance, the FOMC's communication may not seem so different from what you've heard other government agencies say about their policies or businesses say about their products. I hope to show how communication plays a distinct and special role in monetary policymaking.\n\nLet me offer a comparison that may highlight that difference. Suppose, instead of monetary policy, we were talking about an example of transportation policy--widening a road to ease traffic congestion. Whether this road project is announced at a televised press conference or in a low-key press release--or even if there is no announcement--the project is more or less the same. The benefit to drivers will come after the road is widened and won't be affected by whether drivers knew about the project years in advance.\n\nAt the heart of everything I'll be explaining today is the fact that monetary policy is different. The effects of monetary policy depend critically on the public getting the message about what policy will do months or years in the future.2 \n\nTo develop this idea, I will take you on a tour of past FOMC communication, the present, and what I foresee for the future. Until fairly recently, most central banks actively avoided communicating about monetary policy. Montagu Norman, governor of the Bank of England in the early 20th century, reputedly lived by the motto \"never explain, never excuse,\" and that approach was still firmly in place at the Federal Reserve when I went to work there as a staff economist in 1977.\n\nI'll begin by discussing how a growing understanding of the importance of transparency shaped FOMC communication in the years before the financial crisis. Next, I'll relate how the financial crisis brought unprecedented challenges for monetary policy that required the use of unconventional policy tools, including some barely contemplated before the crisis. Communication was a centerpiece of these efforts. Finally, I'll look ahead. I am encouraged by recent signs that the economy is improving and healing from the trauma of the crisis, and I expect that, at some point, the FOMC will return to a more normal approach to monetary policy. At the conclusion of my remarks, I'll discuss the communication challenges the FOMC will face when it comes time to make that transition.\n\nFOMC communication has long been a topic of great interest to me, and one I have worked on more directly since 2010, when Chairman Bernanke asked me to lead a new FOMC subcommittee on communications. This is probably a good moment to remind you that, as always, I speak for myself and not the FOMC or my colleagues in the Federal Reserve System.\n\nFrom \"Never Explain\" to Transparency \nRecently I used the word \"revolution\" to describe the change from \"never explain\" to the current embrace of transparency in the FOMC's communication.3 That might sound surprising to an audience that knows very well what it feels like to be in the middle of a communications revolution. The speed and frequency of most communication, it seems, never stops growing, and I will admit that the FOMC's changes to the pace and form of its communication seem rather modest in comparison. I've mentioned the Chairman's quarterly postmeeting press conferences, which were initiated two years ago. While these events are televised and streamed live, the mode for most of the FOMC's communication is decidedly old-school--the printed word. The Committee's most watched piece of communication is the written statement issued after each of its meetings, which are held roughly every six weeks. It may seem quaint that my colleagues and I continue to spend many hours laboring over the few hundred words in this statement, which are then extensively analyzed only minutes after their release.\n\nThe revolution in the FOMC's communication, however, isn't about technology or speed. It's a revolution in our understanding of how communication can influence the effectiveness of monetary policy.\n\nIt will help if I start with some basics. The FOMC consists of the 7 members of the Federal Reserve Board in Washington and 5 of the 12 presidents of the regional Federal Reserve Banks. All 12 presidents participate in FOMC meetings but only 5 get a vote, a roster that rotates each year.\n\nThe FOMC's job, assigned by the Congress, is to use monetary policy to promote maximum employment and stable prices, objectives that together are known as the Federal Reserve's dual mandate. In normal times, the Committee pursues these goals by influencing the level of a short-term interest rate called the federal funds rate, which is what banks charge each other for overnight loans. When the FOMC pushes the federal funds rate up or down, other short-term interest rates normally move in tandem. Medium- and longer-term interest rates, including auto loan rates and mortgage rates, generally adjust also, through a mechanism I will return to in a moment. By pushing the federal funds rate up or down, the FOMC seeks to influence a wide range of interest rates that matter to households and businesses.\n\nTypically, the FOMC acts to lower the federal funds rate, with the intention of reducing interest rates generally, when the economy is weakening or inflation is declining below the Committee's longer-run objective. The FOMC raises the federal funds rate when inflation threatens to rise above its objective or when economic activity appears likely to rise above sustainable levels. Raising and lowering the federal funds rate was long the primary means by which the FOMC pursued its economic objectives.\n\nIt is hard to imagine now, but only two decades ago, the Federal Reserve and other central banks provided the public with very little information about such monetary policy moves--the spirit of \"never explain\" was very much alive. There were a number of different justifications for this approach. One view was that less disclosure would reduce the risk and tamp down suspicions that some could take advantage of disclosures more readily than others. Some believed that markets would overreact to details about monetary policy decisions. And there was a widespread belief that communicating about how the FOMC might act in the future could limit the Committee's discretion to change policy in response to future developments. In sum, the conventional wisdom among central bankers was that transparency was of little benefit for monetary policy and, in some cases, could cause problems that would make policy less effective.\n\nWhile communication and transparency steadily increased elsewhere in government and society, change came slowly to the FOMC. It wasn't until February 1994 that the Committee issued a postmeeting statement disclosing a change in monetary policy. Even then, it only alerted the public that the Committee had changed its policy stance, with scant explanation.4 \n\nSomething big was changing, however, and it would soon be the force driving major enhancements in the FOMC's communication. By the early 1990s, a growing body of research challenged widespread assumptions about the how central banks, such as the Federal Reserve, affected the economy. The reevaluation starts with a question that puzzled many of my students when I was a professor: How is it that the Federal Reserve manages to move a vast economy just by raising or lowering the interest rate on overnight loans by 1/4 of a percentage point?\n\nThe question arises because significant spending decisions--expanding a business, buying a house, or choosing how much to spend on consumer goods over the year--depend on expectations of income, employment, and other economic conditions over the longer term, as well as longer-term interest rates. The crucial insight of that research was that what happens to the federal funds rate today or over the six weeks until the next FOMC meeting is relatively unimportant. What is important is the public's expectation of how the FOMC will use the federal funds rate to influence economic conditions over the next few years.5 \n\nFor this reason, the Federal Reserve's ability to influence economic conditions today depends critically on its ability to shape expectations of the future, specifically by helping the public understand how it intends to conduct policy over time, and what the likely implications of those actions will be for economic conditions. To return to the example I used earlier, contrast this effect on expectations with that of a road project. Today's commute, alas, will not be improved or changed at all by the news that a road will be widened one day. But the effects of today's monetary policy actions are largely due to the effect they have on expectations about how policy will be set over the medium term.\n\nLet me further illustrate this with some history. Starting in the mid-1960s, the Federal Reserve didn't act forcefully in the face of rising inflation, and the public grew less certain of the central bank's commitment to fighting inflation. This uncertainty led expectations of future inflation to become \"unanchored\" and more likely to react to economic developments. In 1973, an oil price shock led to a large increase in overall inflation. Expectations of higher inflation in the future affected the public's behavior--workers demanded raises, and businesses set prices and otherwise acted in anticipation of higher costs--and this helped fuel actual inflation. The FOMC's occasional efforts to reduce inflation in the 1970s were ineffective partly due to the expectation that it ultimately wouldn't do enough.\n\nBy contrast, most of you probably know about the Federal Reserve's successful inflation fighting in the early 1980s. The FOMC raised the federal funds rate very high, causing a deep recession but also convincing the public that it was committed to low and stable inflation. Anchoring inflation expectations at low levels helped ensure that jumps in commodity prices or other supply shocks would not generate persistent inflation problems. This was illustrated by the effect of another escalation in oil prices starting in 2005. Unlike in the 1970s, these price shocks did not result in a broad and lasting increase in overall inflation because the public believed the Federal Reserve would keep inflation in check. The FOMC wasn't forced to raise interest rates--which softened the blow of higher fuel costs on households and businesses--because of the credibility the Federal Reserve had built since the 1980s.\n\nIf the public's expectations have always been important, you might wonder how monetary policy had any effect prior to the transparency revolution. As it turns out, with the notable exception of the late 1960s and 1970s, the FOMC usually responded in a systematic way to economic conditions. In 1993, economist John Taylor documented that FOMC policy changes since the mid-1980s had fairly reliably followed a simple rule based on inflation and output. Changes in the federal funds rate were usually made in several small steps over a number of months. In practice, the Federal Reserve's approach was \"never explain, but behave predictably.\"\n\nA close analysis of the FOMC's past behavior was a good guide to future policy, but it had two shortcomings as a substitute for transparency: First, it gave an advantage to sophisticated players who studied the FOMC's behavior--something that is arguably inappropriate for a government institution. Second, while a policy rule such as the one developed by John Taylor explained the course of the federal funds rate much of the time, there were cases when it didn't and when even the experts failed to correctly anticipate the FOMC's actions.\n\nThe trend toward greater transparency accelerated during the early 2000s. Starting in 2000, the FOMC issued information after every meeting about its economic outlook. It also provided an assessment of the balance of risks to the economy and whether it was leaning toward increasing or decreasing the federal funds rate in the future. Such information about intentions and expectations for the future, known as forward guidance, became crucial in 2003, when the Committee was faced with a stubbornly weak recovery from the 2001 recession. It had cut the federal funds rate to the very low level of 1 percent, but unemployment remained elevated, and the FOMC sought some further way to stimulate the economy. In this situation, it told the public that it intended to keep the federal funds rate low for longer than might have been expected by adding to its statement that \"[i]n these circumstances, the Committee believes that policy accommodation can be maintained for a considerable period.\"6 \n\nLet's pause here and note what this moment represented. For the first time, the Committee was using communication--mere words--as its primary monetary policy tool. Until then, it was probably common to think of communication about future policy as something that supplemented the setting of the federal funds rate. In this case, communication was an independent and effective tool for influencing the economy. The FOMC had journeyed from \"never explain\" to a point where sometimes the explanation is the policy.\n\nBy the eve of the recent financial crisis, it was established that the FOMC could not simply rely on its record of systematic behavior as a substitute for communication--especially under unusual circumstances, for which history had little to teach. I think we're all fortunate that policymakers had learned this lesson, because the FOMC was about to encounter unprecedented economic conditions and policy challenges. The financial crisis and its aftermath demanded advances in FOMC communication as great as any that had come before.\n\nMonetary Policy since the Onset of the Financial Crisis \nThe situation in 2008 and 2009 was like nothing the Federal Reserve had faced since the 1930s. In late 2008, the FOMC cut the federal funds rate nearly to zero--essentially, as low as it could go--where it has remained. With its traditional tool for expansionary monetary policy--lowering the federal funds rate--off the table, the FOMC turned to unconventional and, in some cases, newly invented policy options to try both to help stabilize the financial system and to arrest the plunge in economic activity. The public had grown accustomed to monetary policy that focused on changes to the federal funds rate target, with occasional, and at this point fairly limited, guidance that a particular policy stance would probably last for a while. Beyond the task of describing the new policies, extensive new communication was needed to justify these unconventional policy actions and convincingly connect them to the Federal Reserve's employment and inflation objectives.\n\nThe best known of these unconventional policies is large-scale asset purchases, commonly known as quantitative easing. Starting in late 2008 and continuing through today, the Federal Reserve has purchased longer-term government agency debt securities, agency-guaranteed mortgage-backed securities, and longer-term Treasury securities that have added about $2.5 trillion to its assets. These purchases were intended to, and I believe have, succeeded in significantly lowering longer-term interest rates and raising asset prices to help further the Federal Reserve's economic objectives. This is an easing of monetary policy, also known as accommodation, beyond what is provided by maintaining the federal funds rate close to zero.\n\nIt is important to emphasize that the effects of asset purchases also depend on expectations. If the FOMC buys, say, $10 billion in longer-term securities today but is expected to sell them tomorrow or very shortly, there will be little effect on the economy. Current research suggests that the effects of asset purchases today depend on expectations of the total value of securities the FOMC intends to buy and on expectations of how long the FOMC intends to hold those securities. To make these asset purchases as effective as possible in adding accommodation, the FOMC, therefore, needs to communicate the intended path of Federal Reserve securities holdings years into the future. I will return in a moment to current and possible future ways in which the FOMC does and might communicate this information.\n\nThe other unconventional policy designed to contribute to monetary easing was almost purely communication--enhanced forward guidance about how long the Committee expects to maintain the federal funds rate near zero. The situation in early 2009 was similar to 2003 but even more challenging, because in that earlier episode, the FOMC at least retained the option of a further reduction in the federal funds rate target. In 2009, communication about the future path of the federal funds rate was the only option.\n\nInitially, the forward guidance was simple and familiar: The FOMC statement noted that \"economic conditions are likely to warrant exceptionally low levels of the federal funds rate for an extended period.\"7 The Committee enhanced its forward guidance in August 2011, when it substituted \"at least through mid-2013\" for the words \"an extended period.\"8 This date was moved into the future several times, most recently last September, when it was shifted to mid-2015.9 \n\nThis \"calendar guidance\" was an advance over the indefinite \"extended period,\" but it suffered from an important limitation. The date failed to provide the public with a clear understanding of what conditions the FOMC was trying to achieve or the economic conditions that would warrant a continuation of the policy. As a consequence, it was hard for the public to tell whether a change in the calendar date reflected a shift in policy or a change in the Committee's economic forecast.\n\nTo help provide greater clarity about the Committee's objectives, in January 2012, the FOMC adopted and released a statement of its longer-run goals and monetary policy strategy.10 This statement laid out, for the first time, the rates of inflation and unemployment that the FOMC considers consistent with the dual mandate. Specifically, it stated that the longer-run inflation goal most consistent with the FOMC's price stability mandate is 2 percent, and that the central tendency of FOMC participants' estimates of the longer-run normal rate of unemployment ranged from 5.2 to 6 percent.\n\nAs the statement also made clear, economic developments may cause inflation and unemployment to temporarily move away from the objectives, and the Committee will use a balanced approach to return both, over time, to the longer-run goals. On the one hand, for example, the current rate of unemployment, at 7.7 percent, is far above the 5.2 to 6 percent range in the statement and is expected to decline only gradually. Inflation, on the other hand, has been running at or below 2 percent and is expected to remain at similar levels for several years. In this circumstance, both legs of the dual mandate call for a highly accommodative monetary policy. With unemployment so far from its longer-run normal level, I believe progress on reducing unemployment should take center stage for the FOMC, even if maintaining that progress might result in inflation slightly and temporarily exceeding 2 percent. The Committee reaffirmed this statement in January 2013, and I expect it to remain a valuable roadmap for many years to come, indicating how monetary policy will respond to changes in economic conditions.11 \n\nMeanwhile, the FOMC has continued to enhance its communication about how it would use the federal funds rate to return inflation and unemployment to its longer-run objectives. Last December, the Committee replaced its calendar guidance for the federal funds rate with quantitative measures of economic conditions that would warrant continuing that rate at its current very low level. Specifically, the Committee said it anticipates that exceptionally low levels for the federal funds rate will be appropriate \"at least as long as the unemployment rate remains above 6-1/2 percent, inflation between one and two years ahead is projected to be no more than a half percentage point above the Committee's 2 percent longer-run goal, and longer-term inflation expectations continue to be well anchored.\"12 \n\nI consider these thresholds for possible action a major improvement in forward guidance. They provide much more information than before about the conditions that are likely to prevail when the FOMC decides to raise the federal funds rate. As for the date at which tightening of monetary policy is likely to occur, market participants, armed with this new information about the Committee's \"reaction function,\" can form their own judgment and alter their expectations on timing as new information accrues over time.\n\nThese thresholds will, as a consequence, allow private-sector expectations of the federal funds rate to fulfill an important \"automatic stabilizer\" function for the economy. If the recovery is stronger than expected, the public should anticipate that one or both of the threshold values will be crossed sooner and, hence, that the federal funds rate could be raised earlier. Conversely, if the outlook for the economy unexpectedly worsens, the public should expect a later \"liftoff\" in rates--an expectation that would reduce longer-term interest rates and thereby provide more-accommodative financial conditions.\n\nCommunication and Monetary Policy Challenges Ahead \nThe threshold guidance for the federal funds rate looks ahead to a time when the economy has healed from the worst effects of the financial crisis. Getting back to more normal economic conditions will allow for a more normal approach to monetary policy. I look forward to the day when we can put away our unconventional tools and return to what now seems like the relatively straightforward challenge of setting the federal funds rate.\n\nAt some point it will be appropriate to cease adding to accommodation and, later, to begin the process of withdrawing the significant accommodation required by the extraordinary conditions caused by the financial crisis. I believe that, once again, communication will play a central role in managing this transition.\n\nLet me start with our current program of asset purchases, which was launched in September 2012 and revised in December. Notably, the FOMC has described this program in terms of a monthly pace of purchases rather than as a total amount of expected purchases. The Committee has indicated that it will continue purchases until the outlook for the labor market has improved substantially in a context of price stability. In its most recent statement, the FOMC also indicated that the pace and composition of the purchases may be adjusted based on the likely efficacy and costs of such purchases, as well as the extent of progress toward the Federal Reserve's economic objectives.13 In my view, adjusting the pace of asset purchases in response to the evolution of the outlook for the labor market will provide the public with information regarding the Committee's intentions and should reduce the risk of misunderstanding and market disruption as the conclusion of the program draws closer.\n\nThe Federal Reserve's ongoing asset purchases continually add to the accommodation that the Federal Reserve is providing to help strengthen the economy. An end to those purchases means that the FOMC has ceased augmenting that support, not that it is withdrawing accommodation. When and how to begin actually removing the significant accommodation provided by the Federal Reserve's large holdings of longer-term securities is a separate matter. In its March statement, the FOMC reaffirmed its expectation that a highly accommodative stance of monetary policy will remain appropriate for a considerable time after the current asset purchase program ends and the economic recovery has strengthened.14 Accordingly, there will likely be a substantial period after asset purchases conclude but before the FOMC starts removing accommodation by reducing asset holdings or raising the federal funds rate.\n\nTo guide expectations concerning the process of normalizing the size and composition of the Federal Reserve's balance sheet, at its June 2011 meeting, the FOMC laid out what it called \"exit principles.\" In these principles, the FOMC indicated that asset sales would likely follow liftoff of the federal funds rate. It also noted that, in order to minimize the risk of market disruption, the pace of asset sales during this process could be adjusted up or down in response to changes in either the economic outlook or financial conditions. For example, changes in the pace or timing of asset sales might be warranted by concerns over market functioning or excessive volatility in bond markets. While normalization of the Federal Reserve's portfolio is still well in the future, the FOMC is committed to clear communication about the likely path of the balance sheet.\n\nThere will come a time when the FOMC begins the process of returning the federal funds rate to a more normal level. In their individual projections submitted for the March FOMC meeting, 13 of the 19 FOMC participants saw the first increase in the target for the federal funds rate as most likely to occur in 2015, and another expected it to occur in 2016. But the course of the economy is uncertain, and the Committee added the thresholds for unemployment and inflation, in part, to help guide the public if economic developments warrant liftoff sooner or later than expected. As the time of the first increase in the federal funds rate moves closer, in my view it will be increasingly important for the Committee to clearly communicate about how the federal funds rate target will be adjusted.\n\nI hope I've been able today to convey the vital role that communication plays in the Federal Reserve's efforts to promote maximum employment and stable prices. Communication became even more significant after the onset of the financial crisis when the FOMC turned to unconventional policy tools that relied heavily on communication. Better times and a transition away from unconventional policies may make monetary policy less reliant on communication. But I hope and trust that the days of \"never explain, never excuse\" are gone for good, and that the Federal Reserve continues to reap the benefits of clearly explaining its actions to the public. I believe further improvements in the FOMC's communication are possible, and I expect they will continue.\n\nIt has been my privilege to share these thoughts with you. Thank you for inviting me here today.\n\n \n\n1. I am indebted to members of the Board staff--Jon Faust, Thomas Laubach, and John Maggs--who contributed to the preparation of these remarks. Return to text\n\n2. Like almost every government policy action, this hypothetical road project could affect expectations--it might influence decisions about where people live or commercial development, for example. The crucial difference is that these are not the primary and stated aim of this policy action, which is to reduce traffic congestion. As these remarks go on to explain, unlike most government policy actions, monetary policy is primarily concerned with affecting expectations of the future. Return to text\n\n3. See Janet L. Yellen (2012), \"Revolution and Evolution in Central Bank Communications,\" speech delivered at the Haas School of Business, University of California, Berkeley, November 13. Return to text\n\n4. Previously, the public inferred policy changes by observing the Federal Reserve's behavior in securities markets. Return to text\n\n5. Another factor that adds to the importance of expectations is that changes in monetary policy affect real activity and inflation with a substantial time lag. Return to text\n\n6. See Board of Governors of the Federal Reserve System (2003), \"FOMC Statement,\" press release, August 12. Return to text\n\n7. See Board of Governors of the Federal Reserve System (2009), \"FOMC Statement,\" press release, March 18. Return to text\n\n8. See Board of Governors of the Federal Reserve System (2011), \"FOMC Statement,\" press release, August 9. Return to text\n\n9. See Board of Governors of the Federal Reserve System (2012), \"Federal Reserve Issues FOMC Statement,\" press release, September 13. Return to text\n\n10. See Board of Governors of the Federal Reserve System (2012), \"Federal Reserve Issues FOMC Statement of Longer-Run Goals and Policy Strategy,\" press release, January 25. Return to text\n\n11. See \"Statement on Longer-Run Goals and Monetary Policy Strategy (PDF),\" as amended effective January 29, 2013. Return to text\n\n12. See Board of Governors of the Federal Reserve System (2012), \"Federal Reserve Issues FOMC Statement,\" press release, December 12. Return to text\n\n13. See Board of Governors of the Federal Reserve System (2013), \"Federal Reserve Issues FOMC Statement,\" press release, March 20. Return to text\n\n14. See Board of Governors, \"FOMC Statement,\" March 20, in note 13. Return to text"
    },
    {
        "title": "Financial and Economic Education",
        "date": "April 04, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/20130404a.htm",
        "content": "April 04, 2013\n\nChairman Ben S. Bernanke\n\nAt the 13th Annual Redefining Investment Strategy Education (RISE) Forum, Dayton, Ohio (via prerecorded video)\n\nHello. I'm Ben Bernanke, Chairman of the Board of Governors of the Federal Reserve System. I appreciate this opportunity to speak to the business and finance students and faculty--as well as the practicing financial professionals--attending the University of Dayton's 13th annual RISE forum.1 Before I became Chairman, I had the pleasure of addressing the 5th annual forum as a member of the Board of Governors in 2005.2 At that time, I spoke about the implementation of monetary policy and how crucial effective communication is to that implementation.\n\nAlthough I cannot join you in person this year, I note from the conference agenda that you are hearing from two Federal Reserve Bank presidents--Charles Evans of Chicago and Dennis Lockhart of Atlanta--as well as former Federal Reserve Board Vice Chairman Roger Ferguson. Effective communication in monetary policy is more important than ever, and I have little doubt that my current and former colleagues will provide you with insights about the Federal Reserve's ongoing efforts to achieve the goals that the Congress has given us: maximum employment and price stability.\n\nIn my brief remarks today, I would like to mention another important mission of the Federal Reserve--promoting economic and financial knowledge among people of all ages and walks of life. The Board in Washington and the 12 Federal Reserve Banks throughout the country are all deeply involved in economic education and supporting the work of teachers, schools, and national organizations. For example, the Federal Reserve provides a financial and economic education website with a variety of resources for teachers as well as for students of various ages and levels of knowledge.3 The site offers educational games, classroom lesson plans, online publications, and multimedia tools. Federal Reserve Banks offer professional development opportunities for teachers to improve their ability to present lessons on personal finance topics. A number of Reserve Banks also organize personal finance essay, video, and academic competitions for students. And we encourage students and teachers to visit Federal Reserve Bank learning centers and museums, which feature interactive exhibits about many aspects of banking, the financial system, and the economy.\n\nAmong the lessons of the recent financial crisis is the need for virtually everyone--both young and old--to acquire a basic knowledge of finance and economics. Such knowledge is necessary for anyone who will be faced with managing a household budget, making financial investments, finding reliable information about buying a car or house, and preparing financially for retirement and other life goals. Accordingly, in addition to ensuring that students graduate with the financial literacy skills they need to navigate in the modern financial world, we, as a society, must also make sure that adults have opportunities to gain these skills or to refresh what they have learned. Many of you are, or will be, practitioners in the financial services industry--perhaps serving retail clients--and in that capacity I hope you will make the promotion of financial and economic education a part of your mission as well. These skills not only help people provide a better life for themselves and their families, but, by deepening their understanding of the world economy, having such skills also helps equip them to be engaged citizens and informed voters.\n\nLet me close by congratulating the University of Dayton for its leadership in hosting the RISE forum. I hope this innovative program, which I'm told is the world's largest student investment conference, succeeds in its ambitious goal of bringing together the current and future leaders of finance to focus on creating a better economic future.\n\n \n\n1. RISE is Redefining Investment Strategy Education. For more information, see www.udayton.edu/business/rise . Return to text\n\n2. See Ben S. Bernanke (2005), \"Remarks by Governor Ben S. Bernanke,\" speech delivered at the Redefining Investment Strategy Education Symposium, Dayton, Ohio, March 30. Return to text\n\n3. See the Federal Reserve Education website, www.federalreserveeducation.org . Return to text"
    },
    {
        "title": "Stress Testing Banks: What Have We Learned?",
        "date": "April 08, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20130408a.htm",
        "content": "April 08, 2013\n\nChairman Ben S. Bernanke\n\nAt the \"Maintaining Financial Stability: Holding a Tiger by the Tail\" financial markets conference sponsored by the Federal Reserve Bank of Atlanta, Stone Mountain, Georgia\n\nLet me begin by thanking President Lockhart and the organizers of the Financial Markets Conference for inviting me to speak here again this year. I have participated regularly in this conference and have always found it stimulating.\n\nFour years ago, in remarks at this very conference, I described the 2009 Supervisory Capital Assessment Program, or SCAP, popularly known as the bank stress tests.1 The SCAP marked the first time the U.S. bank regulatory agencies had conducted a supervisory stress test simultaneously across the largest banking firms.2 At the time of my 2009 speech, we had just published the results of the SCAP and were still evaluating its effects. In retrospect, the SCAP stands out for me as one of the critical turning points in the financial crisis. It provided anxious investors with something they craved: credible information about prospective losses at banks. Supervisors' public disclosure of the stress test results helped restore confidence in the banking system and enabled its successful recapitalization. The resilience of the U.S. banking system has greatly improved since then, and the more intensive use and greater sophistication of supervisory stress testing, as well as supervisors' increased emphasis on the effectiveness of banks' own capital planning processes, deserve some credit for that improvement.\n\nI will begin today with a brief discussion of the state of U.S. banking. I will then turn to the subject of what we have learned about stress testing in the four years since the SCAP, with a focus on the increasingly central role it is playing in bank supervision in the United States. Importantly, as I will elaborate, stress testing adds a macroprudential dimension to our supervision by helping us evaluate the aggregate capital position of the largest banking firms as well as their individual capital levels.\n\nThe Federal Reserve--like all bureaucracies--has an unfortunate tendency to create acronyms, so, before I proceed further, let me explain our acronyms, in addition to SCAP, for stress tests. With the SCAP now in the past, we currently have two distinct but related supervisory programs that rely on stress testing. The first is the stress testing required by the Dodd-Frank Act, which we have shortened to the acronym DFAST--the Dodd-Frank Act stress tests. The purpose of DFAST is to quantitatively assess how bank capital levels would fare in stressful economic and financial scenarios. The second program, called the Comprehensive Capital Analysis and Review, or CCAR, combines the quantitative results from the stress tests with more-qualitative assessments of the capital planning processes used by banks. For example, under CCAR, supervisors evaluate the ability of banks to model losses for various categories of loans and securities and to estimate earnings and capital requirements in alternative scenarios. We recently completed the first set of DFAST stress tests and disclosed the results, followed a week later by the disclosure of our CCAR findings, which included our qualitative assessments of firms' capital planning.3 \n\nThe State of the Banking System, Then and Now\nTo provide context for the developments in the banking system since the introduction of the SCAP in early 2009, it's worth briefly recalling the economic situation that prevailed at that time. The economy was in deep recession, with the unemployment rate having risen 4 percentage points, from 5 percent to 9 percent, over the preceding 12 months. The prices of real estate and equities had plummeted, interest rate spreads--such as the spread between rates on mortgages and Treasury securities--had widened to unprecedented levels, and securitization markets had frozen. Write-downs and losses continued to deplete banks' capital, unnerving investors and counterparties and exacerbating the severe funding pressures faced by many institutions. In the face of this instability, in 2008 and 2009 policymakers had taken a range of extraordinary measures: The Federal Reserve supplied liquidity to banks and other financial institutions, helping to calm the panic and begin the process of restoring the flow of credit to households and businesses; the Treasury Department guaranteed money market funds and injected capital into banks under the Troubled Asset Relief Program; the Congress expanded deposit insurance under the Federal Deposit Insurance Corporation (FDIC); and the FDIC guaranteed banks' issuance of long-term debt. And, as I noted, the SCAP helped to increase confidence in the banking system and restore banks' access to private capital markets. Ten of the 19 large bank holding companies that underwent the SCAP were required to raise equity capital--by $75 billion in total.\n\nToday the economy is significantly stronger than it was four years ago, although conditions are clearly still far from where we would all like them to be. Because bank credit for households and businesses is critical to continued economic expansion, it is positive for the recovery that banks are also notably stronger than they were a few years ago. For example, premiums on bank credit default swaps have fallen by more than half of their 2009 levels, and other measures of bank risk have also declined substantially. More than 90 percent of the public capital injections that were used to stabilize the banking system have been repaid, and the Federal Reserve's extraordinary liquidity programs and the FDIC's temporary guarantees for uninsured business deposits and bond issues have largely been wound down.\n\nThe results of the most recent stress tests and capital planning evaluations continue to reflect improvement in banks' condition. For example, projected aggregate loan losses under this year's most stressful scenario (the so-called severely adverse scenario) were 7 percent lower than the comparable figure last year, in part because the riskiness of banks' portfolios continues to decline. The comparison of today's bank capital levels with those at the time of the SCAP is particularly striking. Over the past four years, the aggregate tier 1 common equity ratio of the 18 firms that underwent the recent tests has more than doubled, from 5.6 percent of risk-weighted assets at the end of 2008 to 11.3 percent at the end of 2012--in absolute terms, a net gain of nearly $400 billion in tier 1 common equity, to almost $800 billion at the end of 2012. Indeed, even under the severely adverse scenario of the latest stress test, the estimate of these firms' post-stress tier 1 common capital ratio is more than 2 percentage points higher than actual capital levels at the end of 2008.4 Higher capital puts these firms in a much better position to absorb future losses while continuing to fulfill their vital role in the economy. In addition, a majority of the 18 CCAR firms already meet new internationally agreed-upon capital standards (the proposed Basel III capital requirements), and the others are on track to meet these requirements as they are phased in over time.\n\nAlthough the stress tests focus on the largest banks, the medium-sized and smaller banks outside of the 18 CCAR firms have also improved their aggregate capital position considerably since the SCAP. For that group of banks, aggregate tier 1 common equity stood at 12.4 percent of risk-weighted assets in the fourth quarter of 2012, more than 4 percentage points higher than at the end of 2008.\n\nAnother key lesson of the crisis, given the intense funding pressures experienced by many financial institutions during the period, is the importance of maintaining adequate liquidity--that is, a stock of cash and unencumbered high-quality liquid assets that can be converted easily into cash. Here too, the news is mostly positive, as the broader banking system--including both larger and smaller banks--has generally improved its liquidity position relative to pre-crisis levels. For example, banks' holdings of cash and high-quality liquid securities have more than doubled since the end of 2007 and now total more than $2.5 trillion. However, in the area of liquidity and funding, continued improvement is still needed on some dimensions. Notably, supervisors will continue to press banks to reduce further their dependence on wholesale funding, which proved highly unreliable during the crisis. And, in analogy to the need for effective capital planning, banks of all sizes need to further strengthen their ability to identify, quantify, and manage their liquidity risks.\n\nThe Evolution of Stress Testing\nLet me turn now to the evolution of stress testing as a supervisory tool. The main benefits of stress tests for supervision have not changed much since the SCAP was conducted in 2009. First, stress tests complement standard capital ratios by adding a more forward-looking perspective and by being more oriented toward protection against so-called tail risks; by design, stress tests help ensure that banks will have enough capital to keep lending even under highly adverse circumstances. Second, as applied by the Federal Reserve, the stress tests look horizontally across banks rather than at a single bank in isolation. This comparative approach promotes more-consistent supervisory standards. It also provides valuable systemic information by revealing how significant economic or financial shocks would affect the largest banks collectively as well as individually. Third, the disclosures of stress test results promote transparency by providing the public consistent and comparable information about banks' financial conditions.\n\nThe basic methodology of our stress testing has also not changed materially since the SCAP. We continue to take a multidisciplinary approach, drawing on a wide range of staff expertise. To begin the process, our economists create a hypothetical macroeconomic scenario that incorporates an assumed sharp deterioration in economic and financial conditions. Supervisors estimate each bank's expected losses and revenues and we use these estimates to project post-stress capital levels and ratios under that hypothetical scenario. The estimated capital ratios are then compared with regulatory benchmarks. We use a common scenario for all firms; for the firms with the largest trading activities, we supplement the basic scenario with a market-shock scenario that incorporates market turbulence of severity similar to that of the latter half of 2008.\n\nAlthough the basic goals and approach of stress testing have remained largely unchanged since the SCAP, the implementation has evolved and improved from year to year. For example, we have continued to refine the formulation of the hypothetical scenarios that form the basis of the stress tests. As explained in a statement we released in the fall, the severely adverse scenario is designed to reflect, at a minimum, the economic and financial conditions typical of a severe post-World War II U.S. recession.5 In devising recession scenarios, we draw on many of the same macroeconomic modeling tools used in making monetary policy. Of course, not all significant risks facing banks are tied to the business cycle. Accordingly, our scenarios now generally incorporate not only the typical consequences of a severe recession but also, simultaneously, other adverse developments such as an exceptionally large decline in house prices, sharp drops in the value of stocks and other financial assets, or a worsening of global economic conditions more severe than might normally be expected to accompany a deep recession in the United States.\n\nImportantly, in specifying the severely adverse scenario, we seek to avoid adding to the procyclicality of the financial system.In other words, in applying stress tests, we do not want to inadvertently set a standard that is easier to meet in good times (when banks should be preparing for possibly tougher times ahead) than in bad times (when banks need to be able to use accumulated capital to support lending). Accordingly, we will want to ensure that the stress scenario remains severe in an absolute sense even when the economy is strong and the near-term risks to the outlook seem relatively modest.\n\nWe have also improved our tools for estimating projected bank losses, revenues, and capital under alternative scenarios. The original SCAP was supervisors' first attempt to produce comprehensive and simultaneous estimates of the financial conditions of the nation's largest banking firms, and the required data and analytical methods were developed under great time pressure. Of necessity, when projecting losses and revenues under alternative SCAP scenarios, supervisors relied on the firms' own estimates as a starting point. Although we scrutinized and questioned the firms' estimates and made significant adjustments based on our own analysis, for that inaugural round of stress tests, it was not possible to produce completely independent estimates.\n\nHowever, over the past four years, considerable progress has been made in data collection and in the development of independent supervisory models. For our most recent supervisory stress tests, we collected and analyzed loan- and account-level data on more than two-thirds of the $4.2 trillion in accrual loans and leases projected to be held by the 18 firms we evaluated this year. Those detailed data include borrower, loan, and collateral information on more than 350 million domestic retail loans, including credit cards and mortgages, and more than 200,000 commercial loans. Currently, the Federal Reserve uses more than 40 models to project how categories of bank losses and revenues would likely respond in hypothetical scenarios. The improvements in data and models have increased our ability to distinguish risks within portfolios. Importantly, these supervisory models are evaluated by a special model validation group made up of experts within the Federal Reserve who do not work on the stress tests. We have also created a Model Validation Council made up of external experts to provide independent views and advice.6 These ongoing efforts are bringing us close to the point at which we will be able to estimate, in a fully independent way, how each firm's loss, revenue, and capital ratio would likely respond in any specified scenario.\n\nAnother innovation since the SCAP is the increased supervisory focus on banks' internal capital planning practices, which are reviewed as part of CCAR. We see the requirement that banks with assets of $50 billion or more submit annual capital plans to the Federal Reserve as a critical enhancement.7 While regulatory minimums and supervisory expectations provide floors for acceptable capital levels, the firms and their boards of directors are responsible for assessing their own capital needs over and above the minimums. Our supervisors scrutinize their practices and assess their capacity to fulfill that responsibility. In particular, we require firms to formulate their own scenarios that capture the risks that they face, and to assess potential losses and revenues under both the supervisory scenarios and their internal scenarios over a nine-quarter horizon. In CCAR, our qualitative assessment of a firm's capital planning is integrated with the quantitative results of both the supervisory and company-run stress tests.\n\nThe Federal Reserve continues to increase the transparency of our stress testing process, the results of the exercises, and our assessments of banks' capital planning. The original SCAP set a new standard of supervisory transparency in disclosing bank-by-bank estimates of stress losses by type of exposure. This departure from the traditionally confidential treatment of supervisory information, as I noted earlier, was intended to restore public confidence by providing much-needed information about banks' potential losses and capital needs. In last month's results, in addition to projected losses and revenues, we disclosed for the first time whether we had objected to each firm's capital plan.8 Also for the first time, banks were required to disclose their own estimates of stressed losses and revenues. The disclosures by banks give investors and analysts an alternative perspective on the test results; they also help them form judgments about banks' appetites for risk and their risk-management practices, particularly their abilities to measure losses in a severe downturn. Even outside of a period of crisis, the disclosure of stress test results and assessments provides valuable information to market participants and the public, enhances transparency, and promotes market discipline.\n\nIn the four years since the SCAP, the Federal Reserve's stress testing program has been expanded and strengthened through both statute and regulation. The Dodd-Frank Act widened the scope of stress testing to all bank holding companies with $50 billion or more in total consolidated assets (approximately 11 companies in addition to the original SCAP participants) and to nonbank financial companies designated by the Financial Stability Oversight Council as systemically important, and therefore subject to consolidated supervision by the Federal Reserve. Dodd-Frank also requires these companies to conduct their own stress tests twice a year. In October, the Federal Reserve Board adopted rules implementing these requirements.9 The 11 additional companies with assets of $50 billion or more will be subject to DFAST and CCAR for the first time next year.\n\nWhile no institutions below $50 billion in assets are subject to supervisory stress testing or the requirements of CCAR, the Dodd-Frank Act does require that institutions with between $10 billion and $50 billion in assets conduct their own stress tests.10 The initial tests by these firms will begin this year and will be completed by March. While we believe that stress testing will help medium-sized institutions better understand the risks they face, we tailored our rule for these institutions to take account of differences in size, complexity, and business models. We specifically exempted community banking organizations with $10 billion or less in total assets from the requirement that they run their own stress tests as those institutions cannot reasonably be expected to have the resources that larger banks devote to stress testing.11 \n\nBenefits and Challenges of Stress Testing\nAs already noted, stress testing has a number of important benefits as a supervisory tool. From a microprudential perspective, the CCAR provides a structured means for supervisors to assess not only whether banks hold enough capital, but also whether banks are able to rapidly and accurately determine their risk exposures, an essential element of effective risk management. The cross-firm nature of the stress tests also helps supervisors identify outliers--both in terms of results and practices--that can provide a basis for further, more targeted reviews.\n\nFrom a macroprudential perspective, the use of a common scenario allows us to learn how a particular risk or combination of risks might affect the banking system as a whole‑‑not just individual institutions. This experience with stress testing has indeed been very useful for our efforts to better monitor and evaluate potential systemic risks. For example, in our macroprudential work, as in our stress tests, we tend to rely on horizontal examinations and comparative studies, as opposed to firm-by-firm assessments; we use multidisciplinary, specialized teams to supplement the work of on-site examiners; and we have increased our use of modeling and quantitative methods, using data drawn from different institutions and time periods. All of these features are apparent in the workings of our Large Institution Supervision Coordinating Committee, which provides coordinated oversight of the supervision of systemically important firms. We have also extended the lessons of systemwide stress testing to analysis of factors other than capital: For example, we recently completed a horizontal review of liquidity positions and liquidity risk-management practices at some of the largest CCAR firms. Like the CCAR review of capital planning, this review was a multidisciplinary effort that used quantitative information--in this case, detailed data on firms' liquidity positions--as well as qualitative information on liquidity risk-management practices.\n\nNotwithstanding the demonstrated benefits of comprehensive stress testing, this evolving tool also presents challenges. For example, even as we continue to explore ways to enhance the transparency of the models we use to estimate banks' projected revenues and losses, we have chosen not to publish the full specification of these models. As a result, we hear criticism from bankers that our models are a \"black box,\" which frustrates their efforts to anticipate our supervisory findings. We agree that banks should understand in general terms how the supervisory models work, and, even more importantly, they need to be confident that our models are empirically validated and sound. I mentioned our internal efforts at model validation, which have increased the quality and accuracy of our models. We have also begun to host an annual stress test modeling symposium, which provides a venue for regulators, bankers, academics, and others to share their views. Over time, we expect banks to better understand the basic elements of the supervisory models, rendering them at least somewhat less opaque.\n\nAt the same time, it is reasonable to worry that, with increased disclosure of supervisory models, firms would see a declining benefit to maintaining independent risk-management systems and would just adopt supervisory models instead. Doing so would certainly make it easier to \"pass\" the stress tests. However, all models have their blind spots, and such an outcome risks a \"model monoculture\" that would be susceptible to a single, common failure. The differences in stress test results obtained by supervisors' and banks' own models can be informative, and we do not want inadvertently to destroy the healthy diversity or innovation of the models and other risk-management tools used in the banking industry.\n\nAnother challenge is that our stress scenarios cannot encompass all of the risks that banks might face. For example, although some operational risk losses, such as expenses for mortgage put-backs, are incorporated in our stress test estimates, banks may face operational, legal, and other risks that are specific to their company or are otherwise difficult to estimate. It is important for banking firms to consider the potential for losses from these other classes of risks as systematically as possible, and supervisors also account for these risks as best they can. Of course, unforeseen events are inevitable, which is why maintaining a healthy level of capital is essential.\n\nConclusion\nAs I have discussed today, the banking system is much stronger since the implementation of the SCAP four years ago, which in turn has contributed to the improvement in the overall economy. The use of supervisory stress tests--a practice now codified in statute--has helped foster these gains. Methodologically, stress tests are forward looking and focus on unlikely but plausible risks, as opposed to \"normal\" risks. Consequently, they complement more conventional capital and leverage ratios. The disclosure of the results of supervisory stress tests, coupled with firms' disclosures of their own stress test results, provide market participants deeper insight not only into the financial strength of each bank but also into the quality of its risk management and capital planning. Stress testing is also proving highly complementary to supervisors' monitoring and analysis of potential systemic risks. We will continue to make refinements to our implementation of stress testing and our CCAR process as we learn from experience.\n\nAs I have noted, one of the most important aspects of regular stress testing is that it forces banks (and their supervisors) to develop the capacity to quickly and accurately assess the enterprise-wide exposures of their institutions to diverse risks, and to use that information routinely to help ensure that they maintain adequate capital and liquidity. The development and ongoing refinement of that risk-management capacity is itself critical for protecting individual banks and the banking system, upon which the health of our economy depends.\n\n \n\n1. See Ben S. Bernanke (2009), \"The Supervisory Capital Assessment Program,\" speech delivered at \"Financial Innovation and Crises,\" a financial markets conference sponsored by the Federal Reserve Bank of Atlanta, held in Jekyll Island, Ga., May 11-13. Return to text\n\n2. For more information about the SCAP exercise, see the Board's website at www.federalreserve.gov/bankinforeg/scap.htm. Return to text\n\n3. See Board of Governors of the Federal Reserve System (2013), \"Federal Reserve Releases Summary Results of Bank Stress Tests,\" press release, March 7; and Board of Governors of the Federal Reserve System (2013), \"Federal Reserve Announces Results of Comprehensive Capital Analysis and Review (CCAR),\" press release, March 14. Return to text\n\n4. On an individual firm basis and taking into consideration planned capital actions--that is, capital raises or distributions--all but 1 of the 18 firms evaluated this year had post-stress capital ratios above the regulatory minimum. Return to text\n\n5. See the proposed \"Policy Statement on the Scenario Design Framework for Stress Testing (PDF)\" of the Board of Governors of the Federal Reserve System (Nov. 15, 2012). Return to text\n\n6. See Board of Governors of the Federal Reserve System (2013), Dodd-Frank Act Stress Test 2013: Supervisory Stress Test Methodology and Results (PDF), Appendix B: Models to Project Net Income and Stressed Capital (Washington: Board of Governors, March), pp. 37-47; and Board of Governors of the Federal Reserve System (2012), \"Federal Reserve Announces the Formation of the Model Validation Council,\" press release, April 20. Return to text\n\n7. A capital plan describes a firm's capital planning strategies and its processes for measuring potential capital needs both under expected and stressed operating environments and for ensuring that it is holding adequate capital to be able to continue to function even under stress. See Board of Governors of the Federal Reserve System (2011), \"Capital Plans,\" final rule (Docket No. R‑1425), Federal Register, vol. 76 (December 1), pp. 74631-48. Return to text\n\n8. See Board of Governors, \"Federal Reserve Announces Results of CCAR,\" in note 3. Return to text\n\n9. See Board of Governors of the Federal Reserve System (2012), \"Supervisory and Company-Run Stress Test Requirements for Covered Companies,\" final rule (Docket No. 1438), Federal Register, vol. 77 (October 12), pp. 62377-96. Return to text\n\n10. See Board of Governors of the Federal Reserve System (2012), \"Annual Company-Run Stress Test Requirements for Banking Organizations with Total Consolidated Assets over $10 Billion Other Than Covered Companies,\" final rule (Docket No. 1438), Federal Register, vol. 77 (October 12), pp. 62396-409. Return to text\n\n11. See Board of Governors of the Federal Reserve System, Federal Deposit Insurance Corporation, and Office of the Comptroller of the Currency (2012), \"Agencies Clarify Supervisory Expectations for Stress Testing by Community Banks,\" press release, May 14. Return to text"
    },
    {
        "title": "Creating Resilient Communities",
        "date": "April 12, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20130412a.htm",
        "content": "April 12, 2013\n\nChairman Ben S. Bernanke\n\nAt the \"Resilience and Rebuilding for Low-Income Communities: Research to Inform Policy and Practice\" Federal Reserve System Community Affairs Research Conference, Washington, D.C.\n\nI am pleased to join you for the eighth biennial Federal Reserve System Community Affairs Research Conference. The work you are doing here--sharing research and exchanging ideas on how best to further the development of low-income communities--is vitally important.\n\nAs this year's theme, \"Resilience and Rebuilding,\" reflects, low-income communities were particularly hard hit by the Great Recession.1 And, while employment and housing show signs of improving for the nation as a whole, conditions in lower-income neighborhoods remain difficult by many measures. For example, an analysis by Federal Reserve staff reveals that long-vacant housing units tend to be concentrated in a small number of neighborhoods that also tend to have high unemployment rates, low educational levels, and low median incomes.2 While some of these neighborhoods are in the inner cities, others are in suburbs.\n\nThis analysis and others like it illustrate the close interconnections of housing conditions, educational levels, and unemployment experience within neighborhoods. Moreover, as this work confirms, poverty is no longer primarily an urban phenomenon but has increasingly spread to suburban areas, many of which lack the social and community development services needed to mitigate poverty and its effects.3 The implications of these trends for community development are profound. Successful strategies to rebuild communities cannot focus narrowly on a single problem, such as the physical deterioration of neighborhoods that suffered high rates of foreclosure. Rather, progress will require multipronged approaches that address housing, education, jobs, and quality-of-life issues in a coherent, mutually consistent way. Moreover, strategies will have to be adapted to meet the special circumstances of urban, suburban, and rural settings. As community development researchers and practitioners, you are confronting the challenge of effectively attending to the needs of both individuals and communities--of people as well as places.\n\nThe Evolution of Community Development\nCommunity development has a long history of innovation and learning from experience. Notably, after decades of large-scale, top-down federal efforts, it became increasingly apparent that a one-size-fits-all approach did not serve local communities well. The urban renewal programs of the 1950s and 1960s were perhaps the most prominent examples of well-meaning but misguided efforts to revitalize decaying inner-city neighborhoods. In practice, these policies often devastated neighborhood cohesion, leading their critics to argue for local, bottom-up solutions. Perhaps the most influential critique of urban renewal and top-down planning was Jane Jacobs's 1961 book, Death and Life of Great American Cities.4 In that book she celebrated the complexity and organic development of city neighborhoods in which intricate social networks enhance safety, quality of life, and economic opportunity. In Jacobs's view, a police force was not as effective at maintaining order as a neighborhood filled with \"public actors\" such as storekeepers, doormen, and interested neighbors acting as street watchers at all hours. The development of this sort of community self-monitoring is most likely to emerge, she argued, in neighborhoods with a rich mixture of activities taking place in buildings of varying age, character, and use.\n\nFor the most part, social science research has vindicated Jacobs's perspective. For example, sociologists studying community resilience in the wake of natural disasters mapped deaths caused by an extreme heat wave in Chicago in 1995.5 They found, not surprisingly, that death rates were higher in poor areas where air conditioners were scarce. But they also noticed a remarkable difference in the fatality rate in two adjacent neighborhoods--Englewood and Auburn Grisham--on Chicago's South Side. These neighborhoods were comparable by many measures: Both were 99 percent African American, with similar numbers of elderly residents and comparably high rates of poverty and unemployment. Yet Englewood experienced 33 deaths per 100,000 residents during the heat wave, while Auburn Grisham had among the lowest fatality rates in the city, 3 deaths per 100,000 residents. Researchers found that a key difference between Auburn Grisham and other neighborhoods lay in its physical and social topography--the vitality of its sidewalks, stores, restaurants, and community organizations that brought friends and neighbors together, making it easier for people to look out for each other.\n\nThis example illustrates a point that many community development practitioners have come to embrace: Resilient communities require more than decent housing, important as that is; they require an array of amenities that support the social fabric of the community and build the capabilities of community residents. The movement toward a holistic approach to community development has been long in the making, but the housing crisis has motivated further progress. To be sure, implementing a holistic approach is easier said than done. Government resources are still largely managed in silos, and coordinating government agencies, philanthropy, and the private sector to meet the needs of local communities requires extraordinary commitment and effective leadership. But persistence and effort pay off. The holistic approach has the power to transform neighborhoods and, as a result, the lives of their lower-income residents.\n\nLet me give another example, drawn from the experience of the East Lake neighborhood in Atlanta, a neighborhood that exemplified the effects of concentrated poverty. In the early 1990s, East Lake had a crime rate 18 times higher than the national average. Nearly 60 percent of adults received public assistance, and only 5 percent of fifth grade children were able to meet state academic performance standards. A local philanthropist, Tom Cousins, wanted to improve the quality of life in this neighborhood by de-concentrating its poverty.6 But he understood that East Lake's problems were interconnected: Replacing substandard housing would do little to attract families to the neighborhood if it lacked good schools, but schools couldn't perform well if students feared for their safety, arrived hungry, and were otherwise unprepared or unable to learn. High dropout rates in turn fueled the neighborhood's high rates of unemployment and crime.\n\nTo deal with the interconnectedness of the neighborhood's problems, Cousins determined to attack them simultaneously. He created the East Lake Foundation to facilitate transformative change. The foundation partnered with the Atlanta Housing Authority to replace the neighborhood's low-income housing project with mixed-income housing that accommodated former tenants and other very low-income residents as well as attracting new, higher-income families. An independently operated public charter school for grades kindergarten through 12, named the Drew Charter School, and an early learning center serving 135 children were built. A new YMCA health and fitness center began to provide wellness programs and to serve as a neighborhood gathering place. Finally, the foundation worked to attract commercial investments in the neighborhood, including a grocery store, a bank branch, and restaurants.\n\nCreating this plan and navigating the complex array of interests and resources of the community, the local government, and the private sector took 10 years of effort. But the character of the neighborhood was fundamentally changed. Today crime in East Lake is down by 73 percent, and violent crime is down by 90 percent. The percentage of low-income adults employed has increased from 13 percent to 70 percent, and Drew Charter School moved from last place in performance among 69 Atlanta public schools after its first year of operation to fourth place. With 74 percent of its students receiving free and reduced-price lunches, Drew performs at the same level as public schools in far more affluent areas.7 The educational outcomes alone argue for the wisdom of the holistic approach to community development.\n\nThe success in East Lake raises the question of whether a similar approach can work in other communities. In 2009, Cousins launched a community development organization, Purpose Built Communities, to try to attain the same good outcomes that were achieved in Atlanta in other cities around the country. Experience so far suggests that, while the framework can be replicated, it requires certain neighborhood conditions to succeed. These conditions include (1) housing developments of concentrated poverty, which can feasibly be replaced by good-quality mixed-income housing at sufficient scale to change the housing and income characteristics of the neighborhood; (2) the opportunity to create one or more schools accountable to parents and the community; and (3) civic and business leadership that is prepared to create and support an organization charged with coordinating the necessary partnerships and seeing through the long-term plans.\n\nAs those involved in this effort note, the Purpose Built strategy is quite different from that of most other bodies whose decisions affect community development.8 For example, city governments rarely organize around neighborhoods. School boards, housing authorities, and transit systems all make decisions critical to the health of neighborhoods, but they generally act independently of city government. Moreover, the goals of such bodies are not typically measured in terms of the health of neighborhoods in any holistic sense.\n\nThis mindset may be changing, however. For example, Los Angeles recently adopted a community-based approach to strategic planning. Its five-year consolidated plan recognizes that no single program or effort is likely, on its own, to lift families out of poverty or reduce crime in a neighborhood. Rather, the plan calls for a multifaceted approach to \"build healthy communities by integrating community, economic, and housing development investments with transit opportunities to increase their positive impact on neighborhoods.\"9 It also recognizes the need to build the city's institutional capacity so that it can effectively coordinate these efforts. To that end, the mayor created the Housing and Community Development Cabinet, which is composed of representatives from city departments from housing and transportation to health, family services, and economic development. The cabinet will be responsible for identifying neighborhoods for coordinated investment across sectors.\n\nPerhaps one of the most promising new partners in community development is the health-care sector. Factors such as educational attainment, income, access to healthy food, and the safety of a neighborhood tend to correlate with individual health outcomes in that neighborhood. Because these factors are linked to economic health as well as physical health, health-care professionals and community development organizations are seeing new opportunities for cooperation in low-income communities. For example, public health specialists and housing leaders are working together in Seattle to reduce the incidence in low-income homes of allergens that can cause or aggravate asthma. Because asthma results in a significant loss of school days and billions of dollars in treatment costs, it is easy to see that these efforts have the potential to improve not only health, but educational and economic outcomes as well.10 \n\nBeyond complementary interests with community development organizations, health professionals offer an important set of skills and tools, including unique data sets and sophisticated evaluation techniques. For example, using data from 38 children's hospitals, the Children's Hospital of Philadelphia Research Institute found an association between rates of foreclosures and poor health in children, including the incidence of abuse.11 Health-related philanthropies are also investing in projects in low-income communities, ranging from projects to identify the health ramifications of proposed community improvements to increasing access to fresh food, by creating partnerships to subsidize grocery stores in low-income communities.12 \n\nAccelerating Transformative Development in Communities\nThese examples illustrate the benefits of broad-based collaboration for rejuvenating communities that, in some cases, have been in decline for decades. Research is helping sharpen this approach and give more insight into what works. For example, in 2009, Federal Reserve Bank of Boston researchers evaluated the effects of concentrated poverty in Springfield, Massachusetts, as part of a larger study conducted by the Federal Reserve System. Intrigued by the results, the Boston Fed researchers turned their attention to trying to identify the factors that make it possible for some cities to adjust to changing economic conditions while others languish. To do this, the researchers identified 25 midsize manufacturing cities around the country that were similar to Springfield in 1960, when that city was at the height of its prosperity, and asked what accounted for the differences in the economic trajectories experienced by this group of cities over the past 50 years. Remarkably, their analysis indicated that industry mix, demographic makeup, and geographic location made less difference to success than the presence of a community leader and collaboration around a vision for the future. In some cases, leadership came in the form of an energetic mayor, but not always. In fact, the study found that leadership could come from almost anywhere. The successful leader was simply the person or entity that recognized the importance of preventing further deterioration in the local economy and agreed to take responsibility for the effort to turn things around. The leader helped facilitate local collaboration, which was essential not only because economic development is complicated and multidimensional, but also for the more prosaic reason that outside funders typically require that all interested stakeholders commit to a strategic direction.\n\nThe specific avenues to recovery varied among the resurgent cities identified in the Boston Fed study. Some built on traditional strengths, while others created new business clusters from scratch. For example, Grand Rapids, Michigan, was once known for its furniture manufacturing. As those jobs disappeared, Grand Rapids worked to become a major medical center in the region, partnering with Michigan State University and Grand Valley State University to form the Medical Education and Research Center. Similarly, Jersey City has successfully transformed itself from a manufacturing-based economy to a financial center. Its proximity to New York City makes this transformation seem obvious in hindsight, but other similarly situated cities have not made comparable strides.\n\nMost of the cities in the study made significant investments in infrastructure and people to aid the transition to a knowledge-based economy. For example, Greensboro, North Carolina, worked with the nearby cities of Winston-Salem and High Point to build a regional airport and to replace its manufacturing economy with one based on high-tech research and production. In a common pattern, Greensboro drew on local resources in post-secondary education, with community colleges providing courses to enhance job skills and universities partnering with businesses to develop innovative products--in Greensboro's case, in nanotechnology and pharmaceuticals. In New Haven, Connecticut, local universities collaborate with private industry and local government to support biotech-related education in public schools by providing teacher training, assistance in curriculum design, and a mobile laboratory.\n\nDeveloping Local Leaders\nThese examples show that a city's path to economic recovery typically depends on its ability to draw on its own particular assets. Leaders that recognize the potential of those assets and foster collaboration in exploiting them can help communities remake themselves. The question then becomes how to develop and encourage local leadership. Technical assistance, networking opportunities, and mentoring programs are just some of the ways that leadership can be fostered locally.\n\nBased on its evaluation of Springfield and cities of similar size, the Boston Fed worked with its public, private, and philanthropic partners to come up with an idea to enhance leadership and spur transformative change. The Bank recently announced the Working Cities Challenge, a grant competition for smaller cities in Massachusetts that is designed to foster local collaboration to improve the economic health and well-being of low-income residents. Initiatives winning grants are expected to demonstrate cross-sector collaboration and involve groups that typically do not work together. Prize money is being provided by Living Cities, a national philanthropic collaborative; the Commonwealth of Massachusetts; and the Massachusetts Competitive Partnership; among others. The value of the competition goes beyond grant money, though that undoubtedly will help those who receive it. The real value of the competition is that it will encourage conversations among local stakeholders that are necessary to make real and lasting change. Moreover, participants will receive access to technical assistance and planning resources, as well as to a growing network of public, private, nonprofit, and philanthropic leaders in the state who are focused on improving the economies of its smaller cities.\n\nFor practitioners of community development, as in any field, joining a network of like-minded professionals is important for building skills and becoming aware of opportunities and resources. NeighborWorks America, the leading provider of community development training in the country, has provided management and leadership training for community development professionals for more than 25 years. In the past few years, NeighborWorks has expanded its programs to develop leadership among its network organizations' executive directors and board members. Recognizing that effective board leadership is key to the health and effectiveness of its more than 235 member organizations across the country, NeighborWorks established the Achieving Excellence program in 2002 for its executive directors and others in the organization with significant responsibility. This 18-month program offers professional coaching and an opportunity to work with peers to solve a particular organizational challenge.\n\nNeighborWorks also trains community leaders through the Community Leaders Institute. The institute is an annual event that attracts some 800 resident leaders from across the country, making it the largest residential leadership development initiative in the field. Attendees arrive in teams of eight and choose from more than 40 workshops on topics such as public speaking, planning, youth development, and mobilizing senior citizens. After four days, the teams have not only learned new skills, but they have developed action plans addressing particular issues in their neighborhoods. They are given a $2,000 grant as seed money so that they can return to their communities and immediately go to work. More than 13,000 resident leaders have gone through the institute to date, and some cities have replicated the format to provide local training for residents.13 These and similar programs not only train leaders, but they also create networks, partnerships, and the opportunity to learn from each other.\n\nConclusion\nIn sum, community development is a complicated enterprise. Neighborhoods and communities are complex organisms that will be resilient only if they are healthy along a number of interrelated dimensions, much as a human body cannot be healthy without adequate air, water, rest, and food. But substantial coordination and dedication are needed to break through silos to simultaneously improve housing, connect residents to jobs, and help ensure access to adequate nutrition, health care, education, and day care. Moreover, each community has its own particular set of needs, which depend on local conditions and resources. Accordingly, local leadership, together with a vision of what each community can be, is essential.\n\nWith that in mind, I want to thank all of you here today for the role you play in bringing your skills in research and analysis to the important work of rebuilding lower-income communities. Community development leaders have no shortage of commitment to their goals, but with the insights you provide, together with the opportunities to learn from the experiences of other communities, they will be better prepared and thus more successful in meeting the very difficult challenges they face. Thank you for being here.\n\n \n\n1. For example, the Survey of Consumer Finances (SCF) data show that the average wealth of individuals in low- and moderate-income areas declined on a percentage basis more than that in higher-income areas (21 percent versus 17 percent). See the 2007-09 SCF panel data. Return to text\n\n2. Raven Molloy (2013), \"Long-Term Vacant Housing Units: An Aggregate View,\" speech delivered at \"Renters, Homeowners, and Investors: The Changing Profile of Communities,\" a conference sponsored by Board of Governors of the Federal Reserve System and Federal Reserve Banks of Philadelphia and Cleveland, Washington, February 26. Return to text\n\n3. Alan Berube (2012), \"The Continuing Evolution of American Poverty and Its Implications for Community Development (PDF) ,\" in Federal Reserve Bank of San Francisco and Low Income Investment Fund, Investing in What Works for America's Communities: Essays on People, Place, and Purpose (San Francisco: FRBSF and LIIF), pp. 55-71. Return to text\n\n4. Jane Jacobs (1961), The Death and Life of Great American Cities (New York: Random House). Return to text\n\n5. Eric Klinenberg (2013), \"Adaptation: How Can Cities Be ‘Climate-Proofed'?\" New Yorker, January 7. Return to text\n\n6. Shirley Franklin and David Edwards (2012), \"It Takes a Neighborhood: Purpose Built Communities and Neighborhood Transformation (PDF) ,\" in Federal Reserve Bank of San Francisco and Low Income Investment Fund, Investing in What Works for America's Communities: Essays on People, Place, and Purpose (San Francisco: FRBSF and LIIF), pp. 170-83. Return to text\n\n7. For statistics cited in this paragraph, see pp. 177-78 in Franklin and Edwards, It Takes a Neighborhood (PDF) , in note 6. Return to text\n\n8. See Franklin and Edwards, It Takes a Neighborhood (PDF) , in note 6. Return to text\n\n9. Los Angeles Housing and Community Development (2013), \"Five-Year Consolidated Plan 2013-2017 (PDF) \" (Los Angeles: Community Development Department, February 26), Strategic Plan, p. 2, available on the Los Angeles CDD website . Return to text\n\n10. Risa Lavizzo-Mourey (2012), \"Why Health, Poverty, and Community Development Are Inseparable (PDF) ,\" in Federal Reserve Bank of San Francisco and Low Income Investment Fund, Investing in What Works for America's Communities: Essays on People, Place, and Purpose (San Francisco: FRBSF and LIIF), pp. 215-25. Return to text\n\n11. Researchers found that each 1 percent increase in 90-day mortgage delinquencies over a one-year period was associated with a 3 percent increase in hospital admissions due to child physical abuse and a 5 percent increase in admissions due to traumatic brain injury suspected to be caused by child abuse. Return to text\n\n12. See Lavizzo-Mourey, \"Health, Poverty, and Community Development (PDF) ,\" in note 10. Return to text\n\n13. Salt Lake City has formed its own leadership institute based on this model and has trained hundreds of local residents. In Seattle, training was provided in Vietnamese using translators and NeighborWorks staff. New Orleans, San Jose, and Charlotte have also begun to provide local leadership training for residents. Return to text"
    },
    {
        "title": "Panel Discussion on \"Monetary Policy: Many Targets, Many Instruments. Where Do We Stand?\"",
        "date": "April 16, 2013",
        "speaker": "Vice Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20130416a.htm",
        "content": "April 16, 2013\n\nVice Chair Janet L. Yellen\n\nAt the \"Rethinking Macro Policy II,\" a conference sponsored by the International Monetary Fund, Washington, D.C.\n\nThank you to the International Monetary Fund for allowing me to take part in what I expect will be a very lively discussion.1 \n\nOnly five or six years ago, there wouldn't have been a panel on the \"many instruments\" and \"many targets\" of monetary policy. Before the financial crisis, the focus was on one policy instrument: the short-term policy interest rate. While central banks did not uniformly rely on a single policy target, many had adopted an \"inflation targeting\" framework that, as the name implies, gives a certain preeminence to that one objective. Of course, the Federal Reserve has long been a bit of an outlier in this regard, with its explicit dual mandate of price stability and maximum employment. Still, the discussion might not have gone much beyond \"one instrument and two targets\" if not for the financial crisis and its aftermath, which have presented central banks with great challenges and transformed how we look at this topic.\n\nLet me start with a few general observations to get the ball rolling. In terms of the targets, or, more generally, the objectives of policy, I see continuity in the abiding importance of a framework of flexible inflation targeting. By one authoritative account, about 27 countries now operate full-fledged inflation-targeting regimes.2 The United States is not on this list, but the Federal Reserve has embraced most of the key features of flexible inflation targeting: a commitment to promote low and stable inflation over a longer-term horizon, a predictable monetary policy, and clear and transparent communication. The Federal Open Market Committee (FOMC) struggled for years to formulate an inflation goal that would not seem to give preference to price stability over maximum employment. In January 2012, the Committee adopted a \"Statement on Longer-Run Goals and Monetary Policy Strategy,\" which includes a 2 percent longer-run inflation goal along with numerical estimates of what the Committee views as the longer-run normal rate of unemployment. The statement also makes clear that the FOMC will take a \"balanced approach\" in seeking to mitigate deviations of inflation from 2 percent and employment from estimates of its maximum sustainable level.  I see this language as entirely consistent with modern descriptions of flexible inflation targeting.\n\nFor the past four years, a major challenge for the Federal Reserve and many other central banks has been how to address persistently high unemployment when the policy rate is at or near the effective lower bound. This troubling situation has naturally and appropriately given rise to extensive discussion about alternative policy frameworks. I have been very keen, however, to retain what I see as the key ingredient of a flexible inflation-targeting framework: clear communication about goals and how central banks intend to achieve them.\n\nWith respect to the Federal Reserve's goals, price stability and maximum employment are not only mandated by the Congress, but also easily understandable and widely embraced. Well-anchored inflation expectations have proven to be an immense asset in conducting monetary policy. They've helped keep inflation low and stable while monetary policy has been used to help promote a healthy economy. After the onset of the financial crisis, these stable expectations also helped the United States avoid excessive disinflation or even deflation.\n\nOf course, many central banks have, in the wake of the crisis, found it challenging to provide appropriate monetary stimulus after their policy interest rate hit the effective lower bound. This is the point where \"many instruments\" enters the discussion. The main tools for the FOMC have been forward guidance on the future path of the federal funds rate and large-scale asset purchases.\n\nThe objective of forward guidance is to affect expectations about how long the highly accommodative stance of the policy interest rate will be maintained as conditions improve. By lowering private-sector expectations of the future path of short-term rates, this guidance can reduce longer-term interest rates and also raise asset prices, in turn, stimulating aggregate demand. Absent such forward guidance, the public might expect the federal funds rate to follow a path suggested by past FOMC behavior in \"normal times\"--for example, the behavior captured by John Taylor's famous Taylor rule. I am persuaded, however, by the arguments laid out by our panelist Michael Woodford and others suggesting that the policy rate should, under present conditions, be held \"lower for longer\" than conventional policy rules imply.\n\nI see these ideas reflected in the FOMC's recent policy. Since September 2012, the FOMC has stated that a highly accommodative stance of monetary policy will remain appropriate for a considerable time after the economic recovery strengthens. Since December 2012, the Committee has said it intends to hold the federal funds rate near zero at least until unemployment has declined below 6-1/2 percent, provided that inflation between one and two years ahead is projected to be no more than 1/2 percentage point above the Committee's 2 percent longer-run goal, and longer-term inflation expectations continue to be well anchored. I believe that the clarity of this commitment to accommodation will itself support spending and employment and help to strengthen the recovery.\n\nAsset purchases have complemented our forward guidance, and the many dimensions of different purchase programs arguably constitute \"many instruments.\" In designing a purchase program, one must consider which assets to buy: Just Treasury securities or agency mortgage-backed securities as well? Which maturities? The Federal Reserve, the Bank of England, and, more recently, the Bank of Japan have emphasized longer-duration securities. At what pace should the securities be purchased? And how long should they be held once purchases cease? Each of these factors may affect the degree of accommodation delivered. Two innovations in the FOMC's current asset purchase program, for example, are that it is open-ended rather than fixed in size like past programs, and that the overall size of the program is explicitly linked to seeing a substantial improvement in the outlook for the labor market.\n\nIn these brief remarks, I won't thoroughly review the benefits or costs of our highly accommodative policies, emphasizing only that I believe they have, on net, provided meaningful support to the recovery. But I do want to spend a moment on one potential cost--financial stability--because this topic returns us to the theme of \"many targets\" for central banks. As Chairman Bernanke has observed, in the years before the crisis, financial stability became a \"junior partner\" in the monetary policy process, in contrast with its traditionally larger role. The greater focus on financial stability is probably the largest shift in central bank objectives wrought by the crisis.\n\nSome have asked whether the extraordinary accommodation being provided in response to the financial crisis may itself tend to generate new financial stability risks. This is a very important question. To put it in context, let's remember that the Federal Reserve's policies are intended to promote a return to prudent risk-taking, reflecting a normalization of credit markets that is essential to a healthy economy. Obviously, risk-taking can go too far. Low interest rates may induce investors to take on too much leverage and reach too aggressively for yield. I don't see pervasive evidence of rapid credit growth, a marked buildup in leverage, or significant asset bubbles that would threaten financial stability. But there are signs that some parties are reaching for yield, and the Federal Reserve continues to carefully monitor this situation.\n\nHowever, I think most central bankers view monetary policy as a blunt tool for addressing financial stability concerns and many probably share my own strong preference to rely on micro- and macroprudential supervision and regulation as the main line of defense. The Federal Reserve has been working with a number of federal agencies and international bodies since the crisis to implement a broad range of reforms to enhance our monitoring, mitigate systemic risk, and generally improve the resilience of the financial system. Significant work will be needed to implement these reforms, and vulnerabilities still remain. Thus, we are prepared to use any of our many instruments as appropriate to address any stability concerns.\n\nLet me conclude by noting that I have touched on only some of the important dimensions of monetary policy targets and instruments that have arisen in recent years. I look forward to a discussion that I expect will explore these issues and perhaps raise others.\n\n1. The views I express here are my own and not necessarily those of my colleagues in the Federal Reserve System. Return to text\n\n2. See Gill Hammond (2012), State of the Art of Inflation Targeting (PDF), Centre for Central Banking Studies, CCBS Handbook No. 29 (London: Bank of England). Return to text"
    },
    {
        "title": "Regulating Large Financial Institutions",
        "date": "April 17, 2013",
        "speaker": "Governor Jeremy C. Stein",
        "url": "https://www.federalreserve.gov/newsevents/speech/stein20130417a.htm",
        "content": "April 17, 2013\n\nGovernor Jeremy C. Stein\n\nAt the \"Rethinking Macro Policy II,\" a conference sponsored by the International Monetary Fund, Washington, D.C.\n\nThank you. I'm delighted to be here, and want to thank the International Monetary Fund and the organizers of the conference for including me in a discussion of these important topics. I will focus my remarks today on the ongoing regulatory challenges associated with large, systemically important financial institutions, or SIFIs.1  In part, this focus amounts to asking a question that seems to be on everyone's mind these days: Where do we stand with respect to fixing the problem of \"too big to fail\" (TBTF)? Are we making satisfactory progress, or it is time to think about further measures?\n\nI should note at the outset that solving the TBTF problem has two distinct aspects. First, and most obviously, one goal is to get to the point where all market participants understand with certainty that if a large SIFI were to fail, the losses would fall on its shareholders and creditors, and taxpayers would have no exposure. However, this is only a necessary condition for success, but not a sufficient one. A second aim is that the failure of a SIFI must not impose significant spillovers on the rest of the financial system, in the form of contagion effects, fire sales, widespread credit crunches, and the like. Clearly, these two goals are closely related. If policy does a better job of mitigating spillovers, it becomes more credible to claim that a SIFI will be allowed to fail without government bailout.\n\nSo where do we stand? I believe two statements are simultaneously true. We've made considerable progress with respect to SIFIs since the financial crisis. And we're not yet at a point where we should be satisfied.\n\nAll of you are familiar with the areas of progress. Higher and more robust capital requirements, new liquidity requirements, and stress testing all should help to materially reduce the probability of a SIFI finding itself at the point of failure. And, if, despite these measures, a SIFI does fail, the orderly liquidation authority (OLA) in Title II of the Dodd-Frank Wall Street Reform and Consumer Protection Act now offers a mechanism for recapitalizing and restructuring the institution by imposing losses on shareholders and creditors. In the interests of brevity, I won't go into a lot of detail about OLA. But my Board colleague Jay Powell talked in depth about this topic in a speech last month, and I would just register my broad agreement with his conclusion--namely that the Federal Deposit Insurance Corporation's (FDIC's) so-called \"single point of entry\" approach to resolution is a promising one.2  The Federal Reserve continues to work with the FDIC on the many difficult implementation challenges that remain, but I believe this approach gets the first-order economics right and ultimately has a good chance to be effective.\n\nPerhaps more to the point for TBTF, if a SIFI does fail I have little doubt that private investors will in fact bear the losses--even if this leads to an outcome that is messier and more costly to society than we would ideally like. Dodd-Frank is very clear in saying that the Federal Reserve and other regulators cannot use their emergency authorities to bail out an individual failing institution. And as a member of the Board, I am committed to following both the letter and the spirit of the law.\n\nStill, we are quite a way from having fully solved the policy problems associated with SIFIs. For one thing, the market still appears to attach some probability to the government bailing out the creditors of a SIFI; this can be seen in the ratings uplift granted to large banks based on the ratings agencies' assessment of the probability of government support. While this uplift seems to have shrunk to some degree since the passage of Dodd-Frank, it is still significant.3  All else equal, this uplift confers a funding subsidy to the largest financial firms.\n\nMoreover, as I noted earlier, even if bailouts were commonly understood to be a zero-probability event, the problem of spillovers remains. It is one thing to believe that a SIFI will be allowed to fail without government support; it is another to believe that such failure will not inflict significant damage on other parts of the financial system. In the presence of such externalities, financial firms may still have excessive private incentives to remain big, complicated, and interconnected, because they reap any benefits--for example, in terms of economies of scale and scope--but don't bear all the social costs. \n\nHow can we do better? Some have argued that the current policy path is not working, and that we need to take a fundamentally different approach.4  Such an alternative approach might include, for example, outright caps on the size of individual banks, or a return to Glass-Steagall-type activity limits.\n\nMy own view is somewhat different. While I agree that we have a long way to go, I believe that the way to get there is not by abandoning the current reform agenda, but rather by sticking to its broad contours and ratcheting up its forcefulness on a number of dimensions. In this spirit, two ideas merit consideration: (1) an increase in the slope of the capital-surcharge schedule that is applied to large complex firms, and (2) the imposition at the holding company level of a substantial senior debt requirement to facilitate resolution under Title II of Dodd-Frank. In parallel with the approach to capital surcharges, a senior debt requirement could also potentially be made a function of an institution's systemic footprint.\n\nTo illustrate my argument, let us take as given the central premise of those who favor size limits: namely, that society would be better off if the distribution of banks were not so skewed toward a handful of very large institutions. (To be clear, I am using the word \"size\" as shorthand for the broader concept of an institution's systemic footprint, which in addition to size, might reflect complexity, interconnectedness, and global span of operations.) In other words, let's simply posit that a goal of regulation should be to lean against bank size, and ask: What are the best regulatory tools for accomplishing that goal? As in many other regulatory settings, this question can be mapped into the \"prices-versus-quantities\" framework laid out by Martin Weitzman nearly 40 years ago.5  Here a size cap is a form of quantity regulation, whereas capital requirements that increase with bank size can be thought of as a kind of price regulation, in the sense that such capital requirements are analogous to a progressive tax on bank size.6 \n\nA key challenge with quantity-based regulation is that one has to decide where to set the cap. Doing so requires a regulator to take a strong stand on the nature of scale and scope economies in large financial firms. Moreover, even if one reads the empirical literature as being quite skeptical about the existence of such economies beyond a certain point in the size distribution--a proposition which itself is debatable--the most that such large-sample studies can do is make on-average statements about scale and scope economies.7  These studies still leave open the possibility of considerable heterogeneity across firms, and that some firms are able to add considerable value in a given line of business by being very big, even if the average firm in the population is not. And such heterogeneity alone is enough to create significant drawbacks to quantity-based regulation.\n\nConsider the following example. There are three banks: A, B, and C. Banks A and B both have $1 trillion in assets, while C is smaller, with only $400 billion in assets. Bank A actually generates significant economies of scale, so that it is socially optimal for it to remain at its current size. Banks B and C, by contrast, have very modest economies of scale, not enough to outweigh the costs that their size and complexity impose on society. From the perspective of an omniscient social planner, it would be better if both B and C were half their current size.\n\nNow let's ask what happens if we impose a size cap of say $500 billion. This size cap does the right thing with respect to Bank B, by shrinking it to a socially optimal size. But it mishandles both Banks A and C, for different reasons. In the case of A, the cap forces it to shrink when it shouldn't, because given the specifics of its business model it actually creates a substantial amount of value by being big. And in the case of C, the cap makes the opposite mistake. It would actually be beneficial to put pressure on C to shrink at the margin--that is, to move it in the direction of being a $200 billion bank instead of a $400 billion one--but since it lies below the cap, it is completely untouched by the regulation.\n\nSuppose instead we attack the problem by imposing capital requirements that are an increasing function of bank size. This price-based approach creates some incentive for all three banks to shrink, but lets them balance this incentive against the scale benefits that they realize by staying big. In this case, we would expect A, with its significant scale economies, to absorb the tax hit and choose to remain large, while B and C, with more modest scale economies, would be expected to shrink more radically. In other words, price-based regulation is more flexible, in that it leaves the size decision to bank managers, who can then base their decision on their own understanding of the synergies--or lack thereof--in their respective businesses.\n\nThis logic can be thought of as supporting the approach taken by the Basel Committee on Banking Supervision in its rule imposing a common equity surcharge on designated global systemically important banks. The exact amount of the surcharge will range from 1 percent to 2.5 percent, and will depend on factors that include a bank's size, complexity, and interconnectedness, as measured by a variety of indicator variables.8  These progressive surcharges are effectively a type of price-based regulation, and therefore should have the advantages I just noted. \n\nHowever, a proponent of size caps might reasonably reply: \"Fine, but how do I know that these surcharges are actually enough to change behavior--that is, to exert a meaningful influence on the size distribution of the banking system?\" After all, the analogy between a capital requirement and a tax is somewhat imperfect, since we don't know exactly the implicit tax rate associated with a given level of capital. Some view capital requirements as quite burdensome, which would mean that even a 2 percent surcharge amounts to a significant tax and, hence, a strong incentive for a bank to shrink, while others have argued that capital requirements impose only modest costs, which would imply little incentive to shrink.9 \n\nThis uncertainty about the ultimate effect of a given capital-surcharge regime on the size distribution of banks could potentially tip the balance back in favor of quantity-based regulation, like size caps. And indeed, if we were faced with a static, once-and-for-all decision, I don't think economic reasoning alone could give us a definitive answer as to whether caps should be preferred to capital surcharges. This ambiguity is in some sense the central message of Weitzman's original analysis.\n\nOne way to resolve this tension is to refrain from putting ourselves in the position of having to make a once-and-for-all decision in a setting of substantial uncertainty. Rather, it might be preferable to try to learn from the incoming data and adjust over time, particularly since the recent changes to capital regulation already on the books may represent an informative experiment. In my view, this observation about the potential for learning tips the balance in favor of capital surcharges. For example, the capital-surcharge schedule proposed by the Basel Committee for globally important systemic banks may be a reasonable starting point. However, if after some time it has not delivered much of a change in the size and complexity of the largest of banks, one might conclude that the implicit tax was too small, and should be ratcheted up.10  In principle, this turning-up-the-dials approach feels to me like the right way to go: It retains the flexibility that makes price-based regulation attractive, while mitigating the risk that the implicit tax rate will be set too low. Of course, I recognize that its gradualist nature presents practical challenges, not least of which is sustaining a level of regulatory commitment and resolve sufficient to keep the dials turning so long as this is the right thing to do.\n\nBefore wrapping up, let me briefly mention another piece of the puzzle that I think is sometimes overlooked, but strikes me as having the potential to play an important complementary role in efforts to address the TBTF problem--namely, corporate governance. Suppose we do everything right with respect to capital regulation, and set up a system of capital surcharges that imposes a strong incentive to shrink on those institutions that don't create large synergies. How would the adjustment process actually play out? The first step would be for shareholders, seeing an inadequate return on capital, to sell their shares, driving the bank's stock price down. And the second step would be for management, seeking to restore shareholder value, to respond by selectively shedding assets.\n\nBut as decades of research in corporate finance have taught us, we shouldn't take the second step for granted. Numerous studies across a wide range of industries have documented how difficult it is for managers to voluntarily downsize their firms, even when the stock market is sending a clear signal that downsizing would be in the interests of outside shareholders. Often, change of this sort requires the application of some external force, be it from the market for corporate control, an activist investor, or a strong and independent board.11  As we move forward, we should keep these governance mechanisms in mind, and do what we can to ensure that they support the broader regulatory strategy.\n\nReferences\nAdmati, Anat R., Peter M. DeMarzo, Martin F. Hellwig, and Paul Pfleiderer (2011). \"Fallacies, Irrelevant Facts, and Myths in the Discussion of Capital Regulation: Why Bank Equity is Not Expensive (PDF) ,\" working paper\n\nBaker, Malcolm, and Jeffrey Wurgler (2013). \"Would Stricter Capital Requirements Raise the Cost of Capital? Bank Capital Regulation and the Low Risk Anomaly (PDF) ,\" working paper\n\nBasel Committee on Banking Supervision (BCBS) (2011). \"Global systemically important banks: assessment methodology and the additional loss absorbency requirement (PDF) ,\" rules text (November) \n\nFisher, Richard W. (2013). \"Ending 'Too Big to Fail' ,\" speech delivered at the Conservative Political Action Conference, National Harbor, Maryland, March 16\n\nHaldane, Andrew G. (2010). \"The $100 billion question (PDF) ,\" speech delivered at the Institute of Regulation & Risk, Hong Kong, March 30\n\nHanson, Samuel G., Anil K. Kashyap, and Jeremy C. Stein (2011). \"A Macroprudential Approach to Financial Regulation (PDF) ,\" Journal of Economic Perspectives, vol. 25 (Winter)\n\nJensen, Michael C. (1993). \"The Modern Industrial Revolution, Exit, and the Failure of Internal Control Systems,\" Journal of Finance, vol. 48(3), http://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.1993.tb04022.x/full\n\nHughes, Joseph P., and Mester, Loretta J. (2011). \"Who said large banks don't experience scale economies? Evidence from a risk-return-driven cost function (PDF) ,\" Working Paper No. 11-27. Philadelphia: Federal Reserve Bank of Philadelphia, July\n\nMoody's Investors Service (2012). \"Moody's downgrades firms with global capital markets operations,\" press release, June 21, www.moodys.com/research/Moodys-downgrades-firms-with-global-capital-markets-operations--PR_248989?WT.mc_id=BankRatings2012\n\nPowell, Jerome H. (2013). \"Ending 'Too Big to Fail',\" speech delivered at the Institute of International Bankers 2013 Washington Conference, Washington, D.C., March 4\n\nTarullo, Daniel K. (2012). \"Industry Structure and Systemic Risk Regulation,\" speech delivered at the Brookings Institution Conference on Structuring the Financial Industry to Enhance Economic Growth and Stability, Washington, D.C., December 4\n\nWeitzman, Martin L. (1974). \"Prices vs. Quantities (PDF) ,\" The Review of Economic Studies, vol. 41 (October)\n \n\n1. The thoughts that follow are my own, and are not necessarily shared by my colleagues on the Federal Reserve Board. I am grateful to members of the Board staff--Michael Gibson, Michael Hsu, Nellie Liang, and Mark Van Der Weide--for their advice. Return to text\n\n2. See Powell (2013). Return to text\n\n3. For example, in June of 2012, Moody's described its ratings process for Bank of America, Citigroup, and JP Morgan Chase as follows: \"[Their] ratings benefit from three notches of uplift from the standalone credit assessment at the bank level, and from two notches of uplift at the holding company, reflecting Moody's assumptions about a very high likelihood of support from the US government for bondholders or other creditors in the event such support was required to prevent a default… . The negative outlook on the parent holding company reflects Moody's view that government support for U.S. bank holding company creditors is becoming less certain and less predictable, given the evolving attitude of U.S. authorities to the resolution of large financial institutions, whereas support for creditors of operating entities remains sufficiently likely and predictable to warrant stable outlooks.\" Return to text\n\n4. See Fisher (2013), who said: \"…we recommend that the largest financial holding companies be restructured so that every one of their corporate entities is subject to a speedy bankruptcy process, and in the case of the banking entities themselves, that they be of a size that is ‘too small to save'. Addressing institutional size is vital to maintaining a credible threat of failure, thereby providing a convincing case that policy has truly changed.\" Return to text\n\n5. See Weitzman (1974). Haldane (2010) also uses Weitzman's framework to talk about price-versus-quantity regulation in the TBTF context. It should be noted that there are various hybrid approaches that are neither pure quantity nor pure price regulation. For example, Tarullo's (2012) discussion of limits on uninsured liabilities is not a rigid size cap, since it does not constrain an institution's absolute size, to the extent that it is able to adjust its funding mix. Return to text\n\n6. To be clear, this taxation aspect of capital requirements is not their only appeal, or even their primary one. Even if it were almost costless to impose higher capital requirements on bigger banks--so that doing so provided essentially no disincentive to bank size--it might still be a good idea to do so, for purely prudential reasons. In other words, capital requirements serve as both a prudential buffer and a tax, and can be a useful regulatory tool for both reasons. Return to text\n\n7. See Hughes and Mester (2011) for a recent contribution to the literature on scale economies in banking. Return to text\n\n8. See BCBS (2011) for a description of the methodology. Return to text\n\n9. For different estimates of the costs of capital requirements to banks, see Baker and Wurgler (2013), Admati and others (2011), and Hanson, Kashyap, and Stein (2011). Return to text\n\n10. Again, it should be emphasized that the underlying problem is not simply an institution's size, but rather its systemic footprint--which in addition to sheer size, is related to its complexity, interconnectedness, and global span of operations. Return to text\n\n11. Jensen (1993) is a classic treatment of the issues. Return to text"
    },
    {
        "title": "Aspects of Inequality in the Recent Business Cycle",
        "date": "April 18, 2013",
        "speaker": "Governor Sarah Bloom Raskin",
        "url": "https://www.federalreserve.gov/newsevents/speech/raskin20130418a.htm",
        "content": "April 18, 2013\n\nGovernor Sarah Bloom Raskin\n\nAt the \"Building a Financial Structure for a More Stable and Equitable Economy\" 22nd Annual Hyman P. Minsky Conference on the State of the U.S. and World Economies, New York, New York\n\nThank you for asking me to join you today at this conference and to be a part of your continuing inquiry into how the ideas and legacy of Hyman Minsky can inform and shape our understanding of financial markets and the economy.\n\nThis speech expands on remarks I made in March to the National Community Reinvestment Coalition, in which I explored the roles that monetary and bank regulatory policy play in reducing the unemployment, economic marginalization, and financial vulnerability of millions of moderate- and low-income working Americans. Today I am interested in continuing this exploration by examining an issue of growing saliency that macroeconomic models used at central banks and by academics have not traditionally emphasized--specifically, how such economic marginalization and financial vulnerability, associated with stagnant wages and rising inequality, contributed to the run-up to the financial crisis and how such marginalization and vulnerability could be relevant in the current recovery.\n\nTo isolate my proper subject here, I want to be clear that I am not engaging this afternoon with the concern that many Americans have that excessive inequality undermines American ideals and values. Nor will I be investigating the social costs associated with wide distributions of income and wealth. Rather, I want to zero in on the question of whether inequality itself is undermining our country's economic strength according to available macroeconomic indicators.\n\nEconomists have documented that widening income and wealth inequality has been one of the most notable structural changes to the U.S. economy since the late 1970s. This change represents a dramatic departure from the three decades prior to that time, when Americans enjoyed broadly rising incomes and shared prosperity. Indeed, many of you in the room have shed important light on the recent trends in inequality and on the potential role of fiscal policy in addressing them. You have also explored how these trends are relevant to issues of financial stability. I won't attempt to repeat this strong line of research and analysis. Instead, my remarks today are specifically focused on adding to the conversation about how such disparities in income and wealth could be relevant for a macro understanding of the financial crisis and the recovery and the appropriate course of monetary policy today.\n\nI will argue that at the start of this recession, an unusually large number of low- and middle-income households were vulnerable to exactly the types of shocks that sparked the financial crisis. These households, which had endured 30 years of very sluggish real-wage growth, held an unusually large share of their wealth in housing, much of it financed with debt. As a result, over time, their exposure to house prices had increased dramatically. Thus, as in past recessions, suffering in the Great Recession--though widespread--was most painful and most perilous for low- and middle-income households, which were also more likely to be affected by job loss and had little wealth to fall back on.\n\nMoreover, I am persuaded that because of how hard these lower- and middle-income households were hit, the recession was worse and the recovery has been weaker. The recovery has also been hampered by a continuation of longer-term trends that have reduced employment prospects for those at the lower end of the income distribution and produced weak wage growth.\n\nOf course, it is not part of the Federal Reserve's mandate to address inequality directly, but I want to explore these issues today because the answers may have implications for the Federal Reserve's efforts to understand the recession and conduct policy in a way that contributes to a stronger pace of recovery. Traditionally, the distribution of wealth and income has not been a primary consideration in the way most macroeconomists think about business cycles. But if inequality played a role in the financial crisis, if it contributed to the severity of the recession, and if its effects create a lingering economic headwind today, then perhaps our thinking, and our macroeconomic models, should be adjusted.\n\nDespite the tentative nature of these conclusions, I do think it is vital to explore these issues, and, in the spirit of Minsky, I hope my remarks spur more inquiry and discussion. I should also note that the views I express are my own and not necessarily those of my colleagues on the Board of Governors or the Federal Open Market Committee (FOMC).\n\nTrends in Income, Wealth, and Debt\nIn order to \"level set\" our understanding, let me begin by reviewing some of the changes to the structure of income, wealth, and debt in the years leading up to the Great Recession--changes that have had significant implications for the well-being of most American households. Long before the recession--decades before, in fact--income data show only sluggish increases in real incomes for low- and middle-income American households, and more-rapid increases for high-income households, resulting in a much greater concentration of income among those at the very top of the income distribution. As just one example of the broader trend, according to the Congressional Budget Office, between 1979 and 2007, inflation-adjusted, pretax income for a household in the top 1 percent more than doubled, while, in contrast, income for a household in the middle of the income distribution increased less than 20 percent.1 Over these years, the share of pretax income accruing to the top 1 percent of households also doubled, from 10 percent to 20 percent, while the share accruing to the bottom 40 percent fell from 13 percent to 10 percent. These growing disparities of total income are largely due to the increasing concentration of labor income, which, on average, accounted for more than 70 percent of all income over this period. In addition, the distribution of other sources of total income‑‑such as profits from small businesses, capital gains and dividend income, rental income, and the like--also became more concentrated over this period.\n\nMany have argued that these disparities in income are hindering economic growth through their effects on consumption. Intuitively, one might assume that the growing concentration of income at the top could lead to less consumer spending and aggregate demand, as wealthier households tend to save more of their additional income than others. However, there is no definitive research indicating that these income disparities show mixed results on the question of whether there are stable differences in the marginal propensity to consume across households with different incomes.2 More generally, the evidence is equivocal as to whether there is an empirical relationship between higher income inequality and reduced aggregate demand. In my view, understanding the links between greater concentrations of income, variation in spending patterns throughout the income distribution, and the effect of that variation on aggregate consumption--and, ultimately, growth--requires more exploration.3 \n\nBut since household behavior is surely driven by more than the size of the paycheck coming in the proverbial front door, the distribution of wealth--as distinct from the distribution of income--could have clearer implications for the macroeconomy. Indeed, wealth inequality is greater than income inequality in the United States, although it has widened little in recent decades. For example, according to the Survey of Consumer Finances (SCF), a survey conducted every three years by the Federal Reserve Board, the top one-fifth of families ranked by income owned 72 percent of the total wealth in the economy in 2010, whereas families in the bottom one-fifth of the income distribution together owned only 3 percent of total wealth in 2010.4 \n\nHence, families with more-modest incomes have much less wealth to cushion themselves against income shocks, such as unemployment. For example, in 2010, the median value of financial assets was less than $1,000 for families in the lowest income quintile. Moreover, what wealth low- and middle-income families do have is typically concentrated in housing. For families in the top quintile of income, the value of residential properties accounted for about 15 percent of total wealth in 2010. For families in the middle and lower half of the income distribution, the ratio of their home values to total net worth was near 70 percent. In contrast, stock market wealth (and the value of other securities) constitutes a very small share of wealth for low- and middle-income families.\n\nBecause the wealth of people at the lower end of the distribution is concentrated in housing, these households are disproportionately exposed to swings in house prices. This compositional effect was intensified during the housing boom, as the share of wealth accounted for by housing grew even faster for low- and middle-income families than for high-income families. That said, the increases in homeownership and house values during the boom were largely financed by rising mortgage debt. Thus, the direct positive effect of rising house prices on most households' net worth was largely offset by the negative effect of increased debt that households took on. On net, mortgage debt and home values moved up together. But when house prices began falling, the mortgage debt and repayment obligations remained.\n\nTo be sure, the increase in mortgage debt prior to the recession occurred across all types of households. But it was families with modest incomes and wealth largely in their homes that were the most vulnerable to subsequent drops in home values.\n\nThe question then arises as to why households with poor income prospects sought out levels of mortgage debt that would ultimately prove so problematic. Putting aside the practice, in the run-up to the crisis, of lenders steering households to mortgage debt products that were more costly than what such households may have otherwise qualified for, one reason may have been that many households in the middle and lower end of the income distribution, whose wage earnings were stagnant, did not recognize the long-run and persistent trends underlying their lack of income growth.5 If households thought they were merely going through a rough patch, it would have been quite reasonable for them to borrow money to smooth through it--to make home improvements, for example, or to send a child to college.6 At the same time, many people believed that the sharp increases in their home values had made them permanently richer and that house prices would never turn down, a belief that appears to have been shared by many households in the upper part of the income distribution as well. In fact, purchasing a house using debt was a profitable investment in the early 2000s. While it is hard to know with any certainty what these individual households believed at the time, it seems quite plausible to me, as others have argued, that stagnant wages and rising inequality, in combination with the relaxation of underwriting standards, led to an increase in the use of credit unsupported by greater income.7 \n\nInequality and the Great Recession\nGiven these developments, when house prices fell, household finances were struck a devastating blow. The resulting fallout magnified this initial shock, ushering in the Great Recession. Let me lay out this argument in more detail.\n\nAs I mentioned earlier, low- to middle-income families held a disproportionate share of their assets in housing prior to the financial crisis and hence were very exposed to what was a historic decline in house prices. And so, while total household net worth fell 15 percent in real terms between 2007 and 2010, median net worth fell almost 40 percent. This difference reflects the amplified effect that housing had on wealth changes in the middle of the wealth distribution.\n\nThe unexpected drop in house prices on its own reduced both households' wealth and their access to credit, likely leading them to pull back their spending. In particular, underwater borrowers and heavily indebted households were left with little collateral, which limited their access to additional credit and their ability to refinance at lower interest rates. Indeed, some studies have shown that spending has declined more for indebted households.8 \n\nCompounding the effect of falling house prices on household wealth and credit was the fact that these low- to middle-income households are also composed of some of the groups that have historically borne the brunt of downturns in the labor market. During recessions, the young, the less educated, and minorities are more likely to experience flat or declining wages, reduced hours, and unemployment.9 While this disparity is not a new phenomenon, dealing with a loss in labor income during the most recent recession was a heightened challenge to households that had mortgage obligations and no other forms of wealth to cushion the blow. The adverse developments in the labor market added to the difficulty most households were having in repaying their existing debts and in accessing credit in the recession.\n\nThese low- to middle-income households that bore the strains in both housing and labor markets, and had little wealth cushion, had more difficulty making payments on their mortgages and other consumer credit debt. For example, among the mortgages originated from 2004 to 2008, almost 25 percent of those in low-income neighborhoods were foreclosed on or in serious delinquency as of 2011, more than twice the rate of mortgages originated in higher-income neighborhoods. Higher-income households had also taken on debt and were affected by declines in asset prices. But these households entered the recession with a larger wealth buffer and higher incomes, so they generally were still able to service their debts. The sharp rise in defaults and delinquencies put extraordinary stress on most households' finances, intensified the financial crisis, and exacerbated the effect of the initial economic shocks. Indeed, a rapid downward spiral of tighter credit, declines in asset prices, rising unemployment, and falling demand caused severe distress and a pullback in spending that was ultimately widespread across households.\n\nInequality and the Recovery\nI have argued that rising inequality and stagnating wages may have led households to borrow more and to pin their hopes for economic advancement on rising home values, developments that exacerbated the severity of the financial crisis and recession. Now we are nearly four years into the recovery, which has been weak. In my view, this same confluence of factors has also contributed to the tepid recovery.\n\nIf my theory about why households overextended themselves before the financial crisis is correct, then it is likely also true that households have had a rude awakening in the years since. Not only did they receive an unwelcome shock to their net current wealth, but they also undoubtedly have come to realize that house prices will not rise indefinitely and that their labor income prospects are less rosy than they had believed. As a result, they are curtailing their spending in an effort to rebuild their nest eggs and may also be trimming their budgets in order to bring their debt levels into alignment with their new economic realities. In this case, the effects of the plunge in net wealth and the jump in unemployment on subsequent spending have been long lasting and lingering.\n\nOverall debt levels remain higher than before the house price boom, and many families continue to struggle to keep up with their monthly payments. Although many households have significantly reduced their debt levels, many others probably have far to go.10 It is hard to know just what the optimal debt-to-income ratio is, but, in my view, households will likely aim for something lower than before the financial crisis: Households are probably working toward lower, more-manageable debt service obligations; the heightened uncertainty in the recession may have raised the desired level of financial buffers; and, to the extent that households saw the negative shocks to house prices and income as permanent, they are reducing their spending and thus their demand for new borrowing. While the process of household deleveraging has affected the spending and borrowing of many households, there is no doubt that the process has been more acute for those that have experienced unemployment, underemployment, or slower wage gains.\n\nTo make matters worse, there is also some evidence to suggest that the factors that contributed to the rise in inequality and the stagnation of wages in the bottom half of the income distribution, such as technological change that favors those with a college education and globalization, are still at play in the recovery--and perhaps may have accelerated.11 About two-thirds of all job losses in the recession were in middle-wage occupations--such as manufacturing, skilled construction, and office administration jobs--but these occupations have accounted for less than one-fourth of subsequent job growth.12 In contrast, the decline in lower-wage occupations--such as retail sales, food service, and other lower-paying service jobs--accounted for only one-fifth of job loss and more than one-half of total job gains in the recovery.13 \n\nIt is not only the occupational and industrial distribution of the new jobs that poses challenges for workers and their families struggling to make ends meet, but also the fact that many of the jobs that have returned are part time or make use of temporary arrangements popularly known as contingent work. The flexibility of these jobs may be beneficial for workers who want or need time to address their family needs. However, workers in these jobs often receive less pay and fewer benefits than traditional full-time or \"permanent\" workers, are much less likely to benefit from the protections of labor and employment laws, and often have no real pathway to upward mobility in the workplace.14 \n\nWage gains have remained more muted than is typical during a recovery. While this phenomenon likely partly reflects the trends in job creation that I have already discussed, weak wage growth also reflects the severe nature of the crisis: Typically, those who are laid off during recessions struggle to find reemployment that is of comparable quality to their previous job, and research has shown that, on average, a person's income remains depressed for decades following job loss, and that income losses over one's working life are especially severe when the job loss occurs during a recession.15 \n\nIndeed, while average wages have continued to increase (albeit slowly) on an annual basis for persons who have remained employed, the average wage for new hires has declined since 2010.16 Although it is too early to state with certainty what the long-term effect of this recession will be on the earnings potential of those who lost their jobs, given the severity of the job loss and sluggishness of the recovery--with nearly 9 million jobs lost and still almost 2-1/2 million jobs below pre-recession employment levels--it is very likely that, for many households, future labor earnings will be well below what they had anticipated in the years before the recession.\n\nImplications for Our Thinking about the Macroeconomy\nI have focused most of my remarks on the experiences of households at the lower ends of the income and wealth distributions, those households whose incomes improved the least in the years prior to the financial crisis and that suffered disproportionately as a result of the crisis and ensuing recession.\n\nTo be clear, my approach of starting with inequality and differences across households is not a feature of most analyses of the macroeconomy, and the channels I have emphasized generally do not play key roles in most macro models. The typical macroeconomic analysis focuses on the general equilibrium behavior of \"representative\" households and firms, thereby abstracting from the consequences of inequality and other heterogeneity across households and instead focusing on the aggregate measures of spending determinants, including current income, wealth, interest rates, credit supply, and confidence or pessimism. In certain circumstances, this abstraction might be a reasonable simplification. For example, if the changes in the distribution of income or wealth, and the implications of those changes for the overall economy, are regular features of business cycles, then even an aggregate model without an explicit focus on distributional issues would capture those historical regularities.\n\nHowever, the narrative I have emphasized places economic inequality and the differential experiences of American families, particularly the highly adverse experiences of those least well positioned to absorb their \"realized shocks,\" closer to the front and center of the macroeconomic adjustment process. The effects of increasing income and wealth disparities--specifically, the stagnating wages and sharp increase in household debt in the years leading up to the crisis, combined with the rapid decline in house prices and contraction in credit that followed--may have resulted in dynamics that differ from historical experience and which are therefore not well captured by aggregate models. How these factors have interacted and the implications for the aggregate economy are subject to debate, but I have laid out some possible channels through which there could be effects and that I believe represent some particularly fruitful areas for continued research.\n\nImplications for Monetary Policy\nThe arguments that I have laid out suggest that paying attention to the experiences of different types of households may be important for the way we understand and interpret the macroeconomic events of the past several years. As a consequence, these differential experiences may also have implications for the conduct of monetary policy. Arguably, the FOMC's conduct of monetary policy in recent years has in part been designed to address this particular landscape. In response to continuing low levels of resource utilization, the FOMC has kept monetary policy highly accommodative by keeping its primary policy instrument, the federal funds rate, at an exceptionally low level; by supplementing this move with forward guidance about the funds rate; and by initiating unconventional policy actions such as large-scale asset purchases. One channel through which these policies operate is by putting downward pressure on longer-term interest rates, thereby encouraging firms to invest in plants and equipment and helping enable households to purchase cars and other durable goods and also to refinance their mortgages. Lower interest rates also support the prices of homes and other assets, which can lead to additional spending. The resulting boost to demand leads firms to hire and invest further, strengthening the economy as a whole. To be sure, every household is different, and the particular mix of assets, skills, and opportunities that each has will determine how much it is able to share in the recovery. But accommodative monetary policy that lifts economic activity more generally is expected to increase the odds of good outcomes for American families.\n\nOf course, it is also relevant to consider whether the unusual circumstances--the outsized role of housing wealth in the portfolios of low- and middle-income households, the increased use of debt during the boom, and the subsequent unprecedented shocks to the housing market--may have attenuated the effectiveness of monetary policy during the depths of the recession. Households that have been through foreclosure or have underwater mortgages or are otherwise credit constrained are less able than other households to take advantage of the lower interest rates, either for homebuying or other purposes. In my view, these effects likely clogged some of the channels through which monetary policy traditionally works. As the housing market recovers, though, I think it is possible that accommodative monetary policy could be increasingly potent. As house prices rise, more and more households have enough home equity to gain renewed access to mortgage credit and the ability to refinance their homes at lower rates. The staff at the Federal Reserve Board has estimated that house price increases of 10 percent or less from current levels would be sufficient for about 40 percent of underwater homeowners to regain positive equity.\n\nIt is my view that understanding the long-run trends in income and wealth across different households is important in understanding the dynamics of the macroeconomy and thus also may be relevant for setting monetary policy to best reach our goals of maximum employment and price stability. I believe that the accommodative policies of the FOMC and the concerted effort we have made to ease conditions in the mortgage markets will help the economy continue to gain traction. And the resulting expansion in employment will likely improve income levels at the bottom of the distribution. However, given the long-standing trends toward greater income and wealth inequalities, it is unlikely that cyclical improvements in the labor markets will do much to reverse these trends.\n\nConclusion\nIt strikes me that macroeconomists are far from a comprehensive understanding of how wealth and income inequality may affect business cycle dynamics. My remarks today are given only in the spirit of describing how that relationship might be further explored. I have said nothing about the social costs associated with such trends, nor have I provided much detail on what is occurring at the top end of the income and wealth distribution and the effects of those trends on the recovery. Nonetheless, I believe that, given the wide income and wealth disparities in the United States, this area is ripe for more research.\n\nIn recent years, the Board has increased its efforts to measure and understand differences in the economic situations faced by different types of families. A particularly strong source of data to improve our understanding of the role for inequality and heterogeneity is the SCF. The triennial SCF marks its 30th anniversary this year, as the fieldwork for the 2013 survey begins this month. The data we collect on U.S. families are a fundamental input for many different types of research projects being undertaken by Board economists, in other government agencies and research centers, and in academia. In addition, the Board, in partnership with other members of the Federal Reserve System, is engaged in a wide range of analysis and research using rich and timely data on households' use of consumer credit. And the Board continues to support direct efforts to understand differences in spending and saving behavior across households, such as studies of stimulus policies in the Thomson Reuters/University of Michigan Surveys of Consumers.\n\nThere is much work to be done on understanding the ways in which income and wealth inequality and other forms of household heterogeneity affect aggregate behavior, and the implications for monetary policy. The times demand that we continue to analyze such dynamics and their implications, in partnership with academics, our Federal Reserve System colleagues, and policy analysts representing many different types of government and private-sector institutions.\n\nThank you for your attention and the creative thought you bring to today's economic challenges.\n\n1. See Congressional Budget Office (2011), Trends in the Distribution of Household Income between 1979 and 2007 (PDF) (Washington: CBO, October). Return to text\n\n2. The survey article by Attanasio and Weber (2010) describes several conditions that raise a household's propensity to consume additional income, such as temporary income shocks, borrowing constraints, and low liquidity. However, existing studies do not provide clear evidence that people with permanently low income have a high marginal propensity to consume. See Orazio P. Attanasio and Guglielmo Weber (2010), \"Consumption and Saving: Models of Intertemporal Allocation and Their Implications for Public Policy,\" Journal of Economic Literature, vol. 48 (September), pp. 693-751. Return to text\n\n3. One concern with rising inequality and stagnating wages is that low- and middle-income households will turn to credit and wealth extraction to maintain their consumption growth. One sign of this behavior would be consumption inequality rising much less than income inequality. Researchers--including Krueger and Perri (2006); Aguiar and Bils (2011); and Attanasio, Hurst, and Pistaferri (2012)--have produced mixed findings on this basic question, although, taken together, there is growing evidence that consumption inequality has also risen substantially over the past several decades. See Dirk Krueger and Fabrizio Perri (2006), \"Does Income Inequality Lead to Consumption Inequality? Evidence and Theory,\" Review of Economic Studies, vol. 73 (January), pp. 163-93; Mark A. Aguiar and Mark Bils (2011), \"Has Consumption Inequality Mirrored Income Inequality?\" NBER Working Paper Series 16807 (Cambridge, Mass.: National Bureau of Economic Research, February); and Orazio Attanasio, Erik Hurst, and Luigi Pistaferri (2012), \"The Evolution of Income, Consumption, and Leisure Inequality in the US, 1980-2010,\" NBER Working Paper Series 17982 (Cambridge, Mass.: National Bureau of Economic Research, April). Return to text\n\n4. The specific measure used to group families for these wealth calculations is the stable component of income, referred to in the SCF as \"normal\" or \"usual\" income. In the SCF, after families have reported their actual incomes for the year, they are asked whether this was a normal year. If the answer is no, they are asked what their income usually would be in a normal year. Using normal income as a classifier removes the systematic bias in average wealth that arises when, for example, normally high-income families are temporarily in the lowest income group because they had a particularly bad year. Return to text\n\n5. In a separate line of inquiry on the social dynamics of spending, Bertrand and Morse (2013) find that moderate-income households spend more if they live in states with rapid spending growth among high-income households, which suggests another channel for inequality to increase debt. See Marianne Bertrand and Adair Morse (2013), \"Trickle-Down Consumption,\" NBER Working Paper Series 18883 (Cambridge, Mass.: National Bureau of Economic Research, March). Return to text\n\n6. In fact, recent research shows that these trends in annual inequality are mostly due to rising disparities in the component of a household's income that is stable over time, rather than rising disparities in the component that varies from year to year. See Jason DeBacker, Bradley Heim, Vasia Panousi, and Ivan Vidangos (2011), \"Rising Inequality: Transitory or Permanent? New Evidence from a U.S. Panel of Household Income 1987-2006,\" Finance and Economics Discussion Series 2011-60 (Washington: Board of Governors of the Federal Reserve System, December). Return to text\n\n7. For example, Rajan (2010) has argued that rising inequality resulted in the relaxation of credit standards, which led to the financial crisis, and Kumhof and Ranciere (2011) present a model with such features. However, Bordo and Meissner (2012) look at data from 14 advanced countries and do not find a general relationship between inequality and credit booms. Meanwhile, Bhutta (2011, 2012) finds that federal programs aimed at increasing homeownership only modestly increased the availability of mortgage credit to lower-income borrowers. See Raghuram Rajan (2010), Fault Lines: How Hidden Fractures Still Threaten the World Economy (Princeton, N.J.: Princeton University Press); Michael Kumhof and Romain Ranciere (2011), \"Inequality, Leverage and Crises,\" CEPR Discussion Paper 8179 (London: Centre for Economic Policy Research, January); Michael D. Bordo and Christopher M. Meissner (2012), \"Does Inequality Lead to a Financial Crisis?\" NBER Working Paper Series 17896 (Cambridge, Mass.: National Bureau of Economic Research, March); Neil Bhutta (2011), \"The Community Reinvestment Act and Mortgage Lending to Lower Income Borrowers and Neighborhoods,\" Journal of Law and Economics, vol. 54 (November), pp. 953-83; and Neil Bhutta (2012), \"GSE Activity and Mortgage Supply in Lower-Income and Minority Neighborhoods: The Effect of the Affordable Housing Goals,\" Journal of Real Estate Finance and Economics, vol. 45 (June), pp. 238-61. Return to text\n\n8. See Atif Mian, Kamalesh Rao, and Amir Sufi (2011), \"Household Balance Sheets, Consumption, and the Economic Slump (PDF),\" unpublished paper, University of Chicago, Booth School of Business, November; and Karen Dynan (2012), \"Is a Household Debt Overhang Holding Back Consumption?\" Brookings Papers on Economic Activity, Spring, pp. 299-358. Return to text\n\n9. An Organisation for Economic Co-operation and Development study by Ahrend, Arnold, and Moeser (2011) documents across a wider range of countries that individuals with low incomes tend to lose the most from adverse macroeconomic shocks. See Rudiger Ahrend, Jens Arnold, and Charlotte Moeser (2011), \"The Sharing of Macroeconomic Risk: Who Loses (and Gains) from Macroeconomic Shocks,\" OECD Economics Department Working Papers 877 (Washington: OECD Publishing, July). Return to text\n\n10. In contrast to the decrease in overall debt, student loans have continued to rise at a solid pace. The outstanding level of student loan balances is nearly twice its level five years ago and now represents the largest component of consumer (nonmortgage) lending. The increase in student loans is likely related to broader developments in the recession and exposes the households holding these loans to new risks. Return to text\n\n11. The poverty rate has risen sharply since the onset of the recession, after a decade of relative stability, and it now stands at 15 percent, significantly higher than the average over the past three decades. See Carmen DeNavas-Walt, Bernadette D. Proctor, and Jessica C. Smith (2012), Income, Poverty, and Health Insurance Coverage in the United States: 2011 (PDF), U.S. Census Bureau Current Population Reports P60-243 (Washington: U.S. Government Printing Office, September). Return to text\n\n12. See National Employment Law Project (2012), \"The Low-Wage Recovery and Growing Inequality,\" Data Brief, report (New York: NELP, August), http://nelp.3cdn.net/8ee4a46a37c86939c0_qjm6bkhe0.pdf. Return to text\n\n13. These patterns were also observed during the recessions of the early 1990s and early 2000s--the so-called jobless recoveries--but not prior to then. See Nir Jaimovich and Henry E. Siu (2012), \"The Trend Is the Cycle: Job Polarization and Jobless Recoveries,\" NBER Working Paper Series 18334 (Cambridge, Mass: National Bureau of Economic Research, August); and Christopher L. Foote and Richard W. Ryan (2012), \"Labor-Market Polarization over the Business Cycle,\" Public Policy Discussion Paper 12-8 (Boston: Federal Reserve Bank of Boston, December). Return to text\n\n14. See U.S. Department of Labor, Commission on the Future of Worker-Management Relations (1994), \"Contingent Workers,\" in Fact Finding Report. Return to text\n\n15. See Steven J. Davis and Till von Wachter (2011), \"Recessions and the Costs of Job Loss,\" Brookings Papers on Economic Activity, Fall, pp. 1-55. Return to text\n\n16. See Jesse Rothstein (2012), \"The Labor Market Four Years into the Crisis: Assessing Structural Explanations,\" ILRReview, vol. 65 (July), figure 11, p. 486. Return to text"
    },
    {
        "title": "Liquidity Regulation and Central Banking",
        "date": "April 19, 2013",
        "speaker": "Governor Jeremy C. Stein",
        "url": "https://www.federalreserve.gov/newsevents/speech/stein20130419a.htm",
        "content": "April 19, 2013\n\nGovernor Jeremy C. Stein\n\nAt the \"Finding the Right Balance\" 2013 Credit Markets Symposium sponsored by the Federal Reserve Bank of Richmond, Charlotte, North Carolina\n\nI'd like to talk today about one important element of the international regulatory reform agenda--namely, liquidity regulation.1 Liquidity regulation is a relatively new, post-crisis addition to the financial stability toolkit. Key elements include the Liquidity Coverage Ratio (LCR), which was recently finalized by the Basel Committee on Banking Supervision, and the Net Stable Funding Ratio, which is still a work in progress. In what follows, I will focus on the LCR.\n\nThe stated goal of the LCR is straightforward, even if some aspects of its design are less so. In the words of the Basel Committee, \"The objective of the LCR is to promote the short-term resilience of the liquidity risk profile of banks. It does this by ensuring that banks have an adequate stock of unencumbered high-quality liquid assets (HQLA) that can be converted easily and immediately in private markets into cash to meet their liquidity needs for a 30 calendar day liquidity stress scenario.\"2 In other words, each bank is required to model its total outflows over 30 days in a liquidity stress event and then to hold HQLA sufficient to accommodate those outflows. This requirement is implemented with a ratio test, where modeled outflows go in the denominator and the stock of HQLA goes in the numerator; when the ratio equals or exceeds 100 percent, the requirement is satisfied.\n\nThe Basel Committee issued the first version of the LCR in December 2010. In January of this year, the committee issued a revised final version of the LCR, following an endorsement by its governing body, the Group of Governors and Heads of Supervision (GHOS). The revision expands the range of assets that can count as HQLA and also adjusts some of the assumptions that govern the modeling of net outflows in a stress scenario. In addition, the committee agreed in January to a gradual phase-in of the LCR, so that it only becomes fully effective on an international basis in January 2019. On the domestic front, the Federal Reserve expects that the U.S. banking agencies will issue a proposal later this year to implement the LCR for large U.S. banking firms.\n\nWhile this progress is welcome, a number of questions remain. First, to what extent should access to liquidity from a central bank be allowed to count toward satisfying the LCR? In January, the GHOS noted that the interaction between the LCR and the provision of central bank facilities is critically important. And the group instructed the Basel Committee to continue working on this issue in 2013.\n\nSecond, what steps should be taken to enhance the usability of the LCR buffer--that is, to encourage banks to actually draw down their HQLA buffers, as opposed to fire-selling other less liquid assets? The GHOS has also made clear its view that, during periods of stress, it would be appropriate for banks to use their HQLA, thereby falling below the minimum. However, creating a regime in which banks voluntarily choose to do so is not an easy task. A number of observers have expressed the concern that if a bank is held to an LCR standard of 100 percent in normal times, it may be reluctant to allow its ratio to drop below 100 percent when facing large outflows, even if regulators were to permit this temporary deviation, for fear that a decline in the ratio could be interpreted as a sign of weakness.\n\nMy aim here is to sketch a framework for thinking about these and related issues. Among them, the interplay between the LCR and central bank liquidity provision is perhaps the most fundamental and a natural starting point for discussion. By way of motivation, note that before the financial crisis, we had a highly developed regime of capital regulation for banks--albeit one that looks inadequate in retrospect--but we did not have formal regulatory standards for their liquidity.3 The introduction of liquidity regulation after the crisis can be thought of as reflecting a desire to reduce dependence on the central bank as a lender of last resort (LOLR), based on the lessons learned over the previous several years. However, to the extent that some role for the LOLR still remains, one now faces the question of how it should coexist with a regime of liquidity regulation.\n\nTo address this question, it is useful to take a step back and ask another one: What underlying market failure is liquidity regulation intended to address, and why can't this market failure be handled entirely by an LOLR? I will turn to this question first. Next, I will consider different mechanisms that could potentially achieve the goals of liquidity regulation, and how these mechanisms relate to various features of the LCR. In so doing, I hope to illustrate why, even though liquidity regulation is a close cousin of capital regulation, it nevertheless presents a number of novel challenges for policymakers and why, as a result, we are going to have to be open to learning and adapting as we go.\n\nThe Case for Liquidity Regulation\nOne of the primary economic functions of banks and other financial intermediaries, such as broker-dealers, is to provide liquidity--that is, cash on demand--in various forms to their customers. Some of this liquidity provision happens on the liability side of the balance sheet, with bank demand deposits being a leading example. But, importantly, banks also provide liquidity via committed lines of credit. Indeed, it is probably not a coincidence that these two products--demand deposits and credit lines--are offered under the roof of the same institution; the underlying commonality is that both require an ability to accommodate unpredictable requests for cash on short notice.4 A number of other financial intermediary services, such as prime brokerage, also embody a significant element of liquidity provision.\n\nWithout question, these liquidity-provision services are socially valuable. On the liability side, demand deposits and other short-term bank liabilities are safe, easy-to-value claims that are well suited for transaction purposes and hence create a flow of money-like benefits for their holders.5 And loan commitments are more efficient than an arrangement in which each operating firm hedges its future uncertain needs by \"pre-borrowing\" and hoarding the proceeds on its own balance sheet; this latter approach does a poor job of economizing on the scarce aggregate supply of liquid assets.6 \n\nAt the same time, as the financial crisis made painfully clear, the business of liquidity provision inevitably exposes financial intermediaries to various forms of run risk. That is, in response to adverse events, their fragile funding structures, together with the binding liquidity commitments they have made, can result in rapid outflows that, absent central bank intervention, lead banks to fire-sell illiquid assets or, in a more severe case, to fail altogether. And fire sales and bank failures--and the accompanying contractions in credit availability--can have spillover effects to other financial institutions and to the economy as a whole. Thus, while banks will naturally hold buffer stocks of liquid assets to handle unanticipated outflows, they may not hold enough because, although they bear all the costs of this buffer stocking, they do not capture all of the social benefits, in terms of enhanced financial stability and lower costs to taxpayers in the event of failure. It is this externality that creates a role for policy.\n\nThere are two broad types of policy tools available to deal with this sort of liquidity-based market failure. The first is after-the-fact intervention, either by a deposit insurer guaranteeing some of the bank's liabilities or by a central bank acting as an LOLR; the second type is liquidity regulation. As an example of the former, when the economy is in a bad state, assuming that a particular bank is not insolvent, the central bank can lend against illiquid assets that would otherwise be fire-sold, thereby damping or eliminating the run dynamics and helping reduce the incidence of bank failure.\n\nIn much of the literature on banking, such interventions are seen as the primary method for dealing with run-like liquidity problems. A classic statement of the central bank's role as an LOLR is Walter Bagehot's 1873 book Lombard Street. More recently, the seminal theoretical treatment of this issue is by Douglas Diamond and Philip Dybvig, who show that under certain circumstances, the use of deposit insurance or an LOLR can eliminate run risk altogether, thereby increasing social welfare at zero cost.7 To be clear, this work assumes that the bank in question is fundamentally solvent, meaning that while its assets may not be liquid on short notice, the long-run value of these assets is known with certainty to exceed the value of the bank's liabilities.8 One way to interpret the message of this research is that capital regulation is important to ensure solvency, but once a reliable regime of capital regulation is in place, liquidity problems can be dealt with after the fact, via some combination of deposit insurance and use of the LOLR.\n\nIt follows that if one is going to make an argument in favor of adding preventative liquidity regulation such as the LCR on top of capital regulation, a central premise must be that the use of LOLR capacity in a crisis scenario is socially costly, so that it is an explicit objective of policy to economize on its use in such circumstances. I think this premise is a sensible one.9 A key point in this regard--and one that has been reinforced by the experience of the past several years--is that the line between illiquidity and insolvency is far blurrier in real life than it is sometimes assumed to be in theory. Indeed, one might argue that a bank or broker-dealer that experiences a liquidity crunch must have some probability of having solvency problems as well; otherwise, it is hard to see why it could not attract short-term funding from the private market.\n\nThis reasoning implies that when the central bank acts as an LOLR in a crisis, it necessarily takes on some amount of credit risk. And if it experiences losses, these losses ultimately fall on the shoulders of taxpayers. Moreover, the use of an LOLR to support banks when they get into trouble can lead to moral hazard problems, in the sense that banks may be less prudent ex ante. If it were not for these costs of using LOLR capacity, the problem would be trivial, and there would be no need for liquidity regulation: Assuming a well-functioning capital-regulation regime, the central bank could always avert all fire sales and bank failures ex post, simply by acting as an LOLR.\n\nThis observation carries an immediate implication: It makes no sense to allow unpriced access to the central bank's LOLR capacity to count toward an LCR requirement. Again, the whole point of liquidity regulation must be either to conserve on the use of the LOLR or in the limit, to address situations where the LOLR is not available at all--as, for example, in the case of broker-dealers in the United States.10 \n\nAt the same time, it is important to draw a distinction between priced and unpriced access to the LOLR. For example, take the case of Australia, where prudent fiscal policy has led to a relatively small stock of government debt outstanding and hence to a potential shortage of HQLA. The Basel Committee has agreed to the use by Australia of a Committed Liquidity Facility (CLF), whereby an Australian bank can pay the Reserve Bank of Australia an up-front fee for what is effectively a loan commitment, and this loan commitment can then be counted toward its HQLA. In contrast to free access to the LOLR, this approach is not at odds with the goals of liquidity regulation because the up-front fee is effectively a tax that serves to deter reliance on the LOLR--which, again, is precisely the ultimate goal. I will return to the idea of a CLF shortly.\n\nThe Design of Regulation\nOnce it has been decided that liquidity regulation is desirable, the next question is how best to implement it. In this context, note that the LCR has two logically distinct aspects as a regulatory tool: It is a mitigator, in the sense that holding liquid assets leads to a better outcome if there is a bad shock; it is also an implicit tax on liquidity provision by banks, to the extent that holding liquid assets is costly. Of course, one can say something broadly similar about capital requirements. But the implicit tax associated with the LCR is subtler and less well understood, so I will go into some detail here.\n\nAn analogy may help to explain. Suppose we have a power plant that produces energy and, as a byproduct, some pollution. Suppose further that regulators want to reduce the pollution and have two tools at their disposal: They can mandate the use of a pollution-mitigating technology, like scrubbers, or they can levy a tax on the amount of pollution generated by the plant. In an ideal world, regulation would accomplish two objectives. First, it would lead to an optimal level of mitigation--that is, it would induce the plant to install scrubbers up to the point where the cost of an additional scrubber is equal to the marginal social benefit, in terms of reduced pollution. And, second, it would also promote conservation: Given that the scrubbers don't get rid of pollution entirely, one also wants to reduce overall energy consumption by making it more expensive.\n\nA simple case is one in which the costs of installing scrubbers, as well as the social benefits of reduced pollution, are known in advance by the regulator and the manager of the power plant. In this case, the regulator can figure out what the right number of scrubbers is and require that the plant install these scrubbers. The mandate can therefore precisely target the optimal amount of mitigation per unit of energy produced. And, to the extent that the scrubbers are costly, the mandate will also lead to higher energy prices, which will encourage some conservation, though perhaps not the socially optimal level.11 This latter effect is the implicit tax aspect of the mandate.\n\nA more complicated case is when the regulator does not know ahead of time what the costs of building and installing scrubbers will be. Here, mandating the use of a fixed number of scrubbers is potentially problematic: If the scrubbers turn out to be very expensive, the regulation will end up being more aggressive than socially desirable, leading to overinvestment in scrubbers and large cost increases for consumers; however, if the scrubbers turn out to be cheaper than expected, the regulation will have been too soft. In other words, when the cost of the mitigation technology is significantly uncertain, a regulatory approach that fixes the quantity of mitigation is equivalent to one where the implicit tax rate bounces around a lot.\n\nBy contrast, a regulatory approach that fixes the price of pollution instead of the quantity--say, by imposing a predetermined proportional tax rate directly on the amount of pollution emitted by the plant--is more forgiving in the face of this kind of uncertainty. This approach leaves the scrubber-installation decision to the manager of the plant, who can figure out what the scrubbers cost before deciding how to proceed. For example, if the scrubbers turn out to be unexpectedly expensive, the plant manager can install fewer of them. This flexibility translates into less variability in the effective regulatory burden and hence less variability in the price of energy to consumers.12 \n\nScrubbers and High-Quality Liquid Assets\nWhat does all this imply for the design of the LCR? Let's work through the analogy in detail. The analog to the power plant's energy output is the gross amount of liquidity services created by a bank--via its deposits, the credit lines it provides to its customers, the prime brokerage services it offers, and so forth. The analog to the mitigation technology--the scrubbers--is the stock of HQLA that the bank holds. And the analog to pollution is the net liquidity risk associated with the difference between these two quantities, something akin to the LCR shortfall. That is, when the bank offers a lot of liquidity on demand to its customers but fails to hold an adequate buffer of HQLA, this is when it imposes spillover costs on the rest of the financial system.\n\nIn the case of the power plant, I argued that a regulation that calls for a fixed quantity of mitigation--that is, for a fixed number of scrubbers--is more attractive when there is little uncertainty about the cost of these scrubbers. In the context of the LCR, the cost of mitigation is the premium that the bank must pay--in the form of reduced interest income--for its stock of HQLA. And, crucially, this HQLA premium is determined in market equilibrium and depends on the total supply of safe assets in the system, relative to the demand for those assets. On the one hand, if safe HQLA-eligible assets are in ample supply, the premium is likely to be low and stable. On the other hand, if HQLA-eligible assets are scarce, the premium will be both higher and more volatile over time.\n\nThis latter situation is the one facing countries like Australia, where, as I noted earlier, the stock of outstanding government securities is relatively small. And it explains why, for such countries, having a price-based mechanism as part of their implementation of the LCR can be more appealing than pure reliance on a quantity mandate. When one sets an up-front fee for a CLF, one effectively caps the implicit tax associated with liquidity regulation at the level of the commitment fee and tamps down the undesirable volatility that would otherwise arise from an entirely quantity-based regime.\n\nMoreover, it bears reemphasizing that having a CLF with an up-front fee is very different from simply allowing banks to count central-bank-eligible collateral as HQLA at no charge. Rather, the CLF is like the pollution tax. For every dollar of pre-CLF shortfall--that is, for every dollar of required liquidity that a bank can't obtain on the private market--the bank has to pay the commitment fee. So even if there is not as much mitigation, there is still an incentive for conservation, in the sense that banks are encouraged to do less liquidity provision, all else being equal. This would not be the case if the CLF were available at a zero price.\n\nWhat about the situation in countries where safe assets are more plentiful? The analysis here has a number of moving parts because in addition to the implementation of the LCR, substantial increases in demand for safe assets will arise from new margin requirements for both cleared and noncleared derivatives. Nevertheless, given the large and growing global supply of sovereign debt securities, as well as other HQLA-eligible assets, most estimates suggest that the scarcity problem should be manageable, at least for the foreseeable future.\n\nIn particular, quantitative impact studies released by the Basel Committee estimate that the worldwide incremental demand for HQLA coming from both the implementation of the LCR and swap margin requirements might be on the order of $3 trillion.13 This is a large number, but it compares with a global supply of HQLA-eligible assets of more than $40 trillion.14 Moreover, the eligible collateral for swap margin is proposed to be broader than the LCR's definition of HQLA--including, for example, certain equities and corporate bonds without any cap. If one focuses just on U.S. institutions, the incremental demand number is on the order of $1 trillion, while the sum of Treasury, agency, and agency mortgage-backed securities is more than $19 trillion.15 \n\nWhile this sort of analysis is superficially reassuring, the fact remains that the HQLA premium will depend on market-equilibrium considerations that are hard to fully fathom in advance, and that are likely to vary over time. This uncertainty needs to be understood, and respected. Indeed, the market-equilibrium aspect of the problem represents a crucial distinction between capital regulation and liquidity regulation, and it is one reason why the latter is particularly challenging to implement. Although capital regulation also imposes a tax on banks‑‑to the extent that equity is a more expensive form of finance than debt--this tax wedge is, to a first approximation, a fixed constant for a given bank, independent of the scale of overall financial intermediation activity. If Bank A decides to issue more equity so it can expand its lending business, this need not make it more expensive for Bank B to satisfy its capital requirement. In other words, there is no scarcity problem with respect to bank equity--both A and B can always make more. By contrast, the total supply of HQLA is closer to being fixed at any point in time.16 \n\nPolicy Implications\nWhat does all of this imply for policy design? First, at a broad philosophical level, the recognition that liquidity regulation involves more uncertainty about costs than capital regulation suggests that even a policymaker with a very strict attitude toward capital might find it sensible to be somewhat more moderate and flexible with respect to liquidity. This point is reinforced by the observation that when an institution is short of capital and can't get more on the private market, there is really no backup plan, short of resolution. By contrast, as I mentioned earlier, when an institution is short of liquidity, policymakers do have a backup plan in the form of the LOLR facility. One does not want to rely too much on that backup plan, but its presence should nevertheless factor into the design of liquidity regulation.\n\nSecond, in the spirit of flexibility, while a price-based mechanism such as the CLF may not be immediately necessary in countries outside of Australia and a few others, it is worth keeping an open mind about the more widespread use of CLF-like mechanisms. If a scarcity of HQLA-eligible assets turns out to be more of a problem than we expect, something along those lines has the potential to be a useful safety valve, as it puts a cap on the cost of liquidity regulation. Such a safety valve would have a direct economic benefit, in the sense of preventing the burden of regulation from getting unduly heavy in any one country.\n\nPerhaps just as important, a safety valve might also help to protect the integrity of the regulation itself, by harmonizing costs across countries and thereby reducing the temptation of those most hard-hit by the rules to try to chip away at them. Without such a safety valve, it is possible that some countries--those with relatively small supplies of domestic HQLA--will find the regulation considerably more costly than others. If so, it would be natural for them to lobby to dilute the rules--for example, by arguing for an expansion in the type of assets that can count as HQLA. Taken too far, this sort of dilution would undermine the efficacy of the regulation as both a mitigator and a tax. In this scenario, holding the line with what amounts to a proportional tax on liquidity provision would be a better outcome.17 \n\nOne situation where liquid assets can become unusually scarce is during a financial crisis. Consequently, even if CLFs were not counted toward the LCR in normal times, it might be appropriate to count them during a crisis. Indeed, while the LCR requires banks to hold sufficient liquid assets in good times to meet their outflows in a given stress scenario, it implicitly recognizes that if things turn out even worse than that scenario, central bank liquidity support will be needed. Allowing CLFs to count toward the LCR in such circumstances would acknowledge the importance of access to the central bank, and this access could be priced accordingly.\n\nFinally, a price-based mechanism might also help promote a willingness of banks to draw down their supply of HQLA in a stress scenario. As I noted at the outset, one important concern about a pure quantity-based system of regulation is that if a bank is held to an LCR standard of 100 percent in normal times, it may be reluctant to allow its ratio to fall below 100 percent when facing large outflows for fear that doing so might be seen by market participants as a sign of weakness.\n\nBy contrast, in a system with something like a CLF, a bank might in normal times meet 95 percent of its requirement by holding private-market HQLA and the remaining 5 percent with committed credit lines from the central bank, so it would have an LCR of exactly 100 percent. Then, when hit with large outflows, it could maintain its LCR at 100 percent, but do so by increasing its use of central bank credit lines to 25 percent and selling 20 percent of its other liquid assets.18 This scenario would be the sort of liquid-asset drawdown that one would ideally like to see in a stress situation. Moreover, the central bank could encourage this drawdown by varying the pricing of its credit lines--specifically, by reducing the price of the lines in the midst of a liquidity crisis. Such an approach would amount to taxing liquidity provision more in good times than in bad, which has a stabilizing macroprudential effect.\n\nThis example also suggests a design that may have appeal in jurisdictions where there is a relatively abundant supply of HQLA-eligible assets. One can imagine calibrating the pricing of the CLF so as to ensure that lines provided by central banks make up only a minimal fraction of banks' required HQLA in normal times--apart, perhaps, from the occasional adjustment period after an individual bank is hit with an idiosyncratic liquidity shortfall. At the same time, in a stress scenario, when liquidity is scarce and there is upward pressure on the HQLA premium, the pricing of the CLF could be adjusted so as to relieve this pressure and promote usability of the HQLA buffer. Such an approach would respect the policy objective of reducing expected reliance on the LOLR while at the same time allowing for a safety valve in a period of stress. The limit case of this approach is one where the CLF counts toward the LCR only in a crisis.\n\nConclusion\nBy way of conclusion, let me just restate that liquidity regulation has a key role to play in improving financial stability. However, we should avoid thinking about it in isolation; rather, we can best understand it as part of a larger toolkit that also includes capital regulation and, importantly, the central bank's LOLR function. Therefore, proper design and implementation of liquidity regulations such as the LCR should take account of these interdependencies. In particular, policymakers should aim to strike a balance between reducing reliance on the LOLR on the one hand and moderating the costs created by liquidity shortages on the other hand--especially those shortages that crop up in times of severe market strain. And, as always, we should be prepared to learn from experience as we go.\n\n1. The views that follow are my own and are not necessarily shared by my colleagues on the Federal Reserve Board. I am grateful to members of the Board staff--Sean Campbell, Mark Carlson, Burcu Duygan-Bump, Michael Gibson, William Nelson, and Mark Van Der Weide--for many helpful conversations and suggestions. Return to text\n\n2. See Basel Committee on Banking Supervision (2013), Basel III: The Liquidity Coverage Ratio and Liquidity Risk Monitoring Tools (PDF) (Basel: Bank for International Settlements, January), p. 1. Return to text\n\n3. Although bank liquidity was not regulated prior to the crisis, it played an important part in the supervisory process. For example, in the CAMELS ratings used by supervisors, the \"L\" stands for \"liquidity.\" Return to text\n\n4. For an elaboration of this argument, see Anil K. Kashyap, Raghuram Rajan, and Jeremy C. Stein (2002), \"Banks as Liquidity Providers: An Explanation for the Coexistence of Lending and Deposit-Taking,\" Journal of Finance, vol. 57 (February), pp. 33-73. Return to text\n\n5. See Gary Gorton and George Pennacchi (1990), \"Financial Intermediaries and Liquidity Creation,\" Journal of Finance, vol. 45 (March), pp. 49-71. Demand deposits may also represent a form of insurance against liquidity shocks, as argued in Douglas W. Diamond and Philip H. Dybvig (1983), \"Bank Runs, Deposit Insurance, and Liquidity,\" Journal of Political Economy, vol. 91 (June), pp. 401-19. Return to text\n\n6. See Bengt Holmström and Jean Tirole (1998), \"Private and Public Supply of Liquidity,\" Journal of Political Economy, vol. 106 (February), pp. 1-40. Return to text\n\n7. See Diamond and Dybvig, \"Bank Runs,\" in note 5. Return to text\n\n8. The underlying premise of solvency is captured in Bagehot's famous dictum for use of the LOLR: In times of crisis, the central bank should lend freely (and at a penalty rate) to banks, provided that the banks are solvent and that the loans are adequately collateralized. See Walter Bagehot ([1873] 1999), Lombard Street: A Description of the Money Market (London: King; reprint, New York: Wiley). Return to text\n\n9. This is, of course, not to say that the LOLR should not be used in extreme circumstances--only that doing so comes with a cost, so policy should seek to reduce the likelihood that it will have to be used. Return to text\n\n10. The fact that broker-dealers do not have access to the LOLR in the United States is, of course, ultimately a policy choice, and one that can be thought of as reflecting exactly the considerations discussed here: Whatever its merits, extending the LOLR to broker-dealers would increase taxpayer exposure and potentially exacerbate moral hazard problems. Hence there may be a rationale for restricting its availability and relying on regulation instead. Return to text\n\n11. Even in this simple full-information case, one cannot generally attain the social optimum on both the mitigation and conservation dimensions using just a mandate to install scrubbers as the only regulatory instrument. By contrast, a tax on pollution, which decentralizes output and mitigation decisions to the firm, can, under full information, attain the optimum on both dimensions. Return to text\n\n12. On the flip side, however, the same flexibility means that there will be more variability in the total amount of pollution generated by the plant--because when costs of mitigation are high, less mitigation will be done. So in the face of uncertainty, one cannot conclude that a price-based tax regime is necessarily superior to a quantity-based mitigation regime. This reasoning follows the classic analysis of Weitzman; see Martin L. Weitzman (1974), \"Prices vs. Quantities,\" Review of Economic Studies, vol. 41 (October), pp. 477-91. Return to text\n\n13. To be more precise, global incremental demand coming from swap margin requirements is estimated at $1.24 trillion; see Basel Committee on Banking Supervision and Board of the International Organization of Securities Commissions (2013), Margin Requirements for Non-Centrally Cleared Derivatives: Second Consultative Document (Basel: Bank for International Settlements and IOSCO, February). Of this $1.24 trillion, $810 billion reflects margin (net of collateral already collected) on uncleared swaps, and $420 billion reflects margin on swaps that will migrate to central clearing. In addition, global incremental demand coming from the LCR is estimated at $2.39 trillion; see Basel Committee on Banking Supervision (2012), Results of the Basel III Monitoring Exercise as of 30 June 2011 (Basel: Bank for International Settlements, April). However this latter number is based on the December 2010 version of the LCR; the recalibration of the LCR in the January 2013 final version will reduce this value for U.S. banks by roughly one-third. Extrapolating this result to the global level suggests that incremental demand resulting from the LCR will fall by roughly $800 billion to $1.6 trillion. Return to text\n\n14. Committee on the Global Financial System (forthcoming), Asset Encumbrance, Financial Reform and the Demand for Collateral Assets (Basel: Bank for International Settlements). Return to text\n\n15. According to Federal Reserve Board flow of funds data, as of December 31, 2012 the total stock of U.S. Treasury securities stood at $11.6 trillion, and the total stock of agency debt and mortgage-backed securities stood at $7.5 trillion. A caveat here is that agency mortgage-backed securities are considered Level 2 assets, so they can count for at most 40 percent of any bank's total holdings of HQLA. Return to text\n\n16. This is not to say that banks cannot adjust on other margins if HQLA is in unexpectedly short supply. For example, they can do less liquidity provision, by terming out their funding or by extending fewer credit lines. This is like the power plant doing more conservation and less mitigation: It reduces the upward pressure on the price of scrubbers (or HQLA), at the cost of cutting back on a set of services that presumably has some social value. Return to text\n\n17. To be sure, it is possible that the rules could be diluted in the context of a price-based CLF mechanism as well, for example, through the administration of collateral-eligibility criteria or haircut requirements. Return to text\n\n18. This presumes that the bank in question is able to present adequate collateral to the central bank to secure the central bank credit line. Return to text"
    },
    {
        "title": "Evaluating Progress in Regulatory Reforms to Promote Financial Stability",
        "date": "May 03, 2013",
        "speaker": "Governor Daniel K. Tarullo",
        "url": "https://www.federalreserve.gov/newsevents/speech/tarullo20130503a.htm",
        "content": "May 03, 2013\n\nGovernor Daniel K. Tarullo\n\nAt the Peterson Institute for International Economics, Washington, D.C.\n\nMore than five years after the failure of Bear Stearns marked an escalation of the financial crisis, and nearly three years since the passage of the Dodd-Frank Act, debate continues over the appropriate set of policy responses to protect against financial instability. In recent months, there has been, in particular, a renewal of interest in additional measures to address the too-big-to-fail problem. In some respects, the persistence of debate is unsurprising. After all, the severity of the crisis and ensuing recession, and the frustratingly slow pace of economic recovery, have properly occasioned much thought about the structure of the financial system and the fundamentals of financial regulation.\n\nContinuing discussion of these issues is part of a protracted policy debate over financial regulatory reform. Some argue that little has changed and that the needed reform is a single, dramatic policy change (though that single policy differs considerably among those taking this view). Others argue that reforms already enacted are sufficient to ensure financial stability. Still others contend that there has already been too much of a regulatory response, which is suppressing credit extension and faster economic recovery.\n\nI think most of us would acknowledge, upon reflection, that a good bit has been done, or at least put in motion, to counteract the problems of too-big-to-fail and systemic risk more generally. At the same time, I believe that more is needed, particularly in addressing the risks posed by short-term wholesale funding markets. This afternoon I would like both to highlight the importance of what has already been accomplished and, at somewhat greater length, to identify what I believe to be the key steps that remain. Before turning to these subjects, though, I begin with a brief reprise of the origins of the financial crisis, to remind ourselves of the vulnerabilities that led to the crisis and that remain of concern today. It should, but does not always, go without saying that proposed solutions should actually help solve the problems at hand, and do so in a manner that minimizes the costs to otherwise productive activities.\n\nVulnerabilities Exposed by the Crisis\nBeginning in the 1970s, the separation of traditional lending and capital markets activities established by New Deal financial regulation began to break down under the weight of macroeconomic turbulence, technological and business innovation, and competition. During the succeeding three decades these activities became progressively more integrated, fueling the expansion of what has become known as the shadow banking system, including the explosive growth of securitization and derivative instruments in the first decade of this century.\n\nThis trend entailed two major changes. First, it diminished the importance of deposits as a source of funding for credit intermediation, in favor of capital market instruments sold to institutional investors. Over time, these markets began to serve some of the same maturity transformation functions as the traditional banking systems, which in turn led to both an expansion and alteration of traditional money markets. Ultimately, there was a vast increase in the creation of so-called cash equivalent instruments, which were supposedly safe, short-term, and liquid. Second, this trend altered the structure of the industry, both transforming the activities of broker-dealers and fostering the emergence of large financial conglomerates.\n\nThere was, in fact, a symbiotic relationship between the growth of large financial conglomerates and the shadow banking system. Large banks sponsored shadow banking entities such as Structured Investment Vehicles (SIVs), money market funds, asset-backed commercial paper conduits, and auction rate securities. These firms also dominated the underwriting of assets purchased by entities within the shadow banking system.\n\nThough motivated in part by regulatory arbitrage, these developments were driven by more than regulatory evasion. The growth and deepening of capital markets lowered financing costs for many companies and, through innovations such as securitization, helped expand the availability of capital for mortgage lending. Similarly, the rise of institutional investors as guardians of household savings made a wide array of investment and savings products available to a much greater portion of the American public.\n\nBut these changes also helped accelerate the fracturing of the system established in the 1930s. While the increasingly outmoded regulation of earlier decades was eroded, no new regulatory mechanisms were put in place to control new risks. When, in 2007, questions arose about the quality of some of the assets on which the shadow banking system was based--notably, those tied to poorly underwritten subprime mortgages--a classic adverse feedback loop ensued. Investors formerly willing to lend against almost any asset on a short-term, secured basis were suddenly unwilling to lend against a wide range of assets, notably including the structured products that had become central to the shadow banking system. Liquidity-strained institutions found themselves forced to sell positions, which placed additional downward pressure on asset prices, thereby accelerating margin calls on leveraged actors and amplifying mark-to-market losses for all holders of the assets. The margin calls and booked losses would start another round in the adverse feedback loop.\n\nSevere repercussions were felt throughout the financial system, as short-term wholesale lending against all but the very safest collateral froze up, regardless of the identity of the borrower. Moreover, as demonstrated by the intervention of the government when Bear Stearns and AIG were failing, and by the aftermath of Lehman Brothers' failure, the universe of financial firms that appeared too-big-to-fail during periods of stress extended beyond the perimeter of traditional safety and soundness regulation.\n\nIn short, the financial industry in the years preceding the crisis had been transformed into one that was highly vulnerable to runs on the short-term, uninsured cash equivalents that fed the new system's reliance on wholesale funding. The relationship between large firms and shadow banking meant that strains on wholesale funding markets could both reflect and magnify the too-big-to-fail problem. These were not the relatively slow-developing problems of the Latin American debt crisis, or even the savings and loan crisis, but fast-moving episodes that risked turning liquidity problems into insolvency problems almost literally overnight.\n\nHowever, note that while the presence of too-big-to-fail institutions substantially exacerbates the vulnerability created by the new system, they do not define its limits. Even in the absence of any firm that may individually seem too big or too interconnected to be allowed to fail, the financial system can be vulnerable to contagion. An external shock to important asset classes can lead to substantial uncertainty as to underlying values, a consequent reluctance by investors to provide short-term funding to firms holding those assets, a subsequent spate of fire sales and mark-to-market losses, and the potential for an adverse feedback loop.& An effective set of financial reforms must address both these related problems of too-big-to-fail and systemic vulnerability.\n\nRegulatory Response to Date\nAs is obvious from the scope of the Dodd-Frank Wall Street Reform and Consumer Protection Act and the amount of activity at the regulatory agencies, reform efforts to date have been extensive. They have also been significant. Without trying to give a full review, let me draw your attention to some of the more notable accomplishments, which can be categorized in three groups.\n\nFirst, the basic prudential framework for banking organizations is being considerably strengthened, both internationally and domestically. Central to this effort are the Basel III changes to capital standards, which create a new requirement for a minimum common equity capital ratio. This new standard requires substantial increases in both the quality and quantity of the loss-absorbing capital that allows a firm to remain a viable financial intermediary. Basel III also established for the first time an international minimum leverage ratio which, unlike the traditional U.S. leverage requirement, takes account of off-balance-sheet items.\n\nSecond, a series of reforms have been targeted at the larger financial firms that are more likely to be of systemic importance. When fully implemented, these measures will have formed a distinct regulatory and supervisory structure on top of generally applicable prudential regulations and supervisory requirements. The governing principle for this new set of rules is that larger institutions should be subject to more exacting regulatory and supervisory requirements, which should become progressively stricter as the systemic importance of a firm increases.\n\nThis principle has been codified in Section 165 of the Dodd-Frank Act, which requires special regulations applicable with increasing stringency to large banking organizations.1 Under this authority, the Federal Reserve will impose capital surcharges on the eight large U.S. banking organizations identified in the Basel Committee agreement for additional capital requirements on banking organizations of global systemic importance. The size of a surcharge will vary depending on the relative systemic importance of the bank. Other rules to be applied under Section 165--including counterparty credit risk limits, stress testing, and the quantitative short-term liquidity requirements included in the internationally-negotiated Liquidity Coverage Ratio (LCR)--will apply only to large institutions, in some cases with stricter standards for firms of greatest systemic importance.\n\nAn important, related reform in Dodd-Frank was the creation of orderly liquidation authority, under which the Federal Deposit Insurance Corporation can impose losses on a failed systemic institution's shareholders and creditors and replace its management, while avoiding runs and preserving the operations of the sound, functioning parts of the firm. This authority gives the government a real alternative to the Hobson's choice of bailout or disorderly bankruptcy that authorities faced in 2008. Similar resolution mechanisms are under development in other countries, and international consultations are underway to plan for cooperative efforts to resolve multinational financial firms.\n\nA third set of reforms has been aimed at strengthening financial markets generally, without regard to the status of relevant market actors as regulated or systemically important. The greatest focus, as mandated under Titles VII and VIII of Dodd-Frank, has been on making derivatives markets safer through requiring central clearing for derivatives that can be standardized and creating margin requirements for derivatives that continue to be written and traded outside of central clearing facilities. The relevant U.S. agencies are working with their international counterparts to produce an international arrangement that will harmonize these requirements so as to promote both global financial stability and competitive parity. In addition, eight financial market utilities engaged in important payment, clearing, and settlement activities have been designated by the Financial Stability Oversight Council as systemically important and, thus, will now be subject to enhanced supervision.\n\nAs you can tell from my description, many of these reforms are still being refined or are still in the process of implementation. The rather deliberate pace--occasioned as it is by the rather complicated domestic and international decisionmaking processes--may be obscuring the significance of what will be far-reaching change in the regulation of financial firms and markets. Indeed, even without full implementation of all the new regulations, the Federal Reserve has already used its stress-test and capital-planning exercises to prompt a doubling in the last four years of the common equity capital of the nation's 18 largest bank holding companies, which hold more than 70 percent of the total assets of all U.S. bank holding companies. The weighted tier 1 common equity ratio, which compares high-quality capital to risk-weighted assets, of these 18 firms rose from 5.6 percent at the end of 2008 to 11.3 percent in the fourth quarter of 2012, reflecting an increase in tier 1 common equity from $393 billion to $792 billion during the same period.\n\nGaps in Regulatory Reform\nDespite this considerable progress, we have not yet adequately addressed all the vulnerabilities that developed in our financial system in the decades preceding the crisis. Most importantly, relatively little has been done to change the structure of wholesale funding markets so as to make them less susceptible to damaging runs. It is true that some of the clearly risky forms of wholesale funding that existed before the crisis, such as the infamous SIVs, have disappeared or substantially contracted. But significant continuing vulnerability remains, particularly in those funding channels that can be grouped under the heading of securities financing transactions (SFTs).2 \n\nRepo, reverse repo, securities lending and borrowing, and securities margin lending are part of the healthy functioning of the securities market. But, in the absence of sensible regulation, they are also potentially associated with the dynamic I described earlier of exogenous shocks to asset values leading to an adverse feedback loop of mark-to-market losses, margin calls, and fire sales. Indeed, some have argued that this dynamic is exacerbated by a \"maturity rat race,\" in which each creditor acts to shorten the maturity of its lending so as to facilitate quick and easy flight, and in which creditors pay relatively little attention to the recovery value of the underlying assets.3 \n\nWith respect to the too-big-to-fail problem, as I noted earlier, actual capital levels are substantially higher than before the crisis, and requirements to extend and maintain higher levels of capital are on the way. The regularization and refinement of rigorous stress testing may be the single most important supervisory improvement to strengthen the resilience of large institutions. The creation of orderly liquidation authority and the process of resolution planning advance prospects for increasing market discipline.  But questions remain as to whether all this is enough to contain the problem. The enduring potential fragility of a financial system substantially dependent on short-term wholesale funding is especially relevant in considering the impact of severe stress or failure at the very large institutions with very large amounts of such funding.\n\nConcern about the adequacy of policy responses to date is supported by some recent research that attempts to quantify the implicit funding subsidy enjoyed by certain institutions by looking to such factors as credit ratings uplifts, differentials in interest rates paid on deposits or in risk compensation for bank debt and equity, and premia paid for mergers that would arguably place the merged firm in the too-big-to-fail category.4 The calculation of a precise subsidy is difficult, and each such effort will likely occasion substantial disagreement. But several measures provide at least directionally consistent results.\n\nKey Additional Reform Measures\nIn sketching out the kinds of steps needed to address these remaining vulnerabilities, let me begin with wholesale funding generally, and then circle back to too-big-to-fail.\n\nShort-Term Wholesale Funding.\nAt a conceptual level, the policy goal is fairly easy to state: a regulatory charge or other measure that applies more or less comprehensively to all uses of short-term wholesale funding, without regard to the form of the transactions or whether the borrower was a prudentially regulated institution. The aspiration to comprehensiveness is important for two reasons. First, the risks associated with short-term funding are as much or more macroprudential as they are firm-specific. From a microprudential perspective, SFTs are low risk, because the borrowing is short-dated, overcollateralized, marked-to-market daily, and subject to remargining requirements. The dangers arise in the tail and apply to the entire financial market when the normally safe, short-term lending contracts dramatically in the face of sudden and significant uncertainty about asset values and the condition of counterparties. A regulatory measure should force some internalization by market actors of the systemic costs of this intermediation.\n\nSecond, to the degree that regulatory measures apply only to some types of wholesale funding, or only to that used by prudentially regulated entities, there will be a growing risk of regulatory arbitrage. Ideally, the regulatory charge should apply whether the borrower is a commercial bank, broker-dealer, agency Real Estate Investment Trust (REIT), or hedge fund.\n\nStating the goal is easy, but executing it is not, precisely because short-term wholesale funding is used in a variety of forms by a variety of market actors. Determining appropriately equivalent controls is a challenging task and, with respect to institutions not subject to prudential regulation, there may be questions as to where--if at all--current regulatory authority resides. And, of course, there is the overarching problem of calibrating the regulation so as to mitigate the systemic risks associated with these funding markets, while not suppressing the mechanisms that have become important parts of the modern financial system in providing liquidity and lowering borrowing costs for both financial and non-financial firms. For all these reasons, it may well be that the abstract desirability of a single, comprehensive regulatory measure may not be achievable in the near term.\n\nStill, at least as a starting point, we would do well to consider measures that apply broadly. One option is to change minimum requirements for capital, liquidity, or both at all regulated firms so as to realize a macroprudential, as well as microprudential, purpose. In their current form, existing and planned liquidity requirements produced by the Basel Committee aim mostly to encourage maturity-matched books. While maturity mismatch by core intermediaries is a key financial stability risk in wholesale funding markets, it is not the only one. Even if an intermediary's book of securities financing transactions is perfectly matched, a reduction in its access to funding can force the firm to engage in asset fire sales or to abruptly withdraw credit from customers. The intermediary's customers are likely to be highly leveraged and maturity transforming financial firms as well, and, therefore, may then have to engage in fire sales themselves. The direct and indirect contagion risks are high. Thus, the long-term and short-term liquidity ratios might be refashioned so as to address directly the risks of large SFT books.\n\nSimilarly, existing bank and broker-dealer risk-based capital rules do not reflect fully the financial stability risks associated with SFTs. Accordingly, higher, generally applicable capital charge applied to SFTs might be a useful piece of a complementary set of macroprudential measures, though an indirect measure like a capital charge might have to be quite large to create adequate incentive to temper the use of short-term wholesale funding.\n\nBy definition, both liquidity and capital requirements would be limited to banking entities already within the perimeter of prudential regulation. The obvious questions are whether these firms at present occupy enough of the wholesale funding markets that standards applicable only to them would be reasonably effective in addressing systemic risk and, even if that question is answered affirmatively, whether the imposition of such standards would soon lead to significant arbitrage through increased participation by those outside the regulatory circle.\n\nIn part for these reasons, a second possibility that has received considerable attention is a universal minimum margining requirement applicable directly to SFTs. The Financial Stability Board has already issued a consultative paper, and received public comment, on the idea. Under such a regime, all repo lenders, for example, could be required to take a minimum amount of over-collateralization as determined by regulators (the amount varying with the nature of the securities collateral), regardless of whether the repo lender or repo borrower were otherwise prudentially regulated. This kind of requirement could be an effective tool to limit procyclicality in securities financing and, thereby, to contain the risks of runs and contagion. Of course, it also raises many of the issues that make settling on a single policy instrument so hard to achieve,5 and the decision on calibration would be particularly consequential. Still, the concept has much to be said for it and seems the most promising avenue toward satisfying the principle of comprehensiveness. It is definitely worth pursuing.\n\nAs you can tell, there is not yet a blueprint for addressing the basic vulnerabilities in short-term wholesale funding markets. Accordingly, the risks of runs and contagion remain. For the present, we can continue to work on discrete aspects of these markets, such as through the diminution of reliance on intraday credit in triparty repo markets that is being achieved by Federal Reserve supervision of clearing banks and through the money market fund reforms that I expect will be pursued by the Securities and Exchange Commission. We might also think about less comprehensive measures affecting SFTs, such as limits on rehypothecation, when an institution uses assets that have been posted as collateral by its clients for its own purposes.6 But I do not think that the post-crisis program of regulatory reform can be judged complete until a more comprehensive set of measures to address this problem is in place.\n\nToo-Big-to-Fail.\nBefore discussing policies specifically directed at too-big-to-fail, let me say a word about the capital regime that should be applicable to all banks, on top of which any additional requirements for systemically important institutions would be built. The first order of business is to complete the Basel III rulemaking as soon as possible. The required increases in the quality and quantity of minimum capital, and the introduction of an international leverage ratio, represent important steps forward for banking regulation around the world. U.S. banks have increased their capital substantially since the financial crisis began, and the vast majority already have Tier 1 common risk-based ratios greater than the Basel III 7 percent requirements.\n\nThe new requirements, while big improvements, are not as high as I would have liked, and the agreement contains some provisions I would have omitted or simplified. In coming years we may well seek changes. Indeed, I continue to be a strong advocate of establishing simpler, standardized risk-based capital requirements and am encouraged at the initial work being done on the topic of simplification in the Basel Committee. And we will certainly simplify the final capital rules here in the United States so as to respond to the concerns expressed by smaller banks. But opposing, or seeking delay in, Basel III would simply give an excuse to banks that do not meet Basel III standards to seek delay from their own governments. It would be ironic indeed if those who favor higher or simpler capital requirements were unintentionally to lend assistance to banks that want to avoid strengthening their capital positions.\n\nTurning to specific policies to address too-big-to-fail, the first task is to implement fully the capital surcharge for systemically important institutions, the LCR, resolution plans, and other relevant proposed regulations. But, completion of this agenda, significant as it is, would leave more too-big-to-fail risk than I think is prudent. What more, then, should be done? As I have said before, proposals to impose across-the-board size caps or structural limitations on banks--whatever their merits and demerits--embody basic policy decisions that are properly the province of Congress.7 \n\nHowever, that does not mean there is no role for regulators. On the contrary, Section 165 of the Dodd-Frank Act gives the Federal Reserve the authority, and the obligation, to apply regulations of increasing stringency to large banking organizations in order to mitigate risks to financial stability. In any event, it is unlikely that the problems associated with too-big-to-fail institutions can be efficiently ameliorated using a single regulatory tool. The explicit expectation in Section 165 that there will be a variety of enhanced standards seems well-advised. We should be considering ways to use this authority in pursuit of three complementary ends: (1) ensuring the loss absorbency needed for a credible and effective resolution process, (2) augmenting the going-concern capital of the largest firms, and (3) addressing the systemic risks associated with the use of wholesale funding.\n\nThere is clear need for a requirement that large financial institutions have minimum amounts of long-term unsecured debt that could be converted to equity and thereby be available to absorb losses in the event of insolvency. Although the details will, as always, be important, there appears to be an emerging consensus among regulators, both here and abroad, in support of the general idea. Debt subject to this kind of bail-in would supplement the increased regulatory capital in order to provide greater assurance that, should the firm become insolvent, all losses could be borne using resources within the firm. This requirement for additional \"gone concern\" capital would increase the prospects for orderly resolution and, thereby, counteract the moral hazard associated with expectations of taxpayer bailouts. Switzerland has already adopted a requirement of this sort, and similar proposals are being actively debated in the European Union. A U.S. requirement, enacted under the Federal Reserve's Section 165 authority, would both strengthen our domestic resolution mechanisms and be consistent with emerging international practice.\n\nWith respect to \"going concern\" capital requirements, there is a good case for additional measures to increase the chances that large financial institutions remain viable financial intermediaries even under stress. To me, at least, the important question is not whether capital requirements for large banking firms need to be stronger than those included in Basel III and the agreement on capital surcharges, but how to make them so and with what specific risks in mind. In this regard, I would observe that our stress tests and capital-planning requirements have already strengthened capital standards by making them more forward-looking and more responsive to economic developments. As we gain experience, and as the annual process becomes smoother for both the banks and the Federal Reserve, we have the opportunity to enhance the stress tests by, for example, varying the scenario for stressing the trading books of the largest firms, so as to reflect changes in the composition of those books.\n\nAs to regulatory measures of capital outside the customized context of stress testing, one approach is to revisit the calibration of two existing capital measures applicable to the largest firms. The first is the leverage ratio. U.S. regulatory practice has traditionally maintained a complementary relationship between the greater sensitivity of risk-based capital requirements and the check provided by the leverage ratio on too much leverage arising from low-risk-weighted assets. This relationship has obviously been changed by the substantial increase in the risk-based ratio resulting from the new minimum and conservation buffer requirements of Basel III. The existing U.S. leverage ratio does not take account of off-balance-sheet assets, which are significant for many of the largest firms. The new Basel III leverage ratio does include off-balance-sheet assets, but it may have been set too low. Thus, the traditional complementarity of the capital ratios might be maintained by using Section 165 to set a higher leverage ratio for the largest firms.\n\nThe other capital measure that might be revisited is the risk-based capital surcharge mechanism. The amounts of the surcharges eventually agreed to in Basel were at the lower end of the range needed to achieve the aim of reducing the probability of these firms' failures enough to offset fully the greater impact their failure would have on the financial system. At the time these surcharges were being negotiated, I favored a somewhat greater requirement for the largest, most interconnected firms.8 Here, after all, is where the potential for negative externalities is the greatest, while the marginal benefits accruing from scale and scope economies are hardest to discern. While it is clearly preferable at this point to implement what we have agreed, rather than to seek changes that could delay any additional capital requirement, it may be desirable for the Basel Committee to return to this calibration issue sooner rather than later.\n\nThe area in which the most work is needed is in addressing the risks arising from the use of short-term wholesale funding by systemically important firms. The systemic risks associated with runs on wholesale funding would, almost by definition, be exacerbated if a very large user of that funding were to come under serious stress. There could also be greater negative externalities from a disruption of large, matched SFT positions on the books of a major financial firm than if the same total activity were spread among a greater number of dealers. Thus, in keeping with the principle of differential and increasingly stringent regulation for large firms, there is a strong case to be made for taking steps beyond any generally applicable measures that are eventually applied to SFTs or short-term wholesale funding more generally.\n\nOne possibility would be to have progressively greater minimum liquidity requirements for larger institutions under the LCR and the still-under-construction Net Stable Funding Ratio (NSFR).9 There is certainly some appeal to following this route, since it would build on all the work done in fashioning these liquidity requirements. The only significant additional task would be calibrating the progressivity structure. However, there are at least two disadvantages to this approach. First, the LCR and, at least at this stage of its development, the NSFR, both rest on the implicit presumption that a firm with a perfectly matched book is in a fundamentally stable position. As a microprudential matter, this is probably a reasonable assumption. But under some conditions, the disorderly unwind of a single, large SFT book, even one that was quite well maturity matched, could set off the kind of unfavorable dynamic described earlier. Second, creating liquidity levels substantially higher than those contemplated in the LCR and eventual NSFR may not be the most efficient way for some firms to become better insulated from the run risk that can lead to the adverse feedback loop and contagion possibilities discussed earlier.\n\nA more interesting approach would be to tie liquidity and capital standards together by requiring higher levels of capital for large firms unless their liquidity position is substantially stronger than minimum requirements. This approach would reflect the fact that the market perception of a given firm's position as counterparty depends upon the combination of its funding position and capital levels. It would also supplement the Basel capital surcharge system, which does not include use of short-term wholesale funding among the factors used to calculate the systemic \"footprint\" of each firm, and thus determine its relative surcharge.\n\nWhile there is decidedly a need for solid minimum requirements for both capital and liquidity, the relationship between the two also matters. Where a firm has little need of short-term funding to maintain its ongoing business, it is less susceptible to runs. Where, on the other hand, a firm is significantly dependent on such funding, it may need considerable common equity capital to convince market actors that it is indeed solvent. Similarly, the greater or lesser use of short-term funding helps define a firm's relative contribution to the systemic risk latent in these markets.\n\nIf realized, this approach would allow a firm of systemic importance to choose between holding capital in greater amounts than would otherwise be required, or changing the amount and composition of its liabilities in order to reduce the contribution it could make to systemic risk in the event of a shock to short-term funding channels. The additional capital requirements might be tied, for example, to specified scores under an NSFR that had been reworked significantly so as to take account of the macroprudential implications of wholesale funding discussed earlier. If one wished to maintain the practice of grounding capital requirements in measures of assets, another possibility would be to add as a capital surcharge a specified percentage of assets measured so as to weight most heavily those associated with short-term funding.\n\nTo provide a meaningful counterweight to the risks associated with wholesale funding runs, the additional capital requirement would have to be material. The highest requirement would be at just the point where a firm had the minimum required level of liquidity. The requirement then would diminish as the liquidity score of the firm rose sufficiently above minimum required levels. If the requirement were significant enough and likely to apply to any large institution with substantial capital market activities, it might also be a substitute for increasing the capital surcharge schedule already agreed to in Basel.\n\nI readily acknowledge that calibrating the relationship would not be easy, and that the stakes for both financial stability and financial efficiency in getting it right would be significant. But I think this approach is worth exploring, precisely because it rests upon the link between too-big-to-fail concerns and the runs and contagion that we experienced five years ago, and to which we remain vulnerable today. Whether it proves feasible, or whether we would have to fall back on the more straightforward approach of strengthening liquidity requirements for systemically important firms, the key point is that the principle of increasing stringency be applied.\n\nConclusion\nOf late I find myself of two minds on the question of bringing to a close the major elements of regulatory change following the financial crisis. On the one hand, I strongly believe that all the regulatory agencies should complete as soon as possible the remaining rulemakings generated by Dodd-Frank and Basel III. It is important that banks and other financial market actors know the rules that will govern capital standards, proprietary trading, mortgage lending, and other activities. In fact, we should monitor whether these rules end up having significant unintended effects on credit availability and, if so, modify them in a manner consistent with basic aims of safety and soundness and consumer protection.\n\nOn the other hand, I equally strongly believe that we would do the American public a fundamental disservice were we to declare victory without tackling the structural weaknesses of short-term wholesale funding markets, both in general and as they affect the too-big-to-fail problem. This is the major problem that remains, and I would suggest that additional reform measures be evaluated by reference to how effective they could be in solving it.\n\n \n\n1. The operative statutory language reads as follows: \"In order to prevent or mitigate risks to the financial stability of the United States that could arise from the material financial distress or failure, or ongoing activities, of large, interconnected financial institutions, the Board of Governors shall...establish prudential standards for nonbank financial companies supervised by the Board of Governors and bank holding companies with total consolidated assets equal to or greater than [$50 billion] that...are more stringent than the standards and requirements applicable to [other regulated firms] and...increase in stringency.\" Return to text\n\n2. For these reasons, there has been an instinct to address various aspects of wholesale funding discretely. Hence the attention paid by the Federal Reserve and other regulators to money market funds, and the steps taken by the Federal Reserve to reduce the risks associated with the extension of intraday credit by clearing banks in triparty repo funding markets. These discrete steps are useful, particularly insofar as they cast light on implicit, but unpriced, support for short-term funding that has been provided by some financial intermediaries. But they do not address head-on the dynamic described in the text. Return to text\n\n3. Markus K. Brunnermeier and Martin Oehmke (2013), \"The Maturity Rat Race, \" The Journal of Finance, vol. 68(2) (April), pp. 483-521. Return to text\n\n4. See, for example, Kenichi Ueda and Beatrice Weder di Mauro (2012), \"Quantifying Structural Subsidy Values for Systemically Important Financial Institutions, \" International Monetary Fund Working Paper (May); Stefan Jacewitz and Jonathan Pogach (2013), \"Deposit Rate Advantages at the Largest Banks,\" FDIC Working Paper (April 16); Dale Gray and Andreas A. Jobst (2010), \"New Directions in Financial Sector and Sovereign Risk Management,\" Journal of Investment Management, vol. 8, no. 1, pp. 23-38; and Elijah Brewer II and Julapa Jagtiani (2013), \"How Much Did Banks Pay to Become Too-Big-To-Fail and to Become Systemically Important?\" Journal of Financial Services Research, vol. 43, pp. 1-35. Estimating the exact size of this funding advantage depends on a number of assumptions as well as contemporaneous market conditions and is difficult to quantify robustly. Estimates must consider a number of factors, including market participants' beliefs about the likelihood of an institution's failure, the value of a government bailout of debt holders were it to occur, and the likelihood that the government would actually choose to bail out debt holders in the event of a failure. Return to text\n\n5. To give just one example: Securities lending sometimes involves an exchange of securities for securities and sometimes involves an exchange of cash for securities. Determining whether and/or how to apply a universal margining requirement to securities lending transactions of both varieties would be challenging. Return to text\n\n6. Rehypothecation of fully paid customer securities held by broker-dealers not only permits a kind of money creation by broker-dealers, it also can put the securities of the customer at risk, as was seen after the Lehman failure, when some clients found that their securities had been reused by the firm's London office in a way that made them difficult to reclaim. In the United States, the Securities and Exchange Commission has long limited, though not prohibited, rehypothecation of customer securities. Other countries may try to limit the practice informally, but have no formal rules. Given the combined macroprudential and investor protection concerns raised by rehypothecation, a review of current U.S. limits, and the adoption of rules by other relevant countries, seems a logical and, relative to some other proposals, feasible step. Return to text\n\n7. See Daniel K. Tarullo (2012), \"Financial Stability Regulation,\" speech delivered at the Distinguished Jurist Lecture, University of Pennsylvania Law School, October 10. Return to text\n\n8. See, for example, Daniel K. Tarullo (2011), \"Regulating Systemically Important Financial Firms,\" speech delivered at the Peter G. Peterson Institute for International Economics, June 3. Return to text\n\n9. For more about the LCR and the NSFR, see Bank for International Settlements (2013), \"Group of Governors and Heads of Supervision endorses revised liquidity standard for banks, \" press release, January 6. Return to text"
    },
    {
        "title": "A View from the Federal Reserve Board: The Mortgage Market and Housing Conditions",
        "date": "May 09, 2013",
        "speaker": "Governor Elizabeth A. Duke",
        "url": "https://www.federalreserve.gov/newsevents/speech/duke20130509a.htm",
        "content": "May 09, 2013\n\nGovernor Elizabeth A. Duke\n\nAt the Housing Policy Executive Council, Washington, D.C.\n\nSince joining the Board in 2008 amid a crisis centered on mortgage lending, I have focused much of my attention on housing and mortgage markets, issues surrounding foreclosures, and neighborhood stabilization. In March of this year, I laid out my thoughts on current conditions in the housing and mortgage markets in a speech to the Mortgage Bankers Association.1 Today I will summarize and update that information with a focus on mortgage credit conditions. Before I proceed, I should note that the views I express are my own and not necessarily those of my colleagues on the Board of Governors or the Federal Open Market Committee.\n\nA sustained recovery in the housing market appears to be under way. House prices, as measured by a variety of national indexes, have risen 6 to 11 percent since the beginning of 2012 (figure 1).2 The recovery of house prices has been broad based geographically, with 90 percent of local markets having experienced price gains over the year ending in February. Also since the beginning of 2012, housing starts and permits have risen by nearly 30 percent (figure 2), while new and existing home sales have also seen double-digit growth rates. Homebuilder sentiment has improved notably, and real estate agents report stronger traffic of people shopping for homes (figure 3).3 In national surveys, households report that low interest rates and house prices make it a good time to buy a home; they also appear more certain that house price gains will continue (figure 4).4 \n\nDespite the recent gains, the level of housing market activity remains low. Existing home sales are currently at levels in line with those seen in the late 1990s, while single-family starts and permits are at levels commensurate with the early 1990s. And applications for home-purchase mortgages, as measured by the Mortgage Bankers Association index, were at a level in line with that of the mid-1990s (figure 5). The subdued level of mortgage purchase originations is particularly striking given the record low mortgage rates that have prevailed in recent years.\n\nThe drop in originations has been most pronounced among borrowers with lower credit scores. For example, between 2007 and 2012, originations of prime purchase mortgages fell about 30 percent for borrowers with credit scores greater than 780, compared with a drop of about 90 percent for borrowers with credit scores between 620 and 680 (figure 6).5 Originations are virtually nonexistent for borrowers with credit scores below 620. The distribution of credit scores in these purchase origination data tells the same story in a different way: The median credit score on these originations rose from 730 in 2007 to 770 in 2013, whereas scores for mortgages at the 10th percentile rose from 640 to 690 (figure 7).\n\nMany borrowers who have faced difficulty in obtaining prime mortgages have turned to mortgages insured or guaranteed by the Federal Housing Administration (FHA), the U.S. Department of Veterans Affairs (VA), or the Rural Housing Service (RHS). Data collected under the Home Mortgage Disclosure Act indicate that the share of purchase mortgages guaranteed or insured by the FHA, the VA, or the RHS rose from 5 percent in 2006 to more than 40 percent in 2011 (figure 8).6 But here, too, loan originations appear to have contracted for borrowers with low credit scores. The median credit score on FHA purchase originations increased from 625 in 2007 to 690 in 2013, while the 10th percentile has increased from 550 to 650 (figure 9).7 \n\nPart of the contraction in loan originations to households with lower credit scores may reflect weak demand among these potential homebuyers. Although we have little data on this point, it may be the case that such households suffered disproportionately from the sharp rise in unemployment during the recession and thus have not been in a financial position to purchase a home.\n\nThere is evidence that tight mortgage lending conditions may also be a factor in the contraction in originations. Data from lender rate quotes suggest that almost all lenders have been offering quotes (through the daily \"rate sheets\" provided to mortgage brokers) on mortgages eligible for sale to the government-sponsored enterprises (GSEs) to borrowers with credit scores of 750 over the past two years.8 Most lenders have been willing to offer quotes to borrowers with credit scores of 680 as well. Fewer than two-thirds of lenders, though, are willing to extend mortgage offers to consumers with credit scores of 620 (figure 10).9 And this statistic may overstate the availability of credit to borrowers with lower credit scores: The rates on many of these offers might be unattractive, and borrowers whose credit scores indicate eligibility may not meet other aspects of the underwriting criteria.\n\nTight credit conditions also appear to be part of the story for FHA-insured loans. In the Federal Reserve's October 2012 Senior Loan Officer Opinion Survey on Bank Lending Practices (SLOOS), one-half to two-thirds of respondents indicated that they were less likely than in 2006 to originate an FHA loan to a borrower with a credit score of 580 or 620 (figure 11). Standards have tightened a bit further since: In the April 2013 SLOOS, about 30 percent of lenders reported that they were less likely than a year ago to originate FHA mortgages to borrowers with a credit score of 580 or 620 (figure 12).10 \n\nThe April SLOOS offers some clues about why mortgage credit is so tight for borrowers with lower credit scores. Banks participating in the survey identified a familiar assortment of factors as damping their willingness to extend any type of loan to these borrowers: the risk that lenders will be required to repurchase defaulted loans from the GSEs (\"putback\" risk), the outlook for house prices and economic activity, capacity constraints, the risk-adjusted opportunity cost of such loans, servicing costs, balance sheet or warehousing capacity, guarantee fees charged by the GSEs, borrowers' ability to obtain private mortgage insurance or second liens, and investor appetite for private-label mortgage securitizations. Respondents appeared to put particular weight on GSE putbacks, the economic outlook, and the risk-adjusted opportunity cost. In addition, several large banks cited capacity constraints and borrowers' difficulties in obtaining private mortgage insurance or second liens as at least somewhat important factors in restraining their willingness to approve such loans.\n\nOver time, some of these factors should exert less of a drag on mortgage credit availability. For example, as the economic and housing market recovery continues, lenders should gain confidence that mortgage loans will perform well, and they should expand their lending accordingly.\n\nCapacity constraints will likely also ease. Refinancing applications have expanded much more over the past year and a half than lenders' ability to process these loans. For example, one measure of capacity constraints--the number of real estate credit employees--has only edged up over this period (figure 13). When capacity constraints are binding, lenders may prioritize the processing of easier-to-complete or more profitable loan applications. Indeed, preliminary research by the Board's staff suggests that the increase in the refinance workload during the past 18 months appears to have been associated with a 25 to 35 percent decrease in purchase originations among borrowers with credit scores between 620 and 680 and a 10 to 15 percent decrease among borrowers with credit scores between 680 and 710.11 Any such crowding-out effect should start to unwind as the current refinancing boom decelerates.\n\nOther factors holding back mortgage credit, however, may be slower to unwind. As the SLOOS results indicate, lenders remain concerned about putback risk. The ability to hold lenders accountable for poorly underwritten loans is a significant protection for taxpayers. However, if lenders are unsure about the conditions under which they will be required to repurchase loans sold to the GSEs, they may shy away from originating loans to borrowers whose risk profiles indicate a higher likelihood of default. The Federal Housing Finance Agency launched an important initiative last year to clarify the liabilities associated with representations and warranties, but, so far, putback risk appears to still weigh on the mortgage market.\n\nMortgage servicing standards, particularly for delinquent loans, are more stringent than in the past due to settlement actions and consent orders. Servicing rules recently released by the Consumer Financial Protection Bureau (CFPB) will extend many of these standards to all lenders.12 These standards remedy past abuses and provide important protections to borrowers, but also increase the cost of servicing nonperforming loans. This issue is compounded by current servicing compensation arrangements under which servicers receive the same fee for the routine processing of current loans as they do for the more expensive processing of delinquent loans. This model--especially in conjunction with higher default-servicing costs--gives lenders an incentive to avoid originating loans to borrowers who are more likely to default. A change to servicer compensation models for delinquent loans could alleviate some of these concerns.\n\nGovernment regulations will also affect the cost of mortgage credit. In January, the CFPB released rules, in addition to those for servicing standards, on ability-to-repay requirements, the definition of a qualified mortgage (QM), and loan originator compensation.13 The Federal Reserve and other agencies are in the process of moving forward on proposed rulemakings that would implement revised regulatory capital requirements and the requirements for risk retention mandated by the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010, which include an exemption for mortgages that meet the definition of qualified residential mortgages (QRM).\n\nAs the regulatory capital and risk retention requirements are still under deliberation, I won't comment on these regulations today. However, I will share a few thoughts on the possible effects of the QM rulemaking on access to credit.\n\nAs background, the QM rule is part of a larger ability-to-repay rulemaking that requires lenders to make a reasonable and good faith determination that the borrower can repay the loan. The rulemaking addresses the lax underwriting practices that flourished during the housing boom by setting minimum underwriting standards and by providing borrowers with protections against lending abuses. In particular, borrowers can sue the lender for violations of the ability-to-repay rules and claim monetary damages. If the original lender sells or securitizes the loan, the borrower can claim these damages at any time in a foreclosure action taken by the lender or any assignee. If the mortgage meets the QM standard, however, the lender receives greater protection from such potential lawsuits because it is presumed that the borrower had the ability to repay the loan.\n\nLoans that fall outside the QM standard may be more costly to originate than loans that meet the standard for at least four reasons, all else being equal. The first reason is the possible increase in foreclosure losses and litigation costs. Although these costs, in the aggregate, are expected to be small, their full extent will not be known until the courts settle any ability-to-repay suits that may be brought forward.14 The second reason is that mortgages that do not meet the QM definition will also not qualify as QRMs, so lenders will be required to hold some of the risk if these loans are securitized.15 The third reason is that loan originators will have better information than investors on the quality of the underwriting decision. Investors may demand a premium to compensate them for the concern that originators might sell them the loans most vulnerable to ability-to-repay lawsuits. The fourth reason is that the non-QM market, at least initially, may be small and illiquid, which would increase the cost of these loans.\n\nThe higher costs associated with non-QM loans should have very little effect on access to credit in the near term because almost all current mortgage originations meet the QM standard. The vast majority of current originations are eligible to be purchased, insured, or guaranteed by Fannie Mae, Freddie Mac, the FHA, the VA, or the RHS. These loans are classified as QMs under the rule.16 The small proportion of mortgages originated at present outside of these programs, for the most part, are being underwritten to tight standards consistent with the QM definition.\n\nAs lender risk appetite increases and private capital returns to the mortgage market, a larger non-QM market should start to develop. Two aspects of the QM rule, though, may make this market slow to develop for borrowers with lower credit scores. First, the QM requirement that borrower payments on all debts and some recurring obligations must be 43 percent or less of borrower income may disproportionately affect less-advantaged borrowers.17 Board staff tabulations based on the Survey of Consumer Finances indicate that such households tend to have lower incomes, fewer financial assets, and higher mortgage loan-to-value ratios than households with lower payment ratios (figure 14).18 \n\nSecond, the QM definition affects lenders' ability to charge for the risks of originating loans to borrowers who are more likely to default. For example, lenders may in general compensate for this risk by charging a higher interest rate on the loan. However, if lenders originate a first-lien QM with an annual percentage rate that is 150 basis points or more above the rate available to the highest-quality borrowers, lenders receive less protection against lawsuits claiming violation of the ability-to-repay and QM rules.19 Lenders who prefer to price for risk through points and fees face the constraint that points and fees on a QM loan may not exceed 3 percent of the loan amount, with higher caps available for loans smaller than $100,000. The extent to which these rules regarding rates, points, and fees will damp lender willingness to originate mortgages to borrowers with lower credit scores is still unclear.\n\nTo summarize, the housing market is improving, but mortgage credit conditions remain quite tight for borrowers with lower credit scores. And the path to easier credit conditions is somewhat murky. Some of the forces damping mortgage credit availability, such as capacity constraints and concerns about economic conditions or house prices, are likely to unwind through normal cyclical forces. However, resolution of lender concerns about putback risk or servicing cost seems less clear. These concerns could be reduced by policy changes. For example, the structure of liability for representations and warrantees could be modified. Or servicing compensation could be changed to provide higher compensation for the servicing of delinquent loans. Or lenders might find ways to reduce their exposure to putback risk or servicing cost by strengthening origination and servicing platforms. New mortgage regulations will provide important protections to borrowers but may also lead to a permanent increase in the cost of originating loans to borrowers with lower credit scores. It will be difficult to determine the ultimate effect of the regulatory changes until they have all been finally defined and lenders gain familiarity with them.\n\nThe implications for the housing market are also murky. Borrowers with lower credit scores have typically represented a significant segment of first-time homebuyers. For example, in 1999, more than 25 percent of first-time homebuyers had credit scores below 620 compared with fewer than 10 percent in 2012 (figure 15).20 Although I expect housing demand to expand along with the economic recovery, if credit is hard to get, much of that demand may be channeled into rental, rather than owner-occupied, housing.\n\nAt the Federal Reserve, we continue to foster more-accommodative financial conditions and, in particular, lower mortgage rates through our monetary policy actions. We also continue to monitor mortgage credit conditions and consider the implications of our rulemakings for credit availability. For your part, I urge you to continue to develop new and more sustainable business models for lending to lower-credit-score borrowers that lead to better outcomes for borrowers, communities, and the financial system than we have experienced over the past few years.\n\n \n\n1. See Elizabeth A. Duke (2013), \"Comments on Housing and Mortgage Markets,\" speech delivered at \"Mid-Winter Housing Finance Conference,\" sponsored by the Mortgage Bankers Association, held in Avon, Colo., March 6-9. Return to text\n\n2. House price information is from staff calculations based on data from CoreLogic, Zillow, Standard & Poor's, and the Federal Housing Finance Agency. Return to text\n\n3. More details on homebuilder sentiment are available on the National Association of Home Builders website . Additional details on real estate agent assessments of market conditions are available at the National Association of Realtors® website . Return to text\n\n4. Household reports are from staff calculations based on results of the Thomson Reuters/University of Michigan Surveys of Consumers . Return to text\n\n5. These calculations are based on data provided by McDash Analytics, LLC, a wholly owned subsidiary of Lender Processing Services, Inc. The underlying data are provided by mortgage servicers. These servicers classify loans as \"prime,\" \"subprime,\" or \"FHA.\" Prime loans include those eligible for sale to the government-sponsored enterprises (GSEs) as well as those with favorable credit characteristics but loan sizes that exceed the GSE guidelines (\"jumbo\" loans). Return to text\n\n6. Staff calculations suggest that the FHA and VA market share dipped a bit in 2012 but remained quite elevated. These calculations are based on data provided by McDash Analytics, LLC, a wholly owned subsidiary of Lender Processing Services, Inc. Return to text\n\n7. The shift in the distributions may partly reflect changes in the FHA's underwriting guidelines. In 2010, the FHA required a minimum credit score of 580 in order to qualify for a loan with a 3.5 percent down payment. In 2013, the FHA required manual underwriting for loans with a credit score less than 620 and a debt-to-income ratio greater than 43 percent. See U.S. Department of Housing and Urban Development (2010), \"FHA Announces Policy Changes to Address Risk and Strengthen Finances,\" press release, January 20; and U.S. Department of Housing and Urban Development (2013), \"FHA Takes Additional Steps to Bolster Capital Reserves,\" press release, January 30. Return to text\n\n8. These quotes assume that the borrower supplies a 10 percent down payment. Return to text\n\n9. These data series begin in 2009 and 2010, so we cannot compare the current level of rate quotes to those that prevailed before the financial crisis. However, in response to a special question on the Federal Reserve's April 2012 Senior Loan Officer Opinion Survey on Bank Lending Practices, nearly 85 percent of lenders reported that they were somewhat or much less likely than in 2006 to originate a mortgage to a borrower with a credit score of 620 and a down payment of 10 percent. This response suggests that credit supply has contracted for such borrowers. Return to text\n\n10. The October 2012 and April 2013 surveys are available on the Federal Reserve Board's website. Return to text\n\n11. These estimates are smaller than the estimates in the March 2013 Mortgage Bankers Association speech because capacity constraints appear to have become less severe in recent months (see Duke, \"Comments on Housing and Mortgage Markets,\" in note 1). These estimates are for the period from February 2011 to February 2013. The March estimates were for the period from October 2010 to October 2012. Return to text\n\n12. See CFPB (2013), \"2013 Real Estate Settlement Procedures Act (Regulation X) and Truth in Lending Act (Regulation Z) Mortgage Servicing Final Rules,\" Regulations: Final Rules Issued by the CFPB 2013, webpage, January 17. Return to text\n\n13. For more on ability-to-repay requirements and the definition of a QM, see CFPB (2013), \"Ability to Repay and Qualified Mortgage Standards under the Truth in Lending Act (Regulation Z),\" Regulations: Final Rules Issued by the CFPB 2013, webpage, January 10.  For information on loan originator compensation, see CFPB (2013), \"Loan Originator Compensation Requirements under the Truth in Lending Act (Regulation Z),\" Regulations: Final Rules Issued by the CFPB 2013, webpage, January 20. Return to text\n\n14. The CFPB estimates of these costs are available at section VII.E.3. Return to text\n\n15. If a mortgage-backed security is collateralized by \"qualified residential mortgages,\" as defined by federal regulators consistent with section 941 of the Dodd-Frank Act, the securitizer is not required to retain any risk in the securitization transaction. Otherwise, the securitizer must retain an economic interest in the transaction consistent with section 941 and any regulations established thereunder, which may increase the securitizer's costs. The Dodd-Frank Act requires that Federal regulators set the definition of a QRM to be no broader than the definition of a QM. Return to text\n\n16. This provision is slated to end no later than January 2021. The Dodd-Frank Act gives the FHA, the VA, the U.S. Department of Agriculture, and the RHS the option to write separate QM regulations for their mortgages. Return to text\n\n17. Borrowers with debt-to-income (DTI) ratios greater than 43 percent may still be able to obtain QMs if the mortgage is guaranteed by the FHA or eligible for purchase by the GSEs. Return to text\n\n18. The tabulation is based on households that purchased a home with mortgage credit in the two years preceding the Board's Survey of Consumer Finances for 2001, 2004, 2007, and 2010. About 15 percent of borrowers in the 2001, 2004, and 2010 surveys and 25 percent in the 2007 survey had DTIs greater than 43 percent. The 2007 statistic was reported incorrectly in the March 2013 Mortgage Bankers Association speech (see Duke, \"Comments on Housing and Mortgage Markets,\" in note 1). DTI is measured at the time of the survey, not at the time of the loan origination, and may understate the number of affected households if household finances improve after the purchase of a home. Return to text\n\n19. The CFPB has proposed a higher spread threshold for first-lien QMs originated by small creditors and for certain types of balloon mortgages. Return to text\n\n20. Staff calculations are based on the Federal Reserve Bank of New York Consumer Credit Panel. First-time homebuyers are measured as consumers who have no record of ever having a mortgage at the end of the second quarter of a given year and opened a mortgage in the third quarter. This estimate includes all types of mortgages but excludes first-time homebuyers who purchased their homes with cash. The credit score was generated from the Equifax 3.0 risk model and measured the credit score as of the end of the second quarter. Consumers without a credit score are excluded from the analysis. Return to text"
    },
    {
        "title": "Monitoring the Financial System",
        "date": "May 10, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20130510a.htm",
        "content": "May 10, 2013\n\nChairman Ben S. Bernanke\n\nAt the 49th Annual Conference on Bank Structure and Competition sponsored by the Federal Reserve Bank of Chicago, Chicago, Illinois\n\nWe are now more than four years beyond the most intense phase of the financial crisis, but its legacy remains. Our economy has not yet fully regained the jobs lost in the recession that accompanied the financial near collapse. And our financial system--despite significant healing over the past four years--continues to struggle with the economic, legal, and reputational consequences of the events of 2007 to 2009.\n\nThe crisis also engendered major shifts in financial regulatory policy and practice. Not since the Great Depression have we seen such extensive changes in financial regulation as those codified in the Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank Act) in the United States and, internationally, in the Basel III Accord and a range of other initiatives. This new regulatory framework is still under construction, but the Federal Reserve has already made significant changes to how it conceptualizes and carries out both its regulatory and supervisory role and its responsibility to foster financial stability.\n\nIn my remarks today I will discuss the Federal Reserve's efforts in an area that typically gets less attention than the writing and implementation of new rules--namely, our ongoing monitoring of the financial system. Of course, the Fed has always paid close attention to financial markets, for both regulatory and monetary policy purposes. However, in recent years, we have both greatly increased the resources we devote to monitoring and taken a more systematic and intensive approach, led by our Office of Financial Stability Policy and Research and drawing on substantial resources from across the Federal Reserve System. This monitoring informs the policy decisions of both the Federal Reserve Board and the Federal Open Market Committee as well as our work with other agencies.\n\nThe step-up in our monitoring is motivated importantly by a shift in financial regulation and supervision toward a more macroprudential, or systemic, approach, supplementing our traditional microprudential perspective focused primarily on the health of individual institutions and markets. In the spirit of this more systemic approach to oversight, the Dodd-Frank Act created the Financial Stability Oversight Council (FSOC), which is comprised of the heads of a number of federal and state regulatory agencies. The FSOC has fostered greater interaction among financial regulatory agencies as well as a sense of common responsibility for overall financial stability. Council members regularly discuss risks to financial stability and produce an annual report, which reviews potential risks and recommends ways to mitigate them.1 The Federal Reserve's broad-based monitoring efforts have been essential for promoting a close and well-informed collaboration with other FSOC members.\n\nA Focus on Vulnerabilities\nOngoing monitoring of the financial system is vital to the macroprudential approach to regulation. Systemic risks can only be defused if they are first identified. That said, it is reasonable to ask whether systemic risks can in fact be reliably identified in advance; after all, neither the Federal Reserve nor economists in general predicted the past crisis. To respond to this point, I will distinguish, as I have elsewhere, between triggers and vulnerabilities.2 The triggers of any crisis are the particular events that touch off the crisis--the proximate causes, if you will. For the 2007-09 crisis, a prominent trigger was the losses suffered by holders of subprime mortgages. In contrast, the vulnerabilities associated with a crisis are preexisting features of the financial system that amplify and propagate the initial shocks. Examples of vulnerabilities include high levels of leverage, maturity transformation, interconnectedness, and complexity, all of which have the potential to magnify shocks to the financial system. Absent vulnerabilities, triggers might produce sizable losses to certain firms, investors, or asset classes but would generally not lead to full-blown financial crises; the collapse of the relatively small market for subprime mortgages, for example, would not have been nearly as consequential without preexisting fragilities in securitization practices and short-term funding markets which greatly increased its impact. Of course, monitoring can and does attempt to identify potential triggers--indications of an asset bubble, for example--but shocks of one kind or another are inevitable, so identifying and addressing vulnerabilities is key to ensuring that the financial system overall is robust. Moreover, attempts to address specific vulnerabilities can be supplemented by broader measures--such as requiring banks to hold more capital and liquidity--that make the system more resilient to a range of shocks.\n\nTwo other related points motivate our increased monitoring. The first is that the financial system is dynamic and evolving not only because of innovation and the changing needs of the economy, but also because financial activities tend to migrate from more-regulated to less-regulated sectors. An innovative feature of the Dodd-Frank Act is that it includes mechanisms to permit the regulatory system, at least in some circumstances, to adapt to such changes. For example, the act gives the FSOC powers to designate systemically important institutions, market utilities, and activities for additional oversight. Such designation is essentially a determination that an institution or activity creates or exacerbates a vulnerability of the financial system, a determination that can only be made with comprehensive monitoring and analysis.\n\nThe second motivation for more intensive monitoring is the apparent tendency for financial market participants to take greater risks when macro conditions are relatively stable. Indeed, it may be that prolonged economic stability is a double-edged sword. To be sure, a favorable overall environment reduces credit risk and strengthens balance sheets, all else being equal, but it could also reduce the incentives for market participants to take reasonable precautions, which may lead in turn to a buildup of financial vulnerabilities. Probably our best defense against complacency during extended periods of calm is careful monitoring for signs of emerging vulnerabilities and, where appropriate, the development of macroprudential and other policy tools that can be used to address them.\n\nThe Federal Reserve's Financial Stability Monitoring Program \nSo, what specifically does the Federal Reserve monitor? In the remainder of my remarks, I'll highlight and discuss four components of the financial system that are among those we follow most closely: systemically important financial institutions (SIFIs), shadow banking, asset markets, and the nonfinancial sector.3 \n\nSystemically Important Financial Institutions \nSIFIs are financial firms whose distress or failure has the potential to create broader financial instability sufficient to inflict meaningful damage on the real economy. SIFIs tend to be large, but size is not the only factor used to determine whether a firm is systemically important; other factors include the firm's interconnectedness with the rest of the financial system, the complexity and opacity of its operations, the nature and extent of its risk-taking, its use of leverage, its reliance on short-term wholesale funding, and the extent of its cross-border operations. Under the Dodd-Frank Act, the largest bank holding companies are treated as SIFIs; in addition, as I mentioned, the act gives the FSOC the power to designate individual nonbank financial companies as systemically important. This designation process is under way.\n\nDodd-Frank also establishes a framework for subjecting SIFIs to comprehensive supervisory oversight and enhanced prudential standards. For all such companies, the Federal Reserve will have access to confidential supervisory information and will monitor standard indicators such as regulatory capital, leverage, and funding mix. However, some of these measures, such as regulatory capital ratios, tend to be backward looking and thus may be slow to flag unexpected, rapid changes in the condition of a firm. Accordingly, we supplement the more standard measures with other types of information.\n\nOne valuable source of supplementary information is stress testing. Regular, comprehensive stress tests are an increasingly important component of the Federal Reserve's supervisory toolkit, having been used in our assessment of large bank holding companies since 2009.4 To administer a stress test, supervisors first construct a hypothetical scenario that assumes a set of highly adverse economic and financial developments--for example, a deep recession combined with sharp declines in the prices of houses and other assets. The tested firms and their supervisors then independently estimate firms' projected losses, revenues, and capital under the hypothetical scenario, and the results are publicly disclosed. Firms are evaluated both on their post-stress capital levels and on their ability to analyze their exposures and capital needs.\n\nStress testing provides a number of advantages over more-standard approaches to assessing capital adequacy. First, measures of capital based on stress tests are both more forward looking and more robust to \"tail risk\"--that is, to extremely adverse developments of the sort most likely to foster broad-based financial instability. Second, because the Federal Reserve conducts stress tests simultaneously on the major institutions it supervises, the results can be used both for comparative analyses across firms and to judge the collective susceptibility of major financial institutions to certain types of shocks. Indeed, comparative reviews of large financial institutions have become an increasingly important part of the Federal Reserve's supervisory toolkit more generally. Third, the disclosure of stress-test results, which increased investor confidence during the crisis, can also strengthen market discipline in normal times. The stress tests thus provide critical information about key financial institutions while also forcing the firms to improve their ability to measure and manage their risk exposures.\n\nStress-testing techniques can also be used in more-focused assessments of the banking sector's vulnerability to specific risks not captured in the main scenario, such as liquidity risk or interest rate risk. Like comprehensive stress tests, such focused exercises are an important element of our supervision of SIFIs. For example, supervisors are collecting detailed data on liquidity that help them compare firms' susceptibilities to various types of funding stresses and to evaluate firms' strategies for managing their liquidity. Supervisors also are working with firms to assess how profitability and capital would fare under various stressful interest rate scenarios.\n\nFederal Reserve staff members supplement supervisory and stress-test information with other measures. For example, though supervisors have long appreciated the value of market-based indicators in evaluating the conditions of systemically important firms (or, indeed, any publicly traded firm), our monitoring program uses market information to a much greater degree than in the past. Thus, in addition to standard indicators--such as stock prices and the prices of credit default swaps, which capture market views about individual firms--we use market-based measures of systemic stability derived from recent research. These measures use correlations of asset prices to capture the market's perception of a given firm's potential to destabilize the financial system at a time when the broader financial markets are stressed; other measures estimate the vulnerability of a given firm to disturbances emanating from elsewhere in the system.5 The further development of market-based measures of systemic vulnerabilities and systemic risk is a lively area of research.\n\nNetwork analysis, yet another promising tool under active development, has the potential to help us better monitor the interconnectedness of financial institutions and markets. Interconnectedness can arise from common holdings of assets or through the exposures of firms to their counterparties. Network measures rely on concepts used in engineering, communications, and neuroscience to map linkages among financial firms and market activities. The goals are to identify key nodes or clusters that could destabilize the system and to simulate how a shock, such as the sudden distress of a firm, could be transmitted and amplified through the network. These tools can also be used to analyze the systemic stability effects of a change in the structure of a network. For example, margin rules affect the sensitivity of firms to the conditions of their counterparties; thus, margin rules affect the likelihood of financial contagion through various firms and markets.\n\nShadow Banking \nShadow banking, a second area we closely monitor, was an important source of instability during the crisis. Shadow banking comprises various markets and institutions that provide financial intermediation outside the traditional, regulated banking system. Shadow banking includes vehicles for credit intermediation, maturity transformation, liquidity provision, and risk sharing. Such vehicles are typically funded on a largely short-term basis from wholesale sources. In the run-up to the crisis, the shadow banking sector involved a high degree of maturity transformation and leverage. Illiquid loans to households and businesses were securitized, and the tranches of the securitizations with the highest credit ratings were funded by very short-term debt, such as asset-backed commercial paper and repurchase agreements (repos). The short-term funding was in turn provided by institutions, such as money market funds, whose investors expected payment in full on demand and had little tolerance for risk to principal.\n\nAs it turned out, the ultimate investors did not fully understand the quality of the assets they were financing. Investors were lulled by triple-A credit ratings and by expected support from sponsoring institutions--support that was, in fact, discretionary and not always provided. When investors lost confidence in the quality of the assets or in the institutions expected to provide support, they ran. Their flight created serious funding pressures throughout the financial system, threatened the solvency of many firms, and inflicted serious damage on the broader economy.\n\nSecurities broker-dealers play a central role in many aspects of shadow banking as facilitators of market-based intermediation. To finance their own and their clients' securities holdings, broker-dealers tend to rely on short-term collateralized funding, often in the form of repo agreements with highly risk-averse lenders. The crisis revealed that this funding is potentially quite fragile if lenders have limited capacity to analyze the collateral or counterparty risks associated with short-term secured lending, but rather look at these transactions as nearly risk free. As questions emerged about the nature and value of collateral, worried lenders either greatly increased margin requirements or, more commonly, pulled back entirely. Borrowers unable to meet margin calls and finance their asset holdings were forced to sell, driving down asset prices further and setting off a cycle of deleveraging and further asset liquidation.\n\nTo monitor intermediation by broker-dealers, the Federal Reserve in 2010 created a quarterly Senior Credit Officer Opinion Survey on Dealer Financing Terms, which asks dealers about the credit they provide.6 Modeled on the long-established Senior Loan Officer Opinion Survey on Bank Lending Practices sent to commercial banks, the survey of senior credit officers at dealers tracks conditions in markets such as those for securities financing, prime brokerage, and derivatives trading.7 The credit officer survey is designed to monitor potential vulnerabilities stemming from the greater use of leverage by investors (particularly through lending backed by less-liquid collateral) or increased volumes of maturity transformation. Before the financial crisis, we had only very limited information regarding such trends.\n\nWe have other potential sources of information about shadow banking. The Treasury Department's Office of Financial Research and Federal Reserve staff are collaborating to construct data sets on triparty and bilateral repo transactions, which should facilitate the development of better monitoring metrics for repo activity and improve transparency in these markets. We also talk regularly to market participants about developments, paying particular attention to the creation of new financial vehicles that foster greater maturity transformation outside the regulated sector, provide funding for less-liquid assets, or transform risks from forms that are more easily measured to forms that are more opaque.\n\nA fair summary is that, while the shadow banking sector is smaller today than before the crisis and some of its least stable components have either disappeared or been reformed, regulators and the private sector need to address remaining vulnerabilities. For example, although money market funds were strengthened by reforms undertaken by the Securities and Exchange Commission (SEC) in 2010, the possibility of a run on these funds remains--for instance, if a fund should \"break the buck,\" or report a net asset value below 99.5 cents, as the Reserve Primary Fund did in 2008. The risk is increased by the fact that the Treasury no longer has the power to guarantee investors' holdings in money funds, an authority that was critical for stopping the 2008 run. In November 2012, the FSOC proposed for public comment some alternative approaches for the reform of money funds. The SEC is currently considering these and other possible steps.\n\nWith respect to the triparty repo platform, progress has been made in reducing the amount of intraday credit extended by the clearing banks in the course of the daily settlement process, and, as additional enhancements are made, the extension of such credit should be largely eliminated by the end of 2014. However, important risks remain in the short-term wholesale funding markets. One of the key risks is how the system would respond to the failure of a broker-dealer or other major borrower. The Dodd-Frank Act has provided important additional tools to deal with this vulnerability, notably the provisions that facilitate an orderly resolution of a broker-dealer or a broker-dealer holding company whose imminent failure poses a systemic risk. But, as highlighted in the FSOC's most recent annual report, more work is needed to better prepare investors and other market participants to deal with the potential consequences of a default by a large participant in the repo market.8 \n\nAsset Markets\nAsset markets are a third area that we closely monitor. We follow developments in markets for a wide range of assets, including public and private fixed-income instruments, corporate equities, real estate, commodities, and structured credit products, among others. Foreign as well as domestic markets receive close attention, as do global linkages, such as the effects of the ongoing European fiscal and banking problems on U.S. markets.\n\nNot surprisingly, we try to identify unusual patterns in valuations, such as historically high or low ratios of prices to earnings in equity markets. We use a variety of models and methods; for example, we use empirical models of default risk and risk premiums to analyze credit spreads in corporate bond markets. These assessments are complemented by other information, including measures of volumes, liquidity, and market functioning, as well as intelligence gleaned from market participants and outside analysts. In light of the current low interest rate environment, we are watching particularly closely for instances of \"reaching for yield\" and other forms of excessive risk-taking, which may affect asset prices and their relationships with fundamentals. It is worth emphasizing that looking for historically unusual patterns or relationships in asset prices can be useful even if you believe that asset markets are generally efficient in setting prices. For the purpose of safeguarding financial stability, we are less concerned about whether a given asset price is justified in some average sense than in the possibility of a sharp move. Asset prices that are far from historically normal levels would seem to be more susceptible to such destabilizing moves.\n\nFrom a financial stability perspective, however, the assessment of asset valuations is only the first step of the analysis. Also to be considered are factors such as the leverage and degree of maturity mismatch being used by the holders of the asset, the liquidity of the asset, and the sensitivity of the asset's value to changes in broad financial conditions. Differences in these factors help explain why the correction in equity markets in 2000 and 2001 did not induce widespread systemic disruptions, while the collapse in house prices and in the quality of mortgage credit during the 2007-09 crisis had much more far-reaching effects: The losses from the stock market declines in 2000 and 2001 were widely diffused, while mortgage losses were concentrated--and, through various financial instruments, amplified--in critical parts of the financial system, resulting ultimately in panic, asset fire sales, and the collapse of credit markets.\n\nNonfinancial Sector \nOur financial stability monitoring extends to the nonfinancial sector, including households and businesses. Research has identified excessive growth in credit and leverage in the private nonfinancial sector as potential indicators of systemic risk.9 Highly leveraged or financially fragile households and businesses are less able to withstand adverse changes in income or wealth, including those brought about by deteriorating conditions in financial and credit markets. A highly leveraged economy is also more prone to so-called financial accelerator effects, as when financially stressed firms are forced to lay off workers who, in turn, lacking financial reserves, sharply cut their own spending. Financial stress in the nonfinancial sector--for example, higher default rates on mortgages or corporate debt--can also damage financial institutions, creating a potential adverse feedback loop as they reduce the availability of credit and shed assets to conserve capital, thereby further weakening the financial positions of households and firms.\n\nThe vulnerabilities of the nonfinancial sector can potentially be captured by both stock measures (such as wealth and leverage) and flow measures (such as the ratio of debt service to income). Sector-wide data are available from a number of sources, importantly the Federal Reserve's flow of funds accounts, which is a set of aggregate integrated financial accounts that measures sources and uses of funds for major sectors as well as for the economy as a whole.10 These accounts allow us to trace the flow of credit from its sources, such as banks or wholesale funding markets, to the household and business sectors that receive it.\n\nThe Federal Reserve also now monitors detailed consumer- and business-level data suited for picking up changes in the nature of borrowing and lending, as well as for tracking financial conditions of those most exposed to a cyclical downturn or a reversal of fortunes. For example, during the housing boom, the aggregate data accurately showed the outsized pace of home mortgage borrowing, but it could not reveal the pervasive deterioration in underwriting that implied a substantial increase in the underlying credit risk from that activity.11 More recently, gains in household net worth have been concentrated among wealthier households, while many households in the middle or lower parts of the distribution have experienced declines in wealth since the crisis. Moreover, many homeowners remain \"underwater,\" with their homes worth less than the principal balances on their mortgages. Thus, more detailed information clarifies that many households remain more financially fragile than might be inferred from the aggregate statistics alone.\n\nConclusion\nIn closing, let me reiterate that while the effective regulation and supervision of individual financial institutions will always be crucial to ensuring a well-functioning financial system, the Federal Reserve is moving toward a more systemic approach that also pays close attention to the vulnerabilities of the financial system as a whole. Toward that end, we are pursuing an active program of financial monitoring, supported by expanded research and data collection, often undertaken in conjunction with other U.S. financial regulatory agencies. Our stepped-up monitoring and analysis is already providing important information for the Board and the Federal Open Market Committee as well as for the broader regulatory community. We will continue to work toward improving our ability to detect and address vulnerabilities in our financial system.\n\n \n\n1. For the most recent report, see U.S. Department of the Treasury, Financial Stability Oversight Council (2013), 2013 Annual Report (Washington: Department of the Treasury). Return to text\n\n2. See Ben S. Bernanke (2010), \"Causes of the Recent Financial and Economic Crisis,\" testimony before the Financial Crisis Inquiry Commission, Washington, September 2; and Ben S. Bernanke (2012), \"Some Reflections on the Crisis and the Policy Response,\" speech delivered at \"Rethinking Finance: Perspectives on the Crisis,\" a conference sponsored by the Russell Sage Foundation and The Century Foundation, New York, April 13. Return to text\n\n3. The remainder of my remarks draws heavily on Tobias Adrian, Daniel Covitz, and Nellie Liang (2013), \"Financial Stability Monitoring (PDF),\" Finance and Economics Discussion Series 2013-21 (Washington: Board of Governors of the Federal Reserve System, April). This paper provides more details on the Federal Reserve's financial stability monitoring program. I thank the authors for their assistance with these remarks. Return to text\n\n4. The Federal Reserve's stress-testing program is discussed in Ben S. Bernanke (2013), \"Stress Testing Banks: What Have We Learned?\" speech delivered at \"Maintaining Financial Stability: Holding a Tiger by the Tail,\" a financial markets conference sponsored by the Federal Reserve Bank of Atlanta, held in Stone Mountain, Ga., April 8-10. More limited forms of stress testing were used by supervisors before 2009. Return to text\n\n5. For example, conditional value at risk provides an estimate of the systemic importance of a firm at a moment in time, based on how the firm's equity value and broader equity values co-vary when overall conditions are very adverse; see Tobias Adrian and Markus K. Brunnermeier (2008; revised September 2011), \"CoVaR (PDF),\" Staff Reports 348 (New York: Federal Reserve Bank of New York, September). The distressed insurance premium uses information from firms' credit default swap spreads and equity prices to measure the implied cost of insuring a given firm against broader financial distress--an indicator of the vulnerability of the firm to systemic instability; see Xin Huang, Hao Zhou, and Haibin Zhu (2009), \"A Framework for Assessing the Systemic Risk of Major Financial Institutions ,\" Journal of Banking and Finance, vol. 33 (November), pp. 2036-49. The systemic expected shortfall uses firm equity prices, leverage, and volatility to measure the propensity of a firm to be undercapitalized given a marketwide decline in equity prices; see Viral V. Acharya, Lasse H. Pedersen, Thomas Philippon, and Matthew Richardson (2010), \"Measuring Systemic Risk (PDF) ,\" unpublished paper, New York University, Leonard Stern School of Business, May. Return to text\n\n6. The Senior Credit Officer Opinion Survey on Dealer Financing Terms is available on the Federal Reserve Board's website. Return to text\n\n7. The Senior Loan Officer Opinion Survey on Bank Lending Practices is available on the Federal Reserve Board's website. Return to text\n\n8. See Financial Stability Oversight Council, 2013 Annual Report, in note 1. Return to text\n\n9. See, for example, Mathias Drehmann, Claudio Borio, and Kostas Tsatsaronis (2011), \"Anchoring Countercyclical Capital Buffers: The Role of Credit Aggregates,\" International Journal of Central Banking, vol. 7 (December), pp. 189-240; and Rochelle M. Edge and Ralf R. Meisenzahl (2011), \"The Unreliability of Credit-to-GDP Ratio Gaps in Real Time:Implications for Countercyclical Capital Buffers,\" International Journal of Central Banking, vol. 7 (December), pp. 261-98. Return to text\n\n10. The flow of funds data are available on the Federal Reserve Board's website. Return to text\n\n11. See Matthew J. Eichner, Donald L. Kohn, and Michael G. Palumbo (2010), \"Financial Statistics for the United States and the Crisis: What Did They Get Right, What Did They Miss, and How Should They Change? (PDF)\" Finance and Economics Discussion Series 2010-20 (Washington: Board of Governors of the Federal Reserve System, April). Return to text"
    },
    {
        "title": "Prospects for a Stronger Recovery",
        "date": "May 16, 2013",
        "speaker": "Governor Sarah Bloom Raskin",
        "url": "https://www.federalreserve.gov/newsevents/speech/raskin20130516a.htm",
        "content": "May 16, 2013\n\nGovernor Sarah Bloom Raskin\n\nAt the Society of Government Economists and the National Economists Club, Washington, D.C.\n\nThank you. I am very pleased to be here among an audience of professional economists, which is certainly preferable to appearing before an audience of unprofessional economists. I like your kind! Your talents are needed now more than ever as we try to put the tools of the economic profession to work for the common good. It's easy to be an economist who looks back on crises and crashes and tries to explain why they happened, but much harder to be an economist whose efforts manage to help stop them from happening in the first place. Economic policymaking, at its best, reflects a continuous struggle to make sure that data and explanations of such data are consistent with real experience. If we're to engage in this struggle honestly, it's no easy task. It involves understanding not just the reliability and signal in various data, but also questioning whether the data accords with our understanding of actual experience. So, to get this right requires many different perspectives, not just on the data but on the underlying realities the data are trying to capture. Government economists understand that non-economists bring something valuable to the table in policymaking--a grounded perspective in what is happening in the economy.\n\nWith that said, what is really happening now in the American economy? What do the economic data we see at the Federal Reserve currently show, and how do we think these data line up with the economic realities of most American households and businesses? In my remarks today I will offer my assessment of recent economic developments and the economic outlook, and I will discuss the actions that the Federal Reserve has been taking, in light of its view of developments and the outlook, to support the economic recovery. Before I begin, I should note that the views that I will be presenting are my own and not necessarily those of my colleagues on the Federal Open Market Committee (FOMC) or the Board of Governors.\n\nRecent Economic and Financial Developments\nFor the past three and a half years the U.S. economy has been in a recovery--albeit a very weak one--from a severe financial crisis and the deepest recession of the post-World War II period. The unemployment rate, which reached a high of 10 percent in the fall of 2009, has since come down 2-1/2 percentage points, to 7.5 percent in April.\n\nThe increase in economic activity and the decline in the unemployment rate are, of course, welcome, but we still have a long way to go to reach what feels like a healthy economy. In fact, the pace of recovery has been slower than most had expected. The gap between actual output and the economy's potential remains quite large, according to estimates from the Congressional Budget Office, and the unemployment rate today remains well above levels seen prior to the recession, and well above the level that the Committee thinks can be sustained once a full recovery has been achieved. In addition, the number of long-term unemployed--people who have been unemployed for 27 weeks or more--remains historically high.\n\nMy interpretation of the economic data that we have received over the past few quarters is that the recovery has continued to gain traction. The Bureau of Economic Analysis reported last month that real gross domestic product (GDP) rose at an annual rate of 2-1/2 percent in the first quarter of this year after barely expanding at all in the fourth quarter of 2012. The step-up in growth in the first quarter partly reflected a rebound from last year's drought and Hurricane Sandy. Smoothing through these factors, real GDP was about 1-3/4 percent above its year-earlier level in the first quarter, a modest gain that is about in line with the pace of growth during much of the recovery.\n\nThe strength of the recovery among the components of GDP has been mixed recently. In terms of the housing sector, there is no question that many communities and neighborhoods were devastated by the effects of the financial crisis. Recently, we see that overall demand has been strengthening, with both home sales and prices rising markedly in many areas. Both new and existing home sales have moved up, on net, since late 2011, and housing starts averaged an annual rate of nearly 1 million units in the first quarter of this year, up considerably from the extremely low levels that prevailed through 2011. Inventories of new homes for sale have become quite lean in most markets over the past year, a notable change from earlier in the recovery. The increase in activity in the housing sector has been driven by historically low mortgage rates, growing optimism about future house prices, continued gains in the job market, and sizable purchases of homes by investors.\n\nElsewhere in the household sector, consumer spending--about two-thirds of overall final demand--has continued growing at a moderate pace. On the whole, families have benefited from the modest improvement in the labor market, and rising stock prices and rebounding home values have helped some households recoup part of the wealth they lost during the recession.\n\nHowever, overall wage growth has been anemic, and many households have not seen their circumstances improve materially. As I described in a speech last month, globalization and technological change have continued to shift the occupations and industrial distribution of new jobs available. These currents of globalization and technological change continue on their path, making it more likely that workers who were laid off during the recession would be unable to find reemployment that is of comparable quality to their previous jobs.1 About two-thirds of all job losses in the recession were in middle-wage occupations--such as manufacturing, skilled construction, and office administration jobs--but these occupations have accounted for less than one-fourth of the job growth during the recovery.2 By contrast, lower-wage occupations, such as retail sales, food service, and other lower-paying service jobs, accounted for only one-fifth of job losses during the recession but more than one-half of total job gains during the recovery. As a result of these trends in job creation, which could well have been exacerbated by the severe nature of the crisis, the earnings potential for many households likely remains below what they had anticipated in the years before the recession. Moreover, as you all know, the temporary payroll tax cut has now expired, and many households have seen their disposable incomes reduced for this reason as well.\n\nSpending in the business sector recently has increased only modestly, perhaps due in part to the effect of these recent tax changes on consumers. Real spending on equipment and software rose about 4 percent over the past 12 months, according to the most recent GDP report, a modest gain for this category of spending. Indicators for capital investment in the months ahead, including new orders for durable capital goods and survey measures of business sentiment, suggest that growth in business spending on new equipment and software is likely to remain modest in the coming quarters.\n\nTurning to the government sector, the legislated reduction in spending by the federal government is exerting a clear and continuing drag on economic activity. Even prior to the bulk of the spending cuts associated with sequestration, real purchases by the federal government were reported to have dropped at an annual rate of more than 8 percent in the first quarter of this year, following an even larger drop in the fourth quarter of last year. These cuts in federal spending are likely to be an important influence on the near-term prospects for economic growth, and I will say more about this issue in a moment.\n\nIn contrast to the federal government, the budget outlook for state and local government continues to improve, and the drag on economic activity from this sector's cutbacks in spending has diminished considerably.\n\nReflecting some of these mixed influences, as I already noted, real GDP has been rising at a very modest rate, and the labor market has shown similarly modest gains over the past year, with the unemployment rate coming down about 1/2 percentage point. To more fully understand the experience of the 11.7 million Americans who can't find work, we look to broader measures of labor underutilization, which take into account job seekers who have stopped looking for work because they have become discouraged, and people working part time but who would prefer to work full time. Recently, these numbers seem to be coming down. The gains in payroll employment over this period have been about in line with the decline in the unemployment rate, although, as is typical, the pace of job gains has been somewhat erratic in recent months. Since the beginning of the year, the increases in payroll employment have averaged 196,000 per month, a little above the 183,000 average monthly gains observed during 2012.\n\nOther indicators from the labor market have also shown some improvement recently. Initial claims for unemployment insurance have declined since last summer, and the number of job openings appears to be increasing. I hope these indicators mean we are turning the corner on some of the painful costs associated with being unemployed or underemployed in America.\n\nTurning to inflation, recent data show that price pressures have remained subdued. Both total and core inflation were only about 1 percent over the 12 months ending in March, below the FOMC's long-run objective of 2 percent. Inflation is being restrained by the continued slack in labor and product markets, while stable inflation expectations have offset disinflationary pressures to some extent. Moreover, the increase in gasoline prices that we saw earlier in the year appears to have fully reversed, and the path of oil futures prices is downward-sloping, suggesting that energy prices are likely to hold down headline inflation rates in the years ahead.\n\nThe Economic Outlook\nLet me now turn to the outlook. As my Federal Reserve colleagues and I have noted in the past, the pace of the economic recovery has been restrained by lingering effects of the financial crisis. Assessing the current strength of the headwinds related to these lingering effects is an important determinant of the economic outlook for the coming years.\n\nUnfortunately, current federal fiscal policy is one headwind to the recovery that has intensified this year. In fact, federal fiscal policy has been tightening since 2011, after having been quite expansionary during the recession and early in the recovery. More recently, actions by the Administration and the Congress to reduce the budget deficit have led to further tightening of federal fiscal policy.\n\nAs I already mentioned, both the tax legislation signed into law in January and the sharp spending cuts associated with sequestration will likely significantly hinder GDP growth this year. Indeed, the Congressional Budget Office has estimated that these changes in fiscal policy would reduce GDP growth by 1-1/2 percentage points this year relative to what we otherwise would have achieved.3 Looking further ahead, fiscal policy seems likely to remain restrictive at the federal level.\n\nThe headwinds from the housing sector have eased, and housing market activity is likely to continue to contribute to GDP growth over the next few years. These headwinds had been substantial, as the aftermath of the financial crisis and housing bubble left many homeowners underwater on their mortgages, a large overhang of vacant homes, and mortgage credit very hard to obtain for anyone without an excellent credit record and a sizable down payment. The rise in house prices over the past year or so has lifted household net worth and pushed some homeowners above water on their mortgages. These developments may help to ease credit for many households as well, although mortgage credit remains very tight.\n\nIn a speech last month, I described how the net decline in housing wealth since the recession has had particularly acute effects on the balance sheets of lower- and middle-income households, which tend to hold a relatively high share of their total wealth in their homes.4 Households at the bottom of the income distribution have also had a harder time than others finding jobs during the recovery and their wages have continued to stagnate. In my view, the large and increasing amount of inequality in income and wealth, which has been an ongoing development for decades, may have exacerbated the crisis and I think more research is required to determine whether it may also pose a significant headwind to the recovery from the crisis for years to come. So, while I am hopeful that pressures will ease further as home prices continue to rebound, I also believe that some of the restraints on the recovery may be quite long-lasting.\n\nThe headwind from the financial sector also has diminished somewhat over the past year and should present less of a restraint on economic growth than has been the case in the recent past. U.S. equity prices are up more than 10 percent so far this year following last year's 13 percent increase. Risk spreads embedded in the interest rates paid by many American businesses, although still above their pre-crisis levels, have also moved down substantially over the past year to levels that are moderate, given the state of the broader economy.\n\nThe situation in Europe, although still uncertain, appears to have improved since last summer--aided importantly by the policies of the European Central Bank (ECB)--and these developments have led to an improvement in financial conditions globally. Policy actions and promises, including the ECB's program to purchase the sovereign debt of vulnerable euro-area countries and discussions about creating a banking union, appear to have helped market participants negotiate past some recent hurdles, including the challenges in forming a governing coalition in Italy and the severe banking difficulties in Cyprus. If policymakers in Europe can follow through on their commitments to financial integration and structural reforms, among other things, financial stress in Europe should continue to lessen, and European economies should gradually recover from their current slump. If the economy in Europe were to begin to grow again, it could support global economic growth more broadly.\n\nThe financial condition of the U.S. banking sector has also continued to improve from the perspective of regulatory capital. While much work remains for regulators and banks implementing pending capital requirements, most large, medium-sized, and community banks are in stronger capital positions today than they were prior to the financial crisis.\n\nAlthough not all, some consumers at least, are seeing the benefits of improvements in financial markets. In combination with low interest rates, the easing of financial stress has allowed some homeowners to refinance their mortgages to lower their monthly payments, and some types of loans, such as those for purchasing a new or used car, have become available to more people. That said, we clearly still have a long way to go in assuring that Americans have access to affordable credit. As I noted, an especially large number of people are unable to obtain mortgage credit, and credit card borrowing is also tight.\n\nTaken together, the incoming data and my own analysis of recent developments in fiscal policy suggest that the recovery will continue at a moderate pace, and the unemployment rate will fall gradually. According to the Summary of Economic Projections that was released by Federal Reserve Board members and Reserve Bank presidents after the March FOMC meeting, my colleagues and I expected real GDP growth to step up moderately this year, rising roughly 2-1/2 percent after having risen 1‑3/4 percent in 2012. In the projection, participants also expected the unemployment rate to be in the range of 7.3 to 7.5 percent by the end of the year. Looking a bit further ahead, FOMC participants largely expected the unemployment rate to continue receding, but it was expected to remain above its long-run sustainable level for several years. Meanwhile, inflation was expected to remain close to or a little below the Committee's objective of 2 percent, consistent with ongoing slack in the labor and product markets and well-anchored inflation expectations.\n\nMonetary Policy Developments\nIn light of this outlook and the risks around the outlook, it has been appropriate for the Federal Reserve to continue to pursue a highly accommodative monetary policy. As you all know, during the financial crisis and at the onset of the recession, the Federal Reserve took strong easing measures, cutting the target for the federal funds rate--the traditional tool of monetary policy--to nearly zero by the end of 2008. During the recovery, we have provided additional accommodation through two nontraditional policy tools aimed at putting downward pressure on longer-term interest rates even with short-term rates stuck at zero: (1) purchases of Treasury securities and mortgage backed securities and (2) communication about the future path of the federal funds rate.\n\nOur most recent policy actions have sought to strengthen the recovery in the face of only slow improvements in labor market conditions and subdued inflationary pressures. After last September's policy meeting, the FOMC announced that the Federal Reserve would continue asset purchases until the outlook for the labor market has improved substantially in the context of price stability.\n\nThen, at the meeting in December, the FOMC voted to continue purchasing longer-term Treasury securities at a pace of $45 billion each month and agency mortgage-backed securities at a pace of $40 billion each month, and we have maintained that pace of asset purchases so far this year. In considering changes to the pace of asset purchases in the future, we take into account judgments about both the efficacy and potential costs of these purchases, including potential risks to inflation and financial stability, as well as the extent of progress toward our economic objectives.\n\nAt its December meeting, the FOMC also recast its forward guidance to clarify how the target for the federal funds rate is expected to depend on future economic developments. Specifically, we said that we anticipate that an exceptionally low funds rate is likely to be warranted at least as long as the unemployment rate remains above 6‑1/2 percent, inflation over the period between one and two years ahead is projected to be no more than 1/2 percentage point above 2 percent, and longer-term inflation expectations remain well anchored. These thresholds are intended to make monetary policy more transparent and predictable to the public by making more explicit our intention to maintain policy accommodation as long as needed to promote a stronger recovery in the context of price stability.\n\nAlthough it is still too early to assess the full effects of the most recent policy actions, available research suggests that our previous asset purchases have eased financial conditions and provided meaningful support to the economic recovery.5 \n\nGiven its statutory mandate, the FOMC's policy actions and communications have naturally sought to lower interest rates as a means of strengthening aggregate demand, promoting the pace of recovery in the labor market, and keeping inflation from falling further below the rate preferred by the Committee over the longer run. We will continue to calibrate monetary policy--including both the ongoing pace of asset purchases and communications about the likely path of the federal funds rate--in light of our interpretations of the latest data and the implications of those interpretations for the outlook for economic activity, labor market conditions, and inflation.\n\nConclusion\nIn summary, the U.S. economy has continued to recover from the effects of the financial crisis and deep recession, though at a pace that has been disappointingly slow. The recovery does appear to have picked up steam in some sectors, most notably in housing, likely reflecting the easing of some of the headwinds that had been holding back the pace of the recovery in earlier years. However, federal fiscal policy remains an important source of restraint.\n\nIn light of these factors, most members of the FOMC project a modest improvement in the pace of the recovery this year and next, and, accordingly, a modest decline in the unemployment rate. The Federal Reserve will continue to conduct monetary policy so as to promote a stronger economic recovery in the context of price stability.\n\n1. See Sarah Bloom Raskin (2013), \"Aspects of Inequality in the Recent Business Cycle,\" speech delivered at \"Building a Financial Structure for a More Stable and Equitable Economy,\" the 22nd Annual Hyman P. Minsky Conference on the State of the U.S. and World Economies, sponsored by the Levy Economics Institute of Bard College, held in New York, April 17-19. Return to text\n\n2. See National Employment Law Project (2012), \"The Low-Wage Recovery and Growing Inequality (PDF),\" Data Brief, report (New York: NELP, August). Return to text\n\n3. See Congressional Budget Office (2013), The Budget and Economic Outlook: Fiscal Years 2013 to 2023 (Washington: CBO, February). Return to text\n\n4. See Raskin, \"Aspects of Inequality in the Recent Business Cycle,\" in note 1. Return to text\n\n5. For a discussion and list of references regarding the effects of recent monetary policy actions, see Ben S. Bernanke (2012), \"The Economic Recovery and Economic Policy,\" speech delivered at the Economic Club of New York, New York, November 20. Return to text"
    },
    {
        "title": "Economic Prospects for the Long Run",
        "date": "May 18, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20130518a.htm",
        "content": "May 18, 2013\n\nChairman Ben S. Bernanke\n\nAt Bard College at Simon's Rock, Great Barrington, Massachusetts\n\nLet me start by congratulating the graduates and their parents. The word \"graduate\" comes from the Latin word for \"step.\" Graduation from college is only one step on a journey, but it is an important one and well worth celebrating.\n\nI think everyone here appreciates what a special privilege each of you has enjoyed in attending a unique institution like Simon's Rock. It is, to my knowledge, the only \"early college\" in the United States; many of you came here after the 10th or 11th grade in search of a different educational experience. And with only about 400 students on campus, I am sure each of you has felt yourself to be part of a close-knit community. Most important, though, you have completed a curriculum that emphasizes creativity and independent critical thinking, habits of mind that I am sure will stay with you.\n\nWhat's so important about creativity and critical thinking? There are many answers. I am an economist, so I will answer by talking first about our economic future--or your economic future, I should say, because each of you will have many years, I hope, to contribute to and benefit from an increasingly sophisticated, complex, and globalized economy. My emphasis today will be on prospects for the long run. In particular, I will be looking beyond the very real challenges of economic recovery that we face today--challenges that I have every confidence we will overcome--to speak, for a change, about economic growth as measured in decades, not months or quarters.\n\nMany factors affect the development of the economy, notably among them a nation's economic and political institutions, but over long periods probably the most important factor is the pace of scientific and technological progress. Between the days of the Roman Empire and when the Industrial Revolution took hold in Europe, the standard of living of the average person throughout most of the world changed little from generation to generation. For centuries, many, if not most, people produced much of what they and their families consumed and never traveled far from where they were born. By the mid-1700s, however, growing scientific and technical knowledge was beginning to find commercial uses. Since then, according to standard accounts, the world has experienced at least three major waves of technological innovation and its application. The first wave drove the growth of the early industrial era, which lasted from the mid-1700s to the mid-1800s. This period saw the invention of steam engines, cotton-spinning machines, and railroads. These innovations, by introducing mechanization, specialization, and mass production, fundamentally changed how and where goods were produced and, in the process, greatly increased the productivity of workers and reduced the cost of basic consumer goods. The second extended wave of invention coincided with the modern industrial era, which lasted from the mid-1800s well into the years after World War II. This era featured multiple innovations that radically changed everyday life, such as indoor plumbing, the harnessing of electricity for use in homes and factories, the internal combustion engine, antibiotics, powered flight, telephones, radio, television, and many more. The third era, whose roots go back at least to the 1940s but which began to enter the popular consciousness in the 1970s and 1980s, is defined by the information technology (IT) revolution, as well as fields like biotechnology that improvements in computing helped make possible. Of course, the IT revolution is still going on and shaping our world today.\n\nNow here's a question--in fact, a key question, I imagine, from your perspective. What does the future hold for the working lives of today's graduates? The economic implications of the first two waves of innovation, from the steam engine to the Boeing 747, were enormous. These waves vastly expanded the range of available products and the efficiency with which they could be produced. Indeed, according to the best available data, output per person in the United States increased by approximately 30 times between 1700 and 1970 or so, growth that has resulted in multiple transformations of our economy and society.1 History suggests that economic prospects during the coming decades depend on whether the most recent revolution, the IT revolution, has economic effects of similar scale and scope as the previous two. But will it?\n\nI must report that not everyone thinks so. Indeed, some knowledgeable observers have recently made the case that the IT revolution, as important as it surely is, likely will not generate the transformative economic effects that flowed from the earlier technological revolutions.2 As a result, these observers argue, economic growth and change in coming decades likely will be noticeably slower than the pace to which Americans have become accustomed. Such an outcome would have important social and political--as well as economic--consequences for our country and the world.\n\nThis provocative assessment of our economic future has attracted plenty of attention among economists and others as well. Does it make sense? Here's one way to think more concretely about the argument that the pessimists are making: Fifty years ago, in 1963, I was a nine-year-old growing up in a middle-class home in a small town in South Carolina. As a way of getting a handle on the recent pace of economic change, it's interesting to ask how my family's everyday life back then differed from that of a typical family today. Well, if I think about it, I could quickly come up with the Internet, cellphones, and microwave ovens as important conveniences that most of your families have today that my family lacked 50 years ago. Health care has improved some since I was young; indeed, life expectancy at birth in the United States has risen from 70 years in 1963 to 78 years today, although some of this improvement is probably due to better nutrition and generally higher levels of income rather than advances in medicine alone. Nevertheless, though my memory may be selective, it doesn't seem to me that the differences in daily life between then and now are all that large. Heating, air conditioning, cooking, and sanitation in my childhood were not all that different from today. We had a dishwasher, a washing machine, and a dryer. My family owned a comfortable car with air conditioning and a radio, and the experience of commercial flight was much like today but without the long security lines. For entertainment, we did not have the Internet or video games, as I mentioned, but we had plenty of books, radio, musical recordings, and a color TV (although, I must acknowledge, the colors were garish and there were many fewer channels to choose from).\n\nThe comparison of the world of 1963 with that of today suggests quite substantial but perhaps not transformative economic change since then. But now let's run this thought experiment back another 50 years, to 1913 (the year the Federal Reserve was created by the Congress, by the way), and compare how my grandparents and your great-grandparents lived with how my family lived in 1963. Life in 1913 was simply much harder for most Americans than it would be later in the century. Many people worked long hours at dangerous, dirty, and exhausting jobs--up to 60 hours per week in manufacturing, for example, and even more in agriculture. Housework involved a great deal of drudgery; refrigerators, freezers, vacuum cleaners, electric stoves, and washing machines were not in general use, which should not be terribly surprising since most urban households, and virtually all rural households, were not yet wired for electricity. In the entertainment sphere, Americans did not yet have access to commercial radio broadcasts and movies would be silent for another decade and a half. Some people had telephones, but no long-distance service was available. In transportation, in 1913 Henry Ford was just beginning the mass production of the Model T automobile, railroads were powered by steam, and regular commercial air travel was quite a few years away. Importantly, life expectancy at birth in 1913 was only 53 years, reflecting not only the state of medical science at the time--infection-fighting antibiotics and vaccines for many deadly diseases would not be developed for several more decades‑-but also deficiencies in sanitation and nutrition. This was quite a different world than the one in which I grew up in 1963 or in which we live today.\n\nThe purpose of these comparisons is to make concrete the argument made by some economists, that the economic and technological transformation of the past 50 years, while significant, does not match the changes of the 50 years--or, for that matter, the 100 years--before that. Extrapolating to the future, the conclusion some have drawn is that the sustainable pace of economic growth and change and the associated improvement in living standards will likely slow further, as our most recent technological revolution, in computers and IT, will not transform our lives as dramatically as previous revolutions have.\n\nWell, that's sort of depressing. Is it true, then, as baseball player Yogi Berra said, that the future ain't what it used to be? Nobody really knows; as Berra also astutely observed, it's tough to make predictions, especially about the future. But there are some good arguments on the other side of this debate.\n\nFirst, innovation, almost by definition, involves ideas that no one has yet had, which means that forecasts of future technological change can be, and often are, wildly wrong. A safe prediction, I think, is that human innovation and creativity will continue; it is part of our very nature. Another prediction, just as safe, is that people will nevertheless continue to forecast the end of innovation. The famous British economist John Maynard Keynes observed as much in the midst of the Great Depression more than 80 years ago. He wrote then, \"We are suffering just now from a bad attack of economic pessimism. It is common to hear people say that the epoch of enormous economic progress which characterised the 19th century is over; that the rapid improvement in the standard of life is now going to slow down.\"3 Sound familiar? By the way, Keynes argued at that time that such a view was shortsighted and, in characterizing what he called \"the economic possibilities for our grandchildren,\" he predicted that income per person, adjusted for inflation, could rise as much as four to eight times by 2030. His guess looks pretty good; income per person in the United States today is roughly six times what it was in 1930.\n\nSecond, not only are scientific and technical innovation themselves inherently hard to predict, so are the long-run practical consequences of innovation for our economy and our daily lives. Indeed, some would say that we are still in the early days of the IT revolution; after all, computing speeds and memory have increased many times over in the 30-plus years since the first personal computers came on the market, and fields like biotechnology are also advancing rapidly. Moreover, even as the basic technologies improve, the commercial applications of these technologies have arguably thus far only scratched the surface. Consider, for example, the potential for IT and biotechnology to improve health care, one of the largest and most important sectors of our economy. A strong case can be made that the modernization of health-care IT systems would lead to better-coordinated, more effective, and less costly patient care than we have today, including greater responsiveness of medical practice to the latest research findings.4 Robots, lasers, and other advanced technologies are improving surgical outcomes, and artificial intelligence systems are being used to improve diagnoses and chart courses of treatment. Perhaps even more revolutionary is the trend toward so-called personalized medicine, which would tailor medical treatments for each patient based on information drawn from that individual's genetic code. Taken together, such advances could lead to another jump in life expectancy and improved health at older ages.\n\nOther promising areas for the application of new technologies include the development of cleaner energy--for example, the harnessing of wind, wave, and solar power and the development of electric and hybrid vehicles--as well as potential further advances in communications and robotics. I'm sure that I can't imagine all of the possibilities, but historians of science have commented on our collective tendency to overestimate the short-term effects of new technologies while underestimating their longer-term potential.5 \n\nFinally, pessimists may be paying too little attention to the strength of the underlying economic and social forces that generate innovation in the modern world. Invention was once the province of the isolated scientist or tinkerer. The transmission of new ideas and the adaptation of the best new insights to commercial uses were slow and erratic. But all of that is changing radically. We live on a planet that is becoming richer and more populous, and in which not only the most advanced economies but also large emerging market nations like China and India increasingly see their economic futures as tied to technological innovation. In that context, the number of trained scientists and engineers is increasing rapidly, as are the resources for research being provided by universities, governments, and the private sector. Moreover, because of the Internet and other advances in communications, collaboration and the exchange of ideas take place at high speed and with little regard for geographic distance. For example, research papers are now disseminated and critiqued almost instantaneously rather than after publication in a journal several years after they are written. And, importantly, as trade and globalization increase the size of the potential market for new products, the possible economic rewards for being first with an innovative product or process are growing rapidly.6 In short, both humanity's capacity to innovate and the incentives to innovate are greater today than at any other time in history.\n\nWell, what does all this have to do with creativity and critical thinking, which is where I started? The history of technological innovation and economic development teaches us that change is the only constant. During your working lives, you will have to reinvent yourselves many times. Success and satisfaction will not come from mastering a fixed body of knowledge but from constant adaptation and creativity in a rapidly changing world. Engaging with and applying new technologies will be a crucial part of that adaptation. Your work here at Simon's Rock, and the intellectual skills, creativity, and imagination that that work has fostered, are the best possible preparation for these challenges. And while I have emphasized technological and scientific advances today, it is important to remember that the arts and humanities facilitate new and creative thinking as well, while helping us to draw meaning that goes beyond the purely material aspects of our lives. I wish you the best in facing the difficult but exciting challenges that lie ahead. Congratulations.\n\n1. See Angus Maddison (2007), Contours of the World Economy, 1-2030 AD: Essays in Macro-Economic History (New York: Oxford University Press), table A.7, p. 382. Return to text\n\n2. Two important examples are Tyler Cowen (2011) and Robert J. Gordon (2010, 2012); the latter reference, in particular, also contains a discussion of headwinds to growth beyond the prospects for innovation. See Tyler Cowen (2011), The Great Stagnation: How America Ate All the Low-Hanging Fruit of Modern History, Got Sick, and Will (Eventually) Feel Better (New York: Dutton); Robert J. Gordon (2010), \"Revisiting U.S. Productivity Growth over the Past Century with a View of the Future,\" NBER Working Paper Series 15834 (Cambridge, Mass.: National Bureau of Economic Research, March); and Robert J. Gordon (2012), \"Is U.S. Economic Growth Over? Faltering Innovation Confronts the Six Headwinds,\" NBER Working Paper Series 18315 (Cambridge, Mass.: National Bureau of Economic Research, August). Return to text\n\n3. John M. Keynes (1931), \"Economic Possibilities for Our Grandchildren (1930),\" in Essays in Persuasion (London: Macmillan), p. 358. Return to text\n\n4. See Martin Neil Baily, James M. Manyika, and Shalabh Gupta (2013), \"U.S. Productivity Growth: An Optimistic Perspective,\" International Productivity Monitor, Spring, pp. 3-12. Return to text\n\n5. This tendency has been referred to as the first law of technology. On the potential impact of genome sequencing, see Francis Collins (2010), \"Has the Revolution Arrived?\" Nature, vol. 464 (April), pp.674-75. For an accessible discussion of the possibilities for life expectancy, see Stephen S. Hall (2013), \"On beyond 100,\" National Geographic, May, http://ngm.nationalgeographic.com/2013/05/longevity/hall-text. Return to text\n\n6. For a discussion of the economic models of growth that build in cumulative forces of knowledge generation and the effects of expansion in the size of the market, see Charles I. Jones and Paul M. Romer (2010), \"The New Kaldor Facts: Ideas, Institutions, Population, and Human Capital,\" American Economic Journal: Macroeconomics, vol. 2 (January), pp. 224-45. Return to text\n\n "
    },
    {
        "title": "Regulatory Landscapes: A U.S. Perspective",
        "date": "June 02, 2013",
        "speaker": "Vice Chair Janet L. Yellen",
        "url": "https://www.federalreserve.gov/newsevents/speech/yellen20130602a.htm",
        "content": "June 02, 2013\n\nVice Chair Janet L. Yellen\n\nAt the International Monetary Conference, Shanghai, China\n\nThank you. I don't want to delay what I expect to be a lively discussion, so my opening remarks will be brief. I'll summarize the considerable progress since 2008 to make the global financial system more resilient, and then offer my views on what more should be done.\n\nA Brief Retrospective on Financial Regulatory Progress\nIt's useful to divide the regulatory reform work of the past few years into three categories: strengthening the basic bank regulatory framework, reducing the threat to financial stability posed by systemically important financial institutions (SIFIs), and strengthening core financial markets and infrastructure.\n\nBank Regulatory Basics\nThe financial crisis revealed that banking firms around the world did not have enough high-quality capital to absorb losses during periods of severe stress. The Basel III reforms promulgated in 2010 by the Basel Committee on Banking Supervision will increase the amount of regulatory capital required to be held by global banking firms and improve the loss-absorbing quality of that capital. U.S. banking agencies issued proposals last summer to implement BaselIII's capital reforms, have reviewed comments, and are preparing the final regulation.\n\nWe also were reminded during the crisis that a banking firm--particularly one with significant amounts of short-term wholesale funding--can become illiquid before it becomes insolvent, as creditors run in the face of uncertainty about the firm's viability. The Basel Committee generated two liquidity standards to mitigate these risks: a Liquidity Coverage Ratio with a 30-day time horizon and a Net Stable Funding Ratio (NSFR) with a one-year time horizon. The U.S. banking agencies expect to issue a proposal to implement the Liquidity Coverage Ratio later this year, and we are working with the Basel Committee now to review the structure and parameters of the NSFR.\n\nSpecial Measures for SIFIs\nThe financial crisis also made clear that international bank rules should focus more on the potential threat to financial stability posed by SIFIs. In this arena, the efforts of the Federal Reserve and the global regulatory community have focused principally on (1) producing stronger regulations to reduce the probability of default of such firms to levels that are meaningfully below those for less systemically important financial firms, and (2) creating a resolution regime to reduce the losses to the broader financial system and economy upon the failure of a SIFI. The goal has been to compel SIFIs to internalize the costs their failure would impose on society and to offset any implicit subsidy that such firms may enjoy due to market perceptions that they are too-big-to-fail.\n\nThe effort to reduce the likelihood of SIFI failure has worked through several channels. The Basel Committee in 2011 agreed on a framework of graduated common equity risk-based capital surcharges for systemic firms, and we are working toward proposing rules to implement this surcharge framework in the United States. Consistent with the Dodd-Frank Wall Street Reform and Consumer Protection Act, the Federal Reserve proposed a broad set of enhanced prudential standards for large U.S. bank holding companies in December 2011. The Federal Reserve also now performs rigorous annual supervisory stress tests and capital plan reviews of the largest banking firms to ensure that these firms can continue to operate and lend through times of severe economic and financial stress.\n\nIn addition, in December the Federal Reserve proposed enhanced prudential standards for foreign banks under the Dodd-Frank Act. The proposal generally would require foreign banks with a large U.S. presence to organize their U.S. subsidiaries under a single intermediate holding company that would be subject to the same capital and liquidity requirements as U.S. bank holding companies. The proposal is designed to increase the resiliency and resolvability of the U.S. operations of foreign banks, help protect U.S. and global financial stability, and promote competitive equity for all large banking firms operating in the United States.\n\nIn addition to reducing the probability of SIFI failure, global regulators also have striven to reduce the potential damage to the financial system and the economy if a failure of a major financial firm were to occur. The Financial Stability Board (FSB) has proposed new standards for statutory resolution frameworks, firm-specific resolution planning, and cross-border cooperation. In the United States, Dodd-Frank created an OrderlyLiquidation Authority and required all large bank holding companies to develop resolution plans. Other countries that are home to large global banking firms are working along similar lines.\n\nStrengthening Resilience of Financial Markets\nReducing the likelihood of a severe financial crisis also requires strengthening the capacity of our financial markets and infrastructure to absorb shocks. Toward that end, U.S. and global regulators have worked to improve the transparency and stability of the over-the-counter derivatives markets and to strengthen the oversight of financial market utilities and other critical financial infrastructure. In particular, U.S. agencies are working together to address structural weaknesses in the triparty repo market and in money market mutual funds.\n\nThe Unfinished Business of Financial Regulatory Reform\nLet me now look forward. Although we have made the financial system safer, important work remains in each of the three areas I have highlighted: the basic bank regulatory apparatus, addressing the problems posed by SIFIs, and limiting risks in shadow banking and financial markets. Let me outline what I consider the principal pieces of unfinished business in global financial regulatory reform.\n\nStrengthening the Basic Bank Regulatory Framework\nFirst, we must actively support the continuing efforts of the Basel Committee to strengthen the foundations of global bank regulation. Key Basel Committee work in the years ahead will include finalizing the BaselIII leverage ratio and NSFR, completing the comprehensive review of trading book capital requirements, adopting a global large-exposure regime, and increasing the comparability of risk-based capital requirements across banks and across countries. I want to highlight the importance of the committee's work to explore ways to increase the standardization and comparability of the risk-based capital rules for global banks. The stability of the global financial system depends critically on the capital adequacy of global banks, the capital adequacy of global banks depends critically on the Basel III reforms, and much of the good progress in the BaselIII reforms rests on the integrity and strength of the risk weights.\n\nReducing the Probability of SIFI Failure\nAs this brief history has highlighted, tougher prudential regulation and supervision have substantially reduced the probability of a SIFI failure. Ending too-big-to-fail will require steadfast implementation by global regulators over the next few years of the work already in train. Some have proposed ideas for more sweeping restructuring of the banking system to solve too-big-to-fail. These ideas include resurrection of Glass-Steagall-style separation of commercial banking from investment banking and imposition of bank size limits. I am not persuaded that such blunt approaches would be the most efficient ways to address the too-big-to-fail problem. But at the same time I'm not convinced that the existing SIFI regulatory work plan, which moves in the right direction, goes far enough. As my colleagues Governors Tarullo and Stein have noted in recent speeches, it may be appropriate to go beyond the capital surcharges put forward by the Basel Committee. As they suggest, fully offsetting any remaining too-big-to-fail subsidies and forcing full internalization of the social costs of a SIFI failure may require either a steeper capital surcharge curve or some other mechanism for requiring that additional capital be held by firms that potentially pose the greatest risks to financial stability.\n\nImproving SIFI Resolvability\nThere are at least three key obstacles that policymakers must overcome to maximize the prospects for an orderly resolution of a global financial firm. First, each major jurisdiction must adopt a statutory resolution regime for financial firms consistent with the FSB's Key Attributes.1 The United States has been a leader in this regard, and I hope that other countries that have not yet adopted a compliant resolution regime will do so promptly. Second, policymakers need to ensure that all SIFIs maintain a sufficient amount of total pre-failure and post-failure loss absorption capacity. In consultation with the Federal Deposit Insurance Corporation, the Federal Reserve is considering the merits of a regulatory requirement that the largest, most complex U.S. banking firms maintain a minimum amount of long-term unsecured debt outstanding. Such a requirement could enhance the prospects for an orderly SIFI resolution. Switzerland, the United Kingdom, and the European Union are moving forward on similar requirements, and it may be useful to work toward an international agreement on minimum total loss absorbency requirements for global SIFIs. Third, it is time for policymakers to find concrete and credible solutions to the thorny cross-border obstacles that impede the orderly resolution of a globally systemic financial firm.\n\nReducing Systemic Risk in the Shadow Banking System\nImportant as banking reforms may be, it is worth recalling that the trigger for the acute phase of the financial crisis was the rapid unwinding of large amounts of short-term wholesale funding that had been made available to highly leveraged and/or maturity-transforming financial firms that were not subject to consolidated prudential supervision.\n\nMany of the key problems related to shadow banking and their potential solutions are still being debated domestically and internationally. But I believe the path forward is reasonably clear. We need to increase the transparency of shadow banking markets so that authorities can monitor for signs of excessive leverage and unstable maturity transformation outside regulated banks. We also need to take further steps to reduce the risk of runs on money market mutual funds. In addition, we need to further ameliorate risks in the settlement process for triparty repo agreements, including through continued reductions in the amount of intraday credit provided by the clearing banks.\n\nBut even when we accomplish these reforms, more work will remain to reduce systemic risk in the short-term wholesale funding markets that shadow banking relies on. A major source of unaddressed risk emanates from the large volume of short-term securities financing transactions (SFTs)--repos, reverse repos, securities borrowing and lending transactions, and margin loans--engaged in by broker-dealers, money market funds, hedge funds, and other shadow banks. Regulatory reform mostly passed over these transactions, I suspect, because SFTs appear safe from a microprudential perspective. But SFTs, particularly large matched books of SFTs, create sizable macroprudential risks, including large negative externalities from dealer defaults and from asset fire sales. The existing bank and broker-dealer regulatory regimes have not been designed to materially mitigate these systemic risks. The global regulatory community should focus significant amounts of energy, now, to attack this problem. The perfect solution may not yet be clear but possible options are evident: raising bank and broker-dealer capital or liquidity requirements on SFTs, or imposing minimum margin requirements on some or all SFTs.\n\nI'll stop there, and I look forward to the discussion.\n\n \n\n1. Financial Stability Board (2011), Key Attributes of Effective Resolution Regimes for Financial Institutions (PDF) (Washington, D.C.: Financial Stability Board, October). Return to text\n\n "
    },
    {
        "title": "The Ten Suggestions",
        "date": "June 02, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20130602a.htm",
        "content": "June 02, 2013\n\nChairman Ben S. Bernanke\n\nAt the Baccalaureate Ceremony at Princeton University, Princeton, New Jersey\n\nView Video\n\nIt's nice to be back at Princeton. I find it difficult to believe that it's been almost 11 years since I departed these halls for Washington. I wrote recently to inquire about the status of my leave from the university, and the letter I got back began, \"Regrettably, Princeton receives many more qualified applicants for faculty positions than we can accommodate.\"1 \n\nI'll extend my best wishes to the seniors later, but first I want to congratulate the parents and families here. As a parent myself, I know that putting your kid through college these days is no walk in the park. Some years ago I had a colleague who sent three kids through Princeton even though neither he nor his wife attended this university. He and his spouse were very proud of that accomplishment, as they should have been. But my colleague also used to say that, from a financial perspective, the experience was like buying a new Cadillac every year and then driving it off a cliff. I should say that he always added that he would do it all over again in a minute. So, well done, moms, dads, and families.\n\nThis is indeed an impressive and appropriate setting for a commencement. I am sure that, from this lectern, any number of distinguished spiritual leaders have ruminated on the lessons of the Ten Commandments. I don't have that kind of confidence, and, anyway, coveting your neighbor's ox or donkey is not the problem it used to be, so I thought I would use my few minutes today to make Ten Suggestions, or maybe just Ten Observations, about the world and your lives after Princeton. Please note, these points have nothing whatsoever to do with interest rates. My qualification for making such suggestions, or observations, besides having kindly been invited to speak today by President Tilghman, is the same as the reason that your obnoxious brother or sister got to go to bed later--I am older than you. All of what follows has been road-tested in real-life situations, but past performance is no guarantee of future results.\n\n1. The poet Robert Burns once said something about the best-laid plans of mice and men ganging aft agley, whatever \"agley\" means. A more contemporary philosopher, Forrest Gump, said something similar about life and boxes of chocolates and not knowing what you are going to get. They were both right. Life is amazingly unpredictable; any 22-year-old who thinks he or she knows where they will be in 10 years, much less in 30, is simply lacking imagination. Look what happened to me: A dozen years ago I was minding my own business teaching Economics 101 in Alexander Hall and trying to think of good excuses for avoiding faculty meetings. Then I got a phone call . . . In case you are skeptical of Forrest Gump's insight, here's a concrete suggestion for each of the graduating seniors. Take a few minutes the first chance you get and talk to an alum participating in his or her 25th, or 30th, or 40th reunion--you know, somebody who was near the front of the P-rade. Ask them, back when they were graduating 25, 30, or 40 years ago, where they expected to be today. If you can get them to open up, they will tell you that today they are happy and satisfied in various measures, or not, and their personal stories will be filled with highs and lows and in-betweens. But, I am willing to bet, those life stories will in almost all cases be quite different, in large and small ways, from what they expected when they started out. This is a good thing, not a bad thing; who wants to know the end of a story that's only in its early chapters? Don't be afraid to let the drama play out.\n\n2. Does the fact that our lives are so influenced by chance and seemingly small decisions and actions mean that there is no point to planning, to striving? Not at all. Whatever life may have in store for you, each of you has a grand, lifelong project, and that is the development of yourself as a human being. Your family and friends and your time at Princeton have given you a good start. What will you do with it? Will you keep learning and thinking hard and critically about the most important questions? Will you become an emotionally stronger person, more generous, more loving, more ethical? Will you involve yourself actively and constructively in the world? Many things will happen in your lives, pleasant and not so pleasant, but, paraphrasing a Woodrow Wilson School adage from the time I was here, \"Wherever you go, there you are.\" If you are not happy with yourself, even the loftiest achievements won't bring you much satisfaction.\n\n3. The concept of success leads me to consider so-called meritocracies and their implications. We have been taught that meritocratic institutions and societies are fair. Putting aside the reality that no system, including our own, is really entirely meritocratic, meritocracies may be fairer and more efficient than some alternatives. But fair in an absolute sense? Think about it. A meritocracy is a system in which the people who are the luckiest in their health and genetic endowment; luckiest in terms of family support, encouragement, and, probably, income; luckiest in their educational and career opportunities; and luckiest in so many other ways difficult to enumerate--these are the folks who reap the largest rewards. The only way for even a putative meritocracy to hope to pass ethical muster, to be considered fair, is if those who are the luckiest in all of those respects also have the greatest responsibility to work hard, to contribute to the betterment of the world, and to share their luck with others. As the Gospel of Luke says (and I am sure my rabbi will forgive me for quoting the New Testament in a good cause): \"From everyone to whom much has been given, much will be required; and from the one to whom much has been entrusted, even more will be demanded\" (Luke 12:48, New Revised Standard Version Bible). Kind of grading on the curve, you might say.\n\n4. Who is worthy of admiration? The admonition from Luke--which is shared by most ethical and philosophical traditions, by the way--helps with this question as well. Those most worthy of admiration are those who have made the best use of their advantages or, alternatively, coped most courageously with their adversities. I think most of us would agree that people who have, say, little formal schooling but labor honestly and diligently to help feed, clothe, and educate their families are deserving of greater respect--and help, if necessary--than many people who are superficially more successful. They're more fun to have a beer with, too. That's all that I know about sociology.\n\n5. Since I have covered what I know about sociology, I might as well say something about political science as well. In regard to politics, I have always liked Lily Tomlin's line, in paraphrase: \"I try to be cynical, but I just can't keep up.\" We all feel that way sometime. Actually, having been in Washington now for almost 11 years, as I mentioned, I feel that way quite a bit. Ultimately, though, cynicism is a poor substitute for critical thought and constructive action. Sure, interests and money and ideology all matter, as you learned in political science. But my experience is that most of our politicians and policymakers are trying to do the right thing, according to their own views and consciences, most of the time. If you think that the bad or indifferent results that too often come out of Washington are due to base motives and bad intentions, you are giving politicians and policymakers way too much credit for being effective. Honest error in the face of complex and possibly intractable problems is a far more important source of bad results than are bad motives. For these reasons, the greatest forces in Washington are ideas, and people prepared to act on those ideas. Public service isn't easy. But, in the end, if you are inclined in that direction, it is a worthy and challenging pursuit.\n\n6. Having taken a stab at sociology and political science, let me wrap up economics while I'm at it. Economics is a highly sophisticated field of thought that is superb at explaining to policymakers precisely why the choices they made in the past were wrong. About the future, not so much. However, careful economic analysis does have one important benefit, which is that it can help kill ideas that are completely logically inconsistent or wildly at variance with the data. This insight covers at least 90 percent of proposed economic policies.\n\n7. I'm not going to tell you that money doesn't matter, because you wouldn't believe me anyway. In fact, for too many people around the world, money is literally a life-or-death proposition. But if you are part of the lucky minority with the ability to choose, remember that money is a means, not an end. A career decision based only on money and not on love of the work or a desire to make a difference is a recipe for unhappiness.\n\n8. Nobody likes to fail but failure is an essential part of life and of learning. If your uniform isn't dirty, you haven't been in the game.\n\n9. I spoke earlier about definitions of personal success in an unpredictable world. I hope that as you develop your own definition of success, you will be able to do so, if you wish, with a close companion on your journey. In making that choice, remember that physical beauty is evolution's way of assuring us that the other person doesn't have too many intestinal parasites. Don't get me wrong, I am all for beauty, romance, and sexual attraction--where would Hollywood and Madison Avenue be without them? But while important, those are not the only things to look for in a partner. The two of you will have a long trip together, I hope, and you will need each other's support and sympathy more times than you can count. Speaking as somebody who has been happily married for 35 years, I can't imagine any choice more consequential for a lifelong journey than the choice of a traveling companion.\n\n10. Call your mom and dad once in a while. A time will come when you will want your own grown-up, busy, hyper-successful children to call you. Also, remember who paid your tuition to Princeton.\n\nThose are my suggestions. They're probably worth exactly what you paid for them. But they come from someone who shares your affection for this great institution and who wishes you the best for the future.\n\nCongratulations, graduates. Give 'em hell.\n\n \n\n1. Note to journalists: This is a joke. My leave from Princeton expired in 2005. Return to text\n\n "
    },
    {
        "title": "Let's Move Forward: The Case for Timely Implementation of Revised Capital Rules",
        "date": "June 06, 2013",
        "speaker": "Governor Sarah Bloom Raskin",
        "url": "https://www.federalreserve.gov/newsevents/speech/raskin20130606a.htm",
        "content": "June 06, 2013\n\nGovernor Sarah Bloom Raskin\n\nAt the Ohio Bankers Day, Columbus, Ohio\n\nGood morning and thank you to the Ohio Department of Commerce Division of Financial Institutions (DFI) for the invitation to come to Columbus to share some thoughts with you on Ohio Bankers Day.\n\nIn my remarks this morning, I want to describe some features of an appropriate regulatory capital framework for banks--focusing on community banks--and I'll cut to the chase by setting out what I believe to be two imperatives in finalizing this framework. Each of these imperatives has, at its core, the inherent goals of minimizing uncertainty and promoting safety and soundness. These imperatives are timeliness and simplicity.1 \n\nTo explain why timeliness--by which I mean timely implementation of final capital rules in the United States--and simplicity are imperative, it helps to set the stage. And to do that, I have to go back in time. Way back, in fact, to when I was a child growing up in a small town in Illinois, just minutes away from the Indiana border. There was no bank in our town, but there was one in the next town over, which was where my family and our neighbors would do their banking. The bank probably had no more than $30 million in assets. On Saturday mornings, my mother (who essentially was the CFO of the family financial unit) would toss me in the back seat of the car and drive over to deposit my parents' paychecks, which, in those days before ATMs, meant visiting a teller. If there were no checks to deposit, Saturday morning would be when my mother would go to withdraw cash for the week. \"Get in this line,\" my mother would order. \"We want Shirley.\"\n\nSometimes, we would end with a visit to the vault. To my seven-year-old self, going to the vault was deadly serious, a ritual that began by signing in with a stern-looking man who held the keys. It felt like entering a cave and looking at gold, although in retrospect I suspect my mother was only checking on insurance policies or her passbook savings. After the vault, back in the lobby there were donuts with sprinkles and coffee, and the donuts came from the bakery next to the bank, which meant they were exceedingly special.\n\nYears later, I learned that this bank was swallowed up by a larger competitor. But what was important about this bank, and why it remains so vivid in my memory, is that it was part of the fabric of our community. Our bank not only bought the local donuts, it sponsored the local Little League team, had a table at the summer sidewalk sale, made the hand fans for the Fourth of July parade, gave money to the local hospital's candy stripers, and surely did hundreds of other things invisible to me but nonetheless sewn into the tapestry of the lives of our community.\n\nCommunity Banking Today\nLest this sound only like nostalgia for small-town America, let's remember that the vast majority of American banks today are still very much like this one in scale, and have deep roots in their communities.2 For the most part, these banks did not engage in subprime lending, nor did they otherwise contribute to the financial crisis. These banks provide their towns with sustainable and affordable credit, and have employees on hand to provide families with good advice about how to save for cars, houses, new businesses, and education.\n\nThis large segment of financial institutions is a necessary and critical part of our country's financial landscape. And it is returning to strength. While revenue is not fully back to pre-crisis levels, the community banking sector is solidly profitable. Asset quality has improved and appears to have stabilized and capital ratios have been strengthened and remain, on average, higher than those of larger banks.\n\nI do not need to trumpet the benefits that community banks provide right now. But I will highlight that post-crisis research regarding these banks is moving front and center and shows that these banks provided public benefits in the crisis and in the recovery stage after the crisis.3 For example, data show that community banks played an important cushioning role in the aftermath of the collapse of the market for jumbo mortgages. When the market for private-label, mortgage-backed securities collapsed in 2007, so too did jumbo mortgage lending as liquidity dried up.4 In the immediate aftermath, despite a substantial reduction in jumbo lending as a share of the overall mortgage market, the data indicate that the share of community bank jumbo mortgage lending held steady. Such lending actually increased at community banks that were not dependent on correspondent banking and at those that were sufficiently well capitalized and more profitable. And, by their sheer numbers and their central role in local communities, these banks are vital and competitive players in a highly diverse landscape for financial services. They often provide competitive options where none would otherwise exist, thereby lower borrowing costs for businesses and consumers.\n\nWhether we single them out for special advantage is a question for legitimate debate. What I do know is that what we most certainly should not do is hinder them from engaging in a fair fight.\n\nThe Post-Crisis Regulatory Landscape\nThis brings me to regulatory policy. One of the questions I am most frequently asked when I speak to audiences like this one is, \"What on earth is going on in Washington these days?\"\n\nWell, there certainly is a lot going on. Right now, among some other things, federal regulators are working to build out hundreds of requirements laid out by Congress in the Dodd-Frank Wall Street Reform and Consumer Protection Act. And, in the midst of this complicated rule-writing effort, there is a renewed debate over whether these requirements are sufficient to end too-big-to-fail. Regulators are also continuing to oversee improvements to the operational problems in the massive numbers of foreclosures in the wake of the financial crisis and exploring the risks to financial stability that may persist in the differentially regulated parts of our financial system. This is all necessary work, and it is appropriately getting significant attention from officials at the highest levels in multiple agencies.\n\nBut just as important is what, unfortunately, is not yet getting as much attention in Washington. What is not happening--what in fact may be difficult to achieve until this post-crisis work is near completion and the overarching goal of financial stability has been addressed--is a more proactive inquiry and articulation of a positive vision of what kind of financial system we want to foster or preserve. While we focus on the difficult task of implementing a wide range of rules, a number of questions about the industry remain, questions that we must shift our full focus to once the post-crisis work is near completion.\n\nFor example, is diversity in both the size and type of financial institutions critical to the goals of stability and access to credit? Should new technologies that permit mobile payments and mobile banking be fostered through federal policy? To what extent should we be concerned about cyber threats, and are there features of a financial system that can mitigate or thwart such threats? After a crisis caused in part by opaque financial engineering, how do we prevent such excesses without stifling innovation that might benefit customers and the public and foster economic growth? Should financial inclusion and financial literacy be regulatory goals, as some have suggested, and what responsibility should banks bear in achieving such ends? What do we do to re-calibrate a multi-layered regulatory response that was partly dictated by the exigencies of a crisis rather than by calculated principles of best design?\n\nWe have to address these and other questions if we hope to envision a post-crisis financial regulatory system that supports a strong, dynamic, and diverse financial system. This, to me, is the strongest motivation for moving ahead as expeditiously as possible on implementing statutory requirements and international agreements to raise capital standards so that we can begin lifting our vision beyond a crisis response. Moreover, as we implement these requirements and agreements, one of the things that the agencies have been considering is how we can do so in a way that does not differentially harm those financial institutions whose actions were not, by and large, responsible for the need to develop a policy response to the crisis.\n\nTimeliness\nLet's talk about the importance of timely implementation of rules based on one set of international agreements--the Basel III framework. The proposed rule, together with the capital-related provisions in the Dodd-Frank Act, is intended to raise both the quality and quantity of capital at banking organizations in the United States.  I fully support this goal, because the financial crisis demonstrated, among other things, the need for robust capital at banks of all sizes.  The issue, of course, is that the framework has not been finalized, and I am concerned that significant, further delays could add to uncertainty and could detract from the maintenance of strong capital levels.\n\nThere are some good reasons why the capital rules have not yet been finalized--in particular, the need to carefully consider the thousands of comment letters on the proposed rules, many of which came from community banks. Meanwhile, since Basel III sets a final deadline for implementation of 2019, one might ask why it is so imperative to act sooner.\n\nFirst, while it is important to get it right, this goal must be balanced with the costs imposed by delay. Lending decisions and funding plans today are shaped by perceptions of business conditions in the future, and those conditions include the details of the final regulatory capital framework. It seems obvious to me that uncertainty over that framework is weighing on the balance sheets of banks that will be affected by the rules.\n\nSecond, while Basel III calls for full implementation by 2019, it also envisions a transition that must start years earlier. Since the transition to the new rules will be gradual, with some elements of the rules proposed to come into effect earlier, the sooner that regulators finalize the rules, the sooner banks will be able to incorporate those rules into their capital planning efforts.\n\nNow that banking agencies, including the Federal Reserve, have completed much of the analytical work in response to public comments on the proposed rules on Basel III, we must continue to work together to get on with the finalization of a regulatory capital framework. So let me add my voice to those who believe that this work must be completed soon. At a moment when the economy finally seems to be gaining some traction, I believe that finalizing a capital rule will minimize uncertainty related to capital requirements as well as promote safer and sounder banks.\n\nSimplicity\nThere is significant justification for both higher levels, and higher quality, of capital. In particular, we have seen that highly capitalized banks are more likely to maintain their lending activity through good times and bad, as evidenced during the recent crisis, a trend that helps their customers and the overall economy.5 A framework requiring higher quality and quantity of capital should be established post-haste. At the same time, however, for community banks in particular, more and better capital should be achieved without significantly increasing the complexity of capital calculations. It is not only possible and desirable, but also necessary, to ensure that our capital requirements for community banks remain relatively simple and effective. Otherwise, we risk drowning banks in a capital adequacy system that is so complex that it both misses the mark of addressing meaningful emerging risks and piles regulatory costs on banks with no public benefit. I should note here that the proposed Basel III rules include complex models-based approaches for internationally-active banks and for banks with significant trading activities. These models-based approaches are clearly inappropriate for, and will not apply to, community banks.\n\nRisk-Weighted Assets\nTo step back, the first framework for risk-based capital was implemented in the United States in 1989 and entailed assigning assets to one of four defined risk-weighting categories: zero percent, 20 percent, 50 percent, and 100 percent, with a higher percentage signifying higher inherent risk.6 This had the advantage of making the framework more risk-sensitive than the simpler, one-size-fits-all, leverage-based approach that I will discuss later. As a result, a Treasury security and an unsecured loan to a start-up business were no longer treated identically for purposes of regulatory capital. This not only made intuitive sense, but was also more consistent with how banks managed their own balance sheets and measured their risk-based performance.\n\nBut the approach of risk-weighting assets by placing them in defined buckets is not precise. While it might have the virtue of providing some capital sensitivity to the quality of different asset classes, a granular system of risk-weighting raises issues of its own.\n\nFor example, the riskiness associated with each asset class can be flat-out wrong. Errors are going to occur in part because risks can change over time and in part because no one has perfect knowledge about the nature of risks associated with every single asset class. To note one prominent example, risk exposures to the sovereign debt of countries that are members of the Organisation for Economic Co-operation and Development currently receive a zero percent risk weight. That is, for regulatory capital purposes, their debt is considered to be risk-free. But if there is one thing we have learned in recent years, sovereign debt can indeed be risky even if, in good times, it appears to be perfectly safe.\n\nIn addition, I believe you can make a case that risk weights for securitization exposures understated the risks and losses that were actually incurred in these exposures. In fairness, losses during the financial crisis far exceeded prior historical losses on securitization exposures. But that's just the point: The risk profile of a particular financial instrument can change significantly over time, which can be very difficult to capture in a regulatory capital regime based on crude risk buckets that do not evolve over time. Accordingly, the amount of capital held can be inappropriate relative to the actual risk.\n\nOne problem this can lead to is that it can create incentives that skew lending decisions and credit allocation more broadly. To be clear, I don't want to give the impression that banks' lending decisions are driven solely, or even primarily, by regulatory capital requirements. Bank lending is influenced by a variety of factors--capital requirements are just one. But at the margin, we shouldn't be surprised to see banks in aggregate making lending and investment decisions that have favorable risk-based capital treatment or that generate higher returns on a given amount of regulatory capital. So, for example, in Europe a number of banks had significant sovereign holdings going into the financial crisis, not only because capital requirements were so low, but also because high credit spreads made these particularly attractive investments. Likewise, here in the United States, banks piled into mortgage lending in the early- to mid-2000s not only because it offered generous returns, but also because regulatory capital requirements did not adequately capture the risks in this lending, particularly for subprime exposures.\n\nLeverage Ratio\nOne of the ways that supervisors, particularly here in the United States, have addressed shortcomings in the risk-based capital regime has been to also impose a simple capital-to-assets requirement, or leverage ratio, to supplement the risk-based measures. A leverage ratio has a number of things that make it intuitively appealing, if it can be set correctly. First and foremost, it has the virtue of simplicity. Not only is it easy to calculate and easy for market participants and the public to understand, it also provides a single benchmark by which to easily compare and calibrate institutions' capital positions. In addition, a leverage ratio provides a relatively straightforward gauge of how close an institution is to insolvency. In simple terms--and I should caution that reality is seldom this simple--if an institution has a leverage ratio of 3 percent, a decline in value of assets on the balance sheet of greater than 3 percent is likely to render the institution insolvent.\n\nMoreover, we know not only from the fundamentals of finance theory but also from hard experience, that while leverage can boost earnings when times are good, leverage can also amplify losses. There is a reason why, despite the evolution of risk-based capital frameworks over the years, the leverage ratio has remained a key part of the banking supervision toolbox. This was recognized by the U.S. Congress when it passed the Federal Deposit Insurance Corporation Improvement Act (FDICIA) in 1991. FDICIA made the leverage ratio one of the key elements of the prompt corrective action framework for assigning capital categories to banks and taking supervisory action as appropriate and required by law. As a matter of fact, U.S. supervisors felt that a leverage ratio was such an important factor in assessing capital adequacy that U.S. negotiators worked to make sure a leverage ratio was included in the Basel III framework for global banks, many of which were not subject to explicit leverage requirements.\n\nFor all its strengths, however, a leverage ratio also has significant shortcomings if not set appropriately. While its simplicity may be one of its greatest virtues, simplicity is also one of its biggest drawbacks. Notably, leverage ratios typically only apply to assets held on the balance sheet. This may be fine for institutions that primarily engage in on-balance-sheet deposit-taking and lending--like most community banks--but it can fail to capture the risks of banks' off-balance-sheet activities, which have grown exponentially over the past several decades. I mentioned previously that leverage tends to amplify losses, and I would suggest that many of the losses during the recent financial crisis, particularly at the largest firms, were a result of off-balance-sheet leverage.\n\nSo, given the various features of a simple leverage-based approach and a more complex and imperfect system of risk weighting, what is the right approach for community banks? The right approach should not significantly increase the complexity of capital. The risk-based capital ratios should provide a rough baseline benchmark for ensuring that sufficient capital is held relative to a bank's risk profile, and the leverage ratio--which has certainly stood the test of time--serves as an effective backstop to reduce the risk that a bank would allow its balance sheet to become overleveraged.\n\nSupervisory Assessments of Capital Adequacy\nIndeed, there is another side to appropriate regulation. And that is supervision and the supervisory process. At least as, if not more important as the regulatory ratios for banks is an effective supervisory assessment of capital adequacy. Regulatory capital ratios certainly provide valuable input into a bank's capital adequacy, but it is important to understand that these ratios are rough and imperfect estimates. As supervisors, we expect banks to hold capital that captures the full range of risks associated with the bank's activities, which, based on a bank's expertise in managing the risks, may very well dictate capital levels that differ from these minimum ratios.\n\nI'm not talking about anything new here: If you look at the criteria for rating capital adequacy under the banking agencies' CAMELS rating system for banks7 , and under the Federal Reserve's RFI rating system for bank holding companies, you will actually see very few references to minimum regulatory capital.8 Instead, the focus is on maintaining capital that is commensurate with the overall risk profile of the bank, not just credit risk. This requires both management and the supervisor to have an effective understanding of the banking organization's risk profile, which is central to our supervisory program. This supervisory feature sometimes gets lost in the public debate about the value of well-constructed regulatory capital ratios, but I believe that effective supervisory assessments of risk and capital adequacy as part of the community bank examination process are absolutely critical.\n\nConclusion\nIn sum, let me conclude by saying that time is of the essence here in moving forward with the Basel III final rules. The proposed rules were not perfect and I expect there to be meaningful modifications. At the same time, while we attempt to craft a risk-based system that makes sense from the perspective of safety and soundness, we have to resist the temptation to believe we can create a perfectly sensitive risk-based regime that gives the illusion of safety. Such a regime would not be a meaningful surrogate for effective on-site supervision, and the effort to try to create an ever-more refined system would distract us from some of the important policy questions that lie ahead for our financial system. Finally, there are costs to complexity that should not be ignored. We shouldn't be lulled into thinking that these unnecessary costs should be allocated to community banks, which are a segment of our financial system that provides meaningful benefits to many Americans.\n\nThank you very much for your time this morning.\n\n \n\n1. The views in these remarks are my own and not necessarily those of my colleagues on the Federal Reserve Board. Return to text\n\n2. According to Call Report data, as of March 31, 2013, 98 percent of the 6,017 insured commercial banks in the United States had total assets of $10 billion or less, which is the threshold that the Federal Reserve typically uses to define community banks. And the vast majority of these (91 percent of all insured commercial banks) are much smaller as of that date, with less than $1 billion in total assets. Return to text\n\n3. To highlight the importance of such research, the Federal Reserve System and the Conference of State Bank Supervisors will host a conference on \"Community Banking in the 21st Century \" at the Federal Reserve Bank of St. Louis on October 2-3, 2013. Return to text\n\n4. See Paul Calem, Francisco Covas, and Jason Wu (2011), \"The Impact of a Liquidity Shock on Bank Lending: The Case of the 2007 Collapse of the Private-Label RMBS Market (PDF),\" (Washington: Board of Governors of the Federal Reserve System, August 15). Publication is also forthcoming in the Journal of Money, Credit and Banking. This paper did not specifically address community bank lending, but the authors conducted subsequent analysis of community bank data using the methodology set forth in the paper. Return to text\n\n5. See R. Alton Gilbert, Andrew P. Meyer, and James W. Fuchs (2013), \"The Future of Community Banks: Lessons From Banks That Thrived During the Recent Financial Crisis (PDF) ,\" Federal Reserve Bank of St. Louis Review (March/April), pp. 115-144. Return to text\n\n6. Note that the number of risk weight buckets would increase under the Basel III notices of proposed rulemaking (77 Fed. Reg. 52791 and 77 Fed. Reg. 52887), but would still remain relatively small. Return to text\n\n7. The interagency CAMELS rating system for banks is described in Supervisory and Regulatory (SR) letter 96-38, \"Uniform Financial Institutions Rating System.\" The main compoments of the CAMELS rating system are capital adequacy (C), asset quality (A), management (M), earnings (E), liquidity (L), and sensitivity to market risk (S), as well as an overall composite rating. Return to text\n\n8. The Federal Reserve's RFI rating system for bank holding companies is set forth in SR letter 04-18, \"Bank Holding Company Rating System.\" The main components of the RFI rating system are risk management (R), financial condition (F), and potential impact (I). Return to text"
    },
    {
        "title": "Thoughts on Unconventional Monetary Policy",
        "date": "June 27, 2013",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20130627a.htm",
        "content": "June 27, 2013\n\nGovernor Jerome H. Powell\n\nAt the Bipartisan Policy Center, Washington, D.C.\n\nView Video\n\nIt is great to be back at the Bipartisan Policy Center. I will comment briefly on the outlook for the economy and then turn to monetary policy.1 \n\nNear-Term Outlook\nOur economy has grown at an average annual rate of only about 2 percent since the recovery began exactly four years ago. That modest pace is notably weaker than the experience of past recoveries would have predicted, even accounting for the depth and duration of the Great Recession.2 Since 2009, the question has been when the recovery will decisively take hold and begin to deliver the higher levels of growth that are needed to put people back to work more quickly.\n\nAgainst that background, the Federal Open Market Committee (FOMC) met last week, and, among other tasks, each of the 19 members of the Committee submitted individual economic projections for growth, unemployment, and inflation for 2013 through 2015. These forecasts are combined into the Summary of Economic Projections (SEP), a high-level outline of which was released at the Chairman's press conference last week. FOMC participants generally expect an acceleration of the recovery through 2013 and 2014 and continued strong growth in 2015. While I make no claim to special forecasting skills, my individual projections are within the so-called central tendency of the projections. Of course, the economy has looked to be poised for a breakout several times since 2009, only to disappoint. Will this time be different?\n\nThere are, in my view, good reasons to believe that the economy will continue to gain strength. I would point in particular to the housing sector, which in prior recoveries has been an important engine of growth. For the first two years of the current recovery, housing contributed nothing to growth, as housing investment hovered at extremely low levels. House prices declined sharply through most of 2011, wiping out about half of home equity and restraining consumer spending. But the housing market finally began to recover in early 2012, and that recovery seems to be proceeding strongly. Single-family housing starts have risen by more than 40 percent over the past two years, albeit from a low base. House prices are up more than 10 percent over the past 12 months. A better housing market has helped boost consumer attitudes from very low levels and supported consumer spending. The housing sector is still being held back by limited credit availability for less-creditworthy homebuyers and tight conditions for homebuilders. But overall trends suggest to me that the housing recovery can continue for many years and become an important contributor to growth.\n\nThe labor market has also made real progress, as I will discuss in a moment. Auto sales have nearly returned to pre-recession levels. Our financial system is far healthier and better capitalized than it was before the crisis. And after losing one-half of its value during the financial crisis, the stock market now exceeds its pre-recession peak in nominal terms.\n\nGrowth would be higher this year but for U.S. fiscal policy. The Congressional Budget Office (CBO) estimates that federal tax increases and spending cuts will slow the pace of real gross domestic product (GDP) growth about 1-1/2 percentage points this year.3 Tight fiscal policy may also be preventing faster reductions in unemployment. I have been surprised by how well consumer spending--and private domestic final demand more generally--have held up in the face of this pronounced fiscal drag. In the first quarter of this year, consumer spending and private domestic final demand rose at an annual rate of just above 2-1/2 percent. More-recent indicators of household and business spending suggest that private demand is continuing to advance at a reasonable clip despite the fiscal tightening. This strength is a reason for optimism. Indeed, even if real GDP rises only 2 percent or so this year--which is at the bottom end of the range of projections from the June SEP--it would still represent a solid performance in the face of these fiscal headwinds.\n\nThere is still a long way to go before we achieve a full recovery. The healing process will take time, but we continue to make real progress.\n\nLet's turn to monetary policy, starting with the dual mandate, pursuant to which the Congress directs the Federal Reserve to conduct monetary policy so as to foster stable prices and full employment.\n\nDual Mandate--Inflation\nInflation is currently running below the FOMC's 2 percent long-term objective for personal consumption expenditure (PCE) price inflation, and these readings have our attention. But inflation often fluctuates for transitory reasons. We generally try to look through such transitory movements, whether above or below our objective. There is some reason to think that the recent low readings partly reflect transitory factors. Other factors point to a gradual increase in inflation. While some measures of longer-term inflation expectations have moved down, others remain more stable. Most FOMC participants anticipate that inflation will gradually move up to the FOMC's 2 percent target over coming years. Continued low or falling inflation could, however, raise real concerns. Inflation can be too low as well as too high. I have no doubt that the Committee will monitor this carefully and defend the inflation goal \"from below,\" if necessary.\n\nDual Mandate--Full Employment\nThe employment side of the dual mandate is a different story. From payroll employment's peak in January 2008 to its trough in February 2010, the U.S. economy lost nearly 9 million jobs, while the unemployment rate rose from an average of about 4‑1/2 percent in 2007 to a high of 10 percent in October of 2009. As the economy has recovered, we have regained only about three-fourths of those lost jobs. Unemployment was 7.6 percent in May and so has come down about 2-1/2 percentage points from its peak. A broader measure that includes those who can only find part-time work, as well as those who want a job but have stopped looking, was 13.8 percent last month; in 2007, this measure averaged 8-1/4 percent.\n\nIn addition, long-term unemployment remains very high--4.4 million Americans or about 37 percent of the unemployed have been out of work for six months or more. These numbers represent tragedy and hardship for these workers and their families, of course, but they also represent a crucial economic challenge. The longer workers are unemployed, the greater the likelihood that their skills will erode and workers will lose attachment to the labor force, permanently damaging the economy's dynamism and potential output.\n\nTo summarize, although inflation is below target, it is expected by most observers to return over time to the Committee's 2 percent objective. The Committee will continue to carefully monitor inflation developments. But we are still far from full employment. The case for continued support for the economy from monetary policy is strong.\n\nImplications for Monetary Policy\nThe federal funds rate has been near zero since late 2008, and since then the FOMC has been providing accommodation through two relatively new policy tools. These tools are \"forward guidance\" about the future level of the federal funds rate, which is the interest rate charged on overnight loans between banks, and large-scale asset purchase programs (\"asset purchases,\" or LSAPs).\n\nIn part, the forward-guidance tool is embodied in the thresholds the FOMC adopted last December. The Committee indicated its intention to hold short-term rates near zero at least as long as unemployment remains above 6.5 percent, provided inflation one- to two-years ahead is projected to be no higher than 2.5 percent.4 And under the current flow-based LSAP program, adopted last year, we are purchasing $85 billion a month in long-term Treasury securities and agency mortgage-backed securities (MBS). Although the level of purchases may vary depending on economic conditions, the program will continue until there is a substantial improvement in the outlook for the labor market, in a context of price stability.\n\nI see the first tool, forward guidance about rates, as really an extension of traditional central bank rate-setting policy. By stating an intention to hold rates low and linking that intention to the path of the economy, forward guidance affects the path of longer-term rates and allows the market to make adjustments to these rates as economic conditions evolve.\n\nThe second tool is large-scale asset purchases. By purchasing and holding large amounts of Treasury securities and MBS, we put additional downward pressure on term premiums and so on long-term rates. Asset purchases are an innovative, unconventional policy. Their likely benefits may be accompanied by costs and risks, the nature and size of which remain uncertain.\n\nThese two policies are complementary but play somewhat different roles. Asset purchases are being deployed to add near-term momentum to the economy. After those purchases are eventually completed, the purchased assets will remain on the Fed's balance sheet for some time and continue to put downward pressure on rates. The Committee will continue to use interest rate policy, including forward guidance about short-term rates, as we return to full employment. Provided inflation remains in check, the Committee will begin to assess whether to increase short-term rates when unemployment reaches 6.5 percent. Two important considerations are likely to arise at that time. First, if inflation remains low, as expected, that would be a signal that there is still significant slack in the economy. Second, a variety of other information will shed further light on the health of the labor market, including the labor force participation rate, flows into and out of employment, and other measures of labor slack. After the Committee first raises short-term rates, it will take a balanced, and in all likelihood gradual, approach consistent with its longer-run goals of full employment and inflation of 2 percent.\n\nBoth forward guidance and asset purchases work by lowering longer-term interest rates and contributing to an easing of overall financial market conditions. Lower rates increase economic activity through a variety of channels.5 Businesses and households react to lower rates by investing and spending more. Lower rates also support the prices of housing and financial assets such as stocks and bonds. Higher asset prices increase wealth and, with a lag, induce higher spending.\n\nIn all likelihood, the current LSAP program will continue for some time. It is therefore appropriate to ask how well asset purchases have worked, and whether they are still working today.\n\nBenefits\nMost research has found, and I agree, that the first round of purchases of longer-term securities, which began in November 2008, contributed significantly to ending the financial crisis and preventing a much more severe economic contraction. The second round of purchases that began in November 2010 also appears to have been successful in countering disinflationary pressures.6 \n\nNow that the financial crisis has receded and the economy is recovering at a moderate pace, are asset purchases still effective? In my view, the evidence across the channels is mixed, but positive on balance.\n\nEconomic models are used to provide a necessarily uncertain estimate of the effect on the economy of the FOMC's asset purchases. The Fed's workhorse macro model is FRB/US, which estimates a reduction of about 20 basis points in the unemployment rate after three years in the wake of $500 billion in purchases of longer-term securities. There are reasons to think that this estimate may be too low; for example, FRB/US does not include any direct channel for LSAPs to boost house prices. There are also reasons to think that the estimate might be too high, since some of the channels by which lower rates spur economic activity could be attenuated in current circumstances, for example, by lower credit availability for small businesses and less creditworthy households, or corporate and household risk aversion.\n\nMy view is that the LSAPs continue to provide meaningful support for economic activity but perhaps less than what the FRB/US estimates suggest. Although the channels may not be working perfectly, it is unlikely that they are not working at all. Beyond these model-predicted effects, it also seems likely that the economy continues to benefit from the knowledge that the Federal Reserve is committed to supporting growth as long as necessary.\n\nCosts of LSAPs\nWhat of the potential costs or risks of the asset purchases? A variety of concerns have been raised over time. With inflation in check, the most important potential risk, in my view, is that of financial instability. One concern is that our policies might drive excessive risk-taking or create bubbles in financial assets or housing. A related worry is that the eventual process of reducing purchases and normalizing the balance sheet may itself be destabilizing or disruptive to the economy. Indeed, recent volatility in markets is in part related to concerns about the possibility of a reduction in asset purchases. I'll address both of these broad concerns, starting with incentives for risk-taking.\n\nMonetary policy has helped to keep real interest rates low. While longer-term real rates have turned positive in recent weeks, they remain at historically low levels. Experience suggests that low real rates, if maintained for a long time, can lead to asset price bubbles and eventually to financial instability. But low rates are not solely or even primarily a result of the Federal Reserve's accommodative monetary policies; they are rooted in the market's expectations of low inflation and the weakness of the economic recovery, factors weighing on rates not just in the United States but throughout the advanced economies.7 Given low real rates and low inflation, expected nominal returns should be low across all asset classes. The concern would be that these conditions, and our policies, could be encouraging irrational expectations of high returns. Is there any sign of that now?\n\nBy most measures, equity valuations seem to be within a normal range. Whether one looks at trailing or forward price-to-earnings ratios, equity risk premiums, or option prices, there is little basis for arguing that markets show excessive optimism about future returns. Of course, in the equity markets there is always downside risk.\n\nBut, as my Board colleague Jeremy Stein has observed, there have been signs of a \"reach for yield\" in the fixed-income markets for some time.8 Demand for higher-yielding fixed-income securities has outstripped new supply. The result has been very low rates, declining spreads, increasing leverage, and pressure on non-price terms such as covenants. These concerns have diminished somewhat as rates have risen since mid-May. Nonetheless, since it is likely that asset purchases will continue for some time, markets will need careful monitoring.\n\nWhat about house prices? At the peak of the bubble, house prices were more than 40 percent above their usual relationship to rents, according to one model that the Fed staff follows. At their trough, house prices had fallen about 10 percent below fair valuation. Given the price increases over the past year, they are--by the lights of this one model--moving back into the approximate neighborhood of fair valuation.\n\nThe second concern is that the process of normalizing monetary policy and the balance sheet could itself be destabilizing or disruptive to the economy. Many cite the experiences of 1994 and 2003, when long-term rates increased quite sharply on changing views about the likely near-term path of policy. In those instances, there were both changes in views about the economy and changes in the public's understanding of the Federal Reserve's policy intentions. These same two factors have affected markets in recent weeks.\n\nMarket adjustments since May have been larger than would be justified by any reasonable reassessment of the path of policy. In particular, the reaction of the forward and futures markets for short-term rates appears out of keeping with my assessment of the Committee's intentions, given its forecasts. The June SEP shows that 15 of 19 participants see the first rate increase happening in 2015 or 2016. The path of rates will ultimately depend on the path of the economy, and the Committee has said that the first rate increase will not happen until a considerable time has elapsed after asset purchases have been concluded. Thus, to the extent the market is pricing in an increase in the federal funds rate in 2014, that implies a stronger economic performance than is forecast either by most FOMC participants or by private forecasters.\n\nWe have made significant strides in communication in recent years. The unemployment and inflation thresholds I discussed earlier, as well as the communication around asset purchases, are all designed to improve public understanding of the Committee's intentions. But communications are bound to be imperfect, and changes in the outlook can still lead to adjustments in asset prices. Thus, some volatility is unavoidable, and indeed is a necessary part of the process by which markets and the economy adjust to incoming information.\n\nThe Path Ahead for Monetary Policy\n\nLast week, the Chairman provided greater clarity about the path of asset purchases. Specifically, the Chairman noted that, if incoming data are broadly consistent with the Committee's sense of the economic outlook, the Committee currently anticipates that it would be appropriate to moderate the monthly pace of purchases later this year. If the subsequent data remain broadly aligned with the Committee's current expectations for the economy, the Committee could continue to reduce the pace of purchases in measured steps through the first half of next year, ending purchases around mid-year. At that time, the unemployment rate would likely be in the vicinity of 7 percent, with growth consistent with further improvements and inflation heading back toward our objective. If unemployment reaches the 7 percent range, that would constitute a substantial improvement from the 8.1 percent unemployment rate that prevailed when the Committee announced the current program of asset purchases.\n\nI want to emphasize the importance of data over date. If the Committee's economic outlook is broadly realized, there will likely be a moderation in the pace of purchases later this year. If the performance of the economy is weaker, the Committee may delay before moderating purchases or even increase them. If the economy strengthens faster than the Committee anticipates, the pace of purchases may be moderated somewhat more quickly. The path of purchases is in no way predetermined; we will monitor economic data and adjust our purchases as appropriate.\n\nIn my view, there has been real progress in the labor market. The Committee first adopted the \"substantial improvement\" test at the September 2012 meeting, so it is appropriate to measure the economy's progress against economic conditions at that time. When the Committee met in September, the unemployment rate stood at 8.1 percent. Today, just nine months later, the unemployment rate is 7.6 percent--a larger decline than most FOMC participants expected in September. At the time of the September meeting, nonfarm payrolls were reported to have increased at a monthly rate of 97,000 over the prior six months.9 Today the trailing six‑month average payroll growth is 194,000. Other labor market indicators also show moderate progress, including aggregate hours worked, initial unemployment insurance claims, the duration of unemployment, and the share of long‑term unemployment.\n\nConclusion\nThere are many signs that the economy is healing. If the Committee's economic outlook is broadly realized, and we do see the first moderation in the pace of purchases later this year, that would be good news. The first reduction in purchases, when it comes, will be an acknowledgement of the economy's progress and a sign of the Committee's confidence in the path to full recovery.\n\nIn all cases, the path of policy will remain fully data-dependent. If economic growth, unemployment, or inflation do not meet the Committee's expectations, or if financial conditions evolve in a way that is inconsistent with continued recovery, the Committee will respond.\n\nThanks, and I am happy to take your questions.\n\n \n\n1. Views expressed in this speech are mine and may not represent those of the FOMC or any of its members. I would like to thank members of the Board staff, including James Clouse, Dan Covitz, Jon Faust, John Maggs, Raven Molloy, Karen Pence, Jeremy Rudd, and Brad Strum. Return to text\n\n2. See Greg Howard, Robert Martin, and Beth Anne Wilson (2011), \"Are Recoveries from Banking and Financial Crises Really So Different?\" International Finance Discussion Papers 1037 (Washington: Board of Governors of the Federal Reserve System, March); and Janet L. Yellen (2013), \"A Painfully Slow Recovery for America's Workers: Causes, Implications, and the Federal Reserve's Response,\" speech delivered at \"A Trans-Atlantic Agenda for Shared Prosperity,\" a conference sponsored by the AFL-CIO, Friedrich Ebert Stiftung, and the IMK Macroeconomic Policy Institute, held in Washington, February 11. Return to text\n\n3. Congressional Budget Office (2013), The Budget and Economic Outlook: Fiscal Years 2013 to 2023 (Washington: CBO, February). Return to text\n\n4. The Committee's long-run objective for PCE inflation remains 2 percent. See Board of Governors of the Federal Reserve System (2013), \"FOMC Longer-Run Goals and Monetary Policy Strategy (PDF),\" statement, January 29. Return to text\n\n5. See Jonathan McCarthy (2013), \"The Monetary Transmission Mechanism,\" speech delivered at \"The Federal Reserve in the 21st Century: A Symposium for College Professors,\" held in New York, March 4-5. Return to text\n\n6. See Canlin Li and Min Wei (2012), \"Term Structure Modelling with Supply Factors and the Federal Reserve's Large Scale Asset Purchase Programs,\" Finance and Economics Discussion Series 2012-37 (Washington: Board of Governors of the Federal Reserve System, May); Arvind Krishnamurthy and Annette Vissing-Jørgensen (2011), \"The Effects of Quantitative Easing on Interest Rates: Channels and Implications for Policy (PDF),\" Brookings Papers on Economic Activity, Fall, pp. 215-65; Stefania D'Amico, William English, David López-Salido, and Edward Nelson (2012), \"The Federal Reserve's Large-Scale Asset Purchase Programmes: Rationale and Effects,\" Economic Journal, vol. 122 (November), pp. F415-F446; James D. Hamilton and Jing Cynthia Wu (2012), \"The Effectiveness of Alternative Policy Tools in a Zero Lower Bound Environment,\" Journal of Money, Credit and Banking, vol. 44 (February supplement), pp. 3-46; Diana Hancock and Wayne Passmore (2012), \"The Federal Reserve's Portfolio and its Effects on Mortgage Markets,\" Finance and Economic Discussion Series 2012-22 (Washington: Board of Governors of the Federal Reserve System, June); and Carlo Rosa (2012), \"How ‘Unconventional' Are Large-Scale Asset Purchases? The Impact of Monetary Policy on Asset Prices,\" Federal Reserve Bank of New York Staff Reports 560 (New York: Federal Reserve Bank of New York, May). Return to text\n\n7. See Ben S. Bernanke (2013), \"Long-Term Interest Rates,\" speech delivered at \"The Past and Future of Monetary Policy,\" a conference sponsored by the Federal Reserve Bank of San Francisco, held in San Francisco, March 1. Return to text\n\n8. See Jeremy C. Stein (2013), \"Overheating in Credit Markets: Origins, Measurement, and Policy Responses,\" speech delivered at \"Restoring Household Financial Stability after the Great Recession: Why Household Balance Sheets Matter,\" a research symposium sponsored by the Federal Reserve Bank of St. Louis, held in St. Louis, Mo., February 5-7. Return to text\n\n9. The level of payroll employment would subsequently be revised up, but the Committee didn't know at the September 2012 meeting that the revision would occur. Return to text\n\n "
    },
    {
        "title": "Comments on Monetary Policy",
        "date": "June 28, 2013",
        "speaker": "Governor Jeremy C. Stein",
        "url": "https://www.federalreserve.gov/newsevents/speech/stein20130628a.htm",
        "content": "June 28, 2013\n\nGovernor Jeremy C. Stein\n\nAt the C. Peter McColough Series on International Economics, Council on Foreign Relations, New York, New York\n\nThank you very much. It's a pleasure for me to be here at the Council on Foreign Relations, and I look forward to our conversation. To get things going, I thought I would start with some brief remarks on the current state of play in monetary policy. As you know, at the Federal Open Market Committee (FOMC) meeting last week, we opted to keep our asset purchase program running at the rate of $85 billion per month. But there has been much discussion about recent changes in our communication, both in the formal FOMC statement, as well as in Chairman Bernanke's post-meeting press conference. I'd like to offer my take on these changes, as well as my thoughts on where we might go from here. But before doing so, let me note that I am speaking for myself, and that my views are not necessarily shared by my colleagues on the FOMC.\n\nIt's useful to start by discussing the initial design and conception of this round of asset purchases. Two features of the program are noteworthy. The first is its flow-based, state-contingent nature--the notion that we intend to continue with purchases until the outlook for the labor market has improved substantially in a context of price stability. The second is the fact that--in contrast to our forward guidance for the federal funds rate‑‑we chose at the outset of the program not to articulate what \"substantial improvement\" means with a specific numerical threshold. So while the program is meant to be data-dependent, we did not spell out the nature of this data-dependence in a formulaic way.\n\nTo be clear, I think that this choice made a lot of sense, particularly at the outset of the program. Back in September it would have been hard to predict how long it might take to reach any fixed labor market milestone, and hence how large a balance sheet we would have accumulated along the way to that milestone. Given the uncertainty regarding the costs of an expanding balance sheet, it seemed prudent to preserve some flexibility. Of course, the flip side of this flexibility is that it entailed providing less- concrete information to market participants about our reaction function for asset purchases.\n\nWhere do we stand now, nine months into the program? With respect to the economic fundamentals, both the current state of the labor market, as well as the outlook, have improved since September 2012. Back then, the unemployment rate was 8.1percent and nonfarm payrolls were reported to have increased at a monthly rate of 97,000 over the prior six months; today, those figures are 7.6 percent and 194,000, respectively. Back then, FOMC participants were forecasting unemployment rates around 7-3/4 percent and 7 percent for year-end 2013 and 2014, respectively, in our Summary of Economic Projections; as of the June 2013 round, these forecasts have been revised down roughly 1/2 percentage point each. While it is difficult to determine precisely, I believe that our asset purchases since September have supported this improvement. For example, some of the brightest spots in recent months have been sectors that traditionally respond to monetary accommodation, such as housing and autos. Although asset purchases also bring with them various costs and risks--and I have been particularly concerned about risks relating to financial stability--thus far I would judge that they have passed the cost-benefit test.\n\nHowever, this very progress has brought communications challenges to the fore, since the further down the road we get, the more information the market demands about the conditions that would lead us to reduce and eventually end our purchases. This imperative for clarity provides the backdrop against which our current messaging should be interpreted. In particular, I view Chairman Bernanke's remarks at his press conference--in which he suggested that if the economy progresses generally as we anticipate then the asset purchase program might be expected to wrap up when unemployment falls to the 7 percent range--as an effort to put more specificity around the heretofore less well-defined notion of \"substantial progress.\"\n\nIt is important to stress that this added clarity is not a statement of unconditional optimism, nor does it represent a departure from the basic data-dependent philosophy of the asset purchase program. Rather, it involves a subtler change in how data-dependence is implemented--a greater willingness to spell out what the Committee is looking for, as opposed to a \"we'll know it when we see it\" approach. As time passes and we make progress toward our objectives, the balance of the tradeoff between flexibility and specificity in articulating these objectives shifts. It would have been difficult for the Committee to put forward a 7 percent unemployment goal when the current program started and unemployment was 8.1 percent; this would have involved a lot of uncertainty about the magnitude of asset purchases required to reach this goal. However, as we get closer to our goals, the balance sheet uncertainty becomes more manageable--at the same time that the market's demand for specificity goes up.\n\nIn addition to guidance about the ultimate completion of the program, market participants are also eager to know about the conditions that will govern interim adjustments to the pace of purchases. Here too, it makes sense for decisions to be data-dependent. However, a key point is that as we approach an FOMC meeting where an adjustment decision looms, it is appropriate to give relatively heavy weight to the accumulated stock of progress toward our labor market objective and to not be excessively sensitive to the sort of near-term momentum captured by, for example, the last payroll number that comes in just before the meeting.\n\nIn part, this principle just reflects sound statistical inference--one doesn't want to put too much weight on one or two noisy observations. But there is more to it than that. Not only do FOMC actions shape market expectations, but the converse is true as well: Market expectations influence FOMC actions. It is difficult for the Committee to take an action at any meeting that is wholly unanticipated because we don't want to create undue market volatility. However, when there is a two-way feedback between financial conditions and FOMC actions, an initial perception that noisy recent data play a central role in the policy process can become somewhat self-fulfilling and can itself be the cause of extraneous volatility in asset prices.\n\nThus both in an effort to make reliable judgments about the state of the economy, as well as to reduce the possibility of an undesirable feedback loop, the best approach is for the Committee to be clear that in making a decision in, say, September, it will give primary weight to the large stock of news that has accumulated since the inception of the program and will not be unduly influenced by whatever data releases arrive in the few weeks before the meeting--as salient as these releases may appear to be to market participants. I should emphasize that this would not mean abandoning the premise that the program as a whole should be both data-dependent and forward looking. Even if a data release from early September does not exert a strong influence on the decision to make an adjustment at the September meeting, that release will remain relevant for future decisions. If the news is bad, and it is confirmed by further bad news in October and November, this would suggest that the 7 percent unemployment goal is likely to be further away, and the remainder of the program would be extended accordingly.\n\nIn sum, I believe that effective communication for us at this stage involves the following key principles: (1) reaffirming the data-dependence of the asset purchase program, (2) giving more clarity on the type of data that will determine the endpoint of the program, as the Chairman did in his discussion of the unemployment goal, and (3) basing interim adjustments to the pace of purchases at any meeting primarily on the accumulated progress toward our goals and not overemphasizing the most recent momentum in the data.\n\nI have been focusing thus far on our efforts to enhance communications about asset purchases. With respect to our guidance on the path of the federal funds rate, we have had explicit links to economic outcomes since last December, and we reaffirmed this guidance at our most recent meeting. Specifically, we continue to have a 6.5 percent unemployment threshold for beginning to consider a first increase in the federal funds rate. As we have emphasized, the threshold nature of this forward guidance embodies further flexibility to react to incoming data. If, for example, inflation readings continue to be on the soft side, we will have greater scope for keeping the funds rate at its effective lower bound even beyond the point when unemployment drops below 6.5percent.\n\nOf course, there are limits to how much even good communication can do to limit market volatility, especially at times like these. At best, we can help market participants to understand how we will make decisions about the policy fundamentals that the FOMC controls--the path of future short-term policy rates and the total stock of long-term securities that we ultimately plan to accumulate via our asset purchases. Yet as research has repeatedly demonstrated, these sorts of fundamentals only explain a small part of the variation in the prices of assets such as equities, long-term Treasury securities, and corporate bonds. The bulk of the variation comes from what finance academics call \"changes in discount rates,\" which is a fancy way of saying the non-fundamental stuff that we don't understand very well--and which can include changes in either investor sentiment or risk aversion, price movements due to forced selling by either levered investors or convexity hedgers, and a variety of other effects that fall under the broad heading of internal market dynamics.\n\nThis observation reminds us that it often doesn't make sense to try to explain a large movement in asset prices by looking for a correspondingly large change in expectations about economic fundamentals. So while we have seen very significant increases in long-term Treasury yields since the FOMC meeting, I think it is a mistake to infer from these movements that there must have been an equivalently big change in monetary policy fundamentals. Nothing we have said suggests a change in our reaction function for the path of the short-term policy rate, and my sense is that our sharpened guidance on the duration of the asset purchase program also leaves us close to where market expectations--as expressed, for example, in various surveys that we monitor--were beforehand.\n\nI don't in any way mean to say that the large market movements that we have seen in the past couple of weeks are inconsequential or can be dismissed as mere noise. To the contrary, they potentially have much to teach us about the dynamics of financial markets and how these dynamics are influenced by changes in our communications strategy. My only point is that consumers and businesses who look to asset prices for clues about the future stance of monetary policy should take care not to over-interpret these movements. We have attempted in recent weeks to provide more clarity about the nature of our policy reaction function, but I view the fundamentals of our underlying policy stance as broadly unchanged.\n\nThank you. I look forward to your questions ."
    },
    {
        "title": "International Financial Regulatory Reform",
        "date": "July 02, 2013",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20130702a.htm",
        "content": "July 02, 2013\n\nGovernor Jerome H. Powell\n\nAt the Deutsche Bundesbank Reception, New York, New York\n\nThank you so much for inviting me to speak today.1 I join others in thanking Mr. Stephan for his service, and in welcoming Ms. Stirbock to her new role as Chief Representative of the Deutsche Bundesbank in the United States. I look forward to working with both of you, and with your colleagues, in the coming years. The Federal Reserve places great importance on our relations with the Bundesbank. Few such relationships have been as important, over the decades, in promoting financial stability and prosperity around the world.\n\nGovernments, central bankers, and financial regulators labor today in the long shadow cast by the global financial crisis, and that likely will remain the case for many years. Against that background, I will touch briefly on fiscal and monetary policy here in the United States, before turning to financial regulatory issues.\n\nIt has long been clear that, starting in this decade, the United States would begin to face longer-term fiscal challenges due to the aging of our population and our high and fast-rising per capita health-care costs. Over the next 20 years, it is projected that the ratio of our retired elderly to our working-age population will increase sharply from about 23 percent to about 36 percent. And, as you surely know, our per capita health care costs are far higher than those of other advanced economies, and have risen over time at a faster pace than per capita income. The combination of these two factors will put the U.S. federal budget on an unsustainable path if appropriate measures are not taken.\n\nAt the end of 2007, just prior to the onset of the last recession, the United States had federal government debt equal to about 36 percent of the size of our annual gross domestic product (GDP)--a moderate level. Since 2007, and largely as a consequence of the recession and policy actions to help alleviate its effects, the U.S. federal government's debt-to-GDP ratio has increased to around 75 percent. It is projected to remain near this level for the remainder of the decade under current federal budget policies. This high level of federal government debt leaves U.S. policymakers with less \"fiscal space\" than may be required to deal with expected increases in retirement and health-care costs, or with unanticipated economic shocks.\n\nOver the last few years, the fiscal authorities have cut federal spending and raised taxes, and our Congressional Budget Office estimates that these fiscal headwinds will reduce real GDP growth by about 1.5 percentage points this year from what it otherwise would have been. Nevertheless, as a nation, we have not yet addressed in a fundamental way our longer-term budget challenges, particularly those associated with federal health-care programs. So I have no doubt that fiscal policy issues will retain an important and highly contentious place on the political agenda for many years here in the United States, as in Europe.\n\nI will turn for a moment to monetary policy. The Congress has tasked the Federal Reserve with conducting monetary policy to foster stable prices and full employment. Today, inflation is well below our 2 percent longer-term objective, as measured by prices for personal consumption expenditures. And although the unemployment rate has declined notably since its peak in 2010, it remains well above our estimate of a longer-run, more normal level. I expect that inflation will return gradually to our 2 percent objective, and that we will continue to make progress in reducing unemployment. In the meantime, the case for continued support for our economy from monetary policy remains strong.\n\nWith these fiscal headwinds and the lingering effects of the recession, growth has remained in the range of 2 percent since 2009. But today, our private sector shows real signs of underlying improvement. Auto sales are strong, as is activity in our energy sector. Our housing market, which was at the heart of the crisis, is now recovering strongly. House prices are rising, and that is supporting improvement in household net worth and consumer attitudes. Homebuilders are responding to this price signal with rising housing starts, which will support job growth. Together, these and other factors give grounds to hope for the kind of self-reinforcing cycle of economic growth that we have been waiting to see.\n\nAnd as our economy has gradually improved, it has become possible, and appropriate, for the Federal Reserve to provide clearer guidance on the path of monetary policy. In all likelihood, this path will involve continued support from accommodative monetary policy for quite some time.\n\nMeanwhile, financial regulators around the world are engaged in a historic and sweeping renovation of the global financial architecture. The scope of this global regulatory project is enormous, and I will touch on only a few of its elements. One of the most important goals is to ensure that banks have adequate capital to withstand severe financial stress. I am pleased that, just this morning, the Federal Reserve Board finalized the Basel III capital requirements for bank holding companies and Federal Reserve state-chartered member banks. The other U.S. bank regulatory agencies are on track to adopt the same set of rules for the institutions they regulate over the next week or so. The Basel III capital reforms will substantially improve the resiliency of global banks and will serve as the cornerstone of the global regulatory effort to safeguard the stability of the world's financial system.\n\nBoth in the United States and in Europe, some parts of the reform agenda will take longer to complete. For example, I note the ongoing progress toward achieving one of the most ambitious and important regulatory goals: the creation of a European banking union. It is clear that this challenging project will be the work of many years; indeed, it is not for an American to educate Europeans on the challenges of international cooperation. But the importance of this project for Europe's future is equally clear. The recent agreement on harmonizing national resolution regimes is an important achievement, and a milestone on the road to longer-term goals such as a single, centralized resolution authority.\n\nAnother reform that will take time to complete is the establishment of a global framework for resolving large, systemically important banks. Work to enable resolution of such institutions with diverse cross-border operations is especially important, and especially daunting. The challenge is not so much to allow such institutions to fail, but rather to contain their failure so that it does not inflict enormous collateral damage on innocent bystanders and the broader economy. As many of you know, in the United States, the Federal Deposit Insurance Corporation is developing a preferred approach to resolution for such rare cases: the single-point-of-entry (SPOE) approach. This approach may be gaining some traction internationally. In my view, SPOE can be a classic \"simplifier,\" making theoretically possible something that seemed impossibly complex.\n\nUnder the SPOE approach, the home country resolution authority for a failing banking firm would effect a creditor-funded parent company recapitalization of the failed firm. To do so, the resolution authority would first use available parent company assets to recapitalize the firm's critical operating subsidiaries, and then would convert liabilities of the parent company into equity of a surviving entity. This approach would have the effect of concentrating the firm-wide losses on the parent company's private sector equity holders and creditors. The SPOE approach places a high priority on what your own President Weidmann recently described as \"the principle of liability,\" meaning that those who benefit should also bear the costs.\n\nPerhaps the greatest challenge for the resolution of a systemic global bank is the possibility that public or private actors in different countries might take local actions that would cause the overall resolution to spin out of control. Creditors and counterparties of solvent operating subsidiaries might rush for the exit if they are unsure of their status. As a subsidiary comes under increasing stress, authorities might preemptively ring-fence local assets. The process of resolution will need to be fully worked out and understood beforehand by market participants, regulatory authorities, and the general public. It will be absolutely essential to build trust among all parties, and especially between regulatory authorities.\n\nMuch remains to be done in eliminating \"too-big-to-fail.\" The Federal Reserve is considering a requirement that systemic institutions maintain sufficient long-term debt at the parent company level to absorb losses and recapitalize operating subsidiaries in the event of failure. We expect to propose such a requirement later this year. I share the view expressed recently by several of my Board colleagues that the work of large bank resolution is not complete, and that further measures may be necessary. No one should doubt that the Federal Reserve is committed to completing this project.\n\nReaching agreement on a cross-border resolution process will be challenging. Our financial services industries and our economies differ in many ways. But we have a shared interest in financial stability, in reducing moral hazard, and in protecting taxpayers.\n\nOn that note, I will briefly discuss the Fed's proposal for oversight of foreign banks operating in the United States, which carries out a mandate from the Congress under the Dodd-Frank Wall Street Reform and Consumer Protection Act.2 Our proposal represents a targeted set of adjustments aimed at reducing the risks posed by the U.S. operations of large foreign banks to U.S. financial stability that were revealed during, and in the aftermath of, the recent financial crisis. The proposal is not intended to create a disadvantage for foreign banks in the U.S. market. Rather, the proposal is part of a larger set of regulatory reforms that substantially raises standards for all banking organizations operating in the United States and aims to achieve the goals we share with Germany: vigorous and fair competition and a stable financial system. Indeed, in some sense it follows the lead of the European Union and its member states in ensuring that all large subsidiaries of globally active banks meet Basel capital rules. We believe that our foreign bank proposal, which would increase the strength and resiliency of the U.S. operations of these firms, would meaningfully reduce the likelihood of disruptive ring-fencing at the moment of crisis that could undermine an SPOE resolution of a large foreign bank. We are fully committed to the international efforts to address cross-border resolution issues and to maintaining strong cooperation between home and host supervisors during normal and crisis periods.\n\nI will close by observing that the international effort to strengthen financial regulation cannot succeed unless each nation understands the goals and challenges faced by its partners. The Federal Reserve and the Bundesbank have a long history. I believe there is a trust between us that is the basis for collaboration. I look forward to working with you to make the financial system safer and stronger.\n\nThank you.\n\n \n\n1. Views expressed in this speech are mine and may not represent those of the FOMC or any of its members. Return to text\n\n2. Board of Governors of the Federal Reserve System (2012), “The Federal Reserve Board releases proposed rules to strengthen the oversight of U.S. operations of foreign banks,” press release, December 14. Return to text\n\n \n\n "
    },
    {
        "title": "A Century of U.S. Central Banking: Goals, Frameworks, Accountability",
        "date": "July 10, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20130710a.htm",
        "content": "July 10, 2013\n\nChairman Ben S. Bernanke\n\nAt the \"The First 100 Years of the Federal Reserve: The Policy Record, Lessons Learned, and Prospects for the Future,\" a conference sponsored by the National Bureau of Economic Research, Cambridge, Massachusetts\n\nI'd like to thank the National Bureau of Economic Research for organizing this conference in recognition of the Federal Reserve's centennial, and I'm glad to have the opportunity to participate. In keeping with the spirit of the conference, my remarks today will take a historical perspective. I will leave discussion of current policy to today's question-and-answer session and, of course, to my congressional testimony next week.\n\nToday, I'll discuss the evolution over the past 100 years of three key aspects of Federal Reserve policymaking: the goals of policy, the policy framework, and accountability and communication. The changes over time in these three areas provide a useful perspective, I believe, on how the role and functioning of the Federal Reserve have changed since its founding in 1913, as well as some lessons for the present and for the future. I will pay particular attention to several key episodes of the Fed's history, all of which have been referred to in various contexts with the adjective \"Great\" attached to them: the Great Experiment of the Federal Reserve's founding, the Great Depression, the Great Inflation and subsequent disinflation, the Great Moderation, and the recent Great Recession.\n\nThe Great Experiment\nIn the words of one of the authors of the Federal Reserve Act, Robert Latham Owen, the Federal Reserve was established to \"provide a means by which periodic panics which shake the American Republic and do it enormous injury shall be stopped.\"1 In short, the original goal of the Great Experiment that was the founding of the Fed was the preservation of financial stability.2 At the time, the standard view of panics was that they were triggered when the needs of business and agriculture for liquid funds outstripped the available supply--as when seasonal plantings or shipments of crops had to be financed, for example--and that panics were further exacerbated by the incentives of banks and private individuals to hoard liquidity during such times.3 The new institution was intended to relieve such strains by providing an \"elastic\" currency--that is, by providing liquidity as needed to individual member banks through the discount window; commercial banks, in turn, would then be able to accommodate their customers. Interestingly, although congressional advocates hoped the creation of the Fed would help prevent future panics, they did not fully embrace the idea that the Fed should help end ongoing panics by serving as lender of last resort, as had been recommended by the British economist and writer Walter Bagehot.4 Legislators imposed limits on the Federal Reserve's ability to lend in response to panics, for example, by denying nonmember banks access to the discount window and by restricting the types of collateral that the Fed could accept.5 \n\nThe framework that the Federal Reserve employed in its early years to promote financial stability reflected in large measure the influence of the so-called real bills doctrine, as well as the fact that the United States was on the gold standard.6 In the framework of the real bills doctrine, the Federal Reserve saw its function as meeting the needs of business for liquidity--consistent with the idea of providing an elastic currency--with the ultimate goal of supporting financial and economic stability.7 When business activity was increasing, the Federal Reserve helped accommodate the need for credit by supplying liquidity to banks; when business was contracting and less credit was needed, the Fed reduced the liquidity in the system.\n\nAs I mentioned, the Federal Reserve pursued this approach to policy in the context of the gold standard. Federal Reserve notes were redeemable in gold on demand, and the Fed was required to maintain a gold reserve equal to 40 percent of outstanding notes. However, contrary to the principles of an idealized gold standard, the Federal Reserve often took actions to prevent inflows and outflows of gold from being fully translated into changes in the domestic money supply.8 This practice, together with the size of the U.S. economy, gave the Federal Reserve considerable autonomy in monetary policy and, in particular, allowed the Fed to conduct policy according to the real bills doctrine without much hindrance.\n\nThe policy framework of the Fed's early years has been much criticized in retrospect. Although the gold standard did not appear to have greatly constrained U.S. monetary policy in the years after the Fed's founding, subsequent research has highlighted the extent to which the international gold standard served to destabilize the global economy in the late 1920s and early 1930s.9 Likewise, economic historians have pointed out that, under the real bills doctrine, the Fed increased the money supply precisely at those times at which business activity and upward pressures on prices were strongest; that is, monetary policy was procyclical. Thus, the Fed's actions tended to increase rather than decrease the volatility in economic activity and prices.10 \n\nDuring this early period, the new central bank did make an important addition to its menu of policy tools. Initially, the Fed's main tools were the quantity of its lending through the discount window and the interest rate at which it lent, the discount rate. Early on, however, to generate earnings to finance its operations, the Federal Reserve began purchasing government securities in the open market--what came to be known as open market operations. In the early 1920s, Fed officials discovered that these operations affected the supply and cost of bank reserves and, consequently, the terms on which banks extended credit to their customers. Subsequently, of course, open market operations became a principal monetary policy tool, one that allowed the Fed to interact with the broader financial markets, not only with banks.11 \n\nI've discussed the original mandate and early policy framework of the Fed. What about its accountability to the public? As this audience knows, when the Federal Reserve was established, the question of whether it should be a private or a public institution was highly contentious. The compromise solution created a hybrid Federal Reserve System. The System was headed by a governmentally appointed Board, which initially included the Secretary of the Treasury and the Comptroller of the Currency. But the 12 regional Reserve Banks were placed under a mixture of public and private oversight, including board members drawn from the private sector, and they were given considerable scope to make policy decisions that applied to their own Districts. For example, Reserve Banks were permitted to set their own discount rates, subject to a minimum set by the Board.\n\nWhile the founders of the Federal Reserve hoped that this new institution would provide financial and hence economic stability, the policy framework and the institutional structure would prove inadequate to the challenges the Fed would soon face.\n\nThe Great Depression\nThe Great Depression was the Federal Reserve's most difficult test. Tragically, the Fed failed to meet its mandate to maintain financial stability. In particular, although the Fed provided substantial liquidity to the financial system following the 1929 stock market crash, its response to the subsequent banking panics was limited at best; the widespread bank failures and the collapse in money and credit that ensued were major sources of the economic downturn.12 Bagehot's dictum to lend freely at a penalty rate in the face of panic appeared to have few adherents at the Federal Reserve of that era.13 \n\nEconomists have also identified a number of instances from the late 1920s to the early 1930s when Federal Reserve officials, in the face of the sharp economic contraction and financial upheaval, either tightened monetary policy or chose inaction. Some historians trace these policy mistakes to the early death of Benjamin Strong, governor of the Federal Reserve Bank of New York, in 1928, which left the decentralized system without an effective leader.14 Whether valid or not, this hypothesis raises the interesting question of what intellectual framework an effective leader would have drawn on at the time to develop and justify a more activist monetary policy. The degree to which the gold standard actually constrained U.S. monetary policy during the early 1930s is debated; but the gold standard philosophy clearly did not encourage the sort of highly expansionary policies that were needed.15 The same can be said for the real bills doctrine, which apparently led policymakers to conclude, on the basis of low nominal interest rates and low borrowings from the Fed, that monetary policy was appropriately supportive and that further actions would be fruitless.16 Historians have also noted the prevalence at the time of yet another counterproductive doctrine: the so-called liquidationist view, that depressions perform a necessary cleansing function.17 It may be that the Federal Reserve suffered less from lack of leadership in the 1930s than from the lack of an intellectual framework for understanding what was happening and what needed to be done.\n\nThe Fed's inadequate policy frameworks ultimately collapsed under the weight of economic failures, new ideas, and political developments. The international gold standard was abandoned during the 1930s. The real bills doctrine likewise lost prestige after the disaster of the 1930s; for example, the Banking Act of 1935 instructed the Federal Reserve to use open market operations with consideration of \"the general credit situation of the country,\" not just to focus narrowly on short-term liquidity needs.18 The Congress also expanded the Fed's ability to provide credit through the discount window, allowing loans to a broader array of counterparties, secured by a broader variety of collateral.19 \n\nThe experience of the Great Depression had major ramifications for all three aspects of the Federal Reserve I am discussing here: its goals, its policy framework, and its accountability to the public. With respect to goals, the high unemployment of the Depression--and the fear that high unemployment would return after World War II--elevated the maintenance of full employment as a goal of macroeconomic policy. The Employment Act of 1946 made the promotion of employment a general objective for the federal government. Although the Fed did not have a formal employment goal until the Federal Reserve Reform Act of 1977 codified \"maximum employment,\" along with \"stable prices,\" as part of the Fed's so-called dual mandate, earlier legislation nudged the central bank in that direction.20 For example, legislators described the intent of the Banking Act of 1935 as follows: \"To increase the ability of the banking system to promote stability of employment and business, insofar as this is possible within the scope of monetary action and credit administration.\"21 \n\nThe policy framework to support this new approach reflected the development of macroeconomic theories--including the work of Knut Wicksell, Irving Fisher, Ralph Hawtrey, Dennis Robertson, and John Maynard Keynes--that laid the foundations for understanding how monetary policy could affect real activity and employment and help reduce cyclical fluctuations. At the same time, the Federal Reserve became less focused on its original mandate of preserving financial stability, perhaps in part because it felt superseded by the creation during the 1930s of the Federal Deposit Insurance Corporation and the Securities and Exchange Commission, along with other reforms intended to make the financial system more stable.\n\nIn the area of governance and accountability to the public, policymakers also recognized the need for reforms to improve the Federal Reserve's structure and decisionmaking. The Banking Act of 1935 simultaneously bolstered the legal independence of the Federal Reserve and provided for stronger central control by the Federal Reserve Board. In particular, the act created the modern configuration of the Federal Open Market Committee (FOMC), giving the Board the majority of votes on the Committee, while removing the Secretary of the Treasury and the Comptroller of the Currency from the Board. In practice, however, the Treasury continued to have considerable sway over monetary policy after 1933, with one economic historian describing the Fed as \"in the back seat.\"22 During World War II, the Federal Reserve used its tools to support the war financing efforts. However, even after the war, Federal Reserve policy remained subject to considerable Treasury influence. It was not until the 1951 Accord with the Treasury that the Federal Reserve began to recover genuine independence in setting monetary policy.\n\nThe Great Inflation and Disinflation\nOnce the Federal Reserve regained its policy independence, its goals centered on the price stability and employment objectives laid out in the Employment Act of 1946. In the early postwar decades, the Fed used open market operations and the discount rate to influence short-term market interest rates, and the federal funds rate gradually emerged as the preferred operating target. Low and stable inflation was achieved for most of the 1950s and the early 1960s. However, beginning in the mid-1960s, inflation began a long climb upward, partly because policymakers proved to be too optimistic about the economy's ability to sustain rapid growth without inflation.23 \n\nTwo mechanisms might have mitigated the damage from that mistaken optimism. First, a stronger policy response to inflation--more like that observed in the 1950s--certainly would have helped.24 Second, Fed policymakers could have reacted to continued high readings on inflation by adopting a more realistic assessment of the economy's productive potential.25 Instead, policymakers chose to emphasize so-called cost-push and structural factors as sources of inflation and saw wage- and price-setting as having become insensitive to economic slack.26 This perspective, which contrasted sharply with Milton Friedman's famous dictum that \"inflation is always and everywhere a monetary phenomenon,\" led to Fed support for measures such as wage and price controls rather than monetary solutions to address inflation.27 A further obstacle was the view among many economists that the gains from low inflation did not justify the costs of achieving it.28 \n\nThe consequence of the monetary framework of the 1970s was two bouts of double-digit inflation. Moreover, by the end of the decade, lack of commitment to controlling inflation had clearly resulted in inflation expectations becoming \"unanchored,\" with high estimates of trend inflation embedded in longer-term interest rates.\n\nAs you know, under the leadership of Chairman Paul Volcker, the Federal Reserve in 1979 fundamentally changed its approach to the issue of ensuring price stability. This change involved an important rethinking on the part of policymakers. By the end of the 1970s, Federal Reserve officials increasingly accepted the view that inflation is a monetary phenomenon, at least in the medium and longer term; they became more alert to the risks of excessive optimism about the economy's potential output; and they placed renewed emphasis on the distinction between real‑‑that is, inflation-adjusted‑‑and nominal interest rates.29 The change in policy framework was initially tied to a change in operating procedures that put greater focus on growth in bank reserves, but the critical change‑‑the willingness to respond more vigorously to inflation--endured even after the Federal Reserve resumed its traditional use of the federal funds rate as the policy instrument.30 The new regime also reflected an improved understanding of the importance of providing a firm anchor, secured by the credibility of the central bank, for the private sector's inflation expectations.31 Finally, it entailed a changed view about the dual mandate, in which policymakers regarded achievement of price stability as helping to provide the conditions necessary for sustained maximum employment.32 \n\nThe Great Moderation\nVolcker's successful battle against inflation set the stage for the so-called Great Moderation of 1984 to 2007, during which the Fed enjoyed considerable success in achieving both objectives of its dual mandate. Financial stability remained a goal, of course. The Federal Reserve monitored threats to financial stability and responded when the financial system was upset by events such as the 1987 stock market crash and the terrorist attacks of 2001. More routinely, it shared supervisory duties with other banking agencies. Nevertheless, for the most part, financial stability did not figure prominently in monetary policy discussions during these years. In retrospect, it is clear that macroeconomists--both inside and outside central banks--relied too heavily during that period on variants of the so-called Modigliani-Miller theorem, an implication of which is that the details of the structure of the financial system can be ignored when analyzing the behavior of the broader economy.\n\nAn important development of the Great Moderation was the increasing emphasis that central banks around the world put on communication and transparency, as economists and policymakers reached consensus on the value of communication in attaining monetary policy objectives.33 Federal Reserve officials, like those at other central banks, had traditionally been highly guarded in their public pronouncements. They believed, for example, that the ability to take markets by surprise was important for influencing financial conditions.34 Thus, although Fed policymakers of the 1980s and early 1990s had become somewhat more explicit about policy objectives and strategy, the same degree of transparency was not forthcoming on monetary policy decisions and operations.35 The release of a postmeeting statement by the FOMC, a practice that began in 1994, was, therefore, an important watershed. Over time, the statement was expanded to include more detailed information about the reason for the policy decision and an indication of the balance of risks.36 \n\nIn addition to improving the effectiveness of monetary policy, these developments in communications also enhanced the public accountability of the Federal Reserve. Accountability is, of course, essential for policy independence in a democracy. During this period, economists found considerable evidence that central banks that are afforded policy independence in the pursuit of their mandated objectives deliver better economic outcomes.37 \n\nOne cannot look back at the Great Moderation today without asking whether the sustained economic stability of the period somehow promoted the excessive risk-taking that followed. The idea that this long period of calm lulled investors, financial firms, and financial regulators into paying insufficient attention to building risks must have some truth in it. I don't think we should conclude, though, that we therefore should not strive to achieve economic stability. Rather, the right conclusion is that, even in (or perhaps, especially in) stable and prosperous times, monetary policymakers and financial regulators should regard safeguarding financial stability to be of equal importance as--indeed, a necessary prerequisite for--maintaining macroeconomic stability.\n\nMacroeconomists and historians will continue to debate the sources of the remarkable economic performance during the Great Moderation.38 My own view is that the improvements in the monetary policy framework and in monetary policy communication, including, of course, the better management of inflation and the anchoring of inflation expectations, were important reasons for that strong performance. However, we have learned in recent years that while well-managed monetary policy may be necessary for economic stability, it is not sufficient.\n\nThe Financial Crisis, the Great Recession, and Today\nIt has been about six years since the first signs of the financial crisis appeared in the United States, and we are still working to achieve a full recovery from its effects. What lessons should we take for the future from this experience, particularly in the context of a century of Federal Reserve history?\n\nThe financial crisis and the ensuing Great Recession reminded us of a lesson that we learned both in the 19th century and during the Depression but had forgotten to some extent, which is that severe financial instability can do grave damage to the broader economy. The implication is that a central bank must take into account risks to financial stability if it is to help achieve good macroeconomic performance. Today, the Federal Reserve sees its responsibilities for the maintenance of financial stability as coequal with its responsibilities for the management of monetary policy, and we have made substantial institutional changes in recognition of this change in goals. In a sense, we have come full circle, back to the original goal of the Federal Reserve of preventing financial panics.39 \n\nHow should a central bank enhance financial stability? One means is by assuming the lender-of-last-resort function that Bagehot understood and described 140 years ago, under which the central bank uses its power to provide liquidity to ease market conditions during periods of panic or incipient panic. The Fed's many liquidity programs played a central role in containing the crisis of 2008 to 2009. However, putting out the fire is not enough; it is also important to foster a financial system that is sufficiently resilient to withstand large financial shocks. Toward that end, the Federal Reserve, together with other regulatory agencies and the Financial Stability Oversight Council, is actively engaged in monitoring financial developments and working to strengthen financial institutions and markets. The reliance on stronger regulation is informed by the success of New Deal regulatory reforms, but current reform efforts go even further by working to identify and defuse risks not only to individual firms but to the financial system as a whole, an approach known as macroprudential regulation.\n\nFinancial stability is also linked to monetary policy, though these links are not yet fully understood. Here the Fed's evolving strategy is to make monitoring, supervision, and regulation the first line of defense against systemic risks; to the extent that risks remain, however, the FOMC strives to incorporate these risks in the cost-benefit analysis applied to all monetary policy actions.40 \n\nWhat about the monetary policy framework? In general, the Federal Reserve's policy framework inherits many of the elements put in place during the Great Moderation. These features include the emphasis on preserving the Fed's inflation credibility, which is critical for anchoring inflation expectations, and a balanced approach in pursuing both parts of the Fed's dual mandate in the medium term. We have also continued to increase the transparency of monetary policy. For example, the Committee's communications framework now includes a statement of its longer-run goals and monetary policy strategy.41 In that statement, the Committee indicated that it judged that inflation at a rate of 2 percent (as measured by the annual change in the price index for personal consumption expenditures) is most consistent over the longer run with the FOMC's dual mandate. FOMC participants also regularly provide estimates of the longer-run normal rate of unemployment; those estimates currently have a central tendency of 5.2 to 6.0 percent. By helping to anchor longer-term expectations, this transparency gives the Federal Reserve greater flexibility to respond to short-run developments. This framework, which combines short-run policy flexibility with the discipline provided by the announced targets, has been described as constrained discretion.42 Other communication innovations include early publication of the minutes of FOMC meetings and quarterly postmeeting press conferences by the Chairman.\n\nThe framework for implementing monetary policy has evolved further in recent years, reflecting both advances in economic thinking and a changing policy environment. Notably, following the ideas of Lars Svensson and others, the FOMC has moved toward a framework that ties policy settings more directly to the economic outlook, a so-called forecast-based approach.43 In particular, the FOMC has released more detailed statements following its meetings that have related the outlook for policy to prospective economic developments and has introduced regular summaries of the individual economic projections of FOMC participants (including for the target federal funds rate). The provision of additional information about policy plans has helped Fed policymakers deal with the constraint posed by the effective lower bound on short-term interest rates; in particular, by offering guidance about how policy will respond to economic developments, the Committee has been able to increase policy accommodation, even when the short-term interest rate is near zero and cannot be meaningfully reduced further.44 The Committee has also sought to influence interest rates further out on the yield curve, notably through its securities purchases. Other central banks in advanced economies, also confronted with the effective lower bound on short-term interest rates, have taken similar measures.\n\nIn short, the recent crisis has underscored the need both to strengthen our monetary policy and financial stability frameworks and to better integrate the two. We have made progress on both counts, but more needs to be done. In particular, the complementarities among regulatory and supervisory policies (including macroprudential policy), lender-of-last-resort policy, and standard monetary policy are increasingly evident. Both research and experience are needed to help the Fed and other central banks develop comprehensive frameworks that incorporate all of these elements. The broader conclusion is what might be described as the overriding lesson of the Federal Reserve's history: that central banking doctrine and practice are never static. We and other central banks around the world will have to continue to work hard to adapt to events, new ideas, and changes in the economic and financial environment.\n\nReferences\nAhmed, Shaghil, Andrew Levin, and Beth Anne Wilson (2004). \"Recent U.S. Macroeconomic Stability: Good Policies, Good Practices, or Good Luck?\" Review of Economics and Statistics, vol. 86 (August), pp. 824-32.\n\nAlesina, Alberto, and Lawrence H. Summers (1993). \"Central Bank Independence and Macroeconomic Performance: Some Comparative Evidence,\" Journal of Money, Credit and Banking, vol. 25 (May), pp. 151-62.\n\nAxilrod, Stephen H. (1982). \"Monetary Policy, Money Supply, and the Federal Reserve's Operating Procedures\" in Paul Meek, ed., Central Bank Views on Monetary Targeting. New York: Federal Reserve Bank of New York, pp. 32-41.\n\nBagehot, Walter ([1873] 1897). Lombard Street: A Description of the Money Market. New York: Charles Scribner's Sons.\n\nBernanke, Ben S. (2002). \"Asset-Price ‘Bubbles' and Monetary Policy,\" speech delivered at the New York Chapter of the National Association for Business Economics, New York, October 15.\n\n-------- (2004). \"The Great Moderation,\" speech delivered at the meetings of the Eastern Economic Association, Washington, February 20.\n\n-------- (2011). \"The Effects of the Great Recession on Central Bank Doctrine and Practice,\" speech delivered at the Federal Reserve Bank of Boston 56th Economic Conference, Boston, October 18.\n\nBernanke, Ben S., and Frederic S. Mishkin (1997). \"Inflation Targeting: A New Framework for Monetary Policy?\" Journal of Economic Perspectives, vol. 11 (Spring), pp. 97-116.\n\nBoard of Governors of the Federal Reserve System (1924). Tenth Annual Report of the Federal Reserve Board, Covering Operations for the Year 1923. Washington: Government Printing Office.\n\nBordo, Michael D., and David C. Wheelock (2013). \"The Promise and Performance of the Federal Reserve as Lender of Last Resort 1914-1933,\" in Michael D. Bordo and William Roberds, eds., A Return to Jekylll Island: The Origins, History, and Future of the Federal Reserve. New York: Cambridge University Press, pp. 59‑98.\n\nBordo, Michael D., Ehsan U. Choudhri, and Anna J. Schwartz (2002). \"Was Expansionary Monetary Policy Feasible during the Great Contraction? An Examination of the Gold Standard Constraint,\" Explorations in Economic History, vol. 39 (January), pp. 1-28.\n\nCalvo, Guillermo A. (1983). \"Staggered Prices in a Utility-Maximizing Framework,\" Journal of Monetary Economics, vol. 12 (September), pp. 383-98.\n\nCarlson, Mark A., and David C. Wheelock (2012). \"The Lender of Last Resort: Lessons from the Fed's First 100 Years,\" Working Paper Series 2012-056B. St. Louis, Mo.: Federal Reserve Bank of St. Louis, November.\n\nClarida, Richard, Jordi Galí, and Mark Gertler (2000). \"Monetary Policy Rules and Macroeconomic Stability: Evidence and Some Theory,\" Quarterly Journal of Economics, vol. 115 (February), pp. 147-80.\n\nCukierman, Alex, and Allan H. Meltzer (1986). \"A Theory of Ambiguity, Credibility, and Inflation under Discretion and Asymmetric Information,\" Econometrica, vol. 54 (September), pp. 1099-128.\n\nDavis, Steven J., and James A. Kahn (2008). \"Interpreting the Great Moderation: Changes in the Volatility of Economic Activity at the Macro and Micro Levels,\" Journal of Economic Perspectives, vol. 22 (Fall), pp. 155-80.\n\nDebelle, Guy, and Stanley Fischer (1994). \"How Independent Should a Central Bank Be? (PDF)\" in Jeffrey C. Fuhrer, ed., Goals, Guidelines, and Constraints Facing Monetary Policymakers, proceedings of the Goals, Guidelines, and Constraints Facing Monetary Policymakers conference held in North Falmouth, Mass., June. Boston: Federal Reserve Bank of Boston, pp. 195-221.\n\nDeLong, J. Bradford (1990). \" ‘Liquidation' Cycles: Old-Fashioned Real Business Cycle Theory and the Great Depression,\" NBER Working Paper Series 3546. Cambridge, Mass.: National Bureau of Economic Research, December.\n\n-------- (1997), \"America's Peacetime Inflation: The 1970s,\" in Christina D. Romer and David H. Romer, eds., Reducing Inflation: Motivation and Strategy. Chicago: University of Chicago Press, pp. 247-76.\n\nDynan, Karen E., Douglas W. Elmendorf, and Daniel E. Sichel (2006). \"Can Financial Innovation Help to Explain the Reduced Volatility of Economic Activity?\" Journal of Monetary Economics, vol. 53 (January), pp. 123-50.\n\nEichengreen, Barry (1992). Golden Fetters: The Gold Standard and the Great Depression, 1919-1939. New York: Oxford University Press.\n\nFischer, Stanley (1977). \"Long-Term Contracts, Rational Expectations, and the Optimal Money Supply Rule,\" Journal of Political Economy, vol. 85 (February), pp. 191‑205.\n\nFriedman, Milton (1963). Inflation: Causes and Consequences. New York: Asia Publishing House.\n\nFriedman, Milton, and Anna J. Schwartz (1963). A Monetary History of the United States, 1867-1960. Princeton, N.J.: Princeton University Press.\n\nGoodfriend, Marvin (1986). \"Monetary Mystique: Secrecy and Central Banking,\" Journal of Monetary Economics, vol. 17 (January), pp. 63-92.\n\nHsieh, Chang-Tai, and Christina D. Romer (2006). \"Was the Federal Reserve Constrained by the Gold Standard during the Great Depression? Evidence from the 1932 Open Market Purchase Program,\" Journal of Economic History, vol. 66 (March), pp. 140-76.\n\nHumphrey, Thomas M. (1982). \"The Real Bills Doctrine (PDF),\" Federal Reserve Bank of Richmond, Economic Review, vol. 19 (September/October), pp. 3-13.\n\nJudd, John P., and Glenn D. Rudebusch (1998). \"Taylor's Rule and the Fed: 1970‑1997 (PDF),\" Federal Reserve Bank of San Francisco, Economic Review, vol. 3, pp. 3-16.\n\nLindsey, David E. (2003). A Modern History of FOMC Communication: 1975-2002 (PDF), unpublished report, Board of Governors of the Federal Reserve System, Division of Monetary Affairs, June.\n\nLindsey, David E., Athanasios Orphanides, and Robert H. Rasche (2005). \"The Reform of October 1979: How It Happened and Why (PDF),\" Federal Reserve Bank of St. Louis, Review, vol. 87 (March/April), pp. 187-236.\n\nMcCallum, Bennett T. (1981). \"Price Level Determinacy with an Interest Rate Policy Rule and Rational Expectations,\" Journal of Monetary Economics, vol. 8 (November), pp. 319-29.\n\nMeltzer, Allan H. (2003). A History of the Federal Reserve, Volume 1: 1913-1951. Chicago: University of Chicago Press.\n\n-------- (2009a). A History of the Federal Reserve, Volume 2, Book 1: 1951‑1969. Chicago: University of Chicago Press.\n\n-------- (2009b). A History of the Federal Reserve, Volume 2, Book 2: 1970‑1986. Chicago: University of Chicago Press.\n\nMishkin, Frederic S. (2007). \"Monetary Policy and the Dual Mandate,\" speech delivered at Bridgewater College, Bridgewater, Va., April 10.\n\nNelson, Edward (2005). \"The Great Inflation of the Seventies: What Really Happened?\" Advances in Macroeconomics, vol. 5 (1), pp. 1-48.\n\nNoyes, Alexander D. (1929), \"Wall Street's Controversy with the Reserve Board: Professor Lawrence Takes the Side of the Stock Market in the Quarrel of the Past Year,\" a review of Wall Street and Washington, by Joseph Stagg Lawrence, New York Times, Book Review, August 25.\n\nOrphanides, Athanasios (2003). \"The Quest for Prosperity without Inflation,\" Journal of Monetary Economics, vol. 50 (April), pp. 633-63.\n\n-------- (2006). \"The Road to Price Stability,\" American Economic Review, vol. 96 (May, Papers and Proceedings), pp. 178-81.\n\nOwen, Robert L. (1919). The Federal Reserve Act: Its Origin and Principles. New York: Century Company.\n\nPoole, William (1979). \"Burnsian Monetary Policy: Eight Years of Progress?\" Journal of Finance, vol. 34 (May), pp. 473-84.\n\nRomer, Christina D., and David H. Romer (2002a). \"The Evolution of Economic Understanding and Postwar Stabilization Policy (PDF),\" in proceedings of Rethinking Stabilization Policy, a symposium sponsored by the Federal Reserve Bank of Kansas City. Kansas City, Mo.: Federal Reserve Bank of Kansas City, pp. 11-78.\n\n-------- (2002b). \"A Rehabilitation of Monetary Policy in the 1950s,\" American Economic Review, vol. 92 (May, Papers and Proceedings), pp. 121-27.\n\n-------- (2013), \"The Most Dangerous Idea in Federal Reserve History: Monetary Policy Doesn't Matter,\" American Economic Review, vol. 103 (May, Papers and Proceedings), pp. 55-60.\n\nRotemberg, Julio J. (1982). \"Sticky Prices in the United States,\" Journal of Political Economy, vol. 90 (December), pp. 1187-211.\n\nSargent, Thomas J. (1982). \"The Ends of Four Big Inflations,\" in Robert E. Hall, ed., Inflation: Causes and Consequences. Chicago: University of Chicago Press, pp. 41-97.\n\nSargent, Thomas J., and Neil A. Wallace (1975). \" ‘Rational' Expectations, the Optimal Monetary Instrument, and the Optimal Money Supply Rule,\" Journal of Political Economy, vol. 83 (April), pp. 241-54.\n\nStock, James H., and Mark W. Watson (2003). \"Has the Business Cycle Changed? Evidence and Explanations (PDF),\" in proceedings of Monetary Policy and Uncertainty: Adapting to a Changing Economy, a symposium sponsored by the Federal Reserve Bank of Kansas City. Kansas City, Mo.: Federal Reserve Bank of Kansas City, pp. 9-56.\n\nStokey, Nancy L. (2002). \" ‘Rules vs. Discretion' after Twenty-Five Years,\" in Mark Gertler and Kenneth Rogoff, eds., NBER Macroeconomics Annual, vol. 17, pp. 62-64.\n\nStrong, Benjamin (1926). \"Open Market Operations,\" in hearing before the U.S. House of Representatives Committee on Banking and Currency, April. Reprinted in W. Randolph Burgess, ed. (1930), Interpretations of Federal Reserve Policy in the Speeches and Writings of Benjamin Strong. New York: Harper and Brothers.\n\nSvensson, Lars E. O. (2003). \"What Is Wrong with Taylor Rules? Using Judgment in Monetary Policy through Targeting Rules,\" Journal of Economic Literature, vol. 41 (June), 426‑77.\n\nTaylor, John B. (1980). \"Aggregate Dynamics and Staggered Contracts,\" Journal of Political Economy, vol. 88 (February), pp. 1-23.\n\n-------- (1993). \"Discretion versus Policy Rules in Practice,\" Carnegie-Rochester Conference Series on Public Policy, vol. 39 (December), pp. 195-214.\n\n-------- (1997). \"Comment on ‘America's Peacetime Inflation: The 1970s,' \" in Christina D. Romer and David H. Romer, eds., Reducing Inflation: Motivation and Strategy. Chicago: University of Chicago Press, pp. 276-80.\n\n-------- (1999a). \"A Historical Analysis of Monetary Policy Rules,\" in John B. Taylor, ed., Monetary Policy Rules. Chicago: University of Chicago Press, pp. 319-41.\n\n--------, ed. (1999b). Monetary Policy Rules. Chicago: University of Chicago Press.\n\nTemin, Peter (1989). Lessons from the Great Depression. Cambridge, Mass.: MIT Press.\n\nU.S. Congress, House Committee on Banking and Currency (1935). \"Banking Act of 1935, Report No. 742 to Accompany H.R. 7617.\" 74 Cong. Washington: Government Printing Office.\n\nWarburg, Paul M. (1914). \"A United Reserve Bank of the United States,\" Proceedings of the Academy of Political Science in the City of New York, vol. 4 (July), pp. 75‑115.\n\nWicker, Elmus R. (1965). \"Federal Reserve Monetary Policy, 1922-33: A Reinterpretation,\" Journal of Political Economy, vol. 73 (August), pp. 325-43.\n\nWillis, H. Parker (1923). The Federal Reserve System: Legislation, Organization, and Operation. New York: Ronald Press Company.\n\nWoodford, Michael (2003). Interest and Prices: Foundations of a Theory of Monetary Policy. Princeton: Princeton University Press.\n\n-------- (2005). \"Central Bank Communication and Policy Effectiveness (PDF),\" in proceedings of The Greenspan Era: Lessons for the Future, a symposium sponsored by the Federal Reserve Bank of Kansas City. Kansas City, Mo.: Federal Reserve Bank of Kansas City, pp. 399-474.\n\nYellen, Janet (2012). \"Revolution and Evolution in Central Bank Communications,\" speech delivered at the Haas School of Business, University of California, Berkeley, November 13.\n\n1. See Owen (1919, p. 24). The Treasury carried out some central banking functions before the creation of the Federal Reserve. In addition, the United States had experimented with central banking before, with the First and Second Banks of the United States. By 1913, however, it had been about 75 years since the latter institution had ceased fulfilling that purpose. Moreover, the Federal Reserve operated somewhat differently from the prior institutions, and, in that respect, its creation amounted to an experiment. Return to text\n\n2. Per a review of the 1929 book Wall Street and Washington in the New York Times, \"The Federal Reserve System has from the first necessarily been a great experiment, bound to adjust its general policies to the requirements of such novel and varying situations as should arise in the course of our financial history and which could not possibly be foreseen\" (Noyes, 1929). Return to text\n\n3. Friedman and Schwartz (1963) describe the debate about the elastic currency. Warburg (1914) discusses hoarding and the panic dynamics that the Federal Reserve was established to prevent. Return to text\n\n4. See Willis (1923, p. 1407), Carlson and Wheelock (2012), and Bordo and Wheelock (2013). Bagehot ([1873] 1897) is the source of the classic dictum that a panic should be addressed by the central bank, by lending freely at a penalty rate. Return to text\n\n5. The Monetary Control Act of 1980 gave all depository institutions access to the discount window. The collateral acceptable to be pledged to the discount window has been expanded significantly over time; in particular, various pieces of banking legislation in the early 1930s enabled the Federal Reserve to make advances to member banks so long as the loans were \"secured to the satisfaction\" of the Federal Reserve Bank extending the loan. Return to text\n\n6. See Humphrey (1982) for a discussion of the historical evolution of the real bills doctrine. Return to text\n\n7. This interpretation follows from the discussion in the Tenth Annual Report of the Federal Reserve Board (Board of Governors, 1924). Soon after the Federal Reserve was founded, its mission shifted to supporting the war effort and then to managing the unwinding of that support. The year 1923 was thus one of the first in which the Federal Reserve confronted normal peacetime financial conditions, and it took the opportunity to articulate its views on the appropriate conduct of policy in such conditions. Return to text\n\n8. The Federal Reserve could undo the effects of gold inflows on the domestic money supply through open market operations, discussed later. Return to text\n\n9. See, for example, Eichengreen (1992). Return to text\n\n10. See Friedman and Schwartz (1963), Humphrey (1982), and Meltzer (2003). Return to text\n\n11. See Strong (1926). Return to text\n\n12. See Friedman and Schwartz (1963). Return to text\n\n13. Meltzer (2003, pp. 282, 729-30) notes that Board members discussed Bagehot's ideas but nevertheless did not integrate them fully into their approach to policy. Return to text\n\n14. See Friedman and Schwartz (1963, chapter 7). Return to text\n\n15. Wicker (1965), Temin (1989), and Eichengreen (1992) suggest that U.S. policymakers felt constrained by the gold standard. In contrast, Hsieh and Romer (2006), as well as Bordo, Choudhri, and Schwartz (2002), focus on the short-lived monetary expansion in 1932 as evidence against the existence of important constraints on the Federal Reserve. Return to text\n\n16. See Meltzer (2003) and Romer and Romer (2013). Return to text\n\n17. See, for example, DeLong (1990). Return to text\n\n18. This language amended section 12A(c) of the Federal Reserve Act. Return to text\n\n19. For example, section 10B enhanced the powers of the Federal Reserve to lend to member banks, and sections 13(3) and 13(13) enabled the Federal Reserve to provide short-term credit to a wide range of potential borrowers in specific circumstances. Return to text\n\n20. More precisely, the three statutory objectives for monetary policy set forth in the Federal Reserve Reform Act of 1977 are maximum employment, stable prices, and moderate long-term interest rates. The dual mandate refers to the first two goals, and the long-term interest rate goal is viewed as likely to emerge from the macroeconomic environment associated with achievement of the employment and price stability goals (Mishkin, 2007). Thus, the interest rate goal of the Federal Reserve Reform Act can be regarded as subsumed within the dual mandate. Return to text\n\n21. See U.S. Congress (1935). Return to text\n\n22. See Meltzer (2003). Return to text\n\n23. See, for example, Orphanides (2003) and Meltzer (2009a). Return to text\n\n24. See Romer and Romer (2002b). Return to text\n\n25. See Lars Svensson's remarks in Stokey (2002, p. 63). Return to text\n\n26. See, for example, Poole (1979), Romer and Romer (2002a, 2013), Bernanke (2004), and Nelson (2005). Return to text\n\n27. Estimates of the response of the federal funds rate to inflation for the 1970s generally show only a weak reaction. See Judd and Rudebusch (1998); Taylor (1999a); and Clarida, Galí, and Gertler (2000). For the quotation, see Friedman (1963, p.17). Return to text\n\n28. See DeLong (1997) and Taylor (1997) for a discussion of views during the 1970s on the costs of inflation. Return to text\n\n29. For discussion of these points, see Meltzer (2009b). Return to text\n\n30. See, for example, Axilrod (1982). Return to text\n\n31. Central banks' emphasis on expectations management partly reflected lessons from the rational expectations literature of the 1970s. Monetary policy implications of the rational expectations literature were further clarified by later research. For example, Sargent (1982) brought out dramatically the dependence of inflation expectations on the monetary policy regime in his study of major disinflations, while rational expectations models were extended to include sticky prices (Fischer, 1977; Taylor, 1980; Rotemberg, 1982; Calvo, 1983) and interest rate rules (Sargent and Wallace, 1975; McCallum, 1981; Taylor, 1993, 1999b; Woodford, 2003). Return to text\n\n32. See Lindsey, Orphanides, and Rasche (2005). Return to text\n\n33. See Woodford (2005). Many of these principles were codified in the emerging doctrine of inflation targeting, the practice of which was greatly advanced by central banks in other countries. One of the most notable examples is New Zealand's introduction of inflation targeting in 1990. Return to text\n\n34. See, for example, Goodfriend (1986) and Cukierman and Meltzer (1986). Return to text\n\n35. See Orphanides (2006) for a discussion of the Federal Reserve's move during the 1980s and 1990s to increased clarity about policy objectives. Return to text\n\n36. See Lindsey (2003). Return to text\n\n37. See Alesina and Summers (1993) and Debelle and Fischer (1994). Return to text\n\n38. For a sampling of the debate, see Stock and Watson (2003); Ahmed, Levin, and Wilson (2004); Dynan, Elmendorf, and Sichel (2006); and Davis and Kahn (2008). Return to text\n\n39. See Bernanke (2011). Return to text\n\n40. See Bernanke (2002). Return to text\n\n41. The statement can be found at www.federalreserve.gov/newsevents/press/monetary/20120125c.htm. Return to text\n\n42. See Bernanke and Mishkin (1997). Return to text\n\n43. In a forecast-based approach, monetary policymakers inform the public of their medium-term targets--say, a specific value for the inflation rate--and attempt to vary the instruments of policy as needed to meet that target over time. In contrast, an instrument-based approach involves providing the public information about how the monetary policy committee plans to vary its policy instrument--typically, a short-term interest rate, like the federal funds rate--in response to economic conditions. See Svensson (2003). Return to text\n\n44. See Yellen (2012) for an elaboration of this point. Return to text"
    },
    {
        "title": "Beyond Capital: The Case for a Harmonized Response to Asset Bubbles",
        "date": "July 17, 2013",
        "speaker": "Governor Sarah Bloom Raskin",
        "url": "https://www.federalreserve.gov/newsevents/speech/raskin20130717a.htm",
        "content": "July 17, 2013\n\nGovernor Sarah Bloom Raskin\n\nAt the The Exchequer Club Luncheon, Washington, D.C.\n\nThank you for inviting me to speak to you this afternoon.1 I'm honored to have the chance to be with so many former colleagues and friends. As I look around this room, I'm reminded of your efforts and the variety of perspectives that you have brought, over the years, to the endeavor of financial regulation. I'm reminded of the contributions you have made to the richness of these debates and tasks.\n\nThere has been a flurry of pronouncements lately regarding regulations, rules, and guidance, and today's meeting of the Exchequer Club seems like an opportune moment to pause and offer a perspective that lifts us above the many details.2 Newly adopted capital rules, and those newly proposed, in particular, have received the most attention, and I believe that these rules and proposed rules are a big step forward. There is no question but that a higher quantity and quality of bank capital will strengthen the banking system.\n\nToday, I want to discuss regulatory policies in the context of the growth and inevitable collapse of asset bubbles, with a focus on the role of credit.Regulatory policies, when well crafted, can lean against credit excesses that result in asset bubbles. In so doing, they can lean against vulnerabilities in the financial system that encourage the growth of excess credit. Well-crafted regulatory policies can also build resilience for banks after asset bubbles have burst. Many such regulatory policies are already in use, but there are others at the frontiers of regulation that haven't been widely employed. Significantly, both sets of regulatory policies--those that lean against excesses and those that build resilience--need to be understood in the context of a comprehensive system of prudential supervision for all financial institutions.\n\nIn my remarks, first, I will briefly review how asset bubbles form, and I'll highlight certain features of asset bubbles so we can discern how regulatory policy might respond to them.\n\nSecond, I'll assert that regulatory tools, including those related to capital, only work if part of a system of prudential supervision for all financial institutions.\n\nThird, I'll ask whether capital and other regulatory requirements have meaning without a prescriptive and individualized analysis of risk for individual financial institutions. In this regard, I'll suggest several other considerations that financial institutions and regulators should consider in the regulatory context. \n\nAsset Bubbles\nIn order to think about regulatory policy from the perspective of leaning against excesses and vulnerabilities created by asset bubbles, or from the perspective of strengthening resilience to asset bubbles, we need to understand how financial institutions participate in the creation of bubbles. The story of asset bubbles, for me, is one in which there is usually explicit and purposeful financial institution involvement. It used to be believed that asset bubbles emerged spontaneously, or perhaps came from sunspots or other mysterious causes. Now we know more and we know better, and, while we may not be able to predict bubbles, we understand them to be a product of particular actions and choices by financial institutions and their regulators.\n\nHere is one way a bubble might start. And, to approximate current economic conditions, we'll assume an environment of interest rates that have been low, and continue to be low, for a long time. To start, retail investors may become dissatisfied with their low yields and begin to seek higher yields by purchasing some specific higher-yielding asset. If investors have access to credit, they might try to raise the return on their money by funding a greater portion of their purchases with debt. The asset purchased could serve to collateralize their loan. If many investors employ this strategy and they borrow to invest in the same asset, the price of that asset, and perhaps the prices of closely related assets as well, will increase noticeably faster than the historical trend.\n\nAt the same time, increased demand for credit to finance these asset purchases could lead lenders to increase their reliance on less expensive, unstable short-term funding, such as uninsured deposits, commercial paper, or repo transactions, in order to fund the loans.\n\nBesides meeting customers' growing demands for credit, financial intermediaries may themselves decide to \"reach for yield\" and take on additional risk in a low interest-rate environment. Banks suffering compressed net interest margins because of low long-term interest rates, money market funds facing an earnings squeeze, insurance companies that had promised minimum rates of return on their products, and others may all begin to take on higher interest rate risk, market risk, liquidity risk, or credit risk in search of higher returns.\n\nIf these conditions seem likely to continue, an initial rise in the asset's price leads to expectations of further increases, which adds to investor demand, spurring further borrowing and credit growth and increased household and financial sector leverage, which, in turn, could drive asset prices still higher. Rising asset prices, in turn, would increase the value of borrowers' collateral, allowing still further borrowing.\n\nFor loans collateralized by an asset whose price is rising, lenders believe they can rely for repayment more on the appreciation of the asset and collateral and less on the borrower's repayment ability. Lenders relax their underwriting standards, such as minimum requirements for borrower down payments, credit scores and credit history, or required maximum debt-to-income ratios. To compete for loans to buy or to hold the appreciating asset, or financial assets related to it, financial institutions could also decrease the margins and haircuts that usually protect them from asset price declines.\n\nFinancial institution decisions to relax underwriting and impose less-stringent margins and haircuts will further increase the pool of potential borrowers and their borrowing capacity, further increasing credit growth and supporting still higher asset prices, but, at the same time, will also increase lenders' credit risks and exposure--as secured creditors--to a decline in the asset's price. Ultimately, the asset becomes severely overvalued, with its price untethered from economic fundamentals. We would then have on our hands a full-blown, credit-fueled asset bubble.\n\nAnd, as we experienced in the financial crisis, when a bubble involving a widely-held asset bursts, the consequent plunge in asset prices can seriously impair the balance sheets of households and firms. Indeed, a dramatic decline in the price of a significant asset can reduce household wealth, spending, and aggregate demand. When such effects on wealth, credit availability, and aggregate demand are large enough, the real economy can suffer a significant recession. And, of course, lower employment and incomes further depress asset prices and borrowers' ability to repay loans, with further adverse effects on financial institutions and their ability to extend credit.\n\nAt this point, some financial institutions may have become nearly insolvent. And this, coupled with their increased reliance on potentially unstable short-term funding, could make them more vulnerable to sudden losses of public confidence.\n\nSuch a loss of confidence, in turn, makes it impossible for affected institutions to roll over existing debts or extend new credit, and may force deleveraging that requires selling illiquid assets quickly and cheaply in asset fire sales, resulting in further declines in asset prices. Such developments further threaten the solvency of financial institutions and intensify credit contraction, depriving households and businesses of financing. A loss of confidence that is institution-specific could spread, causing other institutions to experience their own heightened solvency risks, liquidity problems, and need to de-lever through asset sales.\n\nSomething like what I've just described happened during and after the recent housing boom and bust. Home prices rose dramatically for a decade, and then plunged more than 30 percent, throwing the financial system into chaos, severely contracting credit, and triggering the most severe recession in modern memory. We are still living with the consequences.\n\nIn short, there are common features to asset bubbles. All asset bubbles implicate different segments and participants in financial transactions--lenders, borrowers, and even participants that are connected by virtue of the benefits they derive from the appreciation in the value of the asset in question. The linkages transcend banks. Bubbles are characterized by increased leverage among the various types of lending institutions and by increased maturity transformation on and off the balance sheets of various lenders. Illiquid loans are funded increasingly by unstable short-term funding. At the same time, asset bubbles are accompanied by weakening underwriting standards, and less-stringent margins and smaller haircuts. And asset bubbles are characterized by many investors chasing the same asset, and so there is generally wide-spread participation in the growth and nurturing of the bubble.\n\nPerhaps our recent asset bubble was the result of a perfect storm, one that will not recur for decades. But it is my view that asset bubbles are a feature of our financial landscape; that what happened before could happen again; and that the growth and after-effects of asset bubbles reflect particular financial institution decisions and particular regulatory policy choices or lapses. In my view, their emergence is usually neither intentional nor accidental.\n\nResponding to Asset Price Bubbles\nThe good news is that I believe that regulatory policy, when part of a system of effective prudential supervision, has the potential to address asset price bubbles and their consequences. Regulatory policies can lean against emerging asset bubbles and the vulnerabilities that attend them by restraining financial institutions from excessively extending credit. In addition, such policies can build resilience in the financial system, enhancing its ability to absorb and shrug off unexpected losses from any source, including sharp asset price declines.\n\nOf course, monetary policy also has the power to lean against the growth of asset bubbles. While there could be situations in which monetary policy might be needed to try to limit the growth of a bubble, in my opinion such use would represent a failure of regulatory policy, which represents a more tailored response than the flattening out of aggregate demand that would likely result from contractionary monetary policy.\n\nRegulatory Tools\nSome of the significant regulatory tools for addressing asset bubbles--both those in widespread use and those on the frontier of regulatory thought--are capital regulation, liquidity regulation, regulation of margins and haircuts in securities funding transactions, and restrictions on credit underwriting. Without plumbing the depths of each type of tool, I'll say a few words about each as it relates to the curbing of excess credit growth that fuels asset bubbles and to mitigating the effects of a bubble's collapse.\n\nCapital Regulation \nCapital regulation--in particular, the imposition of minimum capital requirements-- increases capital and thereby improves the ability of regulated financial institutions to absorb losses and maintain lending after a bubble has burst. More capital reduces the probability of institutions' failure, with the added benefit of reducing the chance of funding runs due to loss of confidence.\n\nBut because higher required capital also generally increases the cost of funding assets--by increasing the role of capital in the funding mix--it also raises the possibility of reducing the supply of credit from regulated institutions, making credit more expensive. Thus, higher capital requirements, to some degree, also lean against excessive credit growth that can fuel asset bubbles.\n\nRelevant capital regulation tools include a higher amount and quality of capital, such as is required under Basel III; leverage ratios, particularly the supplementary leverage ratio, if regulators increase it; the Basel III countercyclical capital buffer, which is designed to build resilience and lean against credit-fueled asset bubbles in a countercyclical manner; and capital surcharges. \n\nSupervisory stress testing and capital planning are related regulatory capital-focused tools. They not only increase resilience, but, by including assumed asset bubbles in their scenarios, they can also focus attention on specific assets, causing banking firms to build capital against unexpected losses in those assets. By focusing management attention on the downside risk posed by certain assets, and by increasing the share of capital in the funding mix, they can also lean against bank lending that supports inflated asset values.\n\nIn addition, higher \"sector-specific\" risk weights and capital charges, applied to specific assets such as mortgages, potentially could be a more targeted way of addressing particular asset bubbles; however, these more targeted capital tools require an early understanding of the particular asset class that may be involved in a potential bubble. Whether financial regulators would be capable of spotting such specific asset bubbles early, and then of acting in a timely enough way to address such bubbles is, in my view, unlikely.\n\nLiquidity Regulation \nA second class of policies that addresses asset bubbles and their consequences is liquidity regulation. An example is the new Basel III liquidity coverage ratio. As I discussed earlier, an aspect of credit-driven asset bubbles is financial institutions' increased reliance on unstable short-term wholesale funding, a reliance that makes them vulnerable to heightened rollover risk, sudden losses of confidence, and funding runs. Liquidity regulation increases the stock of cash or easily marketable securities available to institutions in the event of a funding run or margin call.\n\nLiquidity regulation also discourages use of unstable short-term wholesale funding of illiquid longer-term assets in the first place. Truly liquid assets, such as cash or Treasury securities, are low-yielding, and being required to hold them means lower earnings. Therefore, minimum liquidity requirements raise the cost, and so reduce the amount of, liquidity risk taking, reducing the chances of a liquidity crisis and asset fire sales. In that sense, minimum liquidity requirements also lean against building vulnerabilities that could accompany the growth of an asset bubble.\n\nIndeed, regulators might vary liquidity requirements in a countercyclical way, with greater liquidity required during the development of credit-fueled asset bubbles, in order to regulate the amount of allowable maturity transformation.\n\nMargins and Haircuts\nA third class of policies that could be helpful in addressing credit-fueled asset bubbles is margins and haircuts on securities financing transactions.\n\nSuch transactions could include, for example, bilateral repurchase transactions in which a broker–dealer, in order to fund its holdings of some security, borrows short-term from a money market mutual fund, while pledging a security of greater value as collateral. The excess of the value of the security over the amount borrowed at the time of the transaction is the \"haircut.\" Haircuts protect the cash lender, since, if the borrower cannot repay, or chooses not to because collateral values have fallen, the lender can take and sell the collateral to satisfy its loan. The larger the haircut is at the time of the transaction, the greater the lender's protection; that is, the greater the likelihood that that the value of the security, when sold, will exceed the amount owed plus interest.\n\nPresumably, lenders assess their borrowers' riskiness and calibrate the amount of the appropriate haircut. Regulators should require them to do this consistently and prudently across the credit cycle.\n\nHaircuts tend to be cyclical: falling in good times, which adds to the growth of credit, and rising in busts, which contracts credit. A regulator could mitigate the cyclical behavior of haircuts and its consequences by establishing minimum haircuts that apply in both good and bad times. Calibrating minimum haircuts to the risks and volatility expected during bad times would make lenders more secure, increasing their resilience to losses. It could also make it more expensive to fund the purchase of the securities, and so could limit the amount of borrowing that could be supported by an asset of given value; this, in turn, might limit credit-fueled increases in the asset's price.\n\nIn other words, by requiring increased margin, the growth of credit can be slowed and resiliency can be strengthened. Regulators can also simply require margin requirements to be increased in good times. This would lean against the growth of bubbles even if regulators had not yet discerned the particular type of asset bubble growing.\n\nUnderwriting Restrictions\nThe final class of policies that I'll discuss involves underwriting restrictions that can directly address asset bubbles and their consequences.\n\nWhen assets like houses are largely financed with borrowed money, it is possible to use tighter underwriting requirements to lean against credit extension and growing leverage. This could be done, for example, through regulatory actions that raise lenders' minimum down payment requirements or reduce borrowers' maximum permissible debt-to-income ratios. Such measures can be taken either on a one-time basis or as part of an explicitly countercyclical regime that \"switches on\" during a building asset bubble.\n\nIn particular, regulators might impose minimum down payment requirements for property loans or their functional equivalent--maximum loan-to-value ratios. Such policies could both build resilience in the financial system and lean against developing credit excesses. They would build resilience in two ways. First, other things the same, higher minimum down payment requirements reduce the probability of default on loans. And second, higher requirements also imply a lower loss given default. Both effects imply greater resilience for the bank or other entity that made the loan or has an interest in it. Even a structural one-time upward adjustment in minimum down payment requirements--to a prudent level, above industry norms in buoyant times--could have a countercyclical effect in building resilience. Such a requirement could also moderate lender adjustments in minimum down payment requirements over the credit cycle: Minimum requirements would fall less in boom times, implying lower future loan losses than otherwise, and so would increase less in reaction during busts. In addition, by leaning against excessive credit expansion, such a policy could lean against developing asset bubbles and growing financial vulnerabilities.\n\nIn a dynamic variant of this policy, minimum down payments prescribed by regulators could be implemented and would automatically vary over the credit cycle, tightening in booms and relaxing in busts. Tighter minimum down payment requirements in good times would likely reduce defaults and build lender resilience to later losses due to asset price declines. At the same time, by actively leaning progressively harder against property-related credit expansion, they may restrain excessive credit growth and property price appreciation, and reduce the chances--and magnitude--of a sharp price bust. There has been some experience with this type of policy in Hong Kong, Korea, Malaysia, and Singapore. In Hong Kong, for example, tighter down payment rules reduce household leverage and the sensitivity of defaults to changes in property prices, and have been shown to slow property appreciation.\n\nPrudential Supervision for All Financial Institutions\nI don't mean to suggest that all asset bubbles can be addressed by merely implementing some set of regulatory policies. Indeed, how easy our jobs would then be!\n\nIn practice, such policies work best if they are part of a system of prudential supervision for all financial institutions. Of course, in the U.S. economy, savers and borrowers are linked not only through intermediaries like banks, but also through nonbanks, such as money market mutual funds and hedge funds, and through the capital markets and securitization. Regulation can only build resilience in, and affect intermediation and lending by, the parts of the system that are, in fact, regulated. Regulatory policies that aim to increase the resilience of regulated institutions, and lean against asset bubbles by restraining the growth of lending by such institutions, can be circumvented when financial activities migrate into less regulated parts of the financial system, parts likely farther from the protections of deposit insurance and the lender of last resort. Consequently, credit extension and associated vulnerabilities can increase outside of the heavily regulated banking system. In our current system of financial regulation--one that is diffuse and without a single, central regulator --the antidote to such differences in regulatory approach is to put a premium on a high level of cooperation and coordination among relevant financial regulators.\n\nComprehensive financial regulation is required, but comprehensive financial regulation is not the same as unified financial regulation. Looking around this audience today, I see evidence of the fragmented American financial regulatory system. For example, we have representatives of banks regulated by the Office of the Comptroller of the Currency, the Federal Deposit Insurance Corporation, and the Federal Reserve, many in tandem with state bank regulators; we have bank holding companies regulated by the Fed; we have broker-dealers regulated by the Securities and Exchange Commission, we have exchanges regulated by the Commodity Futures Trading Commission; we have consumer financial products regulated by the Consumer Financial Protection Bureau; and we have insurance companies regulated by the state insurance commissioners. I could go on. Needless to say, it's a complicated regulatory system. And such a fragmented structure itself demands unusual and extensive degrees of coordination and cooperation among financial regulators so as to maximize the potential for comprehensive and harmonized regulation. Without such coordination and cooperation, there will be regulatory gaps and overlaps.\n\nFrom this perspective, it made sense to create yet another regulatory body--the Financial Stability Oversight Council--which is dedicated to the goal of coordination. The FSOC calls for agency head and senior-level staff participation of relevant financial regulatory bodies, requires regular meetings and reports on emerging risks to financial stability, and designates systemically important financial institutions.\n\nMaking Regulatory Tools Work to Manage Emerging Risk and Create Resiliency\nIndeed, the goal of coordination among regulators is to make the regulatory tools work across the entire financial system. This strikes me as an important goal and the ultimate challenge for policymakers. The challenge arises not only from the fact that the regulatory system is fragmented, but also from the fact that, in order to work--indeed, in order to instill trust in the resiliency of the financial system--regulations need to be complied with by financial system participants and enforced by supervisors. The recent attention being paid to capital regulation, in particular, shouldn't distract us from the broader context and importance of compliance with, and enforcement of, the various capital rules.\n\nFrom the perspective of the hammer, everything looks like a nail. Similarly, from the perspective of the financial regulator, everything might look like a problem of insufficient capital. Instead, capital might, in fact, be sufficient but appear insufficient because of circumvention of compliance, or because of absent or delayed enforcement.\n\nTo make regulation--any financial regulation--work, there must be on-site opportunities for supervisors to look for risk factors that, if not addressed, can lead to failure. There must be strong governance that is practiced by smart management teams and overseen by informed and engaged boards of directors. Loan loss provisioning must be appropriate, and regulators need to enforce such appropriate provisioning, as well as assess the prudence of the institutions' underwriting standards. Examiners of any financial institution must be able to spot early risks and articulate to institutions' management and boards of directors why such risks are, in fact, risks. And the identification of risks should be true risks, and not just new business practices that examiners have never seen before.\n\nAddressing risks should not be tomorrow's problem; troubled financial institutions should not be \"fixed\" by permitting larger firms to buy them without commitments to address the risks presented by the combined firms.\n\nFinally, the public needs to have faith that regulation is meaningful. The public has an interest in a strong financial system, and this interest needs to be articulated when regulation is crafted, implemented, and enforced.\n\nConcluding Thoughts\nEven within the regulated sector, crafting appropriate financial regulation to address asset bubbles is challenging. In reality, it is hard to know in real time when asset prices have deviated sharply from fundamentals. Asset price increases often initially reflect improving fundamentals and may only subtly and gradually change into reflections of speculative excess. Prior to the peak of housing prices, interest rates were low, making mortgage payments affordable; real incomes were rising; population was growing; and household formation was high--all \"fundamental\" determinants of the demand for housing and house prices. At some point, however, house prices were driven less by these fundamentals and more by speculation and weak underwriting. Ultimately, this drove house prices to unsustainably high levels. Regulatory intervention was much too late.\n\nThe U.S. regulatory system is fragmented, and, hence, it takes time to choose and implement policies and calibrate them appropriately. It takes time to cooperate, coordinate, and harmonize responses. But such is today's imperative. We must complete in a timely fashion the post-Basel III and Dodd-Frank requirements. It is particularly important to increase the amount, and improve the quality, of required minimum capital; to continue stress testing and capital planning; and to reduce overreliance on unstable short-term wholesale funding. These reforms will build resilience to whatever shocks may come, and will reduce the potential for asset bubbles and excessive credit growth, leverage, maturity transformation, reliance on unstable short-term wholesale funding, and, thus, the potential for future financial crises.\n\nStill, if regulators become fixated on the tools at the expense of compliance and enforcement, the tools themselves will be meaningless. Only when such tools--be they capital-focused, liquidity-focused, margin--and haircut-focused, or underwriting-focused--are fully embedded into a comprehensive system of prudential regulation will they reach their potential in mitigating the growth of asset bubbles and providing resiliency against the awful consequences attendant to their destruction.\n\nThank you for your time today. I'm interested in your comments and questions.\n\n \n\n1. I want to thank Daniel Covitz, Andreas Lehnert, Rochelle Edge, Mark Van Der Weide, William Treacy, Karen Pence, Andrew Cohen, Sean Chu, Sean Campbell, Seth Carpenter, Ben McDonough, April Snyder and Winthrop Hambley for their assistance in the preparation of these remarks. Return to text\n\n2. The views expressed here are my own and are not necessarily those of the other members of the Federal Reserve Board or its staff. Return to text\n\n "
    },
    {
        "title": "Macroprudential Regulation",
        "date": "September 20, 2013",
        "speaker": "Governor Daniel K. Tarullo",
        "url": "https://www.federalreserve.gov/newsevents/speech/tarullo20130920a.htm",
        "content": "September 20, 2013\n\nGovernor Daniel K. Tarullo\n\nAt the Yale Law School Conference on Challenges in Global Financial Services, New Haven, Connecticut\n\nWatch Live\n\nReal world crises have a way of shaking up the intellectual foundations of policy disciplines. Elements of received wisdom are undermined, while certain heterodox or less mainstream views are seen as more valid or important than had been widely recognized. The financial crisis of 2007-2009 was no exception. Some ideas, such as the efficient markets hypothesis, have taken some hits, as others have risen to prominence. An example of the latter is the view that financial stability must be an explicit economic policy goal. A corollary of this view is that a \"macroprudential\" perspective--generally characterized as focused on the financial system as a whole as opposed to the well-being of individual firms--should be added to traditional prudential regulation.\n\nA single speech cannot hope to touch on, much less do justice to, the many theoretical and policy issues encompassed by the term macroprudential. In my remarks this afternoon I will focus principally on the project of recasting the regulation and supervision of large financial firms so as to realize the macroprudential objective of reducing systemic risk. Specifically, I will offer five propositions that I think should guide this project over the next couple of years. In so doing, I will explain some of the key steps that have already been taken and identify some priorities that remain, though even here I do not pretend to comprehensiveness. Before addressing the macroprudential dimension of regulating large financial firms, however, let me provide some context by briefly reviewing the evolving idea of macroprudential policy.\n\nMacroprudential Policy\nAlthough the crisis and its aftermath have created a broader consensus for the proposition that financial stability should be a more explicit objective of economic policy, there is considerably less convergence around theories of, metrics for, and policy prescriptions to promote, financial stability. Policy and academic writing generally limits the term \"macroprudential\" to measures directed specifically at countering risks in the financial system that, if realized, can severely impact real activity.1 But adoption of consistent terminology does not itself resolve questions of whether, for example, increases in systemic risk are endogenous to the financial system and thus follow a somewhat regular cyclical pattern, or are instead somewhat randomized, albeit repeated, phenomena.2 \n\nDifferences in views of the origins of systemic risk obviously affect views of the best ways to measure it and, of course, the best policies to contain it. One example, of particular interest to central bankers, is the ongoing debate about the circumstances under which monetary policy should be adjusted to take account of financial stability concerns. Lying behind the various positions in this debate are differing views on how systemic risk propagates, and thus on the relative efficacy of monetary versus macroprudential policies.\n\nProgress in these debates is complicated by the fact that, by definition, financial stability policies are directed toward preventing or mitigating rare events, rather than outcomes such as inflation and unemployment that are continuously observable. This focus on tail risks raises important issues of accountability in the institutional design of macroprudential policies and also complicates the task of testing financial stability theories and proposed policies.\n\nYet even against the backdrop of what is still a comparatively underdeveloped understanding of financial stability,3 commentators and policymakers have compiled and, in some cases, developed so-called \"toolkits\" of possible macroprudential measures. These measures are thought available for use against one or both of two frequently identified dimensions of systemic risk: procyclicality and interconnectedness.4 Of course, the attractiveness of many of these tools will depend on one's views of a variety of theoretical, institutional, and practical questions.\n\nThe tools identified can be variously categorized. One useful distinction is between measures designed to prevent systemic risk from building (often termed \"lean-against-the-wind\" measures) and those designed to increase the resiliency of the financial system should systemic risk nonetheless build sufficiently that broad-based stress ensues. Another distinction is between time-varying and time-invariant measures, with the former based on a response--either discretionary or in accordance with a rule--to some measured increase in risk.\n\nMacroprudential Foundation for the Regulation of Large Banking Organizations\nIt is worth noting that the term \"macroprudential regulation\" can be found in Bank for International Settlements (BIS) documents beginning more than 30 years ago. It appears to have originated in specific contrast to traditional banking regulation, which a 1979 background paper at the BIS characterized as focused on \"sound banking practice and the protection of depositors at the level of the individual bank.\"5 In fact, much of the New Deal legislation that would define the financial regulatory structure for more than 40 years was in direct response to what we would today call systemic concerns, including banking panics and excessive leverage in equity markets.6 In the late 1970s, though, there was indeed reason for the development of an explicitly macroprudential perspective. The New Deal regulatory system was beginning to break down in the face of profound changes in financial markets, most importantly the progressive integration of capital market and traditional lending activities. The forms of regulation that were evolving as substitutes--principally, though not only, minimum capital requirements--were largely based on what various BIS papers characterized as a microprudential approach to regulation.\n\nIt is, however, equally worth noting that the use of the term macroprudential--and, it would seem, the influence of the concerns lying behind the term--was somewhat irregular in the three decades after it was coined. Discussion of the concept and its implications for regulation was more likely to be found in the papers of a few academics and intrepid BIS researchers than in the pronouncements of senior regulators or other official sector representatives. One important exception is a speech delivered in September 2000 by the late Andrew Crockett, then the General Manager of the BIS.7 For several reasons, that speech is a good point of reference for us today--as a nod to Sir Andrew's foresight, as an occasion for regret that his words were not more closely heeded by regulators,8 and as a way of illustrating how the challenge of macroprudential financial regulation has grown in the years since.\n\nSir Andrew's speech contained much that is now familiar and broadly accepted, but was fairly uncommon at the time: He distinguished between the objectives of microprudential regulation--protecting against idiosyncratic risk in a bank--and macroprudential regulation--protecting against systemic risk. He set forth a description of the financial cycle that could be read as a loose paraphrase of Hyman Minsky's theory of financial instability.9 He identified the procyclical and asset-correlation concerns regarding large bank activities that have commanded so much attention in the past several years. And, again foreshadowing many recent discussions, he suggested macroprudential tools both to increase resiliency (as through capital regulation with a systemic perspective) and to lean against the wind in an effort to slow or limit the growth of unsustainable asset bubbles (as through maximum loan-to-value ratio requirements).\n\nThe Crockett speech holds up very well today. With the benefit of the experience gained from the intervening financial crisis, an intense period of analysis from a macroprudential perspective, and a variety of regulatory initiatives, I offer these five propositions both to reinforce and to supplement the views Sir Andrew expressed 13 years ago.\n\nFive Propositions for a Macroprudential Approach to Regulating Financial Institutions\n1. A Macroprudential Perspective Should Dominate the Regulation and Supervision of Large Financial Institutions. Sir Andrew entitled his speech \"Marrying the Micro- and Macro-Prudential Dimensions of Financial Stability,\" suggesting an equal partnership between the two regulatory dimensions, as he called them. My own sense is that we need to concentrate our post-crisis efforts to reshape the regulation and supervision of large financial institutions on measures reflecting the macroprudential dimension, at least for a time. This view is consistent with the Congressional emphasis on financial stability and systemic risk considerations in the Dodd-Frank Wall Street Reform and Consumer Protection Act.10 \n\nTo be sure, idiosyncratic problems such as certain operational risks may threaten large institutions, and traditional regulation and supervision surely have an important ongoing role to play. But the dynamics observed during the financial crisis of highly correlated asset holdings, shared risks, and contagion among the largest firms suggest that the well-being of any one of these firms cannot be considered in isolation from the well-being of the system as a whole. Severe problems at such institutions are far more likely to arise from vulnerabilities to common stresses, and severe problems at such firms are far more likely to exacerbate systemic weaknesses. Since the health of any one of these large institutions is tied to the health of these firms as a group, good microprudential regulation may itself require a macroprudential dimension.\n\nThe reorientation of the Federal Reserve's supervision of large, complex financial firms is reflected organizationally in the Large Institution Supervision Coordinating Committee (LISCC). The LISCC was created three years ago to facilitate the execution of horizontal, cross-firm analysis of the largest firms and to centralize supervision of these firms so as to promote an integrated and consistent supervisory approach. The LISCC includes senior staff not only from the supervisory staffs of the Board and Reserve Banks, but also from the Board's Office of Financial Stability, Division of Monetary Affairs, Division of Research and Statistics, and other relevant divisions. This \"interdisciplinary\" approach to large bank supervision not only fosters more rigorous microprudential regulation, it also facilitates and formalizes a broader look at systemic risks by using quantitative methods to evaluate macroeconomic and financial risks, and how they could affect individual firms and the firms collectively.\n\n2. Building Greater Resiliency is Central to the Macroprudential Regulation of Large Financial Institutions. In early 2009 there was widespread doubt about the solvency of the financial system as a whole, particularly at many of the large firms that had directly or indirectly been deeply involved in mortgage markets and associated securitizations. When we created the first supervisory stress test on the fly, as it were, our aim was to stabilize, and restore confidence in, the financial system as a whole by ensuring that the 19 largest bank holding companies were sufficiently capitalized that they could continue serving as viable financial intermediaries. So the focus on resiliency was initially a matter of necessity.\n\nBut there is also logic to making the resiliency of the largest firms the most important part of our ongoing macroprudential regulatory agenda. Just as a microprudential approach to regulation has come to emphasize building up capital because it makes the individual firm better able to absorb losses from any source, including unpredictable ones, so an appropriately refocused set of macroprudential capital requirements can help make the financial system better able to withstand shocks from unanticipated, as well as familiar, sources. As mentioned by Andrew Crockett, a macroprudential perspective suggests two ways in which resiliency should be strengthened: the first is to treat the financial system as a whole as the \"portfolio\" of assets subject to safety and soundness oversight; the second is to apply stricter regulations on firms of systemic importance whose failure would carry a good chance of endangering the entire system. In the last four years, we have developed both kinds of measures to increase resiliency.\n\nFollowing our use of stress tests of the nation's 19 largest bank holding companies in the midst of the crisis, Congress included in the Dodd-Frank Act a requirement of annual supervisory stress tests for a larger group of firms: all those with greater than $50 billion in assets. These stress tests, and an associated supervisory review of the capital processes and practices of the covered firms, have in just a few years become a core part of the oversight of these large firms.\n\nOur stress testing program is one form of the first type of macroprudential resiliency measure. It also provides a good example of how sound microprudential regulation of the largest banking firms can be difficult to distinguish from regulation with a macroprudential orientation. Conventional capital requirements are by their nature somewhat backward-looking, reflecting loss expectations based on past experience and loss recognition that often occurs well after the likelihood of loss has become clear. Rigorous stress testing helps compensate for these shortcomings through a forward-looking assessment of the losses that would be suffered under stipulated adverse economic scenarios, so that capital can be built and maintained at levels high enough for the firms to withstand such losses and still remain viable financial intermediaries. This forward-looking aspect of stress testing automatically builds capital, and boosts resilience, in the face of weakening loan-underwriting standards because, for any given adverse scenario, weaker underwriting standards will imply higher losses. Also, because the firms are stressed simultaneously, supervisors are able to identify and take account of correlated exposures and other common risks.11 The firms covered by the Dodd-Frank Act supervisory stress tests account for more than 70 percent of U.S. banking sector assets, thus approaching Sir Andrew's standard of a supervisory perspective that examines the assets of the financial system as a whole.\n\nThe effectiveness of stress testing as a macroprudential tool depends, of course, on how the tests are constructed. For example, a macroprudential perspective must inform the construction of the scenarios against which the assets and revenues of the banks are stressed. Such a perspective argues for incorporating particular risks to the financial system even when there is some uncertainty regarding the probability of a particular risk being realized. For example, the scenario might include a sharp drop in house prices if analysis suggested--but did not confirm--that there was overheating in the housing market, and if supervisors judged that large banks had correlated exposures to the housing sector. That is, the stress tests provide for resiliency in the event the risk comes to pass, without necessarily requiring other measures to restrict directly the lending or other activity lying behind the risk.\n\nA macroprudential perspective also counsels against injecting more procyclicality into the financial system by, for example, simply assuming a standard deterioration in economic conditions from whatever the baseline projections might be. Such an approach would overlook the tendency of systemic risk to build during strong, prolonged expansions, when underwriting standards decline, rising asset prices make secured lending seem safer, and defaults wane. The approach we are instead taking is that, under such conditions, our severely adverse scenario would assume a level of unemployment during the stress period comparable to that observed in past severe recessions, not simply an increase in unemployment comparable to the increase observed during those recessions.12 Thus, the scenario's unemployment rate would feature a larger and sharper rise in the unemployment rate as economic expansions proceed.\n\nFinally, stress tests must be modified so as to avoid incentivizing firms to correlate their asset holdings or adopt correlated hedging strategies. This potential problem can be illustrated by reference to the market shocks we have applied to the trading books of the six largest financial firms in the last two stress tests. The shocks, designed to be severe, consisted of instantaneous, hypothetical jumps in asset prices based on those observed over the entire second half of 2008. The resulting trading losses are--as one would expect--quite large. Even so, had we simply used the same shocks that we used in the 2009 exercise, unchanged from the historical experience, we would have underestimated the potential losses associated with subsequent developments. For that reason, we modified the market shock scenario in 2011 to take account of Eurozone stress and then further modified the hypothesized stress in 2012 to include sharp moves in interest rates. We will continue to modify the market shock regularly to incorporate salient risks that were not necessarily present in 2008 and to ensure that firms cannot artificially improve their performance on the test through holding significant amounts of certain assets that happened to perform well in that period.\n\nThe second kind of macroprudential resiliency measure reduces the chances of distress or failure for financial companies of systemic importance to a greater degree than for other firms. Key provisions of Dodd-Frank aim at this form of resiliency. One extends the perimeter of regulation by authorizing the Financial Stability Oversight Council (FSOC) to subject nonbank financial companies to supervision and regulation by the Federal Reserve if the council \"determines that material financial distress\" at such a company, or its nature, size, or other characteristics or activities \"could pose a threat to the financial stability of the United States.\"13 Another requires the Federal Reserve to establish a broad set of enhanced prudential standards, both for bank holding companies with total consolidated assets of $50 billion or more and for nonbank financial companies designated by the FSOC as systemically important, \"[i]n order to prevent or mitigate risks to the financial stability of the United States.\"14 The required standards include capital requirements, liquidity requirements, stress testing, single-counterparty credit limits, an early remediation regime, and risk-management and resolution-planning requirements. These requirements are to increase in stringency in accordance with the relative systemic importance of the companies.\n\nThe capital surcharges that we will apply under this authority provide a clear example of this kind of macroprudentially motivated regulation. A microprudential requirement is informed by asking what level of capital would be necessary to allow the firm to remain a viable financial intermediary even after absorbing losses that, within a fairly high level of confidence, might be encountered over some relevant timeframe. A macroprudential capital requirement should take account of the fact that there would be very large negative externalities associated with the disorderly failure of any systemically important financial institution (SIFI), distinct from the costs incurred by the firm, its stakeholders, and the federal deposit insurance fund.\n\nAs already suggested, the failure of such a firm, especially in a period of stress, significantly increases the chances that other financial firms will themselves experience great stress, for two reasons. First, direct counterparty impacts can lead to a classic domino effect. Second, because losses in a tail event are much more likely to be correlated for firms deeply engaged in trading, structured products, and other capital market instruments, all such firms are vulnerable to accelerating losses as troubled firms sell their assets into a declining market. Enhanced capital requirements should take into account these costs. Thus, the aim of financial stability capital standards is to reduce further the probability that the firm might fail under stress through a requirement to hold additional capital. These additional capital requirements can also help offset any funding advantage derived from the perceived status of such institutions as too-big-to-fail.\n\nIn acting on this rationale for capital standards to mitigate risks to financial stability, we first sought to ensure that there would be an international initiative to develop financial stability capital standards for global systemically important financial institutions. The Basel Committee, an international body of supervisors that includes the U. S. banking agencies, took up this agenda and developed a framework covering more than two dozen large financial firms from around the world. Later this year, we will issue under the authority granted by Dodd-Frank a proposed set of capital surcharges congruent with that framework.\n\nThe task of determining how much additional capital is needed to reduce the probability of a systemically important firm's failure to more acceptable levels is not a straightforward one. In calibrating the surcharge, the Basel Committee, with a good bit of input from the Federal Reserve, began with what has been termed the \"expected impact\" approach, which calls for additional capital to reduce the probability of the firm's failure sufficiently to equalize the expected impact on the financial system of the failure of a systemically important firm and the failure of a banking firm just outside systemic status.15 But implementing this concept is complicated by the fact that, despite some very useful metrics that have been developed in the past few years for measuring the systemic risk associated with a particular firm, there is certainly no generally accepted approach.16 Indeed, differences among reasonable assumptions in applying the expected impact approach led to a fairly broad range of potential surcharges. The 1 to 2-1/2 percent amounts negotiated within the Basel Committee are at the low end of that range, reflecting a good deal of caution--frankly, more caution than I think would have been desirable, even given the uncertainties. Regardless of one's views on calibration, though, the motivation and methodology for what have become known as \"SIFI surcharges\" are clearly macroprudential.\n\nOne last point on macroprudential resiliency measures is that they can have secondary effects that serve the lean-against-the-wind aim of macroprudential policies. For example, a supervisory stress test can assign a higher loss rate to a certain class of assets in a hypothesized adverse scenario because they are particularly vulnerable to potential shocks and thus susceptible to particularly sharp declines in a serious recession. To the extent that firms learn over time that such assets will be treated that way, there is at least a mild disincentive to hold them. As I will discuss in a moment with respect to countercyclical capital requirements, we should not overstate this lean-against-the-wind effect, but perhaps not dismiss it out of hand either.\n\n3. Time-Varying Measures Will Play a More Limited Role. Some discussions of macroprudential policy appear to contemplate a somewhat regular adjustment--up and down--of both resiliency and lean-against-the-wind measures. The idea is to proceed in an intentionally countercyclical fashion by attempting to restrain rapid, unsustainable increases in credit extension or asset prices and to relax those restraints as economic conditions deteriorate. This is a conceptually appealing approach, but, as various commentators on macroprudential policy options have noted, one that raises a fair number of significant issues: the reliability of measures of excess or systemic risk, the appropriate officials to be making macroprudential decisions, the speed with which measures might realistically be implemented and take effect, and the right calibration of measures that will be effective in damping excesses while not unnecessarily reducing well-underwritten credit flows in the economy.\n\nIf the measures are designed to be targeted, questions of efficacy may be raised by those who believe that suppression of excess credit or asset price increases in one sector will likely result only in the redirection of credit and speculation to other sectors until underlying macroeconomic and financial conditions have ceased enabling such activities. If, on the other hand, the measures are designed to be fairly broad-based, the more basic question of the appropriate role of monetary policy may be raised by those who are focused on reactive policies that \"get in all the cracks\" of the financial system, not just the heavily regulated portion occupied by large financial firms.\n\nFinally, we should probably be skeptical as to how effective a macroprudential relaxation of regulatory requirements can be on the downside of economic cycles. Market discipline, which may have been lax in boom years, tends to become very strict when conditions deteriorate rapidly. Even if supervisors were to announce a relaxation in regulatory requirements, in stressed economic conditions, investors and counterparties may well look unfavorably on reductions in capital levels (even from higher levels) or relaxation of underwriting standards at any one firm, notwithstanding the potential benefits for the economy as a whole were all large firms to follow suit. Anticipating such a reaction, senior management of banks may thus have strong non-regulatory incentives to act as if microprudential regulation continued to dominate.\n\nIn short, the task of buffering the financial system against a tail event seems more tractable than that of moderating the financial cycle. But these questions of economic knowledge and institutional capacities should be grounds for proceeding cautiously, not for eschewing time-varying measures entirely. It is true that the state of the art of financial stability risk assessment is still in a relatively early stage. But it is reasonable to think that the amount of effort being put into these efforts in governments, central banks, international organizations, and universities will produce some well-conceived and well-tested metrics over time. Some deviations from historical patterns are, even under existing states of knowledge, surely clear enough to justify some action.\n\nMoreover, in the absence of time-varying macroprudential tools, the burden of systemic risk containment will rest entirely elsewhere. For time invariant measures to bear this burden, it might be necessary to have through-the-cycle constraints that strengthen financial stability at greater cost to economic activity. If a central bank is reluctant ever to use monetary policy in pursuit of financial stability goals at the expense of more immediate employment and price stability goals, the burden on time invariant measures would be large indeed. Even if financial stability objectives are effectively incorporated into monetary policy, monetary tightening will surely not be the correct response to most instances of increasing leverage or asset prices that raise macroprudential concerns. Well-developed time-varying measures might be effective in slowing the increase in systemic risk to give monetary policymakers more time to evaluate the need for a monetary policy response.\n\nThere are two obvious places to begin a considered development of time-varying tools. One is in the traditional supervisory oversight of practices at regulated institutions, as enhanced by the increasingly horizontal, interdisciplinary features of large bank supervision. Good supervision is always time-varying, in that it should respond to potential and growing problems in a directed fashion.17 The coordination engendered by the LISCC and parallel efforts facilitates the identification of potentially risky trends in, for example, underwriting certain forms of lending. The greater use of data, both for the regulated sector as collected by supervisors and for the economy as a whole as analyzed by our Office of Financial Stability, further increases the prospects of timely supervisory responses.\n\nI do not want to overstate the significance of this evolution in supervisory practice, however. For one thing, as was shown by the experience with commercial real estate lending guidance issued before the crisis, supervisory guidance is an imperfect tool. In addition to the issues surrounding real-time interventions mentioned earlier, that episode revealed the potential for substantial political resistance to supervisory actions directed at specific sectors. Still, with the institutionalization of financial stability concerns at the Federal Reserve and the FSOC, and with the ongoing improvements in relevant analytic capacities, there is room to develop this tool further.\n\nThe second place to work on time-varying tools is found in another element of the new capital regime, the countercyclical buffer provision of Basel III. This provision envisions an increase in the applicable risk-weighted capital requirements of financial companies by up to 2-1/2 percentage points when \"credit growth is excessive and is leading to the buildup of system-wide risk.\"18 While stress testing has a built-in degree of time-variance (since macroeconomic scenarios must be constructed annually), the countercyclical buffer is intended to be purely time variant, in that it is to be activated when, and only when, there is \"excess aggregated credit growth,\" a condition that the Basel Committee anticipates will occur only infrequently.19 \n\nThe principal macroprudential rationale of the countercyclical buffer is one of increasing resiliency: that the banking system as a whole will have enough capital to continue effective intermediation, even if a period of stress follows what turned out to be a period of unsustainable, rapid credit growth that leads to unusually high losses as asset prices plummet thereafter.20 The Basel Committee also noted that there could be a secondary, lean-against-the-wind effect if the higher capital requirements raise the cost of, and thus dampen, credit extension.\n\nIt is probably not surprising that the regulators represented on the Basel Committee have chosen capital requirements as a time-varying macroprudential tool. Capital regulation is central to prudential regulation and, as already noted, is being used in service of macroprudential objectives. Both regulators and financial institutions are accustomed to capital regimes (although the post-crisis changes have altered that regime quite significantly).\n\nStill, it is uncertain just how useful this tool will be.21 In addition to some of the limitations affecting use of all time-varying instruments, such as judging when leverage or asset prices have become excessive, it is quite blunt. If \"turned on,\" it would apply to all large banks in all parts of the country. So it would not be useful to deploy in response to asset bubbles or leverage in particular sectors, since the additional capital required for lending in those sectors would be no greater than in less frothy parts of the economy. Indeed, it could in some circumstances have the unintended effect of encouraging banks to do more lending in the booming areas of concern, at the expense of lending in more stable areas. The precise impact on bank lending behavior is further muddied by the one-year period given to build the additional capital cushion.\n\nThese potential shortcomings notwithstanding, the tool is available in the United States to the three federal bank regulatory agencies. It could, in fact, serve as a complement to the more targeted actions available through the supervisory process. The banking agencies included the countercyclical capital provision in the capital regulation to implement Basel III adopted this summer. However, because it will not take effect in the United States until 2016 and because other regulatory and supervisory tasks created by Dodd-Frank and other initiatives need to be completed more quickly, we have not yet built out this tool through policy statements or other institutional steps.\n\nFortunately, when we do turn to the countercyclical capital buffer, we should have the benefit of a good deal of thinking and experience by the Bank of England. The setting of countercyclical capital buffers is now committed to the Financial Policy Committee (FPC) under the reorganization of regulatory functions effected in the United Kingdom on April 1, 2013. The FPC is required to set forth a general statement of its policy and to make quarterly determinations of whether to impose or change a countercyclical buffer.22 I should note, however, that Parliament extended the countercyclical power beyond the broad measure in Basel III and also granted the FPC authority to direct increases in the risk-weights applicable to specific sectors judged to pose a risk to the financial system. While bank regulators in the United States certainly have similar authority as part of our broad power to set capital requirements, we have not to date considered, much less adopted, any regulation along these lines.\n\n4. High Priority to Developing Measures to Control the Structural Vulnerability Presented by Short-Term Wholesale Funding. The shared vulnerabilities of large banking organizations as a whole are underscored by something omitted from Sir Andrew's otherwise prescient speech: the potential for damaging fire sales, itself exacerbated by the prevalence of short-term funding. The use of short-term wholesale funding was hardly unknown among major financial firms in the 1990s, but broadened significantly thereafter, both within large firms and in sponsored entities such as the now infamous Structured Investment Vehicles (SIVs) used to fund asset-backed securities. This trend was a dramatic example of the ways in which traditional lending and capital market activities had become increasingly integrated and another example of how prudential regulation had not quickly enough adjusted to that trend.\n\nEarlier this week, as we reached the five-year anniversary of Lehman Brothers' failure, numerous retrospectives on the crisis reminded us of its multiple causes. But the practice of many firms, including all those with sizeable broker-dealers, of funding large amounts of assets with short-term wholesale funding was an accelerant of all the problems that had grown within the financial system. When questions arose about the quality of some of the assets on which short-term funding had been provided, investors who had regarded short-term secured lending as essentially risk-free suddenly became unwilling to lend against a wide range of assets. Then ensued the classic adverse feedback loop, as liquidity-strained institutions found themselves forced to sell positions, which placed additional downward pressure on asset prices, thereby accelerating margin calls on leveraged actors and amplifying mark-to-market losses for all holders of the assets.\n\nAlthough the amounts of short-term wholesale funding have come down from their pre-crisis peaks,23 this structural vulnerability remains, particularly in funding channels that can be grouped under the heading of securities financing transactions (SFTs).24 The use of such funding surely has the potential to increase again during periods of rapid asset appreciation and ready access to leverage. While SFTs are an important and useful part of securities markets, without effective regulation they can create a large run risk, and thus can increase systemic problems that may develop in various asset and lending markets.\n\nThe risks associated with short-term funding are as much or more macroprudential as they are firm-specific. From a microprudential perspective, SFTs are low risk, because the borrowing is short-dated, overcollateralized, marked-to-market daily, and subject to remargining requirements. Capital charges are low because credit risk is low. The Liquidity Coverage Ratio (LCR), recently adopted by the Basel Committee and soon to be implemented in the United States through a proposed rulemaking, is an important step forward for financial regulation, since it will be the first broadly applicable quantitative liquidity requirement for banking firms. But it, too, has a principally microprudential focus, since it rests on the implicit premise that maturity-matched books at individual firms present relatively low risks.\n\nWhile maturity mismatch by core intermediaries is a key financial stability risk in wholesale funding markets, it is not the only one. Even if an intermediary's book of securities' financing transactions is perfectly matched, a reduction in the intermediary's access to funding can force the firm to engage in asset fire sales or to abruptly withdraw credit from customers. The intermediary's customers are likely to be highly leveraged and maturity-transforming financial firms as well, and, therefore, may then have to engage in fire sales themselves. The direct and indirect contagion risks are high.\n\nThe dangers thus arise in the tail and apply to the entire financial market when normally safe, short-term lending contracts dramatically in the face of sudden and significant uncertainty about asset values and the condition of counterparties. A macroprudential regulatory measure should force some internalization by market actors of the systemic costs of this intermediation. As I have argued elsewhere, one or more such measures should be the highest priority in filling out reform agendas directed both at the largest institutions and at systemic risk more generally.25 \n\nOne reason I place a high priority on initiatives to address the vulnerability created by short-term wholesale funding is that the development of these and other structural measures does not depend so heavily on identifying when credit growth or asset prices in one or more sectors of the economy have become unsustainable. Instead, an externality analysis can help identify the points of vulnerability and guide the fashioning of appropriate regulations. Indeed, what I described as structural policies may be better suited to containing certain kinds of risks than would policies requiring regular adjustment. Obviously, judgment will still be needed to determine the degree of constraint to be imposed on relevant activities of large banking organizations. But unlike real-time measures--where time will presumably be of the essence if those measures are to be effective--the adoption of structural constraints can proceed with the full opportunity for debate and public notice-and-comment that attends the rulemaking process.\n\n5. Migration of Financial Activities Outside the Regulatory Perimeter Must be Closely Monitored. Whenever increased regulation of similar activities applies only to some firms, incentives increase for the unregulated actors to step up their engagement in those activities. The very considerable strengthening of capital, liquidity, and other regulations in the wake of the financial crisis has presumably created commensurately significant opportunities for just such a shift of activities toward firms not subject to prudential regulation. As more macroprudential regulations applicable to large financial firms come into effect, one can expect that market actors will be exploring possibilities for regulatory arbitrage.\n\nIn the short term, the potential for migration outside the perimeter of regulated firms may be somewhat limited, precisely because of the dominance of large commercial banks in certain lending markets, of large broker-dealers in intermediation in securities markets, and the absence of ready alternatives to the major clearing and custody banks. But, if the arbitrage gains promise to be high enough, over time, unregulated market actors may find ways to, for example, deal directly with one another in some forms of securities financing. New kinds of firms, perhaps acting solely as agents, might be formed to facilitate these direct transactions between unregulated firms.\n\nIt is for this reason that the Federal Reserve and our counterparts in other member countries of the Financial Stability Board have been evaluating ideas for market-wide measures even as we move forward with steps directed principally at prudentially regulated firms. Interest in broader, if not universal, regulatory charges on securities financing transactions has developed in recognition of the systemic risks that may develop if, for instance, only certain prudentially regulated firms must incorporate such a charge into their borrowing or lending activities.\n\nAs we make more progress in reorienting the regulation of large financial firms toward more macroprudential objectives, we will need to watch carefully for such leakage of financial transactions. This concern returns us to the larger project of macroprudential regulation, which implicates a more complicated set of issues around legal authorities and institutional capacities for prudential regulation of markets, as well as firms. But it would be preferable to confront these issues now, before too much of this migration has occurred, than to wait until the problem manifests itself in growing systemic risk.\n\nConclusion\nThe five propositions I have laid out this afternoon are generally intended to outline the contours of a macroprudential approach to the regulation and supervision of large financial institutions, not to identify or elaborate specific policies. But I will close by saying that specific policies to counteract the structural vulnerabilities created by short-term wholesale funding are a priority, not just for the stability of our large prudentially regulated institutions, but for the financial system as a whole. A macroprudential reorientation of our bank regulatory policies will require a range of continuing work on resiliency, on other structural measures, and on the effective blending of macroprudential with traditional microprudential regulatory and supervisory policies. But, even as we make more progress in these areas, our efforts will not be complete without measures addressing what I have termed an accelerant of systemic problems.\n \n\n1. Thus, for example, fiscal or tax policies would not be generally characterized as macroprudential tools, even though they could have implications for systemic risk in some circumstances. For useful overviews of macroprudential policy issues and debates, see International Monetary Fund (2011), \"Macroprudential Policy: An Organizing Framework (PDF),\" (Washington: International Monetary Fund, March 14); Gabriele Galati and Richhild Moessner (2011), \"Macroprudential policy--a literature review (PDF),\" BIS Working Paper No. 337 (Basel, Switzerland: Bank for International Settlements, February). Return to text\n\n2. For a recent study finding a correlation between the growth of credit aggregates and financial crises, and also suggesting a secular trend making such crises more of a risk, see Moritz Schularick and Alan M. Taylor (2012), \"Credit Booms Gone Bust: Monetary Policy, Leverage Cycles, and Financial Crises, 1870-2008,\" American Economic Review, vol. 102 (2), pp 1029-61. Return to text\n\n3. There is actually quite a rich history of policy measures in the United States that we would today call \"macroprudential.\" See Douglas J. Elliott, Greg Feldberg, and Andreas Lehnert (2013), \"The History of Cyclical Macroprudential Policy in the United States,\" Finance and Economics Discussion Series 2013-29 (Washington: Board of Governors of the Federal Reserve System, May). It is notable that the enactment and use of a number of tools waned as the integration of capital markets with traditional lending functions accelerated in the last quarter of the 20th century, though even if there is a causal relationship between these two phenomenon, it is not clear which way the causality runs (perhaps in both directions). Return to text\n\n4. The terminology may differ among commentators. For example, \"cross-sectional\" is sometimes used in place of interconnectedness, a term that may have some appeal to the extent it moves away from the traditional domino image of one failing firm knocking down another, and also embraces dynamics such as contagion across the financial system arising from correlated asset holdings and sources of funding. Return to text\n\n5. Piet Clement (2010), \"The term 'macroprudential': origins and evolution (PDF),\" BIS Quarterly Review (March), pp. 2-3. Return to text\n\n6. The establishment of federal deposit insurance and the separation of commercial banking from investment banking--two key elements of New Deal financial reforms--were very much directed at what would today be characterized as systemic risks. Return to text\n\n7. Andrew D. Crockett, General Manager of the Bank for International Settlements and Chairman of the Financial Stability Forum (2000), \"Marrying the Micro- and Macro-Prudential Dimensions of Financial Stability (PDF),\" speech delivered at the Eleventh International Conference of Banking Supervisors in Basel, Switzerland, September 21. Return to text\n\n8. Reading between the lines, one wonders whether Sir Andrew anticipated that his call for action might not be taken up by banking regulators. He styled his remarks as \"provocative\" and concluded by suggesting they were but \"a small awareness-raising step in what, if pursued, is likely to be a long road.\" Return to text\n\n9. Crockett, 2000 speech: \"A review of the instances of financial instability would reveal some shared stylised elements. There is first an over-extension phase during which financial imbalances build up, accompanied by benign economic conditions. In this phase, asset prices are buoyant and their surge tends to feed, and be fed by, rapid credit expansion, domestically or internationally. Leverage, in overt or hidden forms, accumulates in balance sheets, masked in part by the favourable asset price developments. The trigger for a reversal is essentially unpredictable. It can originate either in the financial sphere (e.g., an asset price correction) or in the real economy (e.g., a spontaneous unwinding of an investment boom). The process then moves into reverse. Ex post, a financial cycle is evident.\" Return to text\n\n10. Elsewhere I have discussed this emphasis at some length. See Daniel K. Tarullo (2012), \"Financial Stability Regulation,\" speech delivered at the Distinguished Jurist Lecture, University of Pennsylvania Law School, Philadelphia, PA, October 10. Return to text\n\n11. It is important to emphasize here, as we do in our annual capital reviews of large banking organizations, that our supervisory stress testing of all covered firms simultaneously does not supplant the need for firms to develop, and make capital decisions dependent upon, their own stress scenarios that incorporate risks more specific to the activities and portfolios of each firm. That is, the necessary emphasis on macroprudential measures at the present time does not obviate the need for solid microprudentially inspired measures. Return to text\n\n12. For a full explanation of the Board's approach to scenario design, see \"Policy Statement on the Scenario Design Framework for Stress Testing (PDF),\" Regulation YY--Enhanced Prudential Standards, 12 C.F.R. pt. 252 (2012). See also Nellie Liang (2013), \"Implementing Macroprudential Policies (PDF),\" speech delivered at the Conference on Financial Stability Analysis: Using the Tools, Finding the Data, Federal Reserve Bank of Cleveland and Office of Financial Research, May 31. Return to text\n\n13. Dodd-Frank Wall Street Reform and Consumer Protection Act, Pub. L. No. 111-203, 124 Stat. 1376 (2010), Section 113 (a)(1). Return to text\n\n14. Dodd-Frank Act, Section 165. Return to text\n\n15. For example, if the loss to the financial system from the failure of a systemically important firm would be five times that resulting from failure of the non-systemic firm, then the firm would have to hold additional capital sufficient to make the expected probability of failure one-fifth that of the non-systemic institution. Return to text\n\n16. Among the useful efforts along these lines are a measure of Conditional Value-at-Risk (CoVaR) (see Tobias Adrian and Markus K. Brunnermeier (2011), \"CoVaR (PDF),\" Federal Reserve Bank of New York Staff Reports 348 (New York: Federal Reserve Bank of New York, September), and a measure of systemic risk based on each firm's contribution to the expected capital shortfall of the entire financial system in a crisis (see Christian T. Brownlees and Robert F. Engle (2011), \"Volatility, Correlation and Tails for Systemic Risk Measurement,\" New York University Working Paper (New York: New York University, June). The concept behind the latter measure is also described in Viral V. Acharya, Christian Brownlees, Farhang Farazmand, and Matthew Richardson (2011), \"Measuring Systemic Risk,\" in Regulating Wall Street: The Dodd-Frank Act and the New Architecture of Global Finance (New York: Wiley Publishers), pp. 87–119. Updated systemic risk rankings are maintained by the authors here. A helpful review of the efforts to measure systemic risk is Monica Billio, Mila Getmansky, Andrew W. Lo, and Loriana Pelizzon (2010), \"Measuring Systemic Risk in the Finance and Insurance Sectors (PDF),\" MIT Sloan School Working Paper 4774-10 (Cambridge, MA: MIT Sloan School of Management, March). Return to text\n\n17. One should note that \"time-varying\" supervision should not mean excessively procyclical supervision. Return to text\n\n18. Basel Committee on Banking Supervision (2011), \"Basel III: A Global Regulatory Framework for More Resilient Banks and Banking Systems (PDF),\" (Basel, Switzerland: Bank for International Settlements, June), p. 57. Basel III introduced the concept of a capital \"buffer\" to supplement the long-established concept of minimum capital requirements. In brief, the idea is that a bank's distribution of capital to shareholders or employees will be progressively more restricted as capital levels fall below required buffers, but--unlike the case where capital levels fall below minimum requirements--a bank need not bring its capital levels above the buffer by shedding assets or raising new capital. Basel III introduced a \"fixed\" capital buffer of 2-1/2 percent of common equity on top of the 4-1/2 percent minimum capital requirement. The countercyclical capital buffer would be placed on top of the fixed buffer. If applied at its maximum 2-1/2 percent amount, the countercyclical buffer would thus require that a bank maintain equity capital of at least 9-1/2 percent of risk-weighted assets in order to remain unencumbered by restrictions on capital distributions. There is a view held by some that large banks would be under considerable market pressure to maintain their capital levels above the 7 percent total minimum requirement and fixed buffer (as well as the added systemic surcharge for those banks subject to it), even in stressed periods. Return to text\n\n19. Basel Committee on Banking Supervision (2011). Return to text\n\n20. Basel Committee on Banking Supervision (2010), \"Guidance for National Authorities Operating the Countercyclical Capital Buffer (PDF),\" (Basel, Switzerland: Bank for International Settlements, December), p. 1. Return to text\n\n21. For a useful discussion of the pros and cons of variants on countercyclical capital buffers, see Douglas J. Elliott (2011), \"An Overview of Macroprudential Policy and Countercyclical Capital Requirements,\" (Washington: The Brookings Institution, March 10). Return to text\n\n22. A draft policy statement was published even before the April 1, 2013, effective date of the new FPC authority. See Bank of England (2013), \"The Financial Policy Committee's powers to supplement capital requirements (PDF),\" (London, U.K.: Bank of England, January). Return to text\n\n23. In 2006, just before the onset of the stresses that eventually led to the financial crisis, the largest U.S. financial firms relied on short-term wholesale funding for about half their total funding needs, and deposits for just over one-third. Today (or, more precisely, as of the end of the second quarter of this year) those proportions are almost exactly reversed. Some of the change is likely due to changes in risk assessment and supervisory expectations.But it is also true that deposits were a safe haven for many households and non-household investors during the crisis. It may be that, as financial and economic conditions continue to normalize, households and other investors will move more deposits into other investment vehicles. Return to text\n\n24. Included in this grouping are repo, reverse repo, securities lending and borrowing, and securities margin lending. Return to text\n\n25. Daniel K. Tarullo (2013), \"Evaluating Progress in Regulatory Reforms to Promote Financial Stability,\" speech delivered at the Peterson Institute for International Economics, Washington, D.C., May 3. Return to text\n\n "
    },
    {
        "title": "Yield-Oriented Investors and the Monetary Transmission Mechanism",
        "date": "September 26, 2013",
        "speaker": "Governor Jeremy C. Stein",
        "url": "https://www.federalreserve.gov/newsevents/speech/stein20130926a.htm",
        "content": "September 26, 2013\n\nGovernor Jeremy C. Stein\n\nAt the \"Banking, Liquidity and Monetary Policy,\" a Symposium Sponsored by the Center for Financial Studies, Frankfurt, Germany\n\nWatch live\n\nLet me start by thanking the organizers for including me in this event. It's a great pleasure to be here with other old friends and colleagues to pay tribute to Raghu, and to congratulate him not only on winning the Deutsche Bank prize for Financial Economics, but also on his new job as governor of the Reserve Bank of India. It's an understatement to say that Raghu has a few challenges on his hands in this new role, but having known him for more than 20 years, I can't imagine anybody being better equipped--in terms of intellect, judgment, and strength of character--to handle these challenges.\n\nI would like to talk briefly about some recent research of mine, done jointly with Sam Hanson of Harvard Business School, on the monetary transmission mechanism.1 As will become clear, our work is heavily influenced by some of Raghu's earlier writing, and in particular his famous 2005 Jackson Hole paper.2 After describing what we find, I will try to draw some connections to the current monetary policy environment as well as some lessons about the interplay of monetary policy and financial stability. As always, I am speaking for myself, and my views are not necessarily shared by other members of the Federal Open Market Committee (FOMC).\n\nIn our paper, Sam and I begin by documenting the following fact about the working of conventional monetary policy: Changes in the stance of policy have surprisingly strong effects on very distant forward real interest rates. Concretely, over a sample period from 1999 to 2012, a 100 basis point increase in the 2-year nominal yield on FOMC announcement day--which we take as a proxy for a change in the expected path of the federal funds rate over the following several quarters--is associated with a 42 basis point increase in the 10-year forward overnight real rate, extracted from the yield curve for Treasury inflation-protected securities (TIPS).3 \n\nOn the one hand, this finding is at odds with standard New Keynesian macro models, in which the central bank's ability to influence real variables stems from goods prices that are sticky in nominal terms. In such models, a change in monetary policy should have no effect on forward real rates at a horizon longer than that over which all prices can adjust, and it seems implausible that this horizon could be on the order of 10 years. On the other hand, the result suggests that monetary policy may have more kick than is implied by the standard model, precisely because long-term real rates are the ones that are most likely to matter for a variety of investment decisions.\n\nSo what is going on? How, in a world of eventually flexible goods prices, is monetary policy able to exert such a powerful influence on long-term real rates? A first clue is that the movements in distant forward real rates that we document appear to reflect changes in term premiums, as opposed to changes in expectations about short-term real rates far into the future. Said differently, if the Fed eases policy today and yields on long-term TIPs go down, this does not mean that the real short rate is expected to be lower 10 years from now--but rather that TIPs have gotten more expensive relative to the expected future path of short rates. These changes in term premiums then appear to reverse themselves over the following 6 to 12 months.\n\nThis observation then raises the question of why monetary policy might be able to influence real term premiums. Here is where we draw our inspiration from Raghu's work, in particular his hypothesis that low nominal interest rates can create incentives for certain types of investors to take added risk in an effort to \"reach for yield.\" While an emerging body of empirical research investigates this hypothesis in the context of credit risk--documenting that banks tend to make riskier loans when rates are low--our focus is instead on the implications of the reach-for-yield mechanism on the pricing of interest rate risk, also known as duration risk.4 \n\nThe theory we sketch involves a set of \"yield-oriented\" investors. We assume that these investors allocate their portfolios between short- and long-term Treasury bonds and, in doing so, put some weight not just on expected holding-period returns, but also on current income. This preference for current yield could be due to agency or accounting considerations that lead these investors to care about short-term measures of reported performance. A reduction in short-term nominal rates leads them to rebalance their portfolios toward longer-term bonds in an effort to keep their overall yield from declining too much. This, in turn, creates buying pressure that raises the price of the long-term bonds and hence lowers long-term yields and forward rates.\n\nThus, according to this theory, an easing of monetary policy affects long-term real rates not via the usual expectations channel, but rather via what might be termed a \"recruitment\" channel--by causing an outward shift in the demand curve of yield-oriented investors, thereby inducing these investors to take on more interest rate risk and to push down term premiums.\n\nTo provide some evidence that bears on the theory, we look at the maturity of securities held by commercial banks. Banks fit with our conception of yield-oriented investors to the extent that they care about their reported earnings--which, given bank accounting rules for available-for-sale securities, are based on current income from securities holdings and not mark-to-market changes in value. And, indeed, we find that when the yield curve steepens, banks increase the maturity of their securities holdings. Moreover, the magnitudes of these portfolio shifts are large in the aggregate, so that if they had to be absorbed by other, less yield-oriented investors, the shifts could plausibly drive changes in marketwide term premiums. We also find that primary dealers in the Treasury market--who, unlike banks, must mark their securities holdings to market--take the other side of the trade, reducing the maturity of their Treasury holdings when the yield curve steepens.5 \n\nOverall, I read this evidence as suggesting--albeit tentatively--that some mechanism involving yield-oriented investors may eventually turn out to be central to our understanding of how monetary policy works, both in ordinary and extraordinary times. When I say \"central,\" I mean that this mechanism may play a role not only in determining how monetary policy influences the pricing of credit risk, but also in how it shapes the real and nominal yield curves for credit-risk-free Treasury securities. Of course, much work remains to be done before statements like these can be made with any degree of confidence. But I think there is a promising research agenda here, and one that owes much to Raghu's insights.\n\nWith these observations in mind, let me now turn to the events of the past few months in the bond market. A brief summary goes as follows: Long-term real and nominal rates and term premiums in the United States were very low as of early May, with the 10-year Treasury yield bottoming out at 1.63 percent at the beginning of the month, with an associated term premium estimated to be on the order of negative 0.80 percent.6 The 10-year TIPS yield reached negative 0.72 percent around the same time.7 However, following Chairman Bernanke's May 22 testimony to the Joint Economic Committee and after our June 18-19 FOMC meeting, yields rose sharply, with the nominal and real 10-year rates reaching 2.61 percent and 0.60 percent, respectively, as of June 25.8 \n\nIn the absence of a significant shift in policy fundamentals, a number of observers have highlighted the role of a variety of market dynamics in driving the observed changes in yields. These factors include the unwinding of carry trades, tightening of risk limits in the face of higher volatility, convexity hedging by holders of mortgage-backed securities, and large outflows from bond funds. I believe these factors to have been important collectively, although it is difficult to say how much of an effect is due to any one of them.\n\nHowever, beyond trying to understand the market dynamics that drove changes in rates over the period from May through June, it is also useful to ask a question about the starting levels: What explains why real and nominal rates were as low as they were at the beginning of May? Clearly, our accommodative policies--the combination of forward guidance and asset purchases--played an important role. But I want to draw a key distinction between two views of how our policies might have mattered. One view would be that the configuration of market rates in early May was largely a direct hydraulic outcome of our policies. For example, according to this view, a nominal 10-year yield of 1.63 percent in early May could be explained to a first approximation based on the expected path of the federal funds rate, plus a negative term premium that was itself primarily a function of the cumulative amount of duration that we were expected to remove from the market via our asset purchase program. Let's call this the \"direct Fed control\" view.\n\nAn alternative hypothesis is that our policies were indeed responsible for the very low level of long-term rates, but in part through a more indirect channel. According to this view, real and nominal term premiums were low not just because we were buying long-term bonds, but because our policies induced an outward shift in the demand curve of other investors, which led them to do more buying on our behalf--because we both gave them an incentive to reach for yield, and at the same time provided a set of implicit assurances that tamped down volatility and made it feel safer to lever aggressively in pursuit of that extra yield. In the spirit of my earlier comments, let's call this the \"Fed recruitment\" view.\n\nI take the events of the past few months to be evidence in favor of the recruitment view. And, to be clear, I don't mean this as a criticism of the set of policies that we have in place. Quite to the contrary--it can be useful to enlist help when you have a big job to do. Indeed, my whole point in talking about the research I described earlier was to underscore my belief that something like this investor-recruitment mechanism is central to how monetary policy acquires much of its traction over the real economy even in ordinary times. Of course, the magnitude of the effect--the extent of downward pressure that we may have been inducing other investors to apply to the term premium--is likely to have been more noteworthy given the unprecedented scope of our overall monetary accommodation. But in an important sense, this effect is just a powered-up version of what makes garden-variety monetary policy work.\n\nAgain, the existence of this recruitment channel is helpful; without it, I suspect that our policies would have considerably less potency and, therefore, less ability to provide needed support to the real economy. At the same time, an understanding of this channel highlights the uncertainties that inevitably accompany it. If the Fed's control of long-term rates depends in substantial part on the induced buying and selling behavior of other investors, our grip on the steering wheel is not as tight as it otherwise might be. Even if we make only small changes to the policy parameters that we control directly, long-term rates can be substantially more volatile. And if we push the recruits very hard--as we arguably have over the past year or so--it is probably more likely that we are going to see a change in their behavior and hence a sharp movement in rates at some point. Thus, if it is a goal of policy to push term premiums far down into negative territory, one should be prepared to accept that this approach may bring with it an elevated conditional volatility of rates and spreads.\n\nWhen we talk about the interplay of monetary policy and financial stability, I think that this kind of tradeoff is an important part of what we should be bearing in mind. Indeed, maybe the term \"financial stability\" is a bit misleading, because the risk scenario that I am describing--and that may be among the most relevant when thinking about the costs and benefits of our current highly accommodative policies--need not be one that is so dramatic as to call into question the viability of any large financial firm or threaten an important part of the market's infrastructure. Rather, one scenario to be worried about may simply be a sharp increase in marketwide rates and spreads at an inopportune time, such that it becomes harder for us to achieve our dual-mandate objectives.\n\nHaving said all of this, I believe we are currently in a pretty good place with respect to the pricing of interest rate risk. The movement in Treasury rates that we have seen since early May has led to somewhat tighter financial conditions in certain sectors--most notably the mortgage market--but has also brought term premiums closer into line with historical norms, and thereby has arguably reduced the risk of a more damaging upward spike at some future date. On net, I believe the adjustment has been a healthy one.\n\nFinally, let me say a few words about last week's FOMC meeting. I voted with the majority of the Committee to continue our asset purchase program at its current flow rate of $85 billion per month. It was a close call for me, but I did so because I continue to support our efforts to create a highly accommodative monetary environment so as to help the recovery along by using both asset purchases and our threshold-based approach to forward guidance.\n\nHow should the pace of purchases evolve going forward? The Chairman laid out a framework for winding down purchases in his June press conference.9 Within that framework, I would have been comfortable with the FOMC's beginning to taper its asset purchases at the September meeting. But whether we start in September or a bit later is not in itself the key issue--the difference in the overall amount of securities we buy will be modest. What is much more important is doing everything we can to ensure that this difficult transition is implemented in as transparent and predictable a manner as possible. On this front, I think it is safe to say that there may be room for improvement.\n\nAchieving the desired transparency and predictability doesn't require that the wind-down happen in a way that is independent of incoming data. But I do think that, at this stage of the asset purchase program, there would be a great deal of merit in trying to find a way to make the link to observable data as mechanical as possible. For this reason, my personal preference would be to make future step-downs a completely deterministic function of a labor market indicator, such as the unemployment rate or cumulative payroll growth over some period. For example, one could cut monthly purchases by a set amount for each further 10 basis point decline in the unemployment rate.10 Obviously the unemployment rate is not a perfect summary statistic for our labor market objectives, but I believe that this approach would help to reduce uncertainty about our reaction function and the attendant market volatility. Moreover, we would still retain the flexibility to respond to other contingencies (such as declines in labor force participation) via our other more conventional policy tool--namely, the path of short-term rates.\n\nThank you very much. I look forward to your questions.\n\n \n\n1. See Samuel G. Hanson and Jeremy C. Stein (2012), \"Monetary Policy and Long-Term Real Rates (PDF),\" Finance and Economics Discussion Series 2012-46 (Washington: Board of Governors of the Federal Reserve System, July). Return to text\n\n2. See Raghuram G. Rajan (2005), \"Has Financial Development Made the World Riskier? (PDF) \" in The Greenspan Era: Lessons for the Future, A Symposium Sponsored by the Federal Reserve Bank of Kansas City, Jackson Hole, Wyoming, August 25-27, 2005 (Kansas City: Federal Reserve Bank of Kansas City), pp. 313-69. Return to text\n\n3. Our findings can be illustrated with the events of January 25, 2012. On that date the FOMC changed its forward guidance, indicating that it expected to hold the federal funds rate near zero \"through late 2014,\" whereas it had previously only stated that it expected to do so \"through mid-2013.\" In response to this announcement, the expected path of short-term nominal rates fell significantly from two to five years out, with the 2-year nominal yield dropping 5 basis points and the 5-year nominal yield falling 14 basis points. More strikingly, 10-year and 20-year real forward rates declined by 5 basis points and 9 basis points, respectively. Return to text\n\n4. The idea that banks take on more credit risk when rates are low is explored in, for example, Gabriel Jiménez, Steven Ongena, José-Luis Peydró, and Jesús Saurina (forthcoming), \"Hazardous Times for Monetary Policy: What Do 23 Million Bank Loans Say about the Effects of Monetary Policy on Credit Risk-Taking? (PDF) \" Econometrica. Return to text\n\n5. Primary dealers are broker-dealer firms that serve as trading counterparties of the Federal Reserve Bank of New York in its implementation of monetary policy. Return to text\n\n6. The 10-year nominal rate hit 1.63 percent on May 2, 2013. The Kim-Wright term premium was estimated to be negative 0.78 percent on this day. (For more information on the term premium, see Don H. Kim and Jonathan H. Wright (2005), \"An Arbitrage-Free Three-Factor Term Structure Model and the Recent Behavior of Long-Term Yields and Distant-Horizon Forward Rates (PDF),\" Finance and Economics Discussion Series 2005-33 (Washington: Board of Governors of the Federal Reserve System, August). Return to text\n\n7. The 10-year real rate hit negative 0.72 percent on April 26, 2013. Return to text\n\n8. See Ben S. Bernanke (2013), \"The Economic Outlook,\" statement before the Joint Economic Committee, U.S. Congress, May 22; and Board of Governors of the Federal Reserve System (2013), \"Federal Reserve Issues FOMC Statement,\" press release, June 19. Return to text\n\n9. Information on the Chairman's June 19, 2013, press conference is available on the Board's website. Return to text\n\n10. To be clear, I am sketching out a broad concept, and many details would need to be filled in to make it operational--such as, what to do if the unemployment rate falls in one month and then later rises. Return to text"
    },
    {
        "title": "Brief Welcoming Remarks",
        "date": "October 02, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20131002a.htm",
        "content": "October 02, 2013\n\nChairman Ben S. Bernanke\n\nAt the \"Community Banking in the 21st Century,\" a Conference Co-sponsored by the Federal Reserve System and the Conference of State Bank Supervisors, St. Louis, Missouri\n\nI would like to welcome everyone to the inaugural Community Banking Research and Policy Conference, co-sponsored by the Federal Reserve System and the Conference of State Bank Supervisors (CSBS). I particularly want to thank the Federal Reserve and CSBS staff members who worked hard to organize this event. By bringing together community bankers, bank regulators, and researchers from academic institutions and government agencies, the conference will help us all to better understand the issues that are most important to the future of community banking. You may have noticed that I referred to this as the \"inaugural\" conference. Although firm plans have not yet been made, I do hope this will be the first of many joint Federal Reserve System and CSBS conferences that focus on community banking research and policy.\n\nThe U.S. banking system has undergone significant consolidation over the past two decades or so, with very large banking organizations increasing their market shares. Nevertheless, community banks (which we typically define as banking institutions with assets of $10 billion or less) continue to provide vital financial services to households, small businesses, and small farms in communities across America.\n\nCommunity banking is fundamentally a local, relationship-based business. Community bankers live in the localities they serve; their customers are their neighbors and friends. Their direct, personal knowledge of the local economy enables them to tailor products and services to meet their communities' needs. They can look beyond credit scores and other model-based metrics to make lending decisions in part based on more qualitative information that large regional or national financial institutions are less well suited to consider. Community bankers recognize that their own success depends on the health of the communities they serve, which is why so many community bankers contribute locally as citizens and leaders as well as in their capacities as lenders and providers of financial services. The photos that you see around the conference center do a very nice job of capturing the spirit of community banking and illustrating the contributions of community bankers.\n\nAlthough community banks have some natural advantages, such as local knowledge and relationships, they also face significant challenges. As battle-scarred survivors of a financial crisis and deep recession, community bankers today confront a frustratingly slow recovery, stiff competition from larger banks and other financial institutions, and the responsibility of complying with new and existing regulations. Some observers have worried that these obstacles‑‑particularly complying with regulations‑‑may prove insurmountable. My colleagues at the Federal Reserve and I understand these concerns, and we are committed to crafting supervisory policies and regulations that are appropriately scaled to banks' size and complexity. And we have confidence that the remarkable resilience of America's community bankers will enable them not only to survive, but also to thrive in the years ahead.\n\nThe best way to understand the challenges that community bankers face is to talk to the bankers themselves, and we at the Federal Reserve do that regularly. For example, to ensure that we remain mindful of the unique characteristics of community banks, the Federal Reserve Board established the Community Depository Institutions Advisory Council. This council is composed of representatives of community banks, thrifts, and credit unions from each of the 12 Federal Reserve Districts. Members of the council meet with the Board twice a year, bringing to us the views and concerns of their colleagues back home. Our meetings with the council have been extremely informative and have improved our ability to understand and respond to community bank concerns.\n\nOf course, understanding those concerns is of limited value unless we use what we have learned in the process of rulemaking. To make that connection, we also established a subcommittee of the Board that reviews all regulatory and supervisory proposals for their potential effects on community banks. The subcommittee also has worked toward communicating more effectively with the industry regarding the extent to which new rules and guidance do, or do not, apply to community banks. I hope those efforts are helping community bankers avoid spending time trying to understand rules that do not apply to them.\n\nOne of the strengths of the Federal Reserve System is the quality of the research done by our economists and other professionals. The research we do on community banking helps guide our thinking on regulatory matters and on broader economic trends. In particular, the Board's subcommittee on community banking is regularly briefed on relevant research being conducted across the System. Thus, research findings inform policy, and policy concerns guide research. In fact, after learning about several research projects, the subcommittee suggested that the staff hold a community banking research conference--a suggestion that brought all of us to St. Louis today.\n\nThe range of topics that will be covered over the next day and a half is impressive. The first research session this afternoon will focus on the role of community banks in our financial and economic system. Papers in this session examine whether community banks influence new-firm survival, whether equipment finance is a potential growth area for community banks, how community bank failures affect local economic performance, and whether community bank lending relationships in rural areas are fundamentally different from those in urban areas.\n\nTwo research sessions are scheduled for tomorrow morning. The first will consider community bank performance, with papers looking at the effect of financial derivatives on community bank profitability, the characteristics of community banks that recovered from significant financial distress, the effect of distance between merging banks on postmerger performance, and the determinants of differences in profitability across community banks. The second session will consider issues of bank supervision and regulation, with papers discussing variations in the stringency of bank examination standards over time and their effect on lending, the effects of the Dodd-Frank Act on community banks, the relationship between community bank capital ratios and the likelihood of failure, and an approach for rationalizing bank supervision and regulation.\n\nAs you can see, the papers at this conference cover a variety of important topics, and I expect they will provoke spirited discussions among the many experts in attendance. I must say that I am encouraged to see so many researchers from a wide range of academic and government institutions working on issues of great interest to both community bankers and their regulators.\n\nTo close the conference, CSBS Chairman Charles Vice will present a report summarizing information gathered from more than 1,500 community bankers attending town hall sessions across the country over the past several months. In addition, a panel of community bankers will share their own views on the state of community banking and prospects for the future.\n\nThank you for being here. I wish you an enjoyable and productive conference."
    },
    {
        "title": "Community Banking: Connecting Research and Policy",
        "date": "October 03, 2013",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20131003a.htm",
        "content": "October 03, 2013\n\nGovernor Jerome H. Powell\n\nAt the Federal Reserve/Conference of State Bank Supervisors, Community Banking Research Conference, St. Louis, Missouri\n\nLive webcast\n\nGood afternoon. I am delighted to have the opportunity to participate in this inaugural conference on community banking research and policy. By way of introduction, I have spent most of my career in the private sector, including many years as an investor in small and medium-size companies. Although I have never worked in a community bank, I have been a customer, and I know from personal experience the special skills that these institutions bring to their customers. Community banks are a crucial part of our economy and the fabric of our society.\n\nMy colleagues on the Board of Governors and I understand the value of having a diverse financial system that includes a large and vibrant contingent of community banks. By fostering the economic health and vitality of local communities throughout the country, community banks play a central role in our national economy. One important aspect of that role is to serve as a primary source of credit for the small businesses that are responsible for creating a substantial proportion of all new jobs. A thriving community banking sector is essential to sustaining our ongoing economic recovery.\n\nCommunity banks have faced significant challenges in recent years, as our nation has endured a major financial crisis and recession, followed by a painfully slow recovery. To make matters worse, community bankers, who played no part in causing the financial crisis, have been forced to fight to ensure that they are not swept up in a torrent of costly new regulations that were intended to address problems at those very large banks that did contribute to the crisis. The Federal Reserve will continue to be alert to the possible unintended consequences of regulatory policies, and we welcome input from community bankers as we develop and implement those policies.\n\nWe have established a number of channels of communication to facilitate such input. For starters, the Reserve Banks have long had programs in place to provide training and guidance to banks in their districts. Recently, some of these programs have been expanded nationwide. For example, our host, the Federal Reserve Bank of St. Louis, organizes national “Ask the Fed” calls to provide an opportunity for bankers all over the country to hear Federal Reserve staff discuss timely financial or regulatory topics and to ask questions on these topics. Similarly, for consumer compliance issues, the Federal Reserve Bank of San Francisco hosts a national webinar series called “Outlook Live,” which complements the “Consumer Compliance Outlook,” a quarterly publication sponsored by the Federal Reserve Bank of Philadelphia. In addition, the Federal Reserve recently launched “Community Banking Connections,” a website that serves as a “one-stop shop” for information on issues that affect community banks, as well as providing links to tools and resources that can help them.\n\nAnother recently established communication channel is the Community Depository Institutions Advisory Council (CDIAC).[1] The council, which is made up of representatives of smaller banks, credit unions, and savings associations from each of the 12 Federal Reserve Districts, meets with the Board of Governors in Washington twice a year. These meetings allow the Board to gather firsthand information from community bankers about issues that concern them most and about economic conditions in their areas.\n\nIn addition, the Board of Governors has a community bank subcommittee of our Committee on Bank Supervision that oversees the supervision of community banks and reviews regulatory proposals to ensure they are appropriately tailored for community banks. The subcommittee also meets with Federal Reserve staff to hear about ongoing research in the community banking area. As a new member of this subcommittee, I look forward to helping ensure that community bank concerns receive the attention they deserve in every Federal Reserve policy decision. I also look forward to having the opportunity to help shape the important community banking research that is being conducted by staff across the Federal Reserve System.\n\nAs Chairman Bernanke mentioned yesterday, this conference was conceived as a result of discussions that took place during a community bank subcommittee meeting. I don’t know about you, but I think that, so far, the conference has been a great success. The quality and policy-relevance of papers presented here have been excellent. This work will, no doubt, spur continued research as well as policy discussions about ways in which we can better tailor regulations to meet our legal and prudential goals while reducing burdens on smaller financial institutions.\n\nIn my view, the research presented at this conference reaffirms the importance of community banks to our economy. In the rest of my talk, I’ll try to summarize and tie together what I’ve learned from the research that has been presented,[2] suggest some areas where further research would be helpful, and discuss what I believe should be the focus for supervision and regulation of community banks going forward.\n\nYesterday afternoon’s session on the role of community banks provided ample evidence of their continued viability and importance. The Lee and Williams paper provides evidence of the importance of small businesses to job creation in our economy and the important contribution that community bank lending makes to the survival of small businesses. Focusing on start-ups, Lee and Williams find that proximity to a community bank increases the likelihood that a new small business uses bank credit to finance its operations. Their findings support the importance of local knowledge and “soft information” that emerges from a bank’s relationship with its customers in underwriting loans to particularly opaque small businesses.\n\nDeYoung and his coauthors look at differences in loan default rates across community banks and find that banks in rural areas make loans that default less often than loans made by community banks in urban areas. They also find that loans made outside of a bank’s local area default at higher rates than do local loans. Both results can be interpreted as showing the value of banking relationships, because loans default less often in situations in which soft information is likely to be more available to the lender.\n\nIf any doubt remains about the importance of community banks to local economies, the Kandrac paper looks at the extreme situation in which a community bank fails, and documents the subsequent harm to local economic growth resulting from that failure. Of particular relevance to regulators, Kandrac points out that the effect of a bank’s failure on the local economy differs depending on the resolution method. In particular, he finds that resolutions that include loss-sharing agreements tend to have smaller negative effects on local economic growth than resolutions that do not include such agreements; Kandrac attributes these differences to the greater harm done to banking relationships when there is no loss-sharing agreement.\n\nIn another result, Kandrac finds that relationship lending appears to be stronger in local markets where banking competition is more intense. This is a contribution to a substantial economic literature that has discussed whether there is a conflict between the desire of antitrust authorities to maintain competitive markets and the desire to foster productive long-term relationships between small businesses and their lenders. Kandrac’s finding of no conflict is reassuring for those of us charged with both encouraging economic growth and enforcing antitrust statutes.\n\nThe Kelly, Khayum, and Price paper notes that there has been more emphasis in recent years on the challenges facing community banks than on the opportunities available to them. Given the success that community banks have enjoyed in lending to small businesses, this paper explores the possibility that these institutions could expand their involvement in business equipment leasing, a potential growth area that community banks might want to investigate. The authors find that community banks that are actively involved in lease financing are more profitable and efficient than other community banks.\n\nThis morning’s first session on community bank performance highlighted the heterogeneity of community banks. The Shen and Hartarska paper notes that while use of financial derivatives by community banks has increased rapidly in recent years, only about one in six community banks were active users of derivatives markets in 2012. Shen and Hartarska estimate that community banks could improve their profitability and reduce their risk of default through increased use of derivatives. They also point out that implementation of the Dodd-Frank Act--in particular the Volcker rule--could prevent the realization of these gains, although I should note that the Volcker rule includes an exception for hedging activities that is intended to allow banking organizations of all sizes to appropriately manage their risks. This is an important point to bear in mind. I believe we are doing so in drafting the regulation and that implementation of the Volcker Rule should not prevent community banks from using derivatives to manage their risks in a safe and sound manner.\n\nGilbert, Meyer, and Fuchs have completed two important studies on the experiences of community banks during the recent recession. Their first paper looked at banks that thrived throughout that period of economic distress while the second paper, presented this morning, looks at community banks that endured some level of financial distress during the downturn but then recovered. This research goes beyond statistical analysis to conduct interviews with a sample of bank presidents and CEOs to gain further insight into banks’ unique experiences in recent years. They identify two paths to recovery from financial distress. The first is a return to conservative underwriting practices and sound policies and practices, work that can provide a “road map” for community bankers to follow when confronted with the next--one hopes, less extreme--financial downturn. The second path to recovery is a change of bank ownership or management.\n\nConsolidation among community banks has been a constant theme in recent decades, and the Ferrier and Yeager study yields some interesting results on the profitability of community bank acquisitions and reorganizations. Their findings on bank acquisitions echo both the findings of DeYoung and his coauthors and the wisdom of many community bankers, namely that you increase your profits by sticking to what you know. Post-acquisition performance of community banks is better, the closer the target bank is to the acquirer. While more-distant acquisitions might lead to greater diversification benefits, these appear to be outweighed by the greater difficulties in managing the performance of two banks operating far apart from each other.\n\nI should note that these findings could conflict to some extent with the antitrust responsibilities of financial regulators and the Department of Justice. While a merger with a crosstown rival might lead to the greatest efficiency gains, the Federal Reserve has a statutory responsibility to make sure that such consolidations leave a sufficient number of local firms to ensure a competitive banking environment.\n\nCommunity bank profitability is affected by both external factors outside of bank control, such as local economic conditions, and factors within bank control, such as the composition and stability of the bank’s loan portfolio. The paper by Amel and Prager examines the effects of these two sets of factors on bank profitability over the past 20 years. They find that local economic conditions and demographic changes certainly affect bank profitability, but also that the quality of bank management and the stability of bank portfolio composition consistently have a very substantial impact on a bank’s level of profits. They find that any major change in a bank’s portfolio composition tends to lower bank profits, indicating yet again that banks tend to be better off when they stick to the markets and products that they know.\n\nThe papers in this morning’s second session on supervision and regulation of community banks are of great interest to me, given my current responsibilities on the community bank subcommittee at the Board. The papers in this session stress the need for flexibility in bank regulation and the need--subject to the constraints imposed by Congress--to tailor regulations to fit banking organizations that cover a huge range, from quite simple to extraordinarily complex.\n\nThe paper by Bassett, Lee, and Spiller provides reassuring evidence that CAMELS standards have been quite consistent over time, with no indication that CAMELS ratings were unduly stringent during the recovery from the recent recession. However, they do find that there was a slight tendency for exam ratings to become more stringent as we entered both the recession of the early 1990s and the one we just experienced. This finding should be brought to the attention of our examiners, because even a slight tightening of standards can have a significant effect on credit markets, especially if combined with other supervisory actions, and a tightening at the beginning of a recession could cause it to be deeper or longer than might otherwise be the case.\n\nMarsh and Norman highlight the need to avoid requiring excessive standardization of bank loans. Such standardization could interfere with effective relationship lending, and as we’ve seen from the research I’ve already discussed, that relationship lending is a key aspect that makes community banks such valuable assets to small businesses and so important to a thriving economy. The Marsh and Norman paper stresses that, to the extent the laws allow, we should reduce compliance costs for community banks, such as by simplifying capital rules for smaller banks and relying on market incentives, when feasible. The Moore and Seamans results from their failure-prediction model contribute to this discussion by demonstrating that simple capital ratios do a good job of identifying those community banks with the greatest probability of failure, so that regulators need not unduly impede the actions of the great majority of community banks that are highly unlikely to fail. Meanwhile, the Rosenblum and Organ paper argues for an alternative approach to addressing “too big to fail” that the authors suggest would benefit community banks by creating a more level playing field.\n\nAlthough both the traditional bank regulatory agencies and the Consumer Financial Protection Bureau (CFPB) are constrained, to some extent, by the language in the Dodd-Frank Act, all regulators should aim to ensure that we are not unduly rigid in our actions. Indeed, some steps have already been taken with that goal in mind. For example, the federal banking agencies carefully considered the thousands of comments received from community bankers regarding three notices of proposed rulemaking for revisions to the capital framework. In response to these comments, the agencies reduced and simplified many of the proposed changes to the risk-based capital rules that apply to community banks. And the CFPB has shown an openness to input from the industry and from other regulators in crafting its regulations.\n\nIn our role as a bank supervisor, the Federal Reserve has been refining our examination programs and recently launched an initiative to review our consumer compliance supervision program for community banks. While Federal Reserve consumer compliance examiners have traditionally applied a risk-driven approach to supervision, we recognized the need to provide more specific guidance to our examiners. Under the updated program, our consumer compliance examiners will base the examination intensity more explicitly on the individual bank’s risk profile, including its consumer compliance culture and how effectively it identifies and manages consumer compliance risk. We plan to launch this new consumer compliance supervision program for community banks in 2014. We will begin training for our examiners and outreach to our member community banks later this year.\n\nWhile this conference has presented much valuable research of direct relevance to community bankers, I’d like to recommend a few areas where further work could be of value. First, it would be interesting to explore the effects of risk-retention policies on community banks. To what extent do community banks currently retain a percentage of their loans, and how do small banks compare to money-center banks when it comes to utilizing the secondary markets for loans? Would risk-retention policies be a non-issue for community banks, or would some banks be seriously constrained by such policies? Even if such policies do not constrain community bank activities, would new reporting requirements related to such policies increase the reporting burden faced by small banks?\n\nThese questions point to a more general area in which more research could be useful, namely a detailed examination of the compliance costs for community banks that can highlight the most beneficial areas for regulatory relief. The Dodd-Frank Act has spawned a variety of new regulatory initiatives that add to the already-substantial regulatory burden faced by community banks. Which regulations--whether new or existing--impose the greatest regulatory burden compared to their benefits? Can regulatory agencies modify or provide exemptions to these regulations so as to make life a bit easier and more profitable for community banks, without adversely affecting bank safety and soundness or financial stability?\n\nTo give just one example, one area in which new regulations are being developed involves incentive compensation. This area seems to me to be of much more concern when we consider a money-center bank with thousands of shareholders, none of whom has a major stake, than when we consider a community bank in which management has a large or even majority ownership share. Before imposing more regulatory burden on smaller banks in this area, I would like to understand whether there is any evidence that incentive compensation has caused excessive risk taking in such institutions.\n\nWe are nearing the end of the rulemaking phase of Dodd-Frank and our changes on capital standards, at least those regulations that most directly affect community banks. While we have tried to tailor rules to the size and complexity of institutions, we may not have gotten the balance right in every instance. Thus we will continue to assess the overall effects of the new rules on the safety and soundness of community banks and to consider whether modifications to rules, or the ways in which we implement them, could achieve our safety and soundness aims with a lesser burden on this class of depository institutions. We, of course, would value any observations and suggestions you have along these lines.\n\nMy fellow governors and I encourage community bankers to use all the available communication channels to share with us their insights and concerns regarding new and existing regulations. And I promise that their voices will be heard in Washington when policy issues that may affect the ability of community banks to thrive are under consideration. While community banks certainly face challenges, I do not see their future as bleak. Community banks continue to do a good job of attracting core deposits, and those stable and relatively inexpensive deposits remain the most sought-after liability on bank balance sheets. However, many of the asset classes that traditionally comprised much of community bank portfolios have faced increasing competition in recent decades from firms that operate at the national level. As auto, mortgage, and credit card loans have become increasingly standardized, community banks have had to focus to a greater extent on small business and commercial real estate lending--products where community banks’ advantages in forming relationships with local borrowers are still important. These are not cheap or easy loans to make, and the loss of some traditional product lines has threatened the stability of some community banks. It is incumbent on the Federal Reserve and other regulators to understand the challenges community banks face and to ensure that our regulatory policies do not exacerbate them.\n\nI look forward to hearing from the community bankers who will be participating in the conference’s final session. Thank you for your attention and for your participation in this inaugural community banking conference. I would be happy to take some questions from the audience.\n\n1. For more information on CDIAC, see www.federalreserve.gov/aboutthefed/cdiac.htm. Return to text\n\n2. Abstracts of papers presented at the conference are available on the Federal Reserve Bank of St. Louis website. Return to text"
    },
    {
        "title": "The Fire-Sales Problem and Securities Financing Transactions",
        "date": "October 04, 2013",
        "speaker": "Governor Jeremy C. Stein",
        "url": "https://www.federalreserve.gov/newsevents/speech/stein20131004a.htm",
        "content": "October 04, 2013\n\nGovernor Jeremy C. Stein\n\nAt the Federal Reserve Bank of New York Workshop on Fire Sales as a Driver of Systemic Risk in Triparty Repo and other Secured Funding Markets, New York, New York\n\nThank you. It's a pleasure to be here at this workshop. In an effort to provide some broad framing for the sessions to follow, I thought I would try to do three things in my opening remarks.1  First, I will briefly discuss the welfare economics of fire sales. That is, I will try to make clear when a forced sale of an asset is not just an event that leads to prices being driven below long-run fundamental values, but also one that involves a market failure, or externality, of the sort that might justify a regulatory response. Second, I will argue that securities financing transactions (SFTs) are a leading example of the kind of arrangement that can give rise to such externalities, and hence are particularly deserving of policy attention. And third, I will survey some of the recently enhanced tools in our regulatory arsenal (e.g., capital, liquidity, and leverage requirements) and ask to what extent they are suited to tackling the specific externalities associated with fire sales and SFTs. \n\nTo preview, a general theme is that while many of these tools are likely to be helpful in fortifying individual regulated institutions--in reducing the probability that, say, a given bank or broker-dealer will run into solvency or liquidity problems--they fall short as a comprehensive, marketwide approach to the fire-sales problem associated with SFTs. In this regard, some of what I have to say will echo a recent speech by my Board colleague Daniel Tarullo.2 \n\nThe Positive and Normative Economics of Fire Sales\nIn a recent survey paper, Andrei Shleifer and Robert Vishny write that: \"…[A] fire sale is essentially a forced sale of an asset at a dislocated price. The asset sale is forced in the sense that the seller cannot pay creditors without selling assets….Assets sold in fire sales can trade at prices far below value in best use, causing severe losses to sellers.\"3  Shleifer and Vishny go on to discuss the roles of investor specialization and limited arbitrage as factors that drive the magnitude of observed price discounts in fire sales, and there is, by now, a large body of empirical research that supports the importance of these factors. \n\nHowever, by itself, the existence of substantial price discounts in distressed sales speaks only to the positive economics of fire sales, not the normative economics, and hence is not sufficient to make a case for regulatory intervention. To see why, consider the following example: An airline buys a 737, and finances the purchase largely with collateralized borrowing. During an industry downturn, the airline finds itself in distress, and is forced to sell the 737 to avoid defaulting on its debt. Other airlines also are not faring well at this time, and are not interested in expanding their fleets. So the only two bidders for the 737 are a movie star, who plans to reconfigure it for his personal use, and a private-equity firm, which plans to lease out the plane temporarily and wait for the market to recover so the firm can resell it at a profit. In the end, the private-equity firm winds up buying the plane at half its original price. Two years later, it does indeed resell it, having earned a 60 percent return.\n\nThis is clearly a fire sale in the positive-economics sense, but is there a market failure here that calls for regulation? Intuition suggests not. The airline arguably caused the fire sale by using a lot of leverage in its purchase of the 737, but it also seems to bear most of the cost, by being forced to liquidate at a large loss. The movie star and the private-equity firm are, if anything, made better off by the appearance of a buying opportunity, and there are no other innocent bystanders. So the airline's ex ante capital structure choice would seem to internalize things properly; the fire sale here is just like any other bankruptcy cost that a firm has to weigh in choosing the right mix of debt and equity.\n\nFor a fire sale to have the sort of welfare effects that create a role for regulation, the reduced price in the fire sale has to hurt somebody other than the original party making the leverage decision, and this adverse impact of price has to run through something like a collateral constraint, whereby a lowered price actually reduces, rather than increases, the third party's demand for the asset.4  So if hedge fund A buys an asset-backed security and finances it largely with collateralized borrowing, A's fire selling of the security will create an externality in the conventional sense only if the reduced price and impaired collateral value lower the ability of hedge funds B and C to borrow against the same security, and therefore force them to involuntarily liquidate their positions in it as well.5  The market failure in this case is not simply the fact that this downward spiral causes a large price decline, it is that when hedge fund A makes its initial leverage choice, it does not take into account the potential harm--in the form of tightened financing constraints--that this may cause to hedge funds B and C.6 \n\nAnother key point is that the fire-sales problem is not necessarily caused by a lack of appropriate conservatism on the part of whoever lends to hedge fund A in this example--let's call it dealer firm D. By lending on an overnight basis to A, and with an appropriate haircut, D can virtually assure itself of being able to terminate its loan and get out whole by forcing a sale of the underlying collateral. So D's interests may be very well-protected here. But precisely in the pursuit of this protection, A and D have set up a financing arrangement that serves them well, but that creates a negative spillover onto other market participants, like B and C. It follows that even if policies aimed at curbing too-big-to-fail (TBTF) problems are entirely successful in aligning D's interests with those of taxpayers, this is not sufficient to deal with fire-sales externalities. They are a fundamentally different problem, and one that arises even absent any individually systemic institutions or any TBTF issues. \n\nFire-Sale Externalities in Securities Financing Transactions\nThe preceding discussion makes clear why SFTs, such as those done via repurchase (repo) agreements, are a natural object of concern for policymakers. This market is one where a large number of borrowers finance the same securities on a short-term collateralized basis, with very high leverage--often in the range of twenty-to-one, fifty-to-one, or even higher. Hence, there is a strong potential for any one borrower's distress--and the associated downward pressure on prices--to cause a tightening of collateral or regulatory constraints on other borrowers.\n\nI won't go into much detail about the institutional aspects of SFTs and the repo market. Instead, I will just lay out two stylized examples of SFTs that I can then use to illustrate the properties of various regulatory tools.\n\nExample 1: Broker-dealer as principal\nIn this first example, a large broker-dealer firm borrows in the triparty repo market--from, say, a money market fund--in order to finance its own holdings of a particular security. Perhaps the broker-dealer is acting as a market-maker in the corporate bond market, and uses repo borrowing to finance its ongoing inventory of investment-grade and high-yield bonds. In this case, the asset on the dealer's balance sheet is the corporate bond, and the liability is the repo borrowing from the money fund.\n\nExample 2: Broker-dealer as SFT intermediary\nIn this second example, the ultimate demand to own the corporate bond comes not from the dealer firm, but from one of its prime brokerage customers--say, a hedge fund. Moreover, the hedge fund cannot borrow directly from the money market fund sector in the triparty repo market, because the money funds are not sufficiently knowledgeable about the hedge fund to be comfortable taking it on as a counterparty. So instead, the hedge fund borrows on a collateralized basis from the dealer firm in the bilateral repo market, and the dealer then turns around and, as before, uses the same collateral to borrow from a money fund in the triparty market. In this case, the asset on the dealer's balance sheet is the repo loan it makes to the hedge fund.\n\nClearly, there is the potential for fire-sale risk in both of these examples. One source of risk would be an initial shock either to the expected value of the underlying collateral or to its volatility that leads to an increase in required repo-market haircuts (e.g., the default probability of the corporate bond goes up). Another source of risk would be concerns about the creditworthiness of the broker-dealer firm that causes lenders in the triparty market to step away from it.\n\nIn either case, if the associated externalities are deemed to create significant social costs, the goal of regulatory policy should be to get private actors to internalize these costs. At an abstract level, this means looking for a way to impose an appropriate Pigouvian (i.e., corrective) tax on the transactions.7  Of course, the tax must balance the social costs against the benefits that accompany SFTs; these benefits include both \"money-like\" services from the increased stock of near-riskless private assets, as well as enhanced liquidity in the market for the underlying collateral--the corporate bond market, in my examples.8  So in the absence of further work on calibrating costs and benefits, there is no presumption that the optimal tax should be large, only that it may be non-zero, and that it may make sense for it to differ across asset classes. \n\nCan Existing Regulatory Tools Be Used to Tax SFTs Efficiently?\nWith this last observation in mind, my next step is to run through a number of our existing regulatory instruments, and in each case ask: to what extent can the instrument at hand be used efficiently to impose a Pigouvian tax on an SFT, either one of the dealer-as-principal type or one of the dealer-as-intermediary type? As will become clear, the answer can depend crucially on both the structure of the transaction as well as the nature of the underlying collateral involved. Also, I should emphasize that nothing in this exercise amounts to a judgment on the overall desirability of any given regulatory tool. Obviously, even if risk-based capital requirements are not particularly helpful in taxing SFTs, they can be very valuable for other reasons. I am asking a different question: to what extent can the existing toolkit be used--or be adapted--to deal with the specific problem of fire-sale externalities in SFTs?\n\n1. Risk-based capital requirements\nCurrent risk-based capital requirements are of little relevance for many types of SFTs. In my Example 1, where the dealer firm holds a corporate bond as a principal and finances it with repo borrowing, there would be a capital charge on the corporate bond, but this capital charge is approximately independent of whether the corporate bond is financed with repo or with some other, more stable, form of funding. So there is no tax on the incremental fire-sale risk created by the more fragile funding structure.9 \n\nIn Example 2, in which the dealer is an intermediary with a matched book of repo borrowing and lending, there is, in principle, a capital requirement on its asset-side repo loan to the hedge fund. However, the Basel III risk-based capital rules allow banks and bank holding companies to use internal models to compute this capital charge for repo lending, and the resulting numbers are typically very small--for all practical purposes, close to zero--for overcollateralized lending transactions, with repo being the canonical example.\n\nI'm not arguing that the very low risk-based charges on repo lending in Basel III are \"wrong\" in any microprudential sense. After all, they are designed to solve a different problem--that of ensuring bank solvency. And if a bank holding company's broker-dealer sub makes a repo loan of short maturity that is sufficiently well-collateralized, it may be at minimal risk of bearing any losses--precisely because it operates on the premise that it can dump the collateral and get out of town before things get too ugly. The risk-averse lenders in the triparty market--who, in turn, provide financing to the dealer--operate under the same premise. As I noted earlier, these defensive reactions by providers of repo finance mean that the costs of fire sales are likely to be felt elsewhere in the financial system. \n\n2. Liquidity requirements\nLiquidity requirements, such as those embodied in the Basel III Liquidity Coverage Ratio (LCR), can impose a meaningful tax on certain SFTs in which the dealer acts as a principal. If the dealer holds a corporate bond and finances it with repo borrowing of less than 30 days' maturity, the LCR kicks in and requires the dealer to hold high-quality liquid assets (HQLA) against the risk that it is unable to roll the repo over. In this particular case, there can be said to be a direct form of regulatory attack on the fire-sales problem. However, this conclusion is sensitive to the details of the example. If, instead of holding a corporate bond, the dealer holds a Treasury security that is deemed to count as Level 1 HQLA, there is no impact of the LCR. \n\nMoreover, the LCR plays no role in mitigating fire-sales externalities in the important matched-book case in which the dealer acts as an intermediary.10  If a dealer borrows on a collateralized basis with repo and then turns around and lends the proceeds to a hedge fund in a similar fashion, the LCR deems the dealer to have no net liquidity exposure--and hence imposes no incremental liquidity requirement--so long as the lending side of the transaction has a maturity of less than 30 days. The implicit logic is that as long as the dealer can generate the necessary cash by not rolling over its loan to the hedge fund, it will always be able to handle any outflows of funding that come from being unable to roll over its own borrowing. This logic is not incorrect per se, but it is very micro-focused in nature, and does not attend to fire-sales externalities. It worries about the ability of the dealer firm to survive a liquidity stress event, but does not take into account that the dealer's survival may come at the cost of forcing its hedge fund client to engage in fire sales.11 \n\n3. Leverage ratio\nIf a broker-dealer firm faces a binding leverage ratio, this constraint can act as a significant tax on two types of SFTs that are largely untouched either by risk-based capital requirements or by liquidity regulations. The first is when the dealer, acting as a principal, uses repo to finance its holdings of Treasury securities or agency mortgage-backed securities, assets that generally have only modest risk weights when held as trading positions. The second is when the dealer acts as an intermediary and has a matched repo book. In both cases, the SFTs blow up the firm's balance sheet and, hence, the denominator of the leverage ratio, even while having little impact on risk-based capital or LCR calculations.\n\nThe crucial issue here, however, is whether the leverage ratio does, in fact, bind. A traditional view among regulators has been that the leverage ratio should be calibrated so as to serve as a meaningful \"backstop\" for risk-based capital requirements, but that under ordinary circumstances it should not actually be the binding constraint on firms. For if it were to bind, this would put us in a regime of completely un-risk-weighted capital requirements, where the effective capital charge for holding short-term Treasury securities would be the same as that for holding, say, risky corporate debt securities or loans.\n\nRecently, U.S. regulators have issued a proposed rulemaking that seeks to raise the Basel III supplementary leverage ratio requirement to 5 percent for the largest U.S. bank holding companies, and to 6 percent for their affiliated depository institutions. While this increase might be considered a parallel shift that preserves the backstop philosophy in light of the fact that risk-based requirements have also gone up significantly, it does increase the likelihood that the leverage ratio may bind for some of these firms at some times--particularly for those firms with a broker-dealer-intensive business model in which the ratio of total assets to risk-weighted assets tends to be higher. In this event, there would indeed be a significant tax on SFTs undertaken in the affected firms. However, because it is unlikely that the leverage constraint would bind symmetrically across all of the largest firms, my guess is that the effect would be less to deter SFT activity in the aggregate than to cause it to migrate in such a way as to be predominantly located in those firms that--because they have, say, a larger lending business and, hence, more risk-weighted assets--have more headroom under the leverage ratio constraint.\n\nOther Possible Approaches\nTo summarize the discussion thus far, the mainstays of our existing regulatory toolkit--risk-based capital, liquidity, and leverage requirements--have a variety of other virtues, but none seem well-suited to lean in a comprehensive way against the specific fire-sale externalities created by SFTs. The liquidity coverage ratio affects a subset of SFTs in which a dealer firm acts as a principal to fund its own inventory of securities positions, but does not meaningfully touch those in which it acts as an intermediary. By contrast, an aggressively calibrated leverage ratio could potentially impose a significant tax on a wider range of SFTs, but the tax would by its nature be blunt and highly asymmetric, falling entirely on those firms for whom the leverage ratio constraint was more binding than the risk-based capital constraint. As such, it would be more likely to induce regulatory arbitrage than to rein in overall SFT activity. \n\nThese observations raise the question of whether there are other tools that might be better suited to dealing with SFT-related fire-sales externalities. I will touch briefly on three of these.\n\n1. Capital surcharges\nIn his May speech, Governor Tarullo alluded to the possibility of liquidity-linked capital surcharges that would effectively augment the existing regime of risk-based capital requirements.12  Depending on how these surcharges are structured, they could act in part as a tax on both the dealer-as-principal and dealer-as-intermediary types of SFTs. Accomplishing the latter would require a capital surcharge based on something like the aggregate size of the dealer's matched repo book; this comes quite close to the Pigouvian notion of directly taxing this specific activity. As compared to relying on the leverage ratio to implement the tax, this approach has the advantage that it is more likely to treat institutions uniformly: the tax on SFTs would not be a function of the overall business model of a given firm, but rather just the characteristics of its SFT book. This is because the surcharge is embedded into the existing risk-based capital regime, which should in principle be the constraint that binds for most firms.\n\nThere are a couple of important qualifications, however. First, going this route would involve a significant conceptual departure from the notion of capital as a prudential requirement at the firm level. As noted previously, a large matched repo book may entail relatively little solvency or liquidity risk for the broker-dealer firm that intermediates this market. So, to the extent that one imposes a capital surcharge on the broker-dealer, one would be doing so with the express intention of creating a tax that is passed on to the downstream borrower (i.e., to the hedge fund, in my example).\n\nSecond, and a direct corollary of the first, imposing the tax at the level of the intermediary naturally raises the question of disintermediation. In other words, might the SFT market respond to the tax by evolving so that large hedge funds are more readily able to borrow via repo directly from money market funds and securities lenders, without having to go through broker-dealers? I can't say that I have a good understanding of the institutional factors that might facilitate or impede such an evolution. But if the market ultimately does evolve in this way, it would be hard to argue that the underlying fire-sales problem has been addressed.\n\n2. Modified liquidity regulation\nA conceptually similar way to get at matched-book repo would be to modify liquidity regulation so as to introduce an asymmetry between the assumed liquidity properties of repo loans made by a broker-dealer, and its own repo borrowing. For example, in the context of the Net Stable Funding Ratio (NSFR), one could assume that a dealer's repo loans to a hedge fund roll off more slowly than do its own repo borrowings from the triparty market. This assumption would create a net liquidity exposure for a matched repo book, and would thereby force the dealer to hold some long-term debt or other stable funding against it. Although the implementation is different, the end result is quite close to that obtained with the capital-surcharge approach I just described: in one case, there is a broad stable funding requirement for intermediaries against a matched repo book; in the other case, there is an equity requirement. It follows that, whatever its other advantages, going the modified-NSFR route does not eliminate concerns about disintermediation and regulatory arbitrage.\n\n3. Universal margin requirements\nThese sorts of regulatory-arbitrage concerns have motivated some academics and policymakers to think about a system of universal margin requirements for SFTs.13 In its simplest form, the idea would be to impose a minimum haircut, or down payment requirement, on any party--be it a hedge fund or a broker-dealer--that uses short-term collateralized funding to finance its securities holdings. Because the requirement now lives at the security level, rather than at the level of an intermediary in the SFT market, it cannot be as easily evaded by, say, a hedge fund going outside the broker-dealer sector to obtain its repo funding.14  This is the strong conceptual appeal of universal margin from the perspective of a fire-sales framework.\n\nIn this regard, it is worth noting that the Financial Stability Board (FSB) has recently released a proposal to establish minimum haircut requirements for certain SFTs.15  However, the FSB proposal stops well short of being a universal margin requirement. Rather, the minimum haircuts envisioned by the FSB would apply only to SFTs in which entities not subject to capital and liquidity regulation (e.g., hedge funds) receive financing from entities that are subject to regulation (i.e., banks and broker-dealers), and only to transactions in which the collateral is something other than government or agency securities. In this sense, there is a close relationship between the FSB minimum-haircut proposal and the specific variant of the capital-surcharge idea that I mentioned a moment ago. Both have the potential to act as a restraint on those SFTs that are intermediated by regulated broker-dealer firms, but both are vulnerable to an evolution of the business away from this intermediated mode. The minimum margin levels in the FSB proposal are also quite small, so it is unclear how much of an effect, if any, they will have on market behavior. For example, the minimums for long-term corporate bonds, securitized products, and equities are 2 percent, 4 percent, and 4 percent, respectively.\n\nConclusions\nLet me wrap up. My aim here has been to survey the landscape--to give a sense of the possible tools that can be used to address the fire-sales problem in SFTs--without making any particularly pointed recommendations. I would guess that a sensible path forward might involve drawing on some mix of the latter set of instruments that I discussed: namely, capital surcharges, modifications to the liquidity regulation framework, and universal margin requirements. As we go down this path, conceptual purity may have to be sacrificed in some places to deliver pragmatic and institutionally feasible results. It is unlikely that we will find singular and completely satisfactory fixes.\n\nWith this observation in mind, I would be remiss if I did not remind you of another, highly complementary area where reform is necessary: the money market fund sector. Money funds are among the most significant repo lenders to broker-dealer firms, and an important source of fire-sale risk comes from the fragility of the current money fund model. This fragility stems in part from their capital structures--the fact that they issue stable-value demandable liabilities with no capital buffer or other explicit loss-absorption capacity--which make them highly vulnerable to runs by their depositors. I welcome the work of the Securities and Exchange Commission on this front, particularly its focus on floating net asset values, and look forward to concrete action. Another source of fragility arises from money funds investing in repo loans collateralized by assets that they are unwilling or unable to hold if things go bad. This feature creates an incentive for them to withdraw repo financing from broker-dealers at the first sign of counterparty risk, even if the underlying collateral is in good shape. \n\nI'm sure we will hear much more about this last set of issues over the remainder of the conference today. I look forward to the discussions. Thank you.\n\n \n\n1. I am grateful for helpful comments from Matt Eichner, Mike Gibson, Nellie Liang, Bill Nelson, and Mark Van Der Weide. The thoughts that follow are my own, and are not necessarily shared by other members of the Federal Open Market Committee. Return to text\n\n2. Daniel K. Tarullo (2013), \"Evaluating Progress in Regulatory Reforms to Promote Financial Stability,\" speech at the Peterson Institute for International Economics in Washington, D.C., May 3. Return to text\n\n3. Andrei Shleifer and Robert Vishny (2011), \"Fire Sales in Finance and Macroeconomics (PDF) ,\" Journal of Economic Perspectives, vol. 25 (Winter), p. 30. Return to text\n\n4. An alternative mechanism that works similarly is when the third party is a regulated intermediary and mark-to-market losses reduce its capital ratios, and again force it to involuntarily sell assets in the face of falling prices. Return to text\n\n5. The fundamental welfare economics at work here is developed in John Geanakoplos and Heracles M. Polemarchakis (1986), \"Existence, Regularity, and Constrained Suboptimality of Competitive Allocations When the Asset Market Is Incomplete,\" in Walter P. Heller, Ross M. Starr, and David A. Starrett, eds., Essays in Honor of Kenneth Arrow: Vol 3., Uncertainty, Information, and Communication (New York: Cambridge University Press), pp. 65-95. A discussion of the connection of this work to specific aspects of macroprudential regulation is in Samuel G. Hanson, Anil K. Kashyap, and Jeremy C. Stein (2011), \"A Macroprudential Approach to Financial Regulation (PDF) ,\" Journal of Economic Perspectives, vol. 25 (Winter), pp. 3-28. Return to text\n\n6. This is the first-round externality. Adverse spillovers from a fire sale of this sort may also take the form of a credit crunch that affects borrowers more generally. Such a credit crunch may arise as other financial intermediaries (e.g., banks) withdraw capital from lending, so as to exploit the now-more-attractive returns to buying up fire-sold assets. Ultimately, it is the risk of this credit contraction, and its implications for economic activity more broadly, that may be the most compelling basis for regulatory intervention. Return to text\n\n7. Of course, the Pigouvian taxation approach by itself cannot completely eliminate the ex post costs associated with fire sales. This would require a broad and active lender-of-last resort function, which I do not discuss here. The best that any form of ex ante regulation can hope to do is to reduce the incidence and magnitude of ex post fire-sales damage. Return to text\n\n8. Further discussion on the money-like benefits that are created by near-riskless private assets such as repo can be found in the following: Arvind Krishnamurthy and Annette Vissing-Jorgensen (2012), \"The Aggregate Demand for Treasury Debt ,\" Journal of Political Economy, vol. 120, issue 2 (April), pp. 233-267; Gary B. Gorton and Andrew Metrick (2012), \"Securitized Banking and the Run on Repo,\" Journal of Financial Economics, vol. 103, pp. 425-451; and Jeremy C. Stein (2012), \"Monetary Policy as Financial-Stability Regulation,\" Quarterly Journal of Economics, vol. 127, pp. 57-95. Return to text\n\n9. To be more precise, under Basel III capital rules, there is a small risk-based capital requirement on the repo liability. This requirement is driven by counterparty credit risk, not liquidity risk, and is independent of the term of the repo borrowing. The basic idea is that the repo borrower has to hold a little bit of capital because it has sent $102 in Treasury securities over to its counterparty lender and only received $100 cash. If the repo lender defaults, the borrower could be out $2. Return to text\n\n10. A similar comment applies to the Net Stable Funding Ratio (NSFR), which requires regulated firms to fund illiquid exposures with some amount of long-term debt or other form of stable funding. Like the LCR, the NSFR effectively treats matched-book repo as creating no net liquidity exposure, and hence imposes no requirement on it. Return to text\n\n11. Even from a microprudential perspective, the LCR can be said to have a flaw in that it is blind to maturity mismatches within the 30-day window. For example, if a dealer borrows on an overnight basis from a money fund, and then makes a 29-day loan to a hedge fund, the LCR deems it to be fully matched, and to have no incremental liquidity exposure. Return to text\n\n12. Tarullo (2013) Return to text\n\n13. A closely related motivation for universal margin requirements is that they might be able to limit procyclicality by leaning against increases in leverage during boom times. Return to text\n\n14. Of course, there is always the potential for other forms of regulatory arbitrage. For example, a hedge fund that faces a minimum margin requirement when it uses repo borrowing to fund a corporate-bond position may instead seek to take a leveraged position in the corporate bond through other means by, for example, engaging in a total-return swap with its prime broker. This is the growing business of \"synthetic\" prime brokerage. Properly harmonized initial margin requirements on uncleared derivatives may help to level the playing field between traditional and synthetic prime brokerage activities. Return to text\n\n15. Financial Stability Board (2013), Strengthening Oversight and Regulation of Shadow Banking: Policy Framework for Addressing Shadow Banking Risks in Securities Lending and Repos (PDF) , August 29. Return to text\n\n "
    },
    {
        "title": "Communications Challenges and Quantitative Easing",
        "date": "October 11, 2013",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20131011a.htm",
        "content": "October 11, 2013\n\nGovernor Jerome H. Powell\n\nAt the 2013 Institute of International Finance Annual Membership Meeting, Washington, D.C.\n\nIt is an honor to be here today with such distinguished panelists to discuss the communications challenges associated with quantitative easing. I should say at the outset that the views I express here today are my own and may not reflect those of other Federal Open Market Committee (FOMC) members.\n\nI'll start with the FOMC's commitment, when the current asset purchase program was launched in September 2012, to continue purchases until the Committee sees a substantial improvement in the outlook for the labor market, a term the Committee left undefined.1  This commitment was powerful precisely because it was open ended. But \"open ended\" does not mean unending. As time passed and labor market conditions improved, it would be important for the Committee to clarify the meaning of the term substantial improvement. And given the lack of precedent, it was likely that this transition to more-specific guidance would involve some short-run volatility.\n\nEconomic conditions have improved since the program was launched. Consumer and business confidence moved higher, and sectors such as housing and autos have performed well. Despite strong, ongoing headwinds from fiscal policy, there has been significant progress in the labor market. From September 2012 through August of this year, the private sector created 2.3 million new jobs. The unemployment rate declined from 8.1 percent to 7.3 percent. It's unclear how much of this improvement was due to the program, but I think there is evidence that it played a role, lowering long-term interest rates and raising equity prices and home prices, effects that have supported household and business spending.\n\nIn March 2013, the Committee began noting in its postmeeting statement that it would consider \"the extent of progress toward its economic objectives\" in judging \"the size, pace, and composition of its asset purchases.\"2  In late May, the Chairman stated, in response to a question during a congressional hearing, that the Committee might begin to reduce the pace of asset purchases \"over the next few meetings.\"3  A few weeks later, at his press conference after the June 2013 FOMC meeting, the Chairman noted that the substantial improvement test might well be met over the coming year, and he therefore set forth a framework designed to clarify the path of purchases.4 \n\nUnder the most recent articulation of that framework, in considering when to reduce purchases, the Committee will \"assess whether incoming information continues to support [its] expectation of ongoing improvement in labor market conditions and inflation moving back toward its longer-run objective.\"5  The path of purchases is entirely data dependent, as numerous FOMC participants have emphasized in public remarks.\n\nThe market reaction to the Chairman's May testimony and the June FOMC press conference was significant, particularly given the modest character of the news: that the Committee might bring purchases to a gradual halt over the course of a full year, but only if the economy performs broadly in line with the Committee's expectations--which is to say, pretty well.\n\nMany factors may have contributed to this market reaction. Among them, I would argue that market expectations began to lose touch with Committee intentions in two ways. First, while the Committee sees policy as data dependent, markets seem to fix on dates. The decision to reduce purchases now or to hold off for a meeting or two does not carry great macroeconomic significance. But, to a fixed-income trader, the timing of the decision is everything. It appears that many market participants concluded after the June press conference that the Committee was eager to reduce purchases and committed to doing so at the September meeting, independent of incoming data.\n\nSecond, the expected path of the federal funds rate, as reflected in various market prices, increased significantly, implying an earlier liftoff from the zero lower bound than suggested by the Committee's forward guidance.6  Many FOMC members had said publicly that the decision to reduce purchases did not reflect any change in the Committee's plans for holding the federal funds rate at its current level.\n\nThe September decision not to reduce purchases clearly took some market participants by surprise. For me, the decision was a close call, and I would have been comfortable with a small reduction in purchases. However, as the minutes of the September FOMC meeting reflect, there were legitimate concerns about the strength of incoming economic data, the economic effects of tighter financial conditions and of tighter fiscal policy, and the prospect for disruptive events on the fiscal front.7  I supported the decision as a reasonable exercise in risk management. Events since the September meeting suggest that the concerns regarding fiscal matters were well founded.\n\nI would like to push back against the narrative that the decision at the September meeting has damaged the Committee's communications strategy. In its communications, the Committee seeks to influence market conditions over the medium term in a way that is consistent with its policy intentions. As I suggested earlier, as we navigate this unprecedented transition back to more normal policy, there may be volatility in the short run. And we will continually strive to improve our communications and avoid surprises. But, at the end of the day, my own judgment is that market expectations are now better aligned with Committee assessments and intentions.\n\nThe September decision underscored the Committee's intention to determine the pace of purchases in a data-dependent way based on progress toward our objectives. Moreover, the modest net tightening in financial conditions since the June meeting has likely reduced the prevalence of highly leveraged, speculative positions. I believe that the market is now prepared for a reduction in purchases when the economic outlook and the broader situation support it.\n\nShort term rates have fallen back since the September meeting, and are now better aligned with the Committee's forward rate guidance. This is particularly important because, as the Chairman stressed in September, the Committee views rate policy as its stronger and more reliable tool.\n\nTo wrap up, let me emphasize that what matters is the overall stance of policy, not the pace of asset purchases. In all likelihood, policy will remain highly accommodative for quite a while longer--as long as needed to support an economy that still struggles to shake off the lingering effects of the financial crisis.\n\nThank you.\n\n \n\n1. The Committee also noted: \"In determining the size, pace, and composition of its asset purchases, the Committee will, as always, take appropriate account of the likely efficacy and costs of such purchases.\" See Board of Governors of the Federal Reserve System (2012), \"Federal Reserve Issues FOMC Statement,\" press release, September 13. Return to text\n\n2. See Board of Governors of the Federal Reserve System (2013), \"Federal Reserve Issues FOMC Statement,\" press release, March 20. Return to text\n\n3. The Chairman delivered a statement before the Joint Economic Committee, U.S. Congress, on May 22, 2013. Return to text\n\n4. Information on the Chairman's June 19. 2013, press conference is available on the Board's website at www.federalreserve.gov/monetarypolicy/fomcpresconf20130619.htm. Return to text\n\n5. See Board of Governors of the Federal Reserve System (2013), \"Federal Reserve Issues FOMC Statement,\" press release, September 18. Return to text\n\n6. Decomposing federal funds futures into components representing the true expected path of the federal funds rate and term premiums is difficult. Staff models suggest that a portion of the upward revision in the federal funds futures curve over this period was associated with a pulling forward in the expected date of liftoff in the federal funds rate. Return to text\n\n7. See Board of Governors of the Federal Reserve System (2013), \"Minutes of the Federal Open Market Committee, September 17-18, 2013,\" press release, October 9. Return to text"
    },
    {
        "title": "Celebrating 20 Years of the Bank of Mexico's Independence",
        "date": "October 14, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20131014a.htm",
        "content": "October 14, 2013\n\nChairman Ben S. Bernanke\n\nAt the \"Central Bank Independence--Progress and Challenges,\" a Conference Sponsored by the Bank of Mexico, Mexico City, Mexico (via prerecorded video)\n\nIt is a pleasure to offer a few remarks at this conference marking the 20th anniversary of the Bank of Mexico's independence. In August 1993, Mexico's congress approved changes to the country's constitution that granted policy autonomy to the Bank of Mexico and made price stability its primary mandate. Over the past two decades, these actions, along with a number of other constructive steps taken by Mexican policymakers, have paid substantial dividends in terms of improved economic performance.\n\nAt the time that the Mexican congress changed the status and mandate of the central bank, the nation's economy had been suffering periodic bouts of economic instability for many years. The 1970s through the mid-1990s in particular were marked by episodes of high inflation, boom-and-bust cycles, and financial crises. Indeed, shortly after the new Bank of Mexico law went into effect in April 1994, the Mexican economy entered the throes of the so-called peso crisis. However, the changes to the monetary policy framework, along with greater fiscal discipline and the adoption of a more flexible exchange rate, soon bore fruit. Notably, inflation fell to single-digit levels by the early 2000s. And in 2001 the Bank of Mexico formally adopted an inflation-targeting regime, which--outside of some temporary fluctuations--has succeeded in keeping inflation at around 4 percent.\n\nImportantly, the improved monetary policy framework, together with other reforms, has thus far helped reduce Mexico's susceptibility to financial crises. When the recent financial crisis in the United States and other advanced economies threatened to spill over to Mexico, the inflation credibility enjoyed by the Bank of Mexico allowed it to counter economic weakness by easing monetary conditions, even though headline inflation was running above its target range at the time. The Bank's rate cuts helped stabilize the economy, and Mexican output returned to its pre‑crisis level by late 2010. Strong countercyclical policy actions of this type were unlikely to have been feasible in Mexico a few decades ago; with little in the way of inflation-fighting credibility and an immature financial sector, the monetary authority in earlier years was often forced to respond to a crisis by tightening monetary conditions, rather than loosening them, in an effort to limit capital flight, exchange rate depreciation, and increases in inflation.\n\nOf course, we should not be surprised that central bank independence has contributed to Mexico's improved macroeconomic stability over the past two decades. A broad consensus among economists--supported by considerable empirical evidence--holds that a central bank's credibility and effectiveness are enhanced when it is able to make monetary policy based on its assessment of what is in the economy's long-run interest rather than in response to short-term political pressures. The benefits of a sound monetary framework are further enhanced when combined with good fiscal, regulatory, and trade policies.\n\nAs you probably know, the Federal Reserve is also celebrating an anniversary this year--the centennial of its founding. Like the Bank of Mexico, the Federal Reserve is an independent central bank, and, as in the case of the Bank of Mexico, that independence has evolved and gradually strengthened over time. For example, in the early years following the Fed's founding in 1913, the Secretary of the Treasury and the Comptroller of the Currency served on the Federal Reserve Board, an arrangement that only changed in the 1930s when the Fed underwent significant structural reforms. The Federal Reserve was also less than fully independent during and just after World War II, when it agreed to keep Treasury yields at low levels to reduce the cost of financing wartime deficits. After the war, as inflation pressures rose, Federal Reserve policymakers wanted to return to independent rate setting, but the Treasury demurred, hoping to keep the cost of servicing the national debt low. The conflict was resolved in 1951 through the Treasury-Fed Accord, an agreement that reestablished the Federal Reserve's ability to set rates as dictated by the needs of the broader economy. During the 1980s, under the leadership of Chairman Paul Volcker, the Fed further established its credibility and independence by taking the necessary steps to bring inflation under control. As in Mexico, the benefits of central bank independence in the United States have included low inflation, well‑anchored inflation expectations, and increased policy credibility, which contribute to a more stable overall economic environment. Indeed, during the recent financial crisis and the ensuing recession, the Fed has been able to take aggressive monetary policy actions to help stabilize the economy without dislodging longer-term inflation expectations.\n\nWe should recognize, though, that in democratic societies, central bank independence must be accompanied by accountability to the public and its representatives. In this regard, transparency is key. To ensure appropriate accountability, while also making monetary policy more effective, central banks in the United States, Mexico, and around the world have worked hard to increase their transparency over the past 20 years or so. For example, in the United States, the Fed's policymaking arm, the Federal Open Market Committee, releases a statement after each meeting explaining its decisions and reporting the vote, publishes detailed minutes three weeks after each meeting, and provides a quarterly summary of Committee participants' economic and policy projections. My colleagues on the Board and I often testify before congressional committees, we speak regularly in public, and I hold news conferences four times a year. The Bank of Mexico has likewise significantly increased its transparency since becoming independent, through steps including the adoption of a target range for inflation, the regular publication of inflation reports and policy statements, and the timely release of minutes following each policy meeting.\n\nThe economies of the United States and Mexico not only have in common independent central banks, they are also closely tied by geography and history. The United States is by far Mexico's largest trading partner, accounting for about two-thirds of Mexican merchandise trade. In turn, Mexico accounts for about one-eighth of U.S. foreign trade, thereby ranking, along with Canada and China, among our three largest trading partners. In addition, remittances coming from Mexican workers in the United States benefit the Mexican current account and are a welcome source of income for many Mexican families.\n\nThe strong links between our economies have led to close cooperation between our central banks. An example is the bilateral currency swap arrangement between the Federal Reserve and the Bank of Mexico that was set up during the global financial crisis. This swap line was one of 14 that the Fed established with foreign central banks around the world. These swap arrangements proved their value as they helped alleviate dollar funding pressures, reduce interbank borrowing rates, and calm market fears during some of the worst phases of the crisis. The swap line with Mexico was in addition to a line established in 1994 along with the North American Free Trade Agreement. The Federal Reserve and the Bank of Mexico also work closely together--and with other central banks--through international meetings, seminars, and conferences; in the provision of technical assistance; and through other activities in forums such as the Bank for International Settlements (BIS), the Group of Twenty (G-20), and the Center for Latin American Monetary Studies, or CEMLA.\n\nI would be remiss if, before ending, I did not note the strong leadership that Governor Agustín Carstens continues to provide at the Bank of Mexico. His leadership in economic policy, in several key roles, has been instrumental in solidifying the progress that Mexico has made over the past two decades. Agustín has also built an impressive record in the international policy community more broadly. He is currently the chair of the BIS Consultative Council for the Americas, has recently been appointed chair of the BIS Economic Consultative Committee and the Global Economy Meeting, and played a key role in Mexico's successful presidency of the G-20 last year.\n\nTo conclude, I would like to congratulate the Bank of Mexico on the 20th anniversary of its independence. I wish you a productive conference marking this auspicious occasion. And I wish the Bank of Mexico continued success in its work to stabilize and strengthen the Mexican economy."
    },
    {
        "title": "Lean, Clean, and In-Between",
        "date": "October 18, 2013",
        "speaker": "Governor Jeremy C. Stein",
        "url": "https://www.federalreserve.gov/newsevents/speech/stein20131018a.htm",
        "content": "October 18, 2013\n\nGovernor Jeremy C. Stein\n\nAt the National Bureau of Economic Research Conference: Lessons from the Financial Crisis for Monetary Policy, Boston, Massachusetts\n\nThank you. The theme of this conference is, \"Lessons from the Financial Crisis for Monetary Policy.\" Given the opportunity to speak about this topic, my first thought was that I should organize my remarks around the familiar \"lean versus clean\" debate.1 The traditional, pre-crisis framing of the question went something like this: Should policymakers rely on ex ante measures to lean against potential financial imbalances as they build up, and thereby lower the probability of a bad event ever happening, or should they do most of their work ex post, focusing on the clean-up?\n\nPost-crisis, the emphasis in the debate has shifted. I think it's safe to assume that nobody in this room would now argue that we should be putting all our eggs in the \"clean\" basket. Discussion these days tends to focus instead on which ex ante measures are best suited to safeguard financial stability. Among these, there seems to be widespread support for unconditional, (i.e., time-invariant) tools that increase the overall resiliency of the financial system to shocks. These tools include more robust capital and liquidity requirements, as well as an enhanced capability to resolve a large financial institution that finds itself on the brink of failure. They might also include universal margin requirements on securities financing transactions, as a way of mitigating fire-sales risks. We might argue about various aspects of calibration and implementation, but I don't think there is too much controversy about the basic proposition that strong, comprehensive regulation aimed at enhancing resiliency is essential.\n\nThere is considerably less agreement about the desirability and effectiveness of ex ante measures that seek to lean against the wind in an explicitly time-varying fashion--that is, measures that can be adapted in response to changing economic or financial conditions. At the risk of caricature, one can distinguish three schools of thought. The first school is generally suspicious of any kind of time-varying lean, be it with macroprudential tools such as time-varying, countercyclical capital buffers or margin requirements, or with monetary policy. This school emphasizes the difficulty of identifying emerging financial imbalances in real time. It also points to the political-economy and regulatory-arbitrage impediments that can frustrate the implementation of discretionary time-varying regulation.2 \n\nThe second school is more comfortable with the idea of time-varying leans, but invokes what amounts to a separation principle: It takes the view that any financial-stability-motivated leans should come largely, if not entirely, from time-variation in the application of regulatory and supervisory tools, while monetary policy should stick to its traditional dual-mandate objectives of fostering full employment and maintaining price stability.\n\nThe third school is more heterodox. Like the first, it acknowledges that there are a variety of practical limitations associated with discretionary time-varying regulation, though the severity of these limitations may vary considerably across different countries, markets, and institutional arrangements.3 In cases where regulation can be effectively adjusted over time, doing so remains the preferred approach. But in other situations, and especially when the imbalances in question are relatively pronounced or widespread across a range of markets, this school of thought is more open to working on multiple fronts and to formulating monetary policy with one eye on its potential implications for these imbalances.4 \n\nThe debate between these three schools gets a lot of attention at venues like this one--and with good reason. It touches on issues that are not only of policy interest, but also connect to deeper and strongly held views about how the world works. In other words, this is paradigm-versus-paradigm stuff, which always helps to liven up an academic exchange.\n\nBut precisely for these reasons, the whole lean-versus-clean debate runs the risk of drawing attention away from other crisis-derived lessons that do not make as good fodder for academic discussion, but that are no less relevant from a practical policy perspective. Let me focus the remainder of my remarks on one of these: the importance of the in-between. The lean-versus-clean framing suggests a simple model in which there are just two dates: (1) an initial ex ante date that is prior to when a shock is realized--and when we may not even have much of a clue as to the form the shock will take--and (2) an ex post date when the shock has hit, its full effects have been felt, and policymakers are dealing with the aftermath. But this before-and-after dichotomy is misleading. Many financial crises unfold over months or even years, and the choices made during this in-between period can be among the most crucial to the eventual outcome.\n\nRecall that problems with subprime mortgages were already surfacing in late 2006. The first serious tremors associated with the crisis were felt in August 2007, with BNP Paribas suspending redemptions on its money funds and investor runs on multiple asset-backed commercial paper programs. At this point, there was no longer any real doubt about the nature of the shock confronting us--even if its precise magnitude was yet to be determined. And yet it was more than a full year until the failure of Lehman Brothers in September of 2008, which ignited the most intense part of the crisis. Moreover, during the interval from the start of 2007 through the third quarter of 2008, the largest U.S. financial firms--which, collectively, would go on to charge off $375 billion of loans over the next 12 quarters--paid out almost $125 billion in cash to their shareholders via common dividends and share repurchases, while raising only $41 billion in new common equity. This all happened while there was a clear and growing market awareness of the solvency challenges they were facing. Indeed, the collective market cap of these firms fell by approximately 50 percent from the start of 2007 through the end of June 2008.\n\nThere are two points here worth emphasizing. First, it seems indisputable that the severity of the crisis would have been mitigated if policymakers had clamped down on these payouts earlier, and had compelled substantial new equity raises. Second, the conflict between the interests of the firms, acting on behalf of their shareholders, and those of the broader public became particularly acute once the crisis got underway, because of the debt overhang problem. Cutting back on dividends and issuing new shares might have been strong positives for the banks' overall set of stakeholders, as well as for society more broadly, but were clearly negatives for shareholders, given that such actions would have entailed large transfers to underwater creditors.\n\nThis conflict of interest can make it hard for even the best-intentioned regulators to muster the conviction to take full advantage of either the appropriate legal tools or the resources available under the existing institutional framework. Under what circumstances does one tell a firm that is still well above its regulatory capital requirement that it must do a share issue that will be helpful for the economy as a whole, but highly dilutive to its existing equity holders?\n\nThis discussion brings us to the role of the now ongoing stress-testing framework for large financial institutions. As you may know, the Federal Reserve has been conducting annual stress tests and capital-planning reviews of the 18 largest banks under the auspices of its Comprehensive Capital Analysis and Review (CCAR) program, and is adding 12 more firms this year, consistent with requirements of the Dodd-Frank Wall Street Reform and Consumer Protection Act.5 \n\nDuring normal times, when banks are relatively healthy, the CCAR process functions as an important complement to more conventional capital regulation and, like capital regulation, it can be thought of as an ex ante instrument to increase the general resilience of the banking system to as-yet-unknown shocks.6 I believe that it has been a very valuable addition to our toolkit in this regard, and will continue to be so.\n\nHowever, I also believe that much of the promise of the CCAR framework lies in its potential to help us achieve a better outcome not just in normal times, but also in the important in-between times, in the early stages of a crisis. In other words, when thinking about the design of CCAR, one of the questions I keep coming back to is this: Suppose we were granted a do-over, and it was late 2007. If we had the CCAR process in place, how would things have turned out differently? Would we have seen significantly more equity issuance at this earlier date by the big firms, and hence a better outcome for the real economy?\n\nOn the one hand, there is some reason for optimism on this score. After all, the original stress tests--the Supervisory Capital Assessment Program (SCAP) in May 2009--provided the impetus for a significant recapitalization of the banking system. More than $100 billion of new common equity was raised from the private sector in the six months after the SCAP, and in many ways it was a watershed event in the course of the crisis.\n\nMoreover, the current CCAR framework gives the Federal Reserve both the authority and the independent analytical basis to require external equity issues in the event that, under the stress scenario, a firm's post-stress, tier 1 common equity ratio is below 5 percent, and the ratio cannot be restored simply by suspending dividends and share repurchases.7 In my view, these features of the program are among its most crucial.\n\nAt the same time, having the authority to do something is necessary, but not sufficient--there also needs to be the institutional will. And this will is likely to be especially critical in a time of crisis, again because of the increased prominence of the debt-overhang problem.8 A firm that is told that it needs to improve its capital position will, given the interests of its shareholders, strongly prefer to do so by reducing assets rather than by engaging in a dilutive share issue, even though the latter is more desirable from the perspective of aggregate credit provision. And it can be expected to make its case forcefully.\n\nSo if we are serious about taking a macroprudential approach to regulation--one which aims to protect not just the solvency of individual firms, but the health of the financial system as a whole and its ability to continue to perform its intermediation role in times of stress--it is incumbent on us as regulators to do all that we can to develop both the intellectual case, and the institutional resolve, to be able to push back with equal force when the time comes.\n\nThank you. I look forward to the rest of our discussion.\n\n1. The thoughts that follow are my own, and are not necessarily shared by my colleagues on the Federal Open Market Committee. I am grateful to Tim Clark, Andreas Lehnert, Nellie Liang, Ben McDonough, and Lisa Ryu for their input. Return to text\n\n2. For a forceful exposition of this view, see John Cochrane (2013), \"The Danger of an All-Powerful Federal Reserve,\" Wall Street Journal, August 26, http://online.wsj.com/article/SB10001424127887323906804579036571835323800.html Return to text\n\n3. For a fuller discussion of both the potential and limits of time-varying regulation, see Daniel K. Tarullo (2013), \"Macroprudential Regulation,\" speech delivered at the Yale Law School Conference on Challenges in Global Financial Services, New Haven, Conn., September 20. Return to text\n\n4. To be clear: Taking account of financial-stability considerations when formulating monetary policy can be fully consistent with the dual-mandate objectives of fostering full employment and price stability. Consider a traditional setting where the policymaker has a quadratic loss function over deviations of unemployment and inflation from their target levels. Suppose further that high financial-sector leverage or very buoyant credit conditions today increase the probability of a sharp upward spike in credit spreads at some later date, and the latter prospect in turn raises the conditional variance of economic activity. Then the policymaker's risk aversion over unemployment outcomes may make her willing to try to tighten credit conditions, even at the cost of some employment today, so as to reduce the variance of future employment. In other words, financial-stability factors can weigh significantly in the decisionmaking process, without being an end objective in and of themselves. Return to text\n\n5. The Federal Reserve conducts the CCAR annually to help ensure that companies have forward-looking capital planning processes that account for their unique risks and that result in sufficient capital to enable the institutions to continue lending to households and businesses during times of economic and financial stress. As part of the CCAR, the Federal Reserve evaluates institutions' capital adequacy, internal capital adequacy assessment processes, and their plans to make capital distributions, such as dividend payments or stock repurchases. The CCAR includes a supervisory stress test to support the Federal Reserve's analysis of the adequacy of the firms' capital. Boards of directors of the institutions are required each year to review and approve capital plans before submitting them to the Federal Reserve. The fourth CCAR will begin soon, with the release of instructions and economic scenarios. For more information, see the Board's website at www.federalreserve.gov/bankinforeg/ccar.htm. Return to text\n\n6. For a more detailed discussion of CCAR design, and of the calibration of stress scenarios, see Nellie Liang (2013), \"Implementing Macroprudential Policies (PDF),\" speech delivered at the \"Conference on Financial Stability Analysis: Using the Tools, Finding the Data,\" sponsored by the Federal Reserve Bank of Cleveland and Office of Financial Research, held in Washington, DC, May 31. Return to text\n\n7. More precisely, the rule underpinning the CCAR states that if the Federal Reserve objects to a firm's capital plan, the firm must resubmit, showing how it will address the causes of the objection. So, in the case where the capital plan is objected to because the firm misses the post-stress target of 5 percent common equity (and assuming this cannot be addressed by simply turning off all planned dividends and share buybacks), the firm's resubmission would have to show how it will get back above this target. This plan might include a mix of asset sales, equity issues, and other measures, but the Federal Reserve, in principle and under appropriate circumstances, has the authority to object to a plan that is overly reliant on asset sales and other measures and withhold its non-objection to a plan unless the firm addresses all the shortfall-via-equity issues, over some defined time frame. Return to text\n\n8. Another complicating factor that may make regulators shy away from pushing for new equity issues in the midst of a crisis is the lack of a government backstop. A number of observers have argued that the availability of a backstop in the form of TARP capital played a key role in the original SCAP stress tests. Return to text"
    },
    {
        "title": "Toward Building a More Effective Resolution Regime: Progress and Challenges",
        "date": "October 18, 2013",
        "speaker": "Governor Daniel K. Tarullo",
        "url": "https://www.federalreserve.gov/newsevents/speech/tarullo20131018a.htm",
        "content": "October 18, 2013\n\nGovernor Daniel K. Tarullo\n\nAt the Federal Reserve Board and Federal Reserve Bank of Richmond Conference, \"Planning for the Orderly Resolution of a Global Systemically Important Bank\", Washington, D.C.\n\nObserving the five-year anniversaries of various key moments in the financial crisis throughout 2013 cannot but prompt us to step back and evaluate the effectiveness of the regulatory reform efforts that followed. This week, which marks five years since the U.S. government launched the Troubled Asset Relief Program (TARP), is a particularly appropriate moment to hold this conference on the resolution of systemically important financial institutions (SIFIs). The TARP's extension of unprecedented capital support to many of the largest U.S. banks reflected the view of government officials that the failure of these firms would have posed a grave threat to the financial system. The turmoil that followed the failure of Lehman and the decision to rescue AIG each, in their way, underscored the absence of a third alternative to the options of bailout or disruptive bankruptcy. The creation of such an alternative, included as the Orderly Liquidation Authority in Title II of the Dodd-Frank Wall Street Reform and Consumer Protection Act, was a key part of the reforms.\n\nIn fact, the emergence of a growing consensus around the key elements of a credible resolution mechanism, and the work to engraft those elements into appropriate statutory and administrative frameworks, is one of the more unheralded--if still in progress--successes of the post-crisis regulatory response. Here in the United States, the Federal Deposit Insurance Corporation (FDIC) has been doing path-breaking work to build out the statutory provisions of the Dodd-Frank orderly liquidation authority. Internationally, the Financial Stability Board (FSB) has elaborated a set of principles to guide the development of resolution mechanisms globally.1 And, throughout both processes, there has been fruitful interaction among the official sector, academics, and market participants.\n\nIn my remarks this afternoon, I will begin by explaining the purpose and critical features of a special mechanism for resolving large financial firms, especially those of systemic importance. Next, I will explain why the efforts of the FDIC have been so important in developing credibility for the Title II resolution mechanism for systemically important firms and identify some of the important work that remains, not just for the FDIC, but for a range of official sector and private actors, here and abroad. Finally, I will end with a few thoughts on the relationship between resolution mechanisms and the broader regulatory reform agenda we have been pursuing over the past several years.\n\nThe Purpose and Critical Features of a Special Resolution Mechanism\nThe crisis, and the scope of government support for large banks that it precipitated, spawned an ambitious international regulatory reform agenda directed at the financial stability risks posed by SIFIs. It was recognized that, left unaddressed, the necessary but unpalatable government interventions during the crisis would only further entrench the too-big-to-fail status of systemic financial firms--increasing moral hazard, undermining market discipline, and harming competitive equality among financial institutions of different sizes.\n\nStated most pointedly, then, the purpose of a special resolution mechanism for large financial firms is to prevent future situations in which government officials face the unappealing choice they confronted in 2008, to which I alluded a moment ago. Stated more analytically, a special resolution mechanism is needed to take account of the characteristics of financial markets, and of larger firms operating in those markets, that do not fit easily with normal bankruptcy practice. These characteristics all relate to a basic function of financial intermediaries in providing liquidity to firms and households--whether through maturity transformation, by which banks allow depositors to lend out their savings while maintaining complete liquidity; through market-making, by which dealers provide liquidity to investors in various instruments; or through other forms of intermediation.2 \n\nPrecisely because financial intermediaries provide these liquidity services, they are subject to funding strains when customers or counterparties become uncertain of the value of the loans, securities, or other assets held by the intermediaries. Where those assets are opaque--as can be the case, for example, with a portfolio of conventional loans or with securities backed by many loans bundled together from various originators--the incentive to withdraw funding increases, particularly in periods of stress when the value of broadly held asset classes may be at risk of precipitous decline.\n\nThis familiar dynamic is obviously a potential problem for the intermediary. It becomes a problem for society when one or both of two things follow: First, as in the classic case of bank runs, problems at one bank lead depositors or counterparties at other banks to withdraw their own funds, fearing that their own banks may have similar difficulties repaying them because they hold similar assets. Or, second, the liquidity squeeze leads a sizeable financial firm to engage in a fire sale of its assets in order to raise the funds necessary to compensate for the disruption of its normal funding channels. Dumping a sizeable book of assets on the market, in turn, can lead to the adverse feedback loop observed during the crisis: Downward pressure is placed on similar assets held by others, thereby accelerating margin calls on leveraged actors and amplifying mark-to-market losses for all holders of the assets, thereby prompting fire sales by others. In either or both of these eventualities, the potential insolvency of the financial firm is a problem not just for shareholders, employees, and creditors, but for the financial system as a whole.\n\nA final point is that a financial firm, through the operation of one or both of these dynamics, can shift from viable to non-viable in quite a short period of time. And, once the confidence of counterparties and customers is shaken, and funding withdrawn, the game is essentially over. Of course, matters are made worse if the firm did not maintain adequate capital levels or relied too heavily on short-term funding, as was the case with many of the firms that failed or came under severe pressure in 2008. However, it is important to note that the nature of financial intermediaries means that even firms compliant with more rigorous capital and liquidity requirements could be faced with these dynamics in a tail event.\n\nTo be credible, then, a resolution mechanism for large financial firms must be capable of dealing with these characteristics of financial markets. This is the premise underlying Title II of Dodd-Frank, and I think it has also been the premise of thoughtful commentators who have proposed amendments to the Bankruptcy Code for application to large financial firms.3 There are three key features of Title II and, modified in certain respects, some of these Bankruptcy Code proposals reflect recognition of the peculiarities of financial markets in a way the current Bankruptcy Code does not.\n\nThe first key feature of Title II, simply put, is speed. It is vital that a resolving authority be able to move very quickly from non-resolution to resolution status, while maintaining continuity of operations. As many of you will recall, during the financial crisis the makeshift arrangements crafted by governments in an effort to avoid large negative effects on financial markets were usually completed over a weekend.\n\nThe second key feature is a source of immediate funding to continue essential functions and minimize the kind of fire sales referred to earlier. The Bankruptcy Code allows for so-called debtor-in-possession (DIP) financing to be provided to any firm going through the bankruptcy process.4 Such DIP financing is often essential to maximize the going-concern value of the firm. For a failed SIFI, such funding may be required quickly and in fairly large sums--needs that may not be fully met by private lenders, at least not in the immediate aftermath of a firm being placed into the Title II process.\n\nFor these reasons, funding from the FDIC, drawing on a line from Treasury, is available under Title II. It is important to note, though, that the underlying concept has the same roots as DIP financing--lending that will maintain or increase the going-concern value of the firm, not absorb losses. It is not a capital injection and does not put taxpayers at risk. The FDIC has indicated that it will, in order to protect taxpayers more fully, require that the financing be collateralized and if, for any reason, the FDIC cannot recover the full amount of credit extended, the shortfall is to be made up by a tax on other large financial firms.\n\nThe third necessary feature is a temporary stay of close-out rights of qualified financial contract counterparties. The ability of the FDIC, subject to important creditor safeguards, to nullify the direct- and cross-default rights of counterparties can halt the disruptive, uncertainty-driven race to seize and liquidate a firm's assets immediately upon its entrance into a Title II resolution. The FDIC authority includes the opportunity to decide whether it wants to transfer qualified financial contracts (QFCs) to a bridge financial company or another solvent company during a one-day statutory stay of the contractual rights of counterparties of the firm being resolved. As I will discuss later, this authority is not without limitations, particularly in a cross-border resolution, but it is a critical tool for an effective resolution of a financial firm with complex portfolios of financial contracts.\n\nWhile Title II establishes a special resolution mechanism and grants the FDIC powers responsive to the special challenges posed by the failure of large financial institutions, it provides only a legal framework, not an elaborated description of how these powers would be used to resolve a systemically important financial firm. Moreover, the very large financial firms that are the most likely subjects of a Title II proceeding have extensive cross-border activities, and thus implicate the legal systems of other countries. Thus, for orderly liquidation authority to be effective in containing too-big-to-fail concerns and supporting financial stability, the statutory provisions must be supplemented with administrative planning by the FDIC and with consistent measures in other jurisdictions.\n\nDeveloping a Clear, Credible Approach to Resolution\nIt is important to develop and articulate a credible approach to such a resolution proceeding, for at least two reasons. First, unless creditors and counterparties have well-grounded expectations as to how they will be treated in a resolution setting, they may need to charge a premium to compensate for the additional uncertainty associated with the disposition of their claims, which can lead to a mispricing of risks. In some cases, particularly in periods of increasing stress in the financial system, they may be unwilling to deal with certain firms altogether. Parties who have short-term lending to, or contractual arrangements with, these firms may \"run\" as those loans or contracts lapse, thereby potentially crippling the ongoing business of the firm and creating adverse effects in other parts of the financial system.\n\nA second reason is, in some sense, the converse of the first. If creditors and counterparties do not believe the FDIC can successfully resolve the firm, they may not price in the potential for losses that should be incorporated in their dealings with large firms. That is, if investors and other market actors think the prospects for orderly resolution seem low, they may assume the firm will be rescued by the government, and any moral hazard present in these markets will continue. By specifying which financial obligations will be maintained and where the FDIC will look to impose losses, a well-developed approach to resolution can create incentives for private action compatible with the overall aims of systemic firm resolution.\n\nThe FDIC has made great progress in implementing Title II, in particular by developing the single-point-of-entry approach to resolution of a systemic financial firm. Under the single-point-of-entry approach, the FDIC will be appointed receiver of only the top-tier parent holding company of the failed firm. After the parent holding company is placed into receivership, the FDIC will transfer assets of the parent company to a bridge holding company. The firm's operating subsidiaries (foreign and domestic) will remain open for business as usual. To the extent necessary, the FDIC will then use available parent holding company assets to recapitalize the firm's critical operating subsidiaries. Equity claims of the failed parent company's shareholders will effectively be wiped out, and claims of its unsecured debtholders will be written down as necessary to reflect any losses or other resolution costs in the receivership. The FDIC will ultimately exchange the remaining claims of unsecured creditors of the parent for equity or debt claims of the bridge holding company and return the restructured firm back to private sector control.\n\nThis conceptual approach to resolution under Title II represents an important step toward ending the market perception that any U.S. financial firm is too big or too complex to be allowed to fail.5 The aim of the single-point-of-entry approach is to stabilize the failed firm quickly, in order to mitigate the negative impact on the U.S. financial system, and to do so without supporting the firm's equity holders and other capital liabilities holders or exposing U.S. taxpayers to losses. The single-point-of-entry approach offers the best potential for the orderly resolution of a systemic financial firm under Title II, in part because of its potential to mitigate run risks and credibly impose losses on parent holding company creditors and, thereby, to enhance market discipline.\n\nIn the United States, the top-tier parent company of a large banking firm generally is not an operating company but a holding company, whose primary purpose is to raise capital and direct the operations of its subsidiaries. Its assets largely consist of cash, liquid securities, and equity and debt interests in its subsidiaries. This common organizational feature of U.S. banking firms facilitates the single-point-of-entry approach because the liabilities of the top-tier holding company are structurally subordinated to the customer obligations and other direct liabilities at the firm's operating subsidiaries. Accordingly, under the single-point-of-entry approach, the equity and debt at the holding company level can form a buffer that must first be exhausted before any customer or creditor of a subsidiary suffers losses. The existence of this buffer should help give the customers and creditors of a U.S. banking firm greater clarity regarding their potential loss exposure in failure. The presumption that holding company capital liabilities would be required in the first instance to absorb losses in a systemic financial firm will be critical in maintaining the confidence, and limiting the run potential, of customers, liquidity providers, and other creditors at the operating subsidiary level.\n\nThe single-point-of-entry approach does not involve a government guarantee that subsidizes systemic financial firms by protecting their investors from downside risk. The resolution would result in a recapitalization of a failed firm by the firm's own investors. Any protection received by the creditors of a failed firm's operating subsidiaries would be provided by the equity and debt holders of the failed firm's parent holding company. And even if any temporary losses were suffered by the government because of its provision of liquidity, Dodd-Frank requires that the government be reimbursed through assessments on large financial firms.\n\nThe work being done by the FDIC in building out its approach to Title II will continue, and the FDIC has indicated that it will explain this thinking in further detail in a public release later this year. In addition to the FDIC's work, there are other ways that the credibility of Title II can be enhanced. For example, the Federal Reserve and the FDIC can use their joint responsibility for overseeing the resolution plans, which are required by Dodd-Frank, for large, prudentially regulated firms to improve the resolvability of systemically important financial institutions.6 The largest U.S. bank holding companies and foreign banking organizations submitted their first annual resolution plans to the Federal Reserve and the FDIC in 2012 and have recently submitted a second round of resolution plans. These plans have yielded valuable information that is being used to identify, assess, and mitigate key challenges to resolvability under the U.S. Bankruptcy Code and to support the FDIC's development of backup resolution plans under Title II. We expect the second round of submissions to include improvements that address the initial set of obstacles to resolvability identified during the first round.\n\nMore broadly, our evaluation of the resolvability of these large firms has been further advanced by the resolution planning process. Let me mention two ways in which the organizational structure of systemic financial firms could be shaped so as to facilitate the single-point-of-entry approach. One would be to ensure that losses at material operating subsidiaries, including in material foreign subsidiaries, could be transferred to the parent holding company in resolution. The other would be to keep the firm's parent holding company non-operational and otherwise \"clean\" through limits on the issuance of short-term debt and on the conduct of material business operations in the parent holding company. The single-point-of-entry approach concentrates losses on the creditors and counterparties of the SIFI parent, as opposed to the operating subsidiaries. Accordingly, the impending failure of a SIFI would create strong incentives for creditors and counterparties of the parent holding company to run.7 The single-point-of-entry strategy will be more credible and effective if the only creditors of the parent holding company are holders of capital instruments, and long-term debt holders are fully aware they are subject to bail-in as part of any Title II resolution.\n\nAnother way to enhance the credibility of the FDIC's approach is to require adequate loss-absorbing capacity within large financial firms. Minimum capital requirements, conceptually, are designed to cover losses up to a certain statistical probability. If an extreme tail event occurs and the equity of the firm is wiped out, successful resolution without taxpayer assistance would be most effectively accomplished if a firm had sufficient long-term, unsecured debt to absorb additional losses and to recapitalize the business transferred to the bridge operating company. The presence of this debt explicitly identified for possible bail-in on a \"gone concern\" basis should help other creditors clarify their positions in the orderly liquidation process. A requirement for long-term debt could also have the benefit of improving market discipline, since holders of that debt would know they faced the prospect of loss should the firm enter resolution and would presumably demand an appropriate risk premium.\n\nThe Federal Reserve, in consultation with the FDIC, will be issuing in the next few months a proposal that would require the largest, most complex banking firms to hold minimum amounts of long-term, unsecured debt at the holding company level. This requirement will have the effect of preventing erosion of the current long-term debt holdings of the largest, most complex U.S. firms, which, by historical standards, are currently at fairly high levels. Absent a minimum requirement of this sort, one could expect declines in these levels as the quite flat yield curve of recent years steepens; indeed, we have recently seen some evidence of the beginnings of such declines. At the international level, the FSB has recently announced that it will be issuing proposals for global standards on gone-concern loss absorbency for global systemically important financial institutions.8 \n\nThe single-point-of-entry approach will also be facilitated by the presence of a sufficient amount of assets of the right types at the SIFI parent to enable the recapitalization of its material operating subsidiaries when losses have eroded the capital of the subsidiaries. The write-down of equity and the imposition of haircuts on parent holding company debt in Title II does not by itself recapitalize the operating subsidiaries. Moreover, foreign operations of a SIFI are more likely to be ring-fenced or wound down separately under the insolvency laws of their host countries if foreign authorities or directors do not have full confidence that local interests would be protected. A requirement that a SIFI's parent holding company hold minimum amounts of \"internal bail-in\" debt issued by its material operating subsidiaries could offer a solution to this problem: A failed SIFI parent holding company would be able to inject capital into its material operating subsidiaries by effectively converting that intra-group debt into equity.\n\nCross-Border Issues\nIn many ways, Title II has become a model resolution regime for the international community. In 2011, the FSB adopted the Key Attributes of Effective Resolution Regimes for Financial Institutions, a new standard for resolution regimes for systemic firms.9 The core features of this global standard were already embodied in Title II. By acting early, through the passage of the Dodd-Frank Act, the United States led the way in shaping the development of international policy for effective resolution regimes for systemic financial firms. The FDIC's work on the single-point-of-entry approach continues to help frame the terms of international discussions at the FSB. Moreover, as the home-country supervisor of eight of the 28 global systemically important banks (G-SIBs) identified by the FSB, the Federal Reserve has responsibility for establishing and routinely convening for each U.S. G-SIB a crisis management group.10 These firm-specific crisis management groups, which are comprised primarily of the firm's prudential supervisors and resolution authorities in the United States and key foreign jurisdictions, are working to mitigate potential cross-border obstacles to an orderly resolution of the firms.\n\nAll that said, many other major jurisdictions have not yet enacted legislation that would create a statutory resolution regime with the powers and safeguards necessary to meet the FSB's Key Attributes. Mitigating the obstacles to SIFI resolution will require, at a minimum, that key foreign jurisdictions implement national resolution regimes consistent with the Key Attributes.\n\nWhile compatible host-country resolution regimes are necessary for orderly cross-border resolutions, they may not be sufficient. Most importantly, home-country resolution of a global systemic financial firm may be nearly as difficult if creditors and counterparties of the firm's foreign operations run as will likely happen if domestic creditors and counterparties do so. Possibilities for such runs may be reduced by well-developed and transparent arrangements for cooperation between home- and host-country officials in resolving these firms. The recent joint paper by the FDIC and Bank of England is an important example of such cooperation.11 But, standing alone, even the best of cooperative arrangements may not remove all salient obstacles.\n\nOne key challenge is that certain Title II stabilization mechanisms, including the one-day stay provision with respect to over-the-counter derivatives and certain other financial contracts, may not apply outside the United States. Accordingly, counterparties to financial contracts with the foreign subsidiaries and branches of a U.S. firm may have contractual rights and substantial economic incentives to terminate their transactions as soon as the U.S. parent enters into resolution. Equivalent opportunities and incentives may apply to counterparties of U.S. operations of foreign banking organizations.\n\nOne approach to addressing this problem would be for domestic legislatures to amend bankruptcy and insolvency laws to recognize stays imposed in home-country resolution procedures consistent with international standards. However, it may be difficult to get such legal changes on roughly comparable terms in all relevant jurisdictions, much less to conclude a binding international agreement along those lines.\n\nA second approach, currently under consideration by regulators, would be to seek modifications to standard contractual cross-default, netting, and related practices. This approach would use contractual measures to achieve the same end of having these arrangements effectively governed by resolution decisions in home countries. Of course, even if agreement were reached among regulators, in consultation with relevant industry associations, and effective steps were taken to implement that agreement, it could take some time for the new terms to be widely adopted in relevant markets. But a regulatory timeline could be set to speed up the process. This approach may be the most promising for tackling this vexing problem.\n\nResolution and Regulation\nThe resolution mechanism created by Title II of Dodd-Frank is gaining greater operational credibility as the FDIC builds out its single-point-of-entry approach. With each rule, policy statement, cross-border agreement, and firm-specific resolution plan, that credibility is further increased. Additional measures such as those I have suggested today will continue to enhance this third option of orderly resolution, and relieve government officials of the Hobson's choice of bailout or disruptive bankruptcy for systemically important financial firms.\n\nHowever, as is apparent from the amount of work and planning involved in this effort--particularly, though not exclusively, on cross-border matters--the construction of a resolution framework remains an ongoing challenge. Moreover, even when a large, complex firm can be resolved at no cost to taxpayers without provoking a systemic crisis, there will very likely still be significant negative externalities in the financial system. That is, even if a firm is not too-big-to-fail, it may still be of sufficient systemic importance to make its failure a costly event.\n\nThus, even as policymakers strive to increase prospects for orderly resolution, we must continue efforts to reduce prospects for the failure of a systemically important firm that would require this special mechanism. Stronger capital and liquidity requirements that improve going-concern resiliency will remain crucial to a reform agenda directed at containing the too-big-to-fail problem. The objectives of preventing failure and of reducing systemic costs in the event failure nonetheless occurs are complementary, rather than alternative, policy aims.\n\nThe most important systemic vulnerabilities that have not been subject to sufficient regulatory reforms are those created in short-term wholesale funding markets. In the recent financial crisis, severe repercussions were felt throughout the financial system as short-term wholesale lending against all but the very safest collateral froze up. Although short-term wholesale funding levels at major U.S. and foreign banking firms are lower than they were at the outset of the crisis, major global banks remain significant users. High levels of such funding increase the probability of severe funding problems at, and thus the failure of, major financial firms. They also complicate the orderly resolution of major financial firms in the event of failure.12 Indeed, precisely because an effective orderly resolution mechanism provides for continued funding of certain short-term creditors to staunch potentially calamitous runs, that type of funding will not be subject to the increased market discipline resulting from the creation of a credible resolution process. This fact only strengthens the case for measures to limit the potential of short-term wholesale funding to be an accelerant of systemic problems.\n\nConclusion\nAs I stated at the outset, I believe that creation of the orderly liquidation authority in Title II of Dodd-Frank, the work of the FDIC in developing that authority, the international consensus on the need for similar authority in relevant jurisdictions, and the continuing dialogue with academic and policy commentators together constitute a relatively unnoticed success in the world of financial regulatory reform.\n\nThis observation has come with two, probably predictable caveats. First, considerable work remains, so as to continue building and communicating a credible resolution mechanism that will allow investors, creditors, and counterparties of large financial firms to form reasonable expectations as to how a resolution would be conducted. Second, while it is important to have such a mechanism as part of an overall program to confine too-big-to-fail problems, it would not be desirable to have to use it. The more desirable outcome would be for its very credibility to work in concert with capital, liquidity, and other applicable regulations to reduce the chances of its actual utilization.\n\nThese two thoughts bring me to a final point. As I mentioned, serious work is being done by various commentators on proposals to adapt the Bankruptcy Code to the salient differences between financial and most other industries. As I have watched the back-and-forth between those in the official sector charged with developing orderly resolution mechanisms and those working on bankruptcy amendment proposals, I have noted each side taking account of some points in favor of the other side's model, with attendant modifications in everyone's thinking.\n\nDifferences remain, to be sure, such as the tradeoff between, on the one hand, a bankruptcy model's reliance on the independence of the judiciary and the accumulated precedent for dealing with creditors' claims and, on the other, the advantages in the Title II model of speed, pre-existing knowledge of financial firms, and a systemic perspective. But there has also been productive convergence. I join those who believe that the best outcome may be an amended Bankruptcy Code co-existing with Title II, with the former the default route in the case of a large financial firm's insolvency, and the latter available for the unusual moment when systemic risks loom large. The adaptation of the Bankruptcy Code to deal with large, but not necessarily systemic, financial firms would itself be an important step forward. And the existence of two options other than bailout or disruptive bankruptcy would be welcome to anyone who remembers the position of policymakers in the fall of 2008.\n\n1. In November 2011, the Financial Stability Board adopted Key Attributes of Effective Resolution Regimes for Financial Institutions (PDF), a new international standard that sets out the core elements of an effective special resolution regime for systemically significant financial firms. Return to text\n\n2. The long-standing special resolution powers of the FDIC for insured depository institutions, on which Title II was in part modeled, themselves reflect some relevant peculiarities of banking, and financial markets more generally, compared to other industries. Return to text\n\n3. See, e.g., John F. Bovenzi, Randall D. Guynn, and Thomas H. Jackson (2013), \"Too Big to Fail: The Path to a Solution,\" Bipartisan Policy Center: Washington, D.C., May, and Kenneth E. Scott and John B. Taylor, eds. (2012), Bankruptcy Not Bailout: A Special Chapter 14 (Stanford, Calif.: Hoover Institution Press). Of particular interest in Scott and Taylor is the careful analysis by Professor Thomas Jackson in presenting a proposal for a new Chapter 14 of the Bankruptcy Code. Id. at pp. 25–70. Return to text\n\n4. When a firm is continuing operations under the reorganization provisions of Chapter 11 of the Bankruptcy Code, or even doing so temporarily under the liquidation provisions of Chapter 7, it may, without court approval, incur unsecured debts for which creditors have priority over other unsecured lenders for normal operational expenses; with the approval of the court, the firm may also incur debt for other expenses. As explained above, repayment of some existing short-term creditors may be necessary to maintain the value of a financial firm, something not generally considered a normal operating expense of the sort for which DIP financing is routinely available under current bankruptcy law. Return to text\n\n5. It is worth noting that the Resolution Project at the Hoover Institution, which produced the proposal for a special Bankruptcy Code Chapter 14 cited in footnote 3, is now at work on a variant of its proposal that builds specifically on the single-point-of-entry approach. Return to text\n\n6. Dodd-Frank Section 165(d), 12 U.S.C. §5365(d). Resolution plans are also required of non-bank financial firms designated by the Financial Stability Oversight Council as of systemic importance and thereby subject to supervision by the Federal Reserve. These plans are also useful supervisory tools that have helped the Federal Reserve and the firms focus on opportunities to simplify corporate structures and improve management systems in ways that will help the firms be more resilient and efficient, as well as easier to resolve. Earlier this year, the Federal Reserve issued supervisory guidance relating to operational resilience, including supervisory expectations regarding collateral management; payment, clearing, and settlement activities; liquidity and funding; management information systems; and shared and outsourced services. This guidance was informed by the cross-firm comparative review of the first round of resolution plans and reflected initial supervisory judgments of those practices and capabilities necessary to support effective recovery and resolution planning efforts. Going forward, supervisory assessments will require firms to demonstrate their capabilities in these areas. The resolution planning process has been designed to be iterative; there is still much work to be done in this area by firms, domestic and foreign supervisors, and national governments. Return to text\n\n7. Although long-term debtholders of a troubled SIFI parent will be contractually unable to run, a SIFI parent with sizeable amounts of short-term debt could face substantial runs in times of stress. The contagion could spread to short-term creditors of other SIFI holding companies. Return to text\n\n8. Financial Stability Board (2013), Progress and Next Steps Towards Ending \"Too-Big-To-Fail\" (TBTF): Report of the Financial Stability Board to the G-20 (PDF) . Return to text\n\n9. Financial Stability Board (2011), Ibid. 1 Return to text\n\n10. Financial Stability Board (November 2012), \"Update of group of global systemically important banks (G-SIBs) (PDF)\" . Return to text\n\n11. FDIC and Bank of England (December 2012), Resolving Globally Active, Systemically Important, Financial Institutions: A joint paper by the Federal Deposit Insurance Corporation and the Bank of England (PDF). Return to text\n\n12. Daniel K. Tarullo (2013), \"Evaluating Progress in Regulatory Reforms to Promote Financial Stability,\" speech delivered at the Peterson Institute for International Economics, Washington, May 3. Return to text"
    },
    {
        "title": "Advanced Economy Monetary Policy and Emerging Market Economies",
        "date": "November 04, 2013",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20131104a.htm",
        "content": "November 04, 2013\n\nGovernor Jerome H. Powell\n\nAt the Federal Reserve Bank of San Francisco 2013 Asia Economic Policy Conference, San Francisco, California\n\nI appreciate this opportunity to offer a few thoughts on the effects of advanced economy monetary policies on emerging market economies (EMEs)--an issue of great importance for Asia and the global economy.1 Since the global financial crisis, the Federal Reserve has sought to strengthen the U.S. economic recovery through highly accommodative monetary policy. But my colleagues and I are keenly aware that the U.S. economy operates in a global environment. We understand that America's prosperity is bound up with the prosperity of other nations, including emerging market nations.\n\nEmerging market economies have long grappled with the challenges posed by large and volatile cross-border capital flows. The past several decades are replete with episodes of strong capital inflows being followed by abrupt reversals, all too often resulting in financial crisis and economic distress.2 Some of this volatility no doubt reflects the evolution of strengths and vulnerabilities within the EMEs themselves.\n\nIn recent years, renewed attention has been placed on the role of advanced economies and of common or global factors in driving capital movements.3 In particular, many observers have singled out monetary policy in the United States and other advanced economies as a key driver. As advanced economies pursued highly accommodative monetary policies and EMEs subsequently received strong capital inflows, reflecting investors' pursuit of higher returns, concerns were expressed that a flood of liquidity would overwhelm emerging markets, drive up asset prices to unsustainable levels, set off credit booms, and thus sow the seeds of future crises. More recently, there have been concerns about potential financial and economic dislocations associated with the advanced economies' eventual exit from highly accommodative policies.\n\nIn my remarks today, I will discuss the extent to which monetary policy in the advanced economies--and in the United States in particular--has contributed to changes in emerging market capital flows and asset prices, and I will place this discussion in a broader context of economic and financial linkages among economies. I will also address the risks that EMEs may face from the eventual normalization of monetary policy in the advanced economies.\n\nThe heightened attention to advanced economies' monetary policies and the potential spillovers to EMEs is understandable in light of the unprecedented policy steps taken in the aftermath of the global financial crisis. The severity of the crisis and the challenge of a slow recovery required central banks in the advanced economies and elsewhere to take aggressive action in order to fulfill their mandates. In the United States, the Federal Reserve is bound by its dual mandate to pursue price stability and maximum employment. In following that mandate, the Fed cut the federal funds rate to its effective lower bound in late 2008 and then turned to two less conventional policy tools to provide additional monetary accommodation. The first is forward guidance on the federal funds rate.By lowering private-sector expectations for the future path of short-term rates, forward guidance has reduced longer-term interest rates and raised asset prices, thereby leading to more accommodative financial conditions. The second tool is large scale asset purchases, which likewise increase policy accommodation by reducing longer-term interest rates and raising asset prices.\n\nThe Federal Reserve has not been alone in implementing unconventional monetary policies. The Bank of England has also engaged in substantial asset purchases and recently introduced explicit forward guidance for its policy rate. The Bank of Japan, a pioneer in the use of unconventional policy, has recently embarked on an ambitious asset purchase program to combat deflation. And the European Central Bank (ECB) substantially extended its liquidity provision by offering unlimited longer-term refinancing operations. The ECB also purchased some securities in distressed markets, and recently indicated that it expects interest rates to remain low for an extended period. Thus, since the end of the crisis, central banks in the advanced economies have adopted similar policies to promote recovery and price stability.\n\nWhile a great deal of attention has focused on unconventional policy actions, especially asset purchases, these policies appear to affect financial conditions and the real economy in much the same way as conventional interest rate policy. Indeed, recent research suggests that adjustments in policy rates and unconventional policies have similar cross-border effects on asset prices and economic outcomes.4 ; If that is so, then the overall stance of policy accommodation matters more here than the particular form of easing Moreover, neither conventional nor unconventional monetary policy actions are shocks that come out of the blue. Instead, they are the policies undertaken by central banks to offset the adverse shocks that have restrained our economies. Thus, any spillovers from monetary policy actions must be evaluated against the consequences of failing to respond to these adverse shocks.\n\nIn a world of global trade and integrated capital markets, it is natural for economic and financial shocks and policy actions to be transmitted across borders. Spillovers from advanced-economy monetary policies are to be expected.5 In theory, when advanced economies ease monetary policy in response to a contractionary shock, their interest rates will decline, prompting investors to rebalance their portfolios toward higher-yielding assets. Some of this rebalancing will occur domestically, but some investment will also move abroad, resulting in capital flows to EMEs. In response, EME currencies should tend to appreciate against those of the advanced economies, and EME asset prices should rise. Conversely, a tightening of advanced economy monetary policy in response to a stronger economy should lead these movements to reverse; that is, tightening should reduce capital flows to EMEs and diminish upward pressure on EME currencies and asset prices.\n\nAre these basic relationships apparent in the data? The left side of chart 1 shows an index of EME local-currency sovereign bond yields along with a roughly similar maturity U.S. Treasury yield. The line on the right is the differential between the two, plotted against net inflows of private capital to a selection of EMEs, shown by the bars. If interest rates were the main driver of capital flows, these two series ought to move in a similar fashion. At times, this is indeed the case: From mid-2009 to early 2011, the interest rate differential and EME capital inflows rose together. But the overall relationship is not particularly tight. In early 2007, capital flows to EMEs were quite strong even with a low interest rate differential. And in mid-2011, capital inflows stepped down even as the interest rate differential remained elevated. As I will discuss in a moment, the lack of a tight relationship between capital flows and interest rates suggests that other factors also have been important.\n\nEven though interest-rate differentials and capital inflows do not always move in the same direction, numerous empirical studies have shown that interest rates do in fact help explain capital flows once other determinants of these flows are also taken into account.6 In particular, when U.S. rates decline relative to those in EMEs, private capital flows to EMEs tend to rise, consistent with investors rebalancing toward higher-yielding assets. In a similar vein, event studies have shown that the Federal Reserve's policy announcements, including those related to asset purchases, have been associated with capital flows to EMEs as well as upward movements in EME currencies and asset prices.7 But the role of monetary policy in driving capital flows and the effects of those flows on EMEs should not be overstated. In this regard, I will offer two considerations.\n\nFirst, many factors affect capital flows to EMEs, not just the stance of advanced economy monetary policy. Differences in growth prospects across countries and the associated differences in expected investment returns are important factors.8 Chart 2 shows the growth rate of real GDP for EMEs and advanced economies. Given their stage of development and demographic profile, EMEs should grow faster than advanced economies on a trend basis. As shown by the line in the right panel, EME growth has, in fact, consistently outpaced that of the advanced economies. In addition, the bounceback of the EMEs from the global financial crisis widened this differential even more, although the gap has diminished more recently as growth in the EMEs has slowed. Moreover, investing in EMEs has become more attractive as many EMEs have improved their macroeconomic policies and institutional frameworks over recent decades; growth differentials may partly be reflecting these improvements. As is evident in the right-hand chart, the relationship between the growth differential and capital inflows to EMEs seems to be quite strong. In particular, the rise in capital flows following the global financial crisis coincided with stronger relative growth performance in EMEs. And in 2011, capital inflows diminished along with the growth differential.\n\nAnother key driver of EME capital flows is global attitude toward risk. Swings in sentiment between \"risk-on\" and \"risk-off\" have led investors to reposition across asset classes, resulting in corresponding movements in capital flows.9 Indeed, as shown in chart 3, the most common measure of uncertainty and the market price of volatility--the VIX--is strongly correlated with net inflows into EMEs. Although the causes of movements in global risk sentiment are uncertain, the ebb and flow of potential crises and policy responses, such as we experienced during the European crisis, are clearly important. Of course, movements in risk sentiment may not be fully independent of monetary policy. An interesting line of research has begun to consider how changes in monetary policy itself may affect risk sentiment. For example, some studies indicate that an easing of U.S. monetary policy tends to lower volatility (as measured by the VIX), increase leverage of financial intermediaries, and boost EME capital inflows and currencies.10 \n\nA second point to bear in mind when assessing monetary policy spillovers is that expansionary policies in the advanced economies are not beggar-thy-neighbor; in other words, they do not undermine exports from EMEs. In recent decades, some EMEs have successfully pursued an export-led growth strategy, and policymakers in those economies have sometimes expressed concern that their exports will be unduly restrained as accommodative policies in the advanced economies lead their currencies to appreciate. However, as shown in chart 4, although EME currencies bounced back from their lows during the global financial crisis--when global investors fled from assets they perceived to be risky--for many EMEs real exchange rates have moved sideways or have even declined over the past two years. Some of this weakness may reflect the foreign exchange market intervention and capital controls that policymakers used to staunch the rise in their currencies.\n\nBut even if advanced economy monetary policies were to put upward pressure on EME currencies, the consequent drag on their exports must be weighed against the positive effects of stronger demand in the advanced economies. According to simulations of the Federal Reserve Board's econometric models of the global economy, these two effects roughly offset each other, suggesting that accommodative monetary policies in the advanced economies have not reduced output and exports in the EMEs.11 Indeed, this view seems to be supported by recent experience, as the U.S. current account balance has remained fairly stable since the end of the global financial crisis. Over the longer run, advanced economy policy actions that strengthen global growth and global trade will benefit the EMEs as well.\n\nA particularly important consideration regarding spillovers from accommodative monetary policies in the advanced economies is the extent to which such policies contribute to financial stability risks in the EMEs. Because many EMEs have financial sectors that are relatively small, large capital inflows may foster asset price bubbles and a too-rapid expansion of credit. These are serious concerns, irrespective of the relative importance of monetary policies in the advanced economies in driving these flows. While the picture is a mixed one and some markets show signs of froth, indicators of financial stability do not seem to show widespread imbalances.12 \n\nFor example, EME equity prices, shown in chart 5, plunged during the global financial crisis, rebounded thereafter, but then generally flattened out or even declined. There are exceptions, of course, such as Indonesia, whose stock market soared until earlier this year. But in aggregate, EME stock prices remain below their pre-crisis peak, whereas the S&P 500 is well above its own pre-crisis peak.\n\nChart 6 portrays the rise in credit to the domestic nonfinancial private sector as a share of GDP from its pre-crisis level. For some EMEs, the rise in credit does not seem out of line with historical trends, but some economies have experienced potentially worrisome increases. Credit growth in China is particularly noteworthy, but this does not seem to be the result of accommodative monetary policies in the advanced economies. Much of the rise took place in the aftermath of the crisis, in large part reflecting policy-driven stimulus to support economic recovery.  In addition, China's relatively closed capital account limits the extent to which domestic credit conditions are influenced by developments abroad, including changes in advanced economy monetary policy. Increases in credit in some other economies, notably Brazil, have also been driven to a significant degree by policy actions to support aggregate demand. And, of course, EMEs have policy tools to limit the expansion of credit.\n\nAnother area of potential concern is excessive valuations in property markets.Chart 7 displays inflation-adjusted house prices for several Asian economies. The most striking increases have occurred in Hong Kong, which, through its open capital account and essentially fixed exchange rate, is tied most directly to U.S. financial conditions. Of course, the degree of Hong Kong's exposure to U.S. financial conditions is a policy choice, and other factors have also contributed to the run-up in its property prices. House prices have also resumed their rise in China. But, as with credit growth, this rise seems to reflect domestic developments as opposed to spillovers from global financial conditions.\n\nIn light of these potential financial stability concerns, it is encouraging that EME policymakers have devoted substantial effort since the Asian financial crisis of the late 1990s to bolster the resilience of their banking systems. Banks in many EMEs have robust earnings and solid capital buffers.13 Compared with past experience, emerging market banking systems also generally enjoy improved management and a proactive approach by authorities to mitigate risks. Nevertheless, in an environment of volatile global markets, regulators should guard against the buildup of vulnerabilities, such as excessive dependence on wholesale and external funding, declining asset quality, and foreign currency mismatches.\n\nTo summarize my discussion so far, EMEs clearly face challenges from volatile capital flows and the attendant moves in asset prices. Accommodative monetary policies in the advanced economies have likely contributed to some of these flow and price pressures, and may also have contributed to the buildup of some financial vulnerabilities in certain emerging markets. That said, other factors appear to have been even more important. Moreover, expansionary monetary policies in the advanced economies have supported global growth to the benefit of advanced and emerging economies alike.\n\nTurning to the risks and policy challenges going forward, much attention has focused on potential effects in EMEs when recovery prompts the United States and other advanced economies to begin the gradual process of returning policy to a normal stance. As events over the summer demonstrated, even the discussion of such a policy shift may be accompanied by considerable volatility.\n\nAs shown in chart 8, from May through August, U.S. Treasury yields rose substantially as market participants reassessed the future course of U.S. monetary policy. In response, EME bond and equity funds experienced very large outflows, as shown by the bars. EME yields rose as well, in some cases by more than those on Treasury securities, and many EME currencies depreciated. The magnitude of these market responses may have been amplified by the carry-trade strategies that many investors had in place; these strategies were designed to take advantage of interest rate differentials and appeared profitable as long as EME interest rate differentials remained wide and EME exchange rates remained stable or were expected to appreciate. When anticipations of Fed tapering led to higher U.S. interest rates and higher market volatility, these trades may have been quickly unwound, engendering particularly sharp declines in EME exchange rates and asset prices.\n\nThese developments, however, do not appear to have been driven solely by perceptions of U.S. monetary policy. As I noted earlier, GDP growth in many EMEs has fallen from the pace of previous years, which may have led investors to rethink their investment choices. Additionally, it appears that the retreat from emerging markets reflected a change in global risk sentiment, as investors focused on vulnerabilities in EMEs following a period of complacency. Asset prices have fallen considerably more in economies with large current account deficits, high inflation, and fiscal problems than in countries with stronger fundamentals. For example, as shown in chart 9, changes in EME exchange rates and interest rates since April have been correlated with current account deficits. In general, economies with larger current account deficits experienced greater depreciations of their currencies and larger increases in their bond yields. Thus, while a reassessment of U.S. monetary policy may have triggered the recent retrenchment from EMEs, investor concerns about underlying vulnerabilities appear to have amplified the reaction.\n\nWhatever their source, large capital outflows from EMEs can pose challenges for EME policymakers by simultaneously producing significant currency depreciation, asset price deflation, and inflationary pressures. In such cases, EME central banks are in the difficult position of judging whether to tighten policy at the same time that demand is weakening. It is notable that some central banks with stronger records on price stability have been able to avoid tightening whereas others have been forced to raise rates to defend price stability in the face of domestic weakness.\n\nMonetary policy in the United States is likely to remain highly accommodative for some time, as our economy fights to overcome the remaining headwinds from the global financial crisis. As our economic recovery continues, however, the time will come to gradually reduce the pace of asset purchases and eventually bring those purchases to a stop. The timing of this moderation in the pace of purchases is necessarily uncertain, as it depends on the evolution of the economy.\n\nWhile moderating the pace of purchases and the eventual increase in the federal funds rate may well affect capital flows, interest rates and asset prices in EMEs, the overall macroeconomic effects need not be disruptive. First, tightening will in all likelihood occur in the context of a more firmly established economic recovery in the United States so that any adverse effects on EME financial conditions should be buffered by the beneficial effects of higher external demand. Second, although conditions vary from country to country, on the whole, EMEs exhibit greater resilience than they did in prior decades, reflecting, among other factors, more flexible exchange rates, greater stocks of international reserves, stronger fiscal positions, and better regulated and more conservatively managed banking systems.\n\nEMEs have policy tools to help manage any negative externalities that may arise, and recent developments provide additional rationale for them to redouble their efforts to bolster their resiliency.14 Reducing vulnerabilities, improving policy frameworks, and safeguarding the financial sector will go a long way toward making EMEs more robust to a wide range of shocks, not just those that may arise from changes in monetary policy in the advanced economies. Global investors should also learn from the experience of this summer, when it became clear that unwinding leveraged carry trades can be difficult in an environment of lower liquidity.\n\nAs for advanced economies, policymakers should move gradually to restore normal policies only as their economic recoveries are more firmly established, consistent with their mandates. In addition, policymakers should communicate as clearly as possible about their policy aims and intentions in order to limit the odds of policy surprises and a consequent sharp adjustment in financial markets in response. Indeed, my colleagues on the FOMC and I are committed to just such an approach.\n\nIn closing, the Federal Reserve's mandate, like those of other central banks, is focused on the pursuit of domestic policy objectives. This focus is entirely appropriate. Yet, experience has shown that the fortunes of the U.S. economy are deeply intertwined with those of the rest of the world. Economic prospects for the United States are importantly influenced by the course of the world economy, and, by the same token, prosperity around the globe depends to a significant extent on a strong U.S. economy. In order for the Federal Reserve to fulfill its dual mandate of price stability and maximum employment, we must take account of these international linkages. Indeed, the Federal Reserve has a long and varied history of doing so, including our actions during the global financial crisis. There is every reason to expect that to continue.15 \n\nThank you. I'll be happy to take a few questions or comments.\n\nReferences\n\nAhmed, Shaghil, and Andrei Zlate (2013). \"Capital Flows to Emerging Market Economies: A Brave New World? (PDF) \" International Finance Discussion Papers 1081. Washington: Board of Governors of the Federal Reserve System, June.\n\nBernanke, Ben S. (2013). \"Monetary Policy and the Global Economy,\" speech delivered at the Department of Economics and STICERD (Suntory and Toyota International Centres for Economics and Related Disciplines) Public Discussion in Association with the Bank of England, London School of Economics, London, March 25.\n\nBluedorn, John, Rupa Duttagupta, Jaime Guajardo, and Petia Topalova (2013). \"Capital Flows are Fickle: Anytime, Anywhere (PDF) ,\" IMF Working Paper WP/13/183. Washington: International Monetary Fund, August.\n\nBroner, Fernando, Tatiana Didier, Aitor Erce, and Sergio L. Schmukler (2013). \"Gross Capital Flows: Dynamics and Crises,\" Journal of Monetary Economics, vol. 60 (January), pp. 113-33.\n\nBruno, Valentina, and Hyun Song Shin (2013). \"Capital Flows and the Risk-Taking Channel of Monetary Policy (PDF),\" NBER Working Paper Series 18942. Cambridge, Mass.: National Bureau of Economic Research, April.\n\nCalvo, Guillermo A., Leonardo Leiderman, and Carmen M. Reinhart (1993). \"Capital Inflows and Real Exchange Rate Appreciation in Latin America,\" IMF Staff Papers, vol. 40 (1), pp. 108-51.\n\n------ (1996). \"Inflows of Capital to Developing Countries in the 1990s,\" Journal of Economic Perspectives, vol. 10 (Spring), pp. 123-39.\nChen, Qianying, Andrew Filardo, Dong He, and Feng Zhu (2012). \"International Spillovers of Central Bank Balance Sheet Policies (PDF) ,\" BIS Papers No. 66. Basel, Switzerland: Bank for International Settlements, October.\n\nChuhan, Punam, Stijn Claessens, and Nlandu Mamingi (1998). \"Equity and Bond Flows to Latin America and Asia: The Role of Global and Country Factors,\" Journal of Development Economics, vol. 55 (April), pp. 439-63.\n\nEichengreen, Barry (2013). \"Does the Federal Reserve Care about the Rest of the World? (PDF)\" NBER Working Paper No. 19405. Cambridge, Mass.: National Bureau of Economic Research, September.\n\nFernandez-Arias, Eduardo (1996). \"The New Wave of Private Capital Inflows: Push or Pull?\" Journal of Development Economics, vol. 48 (March), pp. 389-418.\n\nForbes, Kristin J., and Francis E. Warnock, (2012). \"Capital Flow Waves: Surges, Stops, Flight, and Retrenchment,\" Journal of International Economics, vol. 88 (November), pp. 235-51.\n\nFratzscher, Marcel, Marco Lo Duca, and Roland Straub (2013). \"On the International Spillovers of U.S. Quantitative Easing,\" ECB Working Paper No. 1557. Frankfurt, Germany: European Central Bank, June.\n\nGhosh, Atish R., Jun Kim, Mahvash S. Qureshi, and Juan Zalduendo (2012). \"Surges (PDF),\" IMF Working Paper WP/12/22. Washington: International Monetary Fund, January.\n\nGlick, Reuven, and Sylvain Leduc (2013). \"The Effects of Unconventional and Conventional U.S. Monetary Policy on the Dollar (PDF) ,\" Working Paper Series 2013-11. San Francisco: Federal Reserve Bank of San Francisco, May.\n\nHausman, Joshua, and Jon Wongswan (2011). \"Global Asset Prices and FOMC Announcements, (PDF)\" Journal of International Money and Finance , vol. 30 (April), pp. 547-71.\n\nIMF (2011). \"Recent Experiences in Managing Capital Inflows--Cross-Cutting Themes and Possible Policy Framework (PDF) ,\" staff paper. Washington: International Monetary Fund, February.\n\n------ (2013a). Global Financial Stability Report: Transition Challenges to Stability. Washington: International Monetary Fund, October.\n\n------ (2013b). \"Global Impact and Challenges of Unconventional Monetary Policies (PDF) ,\" policy paper. Washington: International Monetary Fund, September.\n\nMoore, Jeffrey, Sunwoo Nam, Myeongguk Suh, and Alexander Tepper (2013). \"Estimating the Impacts of U.S. LSAPs on Emerging Market Economies' Local Currency Bond Markets,\" Staff Report No. 595. New York: Federal Reserve Bank of New York, January.\n\nReinhart, Carmen M., and Vincent R. Reinhart (2009). \"Capital Flow Bonanzas: An Encompassing View of the Past and Present,\" in, Jeffrey A. Frankel and Christopher Pissarides, eds., NBER International Seminar on Macroeconomics 2008. Chicago: University of Chicago Press, pp. 9-62.\n\nRey, Helene (2013). \"Dilemma not Trilemma: The Global Financial Cycle and Monetary Policy Independence,\" paper presented at \"Global Dimensions of Unconventional Monetary Policy,\" a symposium sponsored by the Federal Reserve Bank of Kansas City, held in Jackson Hole, Wyo., August 22-24.\n\nRosa, Carlo (2012). \"How ‘Unconventional' Are Large-Scale Asset Purchases? The Impact of Monetary Policy on Asset Prices,\" Staff Report No. 560. New York: Federal Reserve Bank of New York, May.\n\nSanchez, Manuel (2013). \"The Impact of Monetary Policies of Advanced Countries on Emerging Markets (PDF) ,\" speech delivered at the 55th Annual Meeting of the National Association of Business Economists, San Francisco, California, September 9.\n\nWu, Jing Cynthia, and Fan Dora Xia (2013). \"Measuring the Macroeconomic Impact of Monetary Policy at the Zero Lower Bound (PDF) ,\" paper presented at the Term Structure Modeling at the Zero Lower Bound conference held at the Federal Reserve Bank of San Francisco, October11.\n\n1. I would like to thank Trevor Reeve for his assistance in the preparation of these remarks. Return to text\n\n2. Notable examples of such crises include Latin America in the early 1980s, Mexico in 1994, the Asian financial crises beginning in 1997, Russia in 1998, Argentina in 2001, and Brazil in 2002. See Broner and others (2013), Forbes and Warnock (2012), Ghosh and others (2012), and Reinhart and Reinhart (2009) for discussions of large capital flow movements. Return to text\n\n3. An earlier literature also examined the role of \"push\" and \"pull\" factors in explaining international capital flows. Examples include Calvo and others (1993, 1996), Fernandez-Arias (1996), and Chuhan and others (1998). Return to text\n\n4. See Glick and Leduc (2013), IMF (2013a), Moore and others (2013), Rosa (2012), and Wu and Xia (2013). Recent research by Federal Reserve Board staff finds that reductions in U.S. interest rates for any reason--whether caused by monetary policy or other factors--have typically been associated with declines in EME interest rates and appreciation of EME currencies. Moore and others (2013) document a similar historical relationship. Return to text\n\n5. The U.S. economy is affected by spillovers from abroad as well, and these are very much a part of our policymaking environment. Return to text\n\n6. See, for example, Ahmed and Zlate (2013), Bluedorn and others (2013), Fratzcher and others (2013), Ghosh and others (2012), and IMF (2011). Return to text\n\n7. See Chen and others (2012), Fratzscher and others (2013), Hausman and Wongswan (2011), IMF (2013b), and Moore and others (2013). Return to text\n\n8. See Ahmed and Zlate (2013), Forbes and Warnock (2012), Fratzcher and others (2013), and Ghosh and others (2012). Return to text\n\n9. See Ahmed and Zlate (2013), Bluedorn and others (2013), Forbes and Warnock (2012), and IMF (2011). Return to text\n\n10. See Bruno and Shin (2013) and Rey (2013). Return to text\n\n11. See Bernanke (2013). Return to text\n\n12. See IMF (2013a, 2013b). Return to text\n\n13. See IMF (2013a). Return to text\n\n14. See Sanchez (2013). Return to text\n\n15. See Eichengreen (2013). Return to text\n\n "
    },
    {
        "title": "The Fire-Sales Problem and Securities Financing Transactions",
        "date": "November 07, 2013",
        "speaker": "Governor Jeremy C. Stein",
        "url": "https://www.federalreserve.gov/newsevents/speech/stein20131107a.htm",
        "content": "November 07, 2013\n\nGovernor Jeremy C. Stein\n\nAt the Federal Reserve Bank of Chicago and International Monetary Fund Conference, Chicago, Illinois\n\nThank you. I thought I would focus my remarks today on one piece of the shadow banking system, namely the market for securities financing transactions (SFTs). In so doing, I want to call attention to the fire-sales problem associated with SFTs, and consider potential policy remedies.1 I will do so in three parts. First, I will briefly discuss the welfare economics of fire sales. That is, I will try to make clear when a forced sale of an asset is not just an event that leads to prices being driven below long-run fundamental values, but also one that involves a market failure, or externality, of the sort that might justify a regulatory response. Second, I will argue that securities financing transactions are a leading example of the kind of arrangement that can give rise to such externalities, and hence are particularly deserving of policy attention. And third, I will survey some of the recently enhanced tools in our regulatory arsenal (e.g., capital, liquidity, and leverage requirements) and ask to what extent they are suited to tackling the specific externalities associated with fire sales and SFTs.\n\nTo preview, a general theme is that while many of these tools are likely to be helpful in fortifying individual regulated institutions--in reducing the probability that, say, a given bank or broker-dealer will run into solvency or liquidity problems--they fall short as a comprehensive, marketwide approach to the fire-sales problem associated with SFTs. In this regard, some of what I have to say will echo a recent speech by my Board colleague Daniel Tarullo.2 \n\nThe Positive and Normative Economics of Fire Sales\nIn a recent survey paper, Andrei Shleifer and Robert Vishny write that: \"…[A] fire sale is essentially a forced sale of an asset at a dislocated price. The asset sale is forced in the sense that the seller cannot pay creditors without selling assets….Assets sold in fire sales can trade at prices far below value in best use, causing severe losses to sellers.\"3 Shleifer and Vishny go on to discuss the roles of investor specialization and limited arbitrage as factors that drive the magnitude of observed price discounts in fire sales, and there is, by now, a large body of empirical research that supports the importance of these factors.\n\nHowever, by itself, the existence of substantial price discounts in distressed sales speaks only to the positive economics of fire sales, not the normative economics, and hence is not sufficient to make a case for regulatory intervention. To see why, consider the following example: An airline buys a 737, and finances the purchase largely with collateralized borrowing. During an industry downturn, the airline finds itself in distress, and is forced to sell the 737 to avoid defaulting on its debt. Other airlines also are not faring well at this time, and are not interested in expanding their fleets. So the only two bidders for the 737 are a movie star, who plans to reconfigure it for his personal use, and a private-equity firm, which plans to lease out the plane temporarily and wait for the market to recover so the firm can resell it at a profit. In the end, the private-equity firm winds up buying the plane at half its original price. Two years later, it does indeed resell it, having earned a 60 percent return.\n\nThis is clearly a fire sale in the positive-economics sense, but is there a market failure here that calls for regulation? Intuition suggests not. The airline arguably caused the fire sale by using a lot of leverage in its purchase of the 737, but it also seems to bear most of the cost, by being forced to liquidate at a large loss. The movie star and the private-equity firm are, if anything, made better off by the appearance of a buying opportunity, and there are no other innocent bystanders. So the airline's ex ante capital structure choice would seem to internalize things properly; the fire sale here is just like any other bankruptcy cost that a firm has to weigh in choosing the right mix of debt and equity.\n\nFor a fire sale to have the sort of welfare effects that create a role for regulation, the reduced price in the fire sale has to hurt somebody other than the original party making the leverage decision, and this adverse impact of price has to run through something like a collateral constraint, whereby a lowered price actually reduces, rather than increases, the third party's demand for the asset.4 So if hedge fund A buys an asset-backed security and finances it largely with collateralized borrowing, A's fire selling of the security will create an externality in the conventional sense only if the reduced price and impaired collateral value lower the ability of hedge funds B and C to borrow against the same security, and therefore force them to involuntarily liquidate their positions in it as well.5 The market failure in this case is not simply the fact that this downward spiral causes a large price decline, it is that when hedge fund A makes its initial leverage choice, it does not take into account the potential harm--in the form of tightened financing constraints--that this may cause to hedge funds B and C.6 \n\nAnother key point is that the fire-sales problem is not necessarily caused by a lack of appropriate conservatism on the part of whoever lends to hedge fund A in this example--let's call it dealer firm D. By lending on an overnight basis to A, and with an appropriate haircut, D can virtually assure itself of being able to terminate its loan and get out whole by forcing a sale of the underlying collateral. So D's interests may be very well-protected here. But precisely in the pursuit of this protection, A and D have set up a financing arrangement that serves them well, but that creates a negative spillover onto other market participants, like B and C. It follows that even if policies aimed at curbing too-big-to-fail (TBTF) problems are entirely successful in aligning D's interests with those of taxpayers, this is not sufficient to deal with fire-sales externalities. They are a fundamentally different problem, and one that arises even absent any individually systemic institutions or any TBTF issues.\n\nFire-Sale Externalities in Securities Financing Transactions\nThe preceding discussion makes clear why SFTs, such as those done via repurchase (repo) agreements, are a natural object of concern for policymakers. This market is one where a large number of borrowers finance the same securities on a short-term collateralized basis, with very high leverage--often in the range of twenty-to-one, fifty-to-one, or even higher. Hence, there is a strong potential for any one borrower's distress--and the associated downward pressure on prices--to cause a tightening of collateral or regulatory constraints on other borrowers.\n\nI won't go into much detail about the institutional aspects of SFTs and the repo market. Instead, I will just lay out two stylized examples of SFTs that I can then use to illustrate the properties of various regulatory tools.\n\nExample 1: Broker-dealer as principal\nIn this first example, a large broker-dealer firm borrows in the triparty repo market--from, say, a money market fund--in order to finance its own holdings of a particular security. Perhaps the broker-dealer is acting as a market-maker in the corporate bond market, and uses repo borrowing to finance its ongoing inventory of investment-grade and high-yield bonds. In this case, the asset on the dealer's balance sheet is the corporate bond, and the liability is the repo borrowing from the money fund.\n\nExample 2: Broker-dealer as SFT intermediary \nIn this second example, the ultimate demand to own the corporate bond comes not from the dealer firm, but from one of its prime brokerage customers--say, a hedge fund. Moreover, the hedge fund cannot borrow directly from the money market fund sector in the triparty repo market, because the money funds are not sufficiently knowledgeable about the hedge fund to be comfortable taking it on as a counterparty. So instead, the hedge fund borrows on a collateralized basis from the dealer firm in the bilateral repo market, and the dealer then turns around and, as before, uses the same collateral to borrow from a money fund in the triparty market. In this case, the asset on the dealer's balance sheet is the repo loan it makes to the hedge fund.\n\nClearly, there is the potential for fire-sale risk in both of these examples. One source of risk would be an initial shock either to the expected value of the underlying collateral or to its volatility that leads to an increase in required repo-market haircuts (e.g., the default probability of the corporate bond goes up). Another source of risk would be concerns about the creditworthiness of the broker-dealer firm that causes lenders in the triparty market to step away from it.\n\nIn either case, if the associated externalities are deemed to create significant social costs, the goal of regulatory policy should be to get private actors to internalize these costs. At an abstract level, this means looking for a way to impose an appropriate Pigouvian (i.e., corrective) tax on the transactions.7 Of course, the tax must balance the social costs against the benefits that accompany SFTs; these benefits include both \"money-like\" services from the increased stock of near-riskless private assets, as well as enhanced liquidity in the market for the underlying collateral--the corporate bond market, in my examples.8 So in the absence of further work on calibrating costs and benefits, there is no presumption that the optimal tax should be large, only that it may be non-zero, and that it may make sense for it to differ across asset classes.\n\nCan Existing Regulatory Tools Be Used to Tax SFTs Efficiently?\nWith this last observation in mind, my next step is to run through a number of our existing regulatory instruments, and in each case ask: to what extent can the instrument at hand be used efficiently to impose a Pigouvian tax on an SFT, either one of the dealer-as-principal type or one of the dealer-as-intermediary type? As will become clear, the answer can depend crucially on both the structure of the transaction as well as the nature of the underlying collateral involved. Also, I should emphasize that nothing in this exercise amounts to a judgment on the overall desirability of any given regulatory tool. Obviously, even if risk-based capital requirements are not particularly helpful in taxing SFTs, they can be very valuable for other reasons. I am asking a different question: to what extent can the existing toolkit be used--or be adapted--to deal with the specific problem of fire-sale externalities in SFTs?\n\n1. Risk-based capital requirements\nCurrent risk-based capital requirements are of little relevance for many types of SFTs. In my Example 1, where the dealer firm holds a corporate bond as a principal and finances it with repo borrowing, there would be a capital charge on the corporate bond, but this capital charge is approximately independent of whether the corporate bond is financed with repo or with some other, more stable, form of funding. So there is no tax on the incremental fire-sale risk created by the more fragile funding structure.9 \n\nIn Example 2, in which the dealer is an intermediary with a matched book of repo borrowing and lending, there is, in principle, a capital requirement on its asset-side repo loan to the hedge fund. However, the Basel III risk-based capital rules allow banks and bank holding companies to use internal models to compute this capital charge for repo lending, and the resulting numbers are typically very small--for all practical purposes, close to zero--for overcollateralized lending transactions, with repo being the canonical example.\n\nI'm not arguing that the very low risk-based charges on repo lending in Basel III are \"wrong\" in any microprudential sense. After all, they are designed to solve a different problem--that of ensuring bank solvency. And if a bank holding company's broker-dealer sub makes a repo loan of short maturity that is sufficiently well-collateralized, it may be at minimal risk of bearing any losses--precisely because it operates on the premise that it can dump the collateral and get out of town before things get too ugly. The risk-averse lenders in the triparty market--who, in turn, provide financing to the dealer--operate under the same premise. As I noted earlier, these defensive reactions by providers of repo finance mean that the costs of fire sales are likely to be felt elsewhere in the financial system.\n\n2. Liquidity requirements\nLiquidity requirements, such as those embodied in the Basel III Liquidity Coverage Ratio (LCR), can impose a meaningful tax on certain SFTs in which the dealer acts as a principal. If the dealer holds a corporate bond and finances it with repo borrowing of less than 30 days' maturity, the LCR kicks in and requires the dealer to hold high-quality liquid assets (HQLA) against the risk that it is unable to roll the repo over. In this particular case, there can be said to be a direct form of regulatory attack on the fire-sales problem. However, this conclusion is sensitive to the details of the example. If, instead of holding a corporate bond, the dealer holds a Treasury security that is deemed to count as Level 1 HQLA, there is no impact of the LCR.\n\nMoreover, the LCR plays no role in mitigating fire-sales externalities in the important matched-book case in which the dealer acts as an intermediary.10 If a dealer borrows on a collateralized basis with repo and then turns around and lends the proceeds to a hedge fund in a similar fashion, the LCR deems the dealer to have no net liquidity exposure--and hence imposes no incremental liquidity requirement--so long as the lending side of the transaction has a maturity of less than 30 days. The implicit logic is that as long as the dealer can generate the necessary cash by not rolling over its loan to the hedge fund, it will always be able to handle any outflows of funding that come from being unable to roll over its own borrowing. This logic is not incorrect per se, but it is very micro-focused in nature, and does not attend to fire-sales externalities. It worries about the ability of the dealer firm to survive a liquidity stress event, but does not take into account that the dealer's survival may come at the cost of forcing its hedge fund client to engage in fire sales.11 \n\n3. Leverage ratio\nIf a broker-dealer firm faces a binding leverage ratio, this constraint can act as a significant tax on two types of SFTs that are largely untouched either by risk-based capital requirements or by liquidity regulations. The first is when the dealer, acting as a principal, uses repo to finance its holdings of Treasury securities or agency mortgage-backed securities, assets that generally have only modest risk weights when held as trading positions. The second is when the dealer acts as an intermediary and has a matched repo book. In both cases, the SFTs blow up the firm's balance sheet and, hence, the denominator of the leverage ratio, even while having little impact on risk-based capital or LCR calculations.\n\nThe crucial issue here, however, is whether the leverage ratio does, in fact, bind. A traditional view among regulators has been that the leverage ratio should be calibrated so as to serve as a meaningful \"backstop\" for risk-based capital requirements, but that under ordinary circumstances it should not actually be the binding constraint on firms. For if it were to bind, this would put us in a regime of completely un-risk-weighted capital requirements, where the effective capital charge for holding short-term Treasury securities would be the same as that for holding, say, risky corporate debt securities or loans.\n\nRecently, U.S. regulators have issued a proposed rulemaking that seeks to raise the BaselIII supplementary leverage ratio requirement to 5 percent for the largest U.S. bank holding companies, and to 6 percent for their affiliated depository institutions. While this increase might be considered a parallel shift that preserves the backstop philosophy in light of the fact that risk-based requirements have also gone up significantly, it does increase the likelihood that the leverage ratio may bind for some of these firms at some times--particularly for those firms with a broker-dealer-intensive business model in which the ratio of total assets to risk-weighted assets tends to be higher. In this event, there would indeed be a significant tax on SFTs undertaken in the affected firms. However, because it is unlikely that the leverage constraint would bind symmetrically across all of the largest firms, my guess is that the effect would be less to deter SFT activity in the aggregate than to cause it to migrate in such a way as to be predominantly located in those firms that--because they have, say, a larger lending business and, hence, more risk-weighted assets--have more headroom under the leverage ratio constraint.\n\nOther Possible Approaches\nTo summarize the discussion thus far, the mainstays of our existing regulatory toolkit--risk-based capital, liquidity, and leverage requirements--have a variety of other virtues, but none seem well-suited to lean in a comprehensive way against the specific fire-sale externalities created by SFTs. The liquidity coverage ratio affects a subset of SFTs in which a dealer firm acts as a principal to fund its own inventory of securities positions, but does not meaningfully touch those in which it acts as an intermediary. By contrast, an aggressively calibrated leverage ratio could potentially impose a significant tax on a wider range of SFTs, but the tax would by its nature be blunt and highly asymmetric, falling entirely on those firms for whom the leverage ratio constraint was more binding than the risk-based capital constraint. As such, it would be more likely to induce regulatory arbitrage than to rein in overall SFT activity.\n\nThese observations raise the question of whether there are other tools that might be better suited to dealing with SFT-related fire-sales externalities. I will touch briefly on three of these.\n\n1. Capital surcharges\nIn his May speech, Governor Tarullo alluded to the possibility of liquidity-linked capital surcharges that would effectively augment the existing regime of risk-based capital requirements.12 Depending on how these surcharges are structured, they could act in part as a tax on both the dealer-as-principal and dealer-as-intermediary types of SFTs. Accomplishing the latter would require a capital surcharge based on something like the aggregate size of the dealer's matched repo book; this comes quite close to the Pigouvian notion of directly taxing this specific activity. As compared to relying on the leverage ratio to implement the tax, this approach has the advantage that it is more likely to treat institutions uniformly: the tax on SFTs would not be a function of the overall business model of a given firm, but rather just the characteristics of its SFT book. This is because the surcharge is embedded into the existing risk-based capital regime, which should in principle be the constraint that binds for most firms.\n\nThere are a couple of important qualifications, however. First, going this route would involve a significant conceptual departure from the notion of capital as a prudential requirement at the firm level. As noted previously, a large matched repo book may entail relatively little solvency or liquidity risk for the broker-dealer firm that intermediates this market. So, to the extent that one imposes a capital surcharge on the broker-dealer, one would be doing so with the express intention of creating a tax that is passed on to the downstream borrower (i.e., to the hedge fund, in my example).\n\nSecond, and a direct corollary of the first, imposing the tax at the level of the intermediary naturally raises the question of disintermediation. In other words, might the SFT market respond to the tax by evolving so that large hedge funds are more readily able to borrow via repo directly from money market funds and securities lenders, without having to go through broker-dealers? I can't say that I have a good understanding of the institutional factors that might facilitate or impede such an evolution. But if the market ultimately does evolve in this way, it would be hard to argue that the underlying fire-sales problem has been addressed.\n\n2. Modified liquidity regulation\nA conceptually similar way to get at matched-book repo would be to modify liquidity regulation so as to introduce an asymmetry between the assumed liquidity properties of repo loans made by a broker-dealer, and its own repo borrowing. For example, in the context of the Net Stable Funding Ratio (NSFR), one could assume that a dealer's repo loans to a hedge fund roll off more slowly than do its own repo borrowings from the triparty market. This assumption would create a net liquidity exposure for a matched repo book, and would thereby force the dealer to hold some long-term debt or other stable funding against it. Although the implementation is different, the end result is quite close to that obtained with the capital-surcharge approach I just described: in one case, there is a broad stable funding requirement for intermediaries against a matched repo book; in the other case, there is an equity requirement. It follows that, whatever its other advantages, going the modified-NSFR route does not eliminate concerns about disintermediation and regulatory arbitrage.\n\n3. Universal margin requirements\nThese sorts of regulatory-arbitrage concerns have motivated some academics and policymakers to think about a system of universal margin requirements for SFTs.13 In its simplest form, the idea would be to impose a minimum haircut, or down payment requirement, on any party--be it a hedge fund or a broker-dealer--that uses short-term collateralized funding to finance its securities holdings. Because the requirement now lives at the security level, rather than at the level of an intermediary in the SFT market, it cannot be as easily evaded by, say, a hedge fund going outside the broker-dealer sector to obtain its repo funding.14 This is the strong conceptual appeal of universal margin from the perspective of a fire-sales framework.\n\nIn this regard, it is worth noting that the Financial Stability Board (FSB) has recently released a proposal to establish minimum haircut requirements for certain SFTs.15 However, the FSB proposal stops well short of being a universal margin requirement. Rather, the minimum haircuts envisioned by the FSB would apply only to SFTs in which entities not subject to capital and liquidity regulation (e.g., hedge funds) receive financing from entities that are subject to regulation (i.e., banks and broker-dealers), and only to transactions in which the collateral is something other than government or agency securities. In this sense, there is a close relationship between the FSB minimum-haircut proposal and the specific variant of the capital-surcharge idea that I mentioned a moment ago. Both have the potential to act as a restraint on those SFTs that are intermediated by regulated broker-dealer firms, but both are vulnerable to an evolution of the business away from this intermediated mode. The minimum margin levels in the FSB proposal are also quite small, so it is unclear how much of an effect, if any, they will have on market behavior. For example, the minimums for long-term corporate bonds, securitized products, and equities are 2 percent, 4 percent, and 4 percent, respectively.\n\nConclusions\nLet me wrap up. My aim here has been to survey the landscape--to give a sense of the possible tools that can be used to address the fire-sales problem in SFTs--without making any particularly pointed recommendations. I would guess that a sensible path forward might involve drawing on some mix of the latter set of instruments that I discussed: namely, capital surcharges, modifications to the liquidity regulation framework, and universal margin requirements. As we go down this path, conceptual purity may have to be sacrificed in some places to deliver pragmatic and institutionally feasible results. It is unlikely that we will find singular and completely satisfactory fixes.\n\nWith this observation in mind, I would be remiss if I did not remind you of another, highly complementary area where reform is necessary: the money market fund sector. Money funds are among the most significant repo lenders to broker-dealer firms, and an important source of fire-sale risk comes from the fragility of the current money fund model. This fragility stems in part from their capital structures--the fact that they issue stable-value demandable liabilities with no capital buffer or other explicit loss-absorption capacity--which make them highly vulnerable to runs by their depositors. I welcome the work of the Securities and Exchange Commission on this front, particularly its focus on floating net asset values, and look forward to concrete action. Another source of fragility arises from money funds investing in repo loans collateralized by assets that they are unwilling or unable to hold if things go bad. This feature creates an incentive for them to withdraw repo financing from broker-dealers at the first sign of counterparty risk, even if the underlying collateral is in good shape.\n\nIn closing, I just want to acknowledge how much my own thinking about these complicated issues has benefited from the work of so many of you on the program at this conference. I look forward to continuing the conversation. Thank you.\n\n1. A version of these remarks was previously presented at the Federal Reserve Bank of New York's Workshop on \"Fire Sales as a Driver of Systemic Risk in Triparty Repo and Other Secured Funding Markets\" (October 4, 2013). I am grateful for comments from Matt Eichner, Mike Gibson, Nellie Liang, Bill Nelson, and Mark Van Der Weide. The thoughts in this speech are my own, and are not necessarily shared by other members of the Federal Open Market Committee.Return to text\n\n2. Daniel K. Tarullo (2013), \"Evaluating Progress in Regulatory Reforms to Promote Financial Stability,\" speech at the Peterson Institute for International Economics in Washington, D.C., May 3. Return to text\n\n3. Andrei Shleifer and Robert Vishny (2011), \"Fire Sales in Finance and Macroeconomics (PDF) ,\" Journal of Economic Perspectives, vol. 25 (Winter), p. 30. Return to text\n\n4. An alternative mechanism that works similarly is when the third party is a regulated intermediary and mark-to-market losses reduce its capital ratios, and again force it to involuntarily sell assets in the face of falling prices. Return to text\n\n5. The fundamental welfare economics at work here is developed in John Geanakoplos and Heracles M. Polemarchakis (1986), \"Existence, Regularity, and Constrained Suboptimality of Competitive Allocations When the Asset Market Is Incomplete,\" in Walter P. Heller, Ross M. Starr, and David A. Starrett, eds., Essays in Honor of Kenneth Arrow: Vol 3., Uncertainty, Information, and Communication (New York: Cambridge University Press), pp. 65-95. A discussion of the connection of this work to specific aspects of macroprudential regulation is in Samuel G. Hanson, Anil K. Kashyap, and Jeremy C. Stein (2011), \"A Macroprudential Approach to Financial Regulation (PDF) ,\" Journal of Economic Perspectives, vol. 25 (Winter), pp. 3-28. Return to text\n\n6. This is the first-round externality. Adverse spillovers from a fire sale of this sort may also take the form of a credit crunch that affects borrowers more generally. Such a credit crunch may arise as other financial intermediaries (e.g., banks) withdraw capital from lending, so as to exploit the now-more-attractive returns to buying up fire-sold assets. Ultimately, it is the risk of this credit contraction, and its implications for economic activity more broadly, that may be the most compelling basis for regulatory intervention. Return to text\n\n7. Of course, the Pigouvian taxation approach by itself cannot completely eliminate the ex post costs associated with fire sales. This would require a broad and active lender-of-last resort function, which I do not discuss here. The best that any form of ex ante regulation can hope to do is to reduce the incidence and magnitude of ex post fire-sales damage. Return to text\n\n8. Further discussion on the money-like benefits that are created by near-riskless private assets such as repo can be found in the following: Arvind Krishnamurthy and Annette Vissing-Jorgensen (2012), \"The Aggregate Demand for Treasury Debt ,\" Journal of Political Economy, vol. 120, issue 2 (April), pp. 233-267; Gary B. Gorton and Andrew Metrick (2012), \"Securitized Banking and the Run on Repo,\" Journal of Financial Economics, vol. 103, pp. 425-451; and Jeremy C. Stein (2012), \"Monetary Policy as Financial-Stability Regulation,\" Quarterly Journal of Economics, vol. 127, pp. 57-95. Return to text\n\n9. To be more precise, under Basel III capital rules, there is a small risk-based capital requirement on the repo liability. This requirement is driven by counterparty credit risk, not liquidity risk, and is independent of the term of the repo borrowing. The basic idea is that the repo borrower has to hold a little bit of capital because it has sent $102 in Treasury securities over to its counterparty lender and only received $100 cash. If the repo lender defaults, the borrower could be out $2. Return to text\n\n10. A similar comment applies to the Net Stable Funding Ratio (NSFR), which requires regulated firms to fund illiquid exposures with some amount of long-term debt or other form of stable funding. Like the LCR, the NSFR effectively treats matched-book repo as creating no net liquidity exposure, and hence imposes no requirement on it. Return to text\n\n11. Even from a microprudential perspective, the LCR can be said to have a flaw in that it is blind to maturity mismatches within the 30-day window. For example, if a dealer borrows on an overnight basis from a money fund, and then makes a 29-day loan to a hedge fund, the LCR deems it to be fully matched, and to have no incremental liquidity exposure. Return to text\n\n12. Tarullo (2013) Return to text\n\n13. A closely related motivation for universal margin requirements is that they might be able to limit procyclicality by leaning against increases in leverage during boom times. Return to text\n\n14. Of course, there is always the potential for other forms of regulatory arbitrage. For example, a hedge fund that faces a minimum margin requirement when it uses repo borrowing to fund a corporate-bond position may instead seek to take a leveraged position in the corporate bond through other means by, for example, engaging in a total-return swap with its prime broker. This is the growing business of \"synthetic\" prime brokerage. Properly harmonized initial margin requirements on uncleared derivatives may help to level the playing field between traditional and synthetic prime brokerage activities. Return to text\n\n15. Financial Stability Board (2013), Strengthening Oversight and Regulation of Shadow Banking: Policy Framework for Addressing Shadow Banking Risks in Securities Lending and Repos (PDF) , August 29. Return to text"
    },
    {
        "title": "The Crisis as a Classic Financial Panic",
        "date": "November 08, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20131108a.htm",
        "content": "November 08, 2013\n\nChairman Ben S. Bernanke\n\nAt the Fourteenth Jacques Polak Annual Research Conference, Washington, D.C.\n\nI am very pleased to participate in this event in honor of Stanley Fischer. Stan was my teacher in graduate school, and he has been both a role model and a frequent adviser ever since. An expert on financial crises, Stan has written prolifically on the subject and has also served on the front lines, so to speak--notably, in his role as the first deputy managing director of the International Monetary Fund during the emerging market crises of the 1990s. Stan also helped to fight hyperinflation in Israel in the 1980s and, as the governor of that nation's central bank, deftly managed monetary policy to mitigate the effects of the recent crisis on the Israeli economy. Subsequently, as Israeli housing prices ran upward, Stan became an advocate and early adopter of macroprudential policies to preserve financial stability.\n\nStan frequently counseled his students to take a historical perspective, which is good advice in general, but particularly helpful for understanding financial crises, which have been around a very long time. Indeed, as I have noted elsewhere, I think the recent global crisis is best understood as a classic financial panic transposed into the novel institutional context of the 21st century financial system.1 An appreciation of the parallels between recent and historical events greatly influenced how I and many of my colleagues around the world responded to the crisis.\n\nBesides being the fifth anniversary of the most intense phase of the recent crisis, this year also marks the centennial of the founding of the Federal Reserve.2 It's particularly appropriate to recall, therefore, that the Federal Reserve was itself created in response to a severe financial panic, the Panic of 1907. This panic led to the creation of the National Monetary Commission, whose 1911 report was a major impetus to the Federal Reserve Act, signed into law by President Woodrow Wilson on December 23, 1913. Because the Panic of 1907 fit the archetype of a classic financial panic in many ways, it's worth discussing its similarities and differences with the recent crisis.3 \n\nLike many other financial panics, including the most recent one, the Panic of 1907 took place while the economy was weakening; according to the National Bureau of Economic Research, a recession had begun in May 1907.4 Also, as was characteristic of pre-Federal Reserve panics, money markets were tight when the panic struck in October, reflecting the strong seasonal demand for credit associated with the harvesting and shipment of crops. The immediate trigger of the panic was a failed effort by a group of speculators to corner the stock of the United Copper Company. The main perpetrators of the failed scheme, F. Augustus Heinze and C.F. Morse, had extensive connections with a number of leading financial institutions in New York City. When the news of the failed speculation broke, depositor fears about the health of those institutions led to a series of runs on banks, including a bank at which Heinze served as president. To try to restore confidence, the New York Clearinghouse, a private consortium of banks, reviewed the books of the banks under pressure, declared them solvent, and offered conditional support--one of the conditions being that Heinze and his board step down. These steps were largely successful in stopping runs on the New York banks.\n\nBut even as the banks stabilized, concerns intensified about the financial health of a number of so-called trust companies--financial institutions that were less heavily regulated than national or state banks and which were not members of the Clearinghouse. As the runs on the trust companies worsened, the companies needed cash to meet the demand for withdrawals. In the absence of a central bank, New York's leading financiers, led by J.P. Morgan, considered providing liquidity. However, Morgan and his colleagues decided that they did not have sufficient information to judge the solvency of the affected institutions, so they declined to lend. Overwhelmed by a run, the Knickerbocker Trust Company failed on October 22, undermining public confidence in the remaining trust companies.\n\nTo satisfy their depositors' demands for cash, the trust companies began to sell or liquidate assets, including loans made to finance stock purchases. The selloff of shares and other assets, in what today we would call a fire sale, precipitated a sharp decline in the stock market and widespread disruptions in other financial markets. Increasingly concerned, Morgan and other financiers (including the future governor of the Federal Reserve Bank of New York, Benjamin Strong) led a coordinated response that included the provision of liquidity through the Clearinghouse and the imposition of temporary limits on depositor withdrawals, including withdrawals by correspondent banks in the interior of the country. These efforts eventually calmed the panic. By then, however, the U.S. financial system had been severely disrupted, and the economy contracted through the middle of 1908.\n\nThe recent crisis echoed many aspects of the 1907 panic. Like most crises, the recent episode had an identifiable trigger--in this case, the growing realization by market participants that subprime mortgages and certain other credits were seriously deficient in their underwriting and disclosures. As the economy slowed and housing prices declined, diverse financial institutions, including many of the largest and most internationally active firms, suffered credit losses that were clearly large but also hard for outsiders to assess. Pervasive uncertainty about the size and incidence of losses in turn led to sharp withdrawals of short-term funding from a wide range of institutions; these funding pressures precipitated fire sales, which contributed to sharp declines in asset prices and further losses. Institutional changes over the past century were reflected in differences in the types of funding that ran: In 1907, in the absence of deposit insurance, retail deposits were much more prone to run, whereas in 2008, most withdrawals were of uninsured wholesale funding, in the form of commercial paper, repurchase agreements, and securities lending. Interestingly, a steep decline in interbank lending, a form of wholesale funding, was important in both episodes. Also interesting is that the 1907 panic involved institutions--the trust companies--that faced relatively less regulation, which probably contributed to their rapid growth in the years leading up to the panic. In analogous fashion, in the recent crisis, much of the panic occurred outside the perimeter of traditional bank regulation, in the so-called shadow banking sector.5 \n\nThe responses to the panics of 1907 and 2008 also provide instructive comparisons. In both cases, the provision of liquidity in the early stages was crucial. In 1907 the United States had no central bank, so the availability of liquidity depended on the discretion of firms and private individuals, like Morgan. In the more recent crisis, the Federal Reserve fulfilled the role of liquidity provider, consistent with the classic prescriptions of Walter Bagehot.6 The Fed lent not only to banks, but, seeking to stem the panic in wholesale funding markets, it also extended its lender-of-last-resort facilities to support nonbank institutions, such as investment banks and money market funds, and key financial markets, such as those for commercial paper and asset-backed securities.\n\nIn both episodes, though, liquidity provision was only the first step. Full stabilization requires the restoration of public confidence. Three basic tools for restoring confidence are temporary public or private guarantees, measures to strengthen financial institutions' balance sheets, and public disclosure of the conditions of financial firms. At least to some extent, Morgan and the New York Clearinghouse used these tools in 1907, giving assistance to troubled firms and providing assurances to the public about the conditions of individual banks. All three tools were used extensively in the recent crisis: In the United States, guarantees included the Federal Deposit Insurance Corporation's (FDIC) guarantees of bank debt, the Treasury Department's guarantee of money market funds, and the private guarantees offered by stronger firms that acquired weaker ones. Public and private capital injections strengthened bank balance sheets. Finally, the bank stress tests that the Federal Reserve led in the spring of 2009 and the publication of the stress-test findings helped restore confidence in the U.S. banking system. Collectively, these measures helped end the acute phase of the financial crisis, although, five years later, the economic consequences are still with us.\n\nOnce the fire is out, public attention turns to the question of how to better fireproof the system. Here, the context and the responses differed between 1907 and the recent crisis. As I mentioned, following the 1907 crisis, reform efforts led to the founding of the Federal Reserve, which was charged both with helping to prevent panics and, by providing an \"elastic currency,\" with smoothing seasonal interest rate fluctuations. In contrast, reforms since 2008 have focused on critical regulatory gaps revealed by the crisis. Notably, oversight of the shadow banking system is being strengthened through the designation, by the new Financial Stability Oversight Council, of nonbank systemically important financial institutions (SIFIs) for consolidated supervision by the Federal Reserve, and measures are being undertaken to address the potential instability of wholesale funding, including reforms to money market funds and the triparty repo market.7 \n\nAs we try to make the financial system safer, we must inevitably confront the problem of moral hazard. The actions taken by central banks and other authorities to stabilize a panic in the short run can work against stability in the long run, if investors and firms infer from those actions that they will never bear the full consequences of excessive risk-taking. As Stan Fischer reminded us following the international crises of the late 1990s, the problem of moral hazard has no perfect solution, but steps can be taken to limit it.8 First, regulatory and supervisory reforms, such as higher capital and liquidity standards or restriction on certain activities, can directly limit risk-taking. Second, through the use of appropriate carrots and sticks, regulators can enlist the private sector in monitoring risk-taking. For example, the Federal Reserve's Comprehensive Capital Analysis and Review (CCAR) process, the descendant of the bank stress tests of 2009, requires not only that large financial institutions have sufficient capital to weather extreme shocks, but also that they demonstrate that their internal risk-management systems are effective.9 In addition, the results of the stress-test portion of CCAR are publicly disclosed, providing investors and analysts information they need to assess banks' financial strength.\n\nOf course, market discipline can only limit moral hazard to the extent that debt and equity holders believe that, in the event of distress, they will bear costs. In the crisis, the absence of an adequate resolution process for dealing with a failing SIFI left policymakers with only the terrible choices of a bailout or allowing a potentially destabilizing collapse. The Dodd-Frank Act, under the orderly liquidation authority in Title II, created an alternative resolution mechanism for SIFIs that takes into account both the need, for moral hazard reasons, to impose costs on the creditors of failing firms and the need to protect financial stability; the FDIC, with the cooperation of the Federal Reserve, has been hard at work fleshing out this authority.10 A credible resolution mechanism for systemically important firms will be important for reducing uncertainty, enhancing market discipline, and reducing moral hazard.\n\nOur continuing challenge is to make financial crises far less likely and, if they happen, far less costly. The task is complicated by the reality that every financial panic has its own unique features that depend on a particular historical context and the details of the institutional setting. But, as Stan Fischer has done with unusual skill throughout his career, one can, by stripping away the idiosyncratic aspects of individual crises, hope to reveal the common elements. In 1907, no one had ever heard of an asset-backed security, and a single private individual could command the resources needed to bail out the banking system; and yet, fundamentally, the Panic of 1907 and the Panic of 2008 were instances of the same phenomenon, as I have discussed today. The challenge for policymakers is to identify and isolate the common factors of crises, thereby allowing us to prevent crises when possible and to respond effectively when not.\n\n1. See Ben S. Bernanke (2012), \"Some Reflections on the Crisis and the Policy Response,\" speech delivered at \"Rethinking Finance,\" a conference sponsored by the Russell Sage Foundation and Century Foundation, New York, April 13. For the classic discussion of financial panics and the appropriate central bank response, see Walter Bagehot ([1873] 1897), Lombard Street: A Description of the Money Market (New York: Charles Scribner's Sons). Return to text\n\n2. Information on the centennial of the Federal Reserve System is available at www.federalreserve.gov/aboutthefed/centennial/about.htm .Return to text\n\n3. The Panic of 1907 is discussed in a number of sources, including O.M.W. Sprague (1910), A History of Crises under the National Banking System (PDF), National Monetary Commission (Washington: U.S. Government Printing Office), and, with a focus on its monetary consequences, Milton Friedman and Anna Jacobson Schwartz (1963), A Monetary History of the United States, 1867-1960 (Princeton, N.J.: Princeton University Press). An accessible discussion of the episode, from which this speech draws heavily, can be found in Jon R. Moen and Ellis W. Tallman (1990), \"Lessons from the Panic of 1907 (PDF),\" Federal Reserve Bank of Atlanta, Economic Review, May/June, pp. 2-13. Return to text\n\n4. See Charles W. Calomiris and Gary Gorton (1991), \"The Origins of Banking Panics: Models, Facts, and Bank Regulation,\" in R. Glenn Hubbard, ed., Financial Markets and Financial Crises (Chicago: University of Chicago Press), pp. 109-74. Return to text\n\n5. As discussed in Bernanke, \"Some Reflections on the Crisis\" (see note 1), shadow banking, as usually defined, comprises a diverse set of institutions and markets that, collectively, carry out traditional banking functions--but do so outside, or in ways only loosely linked to, the traditional system of regulated depository institutions. Examples of important components of the shadow banking system include securitization vehicles, asset-backed commercial paper conduits, money market funds, markets for repurchase agreements, investment banks, and mortgage companies. Return to text\n\n6. See Bagehot, Lombard Street, in note 1. Return to text\n\n7. For a more comprehensive discussion of recent changes in the regulatory framework, see Daniel K. Tarullo (2013), \" Evaluating Progress in Regulatory Reforms to Promote Financial Stability,\" speech delivered at the Peterson Institute for International Economics, Washington, May 3. Return to text\n\n8. See Stanley Fischer (1999), \"On the Need for an International Lender of Last Resort,\" Journal of Economic Perspectives, vol. 13 (Fall), pp. 85-104. Return to text\n\n9. For example, see Board of Governors of the Federal Reserve System (2013), Capital Planning at Large Bank Holding Companies: Supervisory Expectations and Range of Current Practice (PDF) (Washington: Board of Governors, August). Return to text\n\n10. For a more detailed discussion, see Daniel K. Tarullo (2013), \"Toward Building a More Effective Resolution Regime: Progress and Challenges,\" speech delivered at \"Planning for the Orderly Resolution of a Global Systemically Important Bank,\" a conference sponsored by the Federal Reserve Board and the Federal Reserve Bank of Richmond, Washington, October 18. Return to text\n\n "
    },
    {
        "title": "Teaching and Learning about the Federal Reserve",
        "date": "November 13, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20131113a.htm",
        "content": "November 13, 2013\n\nChairman Ben S. Bernanke\n\nAt A Teacher Town Hall Meeting: 100 Years of the Federal Reserve, Washington, D.C.\n\nThank you for that introduction. Tonight marks the third time in just a little over three years that the Federal Reserve System has hosted a teacher town hall, and I am very pleased to have this opportunity to speak with educators, both those of you here in Washington, D.C., and those watching at Reserve Bank gatherings around the country. I look forward to your questions in a few moments. But let me begin by briefly discussing an important milestone for the Federal Reserve--its centennial--and the opportunity that this occasion affords to teach and learn about the Fed's origins, history, and role, and about how this institution has helped shape the nation's economy and financial system.\n\nPresident Woodrow Wilson signed the Federal Reserve Act, which established the Federal Reserve System, on December 23, 1913. As the 100th anniversary of that event approaches, we have several reasons to look back at an eventful century. One important reason is to better understand what historical experience can teach us about how best to respond to current challenges. For example, as many of you know, the bold measures the Fed took in response to the recent financial crisis reflected in part its determination to avoid repeating the sorts of mistakes it made before and during the Great Depression of the 1930s. Similarly, our commitment to safeguarding price stability is reinforced by memories of the costs of high inflation during the 1970s and the Federal Reserve's subsequent restoration of price stability under Chairman Volcker during the 1980s.\n\nBeyond the insights that the study of the Federal Reserve's first 100 years offer to economists, historians, and policymakers about how the Fed can best meet its objectives today and in the future, a second reason to mark the centennial is the opportunity it affords to educate young people about the Federal Reserve and its important role in promoting a healthy economy and stable financial system. When I was an educator, I quickly came to understand that students are most motivated to learn when they can see the connection of the lesson to their own lives. The Fed and its activities, and economics in general, can seem remote from daily concerns. But as teachers, you can show students how the Federal Reserve's decisions concretely affect them and their families. The Fed's actions influence the overall strength and stability of the economy, as you know, but they also affect the cost of a mortgage, the prices of goods and services, and the health of the job market that your students are part of or will soon be entering.\n\nEconomics also complements and enriches the study of history. When I took history classes in high school, we spent much of our time memorizing dates and important events--revolutions, wars, elections, the passage of laws, and so on. While I appreciated the need to be familiar with such milestones, I remember feeling that I would like to know more about the lives of ordinary people at those times, not just about kings and queens and presidents. In college and graduate school, I studied economic history and found what I was looking for. For me, economic history added critical context by zooming in on the conditions of ordinary life--how people earned their livings, what their wages would buy, the extent to which they felt economically secure, the pace of economic change that they faced. Appreciating what the lives of ordinary people were like at various times and places helped explain the larger events--the wars, revolutions, and elections--as well.\n\nBy the same token, understanding history also requires an appreciation of the role of key economic institutions, including central banks like the Federal Reserve. When I was in graduate school, my teacher, Stanley Fischer, introduced me to the work of Milton Friedman and Anna Schwartz, which demonstrated that monetary policy can have enormous effects on how the economy performs, for good or for ill. That realization helped motivate me to specialize, in graduate school and after, in monetary economics and related fields. Similarly, for your students, it's impossible to understand the Great Depression, America's strong economic performance after World War II, or the recent financial crisis without learning about the Federal Reserve and the debates that have surrounded it.\n\nLearning about the Federal Reserve and about economics more generally will help students in their daily lives, by helping them make better financial or career decisions, for example, and by helping them become more informed citizens and voters. Learning about the Federal Reserve and its economic context will also give students a deeper understanding of history, as I noted. Yet there is one more reason why we at the Fed hope to use this centennial as an educational opportunity--to maintain and strengthen the democratic accountability and effectiveness of this institution.\n\nTraditionally, like other central banks, the Fed was reluctant to explain its policy decisions or otherwise engage with the public, partly based on a belief that this approach increased the effectiveness of monetary policy. However, this lack of openness became increasingly out of step with other institutions in our democratic society; it also reduced the effectiveness of Fed policies by inhibiting public understanding and discussion of policy goals and strategies. This approach began to change in the 1990s, when the Federal Reserve began to regularly provide more information about how it saw the economic situation and how it would respond. Increasing the Fed's transparency, openness, and accountability has been one of my top priorities as Chairman. A more open Fed, in my view, is both a more effective and more democratically legitimate institution. Indeed, the complex challenges we face as a nation are best addressed in an environment of informed public discourse, which is only possible when policy decisions are made in as transparent a way as possible. The centennial may be just an accident of the calendar, but any time is a good time to help more people learn about the Fed and what it does to enhance the economic well-being of Americans.\n\nIt is often said--alas, accurately--that teaching is a thankless profession, so let me close by thanking you for what you give to your students. Our country and our economy need informed citizens who can think independently and critically. More pertinent to today's meeting, let me also thank you for your interest in teaching your students about the history and role of the Federal Reserve. As many of you have discovered, the Federal Reserve has a variety of classroom tools available through our education portal, FederalReserveEducation.org . Notably, the System's economic and financial education staff is introducing today a set of three lesson plans that examine the past 100 years of central banking. I hope they will provide practical help in your classes.\n\nThank you for participating in today's event. I look forward to your questions and to an interesting discussion of the Federal Reserve's past, present, and future."
    },
    {
        "title": "40th Anniversary of the Annual Conference of the Union of Arab Banks",
        "date": "November 14, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20131114a.htm",
        "content": "November 14, 2013\n\nChairman Ben S. Bernanke\n\nAt the Annual Conference of the Union of Arab Banks, Beirut, Lebanon (via prerecorded video)\n\nGood morning. I am pleased to address the Annual Conference of the Union of Arab Banks (UAB) as it celebrates 40 years of success representing the interests of the Arab banking and financial communities.\n\nThe UAB may justifiably take great pride in its many accomplishments during the past four decades. Among other achievements, the UAB has emerged as a key international and regional participant in developing policies that promote financial stability, economic integration, and sustainable development and prosperity. The UAB has also been a champion of sharing best practices and training among regulators and bankers.\n\nThe partnership that has developed between the Federal Reserve and the UAB may be counted among these successes. Ten years ago, the Federal Reserve helped establish--with the support of many of the countries represented at this conference--the Middle East and North Africa (MENA) Financial Regulators' Initiative. Sarkis Yoghourtdjian of the Federal Reserve Board, who is attending with you today, was asked to lead this initiative, whose aim has been to provide technical assistance and bank supervision training to central banks and bank supervisory authorities. Now in its 10th and final year, the Financial Regulators' Initiative has sponsored more than 40 training programs and conferences throughout the MENA region, and it has provided many short-term, on-the-job training opportunities for MENA regulators with U.S. banking agencies. We are grateful to the UAB for its many contributions to the success of this initiative.\n\nIn addition to celebrating accomplishments, anniversaries also provide a time for reflection and self-assessment. Governments, central bankers, financial regulators, and the banking industry still labor today in the long shadow cast by the global financial crisis. Against that backdrop, financial regulators around the world are engaged in a historic and sweeping renovation of the global financial structure.\n\nOne of the most important goals is to ensure that banks hold more and higher-quality capital, and have sufficient liquid assets on hand, to be able to survive a market shock or severe economic downturn. In addition, we must push banking organizations of all sizes to ensure their compensation practices link pay to performance and do not encourage excessive risk-taking.\n\nPast and current crises underscore an additional lesson. Then as now, international or regional financial crises require a coordinated response to safeguard the stability of the world's financial system. To that end, the UAB can play an important regional role by facilitating efforts to address potential cross-border issues, and by providing a local platform for strong cooperation between home and host supervisors during normal and crisis periods.\n\nAt your conference this week, I anticipate you will discuss the opportunities and challenges that lay ahead for your members. Among the topics, no doubt, will be the prospects for partnership between the public and private sectors, the importance of establishing institutions capable of managing crises, the effects of new regulatory and supervisory structures on the banking industry, and the role of the banking sector in promoting economic growth.\n\nWe at the Federal Reserve face similar challenges and opportunities, and we look forward to working with you to find common approaches and solutions. I wish you a successful and productive conference. Warm congratulations on your 40th anniversary, and best wishes for another 40 years of success."
    },
    {
        "title": "Communication and Monetary Policy",
        "date": "November 19, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20131119a.htm",
        "content": "November 19, 2013\n\nChairman Ben S. Bernanke\n\nAt the National Economists Club Annual Dinner, Herbert Stein Memorial Lecture, Washington, D.C.\n\nNearly eight years ago, when I began my time as Chairman, one of my priorities was to make the Federal Reserve more transparent--and, in particular, to make monetary policy as transparent and open as reasonably possible. I believed then, as I do today, that transparency in monetary policy enhances public understanding and confidence, promotes informed discussion of policy options, increases the accountability of monetary policymakers for reaching their mandated objectives, and ultimately makes policy more effective by tightening the linkage between monetary policy, financial conditions, and the real economy. Of course, responding to the financial crisis and its aftermath soon became the Federal Reserve's main focus. As it has turned out, however, following the stabilization of the financial system, supporting our economy's recovery from the deepest recession since the Great Depression has required a more prominent role for communication and transparency in monetary policy than ever before.\n\nIn my remarks, I will discuss how the Federal Reserve's communications have evolved in recent years and how enhanced transparency is increasing the effectiveness of monetary policy. Despite the challenges inherent in communicating in an unprecedented economic and policy environment about a future that can be only imperfectly foreseen, I will explain why I believe that policy transparency remains an essential element of the Federal Reserve's strategy for meeting its economic objectives.\n\nPolicy Frameworks and Communication\nTo understand the critical role that the Federal Reserve's communications about monetary policy has played in recent years, it is useful to start by discussing the role of monetary policy communication more generally, including the relationship between policy communication and the broader policy framework.\n\nMaking monetary policy is sometimes compared to driving a car, with policymakers pressing on the accelerator or the brakes, depending on whether the economy needs to be sped up or slowed down at that moment. That analogy is imperfect, however, for at least two reasons. First, the main effects of monetary policy actions on the economy are not felt immediately but instead play out over quarters or even years. Hence, unlike the driver of a car, monetary policymakers cannot simply respond to what lies immediately in front of them but must try to look well ahead--admittedly, a difficult task. Second, the effects of monetary policy on the economy today depend importantly not only on current policy actions, but also on the public's expectations of how policy will evolve. The automotive analogy clearly breaks down here, for it is as if the current speed of the car depended on what the car itself expects the driver to do in the future.\n\nThe public's expectations about future monetary policy actions matter today because those expectations have important effects on current financial conditions, which in turn affect output, employment, and inflation over time. For example, because investors can choose freely between holding a longer-term security or rolling over a sequence of short-term securities, longer-term interest rates today are closely linked to market participants' expectations of how short-term rates will evolve. If monetary policymakers are expected to keep short-term interest rates low, then current longer-term interest rates are likely to be low as well, all else being equal. In short, for monetary policy, expectations matter.\n\nIndeed, expectations matter so much that a central bank may be able to help make policy more effective by working to shape those expectations. Experience demonstrates that a useful approach to managing expectations--one that dovetails well with basic principles of transparency--involves policymakers stating clear objectives as well as their plans for attaining those objectives. For example, over the past two decades, many central banks have introduced explicit numerical targets for inflation. Supplemented by regular publication of the central bank's economic forecasts and provisional plans for achieving its objective in the medium term, numerical inflation goals have helped increase the transparency and predictability of policy in a number of economies.\n\nIn this spirit, the Federal Open Market Committee (FOMC) has clarified the Federal Reserve's objectives and policy strategy. Because of its dual mandate from the Congress, which specifies both maximum employment and price stability as policy objectives, the Federal Reserve could not adopt a numerical inflation target as its exclusive goal. Nor would it have been appropriate for the FOMC simply to provide a fixed objective for some measure of employment or unemployment, in parallel with an inflation objective. In contrast to inflation, which is determined by monetary policy in the longer run, the maximum level of employment that can be sustained over the longer run is determined primarily by nonmonetary factors, such as demographics, the mix of workforce skills, labor market institutions, and advances in technology. Moreover, as these factors evolve, the maximum employment level may change over time. Consequently, it is beyond the power of the central bank to set a longer-run target for employment that is immutable or independent of the underlying structure of the economy.1\n\nThe approach on which the FOMC agreed is described in its statement of longer-run goals and policy strategy, issued in January 2012 and reaffirmed in January of this year.2 The statement begins by affirming the FOMC's commitment to meeting both of its statutory objectives. It then indicates that, in the context of the FOMC's dual mandate, the Committee sees price stability as corresponding to a 2 percent longer-term inflation goal. On the employment side of the mandate, the Committee makes its best assessment of the maximum level of employment at any given time, recognizing that such assessments are necessarily uncertain and subject to revision. In practice, the Committee often expresses its employment objective in terms of the longer-run normal rate of unemployment. Currently, FOMC participants' estimates of the longer-run normal unemployment rate, as publicly reported in the quarterly Summary of Economic Projections, range from 5.2 to 6 percent.3\n\nAs I noted, explicit objectives are most useful when accompanied by provisional plans for achieving them. Many central banks supplement their announced objectives with published forecasts that, implicitly or explicitly, lay out plans for achieving their goals. Although the size and diversity of the Federal Reserve's policymaking committee has made achieving a single consensus forecast difficult, the quarterly Summary of Economic Projections reports each FOMC participant's view of the most likely future paths of inflation, unemployment, and output growth, conditional on that individual's view of appropriate monetary policy. In recent years, this survey has also included participants' projections of the path of future short-term interest rates they see as most likely to achieve the Committee's goals. In general, the Committee's two objectives of maximum employment and price stability are complementary. When they are not, the FOMC has stated that it will pursue a balanced approach in the pursuit of its dual mandate, working to ensure that both inflation and employment are close to their desired values in the longer term.\n\nIn short, the Federal Reserve, like many central banks around the world, has made significant progress in recent years in clarifying its goals and policy approach, and in providing regular information about the future path of policy that it views as most likely to attain its objectives. This increased transparency about the framework of policy has aided the public in forming policy expectations, reduced uncertainty, and made policy more effective.\n\nThe financial crisis and its aftermath, however, have raised even greater challenges for, and demands on, the Federal Reserve's communication. We have had to contend with the persistent effects of the seizing-up of the financial system, the collapse of housing prices and construction, new financial shocks in Europe and elsewhere, restrictive fiscal policies at all levels of government, and, of course, the enormous blows to output and employment associated with the worst U.S. recession since the Great Depression. Moreover, for the first time since the FOMC began using the federal funds rate as its policy interest rate, that rate is effectively at zero and thus cannot be lowered meaningfully further. Consequently, to provide needed support to the economic recovery and minimize the risk of deflation, the Federal Reserve has had to adopt new policy tools, which bring their own communication challenges. In the remainder of my talk, I will discuss how the Federal Reserve has used communication to try to further inform the public's expectations about how the FOMC will employ what are currently its two principal policy tools: its plans regarding its short-term policy interest rate and its large-scale purchases of securities.\n\nForward Guidance about Policy Interest Rates\nAs the economy weakened over 2008, the FOMC repeatedly cut its target for the federal funds rate, its short-term policy rate. In December of that year, the target for the funds rate was reduced to a range of zero to 1/4 percent, and money market rates declined nearly to zero. Thus, using the standard means of further easing monetary policy--cutting the target interest rate--was no longer possible.\n\nThe so-called zero lower bound on the FOMC's policy interest rate was not the only challenge the Committee faced. First, the depth of the recession, combined with ongoing concerns about the functioning of the financial system, raised significant uncertainties about both the likely pace of recovery and the effectiveness of monetary policy in supporting growth. The recoveries from most post-World War II U.S. recessions had been relatively rapid, with production, unemployment, and other key variables returning to close to normal levels within six to eight quarters. In such cases, the policy horizon most relevant to financial markets might be the next several quarters. In the aftermath of the recent crisis, however, the Committee had to consider the possibility that a highly accommodative policy might be required for a number of years.\n\nSecond, a federal funds rate effectively at zero created an important asymmetry for policy planning. On the one hand, if the economy were to recover rapidly and inflation were to increase, monetary policymakers would be able to respond in the normal way, by raising the federal funds rate. But, on the other hand, if the economy were to remain weak or recover only gradually--the case we actually faced--the FOMC would not be able to cut the funds rate further. Moreover, in the latter case, the economy could face an increased risk of deflation--falling prices. As the case of Japan illustrates, deflation may impede economic growth while being very difficult to escape. To try to preempt such outcomes, a strong case existed for monetary policy to be more accommodative than suggested by standard policy rules calibrated to normal times.4\n\nSo the Committee faced a situation in which more monetary policy accommodation was needed, and possibly for quite a long time--yet its basic policy tool, the federal funds rate target, had been pushed to its limit. To put the Committee's problem another way, standard policy rules and a range of other analyses implied that, to achieve the FOMC's objectives, the target for the federal funds rate should be set well below zero, which, of course, was not feasible. Fortunately, as I discussed earlier, the degree of accommodation provided by monetary policy depends not just on the current value of the policy rate, but on public expectations of future settings of that rate. The Committee accordingly realized that it could ease policy further--and reduce uncertainty about future policy--by assuring the public and markets that it intended to keep the policy rate low for some time, and for a longer period than the public initially expected.\n\nAt first, the Committee employed purely qualitative language to send this message: After the FOMC stated in December 2008 that it would likely be appropriate for the federal funds rate to remain near zero for \"some time,\" it changed the formulation in March 2009 to \"an extended period.\"5 However, such language did not convey very precisely the Committee's intentions. In August 2011, the Committee introduced a specific date into its guidance, stating that conditions would likely warrant keeping the federal funds rate target near zero at least through mid-2013.6 This date-based guidance was more precise than the qualitative language the Committee had been using, and it appears to have been effective in communicating the FOMC's commitment to a highly accommodative policy. In particular, following the introduction of dates into the FOMC statement, interest rates and survey measures of policy expectations moved in ways broadly consistent with the guidance.7\n\nAlthough the date-based forward guidance appears to have affected the public's expectations as desired, it did not explain how future policy would be affected by changes in the economic outlook--an important limitation. Indeed, the date in the guidance was pushed out twice in 2012--first to late 2014 and then to mid-2015--leaving the public unsure about whether and under what circumstances further changes to the guidance might occur.8 In December of last year, the FOMC addressed this issue by tying its forward guidance about its policy rate more directly to its economic objectives.9 Introducing so-called state-contingent guidance, the Committee announced for the first time that no increase in the federal funds rate target should be anticipated so long as unemployment remained above 6-1/2 percent and inflation and inflation expectations remained stable and near target.10 This formulation provided greater clarity about the factors influencing the Committee's thinking about future policy and how that thinking might change as the outlook changed.11\n\nAs my colleagues and I have frequently emphasized, the conditions stated in this guidance are thresholds, not triggers. Crossing one of the thresholds will not automatically give rise to an increase in the federal funds rate target; instead, it will signal only that it is appropriate for the Committee to begin considering whether an increase in the target is warranted. This threshold formulation helps explain why the Committee was willing to express the guidance bearing on the labor market in terms of the unemployment rate alone, instead of following its usual practice of considering a broad range of labor market indicators. In the judgment of the Committee, the unemployment rate--which, despite some drawbacks in this regard, is probably the best single summary indicator of the state of the labor market--is sufficient for defining the threshold given by the guidance. However, after the unemployment threshold is crossed, many other indicators become relevant to a comprehensive judgment of the health of the labor market, including such measures as payroll employment, labor force participation, and the rates of hiring and separation. In particular, even after unemployment drops below 6-1/2 percent, and so long as inflation remains well behaved, the Committee can be patient in seeking assurance that the labor market is sufficiently strong before considering any increase in its target for the federal funds rate.\n\nLarge-Scale Asset Purchases and Related Communication\nBecause of the severity of the recession and the disruptions in financial markets, and because short-term interest rates were near the zero lower bound, it became clear early on that more monetary accommodation would be needed than could be provided through the management of short-term rates alone, even with guidance that those rates would be kept low well into the future. Accordingly, at about the same time that the FOMC reduced its target for the federal funds rate close to zero, it began supplementing its rate policies and forward rate guidance with large-scale asset purchases (LSAPs)--specifically, open market purchases of longer-term U.S. Treasury securities and securities issued by the government-sponsored enterprises, primarily mortgage-backed securities (MBS).\n\nBoth LSAPs and forward guidance for the federal funds rate support the economy by putting downward pressure on longer-term interest rates, but they affect longer-term rates through somewhat different channels. To understand the difference, it is useful to decompose longer-term interest rates into two components: One reflects the expected path of short-term interest rates, and the other is called a term premium. The term premium is the extra return that investors require to be willing to hold a longer-term security to maturity compared with the expected yield from rolling over short-term securities for the same period.\n\nAs I have noted, forward rate guidance affects longer-term interest rates primarily by influencing investors' expectations of future short-term interest rates. LSAPs, in contrast, most directly affect term premiums. As the Federal Reserve buys a larger share of the outstanding stock of longer-term securities, the quantity of these securities available for private-sector portfolios declines. As the securities purchased by the Fed become scarcer, they should become more valuable. Consequently, their yields should fall as investors demand a smaller term premium for holding them. This argument depends importantly on the assumption that the longer-term Treasury and MBS securities that the Fed buys are not perfectly substitutable with other types of assets, an assumption that seems well supported in practice.12\n\nAs both forward rate guidance and LSAPs affect longer-term interest rates, the use of these tools allows monetary policy to be effective even when short-term interest rates are close to zero. However, the Committee does not view these two tools as entirely equivalent. One reason is that we have much less experience with policies designed to operate on term premiums, as LSAPs do. As a result, though a strong majority of FOMC members believes that both the forward rate guidance and the LSAPs are helping to support the recovery, we are somewhat less certain about the magnitudes of the effects on financial conditions and the economy of changes in the pace of purchases or in the accumulated stock of assets on the Fed's balance sheet. Moreover, economists do not have as good an understanding as we would like of the factors determining term premiums; indeed, as we saw earlier this year, hard-to-predict shifts in term premiums can be a source of significant volatility in interest rates and financial conditions. LSAPs have other drawbacks not associated with forward rate guidance, including the risk of impairing the functioning of securities markets and the extra complexities for the Fed of operating with a much larger balance sheet, although I see both of these issues as manageable.13 In deciding to employ LSAPs, the FOMC has accordingly remained attentive to the possible costs and risks as well as to the efficacy of this less familiar tool, a point the Committee has regularly noted in its post-meeting statements. Of course, elevated unemployment, below-target inflation, lingering economic fragility, and the harmful effects of long-term unemployment on our society and economic potential also pose significant costs and risks, and the Committee has, thus far, judged that the balance favors the use of LSAPs.\n\nBetween November 2008 and June 2012, the FOMC announced or extended a series of asset purchase programs, in each case specifying the expected quantities of assets to be acquired under the program. Like the use of date-based forward guidance, announcing a program of predetermined size and duration has advantages and disadvantages. On the one hand, a fixed program size is straightforward to communicate; on the other hand, a program of fixed size cannot so easily adapt to changes in the economic outlook and the consequent changes in the need for policy accommodation. In announcing its fixed-size programs, the FOMC did state a general willingness to do more if needed--and, indeed, it has followed through on that promise‑‑but such statements left considerable uncertainty regarding the conditions that might warrant changes in an existing program or the introduction of a new one.\n\nIn a step roughly analogous to the shift from date-based guidance to the contingent, thresholds-based guidance now in use for the federal funds rate target, in September 2012 the FOMC announced a program of asset purchases in which the total size of the purchase program would not be fixed in advance but instead would be linked to the Committee's economic objectives. In particular, the Committee initiated purchases of agency MBS at the rate of $40 billion per month and stated its intention to continue purchases until the outlook for the labor market improved substantially in a context of price stability.14 In December 2012, when a program to extend the maturity of the Fed's portfolio of Treasury securities came to an end, the FOMC added purchases of $45 billion per month in longer-term Treasury securities to the new program, bringing the monthly purchase rate to $85 billion, where it remains today.\n\nAs I noted, the Committee set a criterion of substantial improvement in the outlook for the labor market as the condition for ending the new purchase program. The Committee also signaled its expectation that it would end the purchases and return to an emphasis on rates policy and forward guidance before it had fully attained its dual mandate objectives, stating that \"the Committee expects that a highly accommodative stance of monetary policy will remain appropriate for a considerable time after the asset purchase program ends and the economic recovery strengthens.\"15 The reason for this sequencing choice, again, was the greater uncertainty about the costs and efficacy of LSAPs, relative to the more familiar tool of managing the current short-term interest rate and, through forward guidance, expectations of future short-term interest rates. Moreover, to the extent that the use of LSAPs engenders additional costs and risks, one might expect the tradeoff between the efficacy and costs of this tool to become less favorable as the Federal Reserve's balance sheet expands.\n\nHaving seen progress in the labor market since the beginning of the latest asset purchase program in September 2012, the Committee agreed in June of this year to provide more-comprehensive guidance about the criteria that would inform future decisions about the program. Consequently, in my press conference following the June FOMC meeting, I presented a framework linking the program more explicitly to the evolution of the FOMC's economic outlook. In particular, I noted the Committee's expectation at the time that improvements in the job market would continue, supported by a moderate pickup in growth that would support those gains. The Committee additionally expected that inflation would be moving back toward its 2 percent objective over time. If the incoming data were broadly consistent with that outlook, the Committee would likely begin measured reductions in the pace of asset purchases later in 2013. If the economy evolved as anticipated, the end of purchases would occur around midyear 2014. I also emphasized that the path of purchases would depend on incoming data and could be slower or faster than envisioned in the modal scenario--indeed, I noted that the pace of purchases could be increased for a time, if warranted.\n\nThe framework I discussed in June implied that substantial additional asset purchases over the subsequent quarters were likely, with even more purchases possible if economic developments proved disappointing. However, following the June meeting and press conference, market yields moved sharply higher. For example, between the FOMC meetings of June and September, the 10-year Treasury yield rose about 3/4 percentage point and rates on MBS increased by a similar amount.\n\nFinancial market movements are often difficult to account for, even after the fact, but three main reasons seem to explain the rise in interest rates over the summer. First, improvements in the economic outlook warranted somewhat higher yields--a natural and healthy development. Second, some of the rise in rates reportedly reflected an unwinding of levered positions--positions that appear to have been premised on an essentially indefinite continuation of asset purchases--together with some knock-on liquidations of other positions in response to investor losses and the rise in volatility. Although it brought with it some tightening of financial conditions, this unwinding and the associated rise in term premiums may have had the benefit of reducing future risks to financial stability and, in particular, of lowering the probability of an even sharper market correction at some later point. Third, market participants may have taken the communication in June as indicating a general lessening of the Committee's commitment to maintain a highly accommodative stance of policy in pursuit of its objectives. In particular, it appeared that the FOMC's forward guidance for the federal funds rate had become less effective after June, with market participants pulling forward the time at which they expected the Committee to start raising rates, in a manner inconsistent with the guidance.16\n\nTo the extent that this third factor--a perceived reduction in the Fed's commitment to meeting its objectives--contributed to the increase in yields, it was neither welcome nor warranted, in the judgment of the FOMC. This change in expectations did not correspond to any actual lessening in the FOMC's commitment or intention to provide the high degree of monetary accommodation needed to meet its objectives, as Committee participants emphasized in subsequent communications.\n\nAt its September 2013 meeting, the FOMC applied the framework communicated in June. The Committee's decision at that meeting to maintain the pace of asset purchases was appropriate and fully consistent with the earlier guidance. The Committee was looking for evidence that job market gains would continue, supported by a pickup in growth. As it happened, the implications for the outlook of the evidence reviewed at the September meeting were mixed at best, while the ongoing fiscal debates posed additional risks. The Committee accordingly elected to await further evidence supporting its expectation of continued improvement in the labor market.17 Although the FOMC's decision came as a surprise to some market participants, it appears to have strengthened the credibility of the Committee's forward rate guidance; in particular, following the decision, longer-term rates fell and expectations of short-term rates derived from financial market prices showed, and continue to show, a pattern more consistent with the guidance.\n\nIn coming meetings, in evaluating the outlook for the labor market, we will continue to consider both the cumulative progress since September 2012 and the prospect for continued gains. We have seen meaningful improvement in the labor market since the latest asset purchase program was announced in September 2012. At the time, the latest reading on the unemployment rate was 8.1 percent, and both we and most private-sector economists were projecting only slow reductions in unemployment in the coming quarters. Recent reports on payroll employment had also been somewhat disappointing. However, since the program was announced, the unemployment rate has fallen 0.8 percentage point, and about 2.6 million payroll jobs have been added. Looking forward, we will of course continue to monitor the incoming data. As reflected in the latest Summary of Economic Projections and the October FOMC statement, the FOMC still expects that labor market conditions will continue to improve and that inflation will move toward the 2 percent objective over the medium term. If these views are supported by incoming information, the FOMC will likely begin to moderate the pace of purchases. However, asset purchases are not on a preset course, and the Committee's decisions about their pace will remain contingent on the Committee's economic outlook. As before, the Committee will also continue to take into account its assessment of the likely efficacy and costs of the program.\n\nWhen, ultimately, asset purchases do slow, it will likely be because the economy has progressed sufficiently for the Committee to rely more heavily on its rate policies, the associated forward guidance, and its substantial continued holdings of securities to maintain progress toward maximum employment and to achieve price stability.18 In particular, the target for the federal funds rate is likely to remain near zero for a considerable time after the asset purchases end, perhaps well after the unemployment threshold is crossed and at least until the preponderance of the data supports the beginning of the removal of policy accommodation.\n\nConclusion\nI began my time as Chairman with the goal of increasing the transparency of the Federal Reserve, and of monetary policy in particular. In response to a financial crisis and a deep recession, the Fed's monetary policy communications have proved far more important and have evolved in different ways than I would have envisioned eight years ago.\n\nThe economy has made significant progress since the depths of the recession. However, we are still far from where we would like to be, and, consequently, it may be some time before monetary policy returns to more normal settings. I agree with the sentiment, expressed by my colleague Janet Yellen at her testimony last week, that the surest path to a more normal approach to monetary policy is to do all we can today to promote a more robust recovery.19 The FOMC remains committed to maintaining highly accommodative policies for as long as they are needed. Communication about policy is likely to remain a central element of the Federal Reserve's efforts to achieve its policy goals.\n\n \n\nReferences\nBernanke, Ben S. (2012). \"Monetary Policy since the Onset of the Crisis,\" speech delivered at \"The Changing Policy Landscape,\" a symposium sponsored by the Federal Reserve Bank of Kansas City Economic Symposium, held in Jackson Hole, Wyo., August 30-September 1.\n\nBoard of Governors of the Federal Reserve System (2008). \"FOMC Statement and Board Approval of Discount Rate Requests of the Federal Reserve Banks of New York, Cleveland, Richmond, Atlanta, Minneapolis, and San Francisco,\" press release, December 16.\n\n------ (2009). \"FOMC Statement,\" press release, March 18.\n\n------ (2011). \"FOMC Statement,\" press release, August 9.\n\n------ (2012a). \"Federal Reserve Issues FOMC Statement,\" press release, January 25.\n\n------ (2012b). \"Federal Reserve Issues FOMC Statement,\" press release, September 13.\n\n------ (2012c). \"Federal Reserve Issues FOMC Statement,\" press release, December 12.\n\n------ (2013a). \"Federal Reserve Board and Federal Open Market Committee Release Economic Projections from the September 17-18 FOMC Meeting,\" press release, September 18.\n\n------ (2013b). \"Federal Reserve Issues FOMC Statement,\" press release, September 18.\n\n------ (2013c). Transcript of Chairman Bernanke's Press Conference (PDF), transcript, June 19.\n\nCampbell, Jeffrey R., Charles L. Evans, Jonas D.M. Fisher, and Alejandro Justiniano (2012). \"Macroeconomic Effects of FOMC Forward Guidance,\" Brookings Papers on Economic Activity, vol. 43 (Spring), pp. 1-54.\n\nCarpenter, Seth B., Jane E. Ihrig, Elizabeth C. Klee, Daniel W. Quinn, and Alexander H. Boote (2013). \"The Federal Reserve's Balance Sheet and Earnings: A Primer and Projections,\" Finance and Economics Discussion Series 2013-01. Washington: Board of Governors of the Federal Reserve System, January.\n\nEggertsson, Gauti B., and Michael Woodford (2003). \"The Zero Bound on Interest Rates and Optimal Monetary Policy,\" Brookings Papers on Economic Activity, no. 1, pp. 139-211.\n\nFemia, Katherine, Steven Friedman, and Brian Sack (2013). \"The Effects of Policy Guidance on Perceptions of the Fed's Reaction Function,\" Federal Reserve Bank of New York Staff Report 652. New York: Federal Reserve Bank of New York, November.\n\nFriedman, Milton (2000). \"Canada and Flexible Exchange Rates (PDF),\" speech delivered at \"Revisiting the Case for Flexible Exchange Rates,\" a conference sponsored by the Bank of Canada, Ottawa, Ontario, November.\n\nPosen, Adam (2012). \"Comments on ‘Methods of Policy Accommodation at the Interest-Rate Lower Bound' by Michael Woodford (PDF),\" speech delivered at \"The Changing Policy Landscape,\" a symposium sponsored by the Federal Reserve Bank of Kansas City Economic Symposium, held in Jackson Hole, Wyo., August 30-September 1.\n\nRaskin, Matthew D. (2013). \"The Effects of the Federal Reserve's Date-Based Forward Guidance,\" Finance and Economics Discussion Series 2013-37. Washington: Board of Governors of the Federal Reserve System, May.\n\nReifschneider, David, and John C. Williams (2000). \"Three Lessons for Monetary Policy in a Low-Inflation Era,\" Journal of Money, Credit and Banking, vol. 32 (November), pp. 936‑66.\n\nSwanson, Eric T. and John C. Williams (2013). \"Measuring the Effect of the Zero Lower Bound on Medium- and Longer-Term Interest Rates (PDF),\" Working Paper Series 2012-02. San Francisco: Federal Reserve Bank of San Francisco, January.\n\nTobin, James (1965). \"The Monetary Interpretation of History,\" American Economic Review, vol. 55 (June), pp. 464-85.\n\n------ (1969). \"A General Equilibrium Approach to Monetary Theory,\" Journal of Money, Credit and Banking, vol. 1 (February), pp. 15-29.\n\nYellen, Janet (2013). \"Confirmation Hearing,\" statement before the Committee on Banking, Housing, and Urban Affairs, U.S. Senate, Washington, D.C., November 14.\n\n \n\n1. To be clear, although monetary policy has limited influence on the level of employment that can be sustained in the longer run, it can be used to help eliminate gaps between the current level of employment and its sustainable level--as policy is doing today. Return to text\n\n2. The January 2013 statement is available on the Board's website at www.federalreserve.gov/monetarypolicy/files/FOMC_LongerRunGoals.pdf. Return to text\n\n3. The central tendency of the projections for the longer-run normal unemployment rate (which drops the three highest and three lowest values submitted by FOMC participants) was 5.2 to 5.8 percent in September. For the most recent FOMC projections, see www.federalreserve.gov/monetarypolicy/fomcminutes20130918ep.htm on the Board's website. Return to text\n\n4. See, for example, Eggertsson and Woodford (2003) and Reifschneider and Williams (2000). Return to text\n\n5. See Board of Governors (2008, 2009). Return to text\n\n6. See Board of Governors (2011). Return to text\n\n7. Evidence that this is the case has been provided by Campbell, Evans, Fisher, and Justiniano (2012), Swanson and Williams (2013), Raskin (2013), and by a recent study of the Federal Reserve Bank of New York's survey of primary dealers (Femia, Friedman, and Sack, 2013). Return to text\n\n8. See Board of Governors (2012a, b). Return to text\n\n9. See Board of Governors (2012c). Return to text\n\n10. See Board of Governors (2012c). Specifically, the guidance says that the Committee anticipates that its 0 to 1/4 percent target range for the federal funds rate will be appropriate at least as long as the unemployment rate remains above 6-1/2 percent, inflation between one and two years ahead is projected to be no more than a half percentage point above the Committee's 2 percent longer-run goal, and longer-term inflation expectations continue to be well anchored. The FOMC asserted in its statement that it viewed the new thresholds to be consistent with the earlier, date-based guidance. Femia, Friedman, and Sack (2013) present evidence that respondents to the survey of primary dealers largely shared this assessment. Return to text\n\n11. An advantage of the state-contingent formulation is that it increases the tendency of financial market conditions to act as an automatic stabilizer for the economy. For example, bad news about the labor market, which tends to lengthen the amount of time the public expects to be required for the unemployment rate to reach the threshold, should likewise increase the length of time that the public expects policy to remain highly accommodative. In response to this shift in policy expectations, interest rates should fall and asset prices should rise, thus easing financial conditions and helping to offset the adverse change to the outlook. Return to text\n\n12. I discussed this effect more fully in Bernanke (2012). As I noted then, both Milton Friedman (2000) and James Tobin (1965, 1969) made this argument. LSAPs may affect financial conditions through other channels as well; see Bernanke (2012) for a more complete discussion. One such channel is a \"signaling channel,\" which works to the extent that the direct action of buying securities increases the credibility of communication tools like forward rate guidance (Posen, 2012). Return to text\n\n13. An additional concern that some have raised about the Federal Reserve's expanded balance sheet is the possibility that financial conditions could evolve in a way that significantly reduces the Fed's net interest income on its portfolio for a time, which in turn could lead to a period during which the Fed is not remitting income to the Treasury; see Carpenter and others (2013) for an analysis. Such a situation, though unlikely, could have reputational costs and possibly increase risks to the Federal Reserve's independence. Although these costs must be taken into account, careful analysis suggests that, in fact, LSAPs almost certainly will result in improved government finances: First, even if a period of no payments to the Treasury occurs, it is highly likely that the payments over the period of unconventional monetary policy will be significantly higher than they would have been without LSAPs; indeed, since 2009, the Fed has remitted more than $350 billion to the Treasury, about the same total as it remitted during the 18 years prior to the crisis (1990-2007 inclusive). Second, a complete accounting of the fiscal effects of LSAPs should take into account the beneficial effects of a stronger economy on tax receipts, interest payments, and government spending; the reduction in the budget deficit from these sources will certainly outweigh the effects on the deficit of any changes in the pace of Fed payments. Finally, while fiscal effects are important, the full effect of the FOMC's policies also includes important additional benefits of increased economic growth and employment and of greater price stability. Return to text\n\n14. This criterion was expressed in slightly different ways in the FOMC statements between September 2012 and January 2013. Since March 2013, the statement has included the sentence, \"The Committee will continue its purchases of Treasury and agency mortgage-backed securities, and employ its other policy tools as appropriate, until the outlook for the labor market has improved substantially in a context of price stability.\" FOMC statements are available at www.federalreserve.gov/monetarypolicy/fomccalendars.htm. Return to text\n\n15. See Board of Governors (2012c). Return to text\n\n16. For example, the Eurodollar futures rate for mid-2015 rose about 40 basis points in the few days following the June FOMC meeting, far more than could be explained by revisions to the economic outlook. Return to text\n\n17. See Board of Governors (2013a, b). Return to text\n\n18. By the logic described earlier, the Fed's maintenance of a large balance sheet (by reinvesting principal paydowns and rolling over maturing securities) should continue to put downward pressure on term premiums and longer-term interest rates, even after purchases end. Also, as I noted at my June press conference, a strong majority of the Committee now expects that there will be no sales of agency MBS during the process of normalizing monetary policy, although in the longer run limited sales could be used to reduce or eliminate residual MBS holdings. See Board of Governors (2013c). Return to text\n\n19. See Yellen (2013). Return to text"
    },
    {
        "title": "OTC Market Infrastructure Reform: Opportunities and Challenges",
        "date": "November 21, 2013",
        "speaker": "Governor Jerome H. Powell",
        "url": "https://www.federalreserve.gov/newsevents/speech/powell20131121a.htm",
        "content": "November 21, 2013\n\nGovernor Jerome H. Powell\n\nAt the Clearing House 2013 Annual Meeting, New York, New York\n\nThe financial crisis revealed important weaknesses in many areas of our financial system. In response, governments around the world have undertaken a variety of far-reaching regulatory reforms that, I would argue, can be grouped into three categories: those intended to strengthen institutions; those aimed at strengthening financial markets; and those that take steps to reinforce and, in some cases, build new market infrastructures.\n\nThe reform effort seeks to address each of these areas in a comprehensive manner that recognizes the interplay among them. For instance, enhanced capital and liquidity regulations will strengthen the ability of financial institutions to withstand both credit losses and liquidity shocks. Stronger financial institutions, along with enhanced risk management and supervision, will strengthen market infrastructures. And new rules to improve the functioning of markets, such as those that require greater transparency of over-the-counter (OTC) derivatives markets through trade repositories and swap execution facilities, will strengthen financial institutions and infrastructures alike. Moreover, greater post-trade transparency will improve competition and make it easier for market participants to make informed choices about which OTC derivatives are best suited to their needs.\n\nToday I will focus on the third aspect of this effort--reforms intended to strengthen financial market infrastructures. Specifically, I will look at measures to improve the clearing of OTC derivatives through the expanded use of central counterparties (CCPs) and the introduction of margin requirements for those OTC derivatives that remain bilateral. In the United States, several agencies are working together to implement these reforms. The Commodity Futures Trading Commission (CFTC) and the Securities and Exchange Commission (SEC) are responsible for establishing the regulatory regime for and supervising CCPs as well as determining which swaps must be centrally cleared. The Federal Reserve and six other agencies are responsible for establishing margin requirements for derivatives that are not cleared through a CCP.1 The Federal Reserve shares with the other members of the Financial Stability Oversight Council (FSOC) an interest in CCP regulation and central clearing from a broader financial stability perspective. The Fed also plays a role in supervising financial market utilities that are designated as systemically important under Title VIII of the Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank).\n\nThe financial crisis involved significant failures in the functioning, regulation, and supervision of OTC derivatives markets. These failures were well illustrated by the widespread and destabilizing effects of large losses by American International Group (AIG) on its OTC structured finance and credit derivative positions. In the absence of government intervention, AIG's failure would have exposed its counterparties to significant losses at a time of widespread financial stress. Further, the lack of transparency in OTC derivatives markets at that time led to a wave of uncertainty about who was exposed to AIG and the extent of that exposure. This fundamental lack of information fueled concerns about potential losses and drove a cycle of escalating pressure on large financial institutions around the globe. Government intervention was deemed necessary to stop this cycle and contain the threat to the financial system. AIG's failure revealed systemic problems in the OTC derivatives market that went well beyond the failure of a single market participant.\n\nThe Group of Twenty governments responded by committing that all standardized derivatives would be moved to central clearing and that derivatives that are not centrally cleared would be subject to margin requirements.2 Progress has been made on both of these fronts. Since credit default swaps clearing was introduced in 2009, the notional value of cleared credit derivatives has grown to more than $6 trillion. The notional value of interest rate swaps that are centrally cleared has more than doubled since 2009 and now stands at more than $400 trillion.3 These amounts will surely increase further in the coming years. And international standards on margin requirements for derivatives that are not centrally cleared have recently been finalized.4 I would like to briefly discuss how these reform efforts are intended to reduce systemic risks and offer my views on how to ensure that they are effectively implemented.\n\nThe Enhanced Role of Central Counterparties in OTC Derivatives Markets\nBy design, central clearing offers important advantages over a bilateral market structure in which no participant can know the full extent of its counterparties' risk exposures. The hub-and-spoke structure of central clearing enables the netting of gains and losses across multiple market participants, which has the potential to significantly reduce each participant's aggregate counterparty risk exposure. Central clearing can also improve transparency, which is important in reducing incentives for market participants to pull away from other institutions in times of stress. Rather than trying to assess its exposure to all of its trading partners, a market participant would need to manage only its exposure to the central counterparty. And CCPs can also reduce risk by imposing more effective risk controls on clearing members. Since their origins in the 19th century, CCPs have evolved significantly, and that evolution has allowed them to survive and continue functioning through many crises, including the most recent one.5\n\nOf course, the other side of this coin is that concentrating risk in a central counterparty could create a single point of failure for the entire system. Given their heightened prominence in the financial infrastructure, if CCPs are to mitigate systemic risks they must hold themselves to--and be held to--the highest standards of risk management. In many respects, CCPs are the collective reflection of the financial institutions that are their members and the markets that they support. The credit and liquidity risks borne by a CCP arise from the clearing activities of its members. Those risks materialize when a clearing member defaults. Most of the financial resources to cover risk exposures will come from a CCP's members. And a member's default will require the CCP to work with surviving members in the context of prevailing market conditions. CCPs play a critical role in ensuring a robust risk management regime that fully takes account of this interplay among markets, institutions, and infrastructure. Regulators, clearing members, and their clients also must be engaged in making sure CCPs are safe and effective at managing the risks, interactions, and interdependencies inherent in the clearing process.\n\nI will now turn to some key aspects of the regulatory framework for CCPs that will strengthen the financial system and help reduce systemic risk.\n\nThree Keys to Ensuring Central Counterparties Are Effective in Mitigating Systemic Risks\nThere are three key dimensions to making the reform program work in practice: enhancing supervision and regulation of CCPs, strengthening CCP risk management and governance, and promoting the stability of clearing members.\n\nEnhancing Central Counterparty Supervision and Regulation\nThe decision to require central clearing of standardized derivatives as a foundation for reform has raised the stakes for CCPs, clearing members, regulators, and the general public. At the international level, financial regulatory authorities addressed this challenge by updating, harmonizing, and strengthening the minimum risk management standards applied to financial market infrastructures, including CCPs. The new Principles for Financial Market Infrastructures, commonly referred to as the PFMIs, set a higher bar for risk management to strengthen these core market infrastructures and promote financial stability.6 Just last week, the CFTC finalized its adoption of the PFMIs for the derivatives clearing organizations it regulates and supervises.7\n\nThe PFMIs require that a CCP develop strategies to cover its losses and continue operating in a time of widespread financial stress. In particular, the PFMIs require that a CCP maintain financial resources sufficient to cover its current and potential future exposures to each participant fully with a high degree of confidence. CCPs must maintain additional resources to cover the failure of the clearing member with the largest exposure under extreme but plausible market conditions. In the case of CCPs with more complex risk profiles or those that are systemically important in multiple jurisdictions, the CCP must have adequate resources to handle the failure of the two clearing members with the largest exposures. Finally, the PFMIs require a CCP to identify scenarios that may potentially prevent it from being able to continue operations, including so-called end-of-default waterfall issues, and develop detailed plans for recovery or orderly wind-down. Regulators and industry groups are working to establish minimum expectations for CCP transparency of both qualitative and quantitative information that will allow key stakeholders to assess a CCP's risk management.8\n\nThis international strategy for strengthening CCPs has been complemented by several domestic initiatives to introduce regulatory frameworks for OTC derivatives and to enhance supervision of systemically important CCPs. The two most notable developments are the passage of the European Market Infrastructure Regulation and Dodd-Frank, notably titles VII and VIII. Both laws establish a framework for reporting, regulating, and clearing OTC derivatives transactions; call for international coordination; and emphasize enhanced risk management standards for CCPs. Differences of implementation have emerged, however, and it will be important to engage with other governments to ensure that such differences do not lead to regulatory arbitrage or weakened standards.\n\nCentral Counterparty Risk Management and Governance\nThe two primary risks facing a CCP are credit risk (the potential for the CCP to incur losses after it closes out a defaulter's positions) and liquidity risk (the possibility that a CCP will not have sufficient cash on hand to meet its payment obligations in a timely manner). While credit risk and liquidity risk are interrelated, they are also distinct and need to be measured and managed separately.\n\nTo promote sound credit risk management, the PFMIs require that a CCP collect variation margin from its members to limit the buildup of current exposures. In addition, CCPs must also calculate and collect initial margin sufficient to cover potential changes in the value of each participant's position between the last collection of variation margin and the final closeout of a participant's position should it default to the CCP. This process involves modeling potential price movements with an appropriate confidence threshold, determining the closeout period in the event the participant defaults, and numerous other factors. Given the complexity of this modeling, it is important that CCPs rigorously back-test and stress-test the adequacy of their margin models under a wide range of extreme yet plausible scenarios. More broadly, a CCP should test the sufficiency of its total financial resources--initial margin, default funds and capital--to cover potential credit losses, taking into account evolving market volatility and liquidity conditions.\n\nAn important lesson from the financial crisis is that liquidity is extremely important in ensuring ongoing viability and resilience during a period of financial stress. No amount of resources can guarantee that a CCP will be able to meet its payment and settlement obligations, unless those resources can be converted to cash with certainty and within a very short time frame. CCP liquidity is especially important, since a failure to meet required payment obligations could undermine market confidence at precisely the moment when it is most fragile and trigger run-like behavior as financial institutions seek to reduce their exposure to the CCP and its members.\n\nTo measure and manage its liquidity risks, the PFMIs require a CCP to have effective methodologies to estimate its funding exposures under a variety of stressed conditions, to identify available cash resources, and to establish mechanisms for converting its noncash collateral to cash. The need to assure adequate liquidity presents a number of challenges. CCPs will need to mobilize cash within a matter of hours on the day of a large clearing member's default. Cash balances on deposit at a bank can be quickly accessed, but CCPs often put their cash resources in overnight investments to earn a return. The nature and mechanics of such investments, as well as prevailing market conditions, can critically affect the ability of a CCP to unwind those investments quickly enough to meet its cash needs. A similar challenge will arise with the need to convert noncash collateral, such as initial margin collateral, to cash. The PFMIs require CCPs to have in place prearranged and highly reliable funding sources to address this need.\n\nManaging credit and liquidity risks requires effective governance. One important aspect of CCP governance is a commitment to transparency. Clearing members bear primary responsibility for understanding the risks associated with participating in a CCP, including their potential exposures in the event of a default. This will require the CCP to provide relevant and even firm-specific information to facilitate the members' analysis. Clearing members and their clients, regulators, and the broader public require transparency so that they can assess the adequacy of a CCP's risk management and its overall risk profile.\n\nPromoting the Stability of Central Counterparty Members\nSo far, I have focused on CCPs. Now I would like to turn to the critical role played by clearing members of those CCPs. A CCP ultimately draws its strength and resilience from that of its members. And it is not a one-way street, since strong CCPs enable clearing members and their clients to significantly reduce their exposure to counterparty credit risk. Effective risk management by both a CCP and its clearing members need to work in concert.\n\nAs a general matter, enhanced capital and liquidity requirements have substantially improved the overall risk position of the banks that constitute many of the major clearing members. For example, Tier 1 common equity capital ratios at the largest U.S. banks have nearly doubled since 2007.9 In addition, new requirements address the specific interactions that banks have with CCPs and derivatives markets in order to promote both the use of central clearing and strong CCP risk management.\n\nUnder Basel III, capital requirements for bank exposures to a CCP are sensitive to the risk management standards applied by the CCP. These requirements acknowledge that CCPs that adhere to the PFMIs present lower risks to their members. Exposures to such qualifying CCPs require less capital.10 The capital rules also recognize that a CCP requiring more initial margin from its members exposes those members to less default risk, and therefore require less capital. On the liquidity front, the recently proposed liquidity coverage ratio (LCR) recognizes the liquidity-intensive nature of derivatives transactions. Under the LCR, a bank is required to maintain high-quality liquid assets that are sufficient to withstand an extreme yet plausible margin call from its derivatives counterparties.11 Importantly, the liquidity requirement depends on the member's net derivatives position with the CCP--if the position is hedged, the liquidity requirement will be appropriately attenuated.\n\nEnsuring the Stability of OTC Derivatives Markets That Are Not Centrally Cleared: Margin Requirements for Noncleared Derivatives\nWhile central clearing is important and is expected to increase substantially over time, a significant portion of nonstandardized, bespoke derivatives will never be suitable for central clearing. This bilaterally cleared part of the market was a principal source of systemic risk during the crisis. For noncentrally cleared derivatives, margin requirements will serve as the main tool to mitigate systemic risks. The Basel Committee on Banking Supervision (Basel Committee) and the International Organization of Securities Commissions (IOSCO) have recently finalized a framework for margin requirements on noncentrally cleared derivatives that provides for harmonized rules and a level playing field, which is important given the global nature of derivatives markets. Regulatory authorities in participating countries are now in the process of developing margin rules for noncleared derivatives in light of the international framework.\n\nThe framework requires both financial firms and systemically important nonfinancial firms that trade derivatives to collect both variation margin and initial margin, as is the case for centrally cleared derivatives. The initial margin requirements represent a significant change to existing market practice and will undoubtedly impose some costs on market participants. As originally proposed, the new framework would have required most market participants to collect initial margin from the first dollar of exposure. The International Swap Dealers Association estimated that roughly an additional $1.7 trillion in initial margin would have been required globally.12 In light of this concern, the framework was released for public consultation on two separate occasions and the Basel Committee and IOSCO conducted a detailed impact study to determine the potential liquidity costs of the new requirements.13\n\nThe final version of the framework addressed these concerns by allowing firms to begin collecting initial margin only as potential future credit exposures rise above $65 million for a particular counterparty. According to the impact study, this revision reduced the estimated global liquidity requirement from roughly $2.3 trillion to $900 billion.14 The result is a margin regime that will protect the financial system from the largest and most systemic exposures while also reducing overall liquidity costs and providing relief to smaller derivatives market participants.\n\nIt should also be noted that these margin requirements are new to the market and their effects cannot be fully understood before they become effective. There is simply no substitute for experience. Accordingly, the Basel Committee and IOSCO have established a monitoring group that will evaluate the effects of the margin requirements. The evaluation will focus on the consistency of the margin standards with related regulatory initiatives such as the implementation of the LCR and potential minimum haircuts on repurchase transactions. Based on the findings of this monitoring group, the Basel Committee and IOSCO will jointly determine whether any modifications to the margin requirements are necessary or appropriate. In this way, regulators are taking an experience-based approach to managing systemic risk that looks across the combined effect of a number of related regulatory initiatives.\n\nConclusion\nThe financial crisis revealed significant flaws in the structure of the OTC derivatives markets that are now being addressed as part of a worldwide reform effort. Increased central clearing and margins for noncleared derivatives are foundational elements of the program. Together, these reforms can help create a system in which the OTC derivatives market infrastructure acts as a pillar of strength in the next crisis. To achieve this goal, it is imperative that international standards such as the PFMIs and the margining framework for noncentrally cleared derivatives be forcefully and consistently implemented across the globe.\n\nImplementation of the new framework will present some real-world challenges. National rules still need to be written, including rules for margin requirements on noncentrally cleared derivatives. These national rules will need to deal with local legal regimes and markets, yet also be internationally consistent to ensure a level playing field. More broadly, international cooperation will be needed to ensure that the new framework works in practice.\n\n \n\n1. In addition to the Federal Reserve, the CFTC, FDIC, FHFA, FCA, OCC and SEC are responsible for establishing margin requirements on derivatives that are not cleared through a CCP. Return to text\n\n2. See Group of Twenty (2009), \"The G20 Pittsburgh Summit Leaders' Statement (PDF),\" item 13 under \"Strengthening the International Financial Regulatory System\" (Pittsburgh, PA: G-20, September); and Group of Twenty (2011), \"Cannes Summit Final Declaration--Building Our Common Future: Renewed Collective Action for the Benefit of All,\" item 24 under \"Meeting Our Commitments Notably on Banks, OTC Derivatives, Compensation Practices and Credit Rating Agencies, and Intensifying Our Monitoring to Track Deficiencies (DOC)\" (Cannes, France: G-20, November). Return to text\n\n3. Interest rate derivatives cleared volumes reflect notional amounts as of November 8, 2013, reported for LCH.Clearnet's SwapClear service. Credit default swap cleared volumes reflect notional amounts as of November 8, 2013, reported by the Depository Trust and Clearing Corporation's Trade Information Warehouse. Return to text\n\n4. See Basel Committee on Banking Supervision and the Board of the International Organization of Securities Commissions (2013), Margin Requirements for Non-Centrally Cleared Derivatives, report (Basel, Switzerland: Bank for International Settlements, September). Return to text\n\n5. See Ben S. Bernanke (2011), \"Clearinghouses, Financial Stability, and Financial Reform,\" speech delivered at the \"2011 Financial Markets Conference: Navigating the New Financial Landscape,\" sponsored by the Federal Reserve Bank of Atlanta, held in Stone Mountain, Ga., April 4-6. Return to text\n\n6. See Committee on Payment and Settlement Systems and the International Organization of Securities Commissions (2012), Principles for Financial Market Infrastructures, report (Basel, Switzerland: Bank for International Settlements, April). Return to text\n\n7. See Derivatives Clearing Organizations and International Standards (PDF)., 17 C.F.R. pts. 39, 140, and 190 (2013). Return to text\n\n8. See Committee on Payment and Settlement Systems and the International Organization of Securities Commissions (2012), \"Disclosure Framework and Assessment Methodology for Their Principles for Financial Market Infrastructures Issued by CPSS-IOSCO,\" press release, December 14; Committee on Payment and Settlement Systems and the International Organization of Securities Commissions (2013), Public Quantitative Disclosure Standards for Central Counterparties: Consultative Report, report (Basel, Switzerland: Bank for International Settlements, October); and Payments Risk Committee (2013), Recommendations for Supporting Clearing Member Due Diligence of Central Counterparties (PDF), report (New York: Federal Reserve Bank of New York, February). Return to text\n\n9. The Tier 1 common equity ratio for the 18 largest bank holding companies increased from 5.9 percent in December of 2007 to 11.3 percent in September of 2013. For more information, see the FR Y-9C \"Consolidated Financial Statements for Holding Companies (PDF)\" reporting form. Return to text\n\n10. See Board of Governors of the Federal Reserve System (2013), \"Federal Reserve Board Approves Final Rule to Help Ensure Banks Maintain Strong Capital Positions,\" press release, July 2. Return to text\n\n11. See Board of Governors of the Federal Reserve System (2013), \"Federal Reserve Board Proposes Rule to Strengthen Liquidity Positions of Large Financial Institutions,\" press release, October 24. Return to text\n\n12. Documents on initial margin requirements are available on the International Swap Dealers Association website. Return to text\n\n13. See Basel Committee on Banking Supervision and the International Organization of Securities Commissions (2013), Margin Requirements for Non-Centrally Cleared Derivatives: Second Consultative Document, report (Basel, Switzerland: Bank for International Settlements, February). Return to text\n\n14. The Basel Committee-IOSCO impact study reports all results in terms of euros. The results above have been converted to U.S. dollar amounts by multiplying by the euro-dollar exchange rate of 1 euro=1.35 dollars as of November 15, 2013. Return to text"
    },
    {
        "title": "Shadow Banking and Systemic Risk Regulation",
        "date": "November 22, 2013",
        "speaker": "Governor Daniel K. Tarullo",
        "url": "https://www.federalreserve.gov/newsevents/speech/tarullo20131122a.htm",
        "content": "November 22, 2013\n\nGovernor Daniel K. Tarullo\n\nAt the Americans for Financial Reform and Economic Policy Institute Conference, Washington, D.C.\n\nAs illustrated, quite literally, by a chart that New York Fed staff produced a few years ago, the term \"shadow banking system\" encompasses a wide variety of institutions that engage in credit intermediation and maturity transformation outside the insured depository system.1 In my remarks today, I want to concentrate on short-term wholesale funding and, especially, the pre-crisis explosion in the creation of assets that were thought to be \"cash equivalents.\" Such assets were held by a range of highly risk-averse investors, who were in many cases not fully cognizant that the \"cash equivalents\" in their portfolios were liabilities of shadow banks--the institutions depicted in the memorable graphic.\n\nIn some cases, the perception of claims on shadow banks as cash equivalents was based on explicit or implicit promises by regulated institutions to provide liquidity and credit support to such entities. In other cases, the perception came about because market participants viewed the instruments held on the balance sheets of shadow banking entities--notably highly rated, asset-backed securities--as liquid and safe. While reliance on private mechanisms to create seemingly riskless assets was sustainable in relatively calm years, the stress that marked the onset of the financial crisis reminded investors that claims on the shadow banking system could pose far more risk than deposits insured by the Federal Deposit Insurance Corporation (FDIC). Once reminded of their potential exposure, investors engaged in broad-based and sometimes disorderly flight from the shadow banking system.\n\nThis experience of the run on the shadow banking system that occurred in 2007 and 2008 reminds us that similar disorderly flights of uninsured deposits from banks lay at the heart of the financial panics that afflicted the nation in the late nineteenth and early twentieth centuries. The most dramatic of these episodes were the bank runs of the early 1930s that culminated in the bank holiday in 1933. Just as it was necessary, though not sufficient, to alter the environment that led to those successive deposit runs by introducing deposit insurance in order to create a stable financial system in the early-twentieth century, today it is necessary, though not sufficient, to alter the environment that can lead to short-term wholesale funding runs in order to create a stable financial system for the early twenty-first century.\n\nAs I will describe in a few moments, the Federal Reserve has taken some steps toward this end over the past few years. However, as I will also contend, completion of this task will require a more comprehensive set of measures, at least some of which must cover financial actors not subject to prudential regulatory oversight. Before turning to these points, I want to develop briefly the comparison between deposit runs of the pre-FDIC period and contemporary short-term wholesale funding runs in order better to explain the nature of the regulatory challenge.\n\nVulnerabilities Created by Short-Term Wholesale Funding\nThere are notable similarities between the bank runs that periodically afflicted the U.S. banking system before the creation of federal deposit insurance and the dramatic short-term wholesale funding runs that began in 2007. Each had a cascading, self-reinforcing quality, fueled by questions concerning the solvency of borrowing entities--whether deposit-taking banks or dealers seeking credit in repo markets. And, in each case, the opaqueness of the balance sheets of the borrowing entities led lenders to fear that an institution holding assets similar to, or interconnected through counterparty relationships with, another, troubled institution might itself be in trouble. Significantly, though, in each case, at least some of the lending actors were interested not just in eventually recovering the full amount of the funds they had extended, but in having access to those funds more or less immediately. Some depositors in 1932 needed their money in order to meet the requirements of daily life, while many repo counterparties in 2008 needed their money to meet other short-term obligations. Thus the issue was not just a matter of solvency--whether the firm would ultimately be able to pay all the claims even after the run--but also a matter of the short-term liquidity of the bank or broker.\n\nThe dynamic unleashed by short-term wholesale funding runs in 2007 and 2008 directly exacerbated financial stress. Many assets funded through the shadow banking system were traded assets, which could be liquidated rapidly, though often at distressed prices, to reduce the funding needs of the borrowing firms. The resulting fire sales recalled the asset liquidations by some trust companies during the Panic of 1907 and by some securities firms in the 1930s. In 2008, these fire sales created adverse feedback loops of mark-to-market losses, margin calls, and further liquidations. The unwinding of the risk illusion--that is, the assumption that lending to shadow banks was essentially risk-free--helped transform a dramatic correction in real estate valuations into a crisis that engulfed the entire economy.\n\nBut for a few idiosyncratic instances since the introduction of deposit insurance in 1933, bank runs have been rendered a thing of the past. Deposits below the amount of the federal insurance cap are fully and explicitly guaranteed. Access to the Federal Reserve's discount window for depository institutions complements the deposit insurance system by helping to relieve liquidity pressures in solvent banks. In practice, failing banks usually merge into healthier ones, so that depositors do not lose access to their funds and deposits exceeding the amount of the federal insurance cap are effectively protected. In the relatively few instances of depositor payouts, the FDIC has reimbursed depositors expeditiously. Of course, the explicit and de facto extension of federal guarantees created moral hazard problems, which the safety-and-soundness regulation of insured depository institutions was strengthened to address.\n\nThe similarities between deposit runs and short-term wholesale funding runs have suggested to some that the policy responses should also be similar. Those taking this position argue for providing discount window access to broker-dealers, guaranteeing certain kinds of wholesale funding, or both. Others, myself included, are wary of any such extension of the government safety net and would prefer a regulatory approach that requires market actors using or extending short-term wholesale funding to internalize the social costs of those forms of funding. Unlike deposit insurance, the savings of most U.S. households are generally not directly at risk in short-term wholesale funding arrangements. And, also unlike insured deposits, there is an argument in the short-term wholesale funding context that counterparties should be capable of providing some market discipline in at least some of the contexts in which such funding is provided.\n\nIn thinking about how to regulate shadow banking, we must be mindful that it is not really a single system. It is immeasurably more complicated than the bank deposit system of either the 1930s or today. Even with the reduction in activity following the crisis, the scale of shadow banking activity remains very large. Banks and broker-dealers currently borrow about $1.6 trillion, much of this from money market funds and securities lenders, through tri-party repos, leaving aside additional funds sourced from asset managers and other investors through other channels.2 The banks and broker dealers, in turn, use reverse repo to provide more than $1 trillion in financing to prime brokerage and other clients. While the volume of this activity has fallen considerably since the crisis and the haircuts and other conditions associated with current securities financing transactions are considerably more conservative than during the pre-crisis period, there is every reason to believe that the amount of this activity could increase, and the conservatism of the terms of the lending could be eroded, as economic conditions improve.\n\nLet me turn now to some of the specific vulnerabilities, steps that have been taken thus far to address these vulnerabilities, and the work that remains.\n\nRegulated Institutions and Shadow Banking\nWhile the term \"shadow banking\" implies activity outside the purview of regulatory oversight, regulated institutions are in fact heavily involved in these activities, both in funding their own operations and in extending credit and liquidity support to shadow banks beyond the regulatory perimeter.\n\nSupport provided for shadow banking activities may be either explicit or implicit. In some cases, there are explicit contractual provisions for credit enhancements and liquidity support. In other cases, the support is implicit, based on a bank's historical pattern of providing support or a belief among investors that a bank will provide support to maintain the value of its franchise. In the lead-up to the crisis, explicit and implicit commitments by regulated banking firms to shadow banks often combined to create the assumption that the liabilities of such entities were risk-free. This perception led to an underpricing of the risks embedded in these money-like instruments, making them an artificially cheap source of funding and creating an oversupply of these instruments that contributed to systemic risk.\n\nContractually committed credit and liquidity support lends itself more readily to regulation than does implicit support. Basel III reforms have strengthened the regulatory requirements for situations in which there is contractual support for shadow banking activities. For example, the Basel III capital requirements increase from 0 percent to 20 percent the credit conversion factor for commitments with an original maturity of one year or less that are not unconditionally cancellable. In addition, the Basel III Liquidity Coverage Ratio (LCR) assigns a 100 percent drawdown rate to undrawn amounts of credit and liquidity facilities extended by banks to a special purpose entity (SPE), effectively requiring a bank to hold $100 in high-quality liquid assets (HQLA) for every $100 it commits to a SPE.\n\nImplicit support presents more of a regulatory challenge. Identifying implicit forms of support requires a supervisory judgment that, despite sometimes stern warnings in offering documents, a banking organization bears some of the risk associated with that investment. Regulators must decide how much of the risk the banking organization retains and make context-sensitive judgments about the financial stability implications of various remedies. These challenges notwithstanding, regulators have made some progress in addressing instances of implicit support that played a major role in the last crisis. Let me mention two examples.\n\nThe first involves the implicit support associated with the provision of intraday credit by clearing banks in the tri-party repo market. In a repurchase agreement or \"repo,\" the cash borrower agrees to sell a security to a cash lender, and to repurchase the security from the cash lender at a later date. In a tri-party repo transaction, a clearing bank handles settlements through accounts held at that financial institution by the parties to the transaction. To allow broker-dealers who borrow in the tri-party repo market to have access to their securities for routine trading purposes, the market developed an operational feature known as the \"daily unwind.\" Before the crisis and for some time afterwards, the clearing banks unwound all tri-party repo trades each day--even those with a significant term, which in theory represented longer-term financing commitments--returning securities to borrowers and cash to lenders. However, because the securities still required financing during the day, cash borrowers relied on uncommitted secured credit, backed by their overall portfolio of securities and provided by the clearing bank. Transactions were re-wound at the end of the day, with specific securities allocated as collateral to each lender at that time.\n\nCash lenders in the tri-party repo market thus came to expect that the two clearing banks would always unwind their maturing trades in the morning, returning cash to their account, despite the absence of a contractual provision requiring them to do so. As a result, they grew comfortable in the belief that they held a cash-equivalent asset that was perfectly safe and liquid. But as the crisis deepened, cash lenders became aware of the fact that the clearing banks were not contractually obligated to unwind repo trades and that the dealers that were the primary borrowers in the tri-party repo market could fail, leaving lenders with collateral that they had little or no capacity to manage at a juncture when its value and liquidity was open to doubt. This resulted in several distinct episodes during the crisis when cash lenders, despite holding collateral, quickly withdrew financing from dealers perceived to be facing potential financial distress. The tri-party repo market might have suffered a full-scale run in the absence of public-sector intervention.\n\nSince the crisis, the Federal Reserve has led an effort to reduce reliance on intraday credit in the tri-party repo market. Work to date has reduced the amount of intraday credit provided by the clearing banks from 100 percent of the tri-party repo market to approximately 30 percent, and commitments by market participants suggest that this amount will fall to 10 percent by the end of next year. This operational change, in addition to enhancing the resiliency of the settlement process, should help limit the likelihood that tri-party repo lenders return to believing that lending in the tri-party repo market is a risk-free proposition. As a result, tri-party repo lenders are likely to conduct more thorough due diligence on their counterparties and exercise more care in considering the types of collateral that they will lend against than was the case before the crisis.3 \n\nThe second example involves the implicit support provided by bank sponsors of certain securitization SPEs. Before the crisis, the interplay between bank capital requirements and accounting rules created a significant incentive for banks to shift assets off-balance sheet through the use of various SPEs. Under the capital requirements that applied at the time, a bank that sold assets to a conduit or other SPE it sponsored was required to hold capital only against its contractual exposure to the SPE. Yet because a bank that failed to support SPEs it sponsored might irreparably damage the value of its franchise, banks often provided credit and liquidity support in excess of contractually obligated amounts to asset-backed commercial paper (ABCP) programs, credit card securitizations, and other structured finance vehicles. Recognizing this incentive, pre-crisis lenders were willing to hold commercial paper and other liabilities issued by bank-sponsored SPEs at yields only slightly higher than those on liabilities issued directly by the bank. In effect, the bank was able to hold less capital and reduce its funding costs without decreasing its economic exposure.\n\nPost-crisis reforms have reduced the opportunity for banks to exploit this regulatory arbitrage. In 2009, the Financial Accounting Standards Board (FASB) adopted FAS 166 and 167 to modify the accounting treatment of structured finance transactions involving certain SPEs. Under the new accounting guidance, a company is required to consolidate those SPEs for which the company has the power to direct matters that most significantly impact the entity as well as the obligation to absorb losses or the right to receive benefits. Securitization sponsors have generally interpreted the new guidance as requiring a sponsor to consolidate a SPE under circumstances in which the sponsor retains loan-servicing obligations and exposure to the equity tranche of the securitization.\n\nFollowing the publication of FAS 166 and 167, the federal banking agencies adopted new rules requiring banking organizations to hold risk-based and leverage capital against assets of the newly consolidated SPEs.4 These rules eliminated a provision in the bank capital requirements that permitted a banking organization to exclude from the calculation of its risk-weighted assets the assets of an ABCP program that the banking organization sponsored and was required to consolidate. As a result, bank sponsors of ABCP conduits and certain other securitizations must now hold levels of regulatory capital commensurate with the exposure arising from the implicit support they provide.\n\nCollateralized Borrowing Arrangements and Financial Stability\nTurning now to financial stability concerns raised by short-term wholesale funding more generally, I want to focus on collateralized borrowing arrangements. These collateralized borrowing arrangements consist largely of securities financing transactions (SFTs), a term that generally refers to repo and reverse repo, securities lending and borrowing, and securities margin lending. Lenders are willing to extend credit on a secured basis because these transactions are usually short-term, over-collateralized, backed by reasonably liquid securities, subject to daily mark-to-market and re-margining requirements, and exempt from the automatic stay in insolvency proceedings. In the most common practice, a broker-dealer uses SFTs to finance either securities inventory or a back-to-back SFT loan to another financial firm (SFT matched book).\n\nThe financial stability risks associated with a dealer's use of short-term SFT funding to finance its inventory are relatively straightforward. If a broker-dealer loses access to financing and is forced to sell securities at a depressed price, fire sale externalities may result because other market participants may be less able to borrow against the same securities. And if the broker-dealer fails due to runs by short-term SFT lenders, post-default fire sales by the firm's creditors or contagious runs on other financial intermediaries may ensue. Because broker-dealers generally do not internalize the externalities that arise in these cases, they may use more than the economically efficient level of short-term funding.\n\nThe financial stability risks associated with SFT matched books are somewhat less obvious. Even if the outflows and inflows associated with a dealer's SFT positions are perfectly maturity-matched, reputational considerations may inhibit a dealer from reducing the amount of SFT credit that it provides its customers, exposing the dealer to considerable liquidity stress. If the dealer does reduce the amount of credit that it provides to its customers, those customers may be forced to engage in asset fire sales of their own. Particularly in situations in which the customers are highly leveraged, maturity-transforming entities that lack access to a liquidity provider of last resort may pose a significant risk of contagion.\n\nPost-crisis financial regulatory reform has taken some steps to address the financial stability risks associated with a dealer's use of short-term SFT funding to finance inventory. For example, the liquidity coverage ratio requires firms to hold a buffer of high-quality liquid assets when they use SFT liabilities that mature in less than 30 days to fund many types of securities. New risk-based capital rules have substantially increased the amount of capital that dealers are required to hold against assets in the trading book. But these reforms are limited: The LCR does not require firms to hold any liquidity buffer against SFT liabilities that mature in more than 30 days or that are backed by very liquid assets. There continues to be a need for standardized capital requirements for market risk to back up model-derived risk weights.\n\nMoreover, the current regulatory framework does not impose any meaningful regulatory charge on the financial stability risks associated with SFT matched books. The Basel III risk-based capital rules require banking organizations to hold relatively little capital against SFT assets, which are assumed to pose little microprudential risk. Because leverage requirements do not take into account the fact that SFTs are collateralized transactions, leverage requirements have the potential to impose higher charges on SFT assets. But leverage requirements have traditionally been calibrated at non-binding levels and, to the extent they do bind in the future, are unlikely to bind evenly across firms. As a result, the leverage ratio may simply cause SFT assets and liabilities to migrate to those firms with stronger leverage ratios.\n\nSimilarly, the LCR and, at least at this stage of its development, the Net Stable Funding Ratio (NSFR), both assume that a firm with a perfectly matched book is in a stable position. The LCR assumes a bank can call in reverse repos and other SFT assets that mature in less than 30 days or reuse the collateral that secures those assets for purposes of its own borrowing. Thus, reverse repos and other SFT assets generally are treated as completely liquid instruments. Under the initial version of the NSFR, firms would not need to hold any stable funding against reverse repos, securities borrowing receivables, or other loans to financial entities that mature in less than one year. Again, this may be a reasonable position from a microprudential perspective, geared toward more or less normal times. But here is where we need an explicitly macroprudential perspective that forces firms to internalize the tail-event financial stability risks associated with SFT matched books.\n\nPolicy Options\nThere are two kinds of policy options that can be considered, individually or together, in responding to the financial stability vulnerabilities inherent in firms with large amounts of short-term wholesale funding--whether loaned, borrowed, or both. The first would impose a regulatory charge calculated by reference to reliance on SFTs and other forms of short-term wholesale funding, whether the firm uses that funding to finance inventory or an SFT matched book. The second would directly increase the very low charges under current and pending regulatory standards attracted by SFT matched books.\n\nAmong the first set of options, the idea that seems most promising is to tie capital and liquidity standards together by requiring higher levels of capital for large firms that substantially rely on short-term wholesale funding. The additional capital requirement would be calculated by reference to a definition of short-term wholesale funding, such as total liabilities minus regulatory capital, insured deposits, and obligations with a remaining maturity of greater than a specified term. There might be a kind of weighting system to take account of the specific risk characteristics of different forms of funding. The capital requirement would then be added to the Tier 1 common equity requirement already mandated by the minimum capital, capital conservation buffer, and globally systemic bank surcharge standards. However, this component of the Tier 1 common equity requirement would be calculated by reference to the liability side, rather than the asset side, of the firm's balance sheet.\n\nThe rationale behind this policy option is that, while solid requirements are needed for both capital and liquidity, the relationship between the two also matters. For example, a firm with little reliance on short-term funding is less susceptible to runs and, thus, to the need for engaging in fire sales that can depress capital levels. A capital surcharge based on short-term wholesale funding usage would add an incentive to use more stable funding and, where a firm concluded that higher levels of such funding were nonetheless economically sensible, the surcharge would increase the loss absorbency of the firm. Such a requirement would be consistent with, though distinct from, the long-term debt requirement that the Federal Reserve Board will be proposing to enhance prospects for resolving large firms without taxpayer assistance.\n\nThe second kind of policy option is to address head-on the macroprudential concerns arising from large matched books of securities financing transactions. A capital surcharge is in some respects an indirect response to the problem of short-term wholesale funding runs and, as earlier noted, current versions of capital and liquidity standards do not deal with matched book issues. One might choose either to increase capital charges applicable to SFT assets or to modify liquidity standards so as to require firms with large amounts of these assets to hold larger liquidity buffers or to maintain more stable funding structures. It is not clear how much appetite there may be internationally for revisiting agreements that have been completed, such as the LCR and the Basel III capital rules. However, with the NSFR still under discussion, and with the Basel Committee in the process of reconsidering the standardized banking book risk weights and capital regulations associated with traded assets, there are opportunities to pursue these options.\n\nRequirements building on any of the foregoing options would by definition be directly applicable only to firms already within the perimeter of prudential regulation. The obvious questions are whether these firms at present occupy enough of the market that standards applicable only to them would be reasonably effective in addressing systemic risk and, even if that question is answered affirmatively, whether the imposition of such standards would lead to a significant arbitrage through increased participation by those outside the regulatory perimeter. It does not seem far-fetched to think that, with time and sufficient economic incentive, the financial, technological, and regulatory barriers to the disintermediation of prudentially regulated dealers could be overcome. Indeed, there have already been reports of some hedge funds exploring the possibility of disintermediating dealers by lending cash against securities collateral to other market participants.\n\nFor this reason, there is a need to supplement prudential bank regulation with a third set of policy options in the form of regulatory tools that can be applied on a market-wide basis. That is, regulation would focus on particular kinds of transactions, rather than just the nature of the firm engaging in the transactions. To date, over-the-counter derivatives reform is the primary example of a post-crisis effort at market-wide regulation.5 Given that the 2007–2008 financial crisis was driven more by disruptions in the SFT markets than by disruptions in the over-the-counter derivative markets, comparable attention to SFT markets is surely needed. Over the past two years, the Financial Stability Board (FSB) has been evaluating proposals for a system of haircuts and margin requirements for SFTs. In its broadest form, a system of numerical floors for SFT haircuts would require any entity that wants to borrow against any security to post a minimum amount of excess margin that would vary depending on the asset class of the collateral. Like minimum margin requirements for derivatives, numerical floors for SFT haircuts would be intended to serve as a mechanism for limiting the build up of leverage at the security level, and could mitigate the risk of procyclical margin calls.\n\nIn August, the FSB released a proposal that would represent a first step in the direction of such a framework. However the FSB's proposal has some significant limitations. First, with respect to counterparty scope, the FSB's proposal would apply only to SFTs in which regulated entities provide financing to unregulated entities; the proposal would not cover SFTs between a regulated lender and a regulated borrower, between an unregulated lender and a regulated borrower, or between an unregulated lender and an unregulated borrower. Second, the proposal would apply only to lending against collateral other than sovereign obligations. And finally, with respect to calibration, the FSB's proposed numerical floors are set at relatively low levels--levels that are, for example, significantly below the haircuts that currently prevail in the tri-party repo market.\n\nAn alternative to the FSB's proposal would be to apply a system of numerical floors to SFTs regardless of the identity of the parties to the transaction. Such an approach would at least partially offset the incentive that will otherwise exist to move more securities financing activity completely into the shadows. Regarding calibration, there are at least three conceptually plausible bases for setting the level of the numerical floors above the low backstop levels contemplated in the current FSB proposal.\n\nOne approach would be to base the calibration of the numerical floors on current repo market haircuts. These haircuts have increased significantly compared to pre-crisis levels. Establishing numerical floors at around current levels could prevent the return of a less prudent set of practices as memories of the crisis fade. A second approach would be to set haircuts for a given asset class based on asset price volatility or haircut levels observed during times of stress or long-term periods that include times of stress. While minimum haircut levels should not be set as high as the haircuts lenders demanded at the depths of the crisis, setting numerical floors in proportion to those levels might be reasonable. A third alternative would be to set numerical floors for SFT haircuts at levels that are commensurate with the amount of capital a banking organization would need to hold against the security if it held the security in inventory. Such an approach could be viewed as an indirect way of extending bank capital requirements to the shadow banking system, and would reduce the current bank regulatory incentive to lend against a security rather than hold it directly.\n\nFinally, it is worth noting that, while a framework of universal margin requirements for SFTs could not be evaded through the disintermediation of regulated entities, it might be evaded through the use of alternative transactional structures. If margin requirements for cash SFT transactions are significantly higher than margin requirements for creating the same economic exposures using synthetic SFT transactions, a framework of minimum margins for SFTs could push market participants to rely more heavily on derivatives that are the functional equivalent of cash SFTs. Moreover, market participants might attempt to arbitrage margin floors through arrangements whereby the lender effectively lends the SFT borrower the minimum excess margin amount. These and similar issues will need to be addressed as options for minimum margins are further developed.\n\nConclusion\nIf we think back to the rapid growth of the shadow banking system in the pre-crisis period, we are reminded of some glaring vulnerabilities: Large firms that could themselves be considered shadow banks and that relied on the shadow banking system for a significant proportion of their funding--a group that included the \"free-standing\" investment banks--were outside the perimeter of prudential regulation. The breaking of the buck by the Reserve Primary Fund following Lehman's collapse triggered a run on the shadow banking system that required unprecedented support by the Treasury Department and the Federal Reserve.\n\nThe process established by the Dodd-Frank Wall Street Reform and Consumer Protection Act for designation of systemically important non-bank firms has provided a means for ensuring that the perimeter of prudential regulation can be extended as appropriate to cover large shadow banking institutions. The proposals of the Securities and Exchange Commission on money market fund regulation are a response to continuing vulnerabilities as well as to the run in the fall of 2008. These are important initiatives that will contribute to a safer system of funding throughout the financial system. Yet the risk of contagious runs would persist even in the absence of individually systemic institutions. And with less vulnerable money market funds, other cash-rich entities could emerge as a source of inexpensive funding for the shadow banking system. Finally, as I have noted, the systemic risks associated with short-term wholesale funding in prudentially regulated institutions have not fully been countered by the important capital and liquidity standards adopted since the crisis. My purpose today has been to reinforce the point that a sounder, more stable financial system requires a more comprehensive reform agenda.\n\n1. See Zoltan Pozsar, Tobias Adrian, Adam Ashcraft, and Hayley Boesky (2010), \"Shadow Banking (PDF),\" Staff Report No. 458 (New York: Federal Reserve Bank of New York, July). Return to text\n\n2. Federal Reserve Bank of New York, \"Tri-Party Repo Statistics as of 10/09/2013 (PDF),\" Tri-Party Statistical Data file. Return to text\n\n3. This work is explained on the website of the Federal Reserve Bank of New York. Return to text\n\n4. See Board of Governors of the Federal Reserve System, Federal Deposit Insurance Corporation, Office of the Comptroller of the Currency, and Office of Thrift Supervision (2010), \"Agencies Issue Final Rule for Regulatory Capital Standards Related to Statements of Financial Accounting Standards Nos. 166 and 167,\" press release, January 21. Return to text\n\n5. Although the Dodd-Frank Act gives the Commodity Futures Trading Commission and the Securities and Exchange Commission primary responsibility in this area, a broad range of federal financial regulators (including the Federal Reserve) is responsible for developing margin requirements for over-the-counter derivatives transactions. These requirements will limit the amount of leverage that market participants can take on through the use of derivative instruments. In addition, by requiring margin to be posted at the outset of a transaction and mark-to-market gains and losses to be continually offset through transfers of additional collateral, these requirements will help to avoid situations in which firms face margin calls only when they are most pressed for liquidity. Return to text"
    },
    {
        "title": "Concluding Remarks",
        "date": "December 16, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20131216b.htm",
        "content": "December 16, 2013\n\nChairman Ben S. Bernanke\n\nAt the Ceremony Commemorating the Centennial of the Federal Reserve Act, Washington, D.C.\n\nI have been asked to close this ceremony marking the 100th anniversary of the signing of the Federal Reserve Act--the law that created the Federal Reserve--by looking ahead to the next century. Given the well-known difficulties that economists have in forecasting even the next few quarters, I will happily point out one important advantage in making a 100-year forecast, which is that I won't be around to explain why the forecast went wrong. Our ability to make accurate long-term forecasts is limited, to say the least. Nevertheless, I will venture one prediction that I don't think is too bold, which is this: The values that have sustained and served the Federal Reserve at its best, and have permitted it to make critical contributions to the economic health of our nation during the past century, will continue to serve it and the nation well in the century ahead.\n\nAmong the Fed's most important values is the belief that policymaking should be based on dispassionate, objective, and fact-based analysis. The ideal we seek is a combination of the researcher's intellectual rigor and the ability of the effective policymaker to navigate the messiness of the real world, a world that includes complex institutions and markets, imperfect and incomplete data, and often-unpredictable human behavior.\n\nOf course, policy analysis and implementation of the highest quality do not just happen. They require professionalism and a commitment to public service as exemplified by the generations of staff members who have served this institution so well. Without the expertise and creativity embodied in the staff, it would have been impossible to develop the innovative policies required to meet, in the words of the Federal Reserve Act, the \"unusual and exigent circumstances\" we confronted during the recent financial crisis. If there is one thing on which I believe all of us here can agree, it is that the quality of the staff has been a great strength throughout our institution's history. Maintaining that quality and commitment to public service will be essential if the Fed is to have a successful second century.\n\nDispassionate analysis, expertise, and commitment to public service--all are values that have served us well. But one value that strikes me as having been at least as important as any other has been the Federal Reserve's willingness, during its finest hours, to stand up to political pressure and make tough but necessary decisions. The fight against inflation during Paul and Alan's times in office was critical for the nation's longer-term prosperity, and it required perseverance in the face of heavy criticism. I keep in my office one of the 2-by-4s mailed to the Fed during Paul's tenure, which communicates some distinctly unfavorable views of high interest rates and their effects. More recently, of course, the Federal Reserve took controversial but necessary measures to arrest what was arguably the worst financial crisis in American history, helping to avert what likely would have been a much more severe economic downturn than the Great Recession we did experience.\n\nWe have been able to respond nimbly to economic emergencies and make difficult choices in part because of our institutional structure--including long terms for members of the Board of Governors and diverse regional representation in our policymaking Committee--and because of the willingness of policymakers, past and present, to do whatever was needed in the longer-run interest of the economy. As an institution, the Federal Reserve must continue to be willing to make tough decisions, based on objective, empirical analysis and without regard to political pressure.\n\nBut, finally, we must also recognize that the Fed's ability to make and implement such decisions ultimately depends on the public's understanding and acceptance of our actions. For this reason, we must continue to emphasize two other essential values--transparency and accountability. We must do all that we can to explain our actions and to show how they serve the public interest. That's why we must welcome communication, broadly defined. Of course, we will continue to talk to economists and market participants, but that is not enough. Ultimately, the legitimacy of our policies rests on the understanding and support of the broader American public, whose interests we are working to serve. The ability of this institution to support a healthy economy--an economy with high levels of employment, low inflation, and a stable financial system--will require our continued efforts to engage in two-way communication--explaining our actions and, importantly, listening to what our fellow citizens have to say.\n\nLet me end by thanking the organizers of this event and, in particular, all of the past and present policymakers in attendance for helping us mark this centennial milestone in such a memorable fashion."
    },
    {
        "title": "Opening Remarks",
        "date": "December 16, 2013",
        "speaker": "Chairman Ben S. Bernanke",
        "url": "https://www.federalreserve.gov/newsevents/speech/bernanke20131216a.htm",
        "content": "December 16, 2013\n\nChairman Ben S. Bernanke\n\nAt the Ceremony Commemorating the Centennial of the Federal Reserve Act, Washington, D.C.\n\nPaul and Alan have me at a disadvantage. Each of us was asked to reflect on our own term in office. But they have the benefit of perspective, whereas my term still has a short time to run. Moreover, work on some of the Federal Reserve's most important challenges of the past few years--notably, achieving a full economic recovery from the crisis and putting in place a new financial regulatory system--is still ongoing. Nonetheless, I will offer a few thoughts on the past very eventful eight years.\n\nThe Federal Reserve's extraordinary response to the financial crisis and the Great Recession that followed was, in one sense, nothing new. We did what central banks have done for many years and what they were designed to do: We served as a source of liquidity and stability in financial markets, and, in the broader economy, we worked to foster economic recovery and price stability. However, in another sense, what we did was very new--it was unprecedented in both scale and scope, and it made use of a number of tools that were new, or at least not part of the standard central bank toolkit. We found that these new tools were necessary if we were to fulfill the classic functions of a central bank in the context of a 21st century economic and financial environment.\n\nWhen the financial system teetered near collapse in 2008 and 2009, we responded as the 19th century British essayist Walter Bagehot advised, by serving as liquidity provider of last resort to stressed financial firms and markets.1 But we did so in an institutional environment that was very different, and in many ways much more complex, than the one that Bagehot knew. For example, the recent crisis involved runs on financial institutions, as occurred in classic panics. But in 2008, rather than a run of retail bank deposits, the runs occurred in various forms of short-term, uninsured wholesale funding, such as commercial paper and repurchase agreements. Moreover, although commercial banks suffered large losses and some came under significant pressure, the crisis hit particularly hard those nonbank institutions most dependent on wholesale funding, such as investment banks and securitization vehicles. Thus, the Fed lent not only to commercial banks, but also extended its liquidity facilities to critical nonbank institutions and key financial markets, such as the commercial paper market. To minimize the risk of strains abroad feeding back on U.S. dollar funding markets, the Fed also coordinated with foreign central banks to create a network of currency swap lines.\n\nBeyond the provision of liquidity, the Fed worked with other agencies both here and abroad to help restore public confidence in the financial system. Notably, we led the development of stress-testing large banking organizations' capital adequacy. The first stress tests, in 2009, and the public disclosure of their results made it possible for large U.S. banks to once again attract private capital. Since 2009, the stress tests and disclosures, together with other regulatory and supervisory actions, have contributed to a doubling in capital held by the largest U.S. financial institutions and the resumption of more-normal flows of credit.\n\nThe Fed has also worked to draw the appropriate lessons from the crisis and to take the steps necessary to help avoid a similar event in the future. As those assembled here well know, the deliberations that led to the founding of the Federal Reserve were precipitated by a financial panic, the Panic of 1907. The preservation of financial stability was consequently a principal goal of the creators of the new central bank. In response to the Panic of 2008, the Federal Reserve has returned to its roots by restoring financial stability as a central objective alongside the traditional goals of monetary policy. We have refocused our supervision of financial institutions to take a more \"macroprudential\" approach that fosters systemic stability as well as the stability of individual institutions. We also more extensively monitor the financial system as a whole and, in cooperation with other agencies, have put in place stronger oversight of systemically important financial firms, including higher capital and liquidity requirements, tougher supervision, and a process for the orderly resolution of failed firms.\n\nWe have also had to be innovative in finding ways to use monetary policy to help the economy recover from the deep recession that followed the crisis. Providing adequate monetary accommodation has not been a straightforward task because our principal monetary policy tool, the target for the federal funds rate, has been stuck near zero since the end of 2008. Consequently, we've had to find other ways to bring monetary policy to bear, notably including techniques designed to influence longer-term interest rates. For instance, the Fed, like several other central banks, has purchased longer-term securities to put downward pressure on longer-term interest rates, help ease financial conditions, and promote a stronger recovery.\n\nA significant aspect of finding innovative ways to execute our duties as a central bank in a new, more complex environment has been the ongoing revolution in communication and transparency. Part of that effort has involved formally defining our goals under the mandate for maximum employment and price stability given to us by the Congress. Two years ago, we established 2 percent as our inflation goal, and we regularly communicate policymakers' views of the level of unemployment expected to correspond to maximum sustainable employment over time. Additionally, our monetary policy has come to rely more heavily on \"forward guidance.\" With our short-term policy rate about as low as it can practicably go, we have sought to ease financial conditions further and provide additional impetus to the recovery by communicating both quantitatively about the likely future path of our policy rate and qualitatively about the likely evolution of our balance sheet. Other central banks around the world have met the challenge of current conditions with similar innovations. And I would be remiss if I did not point out, especially with Paul and Alan here, that the Fed's recent communications innovations owe a great deal to developments like the monetary targeting framework devised under Chairman Volcker and the post-Federal Open Market Committee statement and qualitative forward guidance introduced under Chairman Greenspan.\n\nIn summary, the financial crisis that the Fed confronted five years ago was in many ways analogous to the panics that central banks have faced for centuries. But, at the same time, the crisis and the deep recession that followed occurred in an economic and financial environment that was certainly different, and in many ways more complex, than in the past. The Federal Reserve found ways to carry out its traditional central bank functions in this environment, and we are working with other policymakers, domestically and internationally, to put in place a strengthened regulatory framework that will help preserve stability in the face of the complexity, interconnectedness, and innovation in our modern financial system.\n\nOne of my personal objectives since I became Chairman has been to increase the transparency of the Fed--to more clearly explain how our policies are intended to work and the thinking behind our decisions. As I already noted, improved communication can help our policies work better, whether through the disclosure of bank stress-test results or by helping the public and market participants better understand how monetary policy is likely to evolve. Ultimately, however, the most important reason for transparency and clear communication is to help ensure the accountability of our independent institution to the American people and their elected representatives. Clarity, transparency, and accountability help build public confidence in the Federal Reserve, which is essential if it is to be successful in fostering stability and prosperity.\n\n1. See Walter Bagehot ([1873] 1897), Lombard Street: A Description of the Money Market (New York: Charles Scribner's Sons). Return to text\n\n "
    }
]