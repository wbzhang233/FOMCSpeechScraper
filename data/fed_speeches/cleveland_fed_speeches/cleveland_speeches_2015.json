[
    {
        "speaker": "Loretta J. Mester",
        "date": "November 18, 2015",
        "title": "U.S. Payment System Improvement and the Federal Reserve",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - The Clearing House Annual Conference - New York, NY - November 18, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20151118-us-payment-system-improvement-and-the-federal-reserve",
        "content": "Good morning. As the central bank of the United States, the Federal Reserve has a strong interest in fostering a well-functioning payment system. In my brief time this morning, I will answer three broad questions about the collaborative initiatives being led by the Federal Reserve working with private-sector stakeholders. These initiatives are aimed at improving the U.S. payment system’s speed, efficiency, access, and security. As always, the views I’ll present today are my own and not necessarily those of the Federal Reserve System or my colleagues on the Federal Open Market Committee.\n\nThe first question one might ask is, “Why is there a need to improve the U.S. payment system?” There has been a lot of talk of late about the need to improve the infrastructure of the U.S. Mostly this has referred to things like highways, bridges, railroads, aviation, and water treatment, all of which play an important role in fostering economic growth and development. I think we should also consider the U.S. payment system a critical part of the infrastructure of this country. A modern payment system is not a luxury. It is a necessary part of a vibrant economy.\n\nThe current payment system in the U.S. is meeting the immediate need of moving payments from payer to payee. It is good to remember that the current system is supporting an $18 trillion economy. In 2012, over 120 billion non-cash, non-wire-transfer payments, valued at almost $175 trillion, were made in the U.S.1 There is a long history of payment-system innovation in this country, including the move from paper check to check imaging and electronic presentment, as well as the advent of Internet and mobile banking. Nonetheless, the payments landscape has been rapidly changing over recent years, and the U.S. payment system is at a crossroads. It is a fragmented patchwork of payment vehicles and providers, often lacking interoperability with one another or the ability to combine invoice information with a payment. The complexity of the payment system, involving incumbent providers, new entrants, and end users, makes it harder to coordinate payment innovations. Thus, even as the payment system has grown in complexity, it has not kept up with the evolving expectations and demands of end-user businesses and consumers. Nor has it kept up with developments in other countries that have taken steps to modernize their payment systems.\n\nMuch of the change in the payment system landscape has been driven by the rapid evolution of technology. Higher-speed computers and mobile devices have enabled the rapid development of e-commerce, which has changed the nature of both retail and business-to-business commerce. Consumers and businesses are demanding faster payments, both domestic payments and cross-border payments. Indeed, maybe the best indication that consumers and businesses want faster payments is that they are willing to pay for speed. According to analysis commissioned by the Federal Reserve, about a third of consumers and three-quarters of businesses are willing to pay a fee for payments that offer faster availability to the payee.2 In addition to meeting customer demand, a modernized payment system could have an added societal benefit of bringing the unbanked and underbanked into the financial mainstream. It could also help low-income households, small businesses, and others who need to closely manage their finances to gain faster access to their funds.\n\nAssessing these trends, the Federal Reserve and a diverse set of industry stakeholders have come to agree that the U.S. payment system needs to evolve further and faster to support the changing nature of commerce, keep pace with the global economy, meet the changing needs of end users, and address new and ongoing threats to safety and security. An improved payment system will contribute to public confidence, economic growth, and global competitiveness.\n\nGiven that we see a need to modernize the payment system, a second question comes to mind: “What approach is the Federal Reserve taking to facilitate the move to a faster, more efficient, ubiquitous, and secure payment system?” Earlier this year, the Federal Reserve Board and Reserve Banks published a paper entitled “Strategies for Improving the U.S. Payment System.”3 This paper communicates our desired outcomes for the payment system and outlines the strategies and tactics that the Federal Reserve is pursuing, in collaboration with stakeholders, to help the country achieve these outcomes. As indicated in the “Strategies” paper, there was a lot of work that preceded the current initiative. In 2002 and in 2012, the Fed undertook gap and opportunity assessments of the payments environment, seeking and receiving considerable input from the public on where the payment system was lagging and where it could be improved. That work laid the foundation for the current initiative, which seeks to achieve five outcomes: (1) a payment system that offers a safe and faster electronic solution for making a variety of personal and business payments, which is ubiquitous and available on demand; (2) a payment system that is secure and resilient, and so one in which the public can be highly confident; (3) a payment system that is efficient and offers better value to consumers and businesses; (4) a payment system that offers a more convenient, cost-effective, and timely way to make cross-border payments; and (5) a payment system that has been improved via a collaborative process involving a broad array of payment participants.\n\nThe collaborative approach the Fed is pursuing follows on from the comprehensive stakeholder engagement we undertook in 2012 to assess the payments landscape. Most of those who commented on the consultative paper that summarized the Fed’s findings strongly supported the Fed’s continuing to serve as a convener of payment-system stakeholders and as a catalyst for collaboration.5 Comprehensive improvement of the system for making payments end-to-end will require a comprehensive approach based on collaboration among and actions from a diverse set of payment stakeholders, including traditional and nontraditional payment providers, technology companies, the government, and end users.\n\nI should note that the approach the Fed is taking to support and guide these various parties to work together on strategies to improve the payment system differs somewhat from the approach taken in other countries, some of which have officially mandated changes to speed the adoption of more efficient payments. For example, the Faster Payments Service launched in the United Kingdom in 2008 was implemented by the private sector by request of the government.6 The New Payments Platform currently being built in Australia, with expected launch date in mid-2017, was an industry-based solution proposed after the Reserve Bank of Australia, that country’s central bank, undertook a strategic review of payment innovation and published strategic objectives it expected the payment system to meet.7 The Fed does not have the power to mandate a solution, nor could we implement meaningful payment improvement on our own. We recognize that many payment innovations have come from the industry. So the Fed is taking a leadership role as a catalyst to spur a private-sector solution that will align private-sector interests with those of the public. This is consistent with the Fed’s responsibility to foster a well-functioning payment system for the public benefit. We believe our collective and collaborative approach to payment-system improvement will increase the probability of successful outcomes by encouraging ubiquitous access and widespread adoption of new payment-system capabilities. Note that the Fed’s approach does not preempt or compete with other efforts already being undertaken by the industry, one of which is The Clearing House’s multiyear project to build a real-time payment system for all U.S. financial institutions.8 And it does not mean that the Fed will halt efforts to improve the efficiency of the payment services we ourselves are providing. In fact, we are acting to speed up settlements on our National Settlement Service, promoting greater use of same-day ACH capabilities, and considering other enhancements to our services that will have a positive impact in the near term.\n\nThis brings me to the third and final question you may be asking yourselves: “What’s been accomplished so far on the payment system improvement initiative?” I am happy to report that since the “Strategies” paper was published earlier this year, there has been considerable progress. First, we have appointed some able leaders of the efforts. Gordon Werkema, who presented at the conference yesterday, is our Payments Strategy Director, overseeing the initiative. We have also established two task forces that will work toward proposed solutions to the goals outlined in the “Strategies” paper: One task force is focused on faster payments and the other on the security of payments. Our Faster Payments Strategy Leader, Sean Rodriguez, chairs the Faster Payments Task Force, and our Payments Security Strategy Leader, Todd Aadland, chairs the Secure Payments Task Force. These three leaders have worked tirelessly to build up wide task-force memberships representing the diverse stakeholders with an interest in the payment system. At last count, the Faster Payments Task Force has 328 members, and the Secure Payments Task Force has 180 members. I would encourage you to take a look at the breadth and depth of the current task-force memberships on our web page FedPaymentsImprovement.org. You’ll see that there are representatives of financial institutions of all sizes, payments networks, trade associations, technology companies, business end users and consumers, and a small number of government officials. You’ll also notice that members of The Clearing House, likely several people in this room, serve on each task force. These task forces have chosen steering committees and have set up a framework for ensuring that task-force decisions and work products have broad support across members; work streams are now underway.\n\nThe Faster Payments Task Force has completed and gathered public comment on a draft set of criteria that will be used to assess whether proposed alternative approaches will be effective in delivering a safe and ubiquitous faster-payments capability. These criteria fall into six categories: ubiquity, efficiency, safety, speed, legal considerations, and governance. The criteria are not meant to be a set of minimum requirements. Many of the criteria may involve a tradeoff, for example, speed vs. safety. The criteria are intended to differentiate the effectiveness of solution proposals across many dimensions. The effort is on track to finalize these criteria in coming months. Work is also progressing on defining a process for encouraging the best ideas on faster payments to come forward and for assessing proposals against the effectiveness criteria.\n\nThe Secure Payments Task Force has also begun its work, focusing not only on the security of the future faster payment system, but also on the security of the current payment system. It has provided input to the Faster Payments Task Force on the effectiveness criteria pertaining to security against which a faster payment solution should be assessed. These include identity management, authentication, and ways to secure sensitive information as it travels through the payment system. Regarding the current payment system, the Secure Payments Task Force is considering better methods to share and analyze fraud and cyber-threat information. Another role of the task force is advising the Fed on ways we could improve security in the payments areas in which we are already involved, including determining priorities for developing and setting payment-security standards in these areas, and identifying issues related to payment-system security and resiliency that would benefit from additional research. Work is currently underway to determine high-priority areas for which work groups will be formed in the next few months.\n\nI hope that you can see from this brief overview that in just a short period of time a lot has been accomplished. But we all recognize that there is still much more to do. The Federal Reserve is committed to facilitating these collaborative efforts with payment stakeholders on behalf of the public, because at the end of the day, the promise of a ubiquitous, faster, secure payment system is worth it."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "November 13, 2015",
        "title": "Perspectives on the Economy and Monetary Policy",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - The City Club of Cleveland - November 13, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20151113-perspectives-on-the-economy-and-monetary-policy",
        "content": "Chris, thank you for that kind introduction and for your service as chair of the Federal Reserve Bank of Cleveland’s Board of Directors. And thanks to the City Club for the opportunity to speak today to so many of Cleveland’s business leaders. Since coming to Cleveland last year, I have made it a point to learn more about the city’s many important institutions, and the City Club of Cleveland is certainly a leader among them. It is an honor for me to be included in your list of very distinguished speakers. For more than 100 years, the City Club has fostered the free and open exchange of ideas. It sees value in bringing together people with diverse viewpoints for a civil discussion of a wide variety of topics. The City Club’s commitment to free speech in promoting a well-informed community is praiseworthy public service.\n\nAlthough it might not be apparent, the City Club and the Federal Reserve have several things in common. Like the City Club, the Federal Reserve System is over 100 years old, and it, too, is committed to public service. At meetings of the Federal Open Market Committee, the body within the Fed that is charged with setting monetary policy, my colleagues and I engage in a free and open exchange of views. In our case, the topics covered aren’t as wide ranging as those discussed at the City Club; we focus on the economy and monetary policy. By design, the discussions at our meetings contain a mosaic of economic information and analysis from all parts of the country. I believe this ability to share what are sometimes diverse views on the state of the economy and policy is one of the strengths of the Federal Reserve System. It allows us to work toward a better-informed consensus on monetary policy to promote the Fed’s congressionally mandated goals of price stability and maximum employment.\n\nLike the City Club, the Fed sees value in a well-informed public, and we feel an obligation to explain our policy decisions so that the public and its elected representatives can hold us accountable for those decisions. So today, before we move on to the question and answer portion of the program, which is a highlight of any speaking engagement at the City Club, I would like to offer my perspectives on the economy and monetary policy. As I just mentioned, while the Committee comes to a consensus policy decision, there can be a diversity of views around the FOMC table, so I want to note that the views I’ll present today are my own and not necessarily those of the Federal Reserve System or my colleagues on the Federal Open Market Committee.\n\nThe Economic Outlook\n\nIt may not come as news to you that at its October meeting, the FOMC decided to maintain the target for our policy rate – the federal funds rate – at essentially zero. The Committee reached this decision based on an assessment of both realized and expected progress toward our objectives of maximum employment and 2 percent inflation. To make such an assessment, the Committee looks at a wide range of economic information – the official economic statistical releases and financial market indicators, as well as the information I and other FOMC participants garner by speaking with business contacts in our regions, including members of our Boards of Directors and advisory groups. When the FOMC says its decisions are “data-dependent,” this is really shorthand for this more comprehensive process of parsing economic and financial information, and assessing what it implies about the current state of the economy, the economic outlook, and the risks around that outlook. The FOMC will be doing this same type of analysis at our next meeting in mid-December. We will be looking at all the incoming information between now and then to see if it supports the FOMC’s expectation that the economy will continue to grow at a pace sufficient to generate some further improvement in labor markets and a gradual return of inflation to our target of 2 percent over the medium run.\n\nGrowth\n\nThere is no denying that the U.S. economy has come a long way since the darkest days of the global financial crisis and the Great Recession,which officially ended more than six years ago. Supported by extraordinary monetary policy action, economic fundamentals have strengthened, and in the face of various shocks, the economy has been resilient enough to sustain a moderate pace of growth over the past six years.\n\nOf course, over this expansion, the pattern of growth has not been smooth. It has varied over time and over sectors, and 2015 was no exception. We began this year with a slowdown in output growth to less than 1 percent at an annual rate. The slowdown mainly reflected temporary factors, including severe winter weather and labor disputes at West Coast ports. As those temporary factors abated, we saw growth rebound sharply to almost 4 percent in the second quarter, only to fall back to 1.5 percent in the third quarter. That slowdown largely reflected a sharp pullback in the rate at which firms were adding to their inventories from an unsustainably strong pace in the first half of the year. A better gauge of growth in demand is final sales adjusted for inflation. These grew at a solid 3.0 percent in the third quarter, suggesting that the economy still has solid underlying momentum.\n\nThe driver of growth this year has been consumer spending, which makes up about two-thirds of output. And when I say “driver,” you can take that literally. Consumers have been purchasing vehicles, especially light trucks, in very high volumes, higher than before the recession. Consumer spending on other durable goods and services has also been growing at a solid pace. Growth in personal income and continued improvement in household balance sheets have supported this spending. At a national level, house prices have recovered to levels seen before the crisis, adding to the wealth of homeowners, and we’ve seen a gradual pickup in housing activity, including sales and construction. Fewer households are underwater on their mortgages and mortgage delinquencies are down. Although stock prices are little changed, on net, so far this year, the cumulative increase in stock prices since the crisis is significant. Households lost $13 trillion in net worth over the Great Recession, but now thanks to the cumulative increase in stock and house prices, households have recovered that loss and have added another $18 trillion in net worth to their balance sheets.\n\nLower energy prices have also boosted household purchasing power. Oil prices are down about $40 per barrel from a year ago and gasoline is currently running about $2.30 per gallon, 80 cents lower than a year ago. The U.S. Energy Information Administration estimates that the drop in gasoline prices this year has saved the average household about $700, and it is projecting that expenditures on home heating oil will be 25 percent lower this winter than last.\n\nWhile, on net, lower oil prices will be a positive for U.S. economic growth over the medium run, in the near term, the drop in oil prices has been a drag on investment in the domestic energy sector and its suppliers. This is affecting growth in certain regions of the country, including parts of eastern Ohio. Investment in drilling and mining equipment is likely to continue to decline for a few more quarters, but outside of energy-related sectors, business investment in equipment and intellectual property continues to grow moderately.\n\nManufacturing, aside from motor vehicles, has been one of the soft spots in the economy. Lower oil prices have led to a pullback in manufacturing related to the energy sector. The appreciation in the value of the U.S. dollar over the past year has also weighed on firms with international exposure. Dollar appreciation reflects the expectation that economic growth in the U.S. will continue to be stronger than growth abroad. A stronger dollar means better terms of trade for U.S. consumers and businesses, which is a positive for a growing economy in the longer run. But in the near term, slower growth in our trading partners and the dollar appreciation are drags on U.S. export growth, and I expect net exports to be a negative influence on real GDP growth for somewhat longer. The good news is that recent changes in the value of the dollar and oil prices haven’t been as sharp, so I expect both drags to lessen over time and to be outweighed by growth in other sectors, including consumer spending and housing.\n\nYou may recall that in August there was an episode of significant volatility in financial markets and a tightening in credit conditions: stock prices fell and credit spreads rose. These financial market developments appeared to have been touched off by concerns about the prospects for growth in China and other emerging market economies. Since then, volatility has subsided and equity markets have stabilized. As the FOMC indicated in its October statement, some of the downside risks related to global economic and financial developments have diminished. But the possibility of a sharper-than-anticipated decline in global growth remains a risk to the outlook, and we will continue to monitor for signs of spillovers to the U.S. economy.\n\nOne question is whether the softening we saw in U.S. growth in the third quarter is signaling a more persistent slowdown in momentum that changes the medium-run outlook, which is the relevant time horizon for monetary policy. My answer is no. The resiliency of the economy through the episode in August, as well as the strength in final sales in the third quarter, suggests to me that there continues to be positive economic momentum. I anticipate that after the weak third quarter, growth will pick up over the rest of this year and next, to an above-trend pace in the 2.5 to 2.75 percent range. I recently revised down my estimate of longer-run growth to 2.25 percent, a quarter of a percentage point lower than my previous estimate. My revision reflects the Bureau of Labor Statistics’ recent downward revisions to past productivity growth.\n\nMany factors, including trend labor force participation, structural productivity growth, and technological innovation, affect the nation’s longer-run growth potential, and there is considerable uncertainty around estimates of potential growth. In fact, it is noteworthy that economists have been revising down their estimates of potential growth almost every year since the Great Recession started. For example, in 2008, the Congressional Budget Office estimated that potential growth between 2008 and 2013 would average 2.5 percent, well above its current estimate of 1.5 percent for that same time period. Similarly, over time, FOMC participants have lowered their projections for longer-run growth. The FOMC began releasing these longer-run projections in January 2009. At that time, the central tendency of the participants’ projections of longer-run GDP growth was 2.5 to 2.7 percent. In the projections released in September, the central tendency was down to 1.8 to 2.2 percent.\n\nThe implication is that even though the economy has been growing at a relatively moderate pace over the expansion, that pace has been sufficient to generate significant cumulative improvements in the labor market.\n\nLabor Markets\n\nIt is good to remember how far we have come. Over the past six years, the unemployment rate has been halved, falling from a high of 10 percent in October 2009 to 5.0 percent this October. It’s down over half of a percentage point since the end of last year. Nonfarm payrolls are now more than 4 million above their previous peak before the Great Recession. More than 2 million jobs have been added this year, and these have been full-time jobs. Last Friday, we learned that following softer gains in August and September, firms added a very robust 271,000 jobs in October. So far this year, payroll gains have averaged a little more than 200,000 jobs per month. As we often say, we shouldn’t read too much into one month’s number given the month-to-month variation in these readings and the fact that there are still revisions to come. That was true of the softer numbers in August and September, but it’s just as true of the outsized gain in October, which I doubt will be repeated in November. It’s better to smooth through the volatility: over the past three months, firms added an average of 187,000 jobs per month. This is somewhat slower than the pace seen earlier in the year, but given the cumulative gains that have been made on the job front and the level of employment growth that is consistent with full employment over the longer run, we should be expecting payroll job growth to slow.\n\nEconomists currently estimate that monthly payroll growth in the 75,000 to 120,000 range would be enough to keep the unemployment rate constant. This is lower than in the past because labor force participation rates have been trending down with the aging of the population and the increase in college enrollments. But notice that this means that even the softer average monthly gain of 145,000 in August and September is enough to put downward pressure on the unemployment rate.\n\nA broad array of other labor market indicators have improved significantly over the past few years, although they are not quite back to pre-recession levels. These measures include the long-term unemployment rate, as well as the unemployment rate that includes discouraged workers and part-time workers who would rather work full-time. Despite the improvement in labor markets, so far we have not seen broad-based acceleration in wages. But signs point to firming. Average hourly earnings growth strengthened in October. We have heard from business contacts in our region that it is becoming increasingly difficult to find qualified workers in specific occupations and industries, including construction, IT, and specialized manufacturing. In fact, our construction contacts report that the primary downside risk they face is a shortage of labor, not potentially higher interest rates. There are similar indications from other parts of the country; firms report having to raise wages to attract and retain workers in these occupations. The recent contract deal at General Motors includes salary increases in the 3 to 4 percent range and higher entry-level wages. As labor markets continue to improve, I expect to see some broader acceleration in compensation.\n\nIn my view, the totality of evidence suggests that the economy is at or very nearly at the Fed’s mandated monetary policy goal of maximum employment, and with growth resuming at an above-trend pace, I expect to see further improvement. This isn’t to say that there aren’t longer-term challenges facing the labor market. Workforce development is a key issue. As a country, we want to ensure that people can enter and remain productive members of the labor force, to raise our standards of living and to make us more competitive in the global economy. Monetary policy is not the tool for addressing this important issue, but the Federal Reserve, through its role in promoting community development, is certainly committed to helping identify effective policies and best practices for strengthening and increasing access to education and training. In fact, this past June, the Cleveland, Philadelphia, and Richmond Feds hosted a policy summit that brought together practitioners, researchers, and policymakers working on these issues.\n\nRegional Growth and Labor Markets\n\nAs I mentioned, an important role of a Federal Reserve Bank President is gathering information from Main Street to help inform monetary policy. So let me spend a few minutes on economic developments in the Fourth Federal Reserve District, which encompasses all of Ohio, western Pennsylvania, eastern Kentucky, and the northern panhandle of West Virginia. While our region is quite diverse, the path of economic expansion here has been similar to the nation’s. Regional firms with international exposure, such as the steel industry, continue to struggle. Shale gas production levels remain high but growth in drilling activity has slowed considerably. Auto and auto parts manufacturing represents a significant share of manufacturing in Ohio and Kentucky, and the strength we’ve seen in this sector has helped to offset some of the weaker manufacturing segments.\n\nLike the nation, our region has also seen considerable improvement in labor markets. In Ohio, the unemployment rate has fallen sharply from a peak of 11 percent in December 2009 to 4.5 percent in September, below the national average. Firms have been adding jobs, but at a slower pace than in the nation. Over the past year, the pace of job growth in Ohio has been only half that of the U.S. as a whole. And while U.S. employment is now 3 percent above its pre-recession peak, employment in Ohio is not quite back to that benchmark.\n\nThis slower job growth in the state relative to the nation is not a new phenomenon – it’s been happening since the mid-1990s. It partly reflects the slower population growth and older population in Ohio, as well as Ohio’s higher share of jobs in manufacturing, a sector that has been experiencing a long-run decline in employment. Manufacturing accounts for about 15 percent of private-sector jobs in Ohio, compared to about 10 percent in the U.S. Those shares are down about 7 percentage points since the mid-1990s. As the regional economy becomes less reliant on old-style manufacturing, and more reliant on higher-skilled manufacturing and service-sector jobs in fields such as education and health care, it faces the challenge of ensuring that its population can gain the necessary skills to enter and remain productive members of the modern labor force. So workforce development is a challenge here, just as it is for the nation as a whole.\n\nInflation\n\nIn addition to maximum employment, the other part of the Fed’s dual mandate is price stability. Inflation has been below the Fed’s 2 percent goal for some time. Headline inflation has been running at about a quarter percent so far this year (as measured by the year-over-year percentage change in the price index for personal consumption expenditures). Excluding food and energy prices, which tend to be volatile, so-called core inflation has been running about 1.3 percent. Low inflation partly reflects the transitory effects of the sharp drop in energy prices, as well as the appreciation of the dollar, which makes non-petroleum imports cheaper in the U.S.\n\nIncoming data are consistent with the inflation dynamics that the FOMC has been expecting. As changes in oil prices and the value of the dollar have tempered, the downward pressure on inflation has started to wane. Recent readings on underlying inflation, including the core, trimmed mean, and median CPI measures, have moved up. For example, the year-over-year change in the Cleveland Fed’s median CPI measure rose to 2.5 percent in September. There is considerable uncertainty around any inflation forecast, but analysis by Cleveland staff and others suggests that core measures of inflation can improve forecasts of headline inflation at least over some time horizons; in some cases, the improvement is statistically significant.\n\nInflation expectations are an important factor shaping the inflation outlook, and in my view, inflation expectations remain well-anchored. Survey-based measures of inflation expectations of both consumers and professional forecasters have been stable despite the low readings of actual inflation. These survey measures have historically done well at capturing longer-run trends in inflation and they have been shown to help in forecasting inflation.1 Inflation compensation, measured by the spread between yields on Treasury securities and Treasury inflation-protected securities, so-called TIPS, has moved down a bit, but analysis suggests that this likely reflects liquidity effects and changes in inflation risk premiums more so than changes in inflation expectations. Cleveland Fed staff analysis also suggests that the fall in inflation compensation may be reflecting the sharp drop in energy prices since last year, which might reverse as movements in oil prices moderate.2\n\nI expect inflation to remain low in the near term, but the firming in the core measures, the stability in inflation expectations, the economy’s expected return to above-trend growth, and continued improvement in labor markets are all factors making me reasonably confident that inflation will gradually return to our 2 percent goal over the medium run.\n\nOf course, my economic outlook is dependent on appropriate monetary policy, so let me turn to that now.\n\nMonetary Policy\n\nIt is well accepted that monetary policy needs to be forward looking. Because monetary policy affects the economy with a lag, rates will need to begin to move up from their very low level before we have fully reached our goals. The FOMC anticipates that two criteria need to be satisfied before it will be appropriate to raise the federal funds rate: some further improvement in the labor market and reasonable confidence that inflation will move back to its 2 percent objective over the medium term.\n\nIn deciding whether these conditions have been met and whether it is appropriate to raise the target range for the fed funds rate, the FOMC has to balance a number of considerations. My colleagues and I are all committed to promoting the goals of price stability and maximum employment, but we may have different views about realized and anticipated progress toward those goals and about the potential costs and benefits to changes in policy. Given the current stage of the business and policy cycles, I find this diversity neither surprising nor troubling.\n\nIn September and October, the FOMC’s consensus expectation was that labor market conditions will continue to improve and that inflation will return to target over time, but the Committee decided that it was prudent to await further evidence supporting this expectation before lifting off from zero.\n\nMy own assessment is that with the economic progress we’ve made and that I expect to continue, the economy can handle an increase in the fed funds rate. In my view, if economic information continues to come in consistent with the outlook, then there will be a strong case that the conditions for liftoff have been met and it would be prudent for monetary policy to take a step back from the emergency measure of zero interest rates. A small increase in interest rates from zero is not tight monetary policy. And while I would expect some reaction in financial markets to the first move in interest rates in over six years, I wouldn’t expect financial conditions to tighten enough to affect the medium-term outlook.\n\nMore important for macroeconomic performance is the expected path of policy beyond liftoff because expectations about the future path of policy can affect today’s economic decisions. Decisions about the path will depend on incoming information on the economy’s performance, but according to the FOMC’s current assessment of the economic outlook, even after the first rate increase, monetary policy is expected to remain very accommodative for some time to come, with rates expected to move up only gradually to more normal levels.\n\nOf course, in the aftermath of the Great Recession there is some uncertainty about what that “normal” level of interest rates is. If the potential growth rate of the economy over the longer run has moved lower, as many economists estimate, that means the longer-run level of the fed funds rate consistent with price stability and maximum employment is also lower than it was in earlier periods. But estimates of long-run growth are imprecise and subject to revision, so this means there is considerable uncertainty around this neutral fed funds rate as well.\n\nOne benefit of a gradual approach to normalization is that it will allow us to recalibrate policy over time as some of the uncertainties surrounding the longer-term level of interest rates, the economy’s potential growth rate, and the longer-run unemployment rate are resolved. But uncertainty about the longer-run destination is not an argument to delay taking the first step. In fact, in my view, given the economic outlook, starting the process to normalize interest rates will help ensure that we can, indeed, take a gradual approach. Delay risks having to move rates up more steeply in order to promote attainment of our goals over time.\n\nAnother cost of postponing liftoff too long is the potential for building risks to financial stability stemming from excessive leverage or from investors taking on risks they are ill-equipped to manage in a search for yield. The FOMC continues to carefully monitor financial markets for signs of these types of emerging problems. However, we need to acknowledge that leading up to the financial crisis, some of the vulnerabilities of the financial system were not fully recognized by policymakers. Although we have made significant strides since then, there likely remain some gaps in our ability to assess the risks in every part of the financial system. The longer interest rates are maintained at zero in an economy that is getting back to normal, the higher the potential risk to financial stability. This potential cost is one that needs to be considered when determining appropriate policy.\n\nI believe the extraordinary monetary policy actions taken by the FOMC in response to the financial crisis and Great Recession were effective in easing monetary and financial conditions; they kept the Great Recession from turning into another Great Depression. I’d like to ensure that these actions remain a part of the monetary policymakers’ toolkit, available for use if such an unfortunate situation arises again in the future. But, ultimately, how history judges those extraordinary actions will depend on our demonstrating that there is a way out. The time to start that demonstration is quickly approaching.\n\nIn summary, the economy has made considerable progress over the expansion and my medium-run outlook is for above-trend growth, continued improvement in labor markets, and inflation gradually returning to our 2 percent target over the medium run. If incoming economic information continues to support this forecast, then in my view it will be time to take the first step in the policy normalization process. As I’m sure the learned audience at the City Club knows, Jean-Paul Sartre was a famous French philosopher and author. His play “No Exit” is a celebrated contribution to the existentialist literature; it should not be a guidebook for monetary policymakers."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "October 15, 2015",
        "title": "Long-Run Economic Growth",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer-Federal Reserve Bank of Cleveland - New York University Stern Center for Global Economy and Business - New York, NY - October 15, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20151015-long-run-economic-growth"
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "October 02, 2015",
        "title": "Comments on \"Microprudential Versus Macroprudential Supervision\" by Paul Tucker",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - 59th Economic Conference Macroprudential Monetary Policy - Federal Reserve Bank of Boston - Boston, MA - October 2, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20151002-comments-on-microprudential-versus-macroprudential-supervision",
        "content": "I thank President Rosengren and the Boston Fed for the opportunity to participate in this year’s economic conference. This conference series has been a source of valuable discussions and insights over many years, and I’m happy to note that this year’s conference marks number 59 in the series, a remarkable track record. I’m even happier to say that I, myself, haven’t yet reached that milestone – although it does remain a goal of mine!\n\nA discussant’s task is never an easy one. Sometimes it is difficult because of the simple fact that there just isn’t that much in the paper to talk about. Other times it is difficult because the paper is filled with so much interesting material that it inspires a plethora of new thoughts and ideas. In this case, Paul Tucker’s paper definitely falls into the latter camp. If you have not yet had the chance to read the paper, I encourage you to do so. And if you have read the paper, I encourage you to read it again, because more is revealed on each reading.\n\nIn my brief time this morning, I will be able to touch on only some of the important issues that Paul’s paper addresses. My main point is that the principles of sound monetary policymaking can be productively applied to financial stability policymaking. As always, the views I’ll present today are my own and not necessarily those of the Federal Reserve System or my colleagues on the Federal Open Market Committee.\n\nPaul was asked to address the larger question of whether the objective functions for microprudential supervision and macroprudential supervision differ, and if so, how any conflicts should be resolved. I agree with his conclusion that the two types of supervision need not be in conflict so long as they are situated within a well-designed financial stability framework, or what Paul calls a regime. I would take this a step further and suggest that micro- and macroprudential supervision should work together. As Paul acknowledges, building such a framework is not trivial. But it is the responsibility of public officials to do so, since the costs imposed on society for failing to do so are very large. The difficulty derives not only from the fact that the global financial system is very complex, which means a lot of intellectual ability needs to be brought to the problem, but also because the framework involves institutions. As underscored by the work of Nobel Prize winner Douglass North and others, institutions matter.1 And those institutions necessarily find themselves having to operate within a political economy that needs to be taken into account.\n\nOver the past 50 years, research and practice have increased our understanding of some basic principles that underlie an effective monetary policymaking framework. These include starting with well-articulated and achievable goals, designing features that foster a credible commitment to those goals, and incorporating a mechanism for holding accountable the institution responsible for promoting those goals. In my view, more systematic, less discretionary policymaking, transparency, and clear communication are important features of sound monetary policymaking. I believe that financial stability policymaking can benefit from these same principles and features.\n\nObjectives\n\nThe first principle of effective monetary policymaking is having a well-articulated objective that is achievable with the available tools. Paul starts there too. I particularly like that he articulates the goal of financial stability in terms of the resilience of the financial system. In the U.K., the Financial Services Act 2012 formally established the Financial Policy Committee (FPC) within the Bank of England and charged it to act “to remove or reduce, systemic risks with a view to protecting and enhancing the resilience of the U.K. financial system.”2 In contrast, the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010 doesn’t mention resilience, but U.S. policymakers might want to consider changing our rhetoric from financial stability to financial resilience. “Stability” gives the impression of being static. But the economy and financial markets are dynamic; they will be hit by shocks and they will respond to those shocks. There will be ups and downs. The goal should not be to thwart all volatility in markets, but rather to limit tail risks. We need to be thinking in terms of the resilience of the financial system to those shocks. As Paul says, “The system must be sufficiently resilient to continue providing the core financial services of payments, credit, and insurance in the face of big shocks.” Another way we might think about the objective is that it chooses a maximum tolerable expected loss from a financial crisis, where the expected loss reflects both the probability of a financial crisis and the cost imposed on the rest of the economy when a crisis-sized shock hits the financial system. Different prudential tools will work on one and/or the other of these two components.\n\nLet me set aside an important issue that Paul addresses in his paper, namely, who should set the resilience standard. Regardless of where that responsibility lies, it is important that the objective be articulated so that the public and its elected representatives understand that there are tradeoffs. Financial systems are able to provide valuable credit, risk-management, and liquidity services to businesses and households because they comprise institutions designed to take on risk and leverage. Even with an optimally designed financial resilience regime, there could be a tradeoff between the average level of economic growth over the longer run and the desired degree of resilience, because risk-taking and risk management are at the heart of the financial system. Indeed, in the U.K., the Financial Services Act recognizes this potential tradeoff and indicates that the act does not authorize the FPC to act in a way that the committee feels is “likely to have a significant adverse effect on the capacity of the financial sector to contribute to the growth of the U.K. economy in the medium or long term.”3\n\nToo high a resilience standard will thwart risk-taking and innovation, which will undermine longer-run economic growth.4 In setting the standard, we need to come to some common understanding about the amount of growth and prosperity we are willing to give up in order to lower the risk to financial stability. In the U.S., people who are 80 years old have lived through two major financial crises (the Depression and the 2008-2009 financial crisis and Great Recession). Is that too many? Would we rather lower the probability of such an event to one every 1,000 years? What would we be willing to give up to do that?\n\nOf course, there may be things we can do to improve the framework that will lower the risk to financial stability without much cost in terms of longer-run growth. If we think of there being a frontier relating the risk to financial stability to the economic return that a well-functioning financial system can provide, then it isn’t hard to imagine that we were operating at a point well off that frontier in the run-up to the crisis, and that improvements in the financial resilience regime could move us onto the frontier without sacrificing growth. However, once we reach that point, we’ll have to make a choice about how much growth we are willing to give up in good times to limit the likelihood of a future financial crisis.\n\nRegardless of which institution chooses the standard of resilience, and therefore the tradeoff between economic growth and the level of systemic risk, the standard will need to be well communicated to get political and public buy-in. That’s going to be a difficult task if you happen to be someone living during the once-in-a-thousand years event, how comforting is it to know that that was a design choice?\n\nSystematic Financial Stability Policymaking and Incentives\n\nNow let’s turn to some of the features that should be included in the regime set up to meet the resilience standard. Paul suggests that one of the key components of a well-designed financial stability regime is dynamic macroprudential policy that is applied systematically. I agree that a systematic approach will be beneficial to financial stability policymaking, just as it is to monetary policymaking.\n\nThe benefit of taking a systematic approach to monetary policy is well established. When monetary policymakers respond in a systematic fashion to incoming information, the public will have a better sense of how policymakers are likely to react to economic developments whether those developments are anticipated or unanticipated so their policy expectations will better align with those of policymakers. This alignment helps households, firms, and financial market participants make better saving, borrowing, investment, employment, and transaction decisions, thereby making monetary policy more effective.\n\nAn additional benefit of a systematic approach is that it provides a mechanism through which policymakers can commit to policies aimed at promoting policy goals over the longer run. That is, being systematic can help alleviate time-inconsistency problems. Note that by systematic policy I do not necessarily mean that monetary policy be set mechanically by a policy rule. Nor do I require the policymaker to be prescient about the shocks that will hit the economy if these were predictable, they would not be “shocks.”\n\nBeing systematic about financial stability policy is perhaps even more important than in the case of monetary policy because of the important role played by incentives those of both private actors and regulators and asymmetric information. The crisis shined a bright light on significant moral hazard problems that exist in financial markets. A financial stability policymaker that is systematic in how it applies its tools to promote attainment of the resilience standard will likely help tame some of the moral hazard problems. For example, systematically applying the resilience standard across the entire financial services landscape will limit regulatory arbitrage one of the unintended consequences of regulating just a portion of the financial system. Applying the resilience standard to all parts of the financial system, while allowing the type of supervision to appropriately vary by the nature of the systemic risk associated with each part, is one component of Paul’s financial stability regime.\n\nRegulators themselves are also subject to incentive problems. Ed Kane, a professor at Boston College, has written extensively on this subject.5 Misaligned incentives need not stem from regulatory capture, which has received some recent attention. Time-inconsistency problems could lead regulators to favor the short run over the long run. Adherence to a systematic approach in applying financial stability policy tools could serve as a commitment device for regulators to focus on long-run goals, but it’s important to have the right tools in order to align regulatory incentives. An important tool in this regard is financial institution resolution. Although, as Paul points out, an improved resolution method for large, complex financial institutions is not a panacea, in my view it is a large positive step. The lack of a credible resolution method meant that during the crisis, in the face of serious distress at a large financial firm, governments faced a dilemma: either rescue the firm and create future moral hazard problems or let the firm fail and risk causing a cascade of other failures. The fact that policymakers had to make these decisions in the heat of the moment using their best judgment based on limited information didn’t help. Without a credible resolution method, it is reasonable to expect that even well-intentioned policymakers will be biased toward bailouts. A resolution method that can be applied systematically can help alleviate this problem.\n\nTransparency, Clear Communication, Independence, and Simplification\n\nA second hallmark of effective monetary policymaking is transparency and clear communication. Of course, clear communication is not without challenges. In the late 1980s and 1990s, the public had a pretty good sense of how the FOMC’s policy would respond to economic developments because after the great inflation of the 1970s, the FOMC became more predictable and systematic in how it reacted to changes in economic activity and inflation.6 The Great Recession required the Fed to behave in a way quite distinct from its past behavior, so the public’s understanding about how policymakers are likely to react to incoming economic information needs to be reestablished.\n\nIn addition to policy effectiveness, transparency in monetary policy is necessary so that the public and elected officials have the ability to hold policymakers accountable for their decisions. The Fed, like many other central banks, has been given independence in setting monetary policy, and this independence has been well documented as yielding more effective policy and better economic outcomes. But accountability must go hand-in-hand with independence. A central bank cannot expect to remain independent from the political process unless it is transparent about the basis for its policy decisions.\n\nA parallel can be drawn with financial stability policy. In the aftermath of the financial crisis, the framework and tools of financial stability policy are still being developed. It will take considerable effort on the part of the financial stability policymaker to explain the tools it will be using and the rationale for its policy decisions. This is likely to be even more challenging than it is for monetary policy because the financial system is complex, with various types of institutions and multiple regulators. In addition, regulators are likely to have more private information on which to base their policy decisions, making it more difficult for the public and elected officials to assess whether the decisions are appropriate ones. Here, I am in full agreement with Paul that while there are some arguments for keeping prudential supervisory information private, I think financial stability policymakers should strive for greater transparency and more disclosure. Similarly, they should require more disclosure from financial firms so that creditors and other market participants can exert market discipline.\n\nThere are good arguments for giving financial stability policymakers a large degree of independence from the political process. If effective monetary policy means taking away the punch bowl just as the party gets going, then effective financial stability policy might mean taking away the punch bowl before the guests have even arrived because the risks to financial stability build up over time and action likely needs to be taken earlier in order to be effective. Contributing to the need for early action is the challenge of having to coordinate policy action across multiple regulatory bodies. If the need for monetary policy to be forward looking is a difficult concept for the public to grasp, the need for financial stability policy to act well before there are clear signs of instability may be even more difficult to explain. In thinking about the design of the financial stability regime, it might behoove policymakers to consider whether it would be better for central banks to keep their monetary policy and financial stability policy discussions separate so as to avoid jeopardizing the independence of monetary policy. Note, however, that in a situation in which financial stability risks are high and growing, the blurring of the line between financial stability goals and monetary policy goals would be high: if we assessed the risks to financial stability to be sufficiently great, achieving our monetary policy goals would be in jeopardy as well.\n\nAnother aspect of regulatory policy that likely makes it hard to explain and hard to monitor is its complexity. Andrew Haldane and Vasileios Madouros have argued that the complexity of the financial landscape does not call for a complex financial regulatory structure, but just the opposite.7 In my view, a sometimes overlooked lesson from the crisis is that regulatory complexity can complicate supervision, risk monitoring, compliance, and enforcement. Given the scope and ever-changing nature of the financial system, regulatory complexity is, to a certain extent, unavoidable. But the tradeoffs should be recognized. For example, it is reasonable to require higher levels of capital to be held against higher-risk assets, but a system of risk weights that is overly granular and complex would be counterproductive. In practice, too much complexity would make it harder for regulators to assess compliance and to determine whether institutions were engaging in some practices merely as a way to hide risk and lower their capital requirements. If regulators have made the rules so complex that they cannot assess compliance, then in practice there are no consequences for firms that fail to meet the standards. Complexity also makes it difficult to monitor the monitors.\n\nBecause the world is very complex, our models are simplifications with many embedded assumptions. A policy that is optimal in one model need not be optimal in another, yet we don’t know which model is the correct representation of the world. Here, we might take another lesson from monetary policy in which a research agenda has documented some of the benefits of policy rules that are robust across various models. Some recent work in economic theory has also shown that simple dynamic contracts can perform approximately as well as optimal contracts, independent of the underlying process for returns.8 Although more work would need to be done, this suggests it is worth exploring whether we would be better off with a much simpler macro- and microprudential supervisory structure that is easier to implement and simpler to govern, one that is approximately right across various models and states of the world even if it is never optimal in any particular model or state.\n\nConclusion\n\nIn his presidential address to the American Finance Association earlier this year, Luigi Zingales asked an important question: “Does finance benefit society?” He pointed out the dissonance between the view of academics, who typically say “yes,” and that of the average American, who is much less certain.9 Luigi argues that academia has an important role to play in ensuring that finance will benefit society. I agree. Academic research can help detect those aspects of financial system design and practices that are beneficial to society and those that are harmful. But major responsibility lies with financial system policymakers, supervisors, and regulators to create a system that is seen by the American public as being beneficial and that truly is. I thank Paul for providing many thoughtful ideas in support of this endeavor."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "July 15, 2015",
        "title": "The Economic Outlook and Monetary Policy: Timing Isn’t Everything",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - The Columbus Metropolitan Club - The Economic Outlook and Monetary Policy: Timing Isn’t Everything",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20150715-the-economic-outlook-and-monetary-policy-timing-is-not-everything",
        "content": "Good afternoon. I thank the Columbus Metropolitan Club for the opportunity to speak with so many of Ohio’s business leaders. I see several Cleveland Fed directors in the audience. I want to thank them and all the attendees for taking time out of your busy schedules to be here today. As the president of the Federal Reserve Bank of Cleveland, I place a high premium on the information I gather from business people like you who are willing to share what you are seeing as you navigate through the ebbs and flows of economic waters. Your insights are enormously helpful to me as I formulate my views on the economy, views that I express when I go to Washington to participate in meetings of the Federal Open Market Committee (FOMC), the body within the Fed that sets monetary policy for the nation. More than 100 years ago, Congress designed the Federal Reserve as a decentralized central bank, with 12 Reserve Banks across the country, overseen by the Board of Governors in Washington. The Federal Reserve System’s structure helps ensure that Main Street perspectives are considered around the FOMC table. It is a true strength of the System, and one worth preserving.\n\nBefore we move on to the question and answer part of today’s program, I would like to open with a brief discussion of my economic outlook and monetary policy. As always, the views I’ll present are my own and not necessarily those of the Federal Reserve System or my colleagues on the Federal Open Market Committee.\n\nThe Economic Outlook\n\nIt has now been over six years since the official start of the economic expansion. Supported by extraordinary monetary policy accommodation, the U.S. economy has made significant progress since the darkest days of the global financial crisis and Great Recession. Underlying economic fundamentals have strengthened, resulting in an economy that has been able to sustain growth at a moderate pace over the past five years.\n\nWe began 2015 with a slowdown in output growth. Much of this year’s slowdown reflected temporary factors, including the harsh winter weather and the labor disputes at ports on the West Coast. Measurement issues also likely played a role. For the past six years or so, output has tended to grow less in the first quarter than in other quarters, and government statisticians are taking steps to improve the methods used to seasonally adjust the numbers.\n\nThe recent monthly economic data, as well as information gleaned from my business contacts, suggest we are seeing a rebound in spending in the second quarter. Although yesterday’s report on retail sales in June was weaker than analysts expected, it came after strong May sales. Consumer spending, which represents about two-thirds of output, picked up in the second quarter, supported by growth in personal income and continued improvement in household balance sheets. Based on projections from the U.S. Energy Information Administration, the drop in gasoline prices is estimated to be saving the average household about $700 this year. Perhaps not surprisingly, consumer sentiment is very good, at levels not seen since before the financial crisis and Great Recession.\n\nBusiness sentiment also remains solid, but industrial activity has been weak in recent months. The drop in oil prices compared to a year ago has led to reduced investment and some dislocation in parts of the domestic energy sector, and this is affecting growth in certain regions of the country, including parts of eastern Ohio. But the U.S. is still a net importer of oil, and so the benefits of lower energy prices in terms of consumer, business, and local government spending will ultimately result in a net positive for the U.S. economy.\n\nAnother factor weighing on firms exposed to international trade is the appreciation in the value of the U.S. dollar since last summer. A stronger dollar means better terms of trade for U.S. consumers and businesses, which is a positive for a growing economy in the longer run. But in the near term, dollar appreciation is putting a drag on U.S. export growth. The recent stabilization in energy prices and slowdown in dollar appreciation mean that both drags should lessen over time.\n\nOn balance, I expect that after a weak first quarter, growth will pick up to an above-trend pace over the rest of this year and next, in the 2.75 to 3 percent range. I want to acknowledge there are risks around this forecast. I’ve incorporated a slowing in the pace of growth abroad, including China, but the magnitude of the slowdown remains uncertain. I’m also assuming that the situation in Greece will have a limited impact on the U.S. economy because our direct exposure via trade and banking is limited, Greek debt is held mainly by the public sector rather than private-sector investors, and the European Central Bank has tools to contain spillovers to broader financial markets. The Greek situation remains unresolved, but we had some positive news earlier this week and the risk of a very bad outcome with sizable effects on the global economy is not high enough to change my modal outlook for the U.S. economy of moderate above-trend growth, which will support continued positive developments in labor markets.\n\nOver the past year, the economy has created an average of 245,000 jobs per month, and nonfarm payrolls are now 3-1/2 million above their previous peak before the recession. The unemployment rate is 5.3 percent, down sharply from its peak of 10 percent in 2009, and down three-quarters of a percentage point over the past year. A broad array of other labor market indicators have improved significantly over the past few years, including the long-term unemployment rate and the unemployment rate that includes discouraged workers and part-time workers who would rather work full-time. In addition, we are now beginning to see signs that wage growth is picking up. Year-over-year gains in the Employment Cost Index, a comprehensive measure of wages and benefits, rose from under 2 percent in the first quarter of last year to over 2-1/2 percent in the first quarter of this year. The delay in wage growth shouldn’t be a surprise. Typically, wages tend to accelerate only after we’ve seen sustained improvements in the labor market. Some analysis we’ve done at the Cleveland Fed shows that in the last three expansions, job gains in industries that pay above-average hourly earnings contributed more to total private-sector job gains as the expansions continued on.1\n\nIn my view, the totality of evidence suggests that the economy is at or nearly at the Fed’s mandated monetary policy goal of maximum employment. This isn’t to say that there aren’t longer-term challenges facing the labor market. Workforce development is a key issue. As a country, we want to ensure that people can enter and remain productive members of the labor force, to raise our standards of living and to make us more competitive in the global economy. However, monetary policy is not the tool for addressing this important issue. It is better served by policies focused on strengthening and increasing access to education and training.\n\nHere in Ohio, we have also seen improvements in labor markets since the recession, but there are longer-run challenges as well. The state’s unemployment rate has fallen sharply, from a peak of 11 percent in December 2009 to 5.2 percent in May, which is half of a percentage point lower than a year ago. Firms have been adding jobs. It is true that the pace of job growth in Ohio is slower than in the nation. Over the past year, jobs have been growing somewhat less than 1-1/2 percent in Ohio, compared to over 2 percent in the U.S. as a whole. And while U.S. employment is now 2-1/2 percent higher than its pre-recession peak, employment in Ohio has not quite reached that milestone.\n\nHow should we interpret this performance? It helps to put this into context. First, the pace of job growth in the state is now well above the pace we saw during the last expansion, when employment in Ohio was flat. Second, job growth in the state has been slower than the national pace since the mid-1990s – this is not a new phenomenon related to the Great Recession. It partly reflects slower population growth in Ohio and Ohio’s higher share of jobs in manufacturing, a sector that has been experiencing a long-run decline in employment. Manufacturing accounts for about 15 percent of private-sector jobs in Ohio, compared to about 10 percent in the U.S. Those shares are down about 7 percentage points since the mid-1990s.\n\nWithin this bigger context, we can characterize the improvement in Ohio labor markets over this expansion as being pretty good but, at the same time, recognize that there are longer-run challenges as manufacturing continues to transform itself into a sector with higher-productivity production processes requiring higher-skilled workers.\n\nThe Columbus metro area is generally faring better than other regions in the state. As you know, Columbus benefits greatly from a highly educated workforce and a diversified industry base. This has contributed to broader gains in employment across multiple sectors in the Columbus area and puts the Columbus economy in a stronger position for sustainable growth.\n\nIn addition to maximum employment, the other part of the Fed’s dual mandate is price stability. Inflation has been below the Fed’s 2 percent goal for some time. Headline inflation has been running at about a quarter percent so far this year (as measured by the year-over-year percentage change in the price index for personal consumption expenditures). Excluding food and energy prices, which tend to be volatile, so-called core inflation has been running about 1-1/4 percent. Low inflation partly reflects the sharp drop in energy prices, as well as the appreciation of the dollar, which makes non-petroleum imports cheaper in the U.S. These downward pressures are starting to wane as oil prices and the value of the dollar have started to stabilize. Would I like to see higher inflation numbers? The answer is yes. Am I reasonably confident that inflation will move gradually back to the Fed’s 2 percent objective over time? The answer is also yes. Supporting this view are above-trend economic growth, continued positive developments in labor markets, and the stability in measures of inflation expectations and some of the alternative measures of inflation, like the Cleveland Fed’s median CPI and the Dallas Fed’s trimmed mean PCE inflation. Of course, my economic outlook is dependent on appropriate monetary policy, so let me turn to that now.\n\nMonetary Policy: Timing Isn’t Everything\n\nAs the FOMC has said, in determining the appropriate path of monetary policy, we assess both realized and expected progress toward our dual mandate goals of maximum employment and 2 percent inflation. So policy is not on a pre-set course; it depends on our read of what incoming data and economic information mean for our economic outlook and the risks around that outlook.\n\nIt is well accepted that monetary policy needs to be forward looking. Because monetary policy affects the economy with a lag, rates will need to begin to move up from their very low level before we have fully reached our goals. Moreover, with rates having been at zero for a sustained period, there is the potential for increased risks to financial stability from excessive leverage or from investors taking on risks they are ill-equipped to manage in a search for yield. The FOMC continues to carefully monitor financial markets for signs of these types of emerging problems, and so far so good.\n\nThe FOMC anticipates that two criteria need to be satisfied before it will be appropriate to raise the federal funds rate: further improvement in the labor market and reasonable confidence that inflation will move back to its 2 percent objective over the medium term.\n\nAccording to the FOMC’s June economic projections, 15 of 17 participants anticipate that it will be appropriate to begin to move interest rates up sometime this year. My own assessment is that the economy can handle an increase in the fed funds rate. A small increase in interest rates from zero is not tight monetary policy, and with the economic progress we’ve made and that I expect to continue, monetary policy can take a step back from the emergency measure of zero interest rates.\n\nBut I understand that others might like to see more confirming evidence before commencing a rate increase. My colleagues and I on the FOMC are all committed to promoting our dual mandate goals of price stability and maximum employment, but we may have different views about realized and anticipated progress toward those goals and about the potential costs and benefits to changes in policy with respect to achieving those goals.\n\nWhile financial market participants are particularly focused on the timing of the first rate increase, when it comes to monetary policy, timing isn’t everything. The FOMC meets eight times a year, and the difference in lifting off from a zero interest rate a meeting or two earlier or later is not significant. More important for macroeconomic performance is the expected path of policy beyond liftoff because expectations about the future path of policy can affect today’s economic decisions. According to the FOMC’s current assessment, even after the first rate increase, monetary policy is expected to remain very accommodative for some time to come, with rates expected to move up only gradually to more normal levels and with the decisions about that path depending on incoming information on the economy’s performance. One benefit of the gradual approach is that it will allow us to recalibrate policy over time as some of the uncertainties surrounding the underlying economy in the post-crisis world, like the potential growth rate, are resolved.\n\nJust like the timing of liftoff, the path of policy after liftoff will depend on how economic developments unfold. There is always uncertainty around projections of growth, unemployment, and inflation. If incoming economic information materially changes our outlook, we will adjust the funds rate up or down, as appropriate. But while our policy path is not pre-determined because the future is not pre-determined, one thing is certain: the Federal Reserve is committed to setting monetary policy to promote our congressionally mandated goals of maximum employment and stable prices."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "June 19, 2015",
        "title": "Community Development and Human Capital",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - 2015 Policy Summit on Housing, Human Capital, and Inequality - Sponsored by the FRBs of Cleveland, Philadelphia, and Richmond - Pittsburgh, PA",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20150619-community-development-and-human-capital",
        "content": "Good afternoon. It is an honor to be the closing speaker at this year’s Policy Summit. For almost 15 years, the Policy Summit has provided an important forum for collaboration between researchers and community development practitioners. Although researchers and practitioners bring different perspectives, they share a common goal: to strengthen communities by improving the opportunities for all people to productively engage in our economy. Research informed by the people who are actually on the ground, working in communities and running the programs, can help identify which strategies, programs, and policies are likely to be most effective. I hope that over the past two days, you’ve had the opportunity to meet someone who has brought a different perspective to the table, whether you are an economist, a nonprofit leader, a policymaker, or someone who puts policy into practice. I know I have and I thank you all for being here and for the effort and dedication to the important work you do.\n\nI also want to thank Paul Kaboth, Theresa Singleton, and Sandy Tormoen, the Community Development officers at, respectively, the Federal Reserve Banks of Cleveland, Philadelphia, and Richmond, as well as their staffs, for putting together such an interesting program. This Policy Summit is just one of the important ways in which the Federal Reserve Banks work together on behalf of the public. The 12 Reserve Banks are part of the Federal Reserve System, which was established by Congress more than 100 years ago. We like to say that the Federal Reserve is a decentralized central bank, which is independent within the government but not independent from the government. The structure is one of balance. Congress designed the Federal Reserve System to alleviate concerns that the central bank would become dominated by financial interests in New York or political interests in Washington. The Fed’s decentralized structure helps ensure that policy decisions take into account a diversity of information and views, reflecting our roots on Main Streets and communities across the country.\n\nAs the closing speaker, perhaps my greatest responsibility is to keep my remarks relatively short. Unfortunately, I am not going to meet that goal today because I want to take the opportunity to discuss the important role human capital plays in driving the economic outcomes of individuals and communities. As always, the views I’ll present are my own and not necessarily those of the Federal Reserve System or my colleagues on the Federal Open Market Committee.\n\nCommunity Development Work at the Fed\n\nThe Federal Reserve has had an interest in community development issues for a long time. In 1977, Congress passed the Community Reinvestment Act (CRA) to help address concerns about the deterioration in low- and moderate-income neighborhoods throughout the U.S. Many people blamed urban decline on limited credit availability and illegal practices such as redlining.\n\nThe CRA reaffirmed that insured depository institutions must serve the communities in which they are chartered to do business, helping to ensure equitable access to credit for all individuals and neighborhoods.1 The Federal Reserve and other federal financial supervisory agencies were charged with implementing the act. In 1981, the Fed created its Community Affairs function to provide technical training and support to depository institutions to help bolster compliance with the CRA.\n\nFrom this targeted beginning, the Federal Reserve’s work in the area of community development has evolved and expanded, much as the nature of community development in general has changed over time. As people in this room know, access to credit is but one factor – albeit an important one – in determining the economic vitality of households and neighborhoods. A glance at the agenda for this Policy Summit conveys the wide range of interconnected issues that community development now encompasses, from health and transportation policy, to housing and education policy, to workforce development. While the focus may have changed over time, one thing that hasn’t changed is the Federal Reserve’s commitment to helping to identify effective policies and best practices for promoting economic progress in low- and moderate-income neighborhoods. In addition to its research, the Fed plays an important role as a “convener.” Bringing together people to share their different perspectives and experiences can ultimately lead to more effective economic policies. I have spoken elsewhere about how the diversity of views expressed around the FOMC table helps the Fed make better monetary policy. I believe the same is true for public policies aimed at addressing the challenges faced in community development.\n\nWe can all be pleased that the economy has greatly improved since the depths of the Great Recession. Employment is up and unemployment rates are down. But not all households or communities have experienced the same amount of improvement; some of the challenges are long-standing ones that the recent recession and slow recovery exacerbated. According to a 2014 Federal Reserve survey of economic well-being, 65 percent of respondents reported that their families are either “doing okay” or “living comfortably” financially. Yet economic challenges persist for sizable parts of the population.2 Forty-seven percent of respondents said they could not cover a $400 emergency expense using cash or its functional equivalent or would have to sell something or borrow to cover it. Just under a quarter of respondents said they or a household family member had experienced some type of financial hardship in the previous year. And, not surprisingly, feelings about economic well-being vary with household income. For lower-income households, those making less than $40,000 per year and who make up about one-third of the respondents, more than half reported they are finding it difficult to get by or are just getting by financially.\n\nI am sure it is not news to you, community development professionals, that problems linger and effective solutions remain elusive. However, one thing is clear: human capital – education and skills that make people more productive and able to contribute to the economy – is one of the fundamental factors that determine economic outcomes of communities and individuals.\n\nThe Value of Human Capital\n\nMany studies have documented the importance to economic well-being of investments in human capital. For example, Cleveland Fed researchers found that over a 75-year-period, education levels were consistently one of the most reliable indicators for each state’s per capita income growth3 and that counties with higher levels of high school graduates tend to have lower poverty rates and higher levels of labor force participation.4 A study by a Philadelphia Fed researcher found that resilient regions, that is, regions that have been able to avoid persistent declines in population over the long run, tend to have a more educated population and a more diverse industry mix.5\n\nThe benefits of investing in human capital are also evident at the individual level. Better education is correlated with higher wages and lower levels of unemployment. For example, the current unemployment rate for those with a college degree is 2.6 percent, compared to 5.4 percent for those with a high school diploma, and 8.0 percent for those who didn’t graduate from high school. The difference in wages between those with a college degree and those without, the so-called skill premium, has widened substantially over time, more than doubling since the 1970s. Median hourly wages for those with a bachelor’s degree are now about 80 percent higher than for high school graduates.6 And over a lifetime, in present value terms, a college graduate can expect to earn nearly twice as much as a high school graduate.7 Other research shows that the skill premium has grown even more for those with a post-graduate degree, even controlling for changing demographics. Those with a graduate degree now earn about 30 percent more than those with a four-year college degree.8\n\nThe rising skill premium since the 1970s reflects the fact that over much of the period, real wages (that is, wages adjusted for inflation) rose for skilled workers while they fell for unskilled workers. Several factors could have led to the rising trend in the skill premium. Globalization, which has led to increased trade between the U.S. and countries with lower-skill, lower-wage workers, is one possible explanation. Demand from the U.S. for the products produced by lower-wage workers abroad would put downward pressure on the wages of lower-skill workers producing similar goods in the U.S. And demand from abroad for goods produced by high-skill workers in the U.S. would put upward pressure on their wages. While this is an interesting theory, there is not much empirical support for trade being a major driver of the skill premium.9\n\nInstead, there appears to be considerably more evidence that technological change has increased the demand for skilled workers relative to unskilled workers. This is consistent with the fact that even industries often viewed as less skill-intensive have increased their demand for skilled labor. The manufacturing plant of the 1970s has transformed itself into a high-tech operation, requiring workers who can operate computerized machinery and even robots.\n\nThe idea that the rising skill premium is driven by technological change also seems consistent with research showing that mathematical achievement is a fairly good predictor of future earnings.10 As discussed in a recent Cleveland Fed Economic Commentary, even among high school dropouts, those who completed geometry or algebra II earn about $1.50 more per hour in the workforce than those who completed fewer math courses. Math attainment in high school also helps predict admission to and success in college. Some Cleveland Fed economists help run a Math Corps program at Cleveland State University. This program for middle and high school students aims to build confidence and mastery in young people’s mathematical abilities. It appears to be working, as Math Corps students are more likely to score higher on standardized tests and more likely to graduate from high school than their peers.11\n\nA refinement of the idea that technological change has driven the widening skill premium is the polarization hypothesis.12 Data suggest that since 2000, jobs have become “polarized,” meaning that while high-skill and low-skill occupations have seen job growth, medium-skill occupations have experienced job losses. Some jobs involve work that is very routinized, work that involves repeated actions and set rules. Other jobs involve work that is less routine, requiring flexibility. Another dimension along which jobs vary is the extent to which they require cognitive skills versus physical skills. Computers can handle tasks usually found in routinized cognitive jobs, e.g., bookkeeping and other clerical tasks. Computers are less suited to replace workers in occupations that require abstract thinking, high levels of cognition, and higher levels of education. But they are also less able to take on non-routine manual work. Academic and Federal Reserve labor-market researchers have found that since 2000, there has been a decline in employment in the routine cognitive and routine manual job categories – jobs that are considered medium-skill jobs – compared to job gains in non-routine cognitive and non-routine manual occupations – high-skill and low-skill jobs, respectively.13 This shift in the distribution of jobs helps to explain the wider gap in wages for highly skilled vs. lower skilled workers, and the increasing return to gaining the education required to obtain those skills.\n\nThe increase in the return to education over the past 35 years has spurred more people to get their degrees – for example, the percent of the U.S. labor force that is college-educated has more than doubled since the 1970s. But because demand for these higher-skill workers continues to grow, the skill premium has continued to rise even as the supply of skilled workers has risen.14\n\nWhile much of the research has focused on college vs. high school, this partly reflects the availability of data. Some of the skills required to meet the demand of jobs in today’s economy can be acquired in settings other than four-year colleges. Also note that some of the cognitive skills needed are not necessarily acquired by studying only math and science. The critical thinking and judgment acquired by studying the social sciences and humanities is very valuable in the modern workplace. And, of course, not every high school graduate earns less than the average college graduate – wages vary quite a bit within an educational level. Indeed, recent research by Cleveland Fed staff shows that across 100 metro areas in the nation, the top 30 percent of earners aged 18-35 without a college degree earned more than a quarter of the workers in this age group who have a bachelor’s degree.15\n\nStill, the earnings prospects of less-educated workers seem to depend on subsequent training and also on location. The locational aspect is being investigated in forthcoming research led by the Philadelphia Fed in collaboration with the Cleveland and Atlanta Feds. Other researchers have provided evidence that less-educated workers benefit in the form of higher wages from working in areas populated with more-educated workers. Such knowledge spillovers mean that the return to communities from education can be higher than the return any one person gains by becoming more educated.16 Evidence of human capital spillovers is also provided by another study that finds that cities with more highly educated populations experience lower unemployment rates, higher productivity growth, and higher growth in entrepreneurship than what would have been predicted by considering only individuals’ educational levels.17 Thus, education appears to be a valuable investment not only for the individual but also for the communities in which people live.\n\nEducational Attainment\n\nIt is important to note that the statistics I’ve quoted on the skill premium and the social return to education are based on people who actually obtain their degrees. While enrollments in college are near historic highs, non-completion rates are also quite high. According to data from the National Center for Education Statistics, only about 55 percent of students who start college earn bachelor’s degrees within five years.18\n\nSeveral factors are likely at play. First, some people aren’t prepared for college when they enter. Research is increasingly pointing to the fact that the foundation has to be laid very early in life – at the pre-school level. When children fall behind early on, it is often difficult to catch up.19 Research is also shedding light on which type of early childhood education programs work and the ways in which they can affect economic outcomes later in life. One study found that a main way in which the influential Perry Preschool Program, which predates Head Start, affected longer-run outcomes was by affecting the social skills of the participants, e.g., lowering aggressive and anti-social behaviors.20 Home environment also matters. Research by a Cleveland Fed economist shows that home environment, as measured by the number of books at home, has a significant impact on achievement in elementary school.21\n\nA second factor affecting college enrollment and completion rates is that college has become increasingly expensive over time. The average cost of tuition and fees at four-year institutions is now over $14,000 a year, and has more than doubled since 2000.22 Subsidies for higher education fell during the Great Recession, shifting costs to students. According to data compiled by the New York Fed, more people are borrowing to go to school: The share of 25 year olds with student debt rose from 27 percent in 2004 to about 45 percent in 2013. And the average debt per borrower has increased from about $15,000 in 2004 to $27,000 in 2014.23 Some students do not have the financial wherewithal to start or to complete their degrees. According to the Fed survey of economic well-being that I mentioned earlier, of those respondents who didn’t attend or complete college, 30 percent reported that they didn’t attend college because it was too expensive, while 24 percent of those who started college said they didn’t complete their degree for this reason. In some cases, family obligations take precedence over education. Forty-three percent of women and 32 percent of men said they didn’t finish because of family obligations. This gender gap was even larger among younger respondents.24\n\nA third factor affecting enrollment and completion rates is that some people may have a personal preference to enter the workforce after high school rather than to go to college. But that choice might really reflect a person’s view that he or she is unprepared to succeed in college or that the return to a college education does not justify the tuition expense or the burden of student loan debt. In other words, while, on average, the return to investing in education is positive, for some individuals it is not, especially if they have to take on high levels of debt. Research by the Richmond Fed, which models college choice, illustrates that uncertainty about whether you’ll complete college or whether you’ll get a good-paying job after graduating will offset some of the positive effects of a rising skill premium on your decision to enroll in college. The effect of uncertainty is larger for lower-income people who need to borrow to go to college, since they’ll need to earn more post-college to make the investment pay off.25\n\nThis work, as well as the other research on educational attainment, suggests to me that college enrollments and completion rates could be increased by programs that help prepare students to enter college and programs that help ensure that financial support is available to students who have the desire and qualifications to earn a college degree. Student loan programs should encourage students to choose colleges or other types of educational programs that maximize the return on the student’s investment in human capital.\n\nPeople who prefer not to attend college will also have to build their human capital to be productive members of the modern workforce. Apprenticeships, certificate programs, and on-the-job training can all potentially play an important role. The U.S. spends a significant amount of money on education. In 2011, total spending on public primary and secondary education was over $600 billion, more than $12,000 per public-school student.26 That same year, private industry spent more than $156 billion on employee learning and development programs.27 But at a time when funding is scarce and the needs are plentiful, rigorous evaluation of the effectiveness of educational and training programs is needed, and there is an active research agenda in this area. I’d like to conclude my remarks with a few examples of such efforts.\n\nSome Examples of Program Evaluation Efforts\n\nIt is impossible to evaluate the effectiveness of a program without the data to do it. In Maryland, the Jacob France Institute at the University of Baltimore keeps a repository of wage and labor market data to track program participants over several years and to coordinate with on-the-ground agencies in designing longer-run programs.28 Similar centers around the country are collecting information as part of new federal workforce investment rules. Data collection and program evaluation are important aspects of the U.S. Department of Education’s Promise Neighborhoods program, which aims to improve the educational outcomes of children in distressed neighborhoods by improving the neighborhoods themselves.\n\nIn addition to data collection efforts, there is ongoing work to identify the most effective programs for hard-to-employ individuals. A Cleveland-based organization, Towards Employment, is leading NEO WorkAdvance, a collaborative effort of more than 13 Northeast Ohio workforce and economic development organizations that are partnering with employers to identify hiring and training needs in manufacturing and health care, two industries significant in the Northeast Ohio region.29 The program is designed to rigorously evaluate what helps unemployed and low-wage working adults succeed in the workplace in general and, in particular, in these two sectors.\n\nOther work is also underway to evaluate job training programs focused on particular industrial sectors. One Cincinnati agency, Partners for a Competitive Workforce, is a leader in tracking its results and sharing information with researchers.30 Research could help identify whether certain sectors, like health care or high-tech manufacturing where qualified workers are in short supply, are more amenable to these kinds of programs or whether such programs can be replicated across multiple industries. Such knowledge could help inform policies that provide incentives to industry to develop meaningful training programs for both new and continuing employees.\n\nAs I mentioned earlier, some of the early childhood education research suggests that the future success of disadvantaged individuals can be improved by strengthening their social skills. Studies are underway to examine the role of characteristics like persistence and other personality traits as they relate to labor market outcomes,31 and the Commonwealth of Kentucky is using the ACT WorkKeys test, which attempts to measure these “soft skills,” as part of its evaluation metrics for qualifying certain communities as having the infrastructure and workforce sought by employers. By their very nature, soft skills are difficult to measure, but furthering our understanding of the extent to which these types of skills improve future success and the ways in which they might be taught may help people successfully enter and remain in the workforce.\n\nThese are but a few examples of agencies undertaking initiatives to critically evaluate educational and workforce development programs. Improving our knowledge about which programs are effective and what makes them so will help ensure that we design the best programs to help the most people and that our investment in these programs is money well spent. This Policy Summit and other similar conferences have an important role to play by bringing together the program designers, community development practitioners, and researchers who will lead the way in developing effective methods to raise the human capital levels in our nation. I encourage you all to keep working toward this very important goal."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "May 25, 2015",
        "title": "Post-Crisis Financial System Regulation and Its Research Foundation",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - Financial Intermediation Research Society - Reykjavik, Iceland - May 25, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20150525-post-crisis-financial-system-regulation",
        "content": "Good afternoon. It is hard for me to convey how honored I am to present the lunch keynote address at this year’s Financial Intermediation Research Society (FIRS) conference. At the risk of dating myself, I am proud to say that I was a founding member of the society, and it’s been a great pleasure to see how FIRS has developed and spread its wings to all parts of the globe. I thank George Pennacchi, president of the society, Vish Viswanathan, president-elect and this year’s program chair, and Allen Berger, my friend and co-author, for the opportunity to speak today. It’s been wonderful catching up with old friends and meeting new scholars who are pushing the envelope of financial intermediation research.\n\nIn his presidential address to the American Finance Association earlier this year, Luigi Zingales asked an important question: “Does finance benefit society?” He pointed out the dissonance between the view of academics, who typically say “yes,” and that of the average American, who is much less certain.1 Zingales argues that academia has an important role to play in ensuring that finance will benefit society. I agree. Academic research can help detect those aspects of financial system design and practices that are beneficial to society and those that are harmful, and Zingales calls for academics to get more involved in policy issues. Today, I’m going to focus on one aspect of policy – the design and practice of financial system regulation after the financial crisis – and the role research has played in informing that regulation. I’ll also discuss an area that needs further research: the interplay between monetary policy and financial stability policy. Before proceeding, I note that the views I’ll present are my own and not necessarily those of the Federal Reserve System or my colleagues on the Federal Open Market Committee.\n\nThe Post-Crisis Supervision and Regulation Framework: A Micro- and Macroprudential Approach\n\nI do not need to tell this audience that financial institutions are able to provide valuable credit, risk-management, and liquidity services to businesses and households because they are designed to take risks and are highly leveraged compared with nonfinancial businesses. But this risk-taking and leverage raise the possibility of systemic problems that could threaten the functioning of the financial system, hurt real economic activity, and impose significant economic costs. The 2008 financial crisis exposed gaps in the regulatory and supervisory architecture, which contributed to a build-up in financial imbalances and systemic risk.\n\nThere are many lessons to be learned from the crisis and its aftermath. The crisis drove home the notion that incentives matter and regulation itself creates incentives. Finance and economic researchers do not need to be told this. Well-designed regulations create incentives that promote financial stability. But sometimes regulations, no matter how well intentioned, can create counterproductive incentives and unintended consequences. At least some part of the strong growth in financial intermediation that occurred outside of the regulated banking system was driven by the desire to avoid regulation. One strong lesson from the crisis is that when setting up regulatory systems, policymakers need to understand the incentives created by the regulatory system itself, incentives that influence the behavior of all market participants: the financial intermediaries and their investors and customers, and also the regulators. Of course, this was recognized in the finance literature well before the recent crisis. In fact, Ed Kane, who presented the lunch keynote address at the very first FIRS Conference, in 2004, has written extensively on the incentives of regulators.2\n\nThe crisis also taught us that we need to avoid designing regulations that attempt to work against market forces. Such regulations will be much more likely to fail or to distort incentives and create unintended consequences. Instead, the regulatory system should attempt to harness market discipline to promote financial stability.\n\nThe financial crisis underscored the need for a new approach to financial system supervision and regulation. The regulatory reforms engendered in the Dodd-Frank Wall Street Reform and Consumer Protection Act, signed into law in 2010, aim to foster financial stability in two ways: first, by lowering the probability of a financial crisis, and second, by reducing the costs imposed on the rest of the economy when a shock hits the financial system. Under Dodd-Frank, the Federal Reserve and other financial regulatory agencies were directed to augment their traditional microprudential approach, which promotes the safety and soundness of individual institutions, with a macroprudential approach in which examiners and supervisors take a horizontal view of risk across institutions rather than looking at only one institution at a time. Such a macroprudential approach had been suggested by Crocket (2000), Borio (2003), and others at the Bank for International Settlements (BIS) well before the recent crisis, so there was a relatively large body of work to draw on. Indeed, according to Clement (2010), records at the BIS indicate the term “macroprudential” was first used in an international context in 1979 in a meeting of the Cooke Committee, which was the precursor to the Basel Committee on Banking Supervision.\n\nAlthough there is still more to be done, regulators continue to make progress in developing tools to implement the macroprudential approach to promoting financial stability and to improve the monitoring of risks over the business and financial cycles. In general, the macroprudential tools can be classified into two categories: structural tools and cyclical tools.\n\nThe structural tools aim to build the resiliency of the financial system throughout the business cycle. These tools include the Basel III risk-based capital requirements, minimum liquidity requirements, central clearing for derivatives, and living will resolution plans.\n\nIn contrast, the cyclical tools are aimed at mitigating the systemic risk that can build up over the business cycle. These tools include the bank stress tests, the countercyclical capital buffer, and the capital conservation buffer. The countercyclical capital buffer allows regulators to increase risk-based capital requirements when credit growth is judged to be excessive and leading to rising systemic risk. The capital conservation buffer ensures that banks raise capital above regulatory minimums in good times so that when they cover losses in bad times, their capital ratio will stay at or above the regulatory minimum. Other possible cyclical tools, not yet established in the U.S. but used in other countries, include loan-to-value ratio limits and debt-to-income ratio limits that vary over the cycle and which have been targeted to particular sectors like housing credit or household credit.3\n\nWhile the structural and cyclical tools show promise, as yet, their performance is largely untested. For example, a study by economists at the International Monetary Fund (IMF) examining the effectiveness of macroprudential tools in reducing systemic risk in 49 countries found mixed results (Lim, Columba, Costa, Kongsamut, Otani, Saiyid, Wezel, and Wu, 2011). The authors concluded that many of the most frequently used tools were effective in reducing the pro-cyclicality of credit and leverage, but the effectiveness depended on the type of shock hitting the financial sector.\n\nResearch Has Informed the Post-Crisis Supervision and Regulation Framework\n\nLegislated regulatory reforms and the work being done by financial regulators to implement those reforms have been informed by a body of academic research over many decades. Many of the people in this room have made significant contributions to this research agenda. Academic research has greatly aided our understanding of how systemic risks can build up and propagate throughout the economy, and this understanding has put a firmer foundation under the regulatory reforms being undertaken. Indeed, well before the crisis, academic research on banking panics pointed to the importance of supplementing microprudential regulation with what we now call macroprudential regulation. The seminal work of Diamond and Dybvig (1983) explicitly modeled a financial crisis in which bank failures had macroeconomic consequences. Gorton (1985) distinguished runs on one bank from banking panics, which entail runs on many banks or the entire banking system.\n\nA large body of research has explored the problems imposed on the financial system from fire sales of assets. While one firm might benefit from the ability to sell assets in response to a negative shock, if the shock hits the potential buyers of these assets at the same time, asset prices can decline sharply, which will affect the prices of similar assets held by other firms. In their Journal of Economic Perspectives paper, Shleifer and Vishny (2011) discuss the role of fire sales in the recent financial crisis. Their model of fire sales (Shleifer and Vishny, 1992) was developed well before the recent crisis and built on Kiyotaki and Moore’s seminal work on the important role collateral plays in lending markets.\n\nIn Kiyotaki and Moore’s (1997) model, because borrowers cannot be forced to repay, all lending is collateralized. When the economy is performing well, the value of the collateral increases, which supports further borrowing and higher output. But when a negative shock hits the economy and output declines, collateral values also fall, which means borrowing falls, which depresses output even further. Thus, the collateral constraint is a mechanism that amplifies and propagates the effects of temporary shocks on the economy. Brunnermeier and Sannikov (2014) build on the Kiyotaki and Moore model. In their model, an economic boom increases bank capital levels high enough so that credit is amply available to borrowers. This lowers the volatility of both output and asset prices. The lower volatility induces banks to increase their leverage and lend even more, so much so that the system is now vulnerable to a negative shock. These models illustrate that systemic risk is endogenous, determined by the choices of the model’s decision makers, and that systemic risk varies across the cycle.\n\nThe research also points out an important aspect of financial crises that, in my view, needs further study: the dynamics of distress in financial markets. In order to determine the appropriate response, regulators and supervisors need to be able to detect whether an institution’s problems stem from temporary liquidity problems or broader solvency concerns. If the former, then the lender of last resort can be used to address the issue, as the institution would have sound, albeit illiquid, collateral to post for the loan. But the demarcation between illiquidity and insolvency is fluid. A temporary liquidity problem at one institution, if not adequately addressed, can morph into a solvency problem, which can then propagate to other institutions. Thus, it is imperative that supervisors stay attentive to the risks that might be developing at individual institutions, as well as across institutions, before those risks become a systemic issue. So, microprudential supervision continues to have an important role to play.\n\nImplementing Supervision and Regulation Informed by Research\n\nWhile academic research has informed us about the benefits of augmenting microprudential with macroprudential supervision, it is up to the supervisors and regulators to actually implement this new framework as directed by the legislation. Let me discuss some of the recent efforts.\n\nThe Federal Reserve and other federal banking agencies in the U.S. are taking a tiered approach to banking supervision and regulation, which finds support in the literature (e.g., Brunnermeier, Crockett, Goodhart, Persaud, and Shin, 2009). This approach recognizes that the risk a banking organization poses to the financial system is likely to vary according to the bank’s size, range of activities, interconnectedness both domestically and globally, complexity, and the extent to which there is a lack of readily available substitutes for the services it provides; oversight is then tailored appropriately. Doing so helps to reduce the potential costs some banks might face if made to comply with rules that don’t further the goal of a healthy and resilient financial system. It also frees up the bandwidth of examiners and supervisors so they can focus more of their attention on where the risks actually lie.4\n\nTwo important focuses of post-crisis regulation and supervision are capital and liquidity. There is close to a consensus in the literature that high leverage was a major contributor to the severity of the financial crisis. Greenlaw, Hatzius, Kashyap, and Shin (2008) show that the concentration of losses in the leveraged financial sector exacerbated the negative effects of the crisis. They argue that leveraged financial institutions suffering from a shortage of capital were not in a position to take advantage of the central bank’s liquidity injections meant to encourage balance-sheet expansion. Rather, these institutions contracted lending in order to be in a position to rebuild their capital levels, and this lengthened the time to recovery. Acharya and Schnabl (2009) argue that mechanisms meant to transfer assets off their balance sheets to other investors, like securitization, actually worked to increase the banks’ effective leverage and raised systemic risk. Admati and Hellwig (2013) have been impassioned advocates for requiring significantly higher levels of bank capital, in particular, in the form of equity capital.\n\nThe Basel III international capital reforms do raise the minimum requirements for both the quantity and quality of capital held by banks, although not to the levels Admati and Hellwig prefer. For all banking organizations, the U.S. rules raise the minimum ratio of tier 1 capital to risk-weighted assets from 4 percent to 6 percent and impose a minimum leverage ratio of tier 1 capital to total assets of 4 percent. Common equity must now be the predominate form of tier 1 capital.5 In addition, large, internationally active banking organizations are subject to a new minimum supplementary leverage ratio that takes into account off-balance-sheet exposures, including credit derivatives, repo-style transactions, and lines of credit.\n\nWhile the U.S. has required banks to meet a minimum leverage ratio requirement for some time, the Basel III reforms introduced this requirement in an international context. I see a lot of benefit to complementing the risk-based capital requirements with a non-risk-based leverage ratio requirement. It is simpler and more transparent and should serve as a further backstop against excessive leverage.\n\nIn my view, another lesson from the crisis is that regulatory complexity can complicate supervision, risk monitoring, compliance, and enforcement. Given the scope and ever-changing nature of the financial system, regulatory complexity is to a certain extent unavoidable. But the tradeoffs should be recognized. It is reasonable to require higher levels of capital to be held against higher-risk assets, but a system of risk weights that is overly granular and complex would be counterproductive. In practice, too much complexity would make it harder for regulators to assess compliance and to determine whether institutions were engaging in some practices merely as a way to hide risk and lower their capital requirements.\n\nIn addition to higher capital requirements, large banking organizations are now subject to minimum liquidity requirements. The earliest research on financial intermediation recognized that, by the design of their assets and liabilities, banks are subject to runs. Deposit insurance and access to the lender of last resort were meant to address the issue in a bank-centric financial system. But financial markets have evolved. The financial crisis showed that runs can occur not just at traditional banking institutions but in many parts of the financial system where short-term financing is used to fund longer-term assets, including money market funds and repo markets. Tirole (2011) reviews and models the role illiquidity played in the crisis and what he calls illiquidity’s friends: market freezes, fire sales, contagion, and, ultimately, insolvencies and bailouts. Much of the academic research points to the role of the lender of last resort in addressing liquidity problems. Liquidity regulation has a role to play, too, by helping to lower the probability of a systemic event and making one more manageable should it occur.\n\nInternational banking agencies through the Basel Committee on Banking Supervision have developed two quantitative liquidity standards: the liquidity coverage requirement (LCR) and the net stable funding ratio (NSFR). Under the U.S. rule implementing the LCR, the largest banking organizations must hold a buffer of high-quality liquid assets sufficient to cover net cash outflows during a 30-day stress scenario.6 The revised and final NSFR was released by the Basel Committee last October. The NSFR is meant to be a complement to the LCR by looking at the bank’s funding profile beyond the 30-day window.\n\nAnother important aspect of the new regulatory approach involves horizontal reviews of banking organizations, which augment the examinations of individual institutions. An example is the annual cross-firm evaluation of capital that the Fed performs at the largest institutions (those with $50 billion or more in consolidated assets). One part of this assessment is the Comprehensive Capital Analysis and Review (CCAR), which evaluates the bank holding company’s capital adequacy, the process by which the holding company ensures its capital adequacy, and its planned capital distributions, including dividend payments and stock buy-backs. Another part of the assessment is the Dodd-Frank Act stress test (DFAST), a forward-looking component that evaluates whether capital is sufficient to absorb losses under a stress scenario. These assessments of bank capital allow regulators to evaluate not only individual firms but also the resiliency of the group of institutions during times of stress.\n\nMany of the regulatory reforms I’ve been discussing foster financial stability by aiming to lower the probability that a financial crisis will develop. But the crisis made clear that it was also important to reduce the costs imposed on the rest of the economy when a shock hits the financial system. Dodd-Frank has taken steps in that direction. The act requires a systemically important financial institution to provide a resolution plan or living will detailing how, were the firm to fail, it could be wound down in an orderly way under the bankruptcy code without imposing severe adverse consequences on the financial system and the rest of the U.S. economy. The Federal Deposit Insurance Corporation (FDIC) and the Fed have provided guidance to financial companies on their submitted plans, asking them to address issues that are impediments to resolution under the bankruptcy code, such as funding and liquidity, counterparty risk, global cooperation, and the interconnectedness and complexity of their organizational and legal structures.7\n\nWhen an orderly resolution by bankruptcy is not possible, the Dodd-Frank Act’s Title II provisions establish an orderly liquidation authority (OLA) to resolve troubled nonbank financial companies, including bank holding companies, securities broker-dealers, and other nonbank financial firms. This authority resides in the FDIC, the agency also responsible for resolving failed banks. Among other powers, the authority includes the ability to establish a bridge financial company, to terminate certain financial contracts, and to convert debt to equity. If a failing firm is taken into receivership by the FDIC under this authority, the act compels the FDIC to ensure that shareholders and creditors bear losses and that the management responsible for the losses is replaced.\n\nJackson and Skeel (2010) and Jackson (2010), among others, have made the case that a modified bankruptcy code could work even for large, complex financial firms and that it might work better than Dodd-Frank’s orderly liquidation authority because, for one thing, it is less discretionary.8 However, because systemically important institutions operate globally, U.S. laws would need to be harmonized with those of other countries. Of course, global operations are also a challenge for resolution under the orderly liquidation authority.\n\nThere continues to be active discussion among academics and policymakers because effective resolution remains a key task in promoting financial stability. Ironically, we will have a more stable financial system if we build a system that allows insolvent institutions to fail and involves less regulatory intervention to prevent closure of these firms. When managers and creditors do not expect to be bailed out ex post, they will have increased incentives to monitor the risks their institutions are taking and to take adequate precautions to avoid failure.\n\nIt is too soon to know how well the new orderly liquidation authority will work in practice, and whether it represents a credible resolution mechanism so that no institution is treated as too big to fail and the moral hazard issues engendered by too big to fail are solved. If too big to fail remains a problem, it seems reasonable to ask whether breaking up the institutions would solve it. My answer is “no.” To evaluate such a potential solution, it is important to know why banks have gotten so large. A body of research suggests that some institutions have grown in size, not to game the system, but for reasons of efficiency.9 More research is needed to calibrate these efficiency benefits against the potential systemic risks posed by large, complex institutions. However, to the extent that market forces and efficiencies encourage banks to grow larger, I remain skeptical that breaking up the banks, however well intentioned, will be effective. Indeed, if the scale economies are large, size restrictions would create great incentives for firms to try to evade the restrictions by moving activities outside of the more regulated sector without necessarily reducing systemic risk. That is, the risk would migrate elsewhere but would not be eliminated. I believe a better approach is to couple a credible resolution method with the imposition of more stringent requirements on institutions that impose more systemic risk on the financial system. This approach, which is a goal of Dodd-Frank, would spur institutions to internalize some of the externalities of taking on risk.\n\nUp to now I have focused mainly on regulation, but to promote financial stability, we need continued vigilance in monitoring the buildup of risks in the financial system. Better monitoring will be aided by data being collected by the Office of Financial Research (OFR) and by metrics being developed by academic and central bank economists, such as the Cleveland Fed’s financial stress index, which summarizes movements in a number of financial variables associated with stress.10 It is important to remember, however, that many of these metrics quantify correlations in the data rather than telling us something about the structure of the underlying financial markets or what has caused the movement in the metric and whether it requires a policy response. Moreover, integrating such metrics into day-to-day supervision remains a challenge.11\n\nFinancial stability surveillance is also receiving regular attention in Federal Open Market Committee meetings. Federal Reserve staff are using a framework, described in Adrian, Covitz, and Liang (2013), that tracks a standard set of financial system vulnerabilities, including the pricing of risk, leverage, maturity and liquidity transformation, and interconnectedness and complexity, across four broad areas of the financial system: asset markets, the banking sector, shadow banks, and the nonfinancial sector. This regular and systematic analysis is already helping us to better identify changes in conditions over time. But more research is needed to determine what such changes signal about financial stability. Of course, an even bigger question is how policy should respond to signs of emerging financial stability risks and, in particular, how financial stability concerns should be incorporated into monetary policymaking.\n\nThe Nexus Between Monetary Policy and Financial Stability Policy\n\nRecent experience has renewed the discussion of how central banks should respond to emerging systemic risk. We saw that financial imbalances can build up even in a low-inflation environment. While price stability may promote financial stability, it is not a sufficient condition. We also saw that when financial markets are not functioning well, the transmission of monetary policy to the economy can be disrupted. In addition, the FOMC has recognized that nonconventional monetary policy, including large-scale asset purchases and the extended period of essentially zero interest rates, could pose potential risks to financial stability by affecting market functioning and spurring risk-taking in a search for yield.12\n\nBefore the crisis, the conventional approach generally taken by the Fed was to use monetary policy to respond to asset price movements – whether driven by fundamentals or not – only to the extent that those movements contained information about inflation and output growth. Monetary policy would not try to limit the size of imbalances as they developed, but would opt to mop up the consequences of a correction after the fact. But others argued for a more activist approach, with monetary policy being used to try to stem developing imbalances before they caused harm to the real economy. White (2009) characterized these approaches as using monetary policy to clean up the mess after a bubble bursts versus using it to lean against a bubble that appears to be forming.\n\nIn deciding whether or not to take action against a growing imbalance, policymakers need to balance the expected improvement in future economic conditions against the potential cost of unduly limiting credit extension. If policymakers decide to intervene, the next question is, what tools should they use? Should macroprudential tools be used for financial stability concerns, with monetary policy focused only on its macroeconomic objectives of price stability and maximum employment? Even in this case, there will be interactions between the two types of policy – very loose monetary policy increases the likelihood that financial instabilities will develop, thereby increasing the likelihood macroprudential policy tools will be needed. Tight macroprudential policy could tighten financial conditions more generally, necessitating a monetary policy response.\n\nA necessary ingredient in gaining insights into the interactions between monetary and macroprudential policy is the development of structural general equilibrium models that seriously incorporate financial markets and the possibility of financial stress, borrower defaults, and financial institution failures. These models need to be fairly complex. While I earlier argued that simpler regulations may have benefits, the models in which we evaluate such regulations and policies, by necessity, need to be complex. Before the financial crisis we may have convinced ourselves that we could rely on representative agent models, linearized around a steady state, with one interest rate. But the nature of the financial crisis pointed out the inadequacies of these models for understanding the impact of severe financial stress on the real economy. By their nature, financial crises involve nonlinearities, potentially multiple equilibria, and financial frictions that limit arbitrage. So our models need to include these features. In addition, macroprudential tools focus on the allocation of credit in the economy and work through redistribution. To study the effects of such tools, our models need to include heterogeneous agents with different rates of risk tolerance and time preference, and multiple interest rates.13 Of course, monetary policy also entails some redistributions of income and wealth, and understanding the dynamics of the effects of monetary policy also requires the use of more complex models.14\n\nAn ongoing research agenda in academia and central banks aims to build models useful for such policy analysis. I don’t have time to review the growing literature in this area, but Adrian and Liang (2014) provide a very useful summary. It is important that research continues to expand our understanding of the interactions between financial markets and the real economy and our ability to monitor developments in each.\n\nIn the meantime, policymakers need to acknowledge that in the lead-up to the financial crisis, some of the vulnerabilities of the financial system were not fully recognized. Despite our best attempts, there likely remain gaps in our ability to assess the risks in every part of the financial system. This is not an argument that we should use monetary policy as the main tool to address financial stability concerns. Given the state of our knowledge, I would opt to use the macroprudential tools as the first line of defense, since they can be more targeted to the markets and institutions where the risks are emerging. However, I do think that when we are making policy decisions, we should be cognizant of the linkages between our nonconventional monetary policy of an extended period of essentially zero interest rates and financial stability. And I encourage the researchers in this room and everywhere to continue pushing out the frontier of our knowledge with some urgency, since the world is not going to stop and wait. I recommend the same sense of urgency to central bankers and financial system supervisors, as we work to implement the new supervision and regulation framework.\n\nA Final Thought on How Research Should Inform Legislation\n\nLet me leave you with one final thought. The complexity of balancing monetary policy with financial stability considerations does not absolve policymakers from having to clearly explain the rationale for their decisions. If anything, it makes clear communication and transparency even more imperative, so that policy can be more effective and so that the public has the information it needs to hold the central bank accountable.\n\nCongress has set the Fed’s goals but it has also given the Fed independence in making monetary policy decisions in pursuit of those goals. That is, monetary policy decisions do not have to be approved by the president or Congress. This is consistent with a large body of research showing that when central banks formulate monetary policy free from government interference and are held accountable for their decisions, better economic outcomes result. I believe that allowing political considerations to influence monetary policy decisions would be a tremendous mistake because it would ultimately lead to poorer economic performance. The research on this point is clear: the Federal Reserve’s independence in setting monetary policy is worth preserving."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "May 01, 2015",
        "title": "Consumer Credit: Suggested Directions for Policy-Relevant Research",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - Conference on Regulating Consumer Credit, A Joint Conference of the Federal Reserve Bank of Philadelphia and the Journal of Economics and Business - Philadelphia, PA - May 1, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20150501-consumer-credit-suggested-directions",
        "content": "Good morning. I thank the conference organizers at the Federal Reserve Bank of Philadelphia and the Journal of Economics and Business, in particular, Paul Calem, Julapa Jagtiani, Bill Lang, and Ken Kopecky, for inviting me to participate in this conference on regulating consumer credit. It is a particular pleasure for me to be back at my old haunt, having grown up at the Philly Fed, and seeing the many people I count not only as my friends but also as my teachers, because I’ve learned so much from you over the years. I also want to acknowledge my long association with the Journal of Economics and Business, and the opportunity Ken Kopecky gave me to serve as an associate editor of the journal and as the editor of a special issue associated with the Federal Reserve System’s March 2007 conference on financing community development.\n\nIt may not surprise you that many of the topics contained in that special issue are still being researched today, including subprime mortgages, foreclosures, predatory lending practices, and consumer literacy. Indeed, some of these very topics are covered in this conference. I don’t think we should take this as signaling a lack of progress. Instead, I view it as recognition that consumer credit markets are a vital part of the modern economy, that the issues pertaining to these markets, including regulation, are intricate ones, and that the data and models being used to study these important markets are becoming more sophisticated and informative. Conferences like this one help us identify what we know and what we don’t know – a necessary step on the road to more effective regulation and policymaking. Today I will offer my perspectives on the research agenda on consumer credit and household finance. As always, the views I’ll present are my own and not necessarily those of the Federal Reserve System or my colleagues on the Federal Open Market Committee.\n\nHousehold Finance Before, During, and After the Financial Crisis\n\nSince I am in Philadelphia, I can’t help but begin by quoting one of Philadelphia’s favorite sons, Ben Franklin. Ben was not stingy with advice, and among the many pieces of wisdom he provided in his Poor Richard’s Almanac was the warning: “...he that goes a borrowing, goes a sorrowing.”1 Yet U.S. households appear to have ignored this warning. Since the 1960s, household debt, including mortgages and consumer credit and other liabilities, has accounted for about 25 to 30 percent of total credit market debt outstanding.2 Consumer loans excluding mortgages have varied between 10 and 20 percent of commercial bank credit.3\n\nIn the aftermath of the global financial crisis, it is easy to forget the important benefits that access to such credit can mean for households and the economy at large. Well-functioning credit markets provide an efficient mechanism for allocating risk and moving funds from savers to borrowers. Credit allows households to consume and invest in goods and services that are currently unaffordable but which are affordable based on their future income, and to manage the risks associated with loss of income. This access to credit allows households to participate in the modern economy. Mortgages allow people to purchase houses, a goal of many families. Auto loans give buyers the means to search for jobs and get to work. Student loans allow people to fund their educations, raising the level of their human capital and the productivity of the workforce. So credit allows people to increase their own well-being and contribute to the country’s economic growth.\n\nOver time, financial innovations, regulatory changes, and technological advances have all led to increased access to credit by households, some of whom found it difficult to borrow in earlier times. For example, the development of the secondary mortgage market and securitization brought new sources of funds to the market. Permitting banks to branch nationwide lowered noninterest expenses and loan losses. And the development of credit scoring models lowered transactions costs and allowed lenders to better assess and monitor the riskiness of potential borrowers.\n\nHowever, as the financial crisis underscored, not all financial innovations and credit extensions are beneficial to households or to the broader economy, especially when the risks they entail aren’t fully appreciated. While household debt-to-income ratios had been trending up since the 1960s, the rate of increase rose dramatically in the period leading up to the financial crisis, from about 100 percent in 2000 to over 130 percent in 2007. Over the same period, residential mortgage debt outstanding more than doubled, from $4.8 trillion to over $10.6 trillion, and consumer debt excluding mortgages rose by nearly $1 trillion, from $1.7 trillion to $2.6 trillion."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "April 16, 2015",
        "title": "The Economic Outlook and Monetary Policy",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - Forecasters Club of New York - New York, NY - April 16, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20150416-the-economic-outlook-and-monetary-policy",
        "content": "Good afternoon. I would like to start by thanking Charlie Steindel and the Forecasters Club of New York for their invitation to speak today. It is a particular pleasure for me to address your group: first, because I have known Charlie for many years – we both grew up as economists in the Federal Reserve System – but also because I know I won’t have to explain to you what a difficult task economic forecasting can be, even in the best of times. Still, forecasting is something economists and policymakers must do, so today I will discuss my outlook for the economy and monetary policy. As always, the views I’ll present are my own and not necessarily those of the Federal Reserve System or my colleagues on the Federal Open Market Committee.\n\nThe Economic Outlook\n\nThe economic expansion began nearly six years ago. While volatility in the monthly data can often obscure underlying trends – and today is no exception – it is important to recognize the significant economic progress the country has made since the darkest days of the global financial crisis and Great Recession. That progress, though slow in coming, has been significantly supported by extraordinary monetary policy accommodation. Underlying economic fundamentals have improved, resulting in an economy that is better able to sustain growth through the inevitable transitory shocks and typical sectoral ups and downs.\n\nFor example, the harsh winter weather took its toll on first-quarter growth this year, just as it did last year. A number of recent data releases have come in below expectations. But my sense in speaking with business contacts is that the economy has resiliency. I expect the slowdown to be temporary and do not view it as pointing to something more fundamental.\n\nMy view reflects the fact that a number of the so-called headwinds have waned. Those headwinds held back growth earlier in the recovery, made the economy more vulnerable to negative shocks, and dampened the transmission of very accommodative monetary policy to the broader economy.\n\nThe Great Recession wreaked havoc on household and business balance sheets. But balance sheets have improved substantially over the expansion. Households have reduced debt levels relative to disposable income from a peak of 130 percent before the recession to about 100 percent today. Very low interest rates mean that households are spending less to service their debt. And thanks to higher prices of equities and houses, households have more than made up the $10 trillion in net worth destroyed in 2008. U.S. businesses are also in better financial condition after deleveraging. They are positioned to expand investment and hiring, and they are doing both.\n\nThe headwind from government spending is also abating. Government spending declined over 2010 to 2013, but began to rise again last year. With tax revenues recovering, state and local governments have been adding to their payrolls and increasing expenditures. The drag from federal government spending has lessened over time, although it is unlikely that such spending will contribute to growth this year.\n\nThe banking sector is regaining its health, with higher capital levels and lower loan delinquencies. Bankers are working through the new regulatory requirements and augmenting systems to better monitor and evaluate risks in their portfolios. Loans to consumers and businesses are now rising and delinquencies and write-offs are at low levels.\n\nAs the headwinds continue to diminish, we now also have a tailwind in the form of lower oil prices. For an oil-importing country like the U.S., lower energy prices will be a net positive. No doubt, the drop in oil prices has led to reduced investment and dislocation in parts of the domestic energy and energy-related sectors. This is already affecting growth, especially in certain regions of the country. But lower energy prices will eventually show up as a positive for consumer, business, and local government spending.\n\nDespite the positives, as is always the case, not all sectors will contribute equally to growth. Residential construction is unlikely to come back strongly this year, but easing of mortgage credit conditions will help support continued moderate improvement in the housing sector.\n\nI also expect net exports to be a drag on U.S. growth this year. The strength of the U.S. economy relative to that of many of our trading partners, as well as interest rate and inflation differentials, has contributed to about a 12 percent appreciation in the broad value of the dollar over the past year. While a stronger dollar means better terms of trade for U.S. consumers and businesses, which is a positive for a growing economy in the longer run, in the near term it can be a drag on U.S. export growth. Accommodative monetary policy actions have brightened the outlook for European economies, but growth and inflation are likely to remain low in the Eurozone for a while longer. Whether the drag from the trade sector will be larger or smaller than I’ve assumed is one of the risks to the forecast.\n\nOn balance, I expect that after a weak first quarter, U.S. economic growth will strengthen, averaging about 3 percent over the remainder of this year and next. This is somewhat above my estimate of 2.5 percent longer-run growth. The above-trend growth I am projecting will support continued improvement in labor markets, one of the factors that will figure into the FOMC’s assessment of the appropriate timing of liftoff.\n\nNotwithstanding the slower job growth reported for March, the economy has seen significant improvement in labor market conditions. Over the past year, average monthly payroll job growth strengthened to about 260,000 jobs, and nonfarm payrolls are now about 2.8 million above their pre-recession peak. I certainly would have liked to have seen more than 126,000 jobs added in March. At the same time, I believe it is premature to read anything about a significant new trend from this number. The FOMC has said that its policy is “data dependent.” But being “data dependent” does not mean reacting to every change in the data. Economic data can be volatile from one month to another. According to the Bureau of Labor Statistics (BLS), which publishes the employment report, the confidence interval for the monthly change in payroll employment is on the order of plus or minus 105,000. But we shouldn’t ignore monthly data reports either. My preference is to look at the broader trends in the data and at a number of indicators to get a better sense of developments.\n\nThese other labor market indicators suggest that the weakness in payroll jobs in March is likely temporary. Let me point out a few of these. According to the Job Openings and Labor Turnover Survey (JOLTS) published by the BLS, the rate of job openings is at a cyclical high, and both the hiring and separation rates are up substantially since the end of the recession, meaning that employers are looking to hire, and workers are confident enough to start looking for better jobs.\n\nThe unemployment rate is 5.5 percent, down sharply from its peak of 10 percent in 2009, more than a percentage point below its level last March, and near the range many economists view as its longer-run level. I continue to view the unemployment rate as a useful indicator of labor market conditions. Some people feel its sharp decline is overstating the improvement in labor markets because of the confounding effect of cyclical declines in labor force participation. However, research, including some by my staff at the Cleveland Fed, finds that a large part of the decline we have seen in labor force participation since 2007 reflects a longer-run structural trend driven by factors like changes in demographics.1 Moreover, there have been significant declines in the broader measures of the unemployment rate, such as those that include discouraged workers and those that include people working part-time who would prefer to work full-time, although these have not yet reached their pre-recession levels.\n\nI expect progress to continue, and in my view, taken together, labor market indicators point to an economy that is nearing the Fed’s goal of full employment. Stronger labor markets have led to stronger growth in disposable income. While wage growth remains subdued, it typically lags improvement in labor market conditions. In fact, some analysis we’ve done at the Cleveland Fed shows that in the last three expansions, job gains in industries that pay above-average hourly earnings contributed more to total private-sector job gains as the expansions continued.2 After the Great Recession, it took some time for job gains to materialize. But our analysis indicates that at the national level, since the start of the expansion through 2014, for every job added in industries paying below-average hourly earnings, about 1.3 jobs have been added in industries paying above-average hourly earnings. As employment continues to grow, I anticipate that wages will accelerate and provide additional support for consumer spending.\n\nI also anticipate that inflation will gradually return to the Fed’s 2 percent objective over time, and I continue to monitor inflation developments closely. The sharp decline in oil prices is showing up in much lower headline inflation numbers, and the appreciation of the dollar has put downward pressure on the prices of non-petroleum imports. I expect further declines in inflation in the near term, but those should prove transitory as oil prices stabilize. The FOMC has indicated that, in addition to further improvement in labor markets, a second factor in assessing the appropriate timing of policy liftoff will be reasonable confidence that inflation will move back to our 2 percent objective over the medium term. I am reasonably confident that inflation will gradually return to the Fed’s goal by late 2016 supported by above-trend economic growth.\n\nI base this view on a couple of factors. First, while there has been some pass-through of declines in oil prices and import prices to core measures of inflation that remove volatile food and energy prices, the pass-through has been relatively modest. Core PCE inflation is about 1.4 percent, but the Cleveland Fed’s median CPI measure has remained near 2.25 percent for the past year, and Cleveland staff research has found that this measure has some predictive power for headline inflation over the medium term.3 In addition, inflation expectations are an important factor in forecasting inflation, and in my view, inflation expectations remain well-anchored. The survey-based measures of inflation expectations of both consumers and professional forecasters have been fairly stable. These survey measures have historically done well at capturing longer-run trends in inflation and they have been shown to help in forecasting inflation.4\n\nI am not inclined to take much of a signal about inflation expectations from the recent movements in inflation compensation measured by the spread between yields on Treasury securities and Treasury inflation-protected securities, so-called TIPS. These market-based measures have been affected by flight-to-quality flows into Treasuries from abroad, and the recent changes in inflation compensation likely reflect liquidity effects and changes in inflation risk premiums more so than changes in inflation expectations. The fall in inflation compensation late last year also seems to be closely correlated with the drop in energy prices. Cleveland staff analysis has found that while typical moves in energy prices explain little of the variation in longer-term inflation expectations, the sharp drop in energy prices since last June can account for all of the decline in the Cleveland Fed’s expected inflation measure, which incorporates market data on inflation swaps and Treasury yields, as well as survey information from professional forecasters.5\n\nAs I am sure the professional forecasters in this room know, forecasting inflation with any precision is very difficult. The confidence bands around the forecasts tend to be wide. For example, historical average projection errors across a range of private-sector and government forecasts indicate that the 70 percent confidence interval around a forecast of CPI inflation one year out is about plus or minus 1 percentage point. So when I say I am “reasonably confident” that inflation will return to target by late 2016, it is within that context – I am not requiring higher-than-normal precision around the forecast. I see quite a bit of difference between the situation in Europe, where inflation has been falling and growth has been weak, and the situation in the U.S., where an oil-price shock is driving down headline inflation rates and the economy has been strengthening. We have been climbing out of a very deep recession and have experienced a negative oil-price shock. In that environment, it does not surprise me that inflation has been slow to return to our 2 percent goal. So long as inflation expectations remain anchored and the economy remains on track to return to trend growth or above, as I expect it to, then I am comfortable with it taking some time for inflation to return to our 2 percent objective.\n\nOf course, my projections for the economy are dependent on appropriate monetary policy. So let me turn to that now.\n\nMonetary Policy\n\nThe financial crisis and the ensuing deep recession required an aggressive policy response. To support its goals of price stability and full employment, the FOMC has kept the federal funds rate at essentially zero since the end of 2008. It pursued further policy accommodation by conducting large-scale asset-purchase programs to exert downward pressure on longer-term interest rates and by providing more explicit forward guidance on the anticipated future path of interest rates. This extraordinarily accommodative monetary policy has provided important support to the economy, helping to promote stronger labor markets and the pickup in growth that underlies my projection that inflation will gradually return to our goal over time.\n\nBecause monetary policy affects the economy with a lag, policy needs to be forward looking and rates will need to begin to move up from their very low level before we have fully reached our goals. With the fed funds rate at zero, even after the first rate increases, policy will remain very accommodative for some time to come and will continue to promote attainment of our goals. While financial market participants are particularly focused on the timing of the first rate increase, more important for macroeconomic performance is the expected path of policy beyond liftoff because expectations about the future path of policy can affect today’s economic decisions.\n\nThe FOMC’s March Summary of Economic Projections (SEP) indicates that most participants anticipate that it will be appropriate to begin raising rates sometime this year and that the path thereafter will be a gradual one. As shown in the SEP, there is some diversity of views about the appropriate path of policy. Such diversity should not be surprising. It does not reflect different views about our commitment to promote our dual mandate goals of price stability and full employment, but rather different views about realized and anticipated progress toward those goals and about the potential costs and benefits to changes in policy with respect to achieving those goals.\n\nThe economy has reached the point where these evaluations are not easy to make. But this situation should be celebrated because while it does mean policy decisions have become somewhat more complicated, it also reflects the significant economic progress that has been made since the end of the recession.\n\nI supported the changes the FOMC made in its communications in March, which made the June meeting and subsequent meetings viable options for liftoff. There has been cumulative improvement in the economy and our monetary policy stance and communications should reflect that. Over the next couple of months, incoming information on the economy – including the two monthly employment reports we will receive before we meet in June – will help us evaluate whether the softness in the first quarter is indeed transitory, as I currently anticipate, or whether it could be more enduring. If it turns out that the incoming information shows that growth is regaining momentum after the first-quarter slowdown and more broadly supports my forecast, I would be comfortable with liftoff relatively soon.\n\nLet me explain my reasoning, which is based on my assessment that the potential returns to delaying action will soon be outweighed by the potential returns to beginning the normalization process.\n\nFirst, although the Committee has been appropriately cautious, the improvement in underlying economic fundamentals consistent with my outlook indicates that the expansion would not be adversely affected by a gradual increase in the policy rate from zero. Liftoff means a reduction in the degree of extraordinary policy accommodation; it doesn’t mean tight policy. Headwinds are diminishing and above-trend growth is projected over the medium run. In this environment, the equilibrium real interest rate will be rising and the policy rate should rise with it.\n\nSecond, the FOMC has been communicating for some time that we anticipate it will be appropriate for policy normalization to take a gradual path. One benefit of the gradual approach is that it allows for a recalibration of policy over time as some of the uncertainties surrounding the equilibrium interest rate, potential growth rate, and longer-run unemployment rate in the post-crisis world are resolved. I would like our policy actions to be consistent with our communications, and in my view, given the economic outlook, starting the normalization process relatively soon will help ensure that we can, indeed, take a gradual approach. A delay that’s too long might risk having to move rates up more steeply in order to promote attainment of our goals over time.\n\nThird, although not an issue now, too long a delay could also eventually pose risks to financial stability. Holding short rates at zero too long might spur excessive leverage or encourage investors to take on risks they are ill-equipped to manage in a search for yield. The FOMC is carefully monitoring financial markets for any signs of adverse consequences of very low interest rates, and so far, there does not appear to be a threat to financial stability. However, we need to acknowledge that leading up to the financial crisis, some of the vulnerabilities of the financial system were not fully recognized by policymakers. And although we have made significant strides since then, there likely remain gaps in our ability to assess the risks in every part of the financial system. This is not an argument that we should use monetary policy as the main tool to address financial stability concerns. As I’ve said elsewhere, given the state of our knowledge, I would opt to use the macroprudential tools as the first line of defense, since they can be more targeted to the markets and institutions where the risks are emerging.6 However, I do think we should be cognizant of the linkages between nonconventional monetary policy and financial stability when we are making policy decisions.\n\nData-Dependent Monetary Policymaking\n\nThis is my current thinking on appropriate policy, but let me emphasize again that it is dependent on whether economic developments are consistent with my forecast. Let me finish my remarks with some thoughts about data-dependent monetary policymaking. As the FOMC has said, policy is not on a pre-set path. Indeed, as I already mentioned, the SEP gives some information on the diversity of views among FOMC participants about the appropriate path of policy. But that diversity understates the degree of uncertainty about the future path because around each participant’s policy path, there is a confidence band, which reflects the fact that shocks will hit the economy and the policymaker will want to respond to some of those shocks.\n\nIn determining the appropriate timing for liftoff and the path thereafter, the FOMC will be assessing incoming information and evaluating how that information affects the economic outlook and progress toward our goals of maximum employment and price stability. If incoming economic information materially changes our outlook, we will adjust the funds rate up or down, as appropriate. Our policy path is not pre-determined because the future is not pre-determined.\n\nBut “data-dependent” does not mean “non-systematic.” Policymakers should strive to respond in a systematic fashion to incoming information because to the extent that households and businesses understand how policymakers are likely to react to economic developments – whether those developments are anticipated or unanticipated – their policy expectations will better align with those of policymakers. This alignment helps households and firms make better saving, borrowing, investment, and employment decisions, thereby making monetary policy more effective.\n\nIn the late 1980s and 1990s, the public had a pretty good sense of how the FOMC’s policy would respond to economic developments, the so-called reaction function. They were able to get a handle on the FOMC’s reaction function because after the great inflation of the 1970s, the FOMC became more predictable and systematic in how it reacted to changes in economic activity and inflation.7 Because the Great Recession required the Fed to behave in a way quite distinct from its past behavior, there is less understanding about how policymakers are likely to react to incoming economic information than there was earlier.\n\nAs our economy returns to more normal territory and the Fed begins the process of normalizing policy, clear communications that enhance the public’s understanding of the rationale behind the FOMC’s policy decisions will have an important role to play. Stepping back from the explicit forward guidance the FOMC found necessary to use as part of its nonconventional policy tools and moving back to conveying a better sense of the FOMC’s policy reaction function should be viewed as a positive step. It is further evidence that our journey back to a more normal economic and policy-setting environment is well underway."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "March 23, 2015",
        "title": "Recent Developments in U.S. Monetary Policy: From Extraordinary Back to Ordinary",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - GIC Central Banking Series: Policies for the Post Crisis Era - Banque de France - Paris, France - March 23, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20150323-recent-developments-in-us-monetary-policy",
        "content": "Good morning. It is a privilege to join you at this event organized by the Global Interdependence Center and the Banque de France. I am proud to say that I have had an association with the GIC for many years. I have always valued the insights I’ve gleaned from attending GIC events, and I am very grateful that David Kotok, John Silvia, and their colleagues have invited me to participate in today’s program, which is part of the GIC’s Central Banking Series.\n\nToday’s topic, “New Policies for the Post-Crisis Era,” is quite timely. Although policymakers in the United States and Europe face distinct economic environments, we face similar challenges in determining the most effective policies in those environments. I plan to share a few thoughts about monetary policy on my side of the pond. In particular, I want to discuss some of the FOMC’s plans for policy normalization. But to put that into context, it is important to understand how we got to this point, so I will start with a review of some of the monetary policy actions the Fed took to address the financial crisis and Great Recession. As always, the views I’ll present today are my own and not necessarily those of the Federal Reserve System or of my colleagues on the Federal Open Market Committee.\n\nU.S. Monetary Policy in Extraordinary Times: Interest Rates, Asset Purchases, and Forward Guidance\n\nIn response to the financial crisis and deep recession, the Federal Reserve took some unprecedented policy actions. The Fed’s policy body, the Federal Open Market Committee, or FOMC, has run an extraordinarily accommodative monetary policy to promote our goals of price stability and maximum employment. The FOMC has kept its policy rate – the federal funds rate – at essentially zero since the end of 2008 and it has used forward guidance to communicate the anticipated future path of policy. In addition, to exert downward pressure on longer-term interest rates, it purchased large volumes of longer maturity Treasury securities and mortgage-backed securities guaranteed by the housing-related U.S. government-sponsored enterprises, Fannie Mae, Freddie Mac, and Ginnie Mae.\n\nThis extraordinarily accommodative monetary policy has provided important support to the U.S. economy, helping to promote stronger labor markets and the pickup in growth that underlies my projection of a gradual return of inflation to our 2 percent goal over time. But it has also presented some challenges for the FOMC in returning to a more normal policy-setting framework. To understand those challenges, it helps to review some of the major policy developments since the crisis.\n\nSome of the Federal Reserve’s policy actions were aimed at addressing the stresses that emerged in financial markets in 2007 and 2008. Other policy actions were focused on easing monetary conditions to promote the Fed’s dual mandate goals of price stability and maximum employment.\n\nThe Fed’s first action in August 2007 was to cut the primary credit rate – the rate that banks pay to borrow from the Fed’s discount window – by 50 basis points, to 5.75 percent. This action was taken to encourage liquidity-constrained institutions to borrow from the Fed.\n\nThe following month, the Fed began lowering the fed funds rate target, starting from 5.25 percent before the September 2007 rate-cut and ending at essentially zero in December 2008. This was an unprecedented step into a new monetary policy regime. The fed funds rate has been effectively at the zero lower bound ever since.\n\nDuring this period the Fed also responded to the crisis by implementing a number of unprecedented lending and liquidity programs, but in the interest of time, I won’t review them here.1\n\nThe Fed’s actions helped to stabilize financial markets. However, the real economy had suffered a lot of damage. The U.S. unemployment rate rose from about 5 percent before the recession to its peak of 10 percent in October 2009. Over the course of the recession, core inflation fell from around 2 percent to about 1 percent. Ordinarily, such conditions would warrant further reductions in the policy rate. But with the fed funds rate at its zero lower bound, the Fed engaged in nontraditional policies to support the economy. In particular, between December 2008 and October 2014, to put downward pressure on longer-term interest rates, the Fed purchased large volumes of longer maturity U.S. Treasury securities and agency mortgage-backed securities.2\n\nLarge-scale asset purchases are thought to affect longer-term interest rates via a couple of channels. The first channel relies on segmented markets. When financial markets are segmented either because arbitrage is disrupted (as it was during the financial crisis) or because certain market participants prefer particular types of assets, then assets are not perfect substitutes. In such a situation, when the central bank reduces the supply of longer-term assets by purchasing a large volume, the prices of those assets should rise and the term premium on the assets should fall. As investors begin to replace those assets with others, their prices will rise too, so there can be a transmission to assets beyond those being purchased by the central bank.\n\nA second channel through which large-scale asset purchases are thought to affect longer-term interest rates is via a signaling channel. The purchases signal that the central bank intends to pursue a more accommodative policy stance than the public currently expects. Thus, the purchases can be viewed as a form of commitment for policy forward guidance, another policy tool that the Federal Reserve has used during the unusual economic circumstances of the past six years.\n\nThe formulation of the Fed’s forward guidance on the future path of interest rates has changed over time, from qualitative guidance, to calendar dates, to economic thresholds, and to a blend of state-contingent and date-based guidance.3 In extraordinary economic times, like those we’ve experienced in recent years, forward guidance is more than a communications device. It is a tool of monetary policy that has the potential to increase the degree of monetary policy accommodation, especially when interest rates are essentially at their zero lower bound. By reducing uncertainty about the future path of policy, forward guidance can help lower interest rates by reducing the premiums investors demand to compensate them for interest-rate uncertainty.\n\nIn addition, in theory, if the central bank indicates that the future path of short-term interest rates will be low for a long time – perhaps lower and for longer than would have been consistent with the central bank’s past behavior – this can also put downward pressure on longer-term interest rates, thereby spurring current economic activity. According to the theory, if people believe that the central bank is committed to keeping rates very low, they will expect higher economic activity and higher inflation in the future. When households, businesses, and market participants are assured of better economic prospects in the future, they should be more willing to make investments in capital and labor today rather than delaying them, and this will help the current economy.4\n\nThere has been considerable study of the effectiveness of these extraordinary policy tools, especially the Fed’s large-scale asset purchase programs. Federal Reserve Board Vice Chairman Stanley Fischer recently reviewed the empirical evidence on how effective the Fed’s purchase programs have been in lowering longer-term interest rates, and discussed the results of a recent Board of Governors staff study on the effectiveness of the purchase programs along with forward guidance on the macroeconomy.5 In general, the studies find that the Fed’s various asset purchase programs have lowered longer-term yields and the staff study finds that purchases and forward guidance have had an impact on the macroeconomy. But as the Vice Chair pointed out, estimated magnitudes vary quite a bit across studies and are surrounded by wide bands of uncertainty.\n\nThere is, however, no uncertainty about the dramatic change in the size and composition of the Federal Reserve’s balance sheet as a result of the purchase programs. Assets on the Fed’s balance sheet have increased five-fold, from less than $900 billion in July 2007 to about $4.5 trillion today. On the liability side, banks have more than $2.5 trillion in reserves at the Fed, most of it in excess of that required to meet reserve requirements. In terms of composition, before the actions taken to combat the crisis, about 90 percent of the Fed’s assets were Treasuries and none were agency securities; now about 55 percent of the Fed’s assets are Treasuries and almost 40 percent are agency MBS. And of the Fed’s Treasury holdings, over 50 percent have a maturity of more than 5 years compared to about 20 percent before the crisis. Today, the Fed holds very few short-term Treasury securities.\n\nThe changes in the Fed’s balance sheet as well as the evolution of the Fed’s forward guidance have raised some challenges about how to move back from extraordinary monetary policy to ordinary monetary policy, what the Fed has called normalization. In my remaining minutes, I would like to discuss some of the Fed’s plans for addressing those challenges.\n\nMoving from Extraordinary Back to Ordinary\n\nThe FOMC has been preparing for policy normalization for quite some time. The FOMC first laid out exit strategy principles in June 2011; these were updated last September to take into account the changes in the Fed’s balance sheet. Just as it did before the Great Recession, the FOMC plans to implement monetary policy by adjusting short-term interest rates. It will communicate changes in the stance of policy by changing the target range for the fed funds rate.\n\nBut because the level of excess reserves held by banks is now much larger, the tools the FOMC will use to move the funds rate into the target range will be different than before the crisis. In particular, in October 2008 Congress gave the Fed the authority to pay interest on the reserve balances that banks and other depository institutions hold at the Fed. The Fed will use the interest rate it pays on excess reserves, the IOER rate, as the main tool for moving the funds rate into the target range. Raising the IOER rate will put upward pressure on the fed funds rate because banks will be unlikely to accept a rate in the market lower than the one they could get by depositing their funds at the Fed. We expect that while reserves are so plentiful and because not all financial institutions holding reserves are eligible to receive interest, the fed funds rate will trade somewhat below the IOER rate.\n\nIn addition to IOER, the Fed will use other tools, as needed, to ensure adequate control of the policy rate. One of these tools is an overnight reverse repurchase agreement facility. Overnight reverse repos, or ON RRPs, involve the Fed selling securities from its large portfolio of assets with an agreement to buy them back the next day at a pre-determined price from eligible counterparties, including banks, primary dealers, money funds, and government-sponsored enterprises. By offering a safe overnight asset for a broader array of money market participants, some of whom are not eligible to receive interest on reserves, overnight reverse repos should help put a firmer floor on the fed funds rate. These counterparties should be reluctant to lend their liquidity in the market at rates lower than what they could get at the Fed via this facility. The Fed has been testing overnight reverse repos, and the results to date suggest that they have been helpful in firming the floor on money market rates.\n\nThe FOMC has indicated that the overnight reverse repo facility will be used only to the extent necessary and will be phased out when no longer needed to help control short-term interest rates. This will help to ensure that the facility doesn’t lead financial institutions to permanently change the way they do financial intermediation. In addition, the Fed has been testing usage caps on overnight reverse repos and other design features. These would help mitigate the possibility that during times of financial stress the facility would attract liquidity from the market, thereby increasing the level of stress in the market. And the Fed is considering other tools, like term deposits and term RRPs, that could absorb some of the excess reserves in the banking system.\n\nThe Fed’s ability to pay interest on excess reserves, along with supplementary tools like overnight reverse repos, will allow the Fed to move interest rates up to target when it is appropriate to do so, despite the large size of the Fed’s balance sheet.\n\nOver the longer run, the Fed’s balance sheet will return to a more normal size and composition. The FOMC intends to reduce security holdings in a gradual and predictable way, primarily through ending reinvestment of principal payments on securities it holds and letting the securities mature and run off the balance sheet. At this point, the FOMC doesn’t anticipate selling the agency mortgage-backed securities on its balance sheet as part of the normalization process, although it might engage in limited sales in the longer run to reduce or eliminate residual holdings.\n\nThe evolution of the language in the FOMC’s statement, in particular its forward rate guidance, also poses some challenges for the FOMC. While explicit forward guidance was used as a policy tool during the recession and earlier in the recovery, in more normal times, away from the zero lower bound, I believe forward guidance should be viewed more as a communications device. As such, I would like to see the forward guidance evolve over time to give more information about the conditions we systematically assess in calibrating the stance of policy to the economy’s actual progress and anticipated progress toward our dual-mandate goals. It would articulate the considerations the Committee would take into account when determining future changes in policy, as well as information to help the public anticipate how policy is likely to change in response to changes in economic developments that affect the economic outlook. To the extent that households and businesses understand policymakers’ reaction function, their policy expectations will better align with those of policymakers, thereby making policy more effective. As normalization proceeds, I expect we will be able to make more progress along these lines.\n\nConclusion\n\nIn summary, the Federal Reserve took some unprecedented policy actions in response to the financial crisis and deep recession. These extraordinary actions helped support progress toward the Fed’s goals of price stability and maximum employment. At the same time, they present some challenges for the return to ordinary monetary policymaking. But the FOMC has plans to address those challenges. It has laid out how it anticipates conducting monetary policy during normalization. In addition, the FOMC’s forward guidance on the future path of policy has been evolving. Most times in life, moving from extraordinary to ordinary is considered a bad thing. In the case of monetary policy, such a move should be viewed as a good thing – because it means conditions are in place for a sustainable economic expansion with maximum employment and price stability."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "March 09, 2015",
        "title": "The Outlook for the Economy and Monetary Policy Communications",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - 31st Annual NABE Economic Policy Conference - Washington, DC - March 9, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20150309-the-outlook-for-the-economy-and-monetary-policy",
        "content": "Good afternoon. I thank the National Association for Business Economics for inviting me to participate in this year’s Economic Policy Conference. As an economist and policymaker, I appreciate learning the perspective of market and business economists. Just as the different views expressed by my colleagues around the FOMC table help to inform my own policy views, the insights of economists like you, whose business it is to forecast economic developments, help to shape my own economic projections.\n\nToday, I will present my outlook for the economy and monetary policy, and then turn to the important role clear communications can play in setting monetary policy. As always, the views I’ll present today are my own and not necessarily those of the Federal Reserve System or of my colleagues on the Federal Open Market Committee.\n\nThe Economic Outlook\n\nIt has been almost six years since the start of the recovery from the Great Recession. Although it hasn’t been the smoothest of rides, the economy has made significant progress. While there are a number of risks to the forecast – which you business economists know is always the case – I believe the improvement in underlying fundamentals points to an economy that has built sustainable momentum.\n\nMy optimism stems from the fact that a number of the so-called headwinds that held back growth earlier in the recovery and dampened the transmission of very accommodative monetary policy to the economy have waned. The Great Recession wreaked havoc on household and business balance sheets. But balance sheets have improved substantially over the expansion. Households have reduced debt levels relative to disposable income from a peak of 130 percent before the recession to about 100 percent today. Very low interest rates mean that households are spending less to service their debt. And thanks to higher prices of equities and houses, households have more than made up the $10 trillion in net worth destroyed in 2008. U.S. businesses are also in better financial condition after deleveraging. They are positioned to expand investment and hiring, and both are happening.\n\nThe headwind from government spending is also abating. Government spending declined over 2010 to 2013, but began to rise again last year. With tax revenues recovering, state and local governments have been adding to their payrolls and increasing expenditures. The drag from federal government spending has lessened over time.\n\nThe banking sector is regaining its health, with higher capital levels and lower loan delinquencies. Bankers are working through the new regulatory requirements and augmenting systems to better monitor and evaluate risks in their portfolios. Loans to consumers and businesses are now rising and delinquencies and write-offs are at low levels.\n\nAs the headwinds continue to diminish, we now also have a tailwind in the form of lower oil prices. No doubt, the drop in oil prices has led to reduced investment and dislocation in parts of the domestic energy sector, and this is affecting growth in certain regions of the country. However, for an oil-importing country like the U.S., the benefits of lower energy prices will offset the costs and result in a net positive for the U.S. economy in terms of consumer, business, and local government spending.\n\nDespite the positives, I should note that not all sectors will be equal contributors to growth. I don’t expect housing to come back strongly this year. However, easing of mortgage credit conditions will help support continued moderate improvement in housing.\n\nNet exports are also unlikely to contribute much to U.S. growth this year. The relative strength of the U.S. economy compared to that of many of our trading partners has contributed to a more than 10 percent appreciation in the broad value of the dollar over the past year and has meant a slowdown in U.S. export growth. Accommodative monetary policy actions have brightened the outlook for European economies, but growth and inflation are likely to remain low in the Eurozone for a while longer.\n\nIn addition, the harsh weather that has plagued most of the U.S. this winter will likely be a drag on growth in the first quarter. But I believe the effect will be temporary, as it was last winter. While some of the regional manufacturing surveys have come in a bit softer of late, I expect that softening reflects temporary factors and typical month-to-month variability rather than something more fundamental.\n\nOn balance, my modal outlook is for the U.S. economy to grow at about a 3 percent pace over 2015 and 2016. This is somewhat above my estimate of 2.5 percent longer-run growth, and is strong enough to support continued improvement in labor markets.\n\nIndeed, we have seen a significant improvement in labor market conditions. Last year, average monthly job growth strengthened to 260,000 jobs. Over the first two months of this year, average monthly gains increased again, to 267,000 jobs, despite the chilly winter weather. Nonfarm payrolls are now about 2.7 million above their pre-recession peak.\n\nIn February, the unemployment rate fell to 5.5 percent, down sharply from its peak of 10 percent in 2009 and more than a full percentage point lower than it was last February. I continue to view the unemployment rate as a useful indicator of labor market conditions. Some people feel its sharp decline is overstating the improvement in labor markets because of the confounding effect of cyclical declines in labor force participation. However, research, including some by my staff at the Cleveland Fed, finds that a large part of the decline we have seen in labor force participation since 2007 reflects a longer-run structural trend driven by factors like the aging of the population.1 Aging will also lead to declines in the employment-to-population ratio over time, yet last year, we saw a nice increase in this ratio as the acceleration in hiring was enough to overcome the effect of demographics. In addition, although they haven’t yet reached their pre-recession levels, we’ve seen significant declines in the broader measures of the unemployment rate such as those that include discouraged workers and those that include people working part-time who would prefer to work full-time.\n\nIn my view, taken together, labor market indicators point to an economy that is near the Fed’s goal of full employment. I expect the unemployment rate to decline to 5-1/4 percent or lower by the end of this year, somewhat below my longer-run estimate of 5-1/2 percent. Although wage growth has been subdued, it typically lags improvement in labor market conditions, and as employment continues to grow, I anticipate that wages will begin to accelerate and provide support for stronger consumer spending.\n\nConsumer price inflation has also been running below the Fed’s 2 percent objective, and I continue to monitor inflation developments closely. The sharp decline in oil prices is showing up in much lower headline inflation numbers, and the appreciation of the dollar has led to lower prices of imports. I expect further declines in inflation in the near term, but those should prove transitory as oil prices stabilize. I am reasonably confident that inflation will gradually return to the Fed’s goal by the end of next year as above-trend economic growth continues.\n\nI base this view on a couple of factors. First, while there has been some pass-through of oil-price declines to core measures of inflation that remove volatile food and energy prices, the pass-through has been relatively modest. For example, the Cleveland Fed’s median CPI measure has remained near 2-1/4 percent since last April. Cleveland staff research has found that this measure has some predictive power for headline inflation over the medium term.2 In addition, in my view, inflation expectations remain well-anchored. The survey-based measures of inflation expectations of both consumers and of professional forecasters have been fairly stable. These survey measures have historically done well at capturing longer-run trends in inflation and they have been shown to help forecast inflation.3 I am not inclined to take much of a signal about inflation expectations from the recent declines in market-based measures of inflation compensation based on the spread between yields on 10-year Treasury securities and 10-year Treasury inflation-protected securities, so-called TIPS. These market measures are likely being affected by the flight-to-quality flows into Treasuries from abroad, reflecting liquidity effects and changes in inflation risk premiums more so than inflation expectations.\n\nIt is important to recognize that forecasting inflation with any precision is very difficult. The confidence bands around the forecasts tend to be wide. For example, historical average projection errors across a range of private-sector and government forecasts indicate that the 70 percent confidence interval around a forecast of CPI inflation one year out is about plus or minus 1 percentage point.4 So when I say I am “reasonably confident” that inflation will return to target by the end of next year, it is within that context – I am not requiring higher-than-normal precision around the forecast. I see quite a bit of difference between the situation in Europe, where inflation has been falling and growth has been weak, and the situation in the U.S., where an oil-price shock is driving down headline inflation rates and the economy is strengthening. We have been climbing out of a very deep recession and have experienced a negative oil-price shock. So long as inflation expectations remain anchored and growth continues to be at or above trend, I am comfortable with it taking some time for inflation to return to our 2 percent goal. Of course, my projection is dependent on appropriate monetary policy, so let me discuss that next.\n\nMonetary Policy\n\nThe financial crisis and the ensuing deep recession required an aggressive policy response. To support its goals of price stability and full employment, the FOMC has kept the federal funds rate at essentially zero since the end of 2008 and it conducted asset-purchase programs to exert downward pressure on long-term interest rates. This extraordinarily accommodative monetary policy has provided important support to the economy, helping to promote stronger labor markets and the pickup in growth that underlies my projection of a gradual return of inflation to our goal over time.\n\nBecause monetary policy affects the economy with a lag, policy needs to be forward looking and rates will need to begin to move up before we have fully reached our goals. Even after the first rate increase, policy will remain very accommodative for some time and this will promote attainment of our policy goals. The economy is now on firmer footing and our monetary policy stance should reflect that. Indeed, if incoming economic information continues to support my forecast, I would be comfortable with liftoff in the first half of this year. I would like our policy statement to allow for this possibility. However, I also want to emphasize, as the FOMC has, that policy is not on a pre-set path. Both liftoff and the path of policy thereafter will be based on incoming information to the extent that it affects the economic outlook and progress toward our goals of maximum employment and price stability.\n\nAt next week’s FOMC meeting, participants will have the opportunity to discuss their various views of the economic outlook and assessments of appropriate policy and I am looking forward to a fruitful discussion among my FOMC colleagues. One of the great strengths of the Fed is its structure. It is a decentralized central bank, which is independent within the government but not independent from the government. The Fed’s structure is one of balance. It includes representation from across the nation, balancing public-sector and private-sector interests, and Wall Street and Main Street concerns. The various viewpoints expressed in our discussions of economic conditions, models, and forecasts help the FOMC set monetary policy in pursuit of our congressionally mandated goals on behalf of the public interest.\n\nSince the FOMC has been given the responsibility to set monetary policy, it is incumbent upon us to explain the rationale for our policy decisions. The Committee has been on a journey toward increased transparency for quite some time. As the time for policy normalization grows nearer, clear communication is becoming ever more important. The better we can communicate our monetary policy framework and the basis for policy decisions, the more likely we can avoid undesirable disruptions and turbulence that could result from misunderstandings as we progress to a more normal policy stance. Of course, clear communication is not without challenges. Concepts like data dependency and forward-looking monetary policymaking might be fairly routine for business economists like you, but they are tougher to explain to the public at large. I would like to finish up my talk today with four concrete suggestions for how we might improve our monetary policy communications over the medium to longer run.\n\nSteps Toward Clearer Communications Over the Medium to Longer Run\n\nFirst, presenting a forecast that could serve as the benchmark for understanding the FOMC’s policy actions and post-meeting statements would be an aid to communication. Such a forecast would make it easier to explain how the economic outlook is dependent on the future path of monetary policy. It would clarify that for the FOMC to achieve its policy goals over the longer run, rates will need to begin rising before both goals are fully attained. Several central banks publish a forecast as part of their communications; in some cases, it is the policymakers’ forecast and in other cases it is a staff forecast. The FOMC experimented with developing a forecast representing the consensus of the Committee in 2012.5 But it proved difficult to reach a consensus on a consensus forecast. I believe there would be value in having such a benchmark forecast, and I think it should remain on our longer-run agenda of communication enhancements. But I also realize it will not be an easy task to accomplish.\n\nIn the meantime, the Summary of Economic Projections – or SEP – has been playing an important role in conveying the FOMC’s economic outlook. Four times a year, the SEP provides information on the range of projections of real output growth, the unemployment rate, and inflation across participants, as well as the policy paths that individual participants view as appropriate in achieving those projections.\n\nMy second suggestion for improving communications is to link the variables in the SEP. That is, instead of presenting ranges, the SEP could indicate what each policymaker is projecting for growth, unemployment, and inflation, and what policy path he or she believes will achieve those outcomes. This could be done without revealing the identities of the participants. Linking the variables would convey information on each individual policymaker’s view of the relationship among the variables and on his or her monetary policy reaction function – how the outlook is expected to play out under the policy path chosen.\n\nMy third suggestion is to enhance the SEP by providing more information on policymakers’ views about the uncertainty around their projections. As I discussed earlier, error bands around forecasted variables can be wide; they can also vary over the business cycle. It might seem counterintuitive that presenting information on uncertainty would actually help clarify things. In general, people like certainty. But the future path of policy is not certain because the evolution of the economy is not certain. In my view, giving the public a better sense of the probabilities associated with the projections would help them understand the current forecast, differences among forecasters, and subsequent changes to the forecast.\n\nMy fourth suggestion pertains to the structure of the FOMC’s post-meeting statement. The statement continues to serve the Committee well. But I believe we could simplify its organization to better illuminate that policy is being formulated based on the economic outlook and on realized and anticipated progress toward our policy goals. In this reorganized statement, economic developments would be discussed – not merely the changes in conditions but also the Committee’s assessment of whether these changes are material enough to have affected the Committee’s economic outlook. There would be more consistency about the conditions we systematically assess in calibrating the stance of policy so that the public would get a better sense of the Committee’s reaction function over time. The statement would then summarize the Committee’s outlook for progress toward its policy goals and the risks to that outlook. Of course, the outlook is dependent on the current and future stance of policy. So the statement would then describe the current stance of policy and any policy actions taken. This would include the funds rate, asset reinvestments, and any other policy tools being used. The statement would conclude by providing some information on the future path of policy. Depending on economic circumstances, this might be explicit forward guidance that serves as a policy tool, as it did during the Great Recession and early part of the recovery. But during more normal policy-setting times, the statement would, instead, provide a rationale for future policy decisions. It would articulate the considerations the Committee would take into account when determining future changes in policy, as well as information to help the public anticipate how policy is likely to change in response to changes in economic developments that affect the economic outlook. To the extent that households and businesses understand policymakers’ reaction function, their policy expectations will better align with those of policymakers, thereby making policy more effective.\n\nConclusion\n\nIn summary, the economy is making substantial progress toward the Federal Reserve’s goals of maximum employment and price stability. If incoming information is consistent with my forecast, I believe it will soon be appropriate to begin raising the fed funds rate from its extraordinarily low level. The path of rates thereafter will continue to depend on the assessment of incoming information relative to the economic outlook and on realized and expected progress toward our monetary policy goals. Although policy communication will likely always remain somewhat of a challenge, I believe the benefits of clearer communication are worth the effort. Better communication is not merely an aspirational goal. I have offered some concrete suggestions on how we might make progress over the medium to longer run in improving our policy communications and, with it, the effectiveness of our monetary policy."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "February 27, 2015",
        "title": "Comments on “The Equilibrium Real Funds Rate: Past, Present, and Future.”",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - 2015 U.S. Monetary Policy Forum, sponsored by the Initiative on Global Markets - University of Chicago Booth School of Business - February 27, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20150227-comments-on-the-equilibrium",
        "content": "It is a real pleasure for me to participate in this year’s Monetary Policy Forum. As an attendee of this event for the past several years, I have been very impressed with the organizers’ ability to choose a year in advance the topic that turns out to be the issue policymakers are grappling with at the time the forum rolls around. Once again, the organizers have been able to do this, with the important paper by Jim Hamilton, Ethan Harris, Jan Hatzius, and Ken West. Another example of the value of being forward looking when it comes to monetary policy!\n\nIn the time I have, I will discuss some of the highlights of the paper – some of which the authors have laid out as “lessons learned” from history. I’ll focus on measurement and implications for policy. Taking their lead, I’ll present five of my own lessons spurred by reading their interesting paper. Of course, the views I’ll present today are my own and not necessarily those of the Federal Reserve System or my colleagues on the Federal Open Market Committee.\n\nMeasurement\n\nThe authors have done a very good job of examining the question, “Is there a new neutral or equilibrium real federal funds rate?” This is a deceptively simple question that hits on bigger issues such as whether the U.S. has drifted into “secular stagnation” and what the implications for monetary policy normalization are.\n\nThe first part of the paper is a thorough analysis of what the historical data and record can tell us. The authors have amassed an impressive data set on 21 countries, with annual data in some cases going back to 1858 and quarterly data back to 1958. Where the data are available, the authors use the discount rate set by the central bank as the interest rate of interest; in some cases, they have spliced together series. For example, in the U.S. for the annual dataset they use the discount rate over 1914-1953 and the average fed funds rate during the last month of the year from 1954 to present. As anyone who has put together data sets for research knows, this effort is not trivial.\n\nOf course before the empirical analysis can commence, it is important to understand what is meant by the “equilibrium federal funds rate” or more generally, the “equilibrium policy rate.” It is a fuzzy concept. There are several definitions in the literature. Moreover, several different terms in the literature, such as the equilibrium rate of interest, natural rate of interest, and neutral rate of interest, refer to the same object.\n\nThe paper’s definition is one that many economists use: the equilibrium real rate, r*, is that level of the policy rate that is consistent with full employment and stable inflation in the medium term. Sometimes instead of full employment a zero output gap or growth at potential is used. Presumably the stable inflation rate referred to is the policymakers’ target inflation rate. What’s undefined here is the meaning of “medium term.”\n\nThis r* is an important concept in monetary policy as it gives one a way to think about the degree of policy accommodation. For example, in a Taylor rule,\n\n\n\n\n\nThe big issue is that the equilibrium real rate, r*, is unobserved. Incidentally, so are the level of potential output and the natural rate of unemployment, which loom large in monetary policy discussions. The fact that r* is unobserved has been recognized by many economists over many decades. The authors explore several time-series approaches to estimating the real rate.\n\nOne approach is to estimate the real rate using averages over a cycle or longer of estimates of the ex ante real rate, defined as the nominal interest rate minus expected inflation,\n\nIf policymakers are setting the nominal interest rate, so that on average, the output gap (or unemployment gap) is zero, inflation is equal to target, and expected inflation is equal to target, then the ex ante real interest rate will equal the equilibrium real rate as defined by the authors. To see this, suppose policymakers are following a simple Taylor rule, then:\n\n\n\nThe authors’ empirical investigation indicates that estimates of the ex ante real rate have varied considerably over time. They show that the correlations between estimates of the ex ante real rate and output growth vary over the sample period and are sensitive to the time period examined and countries included. They also include a narrative review of the history of the U.S. ex ante real rate. This is interesting because it points out some of the factors that theory tells us might influence the real rate of interest. Based on this analysis, drawing on the connection between the ex ante real rate and the equilibrium rate, the authors conclude that it would be a mistake to estimate the equilibrium rate using long historical averages (this is their history lesson 2).\n\nIt is hard to dispute this and I don’t find it surprising. Indeed, Wicksell, in his seminal work Interest and Prices, says:\n\n- Knut Wicksell, Interest and Prices, 1898, p. 106\n\nWhich brings me to my first lesson from the paper:\n\nThe equilibrium real interest rate is an equilibrium concept. As such, it will vary with conditions that affect the demand for investment and the supply of savings. Because of this, it is difficult to estimate the equilibrium real rate using statistical approaches.\n\nAveraging real interest rates to estimate the equilibrium rate assumes that, on average, the real rate equals the equilibrium rate; that is, on average inflation and inflation expectations are at goal and output is at potential. But computing the average for a sample period for which this isn’t the case will yield biased estimates. For example, a sample period dominated by the 1970s in the U.S. would underestimate the equilibrium real rate since it was a period of rising inflation and growth above potential, implying the actual real rate was below the equilibrium real rate.\n\nSeveral other problems in estimating the equilibrium real rate, especially in real time, are discussed by Clark and Kozicki (2005) and Wu (2005). For example, using a filter, like the Kalman filter, to extract the trend based on a model such as the one in Laubach and Williams (2003) runs into problems. If we want to estimate the equilibrium rate today, we can use historical data, but we have no data on what will happen tomorrow. We face a one-sided filtering problem. As we step through time, we will have data beyond today which can be brought to bear in estimating today’s equilibrium rate, and that estimate could look quite a bit different from today’s estimate based only on data up to today. You can see the size of such discrepancies in Exhibit 1.\n\nWe should also keep in mind the data revisions that occur over time in some of the important macroeconomic variables such as output and PCE inflation. The authors of the current paper are using final revised data for their estimations, but the more recent data will be undergoing further revisions. These data revisions make it difficult to estimate the real rate in real time, adding another source of uncertainty to estimates. Clark and Kozicki (2005) show that the data revisions, as well as filtering, can lead to sizable revisions in estimates of the real rate.\n\nThis measurement issue is related to the discussion of secular stagnation. As the authors suggest, we have to be careful in making inferences from the time series. For example, as shown in Exhibit 2, if we look at the authors’ chart of the ex ante real rate, we see a decline in recent years. We might be tempted to extrapolate that decline and conclude that we will experience a lower real rate and lower potential growth in the future – that is, secular stagnation. But we saw a similar decline of the ex ante real rate in the 1930s and 1940s, yet potential growth moved up in the 1950s and 1960s.\n\nThis discussion of the issues that arise when using a purely statistical approach leads me to a second lesson:\n\nSince the equilibrium real rate is endogenous, a theoretical model (or models) should be brought to bear to better understand the factors that will influence supply and demand and, therefore, the equilibrium rate. The natural rate in a DSGE model would be a good yardstick for evaluating the stance of monetary policy.\n\nI find dynamic stochastic general equilibrium (DSGE) models helpful in thinking about the economy. Not because they necessarily produce the best economic forecasts but because they provide an organized way to examine certain policy questions owing to their structural nature. Because they are structural models, they are a tool for better understanding the general equilibrium aspects of the economy. In contrast to reduced-form models, they build up from micro foundations, specifying agents’ objectives and constraints. And because agents are forward looking, expectations of future economic conditions and policy play a key role in determining economic outcomes. These expectations are endogenous and help determine agents’ decisions today, and therefore current economic outcomes. The models are stochastic in nature and economic shocks to supply and demand – e.g., changes in productivity, changes to the price of oil, changes to the rate of time preference, changes to the efficiency of financial intermediation – will generate economic fluctuations. Another important ingredient in the models is the presence of nominal rigidities – firms are price and wage setters, but are assumed not to be able to adjust prices instantaneously in response to a shock. So prices and wages exhibit some stickiness.\n\nWithin the context of a New Keynesian DSGE model, the equilibrium real rate of interest, or natural rate of interest, is that interest rate that keeps the economy’s output at the level that would prevail if all wages and prices were flexible and in the absence of shocks to wage markups, price markups, technology, and preferences. In much of the DSGE literature, this level of output is called the efficient level of output, and it corresponds to the concept of the potential level of output in other models. It is this equilibrium rate that provides a metric for measuring the stance of monetary policy in a DSGE model (see Barsky, Justiniano, and Melosi, 2014).\n\nWhile the definition of the equilibrium rate in the DSGE model abstracts from some shocks, the economy is subject to a large number of other types of shocks. So this theoretical approach suggests that the equilibrium real rate should vary over time. Moreover, the equilibrium rate is likely to be more variable than the estimates derived from statistical trends, since the theoretical concept of efficient output is more variable than the statistical concept of potential output derived from a trend in the output data.\n\nThus, I agree with the authors’ basic premise that the equilibrium rate should move with the economy. But I get there via a somewhat different route.\n\nWhile the DSGE or other structural models provide a conceptual advance, we do not have a definitive model. Models vary with respect to the types of shocks and number of sectors incorporated. Estimates of the equilibrium rate will be model dependent. Hence, the uncertainty uncovered by the authors using the statistical approach is not resolved in this model-based approach.\n\nImplications for Monetary Policy\n\nAfter documenting the large amount of uncertainty around estimates of the equilibrium real rate, the authors then turn to the implications for monetary policy – as a general proposition and for current policy. The authors make a compelling case using simulations of the Fed’s FRB/US model that when the central bank is uncertain about r*, incorporating inertia into the policy rule it would use if r* were certain, i.e., basing the current policy rate prescription less on the uncertain measure of the equilibrium real rate and more on the past level of the policy rate, can lead to lower economic losses.\n\nAs the authors point out, this result is consistent with work by Orphanides and Williams (2002, 2007) and others in the literature that shows that over-reliance on mismeasured objects such as output gaps, unemployment gaps, or equilibrium real rates can lead to poor policy decisions that induce undesirable fluctuations in the economy. Inertial policies can reduce the direct effect of the mismeasurement of r*, but they can also carry forward the policy errors generated by mismeasurement of the output gap. So it is not a given that inertia is always better; it will depend on the degree of mismeasurement and the structure of the model economy used in the analysis.\n\nThis leads me to a third lesson:\n\nMismeasurement may be one reason to favor more inertial policy rules, but there are others, including the zero lower bound.\n\nFor example, Reifschneider and Williams (2000) show that when the policymaker has perfect credibility, then augmenting a baseline rule to incorporate a response to periods in which the rule had been constrained by the zero lower bound can reduce the bad effects of the zero bound. This would have the impact of delaying an increase in the policy rate from the zero lower bound.\n\nIn Exhibit 3 I show this type of augmentation using the simple Taylor 1993 rule as the base rule. (Note, I chose Taylor 1993 for illustrative purposes and because it is simple and well known, not because I believe policy should necessarily follow this particular rule.)\n\nThe top panel illustrates the rule for r* = 2 and the bottom panel for r* = 1.5. In both cases, the rules suggest a liftoff but one that is delayed from what the standard Taylor rule indicates. The longer the zero lower bound has been binding, the longer the delay. Essentially, the rule keeps the funds rate unusually low for a period of time immediately after an episode of zero interest rates; that is, it incorporates a Woodford (2012) period.\n\nWhile I find the authors make a plausible case for using more inertial rules when r* is measured with error, I find their conclusions for current policy less salient. In exercises such as this, one must generate a baseline from which to measure differences. The authors assume that Fed policymakers are using the Taylor (1999) rule, so their conclusions about the exact timing of liftoff are contingent on that assumption.\n\nWhich brings me to my fourth lesson:\n\n“More inertia” is a relative statement. Other factors argue against being too inert. These include less than perfect commitment and communication, (unmodeled) implications for financial stability, and uncertainty aversion.\n\nThe results on inertia depend on agents understanding the policymaker’s reaction function and the policymaker being committed to following that reaction function. If the policymaker hasn’t effectively communicated and the public doesn’t understand the reason for the central bank’s policy path, a delay in liftoff with steeper path after liftoff may be misinterpreted. The public might believe that central bankers are holding rates low for longer because they have a gloomy outlook; this would not necessarily yield better economic outcomes.\n\nIn addition, while I am a firm proponent of using models to inform our policy decisions, there is some bias in the models. Our typical models can give us a pretty good sense of the employment and inflation costs of lifting off sooner rather than later. But they are less likely to be able to quantify the costs of waiting too long. For example, our models aren’t well enough developed to allow us to quantify the risks to financial stability of holding rates at zero for a long time, yet the crisis showed us that financial instability comes with a very high cost.\n\nThe results on inertia also depend on how policymakers react to the uncertainty they encounter. In the paper, policymakers make policy decisions assuming a particular value of r* in their policy rule. If it turns out that that measure is incorrect, then there are economic losses. The authors show that a policy rule that incorporates inertia can lead to lower losses based on a quadratic loss function.\n\nBut the world and decision making are more complicated than that. Policymakers know they don’t know the precise value of r*. Rather than a point distribution, they have beliefs over the value of r*. Only if their beliefs are described by a single distribution and the world is described by a linear-quadratic model would they base decisions on the mean of that distribution. Instead, if policymakers are aware of their own uncertainty about their models and data, and they are averse to uncertainty, then inertia need not be optimal. Giannoni (2002, 2007) shows that with forward-looking agents, if there is model uncertainty, then uncertainty-averse policymakers will follow a min-max strategy that aims to minimize the costs of worst-case scenarios. Their optimal policy rule will react more strongly to fluctuations in inflation and the output gap than if there were no uncertainty. Policymakers would put more weight on stabilizing inflation and the output gap and less weight on stabilizing the nominal interest rate.\n\nThis brings me to my final lesson:\n\nImplications for the timing of liftoff depend on the rule adopted. A difference rule is an alternative to inertia for handling mismeasured levels of the equilibrium real rate and the natural rate of unemployment. The policy path from such a rule differs from that of the inertial rule.\n\nA difference rule, such as those suggested by Orphanides and Williams (2002), would allow the policymaker to avoid having to estimate natural rates of interest or unemployment. As seen in the top panel of Exhibit 4, where the red line is a smoothed version of the difference rule, such a rule would have avoided the mistakes of the 1970s, when policymakers kept the policy rate too low. The bottom panel zooms in on the current period. Such a rule would call for higher interest rates today.\n\nTo conclude, I really appreciate the opportunity to comment on this fine paper. I recommend that everyone read it. The authors have provided a lot of food for thought. I have discussed five lessons I drew from their paper, but their work also underscores the importance of remembering what we don’t know and of remaining humble when it comes to setting monetary policy.\n\nSource: Figure 3 from Tao Wu, “Estimating the ‘Neutral’ Real Interest Rate in Real Time,” Federal Reserve Bank of San Francisco, Economic Letter, No. 2005-27, October 21, 2005.\n\nSource: Figure 3 from Tao Wu, “Estimating the ‘Neutral’ Real Interest Rate in Real Time,” Federal Reserve Bank of San Francisco, Economic Letter, No. 2005-27, October 21, 2005.\n\nSource: Figure 3 p. 407: Todd E. Clark and Sharon Kozicki, “Estimating Equilibrium Real Interest Rates in Real Time,” North American Journal of Economics and Finance 16, 2005, pp. 395-413.\n\nSource: J.D. Hamilton, E.S. Harris, J. Hatzius, and K.D. West, “The Equilibrium Real Funds Rate: Past, Present, and Future,” February 2015.\n\nSource: David Reifschneider and John C. Williams, “Three Lessons for Monetary Policy in a Low-Inflation Era,” Journal of Money, Credit, and Banking 32, November 2000, Part 2, pp. 936-966; author's calculations\n\nSource: Athanasios Orphanides and John C. Williams, “Robust Monetary Policy Rules with Unknown Natural Rates,” Brookings Papers on Economic Activity 2, 2002, pp. 63-145; author's calculations."
    },
    {
        "speaker": "Loretta J. Mester",
        "date": "February 04, 2015",
        "title": "The Outlook for the Economy and Bank Regulation",
        "highlights": "Speech by Loretta J. Mester, President and Chief Executive Officer, Federal Reserve Bank of Cleveland - Ohio Bankers League 2015 Economic Summit - Columbus, OH - February 4, 2015",
        "href": "https://www.clevelandfed.org/collections/speeches/sp-20150204-the-outlook-for-the-economy-and-bank-regulation",
        "content": "Good afternoon. I thank the Ohio Bankers League for inviting me to participate in this year’s economic summit. It is a pleasure to have the opportunity to speak with so many leaders from the state’s banking community. I’m glad to be here with my colleague Steve Jenkins, whom many of you know well and who will be speaking later today. It is also great to be in Columbus, where it seems as if the euphoria from The Ohio State University’s national championship isn’t going to wear off any time soon.\n\nToday, I will share my views on the outlook for the U.S. economy and monetary policy in 2015. Given the important role financial institutions play in the economy, I also want to offer some perspectives on banking supervision and regulation. Of course, the views I’ll present today are my own and not necessarily those of the Federal Reserve System or my colleagues on the Federal Open Market Committee.\n\nThe Economic Outlook\n\nThe U.S. economy begins 2015 in its sixth year of expansion. The trip out of the Great Recession hasn’t broken any speed limits. For most of the journey, the economy has been traveling at a relatively slow to moderate pace, and it’s taken several rest stops along the way. But the recent data on the real side of the economy have been encouraging. There are accumulating signs that the economy is building momentum and that, this time, a pickup in speed will be sustained because the underlying fundamentals have improved.\n\nLast year’s severe winter helped spur an annualized decline of about 2 percent in real output in the first quarter. Growth rebounded to about 4 percent over the remainder of last year, quite a bit higher than the average growth rate of around 2 percent over the prior three years. Many of the so-called headwinds that held back the pace of growth earlier in the expansion and dampened the effect of very accommodative monetary policy on the economy have abated, suggesting that the economic momentum at the start of this year is likely to be sustained.\n\nOne of those headwinds has been the deleveraging that households and businesses had to do after the Great Recession. Consumer balance sheets have improved significantly over the expansion. Household debt relative to disposable personal income peaked at 130 percent prior to the recession but is now closer to 100 percent and has leveled out over the past couple of years. Very low interest rates mean that households are spending less to service their debt. And thanks to higher prices of equities and houses, households have more than made up the $10 trillion in net worth destroyed in 2008. The rise in home prices means that fewer households are underwater on their mortgages and mortgage delinquencies are down. Businesses also had to deleverage. But now business balance sheets are quite healthy. Business sentiment is positive and supportive of higher levels of investment and stronger hiring.\n\nAnother headwind came from the government sector. Government spending has been a drag on growth during much of the expansion. Unlike in most earlier recoveries, government payrolls actually fell during much of this expansion. Last year, buoyed by stronger tax revenues, state and local governments added to their payrolls after a meager increase in 2013 and declines in the prior four years. State and local government spending made a net positive contribution to real output growth last year, and the drag from federal government spending is waning.\n\nOf course, this audience doesn’t need to be reminded of the repairs that had to be made to bring the banking sector back to health in the wake of the Great Recession. Now that banks are recapitalized they are in a better position to take appropriate risks. Loans to consumers and businesses are rising and delinquencies and write-offs are at low levels.\n\nAt the same time the headwinds have diminished, we now have a tailwind in the form of lower oil prices. Last July, oil was selling at around $110 a barrel. Now the price is near $50. While the drop in oil prices will lead to some reduced investment and dislocation in parts of the domestic energy sector, lower oil prices will be a net positive for the U.S. economy. The lower costs of fuel to consumers, businesses, and local governments will support higher spending elsewhere. The U.S. Energy Information Administration is projecting that the average U.S. household will spend about $550 less on gasoline this year than it did last year. This will put money into people’s pockets that can be spent on other goods and services.\n\nBased on the improvement in fundamentals, as well as the fall in energy prices, and with the usual caveats that there are risks around any forecast, I expect the economy to grow at a 3 percent pace in 2015 and 2016, somewhat above my estimate of 2.5 percent longer-run growth. I don’t expect the housing sector to come back strongly this year, although continued moderate improvement is likely. The improvement will be supported by some relaxation of mortgage credit conditions, which remain fairly tight except for the highest quality borrowers. Net exports are also unlikely to contribute much to U.S. growth. As you are well aware, the U.S. economy is in better shape than the economies of many of our trading partners. Weak demand from abroad will dampen U.S. exports but will be more than offset by healthy domestic consumer and business spending that will support above-trend economic growth this year.\n\nThe increased momentum in the economy reflects a significant improvement in labor market conditions, which is seen across a broad number of indicators. On average, firms added 246,000 jobs per month last year, up from an average of 194,000 in 2013 and 186,000 in 2012. Nonfarm payrolls are now 2 million above their pre-recession level.\n\nThe unemployment rate is now 5.6 percent. This is down from a peak of 10 percent in 2009 and a full percentage point lower than it was last January. For several years now, the decline in the unemployment rate has been faster than many economists and policymakers thought it would be. For example, in December 2013, participants on the Federal Open Market Committee projected that the unemployment rate would be between 6.2 and 6.7 percent by the end of 2014. We are now well below that range.\n\nBroader measures of the unemployment rate are also down considerably since the start of the expansion, and their rate of decline is increasing. These measures include those that track people who are working part time but would prefer a full-time job or people marginally attached to the labor force who say they want to work but aren’t actively looking. Improvements are also evident in measures that track the long-term unemployed – people who have been out of work for more than six months. While these broader measures are not yet down to their pre-recession levels, they have all fallen considerably. For example, the Bureau of Labor Statistics’ so-called U6 measure of the unemployment rate, which includes marginally attached workers and people working part-time who want full-time work, fell almost 2 percentage points last year.\n\nI continue to view the unemployment rate as a useful indicator of labor market conditions. However, for those who put less stock in it because of the confounding effect of cyclical declines in labor force participation, I point to the ratio of employment to population. As our population ages, this ratio will naturally decline. Yet last year the acceleration in hiring was enough to overcome the effect of demographics, and we saw a nice increase in the employment-to-population ratio.\n\nLabor market conditions in Ohio have also improved over time, although at a somewhat slower pace than in the rest of the nation. During the recession, Ohio saw a sharper rate of job loss compared to the U.S. Between the start of the recession in December 2007 and the start of the expansion in June 2009, Ohio lost nearly 7 percent of its payroll jobs, while the U.S. lost almost 5-1/2 percent of its jobs. Since the start of the expansion, job growth in Ohio has averaged 1 percent per year. While this is somewhat lower than the 1-1/4 percent per year job growth seen in the nation, it is pretty good performance for Ohio, which usually sees slower job growth compared to the nation because of its industry mix and slower population growth.\n\nDespite the gains we’ve seen in labor markets, wage growth has remained subdued. However, as employment continues to grow, I anticipate that wages will accelerate and help support stronger consumer spending.\n\nConsumer price inflation also remains subdued and is running below the Fed’s 2 percent objective. The sharp drop in oil prices is showing up in much lower headline inflation numbers, and I expect inflation to decline further in the near term. So far, there has been only modest pass-through of those oil price declines to core measures of inflation that remove the volatile food and energy components. The Cleveland Fed’s median CPI measure has remained near 2-1/4 percent since last April, and as shown in Cleveland Fed staff research, this measure has some predictive power for headline inflation over the medium term.1 My expectation is that inflation will gradually move back up to 2 percent by the end of next year as economic activity continues to strengthen, oil prices stabilize, and inflation expectations remain anchored.\n\nI recognize that continued low readings on headline inflation have the potential to unsettle estimates of inflation expectations, so it is important that we carefully monitor developments on this front. Economists look at several different measures to help gauge inflation expectations. Market-based estimates of inflation compensation based on the spread between the yields on 10-year Treasury securities and 10-year Treasury inflation-protected securities, so-called TIPS, have fallen in recent weeks. However, in periods of highly volatile financial markets and flight-to-quality flows into U.S. securities, like those we’ve been experiencing, it is difficult to parse how much of the decline reflects a change in inflation expectations and how much reflects liquidity effects and changes in inflation risk premiums. In such times, I put more stock in the survey-based measures of inflation expectations, and these have been stable. In addition, while the Cleveland Fed’s own estimate of the 10-year expected inflation rate slipped from 1.85 percent in December to 1.66 percent in January, this reading is essentially in the middle of the range of readings we have seen since the financial crisis. Altogether, based on the various measures, my read is that inflation expectations remain anchored. And so long as that continues and growth doesn’t falter, I am comfortable with the forecast that inflation will move gradually toward the Fed’s 2 percent goal over the medium term, while lower oil prices drive down measures of headline inflation in the near term. Of course, this projection is dependent on appropriate monetary policy. So let me turn to that now.\n\nMonetary Policy\n\nIn response to the financial crisis and deep recession, the Federal Reserve has run an extraordinarily accommodative monetary policy to promote its goals of price stability and maximum employment. The FOMC has kept its policy rate – the federal funds rate – at essentially zero since the end of 2008. This has lent important support to the economy, leading to the substantial progress we’ve seen in labor markets and the pickup in the pace of growth that underlie the projection that inflation will gradually return to our goal.\n\nThe economy is moving back to more normal territory, and as it does, monetary policy should begin to do so too. Because monetary policy affects the economy with a lag, policymakers need to be forward looking. We need to base our policy on both realized and expected progress toward our goals. Based on my forecast and the risks I see around that forecast, I believe it will soon be appropriate to begin moving rates up from zero. Because policy must be forward looking, in my view liftoff should occur before our goals are fully met. But even after liftoff, policy will remain very accommodative for some time, promoting attainment of both goals. Indeed, if incoming economic information supports my forecast, I would be comfortable with liftoff in the first half of this year, but as the FOMC has emphasized, policy isn’t on a pre-set path. Both liftoff and the path of policy thereafter will be based on incoming information to the extent that it affects the economic outlook and progress toward our goals of maximum employment and price stability.\n\nA Tiered Approach to Banking Supervision and Regulation\n\nAs I mentioned earlier, one of the headwinds that held back the pace of economic recovery was the considerable work that had to be done to improve the health of the financial system after the financial crisis. I wouldn’t want to conclude my talk to this group without acknowledging the key role that banks play in providing valuable credit, risk-management, and liquidity services to businesses and households.\n\nWhile banks are designed to take risks, operate with leverage, and are subject to oversight, we saw during the financial crisis that our system was not without flaws. The Dodd-Frank Wall Street Reform and Consumer Protection Act, signed into law in 2010, includes a number of provisions to strengthen the supervisory and regulatory framework, with the goal of promoting a more resilient financial system. Consistent with the act, the Federal Reserve and other federal banking agencies are taking a tiered approach to banking supervision and regulation. This approach recognizes that the risk a banking organization poses to the financial system is likely to vary according to its size, range of activities, and complexity, and so supervision and regulation should vary as well. For example, individual community banks are subject to regulatory oversight to help ensure they remain sound and able to extend credit and other services to their communities. But the actions community banks take do not typically impose costs on the rest of the financial system or create the kinds of contagion that can put the entire financial system at risk. So community banks shouldn’t be subject to the same types of macroprudential rules and supervision aimed at the systemically important institutions.\n\nThe tiered approach categorizes institutions based on their complexity and the level of risk they pose to the overall financial system, and then tailors oversight appropriately. Doing so will help to reduce the potential costs bankers might face if made to comply with rules that don’t further the goal of a healthy and resilient financial system. It will also free up the bandwidth of examiners and supervisors so they can focus more of their attention on where the risks actually lie. The Federal Reserve has organized its supervision of institutions around four groups of banks: community banks, which are institutions with $10 billion or less in assets; regional banking organizations, with assets between $10 billion and $50 billion; large banking organizations; and systemically important institutions. By appropriately deploying our supervisory resources, we feel we can better promote a healthier, more resilient financial system.\n\nSeveral examples illustrate the tiered approach. Many of the new requirements under Dodd-Frank apply only to the 100 or so banks with more than $10 billion in assets. For example, the nation’s 5,700 or so community banks are not subject to requirements for annual stress testing or resolution planning, but for those banks to which they do apply, the requirements become more extensive for the largest and most systemically important firms. Community banks and smaller regional banks with $50 billion or less in assets are not subject to the quantitative minimum liquidity requirement the Fed approved last year, nor do they fall under the extensive enhanced prudential standards required under Dodd-Frank for bank holding companies with more than $50 billion in assets.\n\nStronger capital requirements are an essential part of the new regulatory system. But the capital positions needed for systemically important banks are higher than those needed for community banks, and after consultations with community bankers, the rules adopted by the federal regulatory agencies reflect this.\n\nAnother more recent example of the tiered approach involves the Federal Reserve Board’s policy statement that allows certain small, noncomplex bank holding companies to operate with higher levels of debt than normal so long as doing so doesn’t compromise safety and soundness. In a recent speech, Federal Reserve Governor Tarullo explained that while the Federal Reserve Board generally discourages the use of debt to finance acquisitions, it recognizes that debt is often needed to finance transfers of ownership of small banks because they have limited access to equity financing.2 Last December, Congress raised the asset-size threshold for bank holding companies qualifying to operate with higher debt from $500 million to $1 billion. Last week, the Fed invited public comment on its proposed rule to implement this law. When final, this rule will raise the percentage of banks qualifying for the policy to nearly 90 percent from 75 percent.\n\nWhat I hope you will take from these examples is that the Federal Reserve recognizes the new regulatory environment poses challenges for bankers. We are committed to ensuring that our implementation of the Dodd-Frank Act does not put undue burden on community banks, but works to foster a healthier and more resilient financial system, which will benefit banks of all sizes and the overall economy.\n\nConclusion\n\nIn summary, I see the economy on firmer footing than it has been for some time. Although there are risks around my forecast, I see growth averaging about 3 percent over the next two years. While the drop in oil prices will lower inflation in the near term, as oil prices stabilize, output and employment growth continue, and inflation expectations remain anchored, I expect inflation to gradually move back to the Fed’s goal of 2 percent. Based on realized and expected progress toward our goals, I believe it will soon be appropriate to begin moving interest rates up from zero. The Committee will base its decision about the timing and path of interest rates on incoming economic information to the extent that it affects the economic outlook and progress toward our goals of maximum employment and price stability.\n\nAs I noted earlier, it takes time for monetary policy to affect the economy. So the public won’t be able to immediately see whether a policy action taken by the Fed was a good one. That is one reason that I believe clear communication about monetary policy is so important. It is incumbent upon policymakers to explain the rationale for their decisions, including their evaluation of economic conditions as well as their outlook for the economy. This is what I tried to do today.\n\nI would like to leave you with one final thought. Congress has set the Fed’s goals but it has also given the Fed independence in making monetary policy decisions in pursuit of those goals. That is, monetary policy decisions do not have to be approved by the president or Congress. This is consistent with a large body of research, both here and abroad, which shows that when central banks formulate monetary policy free from government interference and are held accountable for their decisions, better economic outcomes result. I believe that calls to audit the Fed are misnamed and misguided. Misnamed because they really aren’t about auditing the Fed – the Fed is already subject to many audits of its financial statements and activities, and Chair Yellen regularly testifies before Congress on monetary policy. Misguided because they really are about allowing political considerations to influence monetary policy decisions. This would be a tremendous mistake because it would ultimately lead to poorer economic performance. I strongly believe that the Federal Reserve’s independence in setting monetary policy is worth preserving."
    }
]