[
    {
        "content": "The Economic Outlook\nTowson University Economic Outlook Conference 2006\nTowson, Maryland\nJanuary 18, 2006\nJeffrey M. Lacker\nPresident, Federal Reserve Bank of Richmond\n\nIt is a pleasure to be with you today to discuss the economic outlook for 2006 and\nbeyond. It is a pleasure, in part, because the economic outlook is fairly encouraging.\nGrowth is on a solid footing, despite this year’s run-up in energy prices and the\ndisruptions of a devastating hurricane season. And after a brief pause this fall,\nemployment is expanding again at a healthy pace, consumer spending continues to grow\nbriskly, and business investment spending is robust. Granted, housing activity seems to\nbe softening, and at least some potential price level pressures remain, so it may be too\nsoon to break out the champagne. But inflation expectations remain contained, and we at\nthe Fed are well-positioned to resist inflation pressures, should they emerge.\nSo all in all, it is quite a good outlook.\nIn my remarks today, I would like to review the economic outlook in a bit more detail,\nand then talk about monetary policy. As always, my remarks reflect my own views, and\nnot necessarily those of my colleagues in the Federal Reserve.\nThe really striking feature of the current outlook is the extent to which economic activity\nin general and consumer spending in particular has rebounded from the shock of last\nyear’s hurricane season. In the immediate aftermath of Hurricane Katrina, fears were\nwidespread that consumers might pull back sharply on spending, both in response to\nsharply higher retail gasoline prices and out of a general sense of heightened anxiety\nabout potential fallout from the storm damage.\nSurvey measures of consumer confidence, which plummeted in September, seemed to\nbolster this view. But the effect of the storms on consumer outlays have turned out to be\nfar more limited than expected, exemplifying the oft-cited resilience of the U.S.\neconomy. Apart from auto sales, which slid following expiration of the summer’s\n“employee discount” promotions, retail sales have held up fairly well and overall\nconsumer spending has continued to advance. And on the whole, holiday spending came\nin stronger than many feared in the immediate aftermath of Hurricanes Katrina and Rita.\nI would argue that this episode illustrates quite well how consumption expenditures are\ngoverned predominantly by households’ assessment of their own future income\nprospects, rather than by any general economic nervousness, despite how they respond to\ntelephone pollsters. With healthy income growth ahead and a reasonably strong overall\njob market, the outlook for consumer spending looks good.\n\n1\n\n\fHousing market activity has been very strong over the last several years, and the\nhistorically low level of inflation-adjusted mortgage interest rates explains much of that\nstrength. The fall in interest rates that began early in 2001 stimulated spending in interestsensitive sectors like housing and durable goods and partially offset the then-emerging\nweakness in business investment spending. As the latter has recovered in the last two\nyears, and real interest rates have had to rise as a consequence, a gradual “handoff” from\nhousing investment has been expected.\nThat handoff has yet to occur; the ratio of business to residential investment outlays fell\nfrom around 2.75 in 2000 to about 1.75 last year, and has been fairly constant since then.\nInstead, the combination of low inflation-adjusted interest rates and sustained real income\ngains have continued to provide a strong stimulus to housing demand.\nIn recent months, we have received widespread anecdotal reports of what one informant\nof ours called “a return to normalcy” in several housing markets in our District. The\nmultiple first-day bids and final sales at above-asking prices that were observed in some\nmarkets seem to have become less common. And in some markets, the amount of time a\nhome stays on the market has returned to more typical levels.\nAt the same time, the aggregate measures of housing activity have so far shown only\nlimited pull-back from their peaks and remain at historically high levels. The fact that\nhousing market activity typically declines in the last few months of each year is making it\ndifficult to collate quantitative and qualitative evidence and assess seasonally adjusted\nhousing market trends. Still, mortgage rates are likely to stay somewhat above their\nrecent lows in the coming year, so I would expect housing price appreciation to flatten\nout next year and aggregate residential investment to stop growing or perhaps even\ndecline.\nThe fundamentals for business investment in equipment and software look quite sound.\nBusiness output is expanding steadily and real funding costs are relatively low, both\nbecause inflation-adjusted, risk-free rates have been low and because corporate risk\nspreads are relatively narrow.\nEvidently, there has been a sufficient flow of opportunities to deploy new capital\nprofitably. Business investment in equipment and software has grown at over 11 percent\nin real terms since the first quarter of 2003, and it appears poised to grow at rates almost\nthat strong next year. Capital formation, particularly investment in information and\ncommunications technology (ICT), played an instrumental role in the widely noted surge\nin productivity growth that took place in the late 1990s. The fundamental driving force\nwas the sustained and rapid fall in the relative prices of these technologies.\nAlthough initial productivity growth figures for that period were revised downward in\nsubsequent data releases, our best estimates now are that productivity accelerated\nsignificantly in the mid-1990s from the relatively stagnant pace of 1.5 percent seen over\nthe previous 20 years to 2.6 percent over the second half of the 1990s.\n\n2\n\n\fProductivity has grown at surprisingly strong rates since then — 3.4 percent since the end\nof 2000 — despite significantly lower rates of capital formation. Productivity growth in\nthe first half of this decade thus must be mainly attributable to gains in what economists\ncall “total factor productivity” — that is, output growth in excess of all input growth\nthrough reorganization of the use of those inputs. At the risk of oversimplification, one\ncould say that firms increased productivity in the 1990s by providing workers with better\ntechnology, but in this decade by restructuring business processes to better exploit the\ntechnology they had.\nOne interpretation of these two episodes is that ICT investment outlays yield both an\ninitial productivity gain (which our standard methods attribute to capital deepening) and\nthen further productivity gains down the road as business processes are steadily\noptimized for the new infrastructure.\nOne implication of this perspective on recent productivity trends is that the current\nexpansion in business investment is laying a foundation for future growth in total factor\nproductivity, and thus provides at least some grounds for optimism that productivity\ngrowth might come in at 2.5 percent or higher, rather than the long-run trend rate of 2.25\npercent.\nUnfortunately, empirical evidence on this is limited, and as always, forecasting\nproductivity growth should be done with humility, given economists’ notably poor track\nrecord in this area.\nGains in labor productivity, whether due to capital deepening or improved business\nprocesses, ultimately pass through to real incomes. As a result, total real personal income\nhas grown recently: over 2 percent per year since the rebound in employment in mid2003, despite significant energy price increases. If productivity growth continues at or\nabove trend, as seems likely, then we should see healthy growth in real income next year,\nanticipation of which should continue to support consumption growth in 2006.\nLabor markets have recovered from the recession of 2001. Although employment was\nstagnant for a time following the downturn, hiring picked up in 2003. Of course,\nHurricane Katrina disrupted labor markets by forcing the displacement of close to a\nmillion people from the Gulf Coast region. That separated a substantial number of\nworkers from their employers, and damaged a substantial portion of the capital stock in\nthe affected areas. As a result, U.S. employment growth was noticeably depressed in\nSeptember and October, although quantitative estimates of the storms’ effects are\nimprecise.\nPayroll expansion has averaged over 200,000 jobs per month since October, however,\nmore than enough to keep up with the growth in working-age population.\nThe overall outlook therefore is for a healthy expansion next year. Real GDP should\ngrow at about 3.5 percent. Household spending should grow at about the same rate in real\nterms. Business investment should expand substantially faster than overall output and\n\n3\n\n\fresidential investment should expand more slowly, perhaps even falling in real terms.\nAnd I expect employment to track the growth in the working-age population in 2006.\nThis is a fairly balanced picture, but naturally there is some uncertainty attached to it.\nEconomic fundamentals could depart from their anticipated trajectories in any number of\nways that could leave a mark on U.S. economic aggregates.\nFor example, spot oil prices — or other commodity prices for that matter — could well\nturn out either above or below the path embodied in futures prices. Many global\ncommodity markets have been affected by the unanticipated surge in worldwide demand\nover the last several of years; those for which supply elasticities are low have experienced\nsignificant price run-ups. Commodity price surprises in either direction could alter\naggregate supply conditions and either add or subtract from output growth.\nOn the demand side, there is some uncertainty regarding the rate at which housing\nactivity is at all likely to cool in the coming year. Although I do not think that a sharp fall\nin housing investment is likely, a range of forecasts from flat to moderately declining\nseem reasonable.\nAnd while continued growth in the share of output devoted to business investment seems\nhighly probable, it is difficult to foresee with any certainty the scale of investment that\nbusinesses will find profitable to undertake, so spending growth in this category could\nwell deviate from expectations.\nIn contrast, growth in household spending is easier to forecast, because both economic\ntheory and empirical evidence indicate that consumption growth is tied closely to income\ngrowth over time. The range of likely outcomes for real consumption growth is\ncorrespondingly more narrow.\nDifferences between how economic fundamentals are expected to unfold and how they\nactually unfold can have important implications for real interest rates and thus for\nmonetary policy.\nAs I have emphasized elsewhere, a real interest rate is a relative price — the price of\ncurrent resources relative to the future resources one either forgoes by borrowing or\nobtains by investing. Real interest rates need to respond to changes in the relative\npressure on current versus future resources.\nUnpredicted movements in economic fundamentals, to the extent that they affect the\nrelative pressure on current and future resources, thus will have implications for policy\nrates, even in situations in which inflation and inflation expectations are low and wellcontained.\nCore inflation has been low and relatively steady in the last several years. The inflation\nmeasure that is widely preferred on methodological grounds, the price index for core\npersonal consumption expenditures, has averaged 1.8 percent over the 12 months ending\n\n4\n\n\fin November. That is within the 1-to-2 percent range that I and others have proposed as\nan announced target.\nEven before Katrina, overall inflation, including food and energy prices, was elevated\ndue to the run-up in energy prices in the spring and summer. Hurricanes Katrina and Rita\nseverely disrupted energy production in the Gulf and led to sharp increases in refining\nmargins and prices for gasoline and natural gas. U.S. natural gas production and\npetroleum refining are still down 5 percent since Katrina, and crude oil production is\ndown 10 percent.\nImmediately following Hurricane Katrina, as the magnitude of the effects on Gulf Coast\nenergy production became clear, many observers came to fear that the resulting sharp\nincrease in energy prices might lead to a broader increase in inflation, and perhaps even\nrecessionary forces. These observers appeared to be reasoning by analogy to the 1970s,\nbut I believe that analogy is seriously mistaken.\nInflation expectations were unanchored in the 1970s, the credibility of the Federal\nReserve was low, and people expected the Fed to allow energy price shocks to feed\nthrough to overall inflation. The Fed often accommodated that expectation by preventing\nshort-term real interest rates from rising. In fact, at times we kept nominal rates from\nrising as fast as inflation and thus provided further monetary stimulus. The Fed was then\nforced to raise rates dramatically to bring inflation back down, and in the process induced\nan economic contraction, exacerbating the real effects of the oil price shocks.\nThus, the proper lesson from the 1970s is not that energy price shocks induce major\nrecessions or cause widespread inflation; it is that monetary policy that reacts to energy\nprice shocks by accommodating the rise in inflation can induce major recessions.\nMonetary policy should to respond to energy shocks by remaining focused on price\nstability. That way, the economy can respond to energy price shocks the way it should —\nthe relative price of energy increases, but core inflation remains anchored. In the\nimmediate aftermath of Hurricanes Katrina and Rita, monetary policymakers naturally\nhave focused on the risk that the attendant energy price increases would “pass through” to\nan acceleration in core inflation. While the lack of an upsurge in the core PCE inflation\nfigures since September is somewhat encouraging, I think it is too soon to declare that\n“pass-through risk” is entirely behind us. This assessment is consistent with the statement\nreleased by the FOMC following its December meeting, which noted that, “…elevated\nenergy prices have the potential to add to inflation pressures.”\nTo my mind, any energy price pass-through to core inflation that is more than\nmarginal and transitory would be unwelcome.\nThus far, market participants appear to believe that core inflation will remain contained.\nSurvey measures of expected inflation rose sharply in September when retail gasoline\nprices reached their peak, but have come back down since. Measures of expected\n\n5\n\n\finflation derived from market prices of inflation protected U.S. Treasury securities drifted\nup a bit this fall, but they too have returned to mid-summer levels.\nTo maintain credibility for price stability, it is essential that monetary policy should\nrespond vigorously to any visible erosion in inflation expectations.\nMany of you may have noticed that in the statement released following the last FOMC\nmeeting, the term “accommodation” was dropped, or, in the words of one of my\ncolleagues, “given an honorable discharge.” Many observers are taking this as a sign that\nthe Committee may be coming close to completing the current sequence of tightening\nmoves that began in June of 2004.\nI discussed earlier that in an era of low and stable inflation, real interest rate movements\nwill predominantly reflect the relative pressure on current versus future resources.\nRecessions, in modern industrialized economies, are associated with transitory declines in\nthe demand for current goods and services. Since demand ultimately will recover, real\ninterest rates need to fall in recessions to reflect the abundance of current relative to\nfuture resources. Thus, the FOMC engineered a reduction in real interest rates in 2001\nthat lasted until mid-2004, when a steady recovery in demand became evident. Since\nthen, the economy has been on a transitional trajectory toward a path characterized by\nsustained and balanced expansion with relatively full utilization of resources. Along this\ntransition, real interest rates have been rising toward a range consistent with the sustained\ngrowth path to which the economy has been headed.\nIt deserves emphasis, however, that sustained growth is not likely to be perfectly smooth\nand predictable. Unpredicted variations in economic fundamentals can and will affect\neconomic conditions, even if they are not so large as to induce a recessionary break in\ngrowth.\nAnd as I emphasized earlier, if those variations have implications for the relative pressure\non current versus future resources, they will have implications for real interest rates as\nwell. The long expansions of the 1980s and 1990s were both cases in which interest rates\nfluctuated as the economy experienced sustained growth.\nThus, whenever the current sequence of tightening moves reaches completion, short-term\ninterest rates should not be expected to remain constant for an extended period of time.\nInstead, they will likely move from time to time during the expansion ahead.\nPolicymakers will need to be alert for movements in economic fundamentals that shift the\nrelative pressure on current versus future resources in ways that require changes in real\ninterest rates, even if inflation pressures subside.\n\n6\n\n\f",
        "date": "January 18, 2006",
        "text_url": "https://fraser.stlouisfed.org/files/text/historical/frbrich/presidents/lacker_20060118.txt",
        "year": "2006",
        "title": "The Economic Outlook : Towson University Economic Outlook Conference 2006, Towson, Maryland",
        "href": "https://fraser.stlouisfed.org/title/statements-speeches-jeffrey-m-lacker-6827/economic-outlook-678636",
        "item_id": "678636",
        "speaker": "effrey M. Lacke"
    },
    {
        "content": "The Economic Outlook for 2006\nRisk Management Association, Richmond Chapter\nRichmond, Virginia\nJanuary 20, 2006\nJeffrey M. Lacker\nPresident, Federal Reserve Bank of Richmond\n\nIt is a pleasure to be with you today to discuss the economic outlook for 2006 and\nbeyond. It is a pleasure, in part, because the economic outlook is fairly encouraging.\nGrowth is on a solid footing, despite this year’s run-up in energy prices and the\ndisruptions of a devastating hurricane season. And after a brief pause this fall,\nemployment is expanding again at a healthy pace, consumer spending continues to grow\nbriskly, and business investment spending is robust. Granted, housing activity seems to\nbe softening, and at least some potential price level pressures remain, so it may be too\nsoon to break out the champagne. But inflation expectations remain contained, and we at\nthe Fed are well-positioned to resist inflation pressures, should they emerge.\nSo all in all, it is quite a good outlook.\nIn my remarks today, I would like to review the economic outlook in a bit more detail,\nand then talk about monetary policy. As always, my remarks reflect my own views, and\nnot necessarily those of my colleagues in the Federal Reserve.\nThe really striking feature of the current outlook is the extent to which economic activity\nin general and consumer spending in particular has rebounded from the shock of last\nyear’s hurricane season. In the immediate aftermath of Hurricane Katrina, fears were\nwidespread that consumers might pull back sharply on spending, both in response to\nsharply higher retail gasoline prices and out of a general sense of heightened anxiety\nabout potential fallout from the storm damage.\nSurvey measures of consumer confidence, which plummeted in September, seemed to\nbolster this view. But the effect of the storms on consumer outlays have turned out to be\nfar more limited than expected, exemplifying the oft-cited resilience of the U.S.\neconomy. Apart from auto sales, which slid following expiration of the summer’s\n“employee discount” promotions, retail sales have held up fairly well and overall\nconsumer spending has continued to advance. And on the whole, holiday spending came\nin stronger than many feared in the immediate aftermath of Hurricanes Katrina and Rita.\nI would argue that this episode illustrates quite well how consumption expenditures are\ngoverned predominantly by households’ assessment of their own future income\nprospects, rather than by any general economic nervousness, despite how they respond to\ntelephone pollsters. With healthy income growth ahead and a reasonably strong overall\njob market, the outlook for consumer spending looks good.\n\n\fHousing market activity has been very strong over the last several years, and the\nhistorically low level of inflation-adjusted mortgage interest rates explains much of that\nstrength. The fall in interest rates that began early in 2001 stimulated spending in interestsensitive sectors like housing and durable goods and partially offset the then-emerging\nweakness in business investment spending. As the latter has recovered in the last two\nyears, and real interest rates have had to rise as a consequence, a gradual “handoff” from\nhousing investment has been expected.\nThat handoff has yet to occur; the ratio of business to residential investment outlays fell\nfrom around 2.75 in 2000 to about 1.75 last year, and has been fairly constant since then.\nInstead, the combination of low inflation-adjusted interest rates and sustained real income\ngains have continued to provide a strong stimulus to housing demand.\nIn recent months, we have received widespread anecdotal reports of what one informant\nof ours called “a return to normalcy” in several housing markets in our District. The\nmultiple first-day bids and final sales at above-asking prices that were observed in some\nmarkets seem to have become less common. And in some markets, the amount of time a\nhome stays on the market has returned to more typical levels.\nAt the same time, the aggregate measures of housing activity have so far shown only\nlimited pull-back from their peaks and remain at historically high levels. The fact that\nhousing market activity typically declines in the last few months of each year is making it\ndifficult to collate quantitative and qualitative evidence and assess seasonally adjusted\nhousing market trends. Still, mortgage rates are likely to stay somewhat above their\nrecent lows in the coming year, so I would expect housing price appreciation to flatten\nout next year and aggregate residential investment to stop growing or perhaps even\ndecline.\nThe fundamentals for business investment in equipment and software look quite sound.\nBusiness output is expanding steadily and real funding costs are relatively low, both\nbecause inflation-adjusted, risk-free rates have been low and because corporate risk\nspreads are relatively narrow.\nEvidently, there has been a sufficient flow of opportunities to deploy new capital\nprofitably. Business investment in equipment and software has grown at over 11 percent\nin real terms since the first quarter of 2003, and it appears poised to grow at rates almost\nthat strong next year. Capital formation, particularly investment in information and\ncommunications technology (ICT), played an instrumental role in the widely noted surge\nin productivity growth that took place in the late 1990s. The fundamental driving force\nwas the sustained and rapid fall in the relative prices of these technologies.\nAlthough initial productivity growth figures for that period were revised downward in\nsubsequent data releases, our best estimates now are that productivity accelerated\nsignificantly in the mid-1990s from the relatively stagnant pace of 1.5 percent seen over\nthe previous 20 years to 2.6 percent over the second half of the 1990s.\n\n2\n\n\fProductivity has grown at surprisingly strong rates since then – 3.4 percent since the end\nof 2000 – despite significantly lower rates of capital formation. Productivity growth in\nthe first half of this decade thus must be mainly attributable to gains in what economists\ncall “total factor productivity” – that is, output growth in excess of all input growth\nthrough reorganization of the use of those inputs. At the risk of oversimplification, one\ncould say that firms increased productivity in the 1990s by providing workers with better\ntechnology, but in this decade by restructuring business processes to better exploit the\ntechnology they had.\nOne interpretation of these two episodes is that ICT investment outlays yield both an\ninitial productivity gain (which our standard methods attribute to capital deepening) and\nthen further productivity gains down the road as business processes are steadily\noptimized for the new infrastructure.\nOne implication of this perspective on recent productivity trends is that the current\nexpansion in business investment is laying a foundation for future growth in total factor\nproductivity, and thus provides at least some grounds for optimism that productivity\ngrowth might come in at 2.5 percent or higher, rather than the long-run trend rate of 2.25\npercent.\nUnfortunately, empirical evidence on this is limited, and as always, forecasting\nproductivity growth should be done with humility, given economists’ notably poor track\nrecord in this area.\nGains in labor productivity, whether due to capital deepening or improved business\nprocesses, ultimately pass through to real incomes. As a result, total real personal income\nhas grown recently: over 2 percent per year since the rebound in employment in mid2003, despite significant energy price increases. If productivity growth continues at or\nabove trend, as seems likely, then we should see healthy growth in real income next year,\nanticipation of which should continue to support consumption growth in 2006.\nLabor markets have recovered from the recession of 2001. Although employment was\nstagnant for a time following the downturn, hiring picked up in 2003. Of course,\nHurricane Katrina disrupted labor markets by forcing the displacement of close to a\nmillion people from the Gulf Coast region. That separated a substantial number of\nworkers from their employers, and damaged a substantial portion of the capital stock in\nthe affected areas. As a result, U.S. employment growth was noticeably depressed in\nSeptember and October, although quantitative estimates of the storms’ effects are\nimprecise.\nPayroll expansion has averaged over 200,000 jobs per month since October, however,\nmore than enough to keep up with the growth in working-age population.\nThe overall outlook therefore is for a healthy expansion next year. Real GDP should\ngrow at about 3.5 percent. Household spending should grow at about the same rate in real\nterms. Business investment should expand substantially faster than overall output and\n\n3\n\n\fresidential investment should expand more slowly, perhaps even falling in real terms.\nAnd I expect employment to track the growth in the working-age population in 2006.\nThis is a fairly balanced picture, but naturally there is some uncertainty attached to it.\nEconomic fundamentals could depart from their anticipated trajectories in any number of\nways that could leave a mark on U.S. economic aggregates.\nFor example, spot oil prices – or other commodity prices for that matter – could well turn\nout either above or below the path embodied in futures prices. Many global commodity\nmarkets have been affected by the unanticipated surge in worldwide demand over the last\nseveral of years; those for which supply elasticities are low have experienced significant\nprice run-ups. Commodity price surprises in either direction could alter aggregate supply\nconditions and either add or subtract from output growth.\nOn the demand side, there is some uncertainty regarding the rate at which housing\nactivity is at all likely to cool in the coming year. Although I do not think that a sharp fall\nin housing investment is likely, a range of forecasts from flat to moderately declining\nseem reasonable.\nAnd while continued growth in the share of output devoted to business investment seems\nhighly probable, it is difficult to foresee with any certainty the scale of investment that\nbusinesses will find profitable to undertake, so spending growth in this category could\nwell deviate from expectations.\nIn contrast, growth in household spending is easier to forecast, because both economic\ntheory and empirical evidence indicate that consumption growth is tied closely to income\ngrowth over time. The range of likely outcomes for real consumption growth is\ncorrespondingly more narrow.\nDifferences between how economic fundamentals are expected to unfold and how they\nactually unfold can have important implications for real interest rates and thus for\nmonetary policy.\nAs I have emphasized elsewhere, a real interest rate is a relative price – the price of\ncurrent resources relative to the future resources one either forgoes by borrowing or\nobtains by investing. Real interest rates need to respond to changes in the relative\npressure on current versus future resources.\nUnpredicted movements in economic fundamentals, to the extent that they affect the\nrelative pressure on current and future resources, thus will have implications for policy\nrates, even in situations in which inflation and inflation expectations are low and wellcontained.\nCore inflation has been low and relatively steady in the last several years. The inflation\nmeasure that is widely preferred on methodological grounds, the price index for core\npersonal consumption expenditures, has averaged 1.8 percent over the 12 months ending\n\n4\n\n\fin November. That is within the 1-to-2 percent range that I and others have proposed as\nan announced target.\nEven before Katrina, overall inflation, including food and energy prices, was elevated\ndue to the run-up in energy prices in the spring and summer. Hurricanes Katrina and Rita\nseverely disrupted energy production in the Gulf and led to sharp increases in refining\nmargins and prices for gasoline and natural gas. U.S. natural gas production and\npetroleum refining are still down 5 percent since Katrina, and crude oil production is\ndown 10 percent.\nImmediately following Hurricane Katrina, as the magnitude of the effects on Gulf Coast\nenergy production became clear, many observers came to fear that the resulting sharp\nincrease in energy prices might lead to a broader increase in inflation, and perhaps even\nrecessionary forces. These observers appeared to be reasoning by analogy to the 1970s,\nbut I believe that analogy is seriously mistaken.\nInflation expectations were unanchored in the 1970s, the credibility of the Federal\nReserve was low, and people expected the Fed to allow energy price shocks to feed\nthrough to overall inflation. The Fed often accommodated that expectation by preventing\nshort-term real interest rates from rising. In fact, at times we kept nominal rates from\nrising as fast as inflation and thus provided further monetary stimulus. The Fed was then\nforced to raise rates dramatically to bring inflation back down, and in the process induced\nan economic contraction, exacerbating the real effects of the oil price shocks.\nThus, the proper lesson from the 1970s is not that energy price shocks induce major\nrecessions or cause widespread inflation; it is that monetary policy that reacts to energy\nprice shocks by accommodating the rise in inflation can induce major recessions.\nMonetary policy should to respond to energy shocks by remaining focused on price\nstability. That way, the economy can respond to energy price shocks the way it should –\nthe relative price of energy increases, but core inflation remains anchored. In the\nimmediate aftermath of Hurricanes Katrina and Rita, monetary policymakers naturally\nhave focused on the risk that the attendant energy price increases would “pass through” to\nan acceleration in core inflation. While the lack of an upsurge in the core PCE inflation\nfigures since September is somewhat encouraging, I think it is too soon to declare that\n“pass-through risk” is entirely behind us. This assessment is consistent with the statement\nreleased by the FOMC following its December meeting, which noted that, “…elevated\nenergy prices have the potential to add to inflation pressures.”\nTo my mind, any energy price pass-through to core inflation that is more than\nmarginal and transitory would be unwelcome.\nThus far, market participants appear to believe that core inflation will remain contained.\nSurvey measures of expected inflation rose sharply in September when retail gasoline\nprices reached their peak, but have come back down since. Measures of expected\n\n5\n\n\finflation derived from market prices of inflation protected U.S. Treasury securities drifted\nup a bit this fall, but they too have returned to mid-summer levels.\nTo maintain credibility for price stability, it is essential that monetary policy should\nrespond vigorously to any visible erosion in inflation expectations.\nMany of you may have noticed that in the statement released following the last FOMC\nmeeting, the term “accommodation” was dropped, or, in the words of one of my\ncolleagues, “given an honorable discharge.” Many observers are taking this as a sign that\nthe Committee may be coming close to completing the current sequence of tightening\nmoves that began in June of 2004.\nI discussed earlier that in an era of low and stable inflation, real interest rate movements\nwill predominantly reflect the relative pressure on current versus future resources.\nRecessions, in modern industrialized economies, are associated with transitory declines in\nthe demand for current goods and services. Since demand ultimately will recover, real\ninterest rates need to fall in recessions to reflect the abundance of current relative to\nfuture resources. Thus, the FOMC engineered a reduction in real interest rates in 2001\nthat lasted until mid-2004, when a steady recovery in demand became evident. Since\nthen, the economy has been on a transitional trajectory toward a path characterized by\nsustained and balanced expansion with relatively full utilization of resources. Along this\ntransition, real interest rates have been rising toward a range consistent with the sustained\ngrowth path to which the economy has been headed.\nIt deserves emphasis, however, that sustained growth is not likely to be perfectly smooth\nand predictable. Unpredicted variations in economic fundamentals can and will affect\neconomic conditions, even if they are not so large as to induce a recessionary break in\ngrowth.\nAnd as I emphasized earlier, if those variations have implications for the relative pressure\non current versus future resources, they will have implications for real interest rates as\nwell. The long expansions of the 1980s and 1990s were both cases in which interest rates\nfluctuated as the economy experienced sustained growth.\nThus, whenever the current sequence of tightening moves reaches completion, short-term\ninterest rates should not be expected to remain constant for an extended period of time.\nInstead, they will likely move from time to time during the expansion ahead.\nPolicymakers will need to be alert for movements in economic fundamentals that shift the\nrelative pressure on current versus future resources in ways that require changes in real\ninterest rates, even if inflation pressures subside.\n\n6\n\n\f",
        "date": "January 20, 2006",
        "text_url": "https://fraser.stlouisfed.org/files/text/historical/frbrich/presidents/lacker_20060120.txt",
        "year": "2006",
        "title": "The Economic Outlook for 2006 : Risk Management Association, Richmond Chapter, Richmond, Virginia",
        "href": "https://fraser.stlouisfed.org/title/statements-speeches-jeffrey-m-lacker-6827/economic-outlook-2006-678637",
        "item_id": "678637",
        "speaker": "effrey M. Lacke"
    },
    {
        "content": "Transition and Continuity at the Federal Reserve in 2006\nAcordia/Royal & SunAlliance Distinguished Lecture Series\nWest Virginia University\nMorgantown, West Virginia\nFebruary 14, 2006\nJeffrey M. Lacker\nPresident, Federal Reserve Bank of Richmond\n\nI would like to talk to you tonight about the evolution in the way the Federal Reserve\ngoes about conducting monetary policy. As my title suggests, one theme is that a\ntransition is taking place. Of course, the most striking transition at the Federal Reserve\nthis year is the change in leadership. On January 31, Federal Reserve Board Chairman\nAlan Greenspan served his last day in office and chaired his last meeting of the Federal\nOpen Market Committee. His successor, Ben Bernanke, took over the following day, and\ntomorrow morning, he delivers his first testimony to Congress as chairman.\nMuch has been written and said recently about this changing of the guard. It is quite\nnatural in such circumstances for commentators to contrast an influential leader and his\nsuccessor and to look for likely differences in philosophy and practice. But in my\nopinion, too much has been made of their differences. Thus, the second theme of my talk:\ncontinuity. In remarks upon the announcement of his nomination, Bernanke very\ndeliberately emphasized the stability of monetary policy. He stated that his “first priority\nwill be to maintain continuity with the policies and policy strategies established during\nthe Greenspan years.” But I won’t ask you to take his word for it. Tonight, I hope to\nconvince you that a careful student of the Federal Reserve should have good reason to\nbelieve that the practice of monetary policy will continue to evolve gradually. I will argue\nthat a certain economic logic has influenced the way policy and practice evolved during\nthe Greenspan years, and that that logic will continue to influence the evolution of policy\nduring the Bernanke years. In particular, the stability of the public’s understanding of and\nexpectations about the future conduct of monetary policy have been central to Chairman\nGreenspan’s success. As a consequence, the Federal Reserve has found it useful to\nsteadily make the conduct of monetary policy more transparent. This logic is likely to\ncontinue to hold sway, and thus the Fed is likely to continue to emphasize credibility and\nenhanced transparency.\nLet me be clear, however. Understanding the economic logic of the evolution of\nmonetary policy over the last several decades should take nothing away from the\nsignificant achievements of Alan Greenspan. He served as Fed chairman for more than\n18-and-a-half years and his record during that time was exemplary. Under his leadership,\nthe Federal Reserve brought inflation down to historically low levels, which contributed\nto a period of extended economic expansion interrupted by only two brief and mild\nrecessions. Indeed, the term “The Great Moderation” has been given to the phenomenal\nimprovement in macroeconomic performance during the period following the mid-1980s,\n\n\fjust before Greenspan took over. In essence, he successfully completed the task begun by\nhis predecessor, Paul Volcker, of re-establishing the expectation of price stability that had\nbeen lost in the inflationary decade of the 1970s.\nWe are fortunate to have in Ben Bernanke a new chairman who has experience in\npolicymaking and has made important contributions to our understanding of monetary\neconomics. He is well-versed in both the economic logic of monetary policy and the\nresearch devoted to dissecting the great monetary policy mistakes of the 1930s and\n1970s. He is therefore eminently qualified to continue to lead Fed policymaking along the\npath laid out by his predecessors. And his public comments thus far, particularly in his\nconfirmation hearings, suggest that we can expect the type of continuity in Fed\npolicymaking that I’ll be talking about this evening.\nI should say at the outset that, as always, my remarks reflect my own views and not\nnecessarily those of my colleagues in the Federal Reserve.\n***\nMany observers, myself included, have argued that one of the hallmarks of the Greenspan\nlegacy is adherence to a systematic approach to policymaking. 1 The value of a systematic\napproach to monetary policy goes beyond the usefulness of minimizing unexpected\ndeviations from what the public anticipates. The purpose of monetary policy, after all, is\nto stabilize the value of money, and the value people place on money today depends\ncritically on what value people expect money to have in the near future, which depends in\nturn on what value people expect money to have a bit further into the future, and so on.\nThe future conduct of monetary policy is thus a fundamental determinant of the value of\nmoney. Therefore, the key to stabilizing the value of money is getting people to\nunderstand the systematic conduct of monetary policy.\nBut saying that Greenspan introduced systematic policymaking is not quite right – and\nnot quite enough. After all, monetary policy during the inflationary 1970s was just as\nsystematic. An econometrician could estimate a statistical relationship between\nmacroeconomic variables and the Fed’s policy actions in the 1960s and 1970s. Indeed,\nmany econometricians have estimated such relationships, and they tend to fit pretty well.\nBut those relationships generally differ from what you get when you estimate\nrelationships for the Volcker or Greenspan years. The question, then, is just what\nsystematic relationship the Fed follows.\nIn the 1960s and 1970s monetary policy typically allowed inflation to rise noticeably\nduring economic expansions. As the economy recovered from a recession and growth\npicked up, the Fed kept interest rates from rising as much as they should. In fact, at times,\nthe Fed failed to raise nominal interest rates by as much as inflation was increasing. This\ncaused real (that is, inflation-adjusted) interest rates to fall and, thus, provided further\nmonetary stimulus at precisely the wrong time. The acceleration of inflation ultimately\nprovoked a sharp tightening in policy, which often exacerbated or even caused an ensuing\nrecession. Policymakers’ fear of even further deepening the slump led them to ease policy\n\n2\n\n\fbefore inflation had fully subsided. So inflation was essentially ratcheting upward\nthroughout the period before 1980.\nAn important part of the economic instability of the 1970s can be attributed to the fact\nthat the public’s inflation expectations became untethered. For a long time before, indeed\nfor centuries, inflation expectations had been anchored by commodity standards – that is,\nby arrangements that tied the value of money to the value of one or more precious metals\nlike gold or silver. Under a commodity standard, inflation wasn’t eliminated, since\nchanges in the supply and demand conditions for the commodity to which money was\nlinked could change the value of money. But over the long run, the real value of a\ncommodity like gold is determined by the cost of extraction, and this tended to be fairly\nstable. Thus, commodity standards provided people with confidence that movements in\nthe value of money would not be persistent and that inflation would ultimately settle back\ndown to low levels.\nThe 20th century saw a gradual but steady departure from the gold standard, culminating\nin the closing of the U.S. “gold window” in 1971. It is not surprising that expectational\nstability would have been lost around the same time. When inflation was observed to rise\nin the 1970s, the public saw no obvious mechanism in place for bringing it back down,\nand so higher inflation became built into people’s long-run expectations. The story of the\nVolcker-Greenspan era, then, is the story of how expectational stability was restored –\nthe story of how the Fed regained the public’s confidence that it would and could keep\ninflation low and stable.\nThe emergence of persistent inflation expectations on the part of the public during the\n1970s was one factor that contributed to important developments in the discipline of\nmacroeconomics. Before the 1970s, the consensus framework for understanding the\neffects of monetary policy treated the public’s expectations about future inflation as a\nfixed parameter, unaffected by the actual current conduct of monetary policy. That\nframework contributed to the policy errors of that period by encouraging policymakers to\ndiscount the possibility that public expectation would shift over time in response to the\nactual conduct of policy.\nEconomists already had begun to think more carefully about how the public’s\nexpectations are formed, and in the 1970s, they had begun to study models in which the\npublic’s expectations were tied very tightly to how policy would actually be conducted.\nThe experience of the 1970s confirmed the importance of this link by teaching us,\nessentially, that you can’t fool all the people all the time. People learn from what they\nsee, and it was unreasonable to assume that people would continue to expect inflation to\nsettle down to low levels when they kept seeing inflation continue to ratchet up. The\nmodels developed in the 1970s provided a compelling diagnosis of the deterioration in\ninflation we witnessed that decade: monetary policy had a systematic inflationary bias,\nand the public had come to understand that and behave accordingly. Those models also\nprovided the Fed with a prescription: systematically adhere to, and convince the public\nwe would systematically adhere to, a non-inflationary monetary policy.\n\n3\n\n\fThat prescription is easier written than followed, however. Merely announcing an\nintention to bring inflation down is not sufficient. After all, the Federal Reserve had been\npublicly advocating lower inflation throughout the 1970s. We needed a way to\nconvincingly demonstrate our commitment to bringing inflation down. The Fed began\nthis process in October 1979, under Chairman Paul Volcker, by allowing interest rates to\nrise sharply and withstanding a deep recession while inflation ratcheted down. Thereafter,\nthe Fed often had to raise the fed funds rate in response to signs of rising inflation, or in\nresponse to inflation scares – that is, signs from the bond market that inflation\nexpectations were rising. Over time, however, inflation has stabilized at a low level and\ninflation scares have become much less frequent as the public has learned that the Fed\nwould respond systematically in a way designed to keep inflation low and steady.\nThe conduct of monetary policy in the last two decades has brought us to a very favorable\nplace. Inflation is low and stable, and the public appears to be fairly confident that\ninflation will remain persistently low and stable. This is the Greenspan legacy, and it is\nnow our responsibility, under the leadership of the new chairman, to preserve that\ncredibility.\nThe challenge of fulfilling that responsibility in the period ahead will be analytically\ndemanding. For how does one conduct monetary policy when inflation is low and stable?\nHere we can draw on our understanding from a class of models that researchers have\ndeveloped and studied in the last decade or two. While this research program is still in\nprogress and important open questions remain, a few clear principles have emerged. First,\nholding interest rates steady until inflation or deflation pressures are actually visible is\nclearly inappropriate. Instead, policy should be conducted recognizing that real interest\nrates should be expected to fluctuate with economic conditions. A real interest rate is the\nrelative price of current resources in terms of future resources. It represents the real\namount of goods and services one must sacrifice in the future (in addition to the\nrepayment of principal) to obtain real goods and services today. As I have emphasized\nelsewhere, real interest rates should be expected to fluctuate over time in response to\nvariations in the relative pressure on current versus future resources. 2 When current\nresource demand is less than it will be in the near future – as was the case from 2001\nthrough the beginning of 2004 – then real interest rates need to be low to reflect the\nrelative lack of pressure on current resources. When that relative pressure on current\nresources rises, as has been happening over the last two years, then real interest rates\nneed to rise. In such circumstances, if the Fed sets and keeps the funds rate too low, the\ninevitable result will be rising inflation.\nThe behavior of the Fed thus has evolved in a way that is consistent with the evolution of\nour understanding of the macroeconomy and of how inflation, growth, and interest rates\ninteract over time. Alan Greenspan’s leadership was vital to this evolution. He\nunderstood the importance of stabilizing the public’s expectations regarding future\nmonetary policy. He proved highly skilled at sensing the evolution of those expectations,\nand at influencing them through the practice of monetary policy. And his focus on the\nFed’s credibility dovetailed with advances in economic research both inside and outside\nthe Federal Reserve. It’s fitting, then, that leadership of the Fed should now pass to Ben\n\n4\n\n\fBernanke who, in addition to his previous experience on the FOMC, has made quite\nimportant contributions to research on monetary policy during his academic career.\n***\nThe importance of expectations and how policy effectiveness hinges on expectations is\none of the most significant contributions of macroeconomic research in recent decades.\nGiven this importance, one might wonder whether a central bank can influence\nexpectations through means other than its own rate-setting behavior. In particular, what\nrole can or should communication by the Federal Reserve play in shaping the public’s\nexpectations?\nBy itself, communication is not a particularly powerful tool for influencing people’s\nbeliefs. To be effective, communication needs to be backed up by and consistent with the\nactual policy behavior. Otherwise, listeners tend to discount what the policymaker says in\nfavor of how the policymaker behaves. Thus the popular aphorism: “Actions speak\nlouder than words.” Words can matter, however, if the public believes that the\npolicymaker will feel compelled to live up to them. A central banker who pledges to keep\ninflation low but then persistently lets it rise runs the risk of not being believed the next\ntime around. This risk strongly discourages making empty promises. Thus, a clear central\nbank commitment to a policy objective can influence the public’s expectations.\nOne widely noticed feature of the Greenspan legacy is the dramatic increase in\ntransparency during his tenure. This is especially apparent in the Fed’s communications\nregarding policy actions. Before 1994, the FOMC released only a difficult-to-interpret\ndocument called the “directive” regarding the supply of bank reserves to the market, and\nthen only after the following meeting, when it had been superseded. Faced with this\n“radio silence,” an industry of Fed-watchers developed to try to infer policy decisions\nfrom market movements after a meeting.\nIn a series of steps beginning in 1994, the FOMC began to expand the amount of\ninformation released to the public immediately following a meeting. First, the intended\ntarget for the federal funds rate was released immediately following the meeting. This\nwas then supplemented by a “balance of risks assessment,” which was often described as\nindicating the “tilt” in policy – that is, whether an increase or a decrease in the funds rate\nwas relatively more likely at coming meetings. Over time, the statements gradually\nincluded more discussion of current and prospective economic conditions. Finally, in\n2005, the FOMC began releasing the full minutes three weeks following the meeting,\nrather than after the subsequent meeting, as had been the practice.\nBack in 2003, the FOMC began issuing statements that sent fairly explicit signals about\nthe likely path for the funds rate. Early in 2003, core inflation had drifted down to 1\npercent. The statement released following the May meeting that year made reference to\n“an unwelcome further fall in inflation.” This was something of a watershed in Fed\nhistory – the first time in our modern experience that inflation threatened to fall too low.\nThe language labeling a further fall in inflation as “unwelcome” conveyed the\n\n5\n\n\fCommittee’s intention to keep core inflation above 1 percent. At the next meeting in late\nJune, the FOMC lowered the fed funds rate to 1 percent and repeated the “unwelcome”\nreference. After the August meeting, the statement said that “policy accommodation can\nbe maintained for a considerable period.” This too was a watershed – explicit\ncommunication about the likely future path of the policy instrument. Since then the\nCommittee has continued to communicate about the likely near-term policy path, using\nphrases like “can be patient” and “a pace that is likely to be measured.”\nThis series of moves toward greater and more timely communication form a natural\nprogression. For decades, the Fed has articulated its desire for low and stable inflation. In\nthe 1990s, the FOMC went beyond general goals and began disclosing current policy\nactions and their rationale, thus providing information on how past policy actions had\nbeen affected by current and prospective economic conditions. The balance of risks\nstatement broke new ground by communicating, though somewhat elliptically, about the\nlikely near-term policy direction. The forward-looking language used since 2003 has in\nturn provided richer insights into the policy actions that the Committee believes it would\nhave to take to achieve its goals.\nI can understand why this progression took as long as it did. Starting from a status quo in\nwhich the Fed provided very little up-to-the-minute information on its policy, small\ninitial steps were probably warranted. Too abrupt a change may have temporarily created\nuncertainty in the markets about the meaning of the information coming out of the Fed,\nalthough clearly, over time, market participants would learn how to interpret Fed\nstatements. If that uncertainty fed into market volatility, even as a transitory matter while\nmarkets learned about the new format, then transparency skeptics might have been able to\nuse that volatility as an argument against sharing information with the public.\nI think it is important to be clear about what the Committee communicates when it\ncomments on the near-term policy direction. Central banks set interest rates in response\nto incoming economic data. What ultimately drives that data is the evolution of economic\nfundamentals – that is, the evolution of technologies and external factors like world\ncommodity prices. So the current policy rate should be thought of as a function (though\nprobably a fairly complicated one) of the fundamentals – that’s what systematic policy\nmeans. When the FOMC communicates about the likely future path of policy rates, as it\ndid from mid-2003 on, it is communicating about two separate things at once – first, how\nfundamentals are likely to evolve, and second, how policy is likely to react to those\nfundamentals. I believe there are important roles for both, but that it is important to\ndistinguish between the two.\nThe striking feature of the period since mid-2003 has been that the likely evolution of\neconomic fundamentals and the likely policy reaction have combined to make the likely\npath of our policy instrument, the fed funds rate, relatively clear. Beginning in early\n2004, for example, it was clear that short-term interest rates were going to have to rise\nsteadily as the economy recovered and made the transition to a sustained growth path.\nHaving now moved much closer to such a growth path, however, it may be much less\n\n6\n\n\fcommon for the FOMC to find itself willing and able to forecast an extended string of\nrate changes.\nBut if the federal funds rate path becomes less predictable than it has been over the last\n14 FOMC meetings, does that mean that the Committee must retreat to saying little\nbeyond announcing its rate decisions when they are made? In my opinion, no. My sense\nis that there will still be room for forward-looking communications that entail more\nconditional statements about how policy is likely to react to evolving economic\nfundamentals, in contrast to the less conditional statements common since 2003. I opened\nmy remarks tonight by noting the importance of systematic public expectations regarding\nmonetary policy. Building better public understanding of how policy systematically\nresponds to evolving economic conditions is the key to enhancing our credibility and\nimproving the effectiveness of monetary policy.\nBeyond moving to more conditional forward-looking language, I think there is probably\nmore that can be done to build systematic public understanding. An important component\nof that understanding is the public’s sense of our long-run intentions for inflation. Several\nFOMC members, myself included, have indicated the level or range of inflation that they\nwould like to see prevail over the long run, but the Committee itself has not formally\nadopted such a goal or target for inflation. Providing quantitative guidance to the public\nabout the Committee’s long-run inflation intentions would have the benefit of reducing\nuncertainty about future monetary policy, and more securely anchoring long-run inflation\nexpectations.\nIn his nomination hearings last November, Chairman Bernanke acknowledged that he has\nsupported the idea of a quantitative inflation objective in academic writings and in\nspeeches as a member of the Board of Governors. But he assured the senators that, if\nconfirmed, he would “take no precipitate steps” in this direction, and he indicated that the\nidea “requires further study … as well as extensive discussion and consultation.” He went\non to say that he would act only if a “consensus” develops that doing so would further\nenhance our ability to achieve our mandated objectives. I have already expressed my own\nsupport for such a formal quantitative statement as a means of providing an anchor for\nlong-term inflation expectations, 3 and I look forward to further study and discussion of\nthe issue under Chairman Bernanke’s leadership.\nI suspect that the next frontier in Fed communications will involve the framework we use\nfor policy analysis. After we have had some practice at communicating our past actions\nand how we are likely to respond in the future, it will be time to communicate more about\nwhy we will respond the way we will respond. Admittedly, this will be a tougher nut to\ncrack, if only because of the genuine scientific uncertainty that typically surrounds\neconomic inferences. But to the extent that a reasonably firm consensus can be obtained\non some basic principles, I believe that it would aid public understanding for us to find\nways to communicate them. Public understanding of the economic reasoning underlying\nour policy choices would help prevent drawing the wrong lessons from history.\n\n7\n\n\fFor example, the initial response of market participants to the spike in energy prices that\nfollowed Hurricane Katrina suggested that people considered it possible or even likely\nthat the FOMC would pause in its sequence of rate hikes, and that we would be willing to\ntolerate an acceleration in broader measures of inflation in response to the energy price\nincreases. In the popular media, this expectation was tied to the experience with energy\nprice shocks in the 1970s. But as I’ve already emphasized, the systematic part of policy\nin the 1970s was very different from what it became in the Greenspan years. Such\nmisunderstandings can create challenges for policymakers. If the public comes to expect\nrising inflation, based on an outdated view of how policy responds to an economic shock,\nthen the task of preventing a rise in inflation is made more difficult.\nI commented earlier about the nature of monetary policy when inflation is low and stable.\nI emphasized that real, inflation-adjusted interest rates should be expected to fluctuate in\nsuch circumstances, even in the absence of visible fluctuations in inflation pressures.\nWith inflation low and steady, changes in real interest rates require changes in the\nnominal overnight policy rate that the Fed directly controls. Communicating that fact will\nhelp the public understand that policy needs to respond to changing real economic\nconditions. Moreover, focusing on real interest rates draws attention to how and why\npolicy must respond; real interest rates must fluctuate to accommodate changes in the\nrelative pressure on current versus future resources. Widespread understanding of this\nwould have aided the market response to Katrina; the storm impaired the supply of\ncurrent resources relative to the future, and so, if anything real interest rates had to rise,\nnot fall.\n***\nTo sum up, then, Chairman Greenspan’s success was predicated on establishing\ncredibility – that is, widespread public confidence that the future conduct of monetary\npolicy would keep inflation low and stable. Building that confidence through actions\nalone was insufficient, and the Greenspan Fed began to expand communications, first\nabout current policy actions, then about likely prospective actions. To maintain and build\ncredibility, we are likely to continue to look for ways to enhance communications in the\nyears ahead. Our efforts in this direction will be informed both by a rich history of\nexperience with monetary policy and by a growing body of knowledge gained from\nviewing that history through the lens of economic logic.\nOn a personal note, I have known Ben Bernanke professionally since shortly after the\npublication of his influential 1983 paper on money and credit in the Great Depression. He\nis an outstanding monetary economist but also an imminently sensible monetary policy\npractitioner. I am looking forward with enthusiasm to serving in the Bernanke Fed.\nLooking back, I count it an extraordinary honor and privilege to have served under\nChairman Greenspan since mid-2004.\n\n8\n\n\f1\n\nSee, for example, Janet Yellen, “2006: A Year of Transition at the Federal Reserve,” Jan. 19, 2006, or\nJeffrey Lacker, “Interest Rate Policy After Greenspan,” Winthrop University, Oct. 20, 2005.\n2\nJeffrey Lacker, “Interest Rate Policy After Greenspan,” Winthrop University, Oct. 20, 2005.\n3\nJeffrey Lacker, “Inflation Targeting and the Conduct of Monetary Policy,” University of Richmond,\nMarch 1, 2005.\n\n9\n\n\f",
        "date": "February 14, 2006",
        "text_url": "https://fraser.stlouisfed.org/files/text/historical/frbrich/presidents/lacker_20060214.txt",
        "year": "2006",
        "title": "Transition and Continuity at the Federal Reserve in 2006 : Acordia/Royal & SunAlliance Distinguished Lecture Series, West Virginia University, Morgantown, West Virginia",
        "href": "https://fraser.stlouisfed.org/title/statements-speeches-jeffrey-m-lacker-6827/transition-continuity-federal-reserve-2006-678638",
        "item_id": "678638",
        "speaker": "effrey M. Lacke"
    },
    {
        "content": "Central Bank Credit in the Theory of Money and Payments\nThe Economics of Payments II Conference\nFederal Reserve Bank of New York\nMarch 29, 2006\nJeffrey M. Lacker\nPresident, Federal Reserve Bank of Richmond\n\nI’m honored to have the opportunity to speak at this conference, although I must admit\nthat I find the conference’s title a bit puzzling. I can certainly think of more than two\nconferences on payment economics. Why, the Richmond Fed alone has sponsored two;\none in 2000 and one way back in 1987.\nBut provenance aside, Jamie and Will and everyone else at the New York and Atlanta\nReserve Banks who have contributed to organizing and staging these two conferences\ndeserve our grateful commendations. Indeed, I’m quite heartened by the proliferation of\ngatherings like this, at which economic theory, econometric evidence and lessons from\nhistory are all brought to bear on questions surrounding payments systems. These\nconferences have been vital to the maturation of payment economics – the study of the\nmechanics of market exchange – as a distinct field of inquiry. Payment economics is no\nnarrow technical specialty, either: it builds on monetary theory, since use in payments\ndefines monetary instruments. It also draws on banking theory, based on the observation\nthat virtually all institutions that we usually think of as banks are significantly involved in\npayments intermediation.\nI want to talk this morning about the role of central bank credit in payments\narrangements. There is a voluminous practitioner literature that touches on this subject.\nMuch of it focuses on some of the terms on which credit is provided, and some recent\ndiscussion centers on the relative advantages of collateralization versus overdraft fees in\nmanaging the risks that arise from the provision of intraday central bank credit. I want to\noffer some thoughts on these issues, but my main purpose today is to explore what\npayment economics has to say about the role of central bank credit in the payments\nsystem.\nOne theme I will emphasize is that payments system policy – specifically, the terms on\nwhich daylight credit is offered – ought to be analyzed within the broader context of the\narray of central bank policies surrounding the provision of deposit accounts. This\nviewpoint naturally connects daylight credit policy to the lender of last resort function as\nwell as the operational mechanics of setting the overnight interbank interest rate. This\nviewpoint leads me quite naturally to a modest proposal for improving payments system\npolicy and the operations of monetary policy. I should emphasize at the outset that my\npolicy proposal is offered up in the spirit of academic inquiry, with the aim of stimulating\ndiscussion that will enhance our understanding of how best to achieve our policy goals. I\nshould also emphasize that the thoughts I’ll be sharing with you this morning are my\nown, and do not necessarily represent the views of the Federal Reserve System.\n\n\fCentral Banks in the Payment System\nCentral banks play a variety of roles in the payment system. The most fundamental, I\nwould argue, is providing banks with deposits and a means of transferring them to make\ninterbank payments. Modern central banks provide electronic transfer systems, but\nsystems based on paper or face-to-face payment orders go back centuries. Indeed,\nprototype central banks – that is, public sector institutions providing transferable deposits\nto banks for use in settlement – are documented in the early 1400s in the northern\nMediterranean (van Dillen, 1964, and Mueller, 1997). I recommend to you a recent\nAtlanta Fed working paper by Stephen Quinn and Will Roberds that provides an\nexcellent description and analysis of the 17th century Bank of Amsterdam, a prominent\nand well-documented example of this type of institution (Quinn and Roberds 2005).\nAdvances in the theory of payments have emphasized the role of communication and\nrecord-keeping in conveying information about the participants in an economic\ntransaction. The economic function of a payment instrument is to communicate reliably\n(that is, in an incentive compatible way) about the buyer’s past transactions (Townsend,\n1989, and Kocherlakota, 1998). Banks, from this perspective, are fundamentally\nspecialized institutions for issuing widely accepted payment instruments, in contrast to\ntheir traditionally emphasized role as balance-sheet intermediaries. Indeed, the provision\nof payments services, I believe, better defines banking than balance-sheet intermediation,\nwhich has been the traditional focus of banking economics, but which many other\nnonbanking institutions engage in as well.\nIssuing, clearing and settling payment instruments are essentially communication and\nrecord-keeping activities. The central role of communication technologies in payment\narrangements points, in modern settings, to the importance of economies of scale,\ncommon costs and joint production. These conditions can give rise to “network effects”\nin which much of the benefits and costs are shared among multiple participants. Private\norganizations that deal effectively with such technologies can be described as clubs, and\nthe theory of clubs teaches us that terms of membership are just as important as unit\nservice prices in inducing efficient participation in the presence of network effects.\nEfficient communication arrangements often take the form of networks in which many\npaths connect through a central node. A clearinghouse can be viewed as a natural club\narrangement for such centralized settlement activities. A central bank then represents a\nnationalized central settlement node for interbank payments. Contemporary legal\nrestrictions more or less compel most banks to settle through the central bank. Some\neconomists have argued that such nationalization was efficiency-enhancing (Goodhart,\n1988). For club goods, however, there is often a range of allocations consistent with\nefficiency – that is, with Pareto optimality. The formation of central banks may represent\nthe pursuit of a politically favored allocation of the net benefits of clearinghouse\narrangements. For example, research into the Federal Reserve’s entry into check\ncollection suggests that it was less about cost-efficiency than it was about shifting the\ncost of collecting checks drawn on country banks.\n\n2\n\n\fIf the fundamental core of central banking consists of interbank deposit services, then the\nfundamental core of central bank policy consists of all of the terms and conditions under\nwhich those deposit services are offered. These include the obvious pricing terms, such as\nthe nominal rate paid on deposits (zero at your Federal Reserve Bank) and the fee\ncharged for transferring funds. It also includes legal restrictions, such as reserve\nrequirements, that impose constraints on deposit holdings. The determination of the\nquantity of deposit liabilities supplied is also a component of central bank policy. Under\ncurrent U.S. arrangements, the New York Fed’s trading desk conducts daily open market\noperations so as to supply an amount of deposits expected to result in an interest rate on\novernight interbank loans equal to the target rate set by the Federal Open Market\nCommittee. Thus the phrase “central bank policy” should be construed here to include the\nmonetary policy operational regime, since, as I’ll argue below, it affects banks’ payment\nsystem choices. This connection between the Fed’s daylight credit arrangements and the\nbroader monetary regime implies that attempts to optimize each separately may not\ndeliver the best policies.\nCentral Bank Credit in the Payment System\nCentral banks have traditionally viewed the provision of credit to the banking system as\nan essential tool for achieving their goals. The lender-of-last-resort function is a widely\naccepted role for central banks to play in responding to emergency liquidity needs.\nBagehot’s prescription – to lend freely but only at a high rate on good collateral to\nsolvent institutions – is one of the most well-known maxims in central banking, although\nsome of these distinctions can be tricky to apply in practice.\nIt is important to recognize, however, that central bank lending involves two distinct\nactions. The first is an increase in the deposit account liabilities of the central bank. The\nsecond is the acquisition of a private liability. In Bagehot’s time, acquiring private\nliabilities was the main method of altering the aggregate supply of central bank deposit\nliabilities, and so the lender-of-last-resort policy he prescribed was the natural way to\nprovide for an elastic supply of deposits when demand for those deposits spiked. The\nfounding of the Federal Reserve System was motivated by a similar desire to prevent\ninterest rate spikes when the demand for reserves surged. The advent of open market\noperations in liquid government securities, however, made it less obvious that acquiring\nprivate liabilities was the best way to manage the supply of central bank deposits. Most\ncentral banks now treat open market operations aimed at pegging overnight interbank\ninterest rates as distinct from lending to individual banking institutions. In fact, pegging\ninterest rates automatically sterilizes the effect of such lending on aggregate deposit\nsupply. Discount window lending now represents a form of fiscal policy – a public sector\nloan to a private entity. It is no longer necessary to the provision of an elastic supply of\nreserves.\nThe lender-of-last-resort function typically involves overnight credit. Many central banks\nprovide intraday credit in the course of operating interbank payment systems that provide\npayment finality. Of course, daylight credit that is not extinguished by the end of the\n\n3\n\n\fprocessing day becomes overnight central bank credit of some form or another. Central\nbanks have taken different approaches to the provision of daylight credit. The Swiss used\nto just say no; now they lend via intraday repurchase agreements. Most central banks\nprovide daylight credit on fairly liberal terms. Many insist that such credit be fully\ncollateralized. The Fed currently allows daylight credit to be uncollateralized, but charges\na fee equivalent to 36 basis points at an annual rate on daylight credit above a certain\nthreshold.\nPayments Theory\nWhat does economics have to say about the role of central bank credit in the payments\nsystem? The nature of the problem provides some guidance, I believe, regarding the\nmethodology one needs to bring to bear. To evaluate the role of central bank credit, one\nneeds to assess the costs and benefits of alternative policy regimes governing the\nprovision of that credit. To do that, one needs to understand how bank behavior will\nchange when one changes central bank credit policy. In other words, how will deposit\nbalances and the timing and magnitude of payment flows differ from one regime to\nanother? Empirical analysis of payments systems data can provide some assistance here\nby providing an understanding of the underlying patterns of payment flows among banks.\nBut such analyses invariably run into the “Lucas Critique” – that is, that estimated\nrelationships from the status quo regime may shift dramatically in response to a change in\nregime. To the extent that one is evaluating an alternative regime that differs substantially\nfrom current policy, one must identify the “structural” determinants of bank behavior that\nare invariant across regimes. Thus, evaluating alternative payment policy regimes calls\nfor a theoretical framework, although observations from history or across countries might\nalso provide some insights. The analysis of a system’s likely response to a major shift in\npolicy requires a plausible model that incorporates the effects of central bank policy on\nequilibrium private sector behavior.\nWhat should we look for in models of payment activity? One important principle is\nembodied in William Baxter’s (1983) Dictum—that the issuance, use, clearing and\nsettlement of a payment instrument is a service of joint benefit to the buyer and the seller\nand that service is provided jointly by all parties to clearing and settlement. As a result, a\nsound economic evaluation of alternative payment policies requires assessing the effect\nof those alternatives on the well-being of and costs incurred by all of the parties involved.\nModels that omit the parties for whom banks are clearing and settling payments – the\n“end-users” – will fail to satisfy Baxter’s Dictum, and will be potentially misleading.\nAs I mentioned earlier, payments arrangements are communications networks, and these\noften take the form of club goods. Private agents that find themselves in such\nenvironments will tend to create multilateral institutions to efficiently cope with their\ninterdependencies. A good payments model should recognize that payment instruments\nand institutions are not exogenous, but are determined by the nature of the information\nand other frictions facing traders in the model environment. This endogeneity of payment\nbehavior is what makes the application of carefully specified models essential for\nthinking about the consequences of significant changes in central bank policies.\n\n4\n\n\fViewing instruments and institutions as endogenous adaptations to the structure of the\neconomy has important methodological implications. First, whenever possible, models of\npayment behavior should be fully articulated general equilibrium models, specified, in\nthe words of an old but useful slogan, at the level of preferences, endowments and\ntechnologies. This is essential for drawing welfare conclusions about alternative policies.\nSecond, the endogeneity of institutions places mechanism design at the heart of payments\ntheory, as is true for modern monetary theory. Under a mechanism design approach,\npayment instruments are seen as messages that embody contingent contracts, and one can\nmodel the information and risk allocation characteristics in a way that takes into account\nthe limitations imposed by real-world payment technologies – for example, the costliness\nand falsifiability of communication, verification and authentication.\nThe Freeman Model\nScott Freeman (1996) developed a model that meets these criteria and has proven useful\nfor studying the role of central bank credit in settlement arrangements. In the\nenvironment of the Freeman Model, both fiat money and private liabilities serve as means\nof payment. Moreover, each period many agents meet at a central location, some bearing\nprivate payment instruments that they want to exchange for money, and others bearing\nmoney with which they will redeem their debt. The (exogenous) timing of agents’\narrivals and departures are such that early in the meeting there is an imbalance between\nagents bearing debt they wish to redeem for money and agents with money to offer for\ndebt. Without central bank intervention, the debt sells at a discount early in the period, an\ninefficiency relative to frictionless settlement. In this model, the central bank can\npurchase debt for newly minted money and later retire that money by presenting the debt\nto issuers for payment.\nThe Freeman Model was developed to study the central bank’s ability to accommodate a\ntemporary bulge in the demand for money in connection with settlement in a way that\ndoes not create inflation. Freeman makes reference to Milton Friedman and Anna\nSchwartz’s (1963) discussion of seasonal movements in money demand in the U.S.\nduring the 19th century. But the series of central bank transactions described above can\nbe interpreted as a short-term or even intraday loan from the central bank to the issuer of\nthe debts. Under this interpretation, Ruilin Zhou (2000) has shown that the optimal terms\nfor the central bank transaction are equivalent to daylight credit at a zero interest rate.\nOne important observation on the Freeman model is due to Ed Green (1997). By\nconstructing a mechanism by which a coalition of private agents can achieve the same\noutcome as central bank intervention in the Freeman Model, Green showed that central\nbank credit was not essential for achieving an optimal allocation. In fact, the coalition\ndescribed by Green’s Theorem resembles the private clearinghouses which stood at the\napex of the U.S. clearing and settlement systems before the creation of the Federal\nReserve. This result highlights the lesson that the need for (perhaps quite complicated)\nmultilateral coordination does not by itself create a need for public sector involvement in\na payments system. This lesson is buttressed by the observation that many private net\n\n5\n\n\fsettlement arrangements exist alongside central bank gross settlement systems. As I noted\nearlier, this reasoning suggests that the question of the central bank role in payments is\nless about efficiency and more about the distribution of costs and benefits.\nAnother important observation on the Freeman Model involves its finding that the\noptimal interest rate on intraday central bank credit is equal to zero. A key feature of his\nenvironment that helps deliver this result is the absence of intraday discounting. An\ninterest rate is the intertemporal price of consumption, and in the Freeman model,\nconsumption is discounted only period-to-period, not within the settlement period. This\namounts to saying that there is no within period (intraday) opportunity cost of\nconsumption or money, an assumption that may or may not be a good approximation to\nthe operation of large value payments systems. Whether it makes sense to posit that all\ndiscounting takes place overnight is an important open research question, especially when\nthe overnight period lasts just 2 ½ hours, as it does for Fedwire.\nIt is worth noting that the motivation for daylight credit in the Freeman Model is\nunrelated to any risk of so-called “gridlock.” People describe gridlock as occurring when\nbanks strategically delay payments within the day, thereby increasing the system’s\nprocessing burden late in the day. The option to delay payment is not available in the\nFreeman Model. In more general settings, one important question regarding the potential\nfor gridlock is the extent to which repeated interaction can constrain the incentive for\nstrategic misbehavior. It is also worth considering whether gridlock could itself be a\nconsequence of the status quo policy regime.\nYet another noteworthy feature of the Freeman Model is that the central bank’s extension\nof daylight credit is risk-free. From this perspective, one might view a daylight overdraft\nfee as compensation for risk. Ideally, one would want to set this fee in Pigovian fashion\nso as to eliminate banks’ incentives to overuse daylight credit. One might think that\nsetting the fee at a level that compensates the central bank for its credit-risk exposure\nwould do the trick, but this would ignore the role of the deposit insurance fund. A central\nbank’s claim on a failing bank’s collateral simply reduces the liquidation value of the\ninstitution and thereby increases the cost to the deposit insurance fund. Moreover, central\nbank lending can allow the chartering agency to delay closure and facilitate the exit of\nuninsured creditors, further shifting losses from private counterparties to the public sector\nand exacerbating moral hazard. Either way, Federal Reserve risk exposure is the wrong\nmetric against which to benchmark overdraft fees. It is essential, in my view, to evaluate\nthe risks associated with central bank credit from the comprehensive perspective of the\nconsolidated fiscal balance sheet rather than from a purely central bank point of view.\nWhile it is widely recognized that credit risk is an element of the benefit-cost calculus\nsurrounding daylight credit, assessment of this risk is fraught with difficulty. When\nfinancial conditions are generally strong, the risk of actual loss due to daylight credit\nexposure is likely to be small, and even a small benefit in the form of a smoother\nfunctioning payment system might appear to make the provision of central bank credit\nworthwhile. Daylight credit is often particularly useful during a severe operational\ndisruption, as illustrated by the aftermath of the terrorist attacks of September 11, 2001.\n\n6\n\n\f(Lacker, 2004) While some banks delayed payments out of concerns about incoming\nfunds, the availability of daylight credit built confidence that payments would flow.\n(McAndrews, 2002) On September 11, the general condition of the banking system was\nquite strong. Should a major operational disruption occur when some financial\ninstitutions are generally more fragile, then an expansion of central bank credit could\ninvolve a substantial increase in exposure.\nOperational disruptions aside, weak banking institutions can create broader moral hazard\nproblems regarding daylight credit. Large banks build sophisticated payment processing\nsystems assuming the availability of automatic daylight credit. Reconfiguring a bank’s\noperations to cope with a denial of daylight credit can be very costly and highly visible to\ncounterparties. This makes it difficult for the Federal Reserve to withdraw daylight credit\nin the case of weak or failing institutions, and this in turn can substantially weaken\nmarket and supervisory discipline.\nReserves versus Payments Credit\nThe Freeman Model has been cited as support for minimal daylight overdraft fees, but I\nwould like to explore an alternative central bank policy regime that involves no daylight\ncredit at all. Under this regime, the Fed would automatically “sweep” the overnight\nexcess reserve balances of banks into reverse repurchase agreements. Specifically, at the\nclose of Fedwire (6:30 p.m.) we would sell them U.S. Treasury securities in exchange for\nall of their excess reserve balance. At the opening of Fedwire on “the following day”\n(actually 9:00 p.m. the same night) the transaction would be reversed; we would buy back\nthe securities and credit their account for the purchase amount, plus interest. Upon\ninitiation of the service, the Fed would conduct a large one-time open market purchase of\nsecurities during the day to start the program up with abundant daylight reserves.\nIf the interest rate were set close to or at the target fed funds rate, this scheme would\nallow us to curtail daylight credit without imposing much cost on banks. For every dollar\nof daylight credit we withdraw, we could supply an additional dollar of daylight reserves\nvia the initial open market purchase. In the limit, we could withdraw all access to\ndaylight credit and increase the aggregate supply of daylight reserves by the maximum\namount of daylight credit usage. In principle, any pattern of intraday payments that is\nfeasible under current policy would still be feasible; no change in the timing of payments\nwould be necessary.\nThe obvious cost to a bank of substituting overnight balances for daylight credit is the\nforegone interest on overnight balances. A Fed sweeps service would virtually eliminate\nthe opportunity cost of holding large daylight balances if the interest rate was set at the\novernight federal funds target rate. This illustrates the extent to which the demand for\ndaylight credit can be viewed as driven by the tax on Fed deposits due to the lack of\ninterest on reserves. Banks could hold large overnight balances now if they so desired,\nbut they prefer to use daylight credit and hold quite minimal balances beyond those\nneeded to meet reserve requirements.\n\n7\n\n\fNote that this policy is equivalent to the optimal policy recommended by the Freeman\nModel of intraday purchases of securities that are reversed at the end of the day. The\nsweeps service would withdraw substantial balances at the end of the settlement day and\nthen inject them back in at the beginning of the next day. But the sweeps plan I described\nwould not be feasible in the Freeman Model, because different agents participate in the\nsettlement meeting each period. Thus, the Freeman Model does not provide opportunities\nto substitute overnight balances for daylight credit. This illustrates the source of the\nFreeman Model’s crisp prediction regarding daylight credit interest rates: the market for\ndaylight credit is sharply segmented from overnight asset markets. This suggests that to\nfully understand the economics of daylight central bank credit we need models that allow\nfor nontrivial substitution between overnight balances and daylight credit.\nIn the Freeman Model, the central bank acquires the private payment liabilities that give\nrise to the daylight demand for money, while the sweeps proposal is agnostic on the debt\nused in the overnight reverse repurchase agreements, although U.S. Treasury securities\nare the natural candidate given the existing Fed book-entry securities service. Of course,\nprivate payment liabilities are the only debt in the Freeman Model, so no meaningful\nquestion arises there, but this points to what might be the most essential difference\nbetween various central bank daylight credit policy regimes: namely, the nature of the\nfinancial claims the central bank acquires. Under current Fed policy, the Federal Reserve\nBanks take unsecured claims when they provide daylight credit, although operating\ncirculars create a lien on any bank collateral that happens to be pledged for use in\novernight borrowing, so perhaps it is best to describe Fed daylight credit as partially\nsecured. Central banks that require full collateralization of daylight overdrafts often allow\na range of assets to serve as collateral – similar to the Fed’s policies for discount window\ncollateral. It is beyond my scope here, but the question of the appropriate collateral for\ncentral bank credit exposure is an open question that involves deeper issues surrounding\nthe financial safety net and related moral hazard considerations. But note that the sweeps\nservice I have described is nearly equivalent to collateralized daylight credit, if the\neligible collateral and repurchase transactions are limited to the same set of assets.\nAside on simplifying monetary policy implementation\nOne side benefit of the sweeps service I have described is that it would allow us to\nsimplify monetary policy operations. At present, New York Fed staff essentially\nestimates the banking system’s demand for excess reserves each day at the funds rate\ntarget and they supply that amount through open market operations. In the process, they\nmust estimate a variety of “technical” influences on the reserves market – changes in\nTreasury balances, for example. The New York Fed staff generally intervenes only once\neach day, however, usually in the morning. Unanticipated disturbances to reserve supply\nor demand can occur after they have intervened, and these can drive the market federal\nfunds rate away from the target. Although it is unclear whether there are significant\nwelfare costs of intraday fed funds rate volatility, substantial resources are devoted to\nassembling data and estimating reserve factors.\n\n8\n\n\fWith a sweep service in place paying interest at the target rate, monetary policy\noperations could in principle be substantially simplified by supplying, via open market\npurchases, more reserves than the banking system wishes to hold. No bank would lend\novernight funds in the market at less than the rate on our sweep service. And a bank in\nneed of borrowed funds could always find a willing lender at a risk-adjusted spread over\nthe sweep rate. The market funds rate thus would not rise above the sweep rate, except to\nreflect borrower-specific risk. The New York Fed staff would merely need to provide an\namount of reserves that will be sufficient to oversupply the system with reserves and\nmeet daylight settlement needs. But they would not need to estimate daily reserves\npositions as precisely as they do now, because a “miss” would rarely affect the funds rate.\nIt’s easy to think of interesting questions about how one would implement an idea like\nthis. For instance, because of some peculiar accounting rules, banks’ overnight reverse\nrepurchase holdings “uses balance sheet” and could require costly additions to capital for\nparticipating banks. If so, then even a rate equal to the target rate would not necessarily\nfully eliminate the opportunity cost of excess reserves. This and other interesting\nquestions merit careful further analysis. But the proposal demonstrates my theme that\ncentral payment credit should be understood whenever possible in the context of the\nbroader set of monetary arrangements in place. This, by the way, is a point that is made\nvery cleanly by the Freeman model.\nConclusion\nLet me conclude by emphasizing what I think are two key lessons from the theory of\npayments. First, understanding payments arrangements and the appropriate role of the\ncentral bank requires a clear understanding of private arrangements and private incentives\nin settings where the services (like payment clearing and settlement) involve multilateral\nbenefits and shared costs. That is, models of payment behavior and analyses of payment\npolicy should respect Baxter’s Dictum to evaluate effects on all parties to a payment\narrangement. The Freeman Model, and other models derived from modern monetary\ntheory are typically very diligent in this regard. Even so, it is hard in such models to\nidentify imperfections that a central bank or other public entity is uniquely suited to\nresolve. As demonstrated by Green’s Theorem, pairing Baxter’s Dictum with a\nmechanism design approach makes clear the strong incentives that private agents have to\nfind efficient arrangements, and this is the second lesson. The network nature of\npayments systems should not be taken to imply the existence of market failures when\nvoluntary, multilateral arrangements are capable of incorporating all of the affected\nparties.\n\n9\n\n\fReferences\nVan Dillen, J.G., 1964. History of the Principal Public Banks. A.M. Kelley, New York.\nMueller, Reinhold G., 1997. The Venetian Money Market: Banks, Panics, and the Public\nDebt, 1200-1500. Johns Hopkins University Press, Baltimore.\nQuinn, Stephen, and Will Roberds, 2005. “The Big Problem of Large Bills: The Bank of\nAmsterdam and the Origins of Central Banking.” Working Paper 2005-16, Federal\nReserve Bank of Atlanta.\nTownsend, Robert M, 1989. Currency and Credit in a Private Information Economy.\nJournal of Political Economy 97, 1323-1344.\nKocherlakota, Naryana R., 1998. “Money is Memory.” Journal of Economic Theory 81,\n232-251.\nGoodhart, Charles, 1988. The Evolution of Central Banks. The MIT Press, Cambridge,\nMass.\nBaxter, William F., 1983. “Bank Interchange of Transactional Paper: Legal and\nEconomic Perspectives.” Journal of Law and Economics 26.\nFreeman, Scott, 1996. “Clearinghouse banks and banknotes over-issue.” Journal of\nMonetary Economics 38; “The Payments System, Liquidity, and Rediscounting.”\nAmerican Economic Review 86.\nFriedman, Milton, and Anna Schwartz, 1963. A Monetary History of the United States.\nPrinceton University Press, Princeton, N.J.\nZhou, Ruilin, 2000. “Understanding Intraday Credit in Large-Value Payment.” Federal\nReserve Bank of Chicago Economic Perspectives 24.\nGreen, Edward J., 1997. “Money and Debt in the Structure of Payments.” Monetary and\nEconomic Studies 15.\nLacker, Jeffrey M., 2004. “Payment System Disruptions and the Federal Reserve\nFollowing September 11, 2001.” Journal of Monetary Economics 51.\nMcAndrews, James J., and Simon M. Potter, 2002. “Liquidity Effects of the Events of\nSeptember 11, 2001.” Federal Reserve Bank of New York Economic Policy Review 8.\n\n10\n\n\f",
        "date": "March 29, 2006",
        "text_url": "https://fraser.stlouisfed.org/files/text/historical/frbrich/presidents/lacker_20060329.txt",
        "year": "2006",
        "title": "Central Bank Credit in the Theory of Money and Payments : The Economics of Payments II Conference, Federal Reserve Bank of New York",
        "href": "https://fraser.stlouisfed.org/title/statements-speeches-jeffrey-m-lacker-6827/central-bank-credit-theory-money-payments-678639",
        "item_id": "678639",
        "speaker": "effrey M. Lacke"
    },
    {
        "content": "The Economic Outlook\nEconomic Roundtable of the Ohio Valley\nParkersburg, West Virginia\nApril 4, 2006\nJeffrey M. Lacker\nPresident, Federal Reserve Bank of Richmond\n\nIt is a pleasure to speak on the economic outlook this morning, in part due to this\ndistinguished Ohio Valley audience, and in part because the outlook is so encouraging.\nGrowth is proceeding on a solid pace this year, and inflation is low and stable. Moreover,\nour economy has withstood several substantial shocks over the last several years, and yet\nhas remained on course. So, I think we have abundant reason to be grateful for a quite\npositive economic outlook. Before I begin reviewing that outlook, however, I would like\nto note, as usual, that the views expressed are my own and are not necessarily those of\nmy colleagues in the Federal Reserve System.\nIt has now become uncontroversial to say that the outlook for overall economic activity is\nquite healthy. But six months ago, you may recall that many pundits were decidedly less\noptimistic. In the wake of the destruction caused by two hurricanes, energy prices had\nsurged. From the end of 2004 to the peak last fall, crude oil prices rose 56 percent,\nwholesale natural gas prices rose 129 percent, and retail gasoline prices rose 70 percent.\nTo some, it seemed obvious that the high energy prices would lead to a significant and\npersistent reduction in consumer spending, which would bring overall economic activity\nto the edge of recession. That didn’t happen. It is true that the growth rate of real GDP\nin the fourth quarter fell by about 2 percentage points from its trend over the previous two\nyears, but a closer look reveals that transitory factors played a large role there. Other data\nhave remained robust, and the consensus forecast is now that real growth in the first half\nof this year will be at about a 4 percent rate.\nLet’s take a closer look at some of the recent data that support this healthy outlook.\nStarting with the national labor market, payroll employment has grown rapidly, adding\nalmost a million new jobs in the last four months, through February. This is more than\ndouble the rate that would simply keep pace with population growth. As you might\nexpect, this has driven the overall unemployment rate down under 5 percent. Another\nindicator of a strong demand for labor is wage growth, which has been steadily increasing\nlately. Over the same four months, average hourly earnings have risen at a 3.5 percent\nannual rate, markedly above the 3 percent growth we had seen in the previous 12 months.\nThe combination of rising employment and rising wage gains has supported substantial\nincome growth – over the last four months for which we have data, real personal income\nhas risen at a healthy 5.4 percent annual rate. And that, in turn, helps explain the\nresilience of consumer spending. The conventional view of economists has long been that\nconsumer spending is governed predominantly by a household’s assessment of their own\n\n\ffuture real income streams. Thus, despite rising energy prices and surveys last fall that\nsuggested sagging consumer confidence, inflation-adjusted consumer spending increased\nat a booming 8.0 percent annual rate over the holiday season, and now runs at about 3.2\npercent ahead of a year ago.\nLooking ahead, to assess the outlook for consumers’ spending, you begin with their\nincome prospects. Expectations are that the overall labor market will continue to be\nstrong: continued job growth, a moderate unemployment rate, and further real wage gains\nshould lead to healthy advances in incomes and, thus, overall consumer spending.\nBefore turning away from households, I’d like to touch on residential housing activity.\nAs I’m sure you know, the housing market has had an amazing run in recent years. To\ncite one measure, new housing starts rose from 1.57 million units in 2000 to 2.07 million\nunits in 2005, a remarkable 5.7 percent average annual rate of increase. And that’s just\nthe number of housing units; on top of that, the size and quality of the average new home\nhas been steadily increasing. Another indicator of strong demand was rising prices for\nexisting homes. For the nation as a whole, the price of a typical single-family home rose\n55 percent over the same time period.\nYou won’t hear me use the B-word to describe this remarkable activity. Instead, I\nbelieve fundamental factors can fully explain the expansion we’ve seen in the demand for\nhousing, particularly rising incomes, rising population, favorable tax treatment, and very\nlow interest rates. At the present time, mortgage interest rates are not as favorable as they\nwere a few years ago, and so it is not surprising that we are seeing some signs of a\ntapering off of residential activity in many markets. For example, there were 1.28 million\nnew single-family home sales last year, but so far this year the sales rate has averaged\n1.14 million. I see this not as a precipitous decline, but rather as a return to more normal\nconditions in many markets. This return to normalcy is especially pronounced in the\ninformal evidence we receive. The multiple first-day bids and final sales at above-asking\nprices that were observed in many markets have become increasingly rare. Also, the\namount of time that a home remains on the market has risen back up to more typical\nlevels. Looking ahead, it seems reasonable to expect the housing market to remain\nstrong, even as some further tapering off in sales and production takes place.\nThe key point I would like to emphasize is that the housing phenomenon was not a\nmysterious, independent boost to the economy, driven by some sort of animal spirits, but\ninstead was a rational response by households to the economic fundamentals, especially\nvery low real interest rates. Thus, going forward, the adjustment of the housing market to\nevolving fundamentals will continue to fit comfortably within the standard economic\nframework. My assessment is that plausible rates of moderation in housing activity will\nnot pose a problem for overall activity this year or next. Moreover, I don’t see\ndiminished housing price appreciation as a major problem for consumer spending, since\nagain, the primary determinant of spending is income, and we see solid and improving\nprospects for real incomes for the nation as a whole.\n\n2\n\n\fTurning to firms, the fundamentals for business investment appear to be quite sound.\nCapital formation, particularly investment in information and communications\ntechnology, played an instrumental role in the widely noted surge in productivity growth\nthat took place in the late 1990s. The unique fundamental driving force then was the\nrapid and sustained fall in the relative price of new computing equipment and associated\nproducts. This investment boom resulted in a growing capital stock, and as a result rising\nproductivity growth. Indeed, productivity growth had only averaged 1.38 percent per\nyear for over two decades, but from 1995 to 2000 averaged 2.52 percent per year. That\nmay sound like a small difference, but remember that over time, productivity growth is\nthe foundation of rising standards of living, and that compounding over many years can\ntransform small differences in growth rates into substantial differences in incomes. Thus\nif productivity growth remained at 1.38 percent, it would take around 50 years for\naverage incomes to double. But with productivity growth at 2.52 percent, the doubling\ntime is cut to almost 28 years.\nLooking at more recent numbers, productivity growth since 2000 has averaged 3.3\npercent per year, which incidentally would double average incomes in less than 21 years.\nThis is an astonishing performance over a time period with significantly lower rates of\ncapital formation than in the late 1990s. Thus, recent productivity gains appear to owe\nsomewhat more to the re-organization of business processes than to the application of\nadditional capital. But as business investment continues to grow, productivity growth is\nlikely to be driven more by capital formation. We should therefore pay special attention\nto current prospects for investment spending.\nIn my view, the fundamentals for investment are encouraging. In the high-tech area, we\nare still seeing declining relative prices for many products. Business sales are strong.\nNew orders for capital equipment have been on a pronounced uptrend for 2 ½ years. The\ncost of capital remains favorable. Capacity utilization in manufacturing has recovered\nfrom the recession and any capital overhang is largely behind us. And business\nprofitability is unusually high. Putting these all together, I expect investment spending to\nbe quite robust this year. Falling relative prices should continue to support technology\nupgrades that enhance efficiency for many firms. In addition, rising capacity utilization\nrates suggest that many firms will need to add capacity to keep up with demand growth.\nAnd if I am correct, this capital spending should be enough to support overall demand in\nthe economy, even as the housing market cools down.\nThis is a good time to review the bidding. It looks like we’re on track for continued\nexpansion, with real GDP growing at about a 3 ½ percent annual rate this year.\nConsumer spending should grow in line with GDP and will be supported by job growth\nand real wage gains. Residential investment will flatten or slow, but business capital\nspending should remain robust. And that capital spending will support productivity\ngrowth going forward, which in turn will support the future income growth that keeps\nhousehold spending healthy. And while there are risks to this forecast, as there are with\nany forecast, I do not see any single scenario that is compelling enough to alter the\ncentral tendency of this outlook.\n\n3\n\n\fLet’s turn now to the inflation picture, where again things are looking better now than\nmany had expected six months ago. Back then, the energy price surge had led some\nobservers to expect to see those prices pass through to a broad range of prices of goods\nand services, much like what happened in the 1970s. But that hasn’t happened. Core\ninflation has been low and relatively steady in the last several years. Our preferred\ninflation measure, the price index for core personal consumption expenditures, has risen\n1.8 percent over the last 12 months. Despite rising energy prices, core inflation actually\nfell slightly last year, since the core price index had risen 2.2 percent in 2004. Similarly,\nwe are not seeing any sign of rising inflation in the most recent data. Over the last two\nmonths, for example, the core index has increased at a 1.8 percent annual rate as well. To\nput that number in perspective, it lies close to the 1 ½ percent figure that I and several\nothers have proposed as an announced numerical objective for inflation.\nWhy haven’t high energy prices boosted other prices as much as many had feared?\nProbably because those fears are based on looking back at the 1970s and seeing that\nsimilar energy price increases had been followed by broader increases in overall inflation.\nI would argue that any analogy with the 1970s is badly flawed. Back then, monetary\npolicy failed to respond effectively to rising inflationary pressures and the public’s\nexpectations of future inflation had consequently become unanchored. Thus, at that time,\nhigher energy prices became a signal for firms to raise prices and for workers to demand\nhigher wages in order not to fall behind a prospective inflationary surge.\nToday, however, the Fed places its highest priority on keeping inflation low, and our\nability and willingness to follow through on our announced intentions appears to be\nwidely understood. Thus, longer-term expectations of inflation have remained moderate\neven as energy prices have moved up over the last couple of years. Looking ahead, shortterm movements in the inflation rate can be hard to predict. But what is important is to\nstabilize inflation over medium- and longer-term horizons. And here the indicators about\nwhat the public expects look fairly good. Both survey data and the market prices of\ninflation-protected Treasury securities tell us that the public expects inflation to continue\nto be contained. I am confident that we at the Fed have the knowledge and the will to\nvalidate those expectations.\n\n4\n\n\f",
        "date": "April 04, 2006",
        "text_url": "https://fraser.stlouisfed.org/files/text/historical/frbrich/presidents/lacker_20060404.txt",
        "year": "2006",
        "title": "The Economic Outlook : Economic Roundtable of the Ohio Valley, Parkersburg, West Virginia",
        "href": "https://fraser.stlouisfed.org/title/statements-speeches-jeffrey-m-lacker-6827/economic-outlook-678640",
        "item_id": "678640",
        "speaker": "effrey M. Lacke"
    },
    {
        "content": "The Evolution of Consumer Finance\nConference of State Bank Supervisors\nNorfolk, Virginia\nMay 18, 2006\nJeffrey M. Lacker\nPresident, Federal Reserve Bank of Richmond\n\nAt the outset this morning I would like to congratulate you: 2005 marked the first year in\nthe history of the federal deposit insurance program in which there were no failures of\nFDIC-insured institutions. While the banking industry clearly has benefited from a\nrelatively healthy macroeconomic environment, I think the lack of bank failures last year\nis strong evidence that supervisory agencies — both state and federal — have been doing\nan outstanding job. In fact, one could argue that we have done too good a job, since, as\nour recently retired Fed Chairman was fond of observing, the optimal number of bank\nfailures is certainly not zero, the point being that risk-taking is an essential part of\nbanking, and even if our banking system as a general matter is taking only prudent, wellmanaged risks, there may still be some failures from time to time. Furthermore, risk is an\ninherent part of innovation, and when banks are trying new things, some will succeed and\nsome will not. But innovation is vital to the continued growth and progress of the\nindustry and its ability to provide the public with ever more useful and efficient financial\nservices over time. I would like to note, as usual, that the views expressed are my own\nand are not necessarily those of my colleagues in the Federal Reserve System.\nThe theme of innovation and its relationship to risk permeates contemporary banking and\nfinance. We certainly see it in the growing use of interest rate and credit derivatives for\nrisk management. While such tools can assist organizations in limiting their exposures to\nrisk, they can also, if used imprudently, be a source of increased risk. Although the term\n“financial innovation” typically conjures up images of what we might call “high finance,”\ninnovation has also been arguably the most important driver for the evolution of the\nmarket for consumer credit, the subject of my talk to you this morning. Because much of\nthe transformation of consumer credit markets in recent decades amounts to the\ndevelopment of new and more varied loan products for a growing set of consumers with\nmore variable pricing.\nMany recent innovations in consumer credit products have garnered a fair amount of\nattention both in the popular press and in supervisory and legislative arenas. Rather than\naddress any of the specifics surrounding these issues, I would like take two steps back\nand look at these innovations from a broader perspective. Over the last two decades, we\nhave witnessed what can arguably be called a revolution in retail consumer finance.\nPerhaps the hallmark of this revolution has been the dramatic expansion of unsecured\nlending through the proliferation of credit cards. This growth has not been limited to\nunsecured credit, but also includes innovative mortgage and home equity lending.\nThe wave of innovation that has driven these trends has brought widespread change to the\nfinancial services industry. While this expansion of credit has been broadly beneficial to a\nwide array of consumers, it has also brought with it a growth in the number and\n\n\ffrequency of consumer defaults and bankruptcies, a trend that has contributed to a\ngrowing concern in some quarters that American households have “lost control” of their\nfinances to a dizzying array of new products and options and that lenders are taking on\nnew risks for which they may not be adequately prepared.\nMy main purpose today is to discuss the nature of innovation in lending, particularly at\nthe retail end. As regulators, it is important for us to understand that innovation is an\ninherently risky activity, whether we are talking about a large, sophisticated institution\nthat “invents” new products or processes, or a smaller community bank that innovates by\nputting new products or processes to use. As supervisors, it is important for us to\nunderstand that innovation in financial products is likely to be a feature of the banking\nlandscape for many years to come. Supervisory practice and philosophy should view\nfinancial innovation as a relatively permanent feature of the banking industry, rather than\ntreat each burst of innovation as an episodic, one-off occurrence. Thus, as a general\nprinciple, supervisors place a great deal of emphasis on the ability of bankers to measure,\nmonitor and manage their risk profiles over time and make informed risk acceptance\ndecisions, since risk is intrinsic to the banking business. Supervisory guidance regarding\ninnovative consumer finance products should recognize their potential benefits to a wide\narray of households in addition to their risk management implications.\n***\nThe expansion of consumer credit in the U. S. over the last decade and a half has been\ntruly astonishing. This expansion occurred across a number of product lines. Probably\nmost prominent has been the expansion of credit card lending. Home mortgage lending,\nincluding home equity credit, has also seen robust growth. Much new mortgage lending\nrecently has taken the form of so-called “non-traditional mortgages,” such as “interestonly” mortgages that allow the borrower to defer principal payments for the first few\nyears, or “option ARMs” that provide the borrower with several flexible payment\noptions.\nAn especially prominent feature of the secular expansion of consumer credit has been the\ngrowth in lending to lower-income consumers, many of whom had in the past been\nunable to obtain credit on as favorable terms from the financial sector. Indeed, many had\nbeen unable to obtain credit except from fringe lenders such as pawnbrokers, payday\nlenders, or through informal arrangements with friends and family. Some borrowers that\ntake out non-traditional mortgages would not have qualified for traditional mortgage\nproducts otherwise, or would not have qualified for loans as large. The growth in retail\ncredit, thus, has brought expanded social benefits to a wide array of consumers.\nI would argue that this broad expansion of consumer credit has been driven by advances\nin information and communication technologies, which have reduced the cost of\nobtaining, evaluating and monitoring consumer account information. At a basic level, this\ndramatically increased the productivity of the back-office functions associated with all\nphases of the banking business. Payments processing and the associated book-keeping\ntasks became much cheaper. The result was a general decline in the intermediation costs\nthat lenders ultimately must recover on top of their funding costs. Competition forced\n2\n\n\flenders to pass on these cost savings to borrowers in the form of lower lending rates.\nMore consumers could afford to borrow, and the market expanded.\nThe application of information technology to the lending process itself has been evident\nin a number of ways, from the automation of underwriting to the use of credit scoring.\nLenders have been able to access and utilize an expanded array of information about\npotential borrowers. These advances did not change the fundamental nature of\nunderwriting, however; they just made it more effective. Underwriting is about making\ndistinctions between people in order to decide whether to lend, and if so, how much to\ncharge. When lenders were limited to reviewing paper loan applications and oldfashioned credit reports, they could sort potential borrowers into only a few broad\ncategories. New technologies allowed lenders to bring more and more consumer-specific\ninformation to bear on lending and pricing decisions, and thus make finer distinctions\nbetween consumers. The result was that the lending decision and loan terms could be\nmore closely tailored to individual borrowers. Lenders were able to offer lower interest\nrates to less-risky customers, and were able to pluck out the creditworthy from among the\ngroup of customers that formerly were unable to qualify for credit at all.\nBeyond the direct impact of new technologies on underwriting, innovations also\ncontributed to the spread of loan securitization, by making it easier for investors to assess\nthe risk characteristics of the underlying loans. Securitization separates loan origination\nfrom holding loans on a balance sheet, thereby allowing originating institutions to\neconomize on funding and capital costs. And the development of quantitative methods\nfor the pricing of options — combining the massive computing power that came online in\nthe late 1980s with the models that finance theorists pioneered in the mid-1970s —\nopened the door for banks and other financial intermediaries to properly price the put\nfeature inherent in a long-term mortgage, and the option value of loan commitments such\nas home equity lines of credit and credit cards.\nThe technology-driven expansion of retail credit is evident in the growth of household\ndebt and in the proliferation of entirely new credit products. For example, many nontraditional mortgage products, particularly those offered to less-creditworthy borrowers,\nwould not have been economically feasible without the new, more advanced pricing\nmodels and underwriting techniques. Likewise, home equity lines of credit became more\nwidely available in part because of the lower cost of accurately assessing\ncreditworthiness.\nThese developments have also had important consequences for the structure of retail\nlending markets and for the activities of community banks. Much of the innovation I have\nbeen describing involves realizing economies from standardization and from the\napplication of technologies with substantial economies of scale. One implication has been\nthe increased concentration of some consumer lending activity at relatively large lenders.\nThis appears to be particularly true in the case of credit cards. On the other hand, the\nspread of securitization, especially in home lending, allows smaller institutions to remain\nin the market as originators of credits that then get securitized. On the whole, however,\ntechnological advances in lending based on quantitative underwriting seem to have\nfavored larger institutions. Consequently, these changes have tended to move community\nbanks toward lending based on less quantitative and more judgmental underwriting\n3\n\n\ftechniques where they appear to have a comparative advantage — exploiting the fact that\nquantitative measures of creditworthiness will always be to some extent incomplete, and\nthat other information available to local lenders can be difficult to commoditize. Thus,\nloans where it’s hard to quantify risk assessment, as in “character lending” and\ncommercial real estate, have become increasingly important to community banks.\nThis is also a recurring theme — the idea that technological advances in banking enhance\neconomies of scale and therefore result in more concentrated market shares. I think that\nit’s possible to make too much of this idea, since it is often possible for the benefits of\nscale to be brought to mid-sized and even smaller institutions through the provision of\nservices by third parties. Still, the consequences of innovation for the structure of the\nindustry are important to bear in mind, and the fact that banks of different sizes might\nimplement technology in different ways — some doing it in-house and some acquiring it\nfrom third parties — creates another dimension of change — organizational change — of\nwhich supervisors must be aware.\nThe usual presumption regarding innovations that successfully penetrate markets — from\nhigh-speed Internet to high-definition TV — is that they are broadly beneficial to\nconsumers, and I believe this to be true of retail financial market innovations as well. The\nexpansion of retail credit has allowed consumers greater flexibility in managing their\nhousehold finances, responding to fluctuations in household financial conditions, and\naccumulating durable goods. At the same time, the expansion of retail credit has brought\nan increase in what one might call “bad outcomes” — households that face high debt\nburdens, have trouble meeting payment commitments, and perhaps even default and\nresort to bankruptcy. The popular media regularly recount horror stories of unsuspecting\nconsumers who find themselves in dire straits following an encounter with the retail\ncredit industry. Consumer advocates have publicized accounts of abusive practices by\nunscrupulous lenders and have charged regulators with lax enforcement of existing\nconsumer protections. It appears that a significant constituency now favors tighter\nlegislative and regulatory constraints on retail credit providers of all types, from banks to\npayday lenders. And new credit market products and practices have given rise to\nsupervisory concerns about the associated risks.\nThe rising incidence of credit problems and the resulting sentiment for new or tighter\nregulation are natural byproducts, I would argue, of the wave of innovation in financial\nproducts and services. A credit expansion naturally brings with it an increase in the\nincidence of “bad outcomes.” As credit becomes available to a broader array of\nborrowers, there is an inevitable increase in the number and even the rate of\ndelinquencies, defaults and bankruptcies. Moreover, the new borrowers being drawn in to\ncredit markets are likely to be, on average, less financially savvy and more vulnerable to\nthe unscrupulous as they struggle to learn about unfamiliar credit products. The popular\nfocus on cases of fraud and financial distress often drives the politics of consumer\nfinance. The very nature of innovation in consumer credit markets thus gives rise to\ncompelling stories that are powerful motivators for attempts to regulate or restrain new\npractices.\nProposed restraints on retail lending often are intended to protect consumers from their\nown poor judgment, which makes them vulnerable to abusive lending practices. In fact,\n4\n\n\fin many historical episodes of expanding credit, the desire to regulate has been\naccompanied by a popular belief that growing debt is a sign of decaying values and thrift.\nOne historian has referred to this persistent belief as the “myth of lost economic virtue.”\nBelief in this myth can easily hide from view the positive economic role of credit in\nhousehold financial management and the benefits that come from expanded access to\ncredit.\nIncreases in the number or frequency of bad credit outcomes could also expose some\nbanks to increased losses. Of course part of the reason for a credit expansion is\nimprovements in the ability of lenders to measure, price for, monitor and absorb such\nlosses, so the mere increase in losses after the fact should not, in itself, be cause for\nconcern, especially if they are expected losses that are priced and reserved for. As long as\na lender’s entry into a new product line is appropriately managed, increased loss rates are\nin a sense a measure of the extent to which access to credit has been provided to new\nborrowers. But just as new financial products expose inexperienced borrowers to the\npossibility of mistaken credit market choices, so too may lenders bring different levels of\nexperience to the adoption of new financial products. These banks, like the new\nconsumer borrowers, will inevitably have varied experiences in their new ventures —\nsome will be more successful than others. But the learning that comes along with the trial\nand error inherent in these diverse experiences is a vital part of the innovation process.\nBecause innovation and progress don’t just come from people inventing new products;\nthey also come from people learning how to manage new processes.\nThis last observation may have implications for how regulators think about banks’\nventures into new activities — whether in consumer finance or any other line of business.\nExaminers are naturally going to pay close attention to the risks associated with new\nactivities, as well they should. But we also have to recognize the value of the learning\nthat is inherent in the process of financial innovation, as in any other innovative\nendeavor. As always, we need to be mindful of benefits as well as risks when evaluating\nbanks’ activities, and be careful not to stifle worthwhile financial innovations. Seeking\nsuch a balance suggests that robust risk practices should include sound processes for\napproving new product offerings.\nPerhaps a more important implication of retail credit expansion for banks and their\nsupervisors stems from the fact that standardization and automation have moved much of\nthis lending — or the credit exposure, in the case of home loan securitization — off the\nbooks of community bank organizations either to large banks or to securities markets in\nthe case of home loan securitization. I mentioned earlier that this seems to have driven\nmany community banks toward lending based on softer, less quantitative risk assessment\n— commercial real estate, for example. Could this broad movement have made\ncommunity bank lending inherently riskier, or harder to monitor and assess? If so, we\nwould have reason to ensure that the banks moving in this direction understand and are\nprepared to manage the risks they take on. The proposed guidance on commercial real\nestate lending issued by the federal financial agencies this past January seeks to do just\nthat. As always, however, regulators need to be mindful of the extent to which observed\ntrends in bank lending may be driven by productive innovation rather than risk\nmanagement myopia.\n5\n\n\fMuch of the popular response to consumer credit expansion and its byproducts has been\nless about prudential supervision, however, and more about consumer protection. Many\nproposals amount to calls for lending restrictions or the outright prohibition of some\nlending practices. This strikes me as a dangerous approach. In the long run, it would tend\nto slow innovation and constrain the availability of financial products to a broad range of\nconsumers in order to protect the relatively few who use a credit product inappropriately\nor unadvisedly. It would be analogous to limiting homeowners insurance on the grounds\nthat many homeowners never file claims in excess of their premium payments and thus\nend up regretting their purchase of insurance.\nSince the rise in undesirable borrowing outcomes is related to the increased participation\nof inexperienced and uninformed borrowers as the credit market expands, a more\npromising approach would seem to be to improve the knowledge and expertise of\nborrowers. One method to address this problem is through careful and more thoughtful\ndesign of lender disclosures. The supervisory community ought to encourage disclosure\nstatements written for real consumers, rather than lawyers, as now seems to be the case.\nMore broadly, moving from strict rules-based consumer protection regulations towards\nmore principles-based disclosure expectations might allow for more effective customer\ncommunications in the face of complex and ever-changing products.\nMore broadly, everyone in the financial services industry should understand their interest\nin enhancing consumers’ financial literacy. We train our young people in how to use\nautomobiles, after all, a product whose early market penetration drew in less savvy users.\nIn my opinion, we could do a better of job of training people in how to use financial\nproducts.\nOn a supervisory level, we would not want our response to the spread of new lending\nproducts to squelch innovations that are useful to consumers. So while we need to ensure\nthat banks understand sufficiently well the risk characteristics of new lending products\nthey deploy and that banks at the forefront of innovation have particularly robust risk\nmanagement practices, any guidance we provide on such products should recognize that\ninnovations that meet a market test are generally beneficial, and that the learning\ngenerated by early experience with new products often results in significant product\nimprovements over time. Balancing these considerations is the challenge.\n\nJohn Weinberg and Jennifer Zara provided valuable assistance in preparing this speech.\n\n6\n\n\f",
        "date": "May 18, 2006",
        "text_url": "https://fraser.stlouisfed.org/files/text/historical/frbrich/presidents/lacker_20060518.txt",
        "year": "2006",
        "title": "The Evolution of Consumer Finance : Conference of State Bank Supervisors, Norfolk, Virginia",
        "href": "https://fraser.stlouisfed.org/title/statements-speeches-jeffrey-m-lacker-6827/evolution-consumer-finance-678641",
        "item_id": "678641",
        "speaker": "effrey M. Lacke"
    },
    {
        "content": "",
        "date": "October 11, 2006",
        "text_url": "https://fraser.stlouisfed.org/files/text/historical/frbrich/presidents/lacker_20061011.txt",
        "year": "2006",
        "title": "The Regional Economic Outlook : District of Columbia Chamber of Commerce, Washington, D.C.",
        "href": "https://fraser.stlouisfed.org/title/statements-speeches-jeffrey-m-lacker-6827/regional-economic-outlook-678642",
        "item_id": "678642",
        "speaker": "effrey M. Lacke"
    },
    {
        "content": "Monetary Policy Tactics and Strategy\nGreater Baltimore Committee\nBaltimore, Maryland\nOctober 30, 2006\nJeffrey M. Lacker\nPresident, Federal Reserve Bank of Richmond\nThank you for that kind introduction, Don. It is a pleasure to be with this esteemed group\ntoday. This morning, I’d like to talk about monetary policy, but before I do, I need to\nnote that, as always, the views I express are my own, and do not necessarily coincide\nwith the views of my colleagues within the Federal Reserve. I’d like to talk about\nmonetary policy from two different perspectives: tactics and strategy. These obviously\nare two pertinent aspects of any sustained planning or decision-making endeavor,\nwhether it involves public policy or the private goals of businesses or households. By\ntactics, I mean the decisions we make and the actions we take on a day-to-day, month-tomonth, or, in the case of the Federal Open Market Committee, twice-a-quarter basis. Our\nmost visible tactical decision is our choice of the federal funds rate. You have probably\nnoticed that I have disagreed with many of my colleagues on this tactical choice at recent\nmeetings, and I will say a few words later on about why.\nTactics are in a sense reactive – for us, the choice of appropriate policy actions as\neconomic conditions unfold. Strategy, on the other hand, is the more forward-looking\npart of a decision-making problem: The process by which you establish specific goals\nand objectives, and think through the types of actions – that is, tactical choices – that are\nlikely to be required to move you toward your goal. A strategy doesn’t pin down all of\nyour actions in advance. Rather, a strategy guides your thinking about how to make\ntactical choices in response to incoming information in a way that is consistent with\nachievement of your long-run goals.\nTactics\nIn the first part of my remarks this morning, I would like to review the tactical situation\nfacing U.S. monetary policymakers. To set the stage, let me start with the broader\ncontext. The U.S. economy currently is in a period of transition. In the three years\nleading up to the second quarter, real gross domestic product – our broadest measure of\ntotal economic activity – grew at a 3.75 percent annual rate. That’s a very healthy growth\nrate to sustain over a number of years, and it significantly cut into the underutilization of\nlabor resources that emerged during the recession earlier in this decade. Over 5 million\nnew jobs were created over this period and the unemployment rate fell by a full 1.5\npercentage points. Labor market conditions are fairly firm now, and the economy is\ntransitioning to a period of growth at a rate consistent with job creation roughly matching\nthe growth in the number of workers over time. Although there is some uncertainty about\nexactly how fast that is, it is probably somewhere around 3 percent per year, and it would\nprobably involve creating roughly 100,000 jobs per month.\n\n\fIt would not be unusual for the transition to trend growth to be a little bumpy, however.\nThat occurred back in 1995, for example. Growth in the first half of that year dipped\nbelow 1 percent at an annual rate before returning to a healthy pace that was sustained for\nthe next five years. And this time around there is an obvious reason to expect growth to\ndrop below average for a time, namely, the end of the housing boom. I’ll offer a couple\nof observations about the boom itself before I talk about its aftermath.\nFirst, the recent housing boom was very large by historical standards; a couple of\nnumbers will help illustrate. In 2005 almost 2 million new homes were built in the U.S.,\nwhich is about 50 percent more than the average number built each year in the 1990s.\nAnd last year the average price of a home sold in the U.S. rose 13 percent; versus an\naverage increase of less than 3 percent per year back in the 1990s.\nSecond, it’s important to remember that the recent housing market boom was driven by\nfundamental factors that were – and still are – quite favorable. Population continues to\nexpand; for example, last year the number of households increased by one percent\nnationwide. Income is growing – so far this year, inflation-adjusted disposable income\nper person has increased at a 2.3 percent annual rate. Household net worth is 53 trillion\ndollars, which represents over five-and-a-half years of disposable personal income. The\ntax treatment of housing remains highly favorable. And finally, mortgage interest rates\nwere extremely low for many years, and even now are quite reasonable by historical\nstandards.\nThis multi-year surge in housing investment was bound to come to an end, as the demand\nfor upgrades and first homes became satiated. In addition, the rise in mortgage interest\nrates since 2004 has helped dampen demand. In fact, it seems likely that much of the\nincrease in interest rates was anticipated, and thus probably gave an extra boost to\ndemand in 2005 as consumers took advantage of what they saw then as the waning days\nof lower mortgage rates. A return to more normal housing market conditions is well\nunder way. New home sales are down about 20 percent from last year’s peak, and\nhousing starts have fallen by a similar magnitude. The rate of price appreciation has\nfallen substantially as well, to the point that average prices were lower in September than\nthey were a year earlier, although data on average sale prices are distorted by changes in\nthe composition of sales.\nSome further retrenchment seems likely in the months ahead, as housing market activity\nreturns to a more sustainable level in which volume, inventories and time-on-market are\ncloser to historical averages. This adjustment naturally involves a fair amount of\nuncertainty for market participants. Both buyers and sellers are probably more unsure\nthan usual right now about where prices need to settle in order to clear markets. In the\nmeantime, they are collectively engaged in a time-consuming process of discovering the\nprices at which expectations and plans of buyers and sellers are mutually consistent. But\nwhile there is substantial uncertainty about where the bottoming out will occur, I don’t\nthink a catastrophic collapse in housing activity is likely, since the fundamental\ndeterminants of housing demand that I listed earlier remain favorable – prospects for\npopulation and real income growth look good, net worth remains high, and after-tax\n\n2\n\n\fmortgage interest rates are still historically low. In fact, tentative signs are emerging that\nhousing markets may be stabilizing, although because housing data are notoriously\nchoppy, one should treat month-to-month numbers with more than the usual amount of\ncare right now.\nOutside of housing, the rest of the economy is in reasonably good health. Business\ncapital spending, for example, has been quite a bright spot in recent years. Since early\n2003, business fixed investment has grown at over a 6.5 percent annual rate, and since the\nbeginning of this year has grown at an 8.8 percent rate. This more than offset the 10\npercent contraction in residential investment over the same time period. The fundamental\nunderpinnings of near-term investment demand are encouraging as well. Profitability is\nhigh, capacity utilization has been steadily rising, and many firms see strong demand for\ntheir products. So I expect capital spending to continue to be a source of strength over\nthe next several quarters.\nMany economic analysts are concerned about the potential fallout of a weakening\nhousing market on consumer spending. Could falling housing prices cause consumers to\nrein in spending? It’s important to begin with fundamentals. While fluctuations in\nhousehold wealth are capable of affecting spending at the margin, consumers’ spending\nbehavior is predominantly determined by their current and future income prospects. And\nthose prospects are looking pretty good right now. With the unemployment rate at 4.6\npercent, the labor market is looking fairly tight. Despite large increases in gasoline prices\nearlier this year, inflation-adjusted incomes have been rising, as I noted earlier. And now\nthat we’ve seen some relief at the gas pump, it would not be surprising to see a modest\npickup in real income growth in the next couple of months. The deceleration and fall in\nhousing prices certainly has cut into household net worth to some extent, and consumer\nspending did decelerate at the beginning of this year. But so far, such wealth effects have\nbeen relatively limited – consumer spending rose a healthy 3.1 percent in the third\nquarter.\nTaking all these considerations into account, I would look for consumer spending to\ncontinue to expand at a reasonably good pace even if housing prices come in weaker than\nexpected.\nThe labor market is another widely-cited arena for potentially adverse spillover effects\nfrom the housing market. We have seen employment in the residential construction\nsector fall this year as residential building activity has declined. Fortunately, however,\nnonresidential construction is on an upswing – over the four quarters ending in\nSeptember, investment in nonresidential structures rose over 13 percent in real terms.\nThis has allowed many home construction workers to simply change construction jobs\nrather than become unemployed. Indeed, although in September residential construction\nemployment had fallen by 54,000 since peaking in February, nonresidential construction\nemployment was up by 95,000.\nSo the outlook for overall spending looks reasonably good: consumer spending is on\ntrack, and business investment is robust. The downturn in housing activity has and will\n\n3\n\n\fsubtract from headline GDP growth, but it is not likely to cancel out these sources of\nstrength.\nIn contrast, the outlook for inflation is discomforting. Over the last two years, there have\nbeen several episodes in which energy prices have surged and pushed up the overall\ninflation rate. More troubling is the fact that we have seen significant increases in “core\ninflation” – the measure of inflation that strips out food and energy prices. According to\nour preferred index, the price index for personal consumption expenditures, core inflation\nran close to 3 percent this past spring.\nWhile core PCE inflation has settled down to around 2.25 percent, that is a rate that\nwould be unacceptable on a sustained basis. Here is where tactics have to be driven by\nstrategy. The Federal Reserve’s strategic goal, as a central bank, is price stability. We\nare the only institution that can achieve this, and attaining and maintaining price stability\nis the best contribution we can make to maximizing economic growth.\nI and several other members of the FOMC have expressed the view that our price\nstability objective is equivalent to a core PCE inflation rate in a band between 1 and 2\npercent, that is, a band centered around 1.5 percent. You might think that price stability\nshould mean inflation equal to zero, that is, prices not changing over time, on average,\nbut there are known upward biases in our available price indexes, and targeting a band\nabove zero is a way of taking those biases into account.\nCore inflation has been above this 1 to 2 percent band for over two years now, since April\n2004, and is running at 2.5 percent so far this year. The longer inflation remains\nelevated, the more difficult it will be to bring it back down. As people observe actual\ncore inflation between 2.25 and 2.5 percent, and as they observe the FOMC’s tactical\nreactions to those numbers, they form expectations regarding future inflation and those\nexpectations become the basis for price setting in product and labor markets. (By the\nway, it was for his contributions to economic research on exactly this phenomenon that\nProfessor Edmund Phelps was awarded the Nobel Prize in economics several weeks ago.\nSome of his cited work emphasized the extent to which the public’s expectations will\nshift over time as they observe policymakers actual tactical choices.) The strategic issue\nhere is that if the Fed allows inflation to remain above target for too long, inflation\nexpectations could become tightly centered around the higher rate.\nThis danger is what prompted me to vote at recent FOMC meetings for tactics aimed at\nbringing inflation down more rapidly, and in a way that convinces the public of our\nstrategic intent to keep inflation low and stable. Against this risk, one must weigh the\nrisk that a further increase in the federal funds rate might exacerbate the housing-related\nslowdown. My assessment at recent meetings has been that the economy is resilient\nenough right now to withstand further policy tightening.\n\n4\n\n\fStrategy\nThere is another way for the public to learn about our intent, however, beyond simply\nobserving our tactical choices. We can try to communicate more directly with the public\nabout our monetary policy strategy. Households, businesses and financial market\nparticipants form their expectations about future inflation from several sources: past\ninflation experience, their understanding of the economic outlook, their observation of\nthe Fed’s monetary policy actions, and their beliefs about the Fed’s inflation strategy. A\nkey component of monetary policy strategy is our long-term goal for inflation – what the\nFed would like to see as an average rate of inflation over long periods of time. While it is\ndifficult to perfectly control inflation quarter to quarter, the Fed can pin down long-run\naverage inflation very well.\nInflation targeting has been adopted by many other central banks: the European Central\nBank and the central banks of the United Kingdom, Sweden and New Zealand, for\nexample. There are many aspects of inflation targeting as it has been implemented\nabroad – inflation reports, consultations with Finance Ministers, supporting legislation,\nand so on. But the core feature of inflation targeting everywhere is communicating an\nexplicit numerical inflation objective. So I think it makes sense to talk about inflation\ntargets in the context of the broader subject of “communications” – how we as a central\nbank communicate about monetary policy.\nI’d like to start by suggesting that we should not think of “conducting monetary policy”\nand “communicating about monetary policy” as two different things. It is certainly\ntempting to think of setting a target for a short-term interest rate and issuing policy\nstatements as two separate acts that raise two separate sets of considerations. But modern\nmonetary economics and common sense both tell us that the two are inseparable. People\nwill always try to figure out what the central bank is going to do with its policy\ninstrument in the future, no matter how much or how little the central bank actually says\nabout these things. If the central bank says nothing, it still implicitly communicates via\nits actions, because people will always try to infer the central bank’s future conduct from\ntheir current and past actions. In fact, modern monetary economics teaches that there is a\nvery real sense in which “monetary policy is all about communication.”\nThe logic behind this statement is not complex or arcane. First, money is intrinsically\nuseless; it has value only for what it can purchase in the future. People accept money in\nexchange for valuable resources only because they expect others to accept it in exchange\nin the future. Therefore, the current value of money depends on the value people expect\nmoney to have in the future. So expected future inflation can give rise to inflation\npressures today.\nA corollary to this principle is that controlling current inflation requires controlling\npeople’s expectations for future inflation. This is the sense in which monetary policy is\nall about communications, because anything we do to shape people’s perceptions and\nexpectations amounts to communications, whether we’re communicating by words or by\n\n5\n\n\fdeeds. The central implication here is the importance of managing and stabilizing the\npublic’s inflation expectations.\nThe history of the 1970s provides a vivid illustration. The Federal Reserve allowed\ninflation to rise during economic expansions and following oil price shocks.\nExpectations regarding future inflation subsequently rose as well, as the public observed\nour tolerance for rising inflation. This provided a further impetus to inflation, as those\nexpectations influenced wage bargains, and price-setting by firms. A large part of the\nbattle to reduce inflation in the 1980s and ’90s was a battle to dampen the “inflation\npsychology” that had taken hold, that is, a battle to convince the public that we would\nachieve and maintain price stability. Over the course of those decades, we and other\ncentral bankers around the world learned another important lesson relating to\ncommunications: Namely, that words and subsequent deeds must ultimately be\nconsistent.\nThe economic term for this principle is “time consistency,” which simply means that your\ntactical choices have to be consistent with people’s expectations of those choices over\ntime. (By the way, the 2004 Nobel Prize in economics honored Professors Finn Kydland\nand Ed Prescott for their pioneering work applying exactly this principle to, among other\nthings, monetary policy.) The more common term for this principle is “credibility,” and a\npopular slang expression is “walking the talk.” The 1970s again provide a vivid\nillustration: All throughout the 1970s, the Fed said it was against inflation, but our\nactions spoke differently and people came to believe our actions rather than our words.\nIn the early 1980s, the battle to reduce inflation required costly policy actions to convince\npeople of our intentions. It took time and effort to establish our credibility.\nWhat does this mean for inflation targeting? If we adopt an inflation target, we will have\nto be sure that we back up our commitment with appropriate monetary policy actions.\nOtherwise, our target would just be viewed as “cheap talk.” One way to appreciate the\npotential value of an explicit inflation target is to consider how it might have helped us\ncope with inflation dynamics over the last few years. On several occasions, usually in\nresponse to energy price shocks, questions have arisen about where inflation was headed,\nthat is, about what inflation rate we were willing to tolerate. After Hurricane Katrina, for\nexample, when retail gasoline prices rose above $3 a gallon, there was widespread\nspeculation that the Fed would pause in order to protect growth rather than protect price\nstability. Measures of inflation expectations rose noticeably as a result. That speculation\nwas off-base, though. Forceful public statements by Committee members tamped down\nthose expectations, but core inflation did bump up for a time as firms were able to pass on\nenergy price increases to buyers who may have been anticipating a broader upswing in\ninflation.\nA similar episode occurred this past spring in response to another round of energy price\nincreases. Inflation expectations rose, and were subsequently tamped down by\nCommittee member communications, but not before another bulge in core inflation\nemerged, a bulge that has now only partly subsided. I take both these episodes as miniinflation-scares. In both cases, and others as well in recent years, I believe some financial\n\n6\n\n\fmarket volatility can fairly be attributed to public uncertainty about our intentions for\ninflation.\nIf we had had a credible inflation target in place, I believe that market reactions most\nlikely would have been different. People would have known that we intended to return\ncore inflation to our target. Maintaining the credibility of a target, however, would\nimpose constraints on our tactical choices. If core inflation drifts substantially above\ntarget, I believe that the Committee would feel compelled to explain how long it was\nlikely to take for inflation to return to target and to comment on the policy actions that\nwould likely be required to get there. Moreover, if we see evidence that markets do not\nview our target as credible, we may feel compelled to take further policy actions to\nenhance our credibility.\nThere are differences of opinion among economists about short-run inflation dynamics,\nand about how fast the central bank should seek to return inflation to target. But there is\nvirtual unanimity that the central bank can bring about any average inflation it likes over\nthe horizon of a decade or more. Moreover, it is important to recognize that this is not\nthe case with regard to real economic quantities such as output growth or the\nunemployment rate. The central bank can influence the path of output and employment\nover short horizons, but in the long-run, real economic variables are determined by the\nfundamental forces of productivity growth, population growth, labor force participation\ndecisions, savings behavior, and the like. There is virtual unanimity that these are\nultimately beyond the control of the central bank, and so to set an explicit objective for\ngrowth or employment would be a mistake.\nI have talked about monetary policy tactics and strategy, and have touched on the\ninterplay between the two. Tactical policy decisions should be guided by strategic\nobjectives; this is an obvious and widely applicable principle. But in the case of\nmonetary policy, the public’s expectations regarding future tactical decisions play a\ncrucial role in determining current outcomes, because inflation expectations play such a\ncrucial role in determining current inflation. Without having credibly and explicitly\ncommunicated our strategic goals, tactical decision-making is more challenging than it\nneeds to be. Policymakers are in that case forced to resort to policy actions – that is,\nfunds rate changes – to influence the public’s expectations. Accordingly, one factor\ncontributing to my voting decisions at the last few FOMC meetings was a sense that\ninflation expectations were somewhat higher than would be consistent with my definition\nof price stability. As communications tools go, however, funds rate changes are\nrelatively blunt. I believe, therefore, and I hope to have convinced you, that an explicit\nnumerical objective for inflation would improve the effectiveness of both the strategy and\ntactics of monetary policy.\n\n7\n\n\f",
        "date": "October 30, 2006",
        "text_url": "https://fraser.stlouisfed.org/files/text/historical/frbrich/presidents/lacker_20061030.txt",
        "year": "2006",
        "title": "Monetary Policy Tactics and Strategy : Greater Baltimore Committee, Baltimore, Maryland",
        "href": "https://fraser.stlouisfed.org/title/statements-speeches-jeffrey-m-lacker-6827/monetary-policy-tactics-strategy-678643",
        "item_id": "678643",
        "speaker": "effrey M. Lacke"
    },
    {
        "content": "How Should Regulators Respond to Financial Innovation?\nThe Philadelphia Fed Policy Forum\nPhiladelphia, Pennsylvania\nDecember 1, 2006\nJeffrey M. Lacker\nPresident, Federal Reserve Bank of Richmond\n\nThe subject of this panel is “Financial Markets and Growth.” There is now quite a\nsubstantial literature devoted to understanding how improvements in the effectiveness of\nthe financial sector can and do contribute to growth and economic well-being in\ndeveloping countries. My focus will be on the innovations in financial markets and\npractices that have been particularly striking in the United States over the last couple of\ndecades, and the key benefits of those innovations. We’ve seen tremendous changes in\nfinancial arrangements in recent years, particularly with regard to the ways in which\nfinancial markets allocate risk; derivative markets have made risks increasingly divisible\nand tradable, and consumers have seen vastly expanded opportunities in credit markets. I\nbelieve these changes have produced noteworthy economic benefits. Many observers,\nhowever, acknowledge the benefits but believe the recent wave of financial innovation\nalso has contributed to increasing financial fragility. The proliferation of new instruments\nseems to have made it easier for someone to accumulate large risk exposures and harder\nfor counterparties to evaluate them.\nIn my remarks today, I will offer up the perspective of an economic policymaker from a\nmore developed country, out of a belief that such a perspective has at least some\nrelevance to policymakers in the developing world. I will speak at a fairly broad and\nabstract level, and will not address specific policy questions. I also will speak as an exresearch economist, which means I am entitled to leave it to others to validate or refute\nthe hypotheses I advance here.\nMy main hypothesis is that one of the most difficult challenges posed by financial\ninnovation has to do with the interplay between institutions that are relatively closely\nregulated and institutions that operate less constrained by government intervention. In\nmany developing countries, the real dilemma in financial development has been how to\nfoster growth in institutions and market segments that are more credibly distanced from\nthe government than are the institutions that have tended to be government controlled or\nprotected. In some Asian economies, for instance, the role of the banking system in\nlending to historically state-run enterprises makes it hard to liberalize the set of saving\noptions available to households, for fear of a destabilizing flight of funds from the\nbanking system.\nIn developed economies, much of the financial innovation taking place in the last 20\nyears has been associated with the movement of credit risk and other exposures off of the\nbalance sheets of regulated banks and into such less-regulated entities as hedge funds.\n\n\fThe presence of a sector that is less regulated (or, one might say, “regulated primarily via\nmarket discipline”) has proven useful as a testing ground for new financial products and\npractices, but some have argued that the ability of such entities to amass concentrated\nexposures poses a potential threat to the stability of regulated institutions.\nLet me again emphasize that I offer up just one policymaker’s views. As always, those\nviews are not necessarily shared by any of my colleagues in the Federal Reserve.\n\nFinancial innovation\nIn my discussion of the effects of developments in financial markets, I want to focus on\nthe period since the early 1980s. I think we can look to the 1980s as a rough starting point\nfor a broad wave of innovation in financial markets and instruments, driven by advances\nin information and communication technologies. And this wave affected the financial\nopportunities of both households and businesses. On the household side, what can be\nfairly called a revolution in unsecured credit began in the 1980s and accelerated in the\n1990s. Mortgage and home equity lending also benefited in this period from the same\nfundamental forces. Falling costs of computing and telecommunications facilitated\nadvances in credit evaluation and the pricing of risk, which facilitated more finely\npartitioned credit origination decisions and improved intermediation of the resulting\nfinancial claims through securitization. Credit became available to more borrowers and\non better terms. 1\nIn the world of business finance, this period saw a significant expansion in the set of\ncontingent claims available to market participants, and a significant expansion in the set\nof claims that are actively traded in secondary markets. Derivative contracts, swaps, loan\nsales, credit derivatives and securities backed by various types of assets all proliferated\nduring this period. These developments increased the divisibility and marketability of\nspecific risks, and greatly enhanced the ability of businesses and intermediaries to\ntransfer particular risks to other market participants. For example, banks now seem to\nhave a greater ability to move corporate credit exposures off of their books and into the\nhands of other banks and, increasingly, nonbank intermediaries such as institutional\ninvestors and hedge funds. Banks, however, have remained important in the origination\nof credits and they remain major providers of lending facilities through which exposures\ncould flow back into the banking system under some circumstances.\nThe period since the early 1980s was also one of markedly diminished macroeconomic\nvolatility. This change, which has been dubbed the “great moderation,” shows up in\nvirtually all aggregate time series for real variables. For example, expansions have been\nlonger and recessions have been shallower and less frequent. This phenomenon has been\nnoted by many authors and the relevant facts were described by Chairman Bernanke in a\n2004 speech. 2\n\n1\n2\n\nLacker (2005)\nBernanke (2004)\n\n2\n\n\fThere are natural reasons to expect a connection between the performance of financial\nmarkets and the variability of real macroeconomic variables. One of the most\nfundamental economic purposes of financial markets and institutions is to facilitate\nhousehold smoothing of consumption against both life-cycle variations and unexpected\nshocks to income. In an idealized, perfectly frictionless financial market, households\nwould be able to shed all idiosyncratic risks and to achieve a consumption profile that is\nat least as smooth as average income. (Rob Townsend’s research has emphasized the\nusefulness of this idealized world as a benchmark for evaluating financial market\nperformance.) 3\nBut households’ ability to smooth consumption appears to be more limited than in such\nideal markets. Most notably, direct insurance against some of the most significant\nindividual shocks that households face – especially persistent income shocks – does not\nappear to be readily available. (Moral hazard or other informational frictions presumably\nlimit the feasibility of such insurance.) In fact, households seem to achieve much of their\nsmoothing with a relatively limited set of financial instruments. Households build up\nstocks of savings that they can draw on to smooth consumption when faced with\nunexpected reductions in income or increases in expenses. And households also smooth\nthrough such shocks by borrowing against future income.\nThe rising use of debt by U.S. households since the 1980s suggests that previously,\nborrowing was a relatively expensive tool for consumption-smoothing. If so, then one\nmight have expected households to rely somewhat more heavily on savings before the\ninnovations that reduced borrowing costs in the 1980s. As borrowing costs fell, the need\nfor savings to smooth consumption fell also. With easier access to credit, many\nhouseholds may have found themselves with more savings than they needed for\nsmoothing purposes. As access to credit and the amount of borrowing grew, one might\nhave expected household savings rates to decline. And this is exactly what happened. 4\nFinancial innovation could contribute to growth, therefore, by reducing the volatility of\nconsumption relative to income and expense shocks. While the intuition for this is\nstraightforward at the level of an individual household, the effect of improved\nconsumption-smoothing opportunities on aggregate volatility is not unambiguous. A\ndecrease in the aggregate consumption volatility associated with a given process for\nfundamental shocks could be offset by greater volatility in hours worked or through\ninvestment. A complicated set of interacting forces is at work in a general equilibrium\nsetting, and the net outcome depends on fundamentals of technology, preferences and the\nnature of the fundamental shocks. And a variety of other causes have been offered to\nexplain the macroeconomic moderation, including better monetary policy and the good\nfortune of receiving smaller shocks. Nonetheless, a causal link between the great\nmoderation and the simultaneous wave of financial innovation would seem to be a\nplausible conjecture.\n3\n\nTownsend (1987)\nWeinberg (2006) reviews trends in household borrowing, while Athreya (2004) conducts quantitative\nexercises to argue that the leading candidate for the cause of increased borrowing is falling borrowing\ncosts.\n\n4\n\n3\n\n\fThe basic story for households, then, appears to be one of reduced credit constraints\nleading to improved consumption-smoothing opportunities. A similar story might apply\nto businesses. A large literature has argued that many firms face credit constraints, and\nthat these constraints result in firms’ investment spending being more tied to available\ninternal cash flow than would otherwise be the case. Such a mechanism would have the\npotential to amplify and propagate more fundamental shocks. But if such a mechanism is\nat work, and if financial innovation has reduced borrowing costs and expanded access to\ncredit for business firms, then we would expect the amplifying effect of credit market\nconstraints to have fallen as well. This, too, could have contributed to the great\nmoderation.\nThe arguments I’ve presented here suggest that financial innovation may have a role in\nexplaining the great moderation. But these arguments do not address the concerns often\nexpressed about the volatility- or fragility-increasing effects of financial innovation. One\nline of reasoning underlying such concerns is that while financial innovation has\nenhanced the divisibility of risks and made it easier to allocate risks across a broader\narray of investors, these innovations also have facilitated greater concentrations of risk.\nThe effectiveness of markets for new financial claims depends to some extent on the\npresence of entities willing and able to arbitrage away pricing misalignments, should they\narise. That ability goes along with an ability to acquire relatively large positions in a\nrelatively narrow set of claims, and thus to accumulate substantial risk exposures. This is\narguably a good description of the role that hedge funds have come to play in financial\nmarkets. The flexibility that hedge funds have in responding to what they perceive to be\npricing misalignments stems in part from their nature as entities free of much of the\nregulation facing other financial firms. The efficiency-enhancing benefits of financial\ninnovations thus might be difficult to disentangle from the rise of less regulated\nintermediaries.\nConcerns about possible fragility-increasing effects of financial innovation tend to\nrevolve around low-frequency events – financial crises in which losses incurred by one\nfinancial market participant have repercussions for other market participants. Such events\nmight be economically costly if, for example, they caused some positive net present value\ninvestment opportunities to be missed or some ongoing, economically viable projects to\nbe shut down. Alternatively, concentration of exposures within hedge funds or other\nentities could prove complicated and costly to resolve in situations of financial distress.\nIn particular, if such a resolution were costly enough, its effects on the prices of financial\nassets might have the effect of curtailing the flow of capital to productive purposes,\nresulting in a disruption to real economic activity.\n\nTwo Views on the Role of Regulation\nTo talk about the implications of financial innovation for regulation, I think it is useful to\nfirst be clear about the underlying reasons for financial regulation. There are two broad\nviews on this question, and each tends to be associated with a corresponding view on how\n\n4\n\n\fpolicy should respond to the risks associated with the financial activities of less-regulated\nintermediaries.\nOne view sees the government financial safety net as the central motivation for the\nregulation of financial intermediaries. The safety net has the potential to distort risktaking incentives of protected institutions, and supervisory oversight attempts to prevent\nexcessive risks from accumulating in sectors supported by the safety net. In this view,\nregulators might be thought of as playing a role similar to that played by private\nproviders of insurance, financial guarantees, or other credit enhancements, who by\nvarious means monitor and constrain risk-taking by their clients.\nThe safety net reduces the incentives of private financial counterparties to manage the\nexposures they take on. And these incentive effects arise not just from such explicit\nsafety net guarantees as deposit insurance. They may also result from the expectations of\nprivate market participants about actions that the central bank or other public sector entity\nmight take during a financial crisis. The mere possibility of public sector action to stem\nso-called “systemic” losses, such as central bank lending, can provide an implicit safety\nnet that makes some participants more willing to hold concentrated exposures. Hence,\nunder this moral hazard view of the need for regulation, the safety net itself can be a\nsource of “systemic” risk. 5\nHow does the financial innovation process I have sketched affect the potential for moral\nhazard induced by the safety net? By expanding the variety of risks that a supported\ninstitution is capable of taking on, the development of new instruments could provide\nnew means to accumulate excessive exposures. Left unchecked, this could exacerbate the\nmoral-hazard costs of the safety net. Enhancements in supervisory practice in the U.S.\nand elsewhere since the early 1990s seem to have made significant progress in\nconstraining the distortionary effects of the safety net.\nThe second view, while not discounting the importance of moral hazard related to the\nsafety net, sees a more fundamental justification for regulatory intervention. In this view,\nthere are inherent market failures in financial markets – leading some risks, especially\nthose that might be labeled “systemic,” to be mispriced. Often this market failure is\nportrayed as an externality. Systemic risks are said to distort choices because a\ncounterparty does not take into account the effect of its own possible losses on its\ncounterparty’s counterparties. Alternatively, market failures are attributed to such market\nfrictions as imperfect information, the idea being that if it’s impossible to know all of the\nrisk-relevant information about a counterparty’s characteristics and past and future\nactions, then credit to that party cannot be priced as precisely as it would under full\ninformation.\nCoordination failures are a closely related type of market imperfection in which multiple\nmarket participants take the same action, such as attempting to sell a particular exposure\nor withdraw funds from an institution, causing losses to all that might have been avoided.\n5\n\nGoodfriend and Lacker (1999) examine the implications of limited commitment in central bank lending.\n\n5\n\n\fThe canonical example of a financial coordination failure is the Diamond-Dybvig bank\nrun. 6\nUnder the market failure view, the safety net acts to ameliorate friction-induced\ndistortions and coordination problems, and financial innovation raises an array of\nconcerns. Since distortions arise in the context of transactions, a dramatic rise in the\nvolume of gross transactions relative to real economic activity would raise the level of\nrisk and expand the need for safety net protection and the associated risk-taking\nconstraints. Moreover, growth in the number of distinct market-traded financial\ninstruments would multiply the potential for coordination failures. Offsetting these\nadverse effects, however, is the fact that innovation improves the ability to assess,\nmeasure and price risk, and thus could reduce the incidence of mispricing. A market\nfailure amounts to the deviation of a market price from the normative fundamental value\nof the underlying claim, as when systemic effects are undervalued and lead to wrongly\npriced risks, or when coordination failures induce “firesale” liquidations at prices below\nfundamental values. The occurrence of such mispricing relies on the inability of any\nmarket participant to recognize and act on the deviation of price from fundamental value.\nIt is exactly the ability to identify and exploit such deviations, however, that financial\ninnovation has tended to enhance.\nSo which of these two views do I align myself with? I think it is useful to bring a healthy\nskepticism to the table about the extent of inherent market failures in financial markets.\nFirst, I would point out that work some 20 years ago by my co-panelist Rob Townsend\n(together with Edward C. Prescott) made clear that information imperfections – moral\nhazard, asymmetric information, and the like – do not constitute market failures. 7 Rather,\nthe financial instruments and contracts we actually observe, and the rich variety of\ncontractual features they display, should be understood as the market’s adaptation to\ninformation limits. And the logic that says markets can allocate risk optimally subject to\ninformational constraints is essentially identical to the logic that says markets are\nefficient when there is perfect information.\nSecond, I think that the notion of “systemic risk” as an externality in the classical sense is\nfundamentally flawed. If I take on a credit-risk exposure to a counterparty who has\nmaterial exposure to another counterparty, then surely that should figure in my risk\nassessment. And similarly with that counterparty’s exposure to others, and so on. Now, it\nmight be quite costly to know everything one would like to know about one’s\ncounterparties’ counterparties. But as I’ve just argued, limits to information do not imply\na market failure.\nSkepticism regarding market failures does not imply a Panglossian stance, however.\nActual markets are complex, and are evolving in ways that are difficult to predict.\nMeasuring and assessing risk in such an environment is an intellectually challenging\nendeavor. Moreover, not all market participants will acquire sophistication and\nproficiency with new products and practices at the same pace. As a result, mistakes\n6\n7\n\nDiamond and Dybvig (1983)\nPrescott and Townsend (1984)\n\n6\n\n\finevitably will be made, some of which could result in high-profile losses to some market\nparticipants – indeed we see these with some regularity, whether in households, business\nfirms or financial institutions. The occurrence of such mistakes does not represent a form\nof market failure, but rather is an integral part of the innovation process. While market\nparticipants should certainly be encouraged to ensure that their own risk-measurement\nand risk-management practices keep pace with market developments as much as possible\n– and supervisors should certainly help in this regard with regulated financial institutions\n– reducing the probability of such mistakes to zero is unlikely to be optimal and could\nwell inhibit beneficial innovation.\n\nSo What Should Regulators Do?\nThe picture that I have painted here today leads me to a few general principles about the\nrole of supervision and regulation in the face of financial innovation.\nFirst, we must always remain mindful that reducing constraints and freeing up institutions\nto pursue new products and processes can have tremendous benefits. In part, these\nbenefits stem from removing constraints to innovation, and I’ve devoted some time today\nto the hypothesis that the fruits of financial innovation can be seen at the macroeconomic\nlevel in the form of reduced real volatility. But reducing regulatory constraints can also\nmore directly improve the allocation of credit and risk. Recent research has used the\nvarying times at which states deregulated their banking industries to find that state-level\nderegulation was associated with improvements in income-smoothing for people within\nthe state. 8\nSecond, to effectively carry out their role of monitoring risks in financial institutions, it is\nessential for regulators to keep pace with changes and advances in the marketplace. If\nsupervisors are to assess the adequacy of banks’ risk-management practices, they must\nhave a thorough understanding of emerging instruments and practices. This task is all the\nmore challenging if innovations originate outside of the regulated banking sector.\nThird, it is possible for regulation itself to be a driver of innovation. The advent of the\none-year, “364-day” credit facility was prompted by the 1988 Basel capital rules. This\nimposed a higher capital charge on credit lines with maturities of one year or more –\nhence, a facility lasting a day less than a year. Similarly, concentration limits on loan\nportfolios spurred the development of the secondary loan market, and the prohibition of\ninterest on corporate deposits spurred the development of “sweep accounts.” While it\nmay often be the case that innovations designed to “bypass” regulations ultimately lead to\nwider benefits for the market, this motivation generally makes innovation less likely to\nenhance efficiency.\nFinally, when innovation occurs outside of the banking industry, regulators’ main\nconcern should be with the interactions between the regulated and unregulated sectors.\nFor example, supervisors and institutions have focused heavily in recent years on\n8\n\nDemyanyk et al, J. Finance, forthcoming\n\n7\n\n\fstrengthening counterparty risk management practices and the settlement infrastructures\nundergirding important new financial markets. As I noted earlier, supervising this\nboundary requires that regulators broadly understand the activities of the unregulated\nsector, but perhaps even more important, it also requires regulators to understand how\ninnovations change the ways in which exposures can flow back into the banking sector.\nThese observations point to a regulatory approach that avoids being overly proscriptive,\nbut that attempts to ensure that regulated institutions’ practices for measuring and\nmanaging risks are appropriate for the changing environment. Regulators should avoid\nextending constraints motivated by safety-net considerations to entities that do not\nreceive safety-net support. And regulators should scrupulously avoid any actions or\npractices that would contribute to the perception that there is a probability of safety net\nsupport being extended into sectors that are now governed chiefly by market discipline.\nIn summary, I believe there is a strong case that financial innovation in the U.S. has\nbrought real, tangible benefits for macroeconomic performance and growth, and I am\ndrawn to the hypothesis that financial innovation can bring similar benefits to economies\nat different stages in the growth process. At the same time, some observers have\nexpressed concerns that this wave of innovation also has resulted in concentrations of risk\nthat add to financial market fragility. But at least as persuasive is the notion that the same\nadvances that have made it easier for market participants to evaluate and exchange\nvarious risks have also made it possible for markets to respond more resiliently to\ndisruptions by allowing market allocations to change more flexibly in response to\nchanging market circumstances. As a consequence, I believe regulators serve their\nmission best, not by second-guessing observed risk allocations, but by assuring that\nindividual institutions with access to a public sector safety net conduct their businesses\nusing risk measurement and management practices that keep pace with the ever-changing\nmarket.\n\n8\n\n\fReferences\nAthreya, K., 2004. “Shame as it Ever Was: Stigma and Personal Bankruptcy,” Federal\nReserve Bank of Richmond Economic Quarterly, 90 (Spring), 1-19.\nBernanke, B., 2004. “The Great Moderation,” speech to the Eastern Economic\nAssociation in Washington D.C., Board of Governors of the Federal Reserve System,\nhttp://www.federalreserve.gov/BOARDDOCS/SPEECHES/2004/20040220/default.htm\nDemyanyk, Y., C. Ostergaard, and B. Sorensen, forthcoming. “U.S. Banking Regulation,\nSmall Business, and Interstate Insurance of Personal Income,” Journal of Finance.\nDiamond, D., and P. Dybvig, 1983. “Bank Runs, Deposit Insurance and Liquidity,”\nJournal of Political Economy, 91 (June), 401-19.\nGoodfriend, M. and J. Lacker, 1999. “Limited Commitment and Central Bank Lending,”\nFederal Reserve Bank of Richmond Economic Quarterly, 85 (Fall), 1-28.\nLacker, J., 2005. “Retail Financial Innovation,” speech to Virginia Bankers Association,\nHot Springs, Va., Federal Reserve Bank of Richmond,\nhttp://www.richmondfed.org/news_and_speeches/presidents_speeches/index.cfm/2005/id\n=74\nPrescott, E. C., and R. Townsend, 1984. “Pareto Optima and Competitive Equilibria with\nMoral Hazard and Adverse Selection,” Econometrica, 52 (January), 21-46.\nTownsend R., 1987. “Arrow-Debreu Programs as Microfoundations of\nMacroeconomics,” in T.F. Bewley, Advances in Advances in Economic Theory: Fifth\nWorld Congress, Econometric Society Monograph Series no. 12, New York and\nMelbourne, Cambridge University Press, 379-428.\nWeinberg, J. 2006. “Borrowing by U.S. Households,” Federal Reserve Bank of\nRichmond 2005 Annual Report, 4-16.\n\n9\n\n\f",
        "date": "December 01, 2006",
        "text_url": "https://fraser.stlouisfed.org/files/text/historical/frbrich/presidents/lacker_20061201.txt",
        "year": "2006",
        "title": "How Should Regulators Respond to Financial Innovation? : The Philadelphia Fed Policy Forum",
        "href": "https://fraser.stlouisfed.org/title/statements-speeches-jeffrey-m-lacker-6827/regulators-respond-financial-innovation-678644",
        "item_id": "678644",
        "speaker": "effrey M. Lacke"
    },
    {
        "content": "Economic Outlook\nAnnual Economic Conference\nCharlotte Chamber of Commerce\nCharlotte, North Carolina\nDecember 21, 2006\nJeffrey M. Lacker\nPresident, Federal Reserve Bank of Richmond\n\nIt’s a pleasure to be here in Charlotte again this year for the Annual Economic\nConference. I am honored to be invited back for a third appearance, particularly after my\nforecasting performance last year. Before I begin, I owe you the usual disclaimer that\nthese views are my own and are not necessarily shared by my colleagues around the\nFederal Reserve System. For those of you who have followed my voting record, however,\nthis should come as no surprise.\nIn considering the economic outlook, it’s important to bear in mind the broader transition\nthat is taking place. In the three-year period leading up to the middle of this year, we’ve\nseen above average growth. Real gross domestic product – our best measure of total\nproduction in the economy – grew at a 3 ¾ percent annual rate. To appreciate the strength\nof that performance, note that the trend rate of GDP growth – by which I mean the rate\nconsistent with trend growth in productivity and the labor force – is more like 3 percent.\nLabor market conditions improved significantly over that period, with 5.4 million new\njobs created and the unemployment rate falling by a full 1 ½ percentage points. With jobs\nincreasingly plentiful, household spending surged – real per capita consumption rose at a\nrobust 2.6 percent annual rate. And even as their spending increased, consumers\ncontinued to build wealth; household net worth increased by 31 percent to reach a level\nequal to 5 years of personal income.\nBut since we’re not in Lake Wobegon, we can’t be above average all the time. Indeed, in\nthe second quarter of this year real GDP only grew at a 2.6 percent rate. In the third\nquarter, growth dropped to a 2.2 percent rate, and growth is likely to be about the same,\nor perhaps a bit higher in the current quarter. Since growth clearly has slowed, the\nquestion on many people’s minds is, “What’s next?”\nFor some guidance, we can look back to similar episodes in the past. The long expansions\nof the 1980s and the 1990s resemble our current expansion in several key respects. Both\nwere unusually long, by historical standards. Both saw substantial increases in\nproduction, employment and wealth. And in both cycles there was a somewhat bumpy\ntransition between an early, high-growth phase and a period of several years of more\naverage, trend-like growth. For example, the cyclical expansion of the 1990s was the\nlongest in our nation’s history, and yet in the midst of this period of strong, sustained\ngrowth, there was a two-quarter period in early 1995 in which real GDP increased by\nonly 0.9 percent at an annual rate, driven in part by weakness in housing investment. That\n\n\fbarely perceptible growth was followed by an additional three quarters of growth at a\nsubpar rate, but then real GDP accelerated and grew quite rapidly for the next four years.\nThis example suggests that we should not be discouraged this time around by an uneven\ntransition from rapid to more sustainable growth.\nThe distinguishing feature of the current transition is the magnitude of the adjustment in\nthe housing market, which comes at the end of what has been an amazing, decade-long\nrun. The homeownership rate increased by 4 full percentage points from 1995 to 2005,\nand the number of houses built per year increased by 46 percent over that 10-year period.\nSome observers have called this extraordinary behavior of the housing market in recent\nyears a bubble. I don’t find that term useful or particularly accurate, since the behavior of\nhousing appears to have been based on solid fundamentals.\nFirst, there were good reasons for the homeownership rate to rise and for homeowners to\nspend more on housing. Before 1995, the prevailing view was that productivity, and by\nimplication real per capita income, was likely to increase at about 1 percent annually. But\nsince then, as is well known, productivity growth has been dramatically higher – about 3\npercent in the nonfarm business sector, for example. People base their investment plans\non current and anticipated income growth, and it is not surprising that households would\nmove increasingly from renting to buying their own home.\nSecond, inflation fell to below 2 percent in the mid-1990s, and over time financial market\nparticipants became more confident that inflation would remain low and stable; that\nconfidence, in turn, led to low mortgage interest rates. Thus, at the beginning of 1995, the\n30-year mortgage rate was above 9 percent; by 2003, it had fallen below 6 percent,\nreducing the relative price of housing services and contributing to the increase in demand.\nSatisfying the growth in housing demand required new construction and new land.\nWhile the supply of construction services appears to be fairly elastic, in some localities\ngeography and zoning regulations can severely limit the supply of buildable lots.\nConsequently, the overall supply of housing can be highly inelastic. Increases in demand\nin such locations generate significant price increases, and those priced out of the market\nlook for homes in locations with less desirable features – for example, with longer\ncommutes.\nThis is well illustrated within the Fifth Federal Reserve District. In Charlotte, population,\nincome, and employment grew rapidly from 1995 to 2005. With ample supplies of usable\nland, 224,000 new building permits were issued, and the price of an existing home\nincreased by a relatively modest 4.2 percent per year. The Washington, D.C., area also\nhad rapid growth in population, income, and employment; and 395,000 new houses were\nbuilt. Unlike Charlotte, however, the supply of new lots was more limited in the\nWashington area, and accordingly the average price of an existing home increased 10\npercent per year from 1995 to 2005.\n\n-2-\n\n\fThe secular increase in housing demand in recent years was apparently satisfied in many\nmarkets by the end of 2005. Nationwide, new home sales have fallen by 22 percent\nthrough October of this year. The pipeline of new projects under construction was not\nscaled back as rapidly, however, and we now have excess inventories of new and existing\nhomes in most localities. Production of new homes will have to undershoot demand for a\ntime in order to work off the backlog. Indeed, new housing starts have fallen 28 percent\nthrough November of this year. The inventory overhang that remains suggests that\nhomebuilding will be below demand for several more months.\nLooking ahead, there are tentative signs that the demand for housing has stabilized. New\nhome sales have bumped around the 1 million unit annual rate for the last four months,\nand new purchase mortgage applications have risen over 15 percent in the last seven\nweeks. If these tentative signs are confirmed by more complete data then new home\nconstruction only needs to lag new home sales long enough to work off the current bulge\nin inventories. In this scenario, I would expect housing starts to realign with sales around\nthe middle of 2007. Should new home demand deteriorate instead, the adjustment could\ntake longer.\nIn any event, the weakness in housing will continue to be a drag on overall economic\nactivity into the first half of next year, with the effect gradually waning as the year\nprogresses. But I seriously doubt it will be enough of a drag to tip the economy into\nrecession. My doubts stem from the fact that residential investment accounts for 6 percent\nof GDP, while household consumption accounts for 70 percent, and the outlook for that\nspending looks quite strong right now. For the first three quarters of this year, consumer\nspending has increased at a healthy 3.4 percent annual rate, and it looks like the fourth\nquarter will see something similar. That growth in spending has been underpinned by a\nstrong labor market and solid income growth. Labor markets are fairly tight, overall, as\nindicated by the 4.5 percent unemployment rate. Real disposable income increased at a\nstrong rate in the third quarter, and there are signs that real wage gains are improving –\nwages and salaries, as measured by the employment cost index, increased at a 3.8 percent\nannual rate in the second and third quarters, the best two-quarter increase in almost five\nyears.\nCould weakness in the housing market spillover and weaken consumption spending as\nwell? As residential investment contracts, construction employment will certainly\ndecline. So far, residential construction employment has shed 110,000 jobs since the peak\nin February. At the same time, however, other segments of the economy have been doing\nwell and overall payrolls actually expanded by 1.2 million jobs. This again reflects the\nsmall size of the residential construction sector relative to the overall economy. Although\nthe outlook is for construction employment to continue to weaken for at least several\nmore months, a decline commensurate with the fall-off we’ve already seen in housing\nstarts still would have only a minor effect on total employment.\nAs I have said before, consumer spending is largely determined by current and expected\nfuture income prospects. I expect the overall job market to continue to expand even after\naccounting for further job losses in homebuilding, and I expect the tight labor market to\n\n-3-\n\n\fcontinue to generate healthy wage gains. With income prospects looking good for 2007,\nit seems a pretty safe bet that consumer spending will do well, and again that’s by far the\nlargest part of the economy.\nWe’ve discussed residential investment, but what about business investment spending?\nHere the fundamentals look favorable. Business profitability is high and the cost of\ncapital is low. In many industries, demand looks strong and capacity utilization is high.\nSo, I would expect business investment to continue to contribute positively to growth in\noverall economic activity.\nThe outlook for real growth in 2007, then, is for continued strength in consumer spending\nand business investment to be partially offset, particularly early next year, by the drag\nfrom the housing market. Growth will start the year on the low side, but should be back\nto about 3 percent by the end of next year. So my best guess right now is that real GDP\ngrowth will average between 2 ½ and 2 ¾ percent in 2007.\nTwo risks to this outlook deserve mention. First, it’s impossible to be sure that housing\ndemand truly has stabilized, so one downside risk is of a further deterioration in the\nhousing market. However, we don’t see any signs of this now. Second, I’ll note again the\nsubstantial uncertainty surrounding oil prices. This is likely to be with us for some time to\ncome, and it cuts both ways, as our experience this fall demonstrated.\nWhat about inflation? The past year has been disappointing on this score as well.\nInflation, according to our generally preferred measure – the core PCE price index –has\nbeen running above 2 percent since early 2004, and has run 2.5 percent so far this year.\nThe longer core inflation persists above 2 percent, the greater the danger of inflation\nbecoming entrenched at too high a rate.\nMany forecasters have been saying core inflation will moderate in the near term, and this\ncertainly would be desirable. But such a moderation is not yet evident, despite the two\nmost recent CPI reports. For example, the three-month average rate of change in the core\nPCE price index has been oscillating between 1.8 percent and 2.9 percent since last year’s\nhurricanes, and stands at 2.7 percent as of October. In view of this recent record, it would\ntake several months worth of data to provide statistically convincing evidence of a\nmoderation in inflation. In the meantime, the risk that core inflation surges again, or does\nnot subside as desired, clearly remains the predominant macroeconomic policy risk.\nAgain, thank you. It’s been a pleasure to be here.\n\n-4-\n\n\f",
        "date": "December 21, 2006",
        "text_url": "https://fraser.stlouisfed.org/files/text/historical/frbrich/presidents/lacker_20061221.txt",
        "year": "2006",
        "title": "Economic Outlook : Charlotte Chamber of Commerce Annual Economic Outlook Conference, Charlotte, North Carolina",
        "href": "https://fraser.stlouisfed.org/title/statements-speeches-jeffrey-m-lacker-6827/economic-outlook-678645",
        "item_id": "678645",
        "speaker": "effrey M. Lacke"
    }
]