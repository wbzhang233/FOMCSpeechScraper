{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 美联储议息决议内容爬取\n",
    "\n",
    "prompt:\n",
    "```shell\n",
    "下面这个网站是美联储FOMC的会议网址：https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm\n",
    "该网址的正文部分按照自然年用Panel控件发布了每年的美联储议息会议的公告，包括会议月份和日期、议息决议Statement和会议备忘录Minutes。其中Statement给出了PDF、HTML以及Implementation Note三个链接，Minutes则只给出了PDF和HTML链接以及发布时间。注意，有的决议可能不披露上述信息，则仅保存月份、日期和决议名称等信息。\n",
    "我想要按照年份，爬取每一条议息决议数据，包括月份、日期、statement中HTML的网址和内容，以及会议备忘录minutes中的内容，每一条决议数据都存储为一个字典，最后按年份来保存所有数据为json文件。\n",
    "记载每一条议息决议的字典应当包含如下键，含义如下：\n",
    "year: 决议年份，为str类型，如2024\n",
    "month: 决议月份，为str类型，如Feb\n",
    "date: 决议日期，为str类型，如17-19\n",
    "statement: 议息决议，为字典类型。包括html和implementation note两个键，每个键对应一个字典，分别包含href, title, date, content四个键。\n",
    "minutes: 会议备忘录，同样为字典类型。包括html一个键，该键包含一个字典，包含href, title, date, content四个键。\n",
    "\n",
    "请帮我开发python代码，爬虫工具可以使用selenium和beautifulsoup4来实现。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-23 00:00:00\n",
      "1995-10-23 00:00:00\n",
      "2024-09-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_date(date_string):\n",
    "    try:\n",
    "        return datetime.strptime(date_string.strip(), \"%b %d, %Y\")\n",
    "    except ValueError:\n",
    "        print(f\"Error parsing date: {date_string}\")\n",
    "        return None\n",
    "    \n",
    "dates = []\n",
    "for year_str in [\"Sep 23, 2024\", \"Oct 23, 1995\"]:\n",
    "    date = parse_date(year_str)\n",
    "    print(date)\n",
    "    dates.append(date)\n",
    "print(max(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 设置 WebDriver\n",
    "driver = webdriver.Chrome()  # 确保已经配置好 ChromeDriver 路径\n",
    "url = 'https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm'\n",
    "driver.get(url)\n",
    "\n",
    "# 等待页面加载完成\n",
    "wait = WebDriverWait(driver, 10)\n",
    "wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'fomc-meeting')))\n",
    "\n",
    "# 获取页面源码\n",
    "html_content = driver.page_source\n",
    "\n",
    "# 解析 HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_statement_html():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to separate JSON files by year.\n"
     ]
    }
   ],
   "source": [
    "# 查找所有 class 为 fomc-meeting 的元素\n",
    "meetings = soup.find_all(class_=\"fomc-meeting\")\n",
    "\n",
    "# 初始化数据结构\n",
    "all_data = []\n",
    "\n",
    "for meeting in meetings:\n",
    "    # 获取日期\n",
    "    month = meeting.find(class_=\"fomc-meeting__month\").strong.text.strip()\n",
    "    date = meeting.find(class_=\"fomc-meeting__date\").text.strip()\n",
    "\n",
    "    # 提取声明（statement）部分的链接\n",
    "    statement_div = meeting.find(class_=\"col-xs-12 col-md-4 col-lg-2\")\n",
    "    if statement_div:\n",
    "        statement_links = statement_div.find_all(\"a\")\n",
    "        statement_data = {\"html\": {}, \"implementation_note\": {}}\n",
    "\n",
    "        for link in statement_links:\n",
    "            text = link.text.strip()\n",
    "            href = link[\"href\"]\n",
    "\n",
    "            if \"HTML\" in text:\n",
    "                statement_data[\"html\"][\"href\"] = href\n",
    "                statement_data[\"html\"][\"title\"] = text\n",
    "                # statement_data[\"html\"][\"date\"] = date\n",
    "            elif \"Implementation Note\" in text:\n",
    "                statement_data[\"implementation_note\"][\"href\"] = href\n",
    "                statement_data[\"implementation_note\"][\"title\"] = text\n",
    "                # statement_data[\"implementation_note\"][\"date\"] = date\n",
    "\n",
    "        # 访问每个声明页面并提取内容\n",
    "        if statement_data[\"html\"]:\n",
    "            try:\n",
    "                driver.get(statement_data[\"html\"][\"href\"])\n",
    "                wait.until(EC.presence_of_element_located((By.TAG_NAME, \"article\")))\n",
    "                article_html = driver.page_source\n",
    "                article_soup = BeautifulSoup(article_html, \"html.parser\")\n",
    "                statement_data[\"html\"][\"content\"] = (\n",
    "                    article_soup.find(\"article\").get_text().strip()\n",
    "                )\n",
    "            except:\n",
    "                statement_data[\"html\"][\"content\"] = None\n",
    "\n",
    "        if statement_data[\"implementation_note\"]:\n",
    "            try:\n",
    "                driver.get(statement_data[\"implementation_note\"][\"href\"])\n",
    "                wait.until(EC.presence_of_element_located((By.TAG_NAME, \"article\")))\n",
    "                article_html = driver.page_source\n",
    "                article_soup = BeautifulSoup(article_html, \"html.parser\")\n",
    "                statement_data[\"implementation_note\"][\"content\"] = (\n",
    "                    article_soup.find(\"article\").get_text().strip()\n",
    "                )\n",
    "            except:\n",
    "                statement_data[\"implementation_note\"][\"content\"] = None\n",
    "    else:\n",
    "        statement_data = {}\n",
    "\n",
    "    # 提取会议备忘录（minutes）部分的链接\n",
    "    minutes_div = meeting.find(class_=\"col-xs-12 col-md-4 col-lg-4\")\n",
    "    if minutes_div:\n",
    "        minutes_links = minutes_div.find_all(\"a\")\n",
    "        minutes_data = {\"html\": {}}\n",
    "\n",
    "        for link in minutes_links:\n",
    "            text = link.text.strip()\n",
    "            href = link[\"href\"]\n",
    "\n",
    "            if \"Minutes\" in text:\n",
    "                minutes_data[\"html\"][\"href\"] = href\n",
    "                minutes_data[\"html\"][\"title\"] = text\n",
    "                # minutes_data[\"html\"][\"date\"] = date\n",
    "\n",
    "        # 访问每个会议备忘录页面并提取内容\n",
    "        if minutes_data[\"html\"]:\n",
    "            driver.get(minutes_data[\"html\"][\"href\"])\n",
    "            wait.until(EC.presence_of_element_located((By.TAG_NAME, \"article\")))\n",
    "            article_html = driver.page_source\n",
    "            article_soup = BeautifulSoup(article_html, \"html.parser\")\n",
    "            minutes_data[\"html\"][\"content\"] = (\n",
    "                article_soup.find(\"article\").get_text().strip()\n",
    "            )\n",
    "    else:\n",
    "        minutes_data = {}\n",
    "\n",
    "    # 组装最终数据\n",
    "    final_data = {\n",
    "        \"month\": month,\n",
    "        \"date\": date,\n",
    "        \"statement\": statement_data,\n",
    "        \"minutes\": minutes_data,\n",
    "    }\n",
    "\n",
    "\n",
    "    all_data.append(final_data)\n",
    "\n",
    "# 将数据保存为 JSON 文件\n",
    "with open(\"fomc_meeting.json\", \"w\") as file:\n",
    "    json.dump(all_data, file, indent=4)\n",
    "\n",
    "# 关闭浏览器\n",
    "# driver.quit()\n",
    "\n",
    "print(\"Data saved to separate JSON files by year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"16c28a8880cd44364efa35ace81cd0a0\", element=\"f.76C63AFA6F8289D2C89D22AF3A53E32E.d.C7C5664ECE4B61BFDEBD83976DF2C9DE.e.31\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16c28a8880cd44364efa35ace81cd0a0\", element=\"f.76C63AFA6F8289D2C89D22AF3A53E32E.d.C7C5664ECE4B61BFDEBD83976DF2C9DE.e.32\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16c28a8880cd44364efa35ace81cd0a0\", element=\"f.76C63AFA6F8289D2C89D22AF3A53E32E.d.C7C5664ECE4B61BFDEBD83976DF2C9DE.e.33\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16c28a8880cd44364efa35ace81cd0a0\", element=\"f.76C63AFA6F8289D2C89D22AF3A53E32E.d.C7C5664ECE4B61BFDEBD83976DF2C9DE.e.34\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16c28a8880cd44364efa35ace81cd0a0\", element=\"f.76C63AFA6F8289D2C89D22AF3A53E32E.d.C7C5664ECE4B61BFDEBD83976DF2C9DE.e.35\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16c28a8880cd44364efa35ace81cd0a0\", element=\"f.76C63AFA6F8289D2C89D22AF3A53E32E.d.C7C5664ECE4B61BFDEBD83976DF2C9DE.e.36\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16c28a8880cd44364efa35ace81cd0a0\", element=\"f.76C63AFA6F8289D2C89D22AF3A53E32E.d.C7C5664ECE4B61BFDEBD83976DF2C9DE.e.37\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16c28a8880cd44364efa35ace81cd0a0\", element=\"f.76C63AFA6F8289D2C89D22AF3A53E32E.d.C7C5664ECE4B61BFDEBD83976DF2C9DE.e.38\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"16c28a8880cd44364efa35ace81cd0a0\", element=\"f.76C63AFA6F8289D2C89D22AF3A53E32E.d.C7C5664ECE4B61BFDEBD83976DF2C9DE.e.39\")>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locate the start and end date input fields and set the desired dates\n",
    "# meetings = soup.find_all(class_=\"fomc-meeting\")\n",
    "\n",
    "articles = driver.find_element(By.ID, \"article\")\n",
    "panels = articles.find_elements(By.CLASS_NAME, \"panel\")\n",
    "panels\n",
    "\n",
    "# meeting_infos = []\n",
    "# for panel in panels:\n",
    "#     header = panel.find_element(By.CLASS_NAME, \"panel-heading\").text\n",
    "#     print(f\"Year: {header}\\n\" + \"-\" * 100)\n",
    "#     # 获取议息会议控件\n",
    "#     meetings = panel.find_elements(By.CLASS_NAME, \"fomc-meeting\")\n",
    "#     # 获取议息会议信息\n",
    "#     info = extract_meeting_infos(meetings)\n",
    "#     meeting_infos.append({\"Year\": header, \"Info\": info})\n",
    "\n",
    "# meeting_infos\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FOMCTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
