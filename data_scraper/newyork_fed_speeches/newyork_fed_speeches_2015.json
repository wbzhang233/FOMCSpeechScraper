[
  {
    "title": "Why Focus on Culture?",
    "date": "Nov 23, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/mus151123",
    "content": "Thank you to the Institute for Law and Finance for the invitation to speak here today. It is a pleasure to be at Goethe University. \n\nThe New York Fed has, for the last two years, been part of an international dialogue on the reform of culture in the financial services industry.  Why culture?  Let\u2019s begin with the following hypothesis: environment drives conduct.  What each of us learned from our parents governs some of our behavior, but not nearly as much as any of us who are parents would like to believe.  Place ordinary people in a bad environment, and bad things tend to happen.  That said, place someone in a good environment, and good things tend to happen. This is just part of being human. We observe and adapt.\n\nBefore continuing, I would like to clarify that the views I express today are my own and may not reflect the views of the Federal Reserve Bank of New York or the Federal Reserve System.\n\nPart of any organization\u2019s environment is its culture.  Some have labored over a precise definition of the word \u201cculture.\u201d  Bill Dudley, the President of the New York Fed, has offered the following description, which works for me:  \u201cCulture relates to the implicit norms that guide behavior in the absence of regulations or compliance rules\u2014and sometimes despite those explicit restraints.  Culture exists within every firm whether it is recognized or ignored, whether it is nurtured or neglected, and whether it is embraced or disavowed.\u201d1\n\nThe New York Fed\u2019s interest in reforming culture is a product of events since the Financial Crisis.  Take, for example, the manipulation of LIBOR and foreign exchange rates, much of which was collusive.  Each of those episodes involved misconduct affecting wholesale markets on which the real economy relies.  Both cases shared an underlying, flawed outlook.  Bankers failed to see beyond their immediate financial goals.  They ignored the broader social consequences of their decisions on the firm and its customers, as well as on consumers, producers, savers and investors.  The same flawed outlook may have contributed to the Financial Crisis.2\n\nThere are many more examples.  One bank was fined for doing business with Sudan despite economic sanctions imposed for engaging in genocide.3   Another bank manipulated electricity markets in California and Michigan.4   Other banks helped U.S. citizens evade taxes.5   I will not review the full litany.  Notably, none of these recent episodes had anything to do with capital levels or liquidity ratios.  The many post-Crisis reforms to bank balance sheets\u2014including the Dodd-Frank Act and new standards developed by the Basel Committee on Bank Supervision and the Financial Stability Board\u2014provided necessary bulwarks against systemic risks.  Capital and liquidity requirements, and the enhanced testing surrounding them, have made banks and the financial system more resilient to stress.  But those new laws, regulations, and standards have done little to curb banker misconduct.  Each post-Crisis episode demonstrates a narrow cultural focus on short-term gain and disregard of broader social consequences.\n\nLast year the New York Fed challenged the industry to consider many factors that have contributed to recent, widespread misconduct.  There are no simple answers and that discussion is continuing.  This year, by contrast, our focus has been more on solutions\u2014what\u2019s working, and what is not.  In both years, we have offered three messages to the industry.\n\nFirst, cultural problems are the industry\u2019s responsibility to solve.  The official sector can monitor progress and deliver feedback and recommendations.  In fact, many individual supervisory findings are often symptoms of deeper cultural issues at a firm.  But the banks themselves must actively reform and manage their cultures. \n\nSecond, a bank\u2019s implicit norms\u2014especially those reinforced through incentives\u2014must align with the public purpose of banking.  Gerald Corrigan, more than three decades ago, presented a theory of banking based on the principle of reciprocity.6 Banks receive operating benefits unavailable to other industries because they provide important services to the public. For example, financial intermediation is enhanced through deposit insurance and access to the discount window.  Public benefits, though, are not a gift.  They are part of a quid pro quo.  In exchange for receiving valuable operating benefits, a bank\u2019s implicit codes of conduct\u2014that is, its culture\u2014must reflect the public dimension of the services that banks provide.\n\nThird, the reform of bank culture should aim to restore trust.7   The bedrock of the financial system is trust and the word credit derives from the Latin notion of believing or trusting. We saw seven years ago that the public\u2019s trust is critical in a crisis.  The repair of the financial system would not have been possible without public support.  If another crisis were to happen tomorrow, would there be that support? \n\nA lack of trust\u2014or, more accurately, low trustworthiness\u2014also imposes day-to-day costs.8 For starters, there are fines.  Then there are the legal costs in investigating allegations and defending lawsuits.  Internal monitoring also becomes more expensive as rules become more extensive.  Some might say that the proliferation of rules since the Financial Crisis is inversely proportional to a decline in the industry\u2019s perceived trustworthiness.  The choice between rules and standards depends on the trustworthiness of the regulated.  A more flexible, standards-based legal regime requires a degree of trustworthiness that, in recent years, banks have not demonstrated.\n\nThose are the measurable costs of low trustworthiness.  There may be other, longer-term costs that are more difficult to price.  Let me raise just two.  If employees perceive a firm as untrustworthy or disloyal, will they choose to work in that firm?  And, if they do, how will they behave toward the firm and its stakeholders?\n\nI am encouraged that the industry seems to understand the importance of reforming its culture.  Consider for a moment the following data points.  In September 2013, shareholders of a major U.S. bank requested that the bank prepare \u201ca full report on what the bank has done to end [its] unethical activities, to rebuild [its] credibility and provide new strong, effective checks and balances within the [b]ank.\u201d  That request was forwarded, by the way, by a Catholic nun.  The bank responded through its attorneys that the nun\u2019s proposal was \u201cmaterially false and misleading\u201d and \u201cimpermissibly vague and indefinite.\u201d9  Fast forward to May 2015.  The Federal Advisory Council\u2014a panel of bankers that advises the Federal Reserve System\u2014reported that \u201cRegulators and the banking industry have worked extensively to restore financial stability through a series of mechanisms and rules that establish appropriate levels of capital, liquidity, and leverage. . . . As often as not, however, the challenges faced in recent years have been behavioral and cultural; post-crisis episodes such as LIBOR and foreign exchange manipulation provide hard evidence that there remains work to be done.\u201d10 This is clearly an encouraging difference in perspectives. \n\nThe public sector, too, has paid increasing attention to culture.  The Group of Thirty, the Basel Committee, the European Systemic Risk Board, and the Financial Stability Board have issued papers on culture, governance, and misconduct risk.  The Fair and Effective Markets Review\u2014a joint project of the Bank of England, the Financial Conduct Authority, and Her Majesty\u2019s Treasury\u2014has called for heightened standards for market practice in matters affecting the public good.  And in the last year, we have seen emerging approaches to supervision that aim to address culture, conduct, and governance.  In particular, the central bank of the Netherlands\u2014De Nederlandsche Bank\u2014has pioneered new techniques for the supervision of corporate governance, especially for assessing the group dynamics of boards and senior management.11\n\nCulture also features prominently in criminal enforcement.  The U.S. Department of Justice requires its prosecutors to determine \u201cthe pervasiveness of wrongdoing\u201d at a corporation before seeking an indictment.  According to its prosecutors\u2019 manual, \u201c[T]he most important [factor in making this determination] is the role and conduct of management.  Although acts of even low-level employees may result in criminal liability, a corporation is directed by its management and management is responsible for a corporate culture in which criminal conduct is either discouraged or tacitly encouraged.\u201d12   Individuals, including senior managers, also face criminal liability for their conduct.  Recent guidance from the U.S. Department of Justice places greater emphasis on individual culpability.13   And the recent convictions of two traders for rigging LIBOR, one of whom served as the Global Head of Liquidity and Finance at a major bank, may send a powerful message to bankers about the consequences of their misconduct.14\n\nThe new acceptance of culture as an important area of focus was evident at a workshop that the Federal Reserve Bank of New York hosted on November 5.  Christine Lagarde, Managing Director of the International Monetary Fund, and Stanley Fischer, Vice Chairman of the Board of Governors of the Federal Reserve System, headlined a contingent of over 20 public sector authorities from around the globe.  They were joined by the CEOs, senior executives, and board members of global financial institutions.  Together, they discussed methods of reforming culture and the continuing challenges in this effort.  In my view, the workshop offered a number of useful insights, chiefly:\n\nThe Federal Reserve Bank of New York recently launched a webpage that collects resources on bank culture.15 We\u2019ve included the papers by the Group of Thirty and other organizations that I have mentioned, and summaries of our two workshops on culture.  I hope you\u2019ll take a look.\n\nTo conclude, the Financial Crisis and subsequent scandals revealed deep and continuing flaws in the culture of banking.  The responsibility to address these flaws rests with the banks themselves.  Many industry leaders have initiated reform programs within their firms.  It is important to keep the momentum going.  Reform requires relentless and sustained effort: from the top of an institution to its most junior employees, and across all of the institution\u2019s business activities.  Reform must include the full scope of an employee's career, beginning with recruiting and continuing with annual performance management, compensation and promotion decisions.  We in the official sector will be looking to the industry to fulfill its end of the bargain\u2014to act consistent with the public well-being, to value long-term stability over short-term gain, and to take account of all stakeholders in making decisions. \n\nThank you for your time and attention.\n\n1 William C. Dudley, Enhancing Financial Stability by Improving Culture in the Financial Services Industry, Remarks at the Workshop on Reforming Culture and Behavior in the Financial Services Industry, October 20, 2014.\n\n2Cf. William C. Dudley, Opening Remarks at Reforming Culture and Behavior in the Financial Services Industry: Workshop on Progress and Challenges, Federal Reserve Bank of New York, November 5, 2015, (\u201cThe banking scandals that followed the financial crisis are evidence that something fundamental is wrong.  I would encourage each of you to consider not just specific examples of misconduct, but the patterns within them that point to underlying causes.  I suspect we will see a strong overlap with those factors that contributed to the financial crisis.\u201d).\n\n3See Thomas C. Baxter, Jr., Reflections on the New Compliance Landscape, Remarks at The New Compliance Landscape: Increasing Roles \u2013 Increasing Risks Conference, July 24, 2014.\n\n4 See Order Approving Stipulation and Consent Agreement, In re Make-Whole Payments and Related Bidding Strategies, No. IN 11-8-000, IN 13-5-000, U.S. Federal Energy Regulatory Commission (July 30, 2013). \n\n5See Baxter, supra n.3.\n\n6 E. Gerald Corrigan, Are Banks Special?, Federal Reserve Bank of Minneapolis Annual Report, January 1983.\n\n7 See Christine Lagarde, Economic Inclusion and Financial Integrity, Address to the Conference on Inclusive Capitalism, May 27, 2014, (\u201cTrust is the lifeblood of the modern business economy. . . . To restore trust, we need a shift toward greater integrity and accountability.  We need a stronger and systematic ethical dimension.\u201d); Mark Carney, Rebuilding Trust in Global Banking, Speech at 7th Annual Thomas d\u2019Aquino Lecture on Leadership, Ontario, February 25, 2013, (\u201cThe real economy relies on the financial system. And the financial system depends on trust. Indeed, trust is imbedded in the language of finance. The word credit is derived from the Latin, credere, which means \u2018to have trust in.\u2019\u201d); Dudley, supra n. 1 (\u201cUnless the financial industry can rebuild the public trust, it cannot effectively perform its essential functions.  For this reason alone, the industry must do much better.\u201d).\n\n8 See generally Onora O\u2019Neill, A Question of Trust 15-17, 23-24, and 43-47 (2002) (distinguishing trust from trustworthiness). \n\n9Letter of Martin P. Dunn to the Office of Chief Counsel at the U.S. Securities and Exchange Commission\u2019s Division of Corporation Finance, January 17, 2014.\n\n10 Federal Advisory Council and Board of Governors, Record of Meeting, May 8, 2015.\n\n11 See Supervision of Behavior and Culture: Foundations, Practice & Future Developments (Mirea Raaijmakers, ed. 2015).\n\n12U.S. Attorneys\u2019 Manual, \u00a7 9-28.500.\n\n13 See Memorandum of Sally Quillian Yates, Deputy Attorney General, regarding Individual Accountability for Wrongdoing, September 9, 2015.\n\n14See U.S. v. Allen et al., 14-cr-00272, Dkt. No. 147 (S.D.N.Y Nov. 6, 2015) (jury verdict against Anthony Allen and Anthony Conti).\n\n15 https://www.newyorkfed.org/governance-and-culture-reform/index.html."
  },
  {
    "title": "The Federal Reserve\u2019s Counterparty Framework: Past, Present, and Future",
    "date": "Nov 19, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/pot151119",
    "content": "Good evening. I would like to thank the Office of Debt Management for inviting me to speak at this year\u2019s roundtable. This forum provides a valuable opportunity for policymakers, academics, and market participants to discuss issues related to the primary and secondary markets for U.S. Treasury securities. I will focus my remarks tonight on the counterparty framework employed by the Federal Reserve Bank of New York, which directly affects not only our implementation of monetary policy, but also the underwriting and distribution of Treasury debt issuance. I will begin with an overview of the objectives that underpin the framework, continue by describing how those objectives have influenced the historical development of the primary dealer system, and conclude by looking ahead as the private and official sectors adapt to the evolving structure of the Treasury market. Before I begin, I would note that the views I share with you this evening are mine and do not necessarily reflect those of the Federal Reserve Bank of New York or the Federal Reserve System.1\n\nPrinciples and Objectives\n\nThroughout the history of Federal Reserve operations in financial markets, our approach to engaging with counterparties has been designed to serve the effective implementation of monetary policy. The New York Fed, through its Open Market Desk (the Desk), is in the business of implementing policy as directed by the Federal Open Market Committee (FOMC, or the Committee), and the Desk has demonstrated a willingness to engage with a wide range of counterparties to achieve this objective under the guidance of the Committee. In addition to its role in the implementation of monetary policy, the New York Fed has a number of responsibilities and duties as the fiscal agent for the U.S. Treasury. We have therefore also used our counterparty relationships to assist the activities we undertake in support of the Treasury. Indeed, for decades, the primary dealers have played a critical role not only in open market operations, but also in the underwriting and distribution of newly issued Treasury securities.\n\nIn addition to carrying out these domestic operations, we stand ready to conduct a number of foreign exchange operations.2 Foreign exchange counterparties are essential to the successful implementation of U.S. foreign exchange policy operations, which are conducted by the Desk but directed and funded generally equally by the Fed and the Treasury. Similarly, the Desk\u2019s foreign reserve management counterparties facilitate operations that are investments of the Fed\u2019s and also the Treasury\u2019s foreign currency reserves.\n\nTwo other considerations underlie the counterparty framework and support the effective execution of open market operations and primary issuance of Treasury securities. First, the Desk has long recognized the importance of transacting with established, regulated market participants that are capable of settling trades and financing long and short positions reliably and on a consistent basis in a range of market conditions. Our counterparty framework must be of an appropriate size to provide adequate execution capacity and competitive pricing. Second, the execution of domestic open market operations and primary issuance of Treasuries is facilitated by a liquid, smoothly functioning secondary market for Treasury securities.\n\nThe Federal Reserve\u2019s abiding interest in promoting the integrity and efficiency of the secondary market has motivated our recent efforts to join other agencies in analyzing the events of October 15, 2014, and to understand the implications of the evolution of Treasury market structure and the increasing incidence of electronic and automated trading. The Treasury Market Practices Group (TMPG), a private sector group of market professionals sponsored by the New York Fed, has played an important role in these efforts. Building on analysis that started before October 15, 2014, the TMPG released earlier this year an updated set of best practice recommendations and a companion white paper discussing automated trading.3 As is typical of TMPG initiatives, the group\u2019s work on automated trading was undertaken to support market liquidity amid these changes in the market ecosystem. Much work remains to calibrate an appropriate response to changes in market structure, and last month\u2019s conference \u201cThe Evolving Structure of the U.S. Treasury Market\u201d provided a valuable opportunity for the official and private sectors to engage in a healthy and open debate on a range of related topics.4 The conference, organized by the Treasury, the Federal Reserve Board, the New York Fed, the Securities and Exchange Commission, and the Commodity Futures Trading Commission, featured a review of the agencies\u2019 July 2015 Joint Staff Report and highlighted a number of key issues, including the adequacy of the Treasury market data currently available to the public and to the official sector, the impact of the current regulatory environment on liquidity, and some potential operational risks posed by shifting market structure and trading behavior.5 The Treasury made clear at the conference that work in this area is ongoing when it disclosed plans for the agencies to issue in the near future a request for information on the next steps outlined in the Joint Staff Report.\n\nThe Joint Staff Report presented data showing that primary dealers now account for less than half of trading volumes in the interdealer broker market, but it is important to remember that this is only a portion of the secondary market for Treasuries. As a forthcoming Liberty Street Economics blog post will show, when these data on the interdealer broker market are combined with the dealer-to-customer market data from the New York Fed\u2019s Primary Dealer Statistics, we can see that primary dealers accounted for roughly two-thirds of overall Treasury market secondary trading volume in April 2014, and about 60 percent on the day of October 15, 2014.6 (see the table) So while the primary dealer share of daily interdealer broker volume has fallen below 50 percent, primary dealers still account for the majority of aggregate secondary market trading activity, owing to their important role in the dealer-to-customer market.\n\nA robust counterparty framework, specifically one that provides reliable execution capacity of sufficient scale and is facilitated by a liquid and smoothly functioning secondary market for Treasury securities, aids the Desk in pursuing our objectives with respect to the implementation of monetary policy and the activities we undertake in support of the Treasury. But these benefits must be balanced against the cost of maintaining counterparty relationships. Staff time and resources are required to monitor and manage these relationships to ensure that we are getting good value not only in terms of trade execution, but also in terms of market monitoring, an important function that the Desk provides for the benefit of the Federal Reserve System and the Treasury. A large, diverse set of counterparties can contribute to competitive trade execution and richer sources of market intelligence, as well as the increased operational coverage and resiliency that support adaptation to changes in market structure or operating directives. But diversity also entails complexity and requires initial and ongoing investment in infrastructure to support a wider range of firm types. Evaluating and onboarding firms, setting up transactional systems and account arrangements, and monitoring and evaluating counterparty performance and risk all take time and resources that must be balanced against the potential benefits of a larger list.7\n\nOne final consideration that bears mention is the concept of an imprimatur that some market participants associate with status as a New York Fed counterparty. Despite this long-standing perception among some market participants that primary dealer status represents an endorsement by the New York Fed of a financial institution\u2019s creditworthiness or ability to provide efficient execution of large transactions, we have repeatedly stressed the importance of other market participants\u2019 engaging in their own assessment of potential counterparties\u2019 capabilities. Recent history provides several reminders that the primary dealer designation provides no guarantee against credit risk or other counterparty risks. While the New York Fed certainly performs its own due diligence, we do so in pursuit of our unique business objectives, which may differ from those of private agents. Market participants should therefore be engaging in the appropriate level of due diligence required by their fiduciary responsibilities in the context of their specific business requirements. Such independent assessments are in our collective interest because they foster market discipline and a safer, more secure financial system.\n\nPrimary Dealer History\n\nThe pursuit of these objectives is reflected in the history of the Fed\u2019s counterparty framework, of which the primary dealer system has long formed the foundation. But before I review that narrative, I must acknowledge that most of what I know about the history of primary dealers I\u2019ve learned from Ken Garbade, who kindly introduced me tonight. Along with his superb analysis of the evolution of the Treasury market, exemplary work for the TMPG and critical contributions during the financial crisis, Ken has expertly researched more than 100 years of history concerning the financial institutions and trading practices that ultimately became the primary dealer system. Ken has published a staff report covering the early years of this system from the 1930s to the 1950s, and we expect to publish more of his research on primary dealers in the future.8\n\nLooking back over the first century of the Fed\u2019s history, we can see how our counterparty relationships have adapted over time in response to changing operational needs and the evolution of financial markets to create a system that is unique among the world\u2019s leading central banks. Open market operations were first established by the Federal Reserve as a tool to control U.S. monetary conditions in 1922, in response to uncoordinated purchases of Treasury securities by different Reserve Banks interested in acquiring earning assets. The Banks formed an \u201cOpen Market Investment Committee\u201d to coordinate their activities, and the Committee soon began to make policy recommendations to increase or reduce the availability of reserves to member banks. The Banking Act of 1935 created the modern Federal Open Market Committee, and the Committee selected the Federal Reserve Bank of New York as its operating agent.9 The Federal Reserve Act specifies the types of transactions that Reserve Banks can undertake, but does not designate how they should be undertaken. Although other possibilities exist, such as public auctions and reverse auctions, for more than 80 years the Desk has conducted monetary policy operations with bank and nonbank dealers, primarily because they were the core market makers\u2014that is, liquidity providers\u2014for Treasury securities.\n\nIn 1942, the Fed and the Treasury agreed to cap Treasury yields for the duration of the Second World War in order to facilitate funding the war effort. By the end of the war, open market transactions were conducted with a small group of \u201cqualified\u201d dealers. The FOMC set the terms and conditions of the counterparty relationship. In 1951, the Fed returned to using open market operations as a tool for maintaining control over the monetary base and restored the \u201crecognized\u201d dealer program that had been in place before the war.10\n\nIn the early 1960s, a reporting dealer regime was created, featuring reporting on positions and a public list of the firms that communicated various data to the New York Fed. During the 1980s, in considering new firms for primary dealer designation, Desk staff increasingly looked for evidence that a firm had a certain share of total customer trading activity. The working threshold was generally 1 percent, with some fluctuations in this level over time. An explicit requirement for primary dealers to participate in Treasury debt auctions was added in the mid-1980s. In 1992, following the Salomon Brothers Treasury auction scandal, the Desk altered its primary dealer requirements and ended its dealer surveillance program, in an effort to eliminate the perception that it had a regulatory relationship with primary dealers and to encourage more firms to become primary dealers. Nevertheless, over the following decade, the list of primary dealers contracted, largely as a result of declining profitability and industry consolidation in the mid-1990s as well as the departure of some Japanese financial institutions following losses in their home market. The number of primary dealers declined further with the failure and/or consolidation of several large dealers during the recent financial crisis, but has begun to grow slowly again in subsequent years. The last revision of our primary dealer operating policy, published in 2010, formalized a pro rata Treasury auction bidding requirement for all primary dealers, which requires primary dealers to bid for their proportional share of each Treasury offering.11\n\nRelative to domestic open market operations and auctions for primary Treasury issuance, foreign market operations undertaken with private counterparties to further foreign exchange policy and the investment of foreign reserves are relatively small and infrequent and have a somewhat shorter history. The Fed first undertook very limited foreign exchange (sterling) purchases in the market during the late 1920s and early 1930s in an effort to defend the gold standard.12 The Gold Reserve Act of 1934 established the U.S. Treasury\u2019s Exchange Stabilization Fund (ESF) to undertake such operations, but the ESF did not exercise its authority very often until the Bretton Woods fixed-exchange-rate regime came under pressure in the 1960s. In 1962, the Fed began to undertake foreign exchange operations in cooperation with the ESF, and the Desk acted as agent for both accounts.\n\nIn those early years, the Fed and the Treasury focused on conducting swap operations with foreign central banks, although some direct intervention with the private-market participants did take place. In 1973, after the collapse of Bretton Woods, the dollar began to float, and foreign exchange operations entered a new phase. Over the next two decades, interventions in the private foreign exchange market became much more frequent and on some occasions quite large. Since the 1990s, foreign exchange intervention has become less frequent. The history of foreign reserves investment operations in the market is even shorter; the Desk began to transact directly with market participants to invest foreign reserves held in the System Open Market Account and ESF foreign reserves only in the mid-1990s. Before that, the U.S. monetary authorities held all foreign currency reserves in the form of deposits at other central banks.\n\nInternational Context\n\nComparing the Federal Reserve\u2019s counterparty framework with those of our foreign central banking peers highlights a number of differences. To begin with, the Federal Reserve is among the most transparent of central banks in disclosing the specifics of its market operations, including the data reported under the requirements of the Dodd-Frank Act. Details about foreign exchange transactions and foreign exchange investment operations are reported in the quarterly foreign exchange reports released to the public by the New York Fed. In addition, summary information about all operations appears on the weekly Federal Reserve balance sheet, which is available on the Board\u2019s website. The Desk posts comprehensive results of all domestic open market operations with primary dealers and expanded counterparties to the New York Fed\u2019s public website within a few minutes of the operations\u2019 completion. Results of Treasury auctions are likewise released to the public within a few minutes of the close of competitive bidding and contain considerable detail regarding participation by primary dealers and both direct and indirect bidders. Such reporting by the Treasury exhibits a high level of transparency relative to foreign treasuries\u2019 reporting.\n\nIn most foreign jurisdictions, the central bank or monetary authority has the ability to conduct open market operations with a large number of banks that make markets in government securities and also have reserve accounts with the central bank, while the national treasury separately manages relationships with financial institutions to underwrite and distribute its debt issuance; these latter entities are termed \u201cprimary dealers\u201d and are often the only entities having access to primary market auctions. In the United States, by contrast, a comparatively smaller number of firms simultaneously act as counterparties for the central bank\u2019s domestic open market operations and as backstop underwriters and distributors for Treasury debt issuance; firms designated as \u201cprimary dealers\u201d are required to act in both capacities. In fact, the United States is somewhat unique in that (i) being a \u201cprimary dealer\u201d means that the firm is a counterparty for central bank monetary policy operations and has certain obligations with respect to primary national debt issuance and (ii) management of the primary dealer system resides with the central bank rather than the national treasury.\n\nThis unique structure is a legacy of history. Beginning in World War I, the Treasury offered coupon-bearing securities on a fixed-price basis. Small banks and securities brokers commonly subscribed for their own and customers\u2019 accounts, and there was little need for any formal or informal underwriting process. Market making in outstanding Treasury securities, however, was a capital-intensive process conducted mostly by nonbank dealers, though a few banks did have significant dealer operations. These dealers maintained the liquid secondary market for Treasuries and served as counterparties for open market operations. This state of affairs continued until 1970, when the Treasury introduced auction offerings of coupon-bearing debt. Auction participation, like market making, was a risky, capital-intensive activity, and dealers\u2014especially primary dealers\u2014began to play an increasingly important role in the primary market. Though the transition was gradual, this period represented the moment in history when the same set of counterparties began to participate in both open market operations and the primary issuance of Treasury securities.\n\nRecent Changes\n\nMore recently, the Federal Reserve\u2019s approach to designing an effective counterparty framework has been informed by our experience of conducting asset purchases as well as other balance sheet actions and exercises necessary to implement policy in the post-crisis period. In these years, we have ventured beyond the primary dealers to conduct open market operations with a wider and more diverse range of market participants. The introduction of daily reverse repurchase agreement (RRP) test operations in September 2013 required several years of work by the Desk to establish relationships with an expanded set of counterparties beyond the primary dealers or entity types that are currently eligible to be primary dealers, and to develop an approach to evaluating the capabilities of these firms that is distinct from the process for assessing primary dealers. This expansion is a requirement of our business needs given the current size of our balance sheet, specifically the need to maintain appropriate control of short-term interest rates with abundant excess reserves in the banking system.13 Primary dealers, and entities of the type that are currently eligible to be primary dealers, which typically exhibit structural demand for cash financing to support inventories, are unlikely to satisfy this requirement.\n\nTo the extent that the ongoing evolution of the structure of the Treasury market, including technological advancements and changing investor behavior, affects the role of primary dealers as market makers, it is important to analyze the implications for the Fed\u2019s ability to meet its objectives. The primary dealer system has proven to be very effective for both the conduct of monetary policy and the issuance of Treasury debt. I am very confident that the existing counterparty framework\u2014continuing to utilize primary dealers for traditional domestic policy open market operations, expanding to new counterparty types, as appropriate, for targeted operations to increase the effectiveness of domestic policy implementation, and maintaining relationships with a sufficient number of large market participants in the relevant foreign exchange markets for possible foreign exchange policy and investment operations\u2014provides enormous capacity to implement a wide range of monetary policies. Moreover, we have demonstrated a commitment throughout our history to make any adjustments necessary to ensure a robust and effective operational framework. Toward that end, the Desk presented at the June 2015 FOMC meeting an update on a review of the counterparty framework, and indicated that we anticipate regular reviews of the counterparty framework roughly every three years in the future.14 We look forward to working with our official and private sector partners represented in this room as we pursue these goals.\n\nThank you.\n\n1 I would like to thank Stephen Douglass, Frank Keane, and Susan McLaughlin for their excellent assistance in the preparation of these remarks and colleagues in the Federal Reserve System for numerous insightful comments and suggestions.\n\n2 Counterparties also facilitate the Desk\u2019s provision of services to foreign central banks, governments and international official institutions. Additional detail on these services can be found on this website.\n\n3 The best practice guidance and white paper on automated trading are available on the TMPG homepage.\n\n4 Additional information about the conference is available here.\n\n5 The Joint Staff Report is available here.\n\n6 The forthcoming blog post will be published on the Liberty Street Economics website.\n\n7 Since July 2013, the Desk has conducted pilot programs with seven smaller firms outside of the primary dealer system in order to explore how to conduct open market operations in Treasury and mortgage markets with firms that are considerably smaller than existing primary dealers. The Treasury Operations Counterparty (TOC) and Mortgage Operations Counterparty (MOC) pilot programs have provided valuable insight into the appropriate size and operational capacity of open market operation counterparties.\n\n8 Kenneth Garbade, The Early Years of the Primary Dealer System (New York: Federal Reserve Bank of New York, 2015).\n\n9 In fact, the FOMC directs a \u201cSelected Reserve Bank\u201d to conduct open market operations. Since the centralization of open market operations in a single Reserve Bank in 1935, the Federal Reserve Bank of New York has always been designated as the Selected Bank, owing in part to New York City\u2019s historical importance to U.S. financial markets.\n\n10 According to Ken\u2019s research, \u201cthe concept of a recognized dealer was somewhat amorphous. An October 1939 Bank memo remarked that the term was \u2018not an exact appellation\u2019 and noted that \u2018the principal factors which we consider in extending such recognition are (1) reputation for integrity, experience, and knowledge, (2) capital at risk of the business, (3) willingness to make markets under all ordinary conditions and to take positions both long and short, and (4) large volume [of business] of national scope, with the contacts which such trading provides.\u2019\u201d (Garbade, The Early Years of the Primary Dealer System, pp. 8-9)\n\n11 Primary dealers are expected to bid in every auction for, at a minimum, an amount of securities representing their pro rata share of the offered amount. That share, currently 1/22nd, is based on the number of primary dealers at the time of the auction.\n\n12 Stephen V. O. Clarke, Central Bank Cooperation 1924-31 (New York: Federal Reserve Bank of New York, 1967), pp. 162, 175-76, 205, and 209.\n\n13 For more on policy normalization, see these three earlier speeches: \u201cInterest Rate Control during Normalization,\u201d \u201cMoney Markets and Monetary Policy Implementation\u201d and \u201c\"Implementation of Open Market Operations in a Time of Transition.\"\n\n14 See the minutes from the FOMC meeting of June 16-17, 2015."
  },
  {
    "title": "Panel Remarks at The Clearing House Annual Conference",
    "date": "Nov 18, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud151118",
    "content": "It is a great pleasure to have the opportunity to speak here today alongside my fellow Reserve Bank presidents, Loretta Mester and Dennis Lockhart. Today\u2019s event comes almost exactly two years since I delivered a set of remarks at NYU School of Law that covered various aspects of what we know as the \u201ctoo big to fail\u201d problem. In view of some significant milestones that have occurred over the past two years, I would like today to briefly review my sense of the work that has been accomplished on this critical issue, and the work that still remains to be completed.\n\nAs always, what I have to say reflects my own views and not necessarily those of the Federal Reserve System.1\n\nBroadly speaking, the regulatory reforms that the U.S. has adopted since the crisis have been designed to address the risks posed by large financial institutions in two related ways. First, our reforms are designed to reduce the probability that large financial institutions will fail by requiring those institutions to be more resilient to stress. Second, a set of resolution-related reforms are intended to limit the consequences to the financial sector if a failure by such an institution still were to occur.\n\nGiven the limited time on this panel, I will not review in detail the post-crisis comprehensive capital and liquidity framework that the Federal Reserve has put in place. However, from the perspective of addressing too big to fail, it is important to highlight the Federal Reserve rule finalized this year that imposes risk-based capital surcharges on the handful of U.S. global systemically important banking organizations (GSIBs). Under this framework, a GSIB\u2019s risk-based capital surcharge will reflect the degree to which its failure would impact the financial system. In effect, the risk-based capital surcharge confronts each U.S. GSIB with the choice to either reduce its systemic footprint or instead to hold more capital.\n\nThe policy approach to too big to fail recognizes, of course, that we can reduce but cannot completely eliminate the possibility of a large financial institution\u2019s failure. Therefore, a second aim of our post-crisis reforms has been to limit the adverse consequences that would result if a large financial institution were to fail. That is, large financial firms need to be capable of being successfully resolved without creating unacceptable collateral damage to the rest of the financial system and to the economy.\n\nIn my November 2013 speech, I noted that an important foundation for making the resolution of our largest banking firms feasible would be to require, at the holding company level, sufficient minimum amounts of long-term debt that could be used to absorb losses in a single point of entry resolution. Important progress has been made on this front, both in the form of the Federal Reserve\u2019s recent issuance of a proposed rule to establish long-term debt and total loss-absorbing capacity (TLAC) requirements for U.S. GSIBs and the announcement last week by the Financial Stability Board (FSB) of an agreed upon international minimum TLAC standard. It is notable that in several important respects the proposed U.S. rules are stronger than the FSB standard.\n\nWith these new proposed requirements, if losses were to wipe out a firm\u2019s capital and push a firm into resolution, a sufficient amount of long-term unsecured debt would be available to absorb additional losses through a \u201cbail in\u201d process, recapitalizing the firm with no taxpayer bailout and without generating systemic financial contagion. These proposed requirements should also improve market discipline by ensuring that each GSIB has a class of creditors who are clearly \u201cat risk,\u201d and therefore have an incentive to monitor the firm\u2019s risk-taking.\n\nIn my 2013 speech, I also called for further work to address the challenges in a resolution scenario posed by potentially disruptive close-out of cross-border derivatives contracts. Here too, important progress has been achieved over the past two years.\n\nThanks to productive collective action by the private sector in dialogue with U.S. and international authorities, an initial set of 18 GSIBs and other large dealer banks have adhered to the 2014 International Swaps and Derivatives Association (ISDA) resolution stay protocol covering OTC bilateral derivatives in connection with last year\u2019s G-20 summit. Under the protocol, counterparties agreed to the cross-border enforceability of existing statutory stays on resolution-related early termination and other default rights in OTC bilateral derivatives contracts.\n\nWith support from the U.S. and other key jurisdictions, the FSB subsequently called on all GSIBs and other firms with significant derivatives exposures to adhere to the protocol by the end of 2015. In addition, the FSB requested that such contractual terms be incorporated into other financial contracts with resolution-related termination features\u2212such as contracts relating to repo and securities lending arrangements. This goal has been accomplished this past week, and represents another positive milestone in improving cross-border resolvability. Importantly, both the proposed U.S. long-term debt requirement and provisions in the resolution stay protocol support resolution under both Title I and Title II of the Dodd-Frank Act.\n\nWhile we should recognize the extent of progress that has been made to set the basic foundations for the cross-border resolution of a GSIB, it is equally important in my view to recognize the significant challenges that still remain, and the important work that still needs to be carried out by both firms and authorities.\n\nBoth within the official sector and within the largest banking firms, important work remains to be done to advance the capacity to effectively operationalize a GSIB resolution.\n\nExamples include:\n\nThis ongoing work is being pursued through a variety of channels, including through the joint Federal Reserve / FDIC review of Title I resolution plans, the Federal Reserve\u2019s horizontal supervisory review of recovery and resolution preparedness, and in the international work of the FSB.\n\nIn addition, while Title II of the Dodd-Frank Act establishes the FDIC Orderly Liquidation Fund as a source of backstop liquidity provision for a firm undergoing a Title II resolution, no equivalent official sector liquidity backstop is available under the bankruptcy regime. Since it is the bankruptcy regime that is relevant for the purposes of resolution planning under Title I, this is a challenge that firms need to address under that framework.\n\nFurther work remains as well with respect to the derivatives close-out issue in resolution. A key next step will be for the U.S. and other major jurisdictions to put in place regulations and supervisory measures that will require non-bank counterparties of GSIBs to trade with the GSIBs on terms equivalent to those found in the ISDA resolution stay protocol. This further step is needed in order to limit the potential for arbitrage within the market and to promote greater stability in the event of a necessary resolution.\n\nAs we move this work forward, we should acknowledge and take stock of the significant advances achieved over the past few years, while at the same time remain focused on our responsibility to address the challenges that remain.\n\nThank you for your kind attention.\n\n1 Dianne Dobbeck, Robert Fitchette, Charles Gray, Joyce Hansen, HaeRan Kim, Kristin Malcarney and Joseph Tracy assisted in preparing these remarks."
  },
  {
    "title": "Dinner Address for the Bank of England-Federal Reserve Bank of New York Conference on Money Markets and Monetary Policy Implementation",
    "date": "Nov 16, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/pot151116",
    "content": "Introduction1\nIt is a pleasure to have the opportunity to give the address at tonight\u2019s dinner. I would like to start by thanking the Bank of England for hosting this conference on money markets and monetary policy implementation. It\u2019s hard to think of a better place to discuss these topics than just steps away from the historic Lombard Street, described in Bagehot\u2019s classic book on money markets.2 I also want to thank all of you for actively participating in today\u2019s discussions. One thing I particularly enjoyed about the event was the interaction among market practitioners, central bankers, and researchers. I think the diversity of perspectives that these groups bring contributes to a fruitful dialogue that can help lead to more informed choices and decisions. I will come back to this point. But before I go on, let me remind you that the views I express are my own and may not reflect the views of the Federal Reserve Bank of New York or the Federal Reserve System.\n\nThe topic of this conference may not appear particularly glamorous. It is natural to view monetary policy implementation as a technical and humble exercise next to the flashiness of policy formulation, which has policymakers determining the appropriate level of interest rates. However, for those of us charged with carrying out policymakers\u2019 decisions, there is keen interest in the mechanics. We have the task of designing and executing operations that ensure that policymakers\u2019 instructions are implemented effectively and efficiently, so that their intentions can affect inflation and the real economy. But while monetary policy implementation is just a means to an end, there is no obvious single \u201cright\u201d way to do it, and every central bank\u2019s operating framework reflects history, unique institutional constraints and the market environment, which may change over time.  \n\nSo even though the topic of today\u2019s conference may seem to lack glamour, it is significant, particularly now, since monetary policy implementation and the market landscape have undergone profound changes in recent years. Many advanced economy central banks have adopted a number of new tools to implement monetary policy or used traditional tools in new ways or in unprecedented size, in part because economic conditions have necessitated historically low interest rates that have bumped up against the zero bound for almost seven years. One result is that the balance sheets of central banks in many advanced countries are now much larger than the amount of currency in circulation, which raises new questions and, perhaps, challenges.3\n\nWe have also seen important changes in money markets, which we can define as wholesale markets for low-risk, highly liquid, short-term IOUs\u2014including central bank liabilities, which are among the highest quality assets traded in these markets. For centuries, money markets have played a central role in financial intermediation. These are the markets in which central banks traditionally operate and from which the monetary policy impulse is transmitted. Although their role hasn\u2019t fundamentally changed, modern money markets look quite different today than they did during Bagehot\u2019s time and even just ten years ago. The pace of change has been remarkable following the financial crisis, mainly because of exceptional monetary policy measures and new regulations. Changes in market structure and regulation have implications for monetary policy implementation, and today\u2019s discussion provided some interesting insights on these topics.\n\nThis combination of changes in money markets and new policy tools, as well as observations on how central banks\u2019 operating frameworks did or didn\u2019t work during the financial crisis, suggests that those of us responsible for monetary policy operations should be researching and analyzing how monetary policy will be implemented in the years to come. What are the lessons from the crisis and the long period spent at the zero bound and how do these lessons change our views regarding monetary policy implementation? These are questions that many central banks are currently facing, particularly in advanced economies. They are certainly relevant for us at the Federal Reserve as we begin our own efforts to think about a long-run framework for monetary policy implementation.4\n\nIn my remarks tonight, I would like to give you my views on the significant issues, and the questions I believe deserve further study. I also want to emphasize how important it is for those of us charged with monetary policy implementation to seek broad engagement on these issues, particularly in our effort to better understand how our money markets function and how best to implement monetary policy in these markets.  \n\nMotivation and Background\n\nWhy should we think hard about issues related to monetary policy implementation? After all, central banks could always go back to the frameworks they used before the crisis. In the case of the Federal Reserve, the pre-crisis framework worked well at targeting the federal funds rate and we have high confidence that a similar system could work again in the future. But can we do better?5 In light of recent experience and changes, are there more effective, transparent, or flexible implementation frameworks that would give policymakers capacity to better steer the economy in the direction they need to satisfy their mandate?\n\nRecent experience suggests that the Federal Reserve\u2019s new tools\u2014interest on reserves and term deposits6\u2014as well as its application of old tools towards new purposes\u2014fixed-rate reverse repos and large-scale outright security purchases\u2014can be very helpful, but we can probably still learn more about how best to employ them. We can benefit collectively from studying the impact of differences in the implementation of similar tools across central banks.7 For example, \u201cquantitative easing,\u201d known shorthand as QE, originates with the Bank of Japan\u2019s (BoJ) efforts to stimulate inflation in the early 2000s at the zero bound. In this effort, they targeted the money base and conducted temporary operations and short-term securities purchases to accomplish that liability-driven operating objective. Because the maturity structure of the BoJ\u2019s assets remained relatively short, the bank was able to run down the size of its balance sheet to a more normal level relatively rapidly when it came time to do so and then raise rates using standard implementation tools. In contrast, in the United States and other countries, including Japan, QE is now associated with targets for longer-term asset purchases and extending portfolio duration, to put downward pressure on long-term interest rates. Policy normalization will need to proceed in a different way than it did in Japan in the mid-2000s if most of the additional assets, and the reserve balance liabilities created as a byproduct of their acquisition, remain on the central bank\u2019s balance sheet until they mature in the far future. In this case, waiting for the passive runoff of the additional assets alone may not be a viable interest rate implementation strategy.  Depending on the details of the operating framework and money market structure, other tools might be needed\u2014at least for some time\u2014to control overnight interest rates above the zero bound while the size of the balance sheet remains elevated. What we learn about these tools through the period of normalization could prove useful when we think about our long-run framework.\n\nCentral bankers around the world have been innovative in developing tools to address recent challenges and to prepare to normalize their operations, and overall, the set of implementation options at our disposal may be much broader than we thought before the crisis. So let\u2019s fully explore the operational issues underlying these options. A deeper understanding will help inform the choices policymakers need to make in order to meet their goals.\n\nNow seems like a particularly good time to start such an effort, for several reasons. First, we need to digest the lessons from the recent crisis with respect to monetary policy implementation and money market functioning, and it is best to do so while the experience is still fresh in our minds. Second, while the Federal Reserve has great confidence that our normalization framework will be effective at allowing us to raise money market interest rates when the Federal Open Market Committee (FOMC) determines it is appropriate, we expect to learn a lot about how money markets react to that framework as we move away from the current very low interest rates with a large amount of reserves in the banking system. We can then incorporate knowledge gained during our post-liftoff experience into our thinking.\n\nWe have the benefit of not starting from scratch in this effort. There already exists a rich academic literature on monetary policy implementation frameworks, and we saw some relevant examples this morning. This literature dates at least back to the late 1960s, when Bill Poole developed a model that is still being used today.8 Recent developments have revealed that our money markets are not frictionless, and current research incorporates this reality of market segmentation. Some of the papers we have seen today try to contend with the effects of new regulation,9 or try to model impediments to trade in the form of preferred habitat frictions10 or search frictions.11 These new models provide fresh insights and can also be useful for us in communicating with academics and market experts. These improvements are notable because they represent a significant departure from views that were espoused a few decades ago.12 Much research before the crisis put too much faith in market efficiency and spent too little time exploring the detailed plumbing of the financial system.13 Empirical work can also contribute to our thinking about monetary policy implementation. What more can we learn about the relationship between different money markets, such as the spreads between various secured and unsecured rates?14 How much should we care about volatility in money markets and how does that volatility affect the monetary policy outcome? We saw some interesting work on the topic today.15\n\nIn the United States, we also have the benefit of internal work, now public, that we undertook previously. The Federal Reserve had started to examine ways to improve its policy implementation framework before the crisis. Analytical work between 2006 and 2008 provides a solid foundation from which to build. As you may recall, in 2006 Congress granted the Federal Reserve the authority to pay interest on reserve balances held by depository institutions, and this authority was originally set to become effective in 2011.16 We went to work to try to understand how best to employ this new tool. The focus of that work was on operating regimes to target the fed funds rate. Basically, it considered several variants of corridor and floor systems. The financial crisis interrupted this work, and it was not completed as had been intended.\n\nThe lessons from the crisis suggest that the implementation framework needs to be considered more broadly. For example, in the 2008 work, we did not think about the zero bound very much.  Yet we have now been at or near zero for nearly seven years, and many other countries are in a similar situation. So we need to incorporate these new dimensions, and the lessons from the experience of other central banks, in our analysis. Another thing that was not taken into account enough in the 2008 work was the complexity of U.S. dollar money markets, both on- and offshore. In particular, we did not anticipate that frictions in our money markets would limit the arbitrage that would keep market rates in line with the rate of interest we pay on excess reserves by such an extent, leaving many money market interest rates well below the rate of interest paid on excess reserves (IOER), contrary to what theory would suggest. Meanwhile, we learned a lot about the behavior of money market participants during the crisis, and we continue to observe how money market trading dynamics are evolving in response to changes in the market environment.17\n\nThe Federal Reserve\u2019s balance sheet is much larger than we would have ever anticipated before 2008. To give you an idea, prior to the crisis, a few tens of billions of excess reserve balances was considered a large supply for a floor system.18 Today, the Federal Reserve, in addition to currency and capital, has around $3 trillion of liabilities outstanding, most of which are in the form of excess reserves held in the banking system. We have also seen changes in markets since the crisis and expanded the set of our counterparties for certain operations in ways that were not contemplated in our prior work. These developments have implications for determining the appropriate level of reserves in a future framework.\n\nLooking Ahead\n\nAs Ulrich Bindseil noted in his excellent book, even if one thinks that implementation details aren\u2019t ultimately very important to the transmission of monetary policy, they may well have implications for important aspects of the financial markets, such as the cost effectiveness of banks\u2019 liquidity management, bank business and funding models, and financial stability.19 So these considerations should influence the type of questions we ask ourselves when it comes to improving the operating frameworks of central banks. We should, of course, consider the traditional parts of an operating framework, for example, possible interest rate targets and the mechanisms used to achieve the target. But recent experience strongly suggests that we need to consider options beyond just a classic interest rate targeting regime that\u2019s based on a scarcity of reserve balances. We will need to think about the composition and structure of our balance sheet on both the asset and liability sides.20 This consideration will be important should large-scale asset purchases (LSAPs) become a more standard tool for central banks, which could happen if lower levels of equilibrium real rates imply an increasing frequency of very low overnight rates. Further, some analysts have argued that there might be a role for balance sheet policies away from very low interest rates in supporting the macroeconomic and macroprudential objectives of central banks.21\n\nThat said, a large central bank balance sheet relative to currency in circulation raises a number of questions about the monetary authority\u2019s footprint in money markets, which some policymakers say presents potential risks to central bank independence.22 A large footprint may also increase the central bank\u2019s role in money markets in ways that are difficult to anticipate and that may prove to be undesirable.23 One simple principle for monetary policy implementation regimes is to avoid structures where central bank intermediation crowds out activity that private participants can do more effectively and efficiently. Applying this principle is not simple, since expectations of central bank interventions affect private incentives and can produce changes in the structure of markets.24 So central banks need to be mindful of potential unintended consequences of their implementation regimes. This prudence is well captured in the FOMC\u2019s Policy Normalization Principles and Plans, released in September 2014, which note that, in the long run, the Fed\u2019s balance sheet should be no larger than necessary for the effective and efficient implementation of monetary policy and should consist primarily of Treasury securities.25\n\nWe also need to make sure that the impulse of monetary policy is transmitted effectively to the real economy. Given the growing importance of nonbanks in many money markets, especially in the U.S. dollar markets, we should think about the counterparties with whom we interact. Would expanding the types of counterparties that we do business with increase the effectiveness of monetary policy? What are the costs and benefits of interacting with counterparties beyond our traditional set?\n\nAny long-run monetary policy implementation framework should be assessed relative to goals. That assessment may be informed by recent experience.  For example, a framework should allow us to achieve an appropriate degree of control over short-term rates, both in normal times and during periods of financial distress. It should also be as robust as possible to potential structural changes in the financial system. The framework should enhance our ability to achieve macroeconomic objectives at very low or even negative interest rates. Further, it might be important to consider the framework\u2019s ability to address liquidity strains in money markets and to support overall financial stability.\n\nOther concerns could include the burdens and deadweight losses associated with reserve requirements, the implications of the framework for the efficiency and resilience of money markets and government securities markets, and the framework\u2019s ability to help support the efficiency and resilience of payment systems.\n\nConclusion\n\nI want to conclude by saying a few more words about the value of engaging broadly with the public, with market participants, with researchers both in central banks and in academia, and with our global central bank counterparts. The issues we will have to tackle are important and complex, and there is much to gain from different points of view. Market participants can provide a deeper understanding of financial market dynamics and shed necessary light on the impact and limitations of monetary policy on a practical dimension. As we saw today, researchers can provide empirical analysis as well as models that help us think about the impact and effectiveness of different tools or policies. Whether they work in central banks or academia, they provide a perspective that we need to take into account when thinking about our long-run framework. And, of course, we can learn from our peers in policymaking and on markets desks at other central banks. We may have tried things that worked very well, or did not work so well, and comparative experience can be extremely valuable. Forums like this, which bring together a range of experts from different areas, can help advance our understanding of the important issues we will have to face.\n\nSo, I hope to see more of this type of engagement going forward. We have a unique opportunity to think very broadly about the issues that will confront us in the foreseeable future. We should seek diverse perspectives and be open to new ideas and perspective.\n\n1 I would like to thank Deborah Leonard and Antoine Martin for their excellent assistance in the preparation of these remarks and colleagues in the Federal Reserve System and global central bank community for their insightful comments and suggestions.\n\n2 Walter Bagehot, Lombard Street: A Description of the Money Market (London: Henry S. King, 1873). While Bagehot is often remembered for his advice regarding lender-of-last-resort policy, most of his book provides a careful study of money markets, which is our current focus.\n\n3 Central banks that maintain large foreign exchange reserves may also have balance sheets that far exceed currency in circulation. This is more typical in emerging markets, where domestic currency money markets tend to be less mature.\n\n4 An extended effort to evaluate potential long-run monetary policy implementation frameworks was announced in the July 2015 FOMC meeting minutes.\n\n5 For example, some have suggested that the Federal Reserve could target a repo rate, rather than the federal funds rate (see Bernanke, or Gagnon and Sack). Targeting a repo rate could have some benefits, but may entail a number of complications, so more work would be necessary to evaluate the potential consequences of such a change.\n\n6 Although the Federal Reserve only recently introduced these instruments, versions of interest on reserves and term deposits are standard components of some other central banks\u2019 implementation toolkits.\n\n7 For example, there is much to learn from the experience of the central banks that have implemented negative rates recently. It is important to note that, with the exception of the Swiss National Bank, the implementation of negative rates did not require any changes in these central bank\u2019s respective frameworks for policy implementation, although some legal and operational work was required.\n\n8 William Poole, \u201cCommercial Bank Reserve Management in a Stochastic Model:  Implications for Monetary Policy,\u201d Journal of Finance 23, no. 5 (1968): 769-91.\n\n9 See Christopher Jackson and Joseph Noss, \u201cA Heterogeneous Agent Model for Assessing the Effects of Capital Regulation on the Interbank Money Market under a Corridor System,\u201d Bank of England Working Papers, no. 548, September 2015, as well as Morten L. Bech and Todd Keister, \u201cLiquidity Regulation and the Implementation of Monetary Policy,\u201d BIS Working Papers, no. 432, October 2013.  See also Bank for International Settlements Committee on the Global Financial System and Markets Committee, \u201cRegulatory Change and Monetary Policy,\u201d CGFS Papers, no. 54, May 2015.\n\n10 See Jim Clouse, Jane Ihrig, Elizabeth Klee, and Han Chen, \u201cThe Federal Reserve\u2019s Tools for Policy Normalization in a Preferred Habitat Model of Financial Markets,\u201d Board of Governors of the Federal Reserve System Finance and Economics Discussion Series, no. 2014-83, October 2014.\n\n11 See Ben Lester and Roc Armenter, \u201cExcess Reserves and Monetary Policy Normalization,\u201d Federal Reserve Bank of Philadelphia working paper no. 15-35, August 2015.\n\n12 For example, Marvin Goodfriend and Robert G. King argued in 1988 that \u201ctoday\u2019s financial markets provide a highly efficient means of allocating credit privately. On the basis of such considerations, we find that it is difficult to make a case for central bank lending and the regulatory and supervisory activities that support it.\u201d See \u201cFinancial Deregulation, Monetary Policy, and Central Banking,\u201d Federal Reserve Bank of Richmond Economic Review, May-June 1988.\n\n13 For example, the work prepared by Federal Reserve staff in 2008 to assess possible use of the authority to pay interest on reserves (IOR) did not deal with the fact that some institutions cannot earn IOR, so it did not contemplate that this rate may not serve as a firm floor; see http://www.federalreserve.gov/foia/files/20080411.IoR.FOMC.Options.paper.public.pdf. More recent work explicitly considers frictions that limit the effectiveness of IOR to serve as a floor and explores other tools that can support money market interest rates. See, for example, Antoine Martin, James McAndrews, Ali Palida, and David Skeie, \u201cFederal Reserve Tools for Managing Rates and Reserves,\u201d Federal Reserve Bank of New York Staff Reports, no.  642, September 2013.\n\n14 In the case of the United States, more research on the relationship between the Eurodollar rate, the federal funds rate, and the repo rate could provide insights on the functioning of our money markets.\n\n15 See Matthew Osborne, \u201cMonetary Policy and Volatility in the Sterling Money Market,\u201d paper presented at the Bank of England-Federal Reserve Bank of New York conference, \u201cMoney Markets and Monetary Policy Implementation,\u201d November 16-17, 2015.\n\n16 The implementation date was accelerated to October 2008 during the financial crisis to enhance the Federal Reserve\u2019s ability to control short-term interest rates.\n\n17 To support the implementation of monetary policy and the analysis of money market conditions, the Federal Reserve began collecting transaction-level data on federal funds, Eurodollars, and certificates of deposits from a large set of domestic banks and agencies of foreign banks operating in the United States on April 1, 2014. In February 2015, the New York Fed announced plans to begin using the new data to calculate the daily federal funds effective rate and to begin publishing an overnight bank funding rate based on transactions in both federal funds and Eurodollar markets. See http://www.newyorkfed.org/markets/opolicy/operating_policy_150202.html and http://libertystreeteconomics.newyorkfed.org/2015/04/the-fr-2420-data-collection-a-new-base-for-the-fed-funds-rate.html.\n\n18 A staff memo from 2008 suggested that in a floor system the level of excess reserves \u201cmight be on the order of $35 billion but could be larger on some days.\u201d For context, at the time, a number like $150 billion would have been held up as an extremely large level of excess reserves, well beyond anything we might have seriously considered as the level of reserves needed to implement a floor on rates. See http://www.federalreserve.gov/foia/files/20080411.IoR.FOMC.Options.paper.public.pdf.\n\n19 Ulrich Bindseil, Monetary Policy Operations and the Financial System (Oxford: Oxford University Press, 2014).\n\n20 Central bank assets include securities held outright or under repurchase agreements, as well as credit extensions and foreign currency-denominated assets. Central bank liabilities include currency, reserve balances, term deposits held by depository institutions, and reverse repos.\n\n21 For example, a large supply of \u201cmoney-like\u201d assets provided by the official sector could crowd out some short-term private sector liabilities, reducing the amount of maturity transformation in the financial system and improving financial stability. See, for example, Mark Carlson, Burcu Duygan-Bump, Fabio Natalucci, William R. Nelson, Marcelo Ochoa, Jeremy Stein, and Skander Van den Heuvel, \u201cThe Demand for Short-Term, Safe Assets and Financial Stability: Some Evidence and Implications for Central Bank Policies,\u201d Board of Governors of the Federal Reserve System Finance and Economics Discussion Series, no. 2014-102, November 2014.\n\n22 Maintaining a large balance sheet in normal times may be perceived as a \u201cslack\u201d variable that invites policymakers to use it for non-monetary policy objectives.  See, for example, https://www.philadelphiafed.org/publications/speeches/plosser/2010/09-24-10_swiss-national-bank.\n\n23 For a discussion of footprint considerations in the design of the Federal Reserve\u2019s overnight reverse repo operations, see Joshua Frost, Lorie Logan, Antoine Martin, Patrick McCabe, Fabio Natalucci, and Julie Remache, \u201cOvernight RRP Operations as a Monetary Policy Tool:  Some Design Considerations,\u201d Federal Reserve Bank of New York Staff Reports, no. 712, February 2015.\n\n24 For example, a money market mutual fund could choose to restrict its investments only to overnight reverse repurchase agreements provided by the Federal Reserve if it believed these instruments would continue to be supplied in the far future.\n\n25 See http://www.federalreserve.gov/newsevents/press/monetary/20140917c.htm."
  },
  {
    "title": "The U.S. Economic Outlook and Monetary Policy",
    "date": "Nov 12, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud151112",
    "content": "It is a pleasure to have an opportunity to speak here at the Economic Club of New York.  As the current chair of the Club, I\u2019m admittedly biased, but this is a great venue to have the opportunity to share my thoughts about the U.S. economic outlook and the implications for monetary policy.  As always, what I have to say reflects my own views and not necessarily those of the Federal Open Market Committee (FOMC) or the Federal Reserve System.1\n\nBefore I start, I want to be clear about one specific issue I will not address today\u2014that is, whether or not I expect the monetary policy normalization process to commence at the next FOMC meeting in December.  Let me just say that my view will depend on how incoming data, broadly defined, influences my assessment of the prospects for further improvement in the U.S. labor market and my confidence that inflation will return to the FOMC\u2019s 2 percent objective over the medium term. \n\nWith that caveat out of the way, how do I assess the U.S. economic outlook?  On balance, I believe we have been making progress toward our goals, recognizing that a few issues still cloud the outlook.  Most noteworthy is the fact that inflation continues to run well below our 2 percent objective. \n\nWith respect to the economic growth outlook, the softness in third-quarter real GDP\u2014which according to its initial estimate rose at only a 1.5 percent annualized pace\u2014and the weakness of the manufacturing sector have raised concerns that the U.S. economy may be losing some forward momentum.  Sharp reductions in oil and gas drilling activity and a loss of international competitiveness associated with the dollar\u2019s appreciation over the past year have restrained factory output.  Judging from historical experience, the impact of the dollar\u2019s recent strength has the potential to be protracted, so that the trade sector probably will continue to be a drag on growth in 2016.  Thus, the manufacturing sector is likely to continue to lag behind the rest of economy. \n\nBut these negatives need to be set against the many positive aspects of the economic outlook.  In particular, domestic demand continues to grow at a solid pace as increases in consumer spending, housing and business fixed investment all contributed to the third quarter\u2019s 2.9 percent annualized gain in real domestic final sales.  A large decline in the pace of inventory accumulation was the main reason why real GDP growth faltered in the third quarter.  Because the contribution to growth from inventory investment can be quite volatile on a quarter-to-quarter basis, the growth in real final sales probably provides a better sense of the state of economic activity than does the GDP figure. \n\nMoreover, when one digs deeper, the fundamentals supporting domestic demand look quite sturdy.  For example, consumer spending has been well-supported by real income gains and rising household net worth.  Household balance sheets do not appear over-extended.  The household debt service burden is low, the household saving rate is not low relative to household net worth, and household credit growth has been slow. \n\nHousing fundamentals are solid as well.  Decent payroll gains have supported household formation over the past year and mortgage rates remain low.  Housing prices are rising and the constraint on growth in residential investment now appears to be more on the supply side, as building contractors struggle to mobilize the resources needed to construct more homes.  The National Association of Home Builders\u2019 index rose in October to the highest level since late 2005.  While the housing indicators will likely continue to be volatile on a month-to-month basis, I expect the gradual improvement in the housing sector to continue.  \n\nAlso, the international outlook appears less problematic than it did just a few months ago.  Although substantial questions remain about the Chinese growth outlook and the consequences of lower commodity prices for major commodity-exporting countries, we have seen two important positive developments.  First, the Chinese transition to a more balanced growth path appears to be underway\u2014with stronger consumption and less emphasis on investment.  And the Chinese authorities have a range of tools available to support their economy during this transition. \n\nSecond, despite the intense strain placed on many emerging market economies by the substantial deterioration in recent years in their terms of trade, this stress does not yet appear to have led to the type of financial system breakage that might lead to widespread contagion and large capital flow reversals.  In fact, in recent weeks, emerging market equity markets have recovered substantial ground and many countries\u2019 currencies have stabilized. \n\nIt is also important that the forward momentum in the jobs market persists.  The August and September employment reports raised some concerns that the U.S. labor market might be faltering.  Those concerns should be at least partially put to rest given the strength of the October employment report, recognizing that the employment news can be volatile on a month-to-month basis.  Most noteworthy to me are the strong payroll employment gains in October and the solid 0.3 percent rise in aggregate hours worked.  Over the past three months, payroll gains have averaged 187,000 per month, not much below the average payroll growth of 213,000 per month during the first half of 2015.   \n\nWe are now much closer to our goal of maximum sustainable employment than at the start of the year.  The civilian unemployment rate is 5 percent, not much above the level generally viewed as consistent with full employment.  For example, in the September FOMC Summary of Economic Projections, the median estimate of the longer-run unemployment rate was 4.9 percent.  And, broader measures of unemployment\u2015such as indicators that include people that are working part-time for economic reasons and discouraged workers who have left the labor market but still want a job\u2014have also shown substantial improvement over the past year. \n\nDiscerning the degree of slack remaining in the labor market becomes more difficult as the margin of unused and underused labor resources shrinks.  My own assessment is that some margin still remains.  I reach that conclusion for two reasons.  First, broader measures of unemployment are still high relative to where you would expect them to be given a 5 percent civilian unemployment rate.  Part-time workers and discouraged workers remain a potential source of additional labor, and the labor market participation rate seems low even when adjusting for demographic factors.  If the normal historical relationship between the broader U6 measure of unemployment\u2014which includes part-time workers that want a full-time job and discouraged workers\u2014and the narrower U3 measure of unemployment\u2014which excludes these workers\u2014were to reassert itself, this would imply about an additional \u00bc to \u00bd percentage point of labor market slack in my assessment. \n\nSecond, we have still not seen compelling evidence that a tightening labor market is leading to more rapid labor compensation gains.  Although average hourly earnings rose more quickly in October\u2015pushing the year-over-year pace up to 2.5 percent\u2015this indicator can be volatile on a month-to-month basis, and it has not been borne out by some other important measures of labor compensation.  For example, over the past year, the Employment Cost Index for private sector worker compensation has risen 1.9 percent, remaining within the narrow range of recent years.  This is important because my assessment of what constitutes maximum sustainable or full employment depends in large part on how a tighter labor market translates into compensation gains.  At the same time, one needs to be cautious about interpreting compensation trends in the current environment.  It is possible that factors such as very low headline inflation and weak productivity growth are holding down what workers receive in compensation.  Therefore, because of such factors, compensation growth may not provide a reliable signal about whether we are approaching full employment. \n\nTo sum up on the growth side, the economy looks to be in decent shape and is likely to continue to grow at a slightly above-trend pace.  Spare labor resources are shrinking.  But there still is some risk that the growth pace could slow as the trade sector acts as a drag on aggregate economic activity.\n\nOn the inflation side of the ledger, I have greater concerns because we continue to fall substantially short of our inflation objective of 2 percent for the personal consumption expenditures (PCE) deflator.  Over the past year, the PCE deflator has risen only 0.2 percent\u2014held down by lower import prices and falling energy prices\u2014and the core PCE deflator, which excludes the more volatile food and energy components, has risen 1.3 percent. \n\nThere is also some evidence that suggests that inflation expectations are under downward pressure.  In particular, some survey measures of long-term inflation expectations are at the low end of the ranges that have prevailed in recent years.  For example, the University of Michigan median measure of inflation expectations at a five-to-ten year horizon fell last month to 2.5 percent, the lowest level since September 2002.  Similarly, the New York Fed\u2019s three-year median inflation expectations measure from our Survey of Consumer Expectations is currently at 2.8 percent, down from 3 percent a year ago.  The good news, however, is that these declines are very modest in magnitude.  Thus, I would still judge that inflation expectations remain well-anchored based upon these survey measures.   \n\nSimilarly, measures of inflation compensation based on the interest rate spread between nominal Treasury securities and Treasury Inflation Protected Securities (TIPS) have fallen sharply over the past year.  For example, the Board of Governors\u2019 5-year, 5-year forward measure\u2014in other words, what inflation compensation would be for the period five-to-ten years from now\u2014currently stands at around 1.8 percent, down about 40 basis points from a year ago. \n\nHowever, I put even less weight on this development than on the survey evidence for two reasons.  First, the decline in these forward inflation compensation measures has been highly correlated with the fall in oil prices\u2014a pattern that is hard to explain.  Second, a careful analysis of the factors behind the decline in inflation compensation suggests that changes in liquidity risk premia and what investors are willing to pay for inflation protection account for most of the decline, rather than the decline reflecting a change in inflation expectations.  Still, we need to continue to monitor inflation compensation closely, while recognizing that sorting out the allocation of the decline in inflation compensation across the three factors\u2014liquidity risk premia, the price for inflation protection and inflation expectations\u2014is admittedly difficult.  And also, the conclusions reached in such models are sensitive to these models\u2019 assumptions and structures. \n\nRegardless of how much signal one takes from these recent data, a decline in inflation expectations below levels consistent with our 2 percent inflation objective would be problematic because inflation expectations are an important influence on actual inflation.  Businesses, for example, make decisions about the size of annual wage increases based, in part, on their expectations of future inflation.  And, households base their spending decisions, in part, on how fast they expect their incomes to rise, and inflation expectations play a role in that process.  Lower inflation expectations also raise the level of real interest rates, all else equal, which can undercut the power of monetary policy to support economic activity.  This is particularly relevant at the zero lower bound for interest rates.\n\nIf the economy continues to grow at an above-trend pace, then I think worries about inflation remaining too low should begin to recede.  After all, headline inflation on a year-over-year basis is likely to rise early next year as much of the past year\u2019s decline in energy prices falls out of the year-over-year inflation rate calculations.  Also, some of the factors holding down headline and core inflation are likely to be transitory.  Energy prices will not go down forever and, as the dollar stabilizes, import prices will likely stop falling.  In addition, despite these factors that are weighing on core inflation, the recent trend of core inflation has been very steady, with the 12-month change in the core PCE deflator in a tight range of 1.2 to 1.7 percent since the beginning of 2013.  This suggests that core inflation should rise once these transitory factors dissipate.  Finally, I take some signal from the fact that the spread between the core services inflation rate and core goods inflation rate is wider than normal.  Core services likely better reflect the underlying trend, while core goods prices are more sensitive to external factors such as the drop in commodity prices and import prices.\n\nSo what does this imply for monetary policy and the likely timing and pace of interest rate normalization?  As you may be able to infer from my earlier remarks, I think it is quite possible that the conditions the Committee has established to begin to normalize monetary policy could soon be satisfied.  In particular, I will be evaluating the incoming information to see if it confirms my expectation that growth will be sufficient to further tighten the U.S. labor market.\n\nAfter lift-off commences, I expect that the pace of tightening will be quite gradual.  In part, that is because monetary policy is not as stimulative as the low level of the federal funds rate might suggest.  There is strong evidence that the short-term neutral real interest rate\u2014let\u2019s call that r*\u2014is currently quite low, certainly below the level that historically has applied on a longer-term basis.2\n\nA wide range of models suggest that the short-run real r* is currently around 0 percent, far below its historical longer-run level that is estimated to be about 2 percent.3  This benchmark \u201cneutral\u201d rate needs to be compared to the actual real federal funds rate.  If we measure the latter by subtracting the core PCE inflation rate from the nominal federal funds rate, the actual real federal funds rate is slightly below -1 percent.  Thus, current short-term real interest rates are not far below their neutral counterparts, suggesting that the current monetary policy stance is not exceptionally stimulative.\n\nThe notion that r* is currently very low is also evident by more casual empiricism.  Simply ask the following question:  If r* were close to its long-run historical value of 2 percent, would we expect to see the economy growing at only slightly above its potential growth rate?  The fact that the economy is growing quite slowly despite a low federal funds rate and a very large Federal Reserve balance sheet suggests that monetary policy currently is not providing that much stimulus to the economy.  In other words, the gap between r* and the federal funds rate is relatively narrow.\n\nWhy is r* depressed and how is it likely to evolve over time?  In my view, several short-term factors are restraining r*.  First, the short-run r* is low because the foreign exchange value of the dollar has risen, reflecting both the fact that foreign economies are growing slowly and as well as an expectation that the monetary policies of the U.S. and other major economies will continue to diverge for some time.  If foreign demand picks up and the dollar weakens, then r* would likely rise over time as the persistent drag from the trade sector lessens.  Second, short-run r* is low because of the hangover of the financial crisis.  For example, mortgage credit availability for households with low FICO scores is still very limited compared to pre-housing boom standards.  This is constraining their ability to purchase housing, which holds back the pace of residential investment.  Also, because the searing experience of the Great Recession has likely caused households and businesses to be more cautious in terms of their saving and investment decisions, this has also pulled down the short-run value of r*.  Some of these factors should fade over time, gradually pushing up short-run r* toward its long-run value. \n\nAt the same time, there are some longer-term factors that are likely to keep r* below its long-run historical average far into the future.  In particular, potential real GDP growth in the U.S. appears to have declined in recent years\u2014held down by slower productivity growth and demographic factors that are causing the workforce to grow more slowly.  This is the main reason why I have cut my estimate of the longer-run federal funds rate in recent years.  And I\u2019m not alone.  In the FOMC\u2019s September Summary of Economic Projections, the median projection for the long-run federal funds rate was 3 \u00bd percent, 50 basis points below  the level of two years earlier.\n\nMy discussion about short-run r* and long-run r* has implications for how I think about monetary policy.  The likelihood that we face a situation where the short-run r* is depressed, the economy is growing only slightly at an above-trend pace and inflation is too low relative to our objectives, suggests that we need to think carefully whether the time is right to begin to normalize monetary policy.  Additionally, the likelihood that long-run r* is lower than it has been historically, suggests that after lift-off the upward trajectory of the short-term rates is likely to be quite shallow.  \n\nAnother factor that weighs on the timing and pace of normalization is risk management.  What are the relative costs of going too early versus too late?  As I see it, there are risks on both sides, and I think this explains why reasonable people can differ as to the appropriate path for the policy rate.  Consider the two main risks of normalizing too quickly.  First, we could just be too optimistic about our growth and inflation forecasts.  Second, we could be right about our forecasts, but the rise in short-term rates could provoke an outsized tightening of financial conditions that might cause the economy\u2019s forward momentum to slow more than we anticipate.  In either case, the economy would not be growing fast enough to put increased pressure on resources.  In such circumstances, underlying inflation might not rise and inflation expectations could become unanchored to the downside.  Consequently, not only might the FOMC be forced to reverse course and ease monetary policy, but the efficacy of additional stimulus measures could be attenuated by the fall in inflation expectations.  Avoiding a Japan-like experience in which inflation expectations have become unanchored to the downside should be an important consideration in the conduct of monetary policy. \n\nOn the other side, there are several risks of delaying the start of lift-off and normalizing more slowly.  The first one is that the unemployment rate could fall to an unsustainably low level that is not consistent with our long-run price stability objectives.  Monetary policy works with long and variable lags, so overheating is a risk.  If overheating did occur, the FOMC might need to tighten monetary policy more aggressively in order to keep inflation from significantly overshooting its 2 percent objective.  In such circumstances, the risk of a recession would probably climb significantly.  In the past, it has been very difficult for the Federal Reserve to engineer a soft landing for the economy when it had to tighten policy aggressively in order to keep inflation in check.  Historically, once the unemployment rate rises above a small threshold of 0.3 to 0.4 percentage points, the next stop has always been a full-blown recession.  I very much would want to avoid such an outcome.  A long-lived economic expansion is always desirable, but especially so in the aftermath of the financial crisis and Great Recession.\n\nThe second risk of delaying lift-off and normalizing more slowly is that the low level of the federal funds rate may be distorting financial markets and increasing financial stability risks.  I don\u2019t think this has yet occurred to any significant degree, but it is a real risk that we should continue to monitor closely.   \n\nI see the risks right now of moving too quickly versus moving too slowly as nearly balanced.  The weight that one puts on each undoubtedly influences one\u2019s views on when the time will be right to begin to normalize monetary policy and the appropriate short-term rate trajectory thereafter. \n\nFinally, in conclusion, a few words about the importance of financial conditions in thinking about the future path of short-term interest rates.  Monetary policy does not work directly on the economy, but instead works through its effect on financial conditions.  By financial conditions, I mean all those financial factors that weigh on spending, saving and borrowing decisions.  Financial conditions include the level of the stock prices, the level of short- and long-term interest rates, the size of credit spreads, the foreign exchange value of the dollar and factors that weigh on the availability of credit.  If the linkage between financial conditions and the short-term interest rate controlled by the Federal Reserve were stable and predictable, then there would be no need to also monitor financial conditions.  But the linkage is not stable and predictable.  Sometimes financial conditions loosen or tighten in response to economic developments independent of our monetary policy decisions.  At other times, the response of financial conditions can be much larger or smaller than anticipated for a given change in interest rates. \n\nSeveral examples will help me make these points.  During 2004 to 2007, the FOMC raised the federal funds rate target 17 meetings in a row, lifting the federal funds to 5.25 percent from 1.0 percent.  Yet, during this period, financial conditions eased, as evidenced by the fact that the stock market rose, bond yields fell and credit availability\u2014especially to housing\u2014eased substantially.  In hindsight, perhaps monetary policy should have been tightened more aggressively.  In contrast, during the Fall of 2008, financial conditions tightened substantially even as the FOMC was cutting short-term rates.  Again, in hindsight, perhaps monetary policy should have been eased more aggressively.   \n\nHow financial conditions evolve and how markets respond to our actions are important in influencing the economic outlook, and we need to take that into consideration in our monetary policy decision-making.  When we begin to normalize monetary policy, will we provoke another \u201ctaper tantrum,\u201d or will market participants be relaxed as was the case when we actually tapered the rate of our asset purchases in 2014?  If financial conditions were to tighten more than expected when we began to normalize monetary policy, then I suspect we would go more slowly.  In contrast, if financial conditions did not respond at all, or eased, then I suspect we would go more quickly, all else equal. \n\nAlso, I don\u2019t think there is a particular set of financial conditions that we should target.  After all, the linkage between financial conditions and the economy is variable and the economic outlook is influenced by much more than financial conditions.  Thus, I have no target in mind for the U.S. equity market or other indicators of financial conditions.  But I do care about how financial conditions evolve when the changes are sufficiently large or persistent enough so they are likely to influence the economic outlook.  In that case, financial conditions need to be taken into consideration in the design and conduct of monetary policy.\n\nIt has been a pleasure to speak here today.  I hope my comments have made it clear that the monetary policy decision-making process is difficult when the margins of excess capacity narrow, but inflation remains below our objectives.  The world is highly complex and there is much we don\u2019t know about how the economy will evolve in the future.  As a Fed policymaker, I strive to be clear in my communications.  But I can\u2019t tell you today precisely what I\u2019d favor doing in the future, because that future remains uncertain.  Thank you very much for your kind attention.  \n\n1 Jonathan McCarthy, Paolo Pesenti and Joseph Tracy assisted in preparing these remarks.\n\n2 This is also a reason to not rely on mechanical monetary policy rules that assume that short-run r* is constant over time.  The widely-cited Taylor rule, for example, typically utilizes an r* of 2 percent.  For my thoughts on the\u2026 shortcomings of using monetary policy rules versus an approach that considers a broader range of factors, see Panel Remarks at the Brookings Institute, October 15, 2015.\n\n3 The Laubach-Williams model constructed to estimate the short-run level of r* estimates that r* is currently about -0.1 percent. Dynamic Stochastic General Equilibrium (DSGE) models, which take a very different approach to estimating r*, typically generate similar results.  For example, the New York Fed\u2019s DSGE model currently puts the short-run r* at between -0.1 and 0.1 percent. See Marco Del Negro, Marc Giannoni, Matthew Cocci, Sara Shahanaghi, and Micah Smith, Why Are Interest Rates So Low?, Liberty Street Economics, May 20, 2015."
  },
  {
    "title": "Opening Remarks at Reforming Culture and Behavior in the Financial Services Industry: Workshop on Progress and Challenges",
    "date": "Nov 5, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud151105",
    "content": "Welcome to the New York Fed and to a discussion of how culture and conduct might be improved within the financial services industry.  I am pleased to see all of you here today\u2014there is tremendous breadth of experience and responsibility within this room.  We need to take full advantage of this opportunity. I encourage all participants to be candid and on-point, because the task of reforming culture is formidable.1 \n\nUntrustworthy behavior on the scale that we have witnessed in financial services does not arise in a vacuum.  Social science research makes it clear that context largely drives conduct.2  This is not a new insight.  Adam Smith observed centuries ago that, independent of personal sentiment, we often behave according to what we \u201c[see are] the established rules of behavior.\u201d3  We observe the activity around us, assess the norms of conduct and generally adapt to those norms in our own behaviors. \n\nBanking is not exempt from this universal propensity.  Gerry Corrigan noted three decades ago that the \u201cimplicit codes of conduct\u201d that govern banker behavior exist apart from \u201cexplicit regulations.\u201d  He posited that these implicit codes must align with the public good\u2014an obligation that banks owe in exchange for the benefits \u201cuniquely available to [that]particular class of institutions.\u201d4  This, in Corrigan\u2019s view, was what made banks \u201cspecial\u201d\u2014the reciprocal benefits and responsibilities that support and constrain an industry essential to public well-being.\n\nCorrigan\u2019s premise is not an antique concept from a bygone era of banking.  Then, as now, there are public purposes of banking\u2014including financial intermediation, corporate valuation, facilitating investment opportunities, providing credit and creating market liquidity.  These activities underpin the economy and financial stability.  Reciprocity\u2014in other words, the expectation of a quid pro quo in the relationship between society and the financial services industry\u2014is the basis of public trust in financial institutions.  There is, however, a widespread sense that this principle has been compromised.   \n\nIndustry Responsibility\n\nTwo years ago, I noted that recent scandals in banking evidenced \u201cdeep-seated cultural and ethical failures.\u201d5  Many of the industry\u2019s leaders now agree.  According to the Federal Advisory Council of the Federal Reserve System, a group composed of senior representatives from the industry, \u201cas often as not [...] the challenges faced in recent years have been behavioral and cultural; post-crisis episodes such as LIBOR and foreign exchange manipulation provide hard evidence that there remains work to be done.\u201d6\n\nLast year I argued that \u201cthe solution [to cultural problems] needs to originate from within the firms, from their leaders.\u201d7  I view today\u2019s workshop as a progress report on the industry\u2019s efforts.  This is an opportunity for us to discuss collectively what is working, what is not, and the next steps that are needed. \n\nWe should take care, though, not to confuse cause and effect.  The banking scandals that followed the financial crisis are evidence that something fundamental is wrong.  I would encourage each of you to consider not just specific examples of misconduct, but the patterns within them that point to underlying causes.  I suspect we will see a strong overlap with those factors that contributed to the financial crisis.  I think your focus should be less on the search for bad apples and more on how to improve the apple barrels. \n\nRole of the Official Sector\n\nDodd-Frank strengthened bank balance sheets, and banks have become more resilient to systemic shocks.  This is a positive development.  At the same time, it is also important to mitigate the sources of systemic shocks. Dodd-Frank apparently did little to curb misconduct\u2014a possible source of systemic risk.  If the people managing capital cushions and liquidity buffers view these tools as sufficient mitigants for the costs of misconduct, or if powerful incentives encourage workarounds of the new regulations, then the connection between post-crisis reforms and greater financial stability becomes threatened.\n\nIn the last year, we have seen emerging approaches to supervision that aim to address culture, conduct and governance.  These methods are being developed in a number of jurisdictions.8  I am pleased to welcome representatives of 15 foreign supervisors and other official sector agencies who are joining the many representatives of U.S. supervisory and regulatory agencies here today.  The topic of culture and conduct has truly become a global dialogue.  We have a lot to learn from each other. \n\nOne question on the minds of many in the official sector is, \u201cwhat is the most effective way to promote reform?\u201d  Sharing ideas on leading practices, challenges and the opportunities for industry collaboration is a start\u2014but it is not the end.  Financial firms need to act on this information, and the official sector should hold institutions accountable for demonstrating sustained, observable progress.\n\nOverview of Agenda\n\nLet me now give a brief overview of today\u2019s agenda.  The first panel will present the Group of Thirty\u2019s recent report on banking conduct and culture, which calls for fundamental and sustained change.  As you all know, the Group of Thirty is a forum consisting of senior public officials and private sector bankers.  Its purpose is to facilitate non-partisan discussion of issues that threaten global economic stability and economic progress.  It speaks volumes that the Group has focused its work in recent years on effective governance, the role of supervision, and on conduct and culture. \n\nEach of the four remaining panels will address one aspect of the multidimensional nature of cultural change. \n\nOur keynote speaker today is Christine Lagarde, the managing director of the International Monetary Fund.  Christine Lagarde has been outspoken in her view that \u201cfinancial leaders [must] take values as seriously as valuation, culture as seriously as capital.\u201d9  This makes abundant sense to me\u2014culture and capital each promote financial stability.  Thank you for joining us.  I am also grateful to Stanley Fischer, the vice chairman of the Board of Governors, who will speak with Christine Lagarde following her remarks.\n\nPlease join me in welcoming Christine Lagarde. \n\n1 What I have to say today represents my own views and not necessarily those of the Federal Open Market Committee or the Federal Reserve System. Stephanie Chaly, James Hennessy, Thomas Noone and Joseph Tracy assisted in preparing these remarks.\n\n2 See Malcolm Gladwell, The Tipping Point (2002), 133-168 (collecting sources).  For additional information on the famous Stanford Prison Experiment, see www.prisonexp.org.\n\n3 Adam Smith, The Theory of Moral Sentiments (11th ed. 1812), 276.\n\n4 E. Gerald Corrigan, Are Banks Special?, Federal Reserve Bank of Minneapolis Annual Report, January 1983. \nCf. Joseph Story, Commentaries on the Law of Bailments \u00a7 464 (1832). (\u201cThe soundness of the public policy of subjecting particular classes of persons to extraordinary responsibility, in cases where an extraordinary confidence is necessarily reposed in them, and there is an extraordinary temptation to fraud, or danger of plunder, can hardly admit of question; and has been recognized in the jurisprudence of many countries.\u201d).\n\n5 William C. Dudley, Ending Too Big to Fail, Remarks at the Global Economic Policy Forum, November 7, 2013.\n\n6 Federal Advisory Council and Board of Governors, Record of Meeting, May 8, 2015.\n\n7 William C. Dudley, Enhancing Financial Stability by Improving Culture in the Financial Services Industry, Remarks at the Workshop on Reforming Culture and Behavior in the Financial Services Industry, October 20, 2014.\n\n8 See, e.g., Mirea Raaijmakers, ed., Supervision of Behavior and Culture: Foundations, Practice & Future Developments, De Nederlandsche Bank (2015).\n\n9 Christine Lagarde, Economic Inclusion and Financial Integrity, Address to the Conference on Inclusive Capitalism, May 27, 2014."
  },
  {
    "title": "Beyond the Macroeconomy",
    "date": "Nov 4, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud151104",
    "content": "Good afternoon and welcome once again to the Federal Reserve Bank of New York\u2019s Economic Press Briefing.  I am pleased to have this opportunity to speak with you.  Today I want to focus on how economic outcomes often differ substantially across different segments of the population.  As always, what I have to say reflects my own views and not necessarily those of the Federal Open Market Committee (FOMC) or the Federal Reserve System.1\n\nThe Federal Reserve has a dual mandate of maximum employment and price stability.  While these mandates are expressed at an aggregate national level, it is important for policymakers to understand how they impact different groups of individuals across the country.  Consequently, in addition to monitoring macroeconomic conditions closely on a day-to-day basis, economists at the New York Fed have been doing a substantial amount of work to understand how economic experiences differ across individuals and regions.  As highlighted by the Nobel Prize Committee\u2019s recent recognition of Professor Angus Deaton\u2019s work, analyzing individual outcomes is vital to fully understanding the workings of the macroeconomy.  With that in mind, I want to talk about two important areas that impact household well-being: labor income and housing opportunities.\n\nLet me start with labor income, which for most households is the dominant source of household income.  As one would expect, differences in labor income across individuals of a given age tend to increase as people get older.  Some of this is due to education and occupation choices\u2014and how they impact income growth\u2015and some is due to various events that individuals face in their working lives.  Unemployment risk is an example of an adverse development that can substantially affect people\u2019s careers and labor income during their lifetime.  Over the period from 1976 to 2015, the overall unemployment rate averaged around 6.5 percent, but unemployment varied substantially across regions and across worker backgrounds.  Unemployment was especially high for workers with lower earnings, a group that tends to have little savings to draw upon.  Looking across demographic groups, younger workers, less-educated workers and those in manual occupations, as well as workers who identify as Black or Hispanic, experienced significantly higher average unemployment rates when compared to older and college-educated workers.  These stark differences across demographic groups in terms of levels of unemployment are also evident in terms of how unemployment changed over business cycles, including the Great Recession.  While the overall unemployment rate increased from 5 percent in December 2007 to 10 percent in October 2009, it increased substantially more for workers with lower earnings.  In other words, looking at the national unemployment rate tells only part of the story of the labor market experiences for different groups of individuals.  Understanding this diversity is critical to better understanding the health of the labor market and the overall economy, and is important for informing policy. \n\nNow let\u2019s turn to housing.  Macroeconomists focus on aggregate residential construction as a measure of how the housing sector is contributing to overall economic growth.  It is important to note, however, that housing market experiences vary substantially across individuals in ways not reflected in the aggregate construction data.  For example, the type of housing units typically occupied by low-income households saw higher-than-average rent inflation from 2009 to 2011.  Much of this difference appears to be due to contrasting ways that additions to the housing stock enter into different segments of the housing market.  For households in the highest income quintile, new construction more than accounts for the net increase in housing units, which in turn tends to hold down rent increases for these households.  However, as one moves down the income distribution, new construction represents a smaller share of the net increase in housing units.  For households in the lowest income quintile, additions to rental supply come more from units that with age have depreciated and are no longer rented by higher income households.  These supply additions tend to have higher rents than existing units rented by low-income households, thus putting upward pressure on rental costs.\n\nThe diversity of experiences is also evident with respect to access to mortgage credit, both for households attempting to transition to homeownership and for homeowners who want to trade up.  We have also been monitoring mortgage originations at the zip code level using the New York Fed\u2019s Consumer Credit Panel.  When we rank zip codes by their 2012 average adjusted gross income, we see mortgage origination volume in the lowest quintile locations was 38 percent of the volume for the highest quintile locations in 2007.  By early 2015, this ratio had fallen to only 14 percent.\n\nAs highlighted by these examples, and as you\u2019ll hear during today\u2019s presentation, data at the aggregate level and at a more micro-level illustrate different sides of the same picture.  As such, both must be considered as we work toward fully understanding the economy.\n\nI will now ask Aysegul Sahin to provide a detailed account of how various economic outcomes vary across individuals, households and regions.\n\n1 Aysegul Sahin and Joseph Tracy assisted in preparing these remarks."
  },
  {
    "title": "Welcoming Remarks at The Evolving Structure of the U.S. Treasury Market Conference",
    "date": "Oct 20, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud151020",
    "content": "In recent years, the structure of the Treasury market has changed significantly. Trading has become increasingly electronic, and, in many cases, highly automated. Less traditional firms, often with a primary focus on automated, low-latency trading strategies, have entered the arena and helped to transform the landscape. In addition to adapting to these changes, traditional broker-dealers are complying with a more rigorous regulatory framework and are also expanding their use of automated trading technologies.\n\nThese developments raise a number of important questions. They include: Who are these new entrants and what are their motivations? Has the changing composition of firms affected the nature of market making and liquidity provision? How have traditional liquidity providers responded to the expanded use of new technology? Has the changing structure introduced operational risks in the clearing and settlement infrastructure? How has the evolution of the repo market affected the secondary market for Treasury securities? Are the regulatory requirements imposed upon the Treasury market sufficient in today\u2019s world? And finally, are there any changes\u2015regulatory or otherwise\u2015that could improve the functioning, efficiency and/or integrity of the Treasury market?\n\nAs I noted in my recent remarks on market liquidity, many open questions remain on the subject of Treasury market liquidity.3 At the same time, the agenda for this conference makes it clear that there are many other important questions beyond market liquidity worthy of consideration and debate. The breadth and expertise of the attendees at this conference make this forum an excellent opportunity to advance our collective thinking on this range of important subjects.\n\nWhile the recent joint staff report on the events of October 15 certainly revealed that much has changed, it is also important to recognize that both private and official sector efforts to ensure a healthy and efficient Treasury market have been ongoing for some time.4 One obvious example is the Treasury Market Practices Group, or the TMPG. Set up in February 2007, the TMPG is a group of market professionals committed to supporting the integrity and efficiency of the Treasury market.5 A core purpose of the TMPG is to develop and update a set of best practices related to trading, settlement and risk management, thereby establishing a set of behavioral norms to which market participants are expected to adhere. Most recently, the TMPG updated its best practice guidance to address automated trading, and published a companion white paper on the subject. And no discussion of the TMPG can go without mention of the \u201cfails charge.\u201d Instituted in May 2009, this practice provides a standard procedure for market participants to assess\u2015or pay\u2015a fee for settlement failures, and this has proven to be a highly effective remedy for curbing the volume of fails in the Treasury market.6 I want to thank the entire TMPG for their leadership in supporting the efficiency and integrity of the Treasury market. I\u2019d like to single out Tom Wipf with a personal thank you. Tom has served with distinction as the TMPG\u2019s chair since its inception, providing credible, balanced and independent leadership to the Group.\n\nI would be remiss if I did not also mention the ongoing work of the Inter-Agency Working Group on Treasury Market Surveillance, or the IAWG. After the Salomon auction bidding scandal in January 1992, the official sector established the IAWG. Since that time, it has been a useful forum for the official sector to coordinate and communicate on the various issues that have arisen in the Treasury market. Indeed, over the years there have been numerous examples of questionable behavior that has come to the attention of the IAWG, and these have been channeled onwards to the appropriate authorities. The IAWG continues to meet biweekly, as it has since its inception.\n\nAs you all know, the Joint Staff Report concluded that further work is necessary in light of the evolving structure of the Treasury market, and it also highlighted a series of additional steps that the official sector will take to evaluate its approach to this market. I remain very supportive of these efforts. In fact, this conference is among the first of those next steps, and presents a perfect opportunity to have a rich debate on the market's evolving structure and the actions that may be appropriate in response.\n\nThank you once again for coming here today. I look forward to our engagement and discussion.\n\n1 Frank Keane, Michael McMorrow, Joseph Tracy and Nate Wuerffel assisted in preparing these remarks.\n\n2 What I have to say today represents my own views and not necessarily those of the Federal Open Market Committee or the Federal Reserve System.\n\n3 See Regulation and Liquidity Provision, remarks at the SIFMA Liquidity Forum, September 30, 2015.\n\n4 Joint Staff Report: The U.S. Treasury Market On October 15, 2014\n\n5 The TMPG has since expanded its mandate to include the agency debt and agency mortgage-backed securities (MBS) markets.\n\n6 A more recent and equally successful practice has also been instituted for the MBS market."
  },
  {
    "title": "Panel Remarks at the Brookings Institution",
    "date": "Oct 15, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud151015",
    "content": "To get right to the punch line, I favor a more flexible approach that incorporates a broader set of factors into the monetary policy decision-making process. The world is complex and ever-changing. There are many factors that can affect the economic outlook and the attainment of the Federal Reserve\u2019s mandated objectives and, thereby, the appropriate stance of monetary policy.\n\nAt the same time, I do not favor total discretion in which the monetary policy strategy is determined in an ad hoc fashion as we go along. For monetary policy to be most effective, market participants, households and businesses need to be able to anticipate how the Federal Reserve is likely to respond to evolving conditions. That is because the transmission of monetary policy to the real economy depends not only on what policymakers decide to do today, but also on what the public anticipates that the FOMC is likely to do in the future as the economic outlook changes and evolves.\n\nOur experience at the zero lower bound in recent years underscores how important expectations are in influencing the effectiveness of monetary policy. Policymakers thus need to act in a systematic and consistent manner so that expectations are formed accurately and economic behavior can respond consistently with those expectations. In my view, this consideration rules out a totally discretionary monetary policy.\n\nBefore I critique the use of prescriptive rules in monetary policy-making, I\u2019d like to make it clear at the start that the Taylor Rule (by which I mean the formulation based on John\u2019s 1993 and 1999 papers) has a number of positive attributes that make it a useful reference for policymakers. First, it has two parameters\u2014the long-term inflation objective and the level of potential output\u2014that map directly to the Federal Reserve\u2019s dual mandate objectives. Second, the Rule has the desirable feature that when economic shocks push the economy away from the central bank\u2019s objectives, the Taylor Rule prescribes a policy response that can help push the economy back toward the central bank\u2019s goals. Third, a number of studies have shown that Taylor Rules are robust in the sense that they generally perform quite well across a range of different assumptions about how the economy is structured and operates.\n\nDespite these attractive features, I don\u2019t believe that any prescriptive rule, including the Taylor Rule, can take the place of a monetary policy framework that incorporates the FOMC\u2019s collective assessment of the large number of factors that impact the economic outlook.\n\nAs I see it, the Taylor Rule has several significant shortcomings that can be detrimental to the attainment of the Federal Reserve\u2019s mandated objectives. These shortcomings are not just theoretical; they have been very relevant to monetary policy in recent years. First, the Taylor Rule is not forward-looking. Its policy prescription is based on the current size of the output gap and the deviation of current inflation from the Fed\u2019s objective, not on how these variables are likely to evolve in the future. So, in a rapidly changing environment, the Taylor Rule and other similar prescriptive rules will wind up being \u201cbehind the curve.\u201d For example, in the fall of 2008, Taylor Rule prescriptions were well above the level of rates that was appropriate given the sharp and persistent deterioration in the economic outlook and the sharp tightening in financial conditions that occurred during that period.\n\nOf course, many economists at that time recognized that such prescriptions would have been inappropriate and suggested various ad hoc modifications to the prescriptions\u2014in fact, John himself suggested that modifications to his rule were appropriate at that time.2\n\nSecond, the Taylor Rule, as typically used, assumes that a 2 percent real short-term interest rate is consistent with a neutral monetary policy. However, a large literature concludes that the equilibrium real short-term rate is very unlikely to be constant, with its value affected by many factors, including the pace of technological change, fiscal policy and the evolution of financial conditions.3\n\nMore recently, the slow growth rate of the economy and the low rate of inflation are evidence that the equilibrium real short-term rate today is well below the 2 percent rate assumed in the Taylor Rule. If 2 percent really was consistent with a neutral monetary policy, then the very low real rates of recent years\u2014buttressed by our large-scale asset purchases\u2014should have been extraordinarily accommodative. As a result, we should have grown much faster than the 2\u00bd percent pace evident over the past couple of years and seen an inflation rate much higher than what we experienced. This conclusion is supported by a number of more formal models. For example, the Laubach-Williams model currently estimates that the equilibrium real short-term rate is around zero percent.4\n\nThird, the Taylor Rule \u2015and more broadly, any prescriptive rule for the systematic quantitative adjustment of the policy rate to changes in intermediate policy inputs such as real GDP or inflation\u2015is incomplete because it does not fully account for factors that are crucial to how monetary policy impulses are transmitted to the real economy. Monetary policy affects economic activity through its impact on financial conditions\u2014including the level of equity prices, bond yields, the foreign exchange value of the dollar and credit conditions. If the relationship between the federal funds rate and other indicators of financial conditions were stable, then one could just focus on the level of short-term rates.5\n\nIn fact, at times, when short-term rates have been pinned at the zero lower bound, the Federal Reserve has taken actions that eased financial conditions without changing short-term interest rates. Such actions have included forward guidance that the FOMC was likely to keep short-term rates low for a long time and large-scale asset purchases that led to lower bond term premia.\n\nNow, as I said at the start, just because I don\u2019t want to follow a rule mechanically does not mean that I favor the polar opposite\u2014that is, a fully discretionary monetary policy in which market participants, households and businesses cannot anticipate how monetary policy is likely to evolve as economic and financial market conditions and the economic outlook change. If households and businesses do not have a good notion of how the Federal Reserve will respond to changing economic and financial market conditions, then this would loosen the linkage between short-term rates and financial conditions. This would also likely lead to greater uncertainty about the outlook and higher risk premia, and it would make it more difficult for policymakers to attain their objectives.\n\nInstead, what I favor is a careful elucidation of those factors that influence the economic outlook and how monetary policy is likely to respond to changes in the outlook. This includes fiscal policy, productivity growth, the international outlook and financial conditions, as well as how much employment and inflation deviate from the Fed\u2019s objectives. By conducting policy in a transparent way and communicating what is important in determining the central bank\u2019s reaction function, I think policymakers can strike the best balance between a monetary policy that fully incorporates the complexity of the world as it is, while, at the same time, retaining considerable clarity about how the FOMC is likely to respond to changing circumstances. A formal policy rule such as the Taylor Rule misses this balance by going too far in one direction.\n\nWhat is important for attaining the Federal Reserve\u2019s mandated objectives is not that monetary policy is described in terms of a formal prescriptive rule, but rather that the FOMC\u2019s intentions and strategy are well understood by the public. This argues for clear communication through the FOMC meeting statements and minutes, the FOMC\u2019s statement concerning its longer-term goals and monetary policy strategy, the Chair\u2019s FOMC press conferences and testimonies before Congress, and speeches by the Chair and other FOMC participants. But it also is important that the strategy be the \u201cright\u201d reaction function. This means a policy approach that responds appropriately to important factors beyond the two parameters of the Taylor Rule\u2014the output gap estimate and the rate of inflation.\n\nThank you for your kind attention.\n\n1 Jonathan McCarthy, Paolo Pesenti, Argia Sbordone and Joseph Tracy assisted in preparing these remarks.\n\n2 For example, John suggested in February 2008 to lower the standard Taylor Rule prescription by 50 basis points to take into account the increase in the LIBOR-OIS spread at that time. See Monetary Policy and the State of the Economy, Testimony before the Committee on Financial Services, U.S. House of Representatives, February 26, 2008.\n\n3 See James D. Hamilton, Ethan S. Harris, Jan Hatzius, and Kenneth D. West (2015), The Equilibrium Real Funds Rate: Past, Present and Future, working paper for U.S. Monetary Policy Forum, August.\n\n4 See Thomas Laubach and John C. Williams \u201cMeasuring the Natural Rate of Interest\u201d, Review of Economics and Statistics, November 2003, Vol 85, No. 4, pp 1063-1070. Updated estimates available from the Federal Reserve Bank of San Francisco.\n\n5 An analogy can be made to the applicability of a Friedman k-percent monetary aggregate rule. Just as a k-percent rule requires a stable relationship between a monetary aggregate and nominal GDP (i.e., stable money velocity), a Taylor Rule needs a stable relationship between the policy rate and financial conditions."
  },
  {
    "title": "Is the Active Use of Macroprudential Tools Institutionally Realistic?",
    "date": "Oct 3, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud151003",
    "content": "It is a pleasure to be here today and to have the opportunity to talk about the potential use of macroprudential tools in the United States.  \n\nBefore I respond to Adam Posen, I\u2019d like to make a few general comments on macroprudential tools.  I am interested in such tools both as a U.S. policymaker and in my role as chair of the Committee on the Global Financial System of the Bank for International Settlements (BIS), a body that has done considerable work in this area in recent years.  What I have to say today represents my own views and not necessarily those of the Federal Reserve System.1\n\nThe use of macroprudential tools has gotten considerable attention for several reasons.  Some countries have implemented macroprudential measures with respect to the housing market that may have limited the extent of home price appreciation and made their financial systems more resilient when the boom unwound.  Other countries have implemented countercyclical capital requirements that have made their banking systems more resilient.  Thus, the hope is that U.S. policymakers can learn from these international experiences and incorporate effective macroprudential tools into our toolkit that could be used to limit financial stability risks. \n\nSupport for using macroprudential tools in the United States has also been bolstered by our experience during the financial crisis.  The U.S. housing boom and subsequent bust might have been less severe had a set of macroprudential measures been in place at the time to limit the degree of leverage and speculative activity in the housing sector.  The housing boom was fueled by optimistic expectations for house price appreciation, combined with lax underwriting standards embodied in such practices as no-doc mortgages and widespread speculative activity by investors.  I remember, for example, the website, Condoflip.com, which says it all in terms of the degree of speculative fervor that was evident at the time.  \n\nIf underwriting practices had been held to high standards (e.g., strict mortgage service-to-income ratio limits had been honored) and speculative activity had been constrained (e.g., by lower loan-to-value ceilings for investors with multiple mortgage liens outstanding), this might have limited the size of the boom and subsequent bust.  \n\nMy own view is that while the use of macroprudential tools holds promise, we are a long way from being able to successfully use such tools in the United States.  There are two major sets of difficulties.  First, unlike monetary policy and microprudential regulation, there is not a well-defined framework for identifying emerging imbalances and applying macroprudential tools in response.  A recent tabletop exercise conducted by a number of Federal Reserve Bank presidents, which I will discuss a bit later, indicates some of the difficulties here. \n\nA workshop held by the Committee on the Global Financial System earlier this year in Hong Kong also noted this difficulty.  Appropriate calibration of macroprudential tools is difficult because of the lack of data and information about how the transmission process works\u2015that is, what impact the tool will have on the targeted sector.  Even assessing the impact ex post is challenging because it is difficult to predict how the macroeconomy and financial system would have evolved if the macroprudential tool had not been in place.  \n\nSecond, in the U.S., even if such a framework existed, there would still be a problem in terms of timely implementation.  The U.S. regulatory structure is fragmented, so that in most cases, no single regulator is able to implement macroprudential tools in a comprehensive manner.  As a result, imposing macroprudential tools in the United States would almost certainly leave significant gaps in coverage.  Such coverage gaps would likely lead to distortions within the financial sector, as the tool would have differential impacts across financial intermediaries inside versus outside a particular regulatory boundary.  Also, activity would migrate toward those areas outside the scope of the macroprudential tools that had been implemented. \n\nIt is important to note the regulatory mandates of the numerous federal and state regulatory authorities differ considerably.  Some simply may not view financial stability as an important part of their mandate.  As a result, I suspect it would be difficult to get all the relevant regulators on board in a timely way to implement macroprudential tools successfully.  \n\nIn principle, the Financial Stability Oversight Council (FSOC) might be well placed to coordinate a response across different regulatory jurisdictions.  But, I believe this is likely to prove difficult to do in practice.  Each of the regulatory agencies guards its own authority and prerogatives, and may not always be responsive to pressure from other regulators or the U.S. Treasury.  \n\nThere is also the problem of responding to an emerging financial stability risk in a timely manner.  First, the emerging problem needs to be identified.  Then alternative policy responses need to be analyzed and debated.  And, there is an understandable bias to start small and to escalate only as needed given the lack of understanding about how big an impact a particular tool may have on the economy.  So, even if the FSOC could be effective in developing a consensus among the regulators, I wonder whether it could do this in a timely way.  The housing boom in the U.S. that culminated in the financial crisis began in 2002 and 2003.  By the time that it was broadly identified as an issue in 2005 and 2006, it might have been too late to do much to temper its effects, even with a sound macroprudential response by the regulatory community.  \n\nIn the remainder of my time, I will discuss two topics in more detail.  First, I will discuss briefly what we learned at tabletop exercise with a number of Federal Reserve Bank presidents concerning the potential use of macroprudential tools in response to sectoral imbalances.  I think the tabletop exercise underscores the difficulty of using macroprudential tools in practice in the United States.  Second, I will discuss the issue that Adam Posen has raised\u2014whether we should focus on the use of rules that are hardwired into the financial system ex ante or instead favor using macroprudential tools in a more discretionary, ex post basis, once particular problems have been identified.  \n\nIn the tabletop exercise, the five Federal Reserve Bank presidents who are members of the Subcommittee on Financial Stability of the Conference of Presidents discussed the best way to respond to a scenario in which the commercial real estate market was overheating.2  The scenario was much more detailed than that, but the commercial real estate sector was the major problem with respect to financial stability.  The stated goal of the exercise was to reduce the risk posed by the commercial real estate boom to financial stability and, by extension, to the Federal Reserve\u2019s ability to achieve its macroeconomic objectives of maximum sustainable employment and price stability. \n\nPrudential tools under consideration included:\n\nMonetary policy was also considered as a tool\u2014either as a complement or as a substitute.\n\nIt was noteworthy that in the discussion there was no agreement as to what instruments should be emphasized and the ordering in which they should be used relative to monetary policy.  Among the available macroprudential tools, stress testing, raising margins on repo funding, and supervisory guidance garnered greater support compared to capital, liquidity, or credit-based tools. \n\nIn general, the exercise identified several issues with respect to the use of macroprudential tools.  One issue was the perceived difficulty of coordinating among different regulators.  Another was the fact that many of the tools have implementation lags.  The challenge of timely implementation steered some members back to using monetary policy, or toward those macroprudential tools\u2014such as stress tests\u2014that might be able to be implemented more quickly.  The exercise underscored that much more development work in the area of macroprudential regulation is needed. \n\nLet me now turn to the issue of ex ante, hardwired macroprudential standards that Adam has discussed.  In general, I see some advantages with having rules that are hardwired in place so that adjustment of the parameters of the tool\u2014say, limits on the loan-to-value ratio\u2014happen automatically in response to sectoral developments. \n\nAutomatic rules that are always in place have several advantages over discretionary measures that are implemented, ex post, only after some potential source of financial stability risk has been identified.  First, they are transparent and will work more quickly.  Second, they avoid some of the problems associated with announcing that a new measure is going to be put in place.  When implementing a new measure there will always be some reluctance to overcome in terms of deciding whether it is necessary.  Also, there may be political opposition to imposing a new measure.  For example, during the housing boom, limits on subprime lending would undoubtedly have provoked the objection that the regulators\u2019 actions would limit home ownership for low-and moderate-income families.  \n\nImposing automatic, countercyclical standards also has this difficulty to some degree.  But I think it is much less severe because at the time such standards are put in place, they generally will not be binding and it will be unclear whether they will necessarily become either more stringent or more binding in the future.  In other words, the rule\u2019s potential impact will be highly speculative and uncertain at the time of implementation.  This may lessen the political opposition to putting such a rule in place. \n\nIn the same vein, automatic rules that are imposed ex ante might also be less risky in terms of potential unintended consequences.  When new rules are implemented it is always hard to gauge what the impact will be because imposition of the rule not only changes the economics of borrowing and investing in a particular sector, but also changes expectations about what might happen in the future.  When the rule is viewed as likely to be binding in the future\u2014this seems more likely in the case of the ex post measures\u2014it will be very hard to judge how economic agents will respond to a new measure.  \n\nIn this regard, I think back to the Carter administration and the imposition of credit controls to restrain inflation in 1980.  Even though the credit controls were not expected to bind right away, the economy began to contract almost immediately as households and businesses rapidly adjusted their behavior to preserve some credit capacity.  The response was a much more powerful downturn in economic activity than had been anticipated, which forced the Carter administration to scrap the credit controls because they worked too well in restraining economic activity.  \n\nSo I see some potential advantages of hardwired rules.  But, I think this advantage needs to be set against the practical difficulty of figuring out what rules would need to be in place now to deal with all the potential financial stability excesses that could occur in the future.  That seems a very difficult task to work out in my opinion.  It implies that such rules would need to be designed to treat broad issues, such as increases in financial system leverage or aggregate credit growth, rather than more limited sectoral issues.  This may work well in some circumstances in which the financial excess is occurring broadly, but might not be very effective when the problem, while extreme, may be more narrowly based.\n\nHistorical experience suggests that past bubbles in the United States that have threatened financial stability have taken many different forms and affected many different sectors of the economy.  Often, the bubbles have occurred in response to some important innovation in the economy or the development of instruments that facilitated real estate lending to lower-quality borrowers.  Examples of these include the development of the internet in the technology stock boom of the late 1990s, and subprime lending and mortgage securitization innovations prior to the financial crisis.  These innovations, in turn, sparked changes in belief systems that turned out to be false\u2014such as, the rise in home prices reinforced the view that housing is an excellent investment and that national home prices can never decline.  When the assumption that widely supports a boom is revealed as false, the consequence is often a sharp reversal in behavior and prices as the boom deflates quickly.  I think it is very hard to anticipate these episodes and put rules in place that would limit such excesses. \n\nMy concern is that we could over-engineer the financial system, building in complexity in response to potential risks that might, or might not, manifest themselves in the future.  The complexity might not gain us much in terms of greater financial stability, either because the problem that ultimately manifested itself was different than we planned for, or because people found a way around the constraint that we had imposed on the system.  \n\nThere are also the challenges of appropriate calibration and timing.  How much restraint should the rule exert as home prices rise or aggregate credit growth picks up?  Without historical experience and with an underdeveloped macroprudential framework, getting the calibration right is a difficult issue at this point.  Also, how quickly should the tool be unwound once it has done its work?  The tool needs to work in a countercyclical way, but turning points are difficult to anticipate and which makes it challenging to get the leads and lags right.   \n\nWe have a very complex financial system in the United States.  I think we need to do much more work in developing a coherent macroprudential framework before we start contemplating putting a number of countercyclical measures in place.  Such a framework needs to take into consideration how it interacts with other policies, such as microprudential policies\u2014to ensure the safety and soundness of individual institutions and monetary policy\u2014designed to help ensure a stable macroeconomy.  When are these policies substitutes?  When are they complements?  How will they interact?  How will the governance work in coordinating across these three realms? \n\nIn the meantime, while we work to sort all this out, we should take considerable solace from the fact that we have made the financial system more resilient to shocks.  We may not be able to anticipate the next area of excess.  But with higher capital and liquidity requirements and the use of stress tests to assess emerging vulnerabilities, I think we are much better placed than we have been in the past.\n\nThank you for your kind attention.\n\n1Tobias Adrian, Meg McConnell and Joseph Tracy assisted in preparing these remarks.\n\n2See Macroprudential Policy: Case Study from a Tabletop Exercise, Tobias Adrian, Patrick de Foutnouvelle, Emily Yang, and Andrei Zlate, Federal Reserve Bank of New York Staff Report No. 742, September 2015."
  },
  {
    "title": "Regulation and Liquidity Provision",
    "date": "Sep 30, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150930",
    "content": "The financial crisis and the ensuing recession exacted a high cost on the country.  Real gross domestic product (GDP) declined by over a half of a trillion dollars.  Total nonfarm payroll employment declined by 8.7 million jobs, and 5.8 million households lost their homes to foreclosure.  Extraordinary fiscal and monetary policy efforts were required to prevent a collapse of the financial system and the onset of a world-wide economic depression.  In the aftermath, new regulations, such as Basel III and the Dodd-Frank Act, were implemented to strengthen the financial system and to limit the risk of a future financial crisis.\n\nSome opponents of tougher bank regulation claim that the increased regulatory requirements, such as the higher capital requirements and new liquidity standards, that have been imposed on large financial institutions in the aftermath of the financial crisis have reduced these firms' market-making capacity.  As a result, so the argument goes, this is leading to less liquidity for trading securities, and to more illiquidity events in which the prices of financial assets move sharply and become temporarily unmoored from their fundamental valuations.  The contention is that higher liquidity costs and more frequent illiquidity events will, over time, drive up the borrowing costs of households, businesses and the U.S. government; and that this is a substantial, largely unintended cost imposed by tougher regulation.  Thus, the argument concludes, the regulatory burden should be rolled back. \n\nThis is a noteworthy assertion and would have significant implications for regulatory policy if it were correct.  However, as I will lay out in my remarks, I don't think the hypothesis is well-supported by the available evidence.  First, the evidence to date that liquidity has diminished markedly is, at best, mixed.  Second, even if one were to interpret the evidence as indicating that liquidity has been reduced, it is not clear whether regulation is the primary driver, as other changes have played important roles as well.  Moreover, even if higher capital and new liquidity requirements were found to result in greater transaction costs, these costs would need to be assessed against the benefits of having a more robust and resilient financial system and a reduced risk of financial crises in the future.\n\nThat said, more work should be undertaken to fully assess this issue.  There is much that is still unknown.  The available market liquidity data primarily focus on the inter-dealer markets and thus do not shed light on possible liquidity changes between dealers and customers.  In addition, the financial system is adjusting in complex ways in reaction to regulatory, technological and other changes.  We need to better understand the degree to which any changes in the nature of liquidity reflect the evolving structure of financial markets, changes in regulatory policy or other factors.  With respect to regulatory policy, an important objective should be to achieve the best balance between the benefits of increased safety and soundness versus any costs imposed by these regulatory changes on market function and liquidity.\n\nIn my remarks today, I will focus on market liquidity rather than funding liquidity, although I recognize that the two are related in important ways.  I will examine market liquidity in two important fixed-income markets\u2014the U.S. Treasury market and the U.S. corporate bond market.  The Treasury and corporate bond markets provide a useful contrast in evaluating liquidity conditions as they differ with respect to the homogeneity of their securities, how their securities are traded and how regulatory changes may have affected the incentives of dealers to make markets in these securities.\n\nThe Treasury market is much more homogeneous and the average size of each issue is much larger.  Trading volume and average trade sizes are much larger, and much of the trading activity for interdealer on-the-run securities is conducted electronically through the use of central limit order books (CLOB).  In contrast, the corporate bond market is much more heterogeneous; there are many more distinct bonds available; and bond sizes are much smaller.  As a result, corporate bond trading is fragmented across a large number of distinct outstanding bonds. Consequently, trading tends to occur infrequently and largely on a bilateral basis. \n\nThrough the prism of these two asset classes, I hope to provide some preliminary answers to five key questions.  First, what do we mean by liquidity and how can we measure it?  Second, what does the available evidence show in terms of how liquidity has changed in recent years in the U.S. Treasury and corporate bond markets?  Third, what factors could influence liquidity provision?  Regulation might be one factor, but there also could be others.  Fourth, what are the costs associated with shifts in liquidity and how do these costs compare to the benefits of a more resilient and robust financial system?  Fifth, what future work is needed to better assess whether increased regulation has damaged liquidity provision and whether the resulting costs exceed the benefits of higher capital and liquidity standards in terms of financial stability?  As always, what I have to say today represents my own views and not necessarily those of the Federal Open Market Committee (FOMC) or the Federal Reserve System.1 \n\nWhat do we mean by liquidity and how can we measure it?\nI would define liquidity as the cost\u2014both in expense and in time\u2014of buying or selling an asset for cash.  This would incorporate any direct transaction expense, such as fees or brokerage costs, the price the transaction was executed at relative to the midpoint of bid-ask spreads, how much\u2014if at all\u2014the size of the transaction moved market prices, and the immediacy or speediness with which the transaction could be completed.  How quickly prices revert back to earlier prices after a large trade also is relevant in assessing liquidity costs.  The costs of liquidity would go up if the costs of execution rose, the bid-ask spread widened, if prices moved more in response to a given sized transaction or if it took a longer period of time to complete the transaction and receive cash.\n\nIn assessing liquidity, we also need to distinguish between those liquidity conditions that generally prevail versus those that arise during periods of market stress when liquidity may become constrained.  Liquidity risk is the risk that liquidity might be impaired in the future when one wants to buy or sell an asset.  If liquidity risk is high, this means that there is a substantial risk that the price received could be at a greater concession to the prior trade than anticipated.\n\nLiquidity is dynamic, unobservable and multi-dimensional in nature, and, as such, can only be measured indirectly.  We can measure liquidity using a number of metrics, including bid-ask spreads, market depth and price impact.  Bid-ask spreads are a measure of the potential compensation for market makers for liquidity provision.  Market depth measures how thick the central limit order book is at any point in time.  If the CLOB is denser and thicker, then a large trade should result in a smaller price concession, everything else equal.  Price impact measures how the price of a security changes in response to trades of a given size.\n\nTo measure liquidity risk, we combine the various measures of liquidity discussed above into a single liquidity index.  Large jumps in illiquidity are identified as days in which the liquidity index deteriorates by an unusually large amount.  We benchmark this as moves of greater than two standard deviations.  Liquidity risk is calculated as the number of such jumps in illiquidity over a two-year rolling window.  Constructed in this manner, we are implicitly assuming that the risk of an illiquidity event in the future is correlated with the frequency of such illiquidity events in the recent past.\n\nWhat does the available evidence show in terms of how liquidity has changed in recent years in the U.S. Treasury and corporate bond markets?\nWith respect to the U.S. Treasury market, we do not find much evidence based on available measures consistent with a significant deterioration in liquidity.  For example, quoted bid-ask spreads, after widening sharply during the financial crisis, subsequently narrowed and have remained stable at pre-crisis levels since 2010. (Exhibit 1)  Other measures paint a more mixed picture.  While order book depth is appreciably lower now than in 2012 and 2013, it is much higher than during the financial crisis, and does not appear to be unusually low by historical standards. (Exhibit 2)  Similarly, the price impact of trades appears to have risen a bit since the October 15 flash rally indicating some deterioration of liquidity, but is still not high relative to its longer-run experience. (Exhibit 3)  Average trade sizes have followed a similar pattern to the order book depth and have recently declined somewhat. (Exhibit 4)\n\nAnother way to assess liquidity conditions is through the potential impact on Treasury yields.  If liquidity had deteriorated markedly, then we would expect to see larger deviations of actual yields compared to the yields predicted by an empirically fitted yield curve.  If liquidity were more costly, the deviations of actual yields from fitted yields would increase because the costs of arbitrage to eliminate those divergences would be higher.  During the financial crisis, for example, there was a sharp deterioration in liquidity, which was associated with a sharp rise in some measures of yield curve fitting errors to a peak of about 20 basis points. This compares to less than 2 basis points prior to the crisis.  In contrast, yield curve fitting errors have been low and stable recently and not outside historical norms. (Exhibit 5)  Of course, the Federal Reserve's large scale interventions in the Treasury market over this period may also have had an impact on this measure.  \n\nTurning to corporate bonds, given their heterogeneous nature, liquidity in the corporate bond market depends on the ability and willingness of dealers to hold these securities on their balance sheets while they find buyers.  Disaggregated data on dealer balance sheet holdings have only been published since April 2013.  While limited in terms of its history, these data indicate no clear reduction in investment grade security holdings over time, but do show a significant reduction in high-yield security holdings since the end of the financial crisis.  This might be indicative of deterioration in market liquidity in corporate bonds.\n\nTo investigate corporate bond market liquidity in more detail, let's examine three liquidity measures: the average trade size, \"effective\" bid-ask spreads and price impact.  The evidence on the average trade size for investment grade corporate bonds indicates a slight reduction from between $700,000 to $800,000 in the early 2000s to around $500,000 in the last few years. (Exhibit 6)  However, price measures of corporate bond liquidity do not substantiate the trend in this quantity measure.  The effective bid-ask spread has been trending down since the early 2000s, around the same time that TRACE reporting was introduced.  The spread spiked during the financial crisis, but is now lower than its pre-crisis levels. (Exhibit 7)  Similarly, price impact\u2014the effect on price from a $1 million trade\u2014has also been trending down since the early 2000s apart from the jump during the financial crisis. (Exhibit 8)\n\nAlthough liquidity in the Treasury and corporate bond markets does not appear to have changed much recently, liquidity risk may have risen.  For the Treasury market, our liquidity risk measure increased sharply with the financial crisis, and declined from 2009 to 2013.  However, over the last two years Treasury liquidity risk has moved higher and relative to the pre-crisis period is currently somewhat elevated.  For the corporate bond market, liquidity risk also increased sharply during the financial crisis, and then quickly fell as the crisis passed.  Corporate bond liquidity risk subsequently increased again in 2012 and early 2013, but is now back down close to its pre-crisis level. (Exhibit 9)\n\nIn sum, there is limited evidence pointing to a reduction in the average levels of liquidity.  However, there are reasons to think liquidity risk may have increased, and there are some data to support this conjecture.\n\nTwo cautionary notes are warranted in evaluating the available evidence.  First, the Treasury market evidence is based on the inter-dealer markets, and we do not have comparable evidence on liquidity conditions in the dealer-to-customer market.  Second, it is important to note that the FOMC's unconventional monetary policy may have affected recent measures of liquidity in ways that could make it more difficult to clearly discern any potential changes.  To the extent that this may be the case, then a clearer picture on liquidity conditions may only emerge as monetary policy is normalized.\n\nWhat factors could influence liquidity provision? \nClearly many factors could affect liquidity provision.  On the regulatory side, capital and liquidity requirements are probably the most important factors.  Dealers have been an important provider of liquidity.  Higher capital requirements reduce dealers' returns on equity for a given level of intermediation activity and margin.  At the same time, liquidity requirements increase the cost of holding less liquid assets.  To compensate for the higher capital and liquidity requirements, dealers can shrink their activity in lower margin businesses and raise the price for the liquidity services they provide.  Presumably, both adjustments occur in most markets with the ease of entry, the degree of economies of scale, business model and overall client profitability influencing whether the adjustment occurs more through a resizing of the activity or a change in unit trading margins.\n\nFor the U.S Treasury market, the most important change in regulatory requirements is probably the introduction of the supplementary leverage ratio (SLR) in the United States.  The SLR limits how leveraged a dealer balance sheet can be.  Because in the SLR all assets require regulatory capital, the SLR is much tougher on low risk assets compared to the risk-based capital measures it complements.  Of note, the long-standing U.S. tier 1 leverage ratio also requires the same amount of regulatory capital for all assets, but the SLR has been more binding given its higher calibration and more expansive coverage of exposures.  The SLR is currently the binding capital requirement for some dealers, and it has significantly increased the amount of capital that needs to be held against low-risk assets.  This has resulted in significant adjustments in the composition of dealer balance sheets.  For example, the imposition of the SLR has been cited as an important factor in the shrinkage of dealer repo financing activity.  In contrast, the risk-based capital standards and new liquidity standards are unlikely to be important for Treasuries and repo backed by Treasuries because Treasuries are treated as posing less risk to the banks that hold them and count as high-quality liquid assets.  \n\nFor the corporate bond market, the most relevant factors are probably the increase in the Basel risk-weighted capital ratio, the Comprehensive Capital Analysis and Review (CCAR) stress tests\u2014which subject the dealer trading book to additional global market shocks that include a sudden increase in general risk premiums and credit risk combined with significant market illiquidity\u2014and the Volcker Rule, which prohibits proprietary trading for a number of asset classes including corporate bonds, but not U.S. Treasuries.\n\nHowever, for both markets, other non-regulatory factors are also important.  Liquidity provision is affected by changes in market structure, how trades are executed and by competition from outside of the regulatory boundaries that have been established for systemically important financial institutions.  The market structure for many asset classes has evolved from a bilateral OTC structure toward a more open, centralized structure through the adoption of electronic trading platforms, post-trade infrastructures and higher degrees of transparency.  For example, in the U.S. Treasury market, firms specializing in high-frequency algorithmic trading have become much more important and now make up more than half the trading in the electronic, interdealer cash market.  This change in market structure has reduced the cost of trading in the interdealer market, especially for small trade sizes.  Electronic trading enables the use of automated trading strategies which tend to employ speed for executing small-size trades, and the liquidity on electronic trading platforms allows traders to get in and out of positions quickly.  The growth in high-frequency trading likely accounts for the reduction in trade size discussed earlier rather than this reduction being indicative of less liquidity.  The movement toward electronic trading has allowed a more diverse set of actors to participate in the market, thereby increasing competition and likely leading to improved market liquidity.  These changes, though, may have reduced the profitability of providing liquidity for dealers engaged in trading activity in the Treasury market.2 \n\nLiquidity risk in the Treasury market may also reflect the growth in high-frequency trading rather than the impact of regulation.  Temporary illiquidity events may reflect unanticipated, complex and dynamic interactions among high-frequency trading strategies that can play out faster than the timeframe in which human intervention can occur.  In addition, high-frequency trading activity, by undercutting the returns to providing liquidity services on a lower frequency and a higher trade size basis, may have both increased liquidity in the small\u2014hence narrowing bid/offer spreads in normal trading conditions\u2014but decreased it in the large\u2014when selling or buying pressure on one side of the market predominates.\n\nFor the corporate bond market, market structure has also changed in important ways.  For example, bond mutual funds and exchange traded funds now hold a much higher proportion of corporate bonds than before the financial crisis.  Presumably, this shift in the structure of the market has affected liquidity provision and liquidity risk in the corporate bond market through the redemption risk faced by these funds.  Also, shifts in market structure and regulation have undoubtedly affected other markets related to the corporate bond market.  For example, changes in capital requirements for single name credit default swaps have presumably\u2014and appropriately from a supervisory perspective\u2014increased hedging costs and affected dealer market-making appetites and capabilities.\n\nWhat are the costs associated with shifts in liquidity and how do these costs compare to the benefits of a more resilient and robust financial system?\nEven if one were to read the evidence as supporting the notion that liquidity has become somewhat more costly, this does not imply that we should simply unwind recent regulatory requirements.  First, as I discussed, there are non-regulatory factors that could be more important factors.  Second, even if a connection could be made to regulatory causes, the costs of any reduction in liquidity or increase in liquidity risk might be low relative to the benefits of the regulations.   \n\nAs I noted at the outset of my remarks, recent regulatory changes have been designed to produce a safer and sounder financial system.  Higher capital and liquidity requirements have made major financial institutions less prone to failure.  This can be seen in the sharp fall in credit default swap spreads for major dealers in recent years.  Moreover, other steps have made the financial system more robust to the failure of a systemically important firm.  For example, the shift to central clearing of over-the-counter derivatives through central counterparties (CCPs) has reduced bilateral risk exposures, and significant progress is being made on how to resolve the failure of a systemically important financial firm in a way that does not threaten the entire financial system.3 \n\nAs I see it, the prior regime did not sufficiently foster financial stability, a necessary condition for sustained economic growth.  Most noteworthy to me is the fact that the regulatory regime that was in place in 2008 and 2009 was associated with an episode of the most illiquid market conditions since at least the Great Depression.  A return to such a regime could lead to a higher cost for liquidity over the long-run.  \n\nI think we are in a much better place today.  We have a financial system that is much more resilient, and the available evidence suggests that this transformation has not resulted in any significant erosion in market liquidity.\n\nWhat future work is needed?\nThere is a tendency to compress a complex world into a sound bite\u2014such as, \"tougher regulation is increasing the cost of liquidity and driving up liquidity risk.\"  Policy needs to be based on evidence and the available evidence supporting this claim is mixed, at best.  Most importantly, I think it ignores the complex nature of the changes underway in financial markets.  The methods of intermediation are changing and will likely continue to evolve.  There are new players with different objectives and goals, and technology is evolving rapidly.  These factors strike me as just as important as the increase in regulatory requirements for the large dealers. \n\nThe recent work analyzing the October 15 Treasury market flash rally illuminates the complexity of today's market structure.  After a careful examination of the evidence, the authors of the October 15 flash rally report conclude that \"the events of October 15 underscore the importance of efforts by the official and private sectors to understand more fully the implications of the evolving Treasury market structure for liquidity, trading and risk management practices, data access, and monitoring and surveillance.\"  The report goes on to suggest \"further study of the evolution of the U.S. Treasury market and the implications for market structure and liquidity;\" \"continue monitoring of trading and risk management practices across the U.S. Treasury market;\" \"an assessment of the data available to the public and to official sectors on U.S. Treasury cash securities;\" and \"continued efforts to strengthen monitoring and surveillance and to promote interagency coordination related to trading across the U.S. Treasury market.\"4  I concur with all these recommendations.\n\nThere is much more work to do\u2014not just with respect to the U.S. Treasury market, of course, but also on the broader issue of how changes in regulation and market structure influence liquidity conditions across the different financial markets.  For example, electronic trading was introduced to the foreign exchange market well before recent regulatory changes.  Consequently, a study of the foreign exchange market may shed some additional light on the role of electronic trading on liquidity risk in an environment prior to recent regulatory changes.  Only through much more careful study and data analysis can we thoughtfully address the two most important questions\u2014not whether regulation should be rolled back in order to return to the liquidity conditions prior to the financial crisis, but instead:\n\nWe certainly don't want to undermine the progress we have made in making the financial system more robust and resilient.  But if there are adjustments to regulation that could improve liquidity provision without increasing financial stability risks, we should be open to considering such changes.  I suspect, however, making this determination will require considerably more data, research and reflection before we reach any definitive conclusions.\n\nThank you for your kind attention.  I would be happy to take a few questions.\n\nCharts\n\n1 Tobias Adrian, Dianne Dobbeck, James Egelhof, Michael Fleming, Joshua Frost, Lorie Logan, Michael McMorrow, Matthew Raskin, Ernst Schaumburg, Katherine Tilghman-Hill, Joseph Tracy and Nathaniel Wuerffel assisted in preparing these remarks.\n\n2 The Federal Reserve's large scale asset purchases presumably have also played a role by removing a large volume of Treasury securities from the marketplace. \n\n3 This includes requirements for total loss-absorbing capital (TLAC), Title I resolution plan requirements and the option of Title II single point of entry resolution\n\n4See Joint Staff Report: The U.S. Treasury Market on October 15, 2014, pp 6-7."
  },
  {
    "title": "The Regional Economic Outlook",
    "date": "Aug 26, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150826",
    "content": "Good morning and welcome to the Federal Reserve Bank of New York's Economic Press Briefing.  I am pleased to have this opportunity to speak with you today about economic conditions in our District.  As always, what I have to say reflects my own views and not those of the Federal Open Market Committee (FOMC) or the Federal Reserve System.\n\nTracking economic conditions in our region is an important part of our work here at the New York Fed.  We need to understand how the diverse economies in our District are performing\u2014from the metropolis of New York City and its surrounding areas, to rural communities in upstate New York and the tropical island of Puerto Rico.  I take all of this to the table when the FOMC discusses business and economic conditions and trends.  In addition, we provide our regional analysis to the public so that everyone can benefit from our work.  At today's briefing, we will share some of this work with you.\n\nAs president of the New York Fed, I believe it is essential to listen firsthand to a broad set of businesses and people in the communities we serve to get as comprehensive a picture as possible of how our region is doing.  To accomplish this, we have a team dedicated to going out into the region to gather economic intelligence and to help our communities develop programs to support local economic development.  Let me speak a little further about our work analyzing local economic conditions and how we use this work to help our stakeholders.\n\nWe have developed a number of analytical tools to track the regional economy.  To get the most up-to-date read on economic conditions in our District as possible, we conduct two monthly business surveys.  Our Empire State Manufacturing Survey gives a real-time read on manufacturing conditions in New York State, while our Business Leaders Survey allows us to track economic activity across the tri-state region in the broader services sector.  We also conduct regular polls of small businesses in our area to better understand their evolving situation and needs.  In addition, we publish monthly indexes of economic activity for New York State, New York City and New Jersey.  We also monitor the financial health of households through our quarterly Household Debt and Credit Report and track the state of school finances in our region.\n\nBut economic data can only tell you so much. It is also imperative that we engage with people in our region to see the broader picture behind the facts and figures.  To this end, I regularly travel to various parts of our District to hear firsthand about local economic conditions and to get a sense of the issues and concerns facing businesses and residents.  Just two weeks ago I visited Rochester and Buffalo. One thing I tend to focus on in my meetings, more generally, is what hurdles businesses and households are facing that might be holding back growth.  When we identify issues of concern, we factor those in to our decision-making and explore what we can do proactively to address these issues.  This might include providing data and information that can assist others in tackling the underlying problems, or in convening stakeholders to discuss potential solutions and the best way forward.   \n\nRecently, two themes have emerged from our community visits that warrant special attention.  The first is in the arena of workforce development.  Employers often have difficulty finding potential employees with the specific skills they need, and workers often lack the specific skills employers are looking for.  Workforce development aims to bridge this gap.  Good jobs increasingly require higher levels of skill and education, and a skilled workforce that is matched to the needs of employers is also necessary for an economy to grow and prosper.  That is why I believe workforce development is so important for the long-term health of the economy.\n\nOur outreach group regularly engages with community leaders to help them take action to address workforce development needs and skill gaps.  In fact, in Rochester, our team is partnering with several educational and community organizations to promote local workforce development programs.  As in many places around the region, employers in Rochester are having difficulty finding workers to fill a number of middle-skill jobs, like nurses, automotive technicians and computer-controlled machine operators.  Out of this partnership, we launched a pilot project challenging college students to create a short video profiling middle-skill jobs that are available in the area in order to drum up interest in opportunities many people may not even know exist.\n\nAccess to credit for small businesses is another important issue we've focused on in recent years.  Our outreach group conducts a bi-annual poll of small businesses in our region to better understand their credit needs and access to credit.  The results consistently show that gaining access to credit is one of the top growth challenges for small businesses.  In my visits across the District, I have heard small business owners voice similar concerns. \n\nIn response, we've helped bring small businesses together with lenders to help smooth access to credit.  Over the past year we have conducted ten access-to-credit events\u2014workshops, clinics and conferences\u2014for companies interested in learning about traditional and alternative sources of financing.  We partnered with local and national government agencies, small business development centers and local nonprofit organizations to hold these events throughout the District. \n\nOne such workshop was held recently in Queens.  The Queens Economic Development Corporation and the Queens Chamber of Commerce, with support from the New York Fed's Asian Professional Network Alliance, co-sponsored a resource clinic for small businesses.  The clinic offered an opportunity for attendees to receive one-on-one advice from several non-profit organizations on a wide range of topics, including which types of financing are most appropriate for their needs, what lenders look for in potential borrowers, alternatives to traditional bank loans and tips on improving their chances for success.\n\nThese are just a few examples of the activities that reflect the Bank's commitment to the region. Let me turn now to the subject matter of today's briefing: the economic outlook for the regional economy.\n\nThere is a lot of good news to share.  Many parts of the region have bounced back quite well from the Great Recession, and now have more jobs than before the downturn.  New York City really stands out in this regard.  While the Great Recession was the deepest and longest recession in modern history for the nation as a whole, New York City bucked that trend to a surprising degree, and did it with little help from Wall Street.  As we will discuss later in the briefing, one of New York City's strongest sectors has been technology.  In this recovery, employment in the city's tech sector has added nearly 50,000 jobs, many of which pay well.  The growth of the so-called Silicon Alley has not only helped the city bounce back from the recession, but, I believe, is a key for the city moving forward.  When I visited Brooklyn late last year, I saw firsthand how technology is spurring economic activity, directly and indirectly.   For example, Etsy, the popular e-commerce website, which in many ways resembles a retail company, relies on technology to underpin its business model. \n\nBut it's not just New York City that is growing nicely.  Employment levels on Long Island and in parts of upstate New York\u2014most notably the Albany, Buffalo and Rochester metro areas\u2014have also climbed and are at or near record highs.  During my recent trip to upstate New York, I saw first-hand some of the positive developments in Rochester and Buffalo.  After undergoing a prolonged period of economic transformation and reinvention, Rochester's economy is now more diverse and dynamic than ever before.  Meanwhile, the growth in Buffalo was striking.  The numbers show a dramatic uptick in construction employment, and the visual evidence of development was widespread.  I was especially impressed with the downtown and waterfront areas, as well as the new SolarCity factory\u2014all of which looked dramatically different than when I visited the area less than two years ago.  Both of these places are well positioned for future success.    \n\nOn the other hand, the employment recovery has been slow to take hold in both Northern New Jersey and the Lower Hudson Valley, where jobs are still not back to their pre-recession peak despite employment growing steadily.  For Northern New Jersey, this lag is due, in part, to a stall in the growth of jobs in professional and business services.  But the education and health sectors continue to add jobs, and construction employment is seeing a rebound.   I also saw a number of bright spots on my visit to the area a few months ago.  One was Jersey City, which is leveraging its proximity to New York City to attract residents and jobs.  Another was Newark, where I saw signs of downtown development, including Teacher's Village, a mixed-use community of teachers with new schools, housing and retail businesses. \n\nBut pockets of weakness remain.  For example, in upstate New York, Binghamton has had no meaningful rebound in employment.  Although the U.S. Virgin Islands and Puerto Rico remain in a deep economic slump, employment appears to have steadied in both places in recent months.  However, Puerto Rico's weak economy coupled with a fiscal crisis means its economic outlook remains uncertain as it struggles to address its unique set of problems. \n\nNow, I'd like to turn things over to one of our regional economists, Jim Orr, who will provide a more detailed presentation of economic conditions across our region."
  },
  {
    "title": "Workforce Development and Reinvention in the Rochester Economy",
    "date": "Aug 12, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150812",
    "content": "Good morning.  I am very pleased to be in Rochester and to have the opportunity to speak here today.  I would like to give a special thanks to the Rochester Business Alliance for their part in making this event possible.  My meeting with you today is part of our continuing efforts to understand what is going on at the grassroots level of our economy.  During these trips I meet with a variety of stakeholders, which helps me develop a comprehensive view of local conditions and a fuller understanding of any major issues and concerns.  This is my third visit to Rochester in the past five years.  In my remarks, I will provide an overview of the regional economy and discuss the importance of workforce development, both for Rochester and the broader economy.  As always, what I have to say today reflects my own views and not necessarily those of the Federal Open Market Committee or the Federal Reserve System.1\n\nReinvention in the Rochester Economy\nLike Upstate New York more generally, the Rochester economy has lagged behind the nation for a number of decades.  During this time, Rochester has been going through a prolonged period of economic transformation and reinvention.  While this process has been a painful one in many respects, I believe that it is well-advanced and the area is well-positioned for the years ahead.  Rochester possesses a unique set of assets that are key to a successful economic reinvention, including a highly skilled workforce, world class higher education institutions, a diverse economic base, and a forward-looking cooperative engagement between the public and private sector.  There is strong evidence that Rochester is already tapping into these assets to great success.  To prove my point, I would note that my colleague, Narayana Kocherlakota, is leaving the Federal Reserve Bank of Minneapolis at the end of the year to become a professor at the University of Rochester.  Our loss is your gain!\n\nConsider how we got to where we are today.  Early in the 20th century, with the explosive growth of the \"Big 3\"\u2014Kodak, Xerox and Bausch & Lomb\u2014came a great demand for innovative and skilled workers, especially engineers, who helped make these companies highly successful.  At their peak, these three companies alone employed roughly 20 percent of the Rochester workforce.  These workers developed innovative new products and processes, which often resulted in patents that remain valuable to this day.  In many ways, Rochester, and its skilled workforce, was ahead of its time.\n\nThese companies, though, came under pressure in the 1980s as a result of rapid technological changes and increased global competition.  As their employment began to decline, some workers left the area while others remained.  Indeed the legacy of the \"Big 3\" lies not in what was lost, but in what remains in the skills and entrepreneurial spirit of the many talented people that are here today.  Some of these talented people started their own companies, while others found different ways to contribute their unique talents to the local economy.\n\nAs a result, Rochester continues to reinvent itself, and is now much more diverse, with an employment base that is no longer concentrated among a few large manufacturers.  The top employers in the region, like the University of Rochester and Rochester Institute of Technology (RIT), Wegmans, the Rochester General Health System and Paychex, just to name a few, perform a variety of activities, from health care and education to consumer and business services.\n\nThe process of reinvention and economic diversification, in part, allowed the region to better weather the storm of the Great Recession compared to past economic recessions.  For Rochester, the downturn was both shorter and less severe in terms of job loss than for the nation as a whole\u2014a situation quite different from what had occurred before.  Though it still lags the nation, the Rochester area has continued to grow at a solid pace through the recovery.  This is no small feat, and it certainly is not true for all of Upstate New York.  For example, the recovery has been much more sluggish in Syracuse and Utica, and Binghamton has yet to see any meaningful recovery.\n\nDespite Rochester's relatively favorable economic performance in recent years, the region's job base is actually slightly lower today than it was at the start of this century.  While at first blush it may seem that such a statistic indicates a stagnant economy, that couldn't be further from the truth.  When you look deeper, you see an economy that has been very active and dynamic in a number of respects.  While some parts of the economy have declined, other areas have grown to fill in the gaps.\n\nThe most familiar part of this story is the swift and severe loss of the region's manufacturing jobs.  Ongoing technological change has increased worker productivity and has reduced the demand for many \"middle-skill\" workers, while globalization shifted many manufacturing jobs to other parts of the world.  These forces have reduced manufacturing employment nationwide, but the effects on Rochester have been particularly potent.  Between 2000 and 2010, the number of manufacturing jobs in Rochester declined by over 40 percent.  That's a huge loss to incur in just a single decade.  Moreover, the loss was on top of the previous significant decline in manufacturing that the region experienced throughout the 1980s and 1990s.\n\nHowever, what's impressive is that in the midst of this decline, Rochester's manufacturing sector has been very dynamic.  While once focused on the \"Big 3,\" the region is now producing a much more diverse set of products, such as foods, computers and electronics.  And, the manufacturing companies that remained are leaner and have an even higher-skilled workforce than in the past.\n\nFortunately, Rochester has also experienced significant job growth outside of the manufacturing sector.  The regional economy added over 44,000 non-manufacturing jobs since 2000, keeping its overall employment fairly steady.  The vast majority of these jobs are in the education and health sectors, which together have grown by more than 40 percent over the past 15 years in Rochester.  Many of the jobs added in these sectors are high-paying jobs.  And, importantly, these sectors tend to be less susceptible to cyclical downturns than other parts of the economy, which helps make the region more stable.  There has also been solid growth in business services, leisure and hospitality and even construction.\n\nThe Importance of Workforce Development\nWith today's economy going through such enormous change, what people do in the workplace and how they do it is also changing significantly.  It is no longer the case that people can easily find good-paying, career-oriented jobs with a high school diploma.  The jobs of today typically require more knowledge, skill and flexibility.  Often, this means that today's workers must invest more in education and training than earlier generations.  In addition, the depreciation rate for many skills is much higher now than in the past.  This requires workers to continuously reinvest in skill development.  Broadly speaking, workers who can build skills and remain nimble can do very well in today's economy, while those who can't are much more likely to fall into lower-paying jobs and get stuck there.\n\nA skilled workforce that is matched to the needs of employers is also necessary for the economy to grow and prosper.  By pursuing its mandated goals of maximum employment and price stability, monetary policy can help labor markets recover by providing incentives for firms to invest and grow.  However, monetary policy cannot by itself solve skill mismatches that may exist in the economy.  These frictions must be addressed in other ways, such as by workforce development policies.  That is, monetary policy can complement workforce development policies, but is not a substitute for these policies.\n\nThat is why I believe workforce development is so important for the long-term health of the economy.  We need to help workers build the skills necessary to adapt to change.  This makes workforce development a top priority for everyone involved: workers, their employers, their communities and the public sector, as well as education and job training institutions.  We all need to share in the responsibility of helping people increase and maintain their skills.\n\nSuccessful workforce development needs to include what I call the 3 P's: Partnerships, Programs and Placement.  Partnerships entail the cooperative endeavors between local employers and educational institutions to determine the best strategies to help workers develop the skills that employers need.  Programs must be tailored to the current skills required by local employers.  Placement needs to be a priority, and should be considered even before people are accepted into these programs.  Workers need to know that a job will be waiting for them after they go through the effort of building their specific skills.  There are several examples from Rochester and other parts of the region that illustrate the potential for this approach to workforce development.\n\nIn fact, Rochester has a long history of involvement in workforce development.  In 1885, a group of Rochester businessmen founded the Mechanics Institute.  The Institute's mission was to establish free evening schools in the city for instruction in mechanical drawing and other technical skills important for industrial firms.  Funding was provided by contributions from Rochester residents.  The first class drew more than 400 students. This endeavor evolved over time into RIT.\n\nStrong partnerships between Rochester's higher education institutions and local businesses continue to this day. For example, RIT's Center for Bioscience Education and Training provides local businesses and associations with workforce training tailor-made to specific organizational needs.  And at RIT's newly created Knorr-Bremse Mechatronics Laboratory, the university works with the companies that employ its graduates to make sure they have the technical skills they need to be successful.  At the University of Rochester, the Center for Emerging & Innovative Sciences as well as the Center for Medical Technology partner with local companies to leverage the cutting edge research being done by the university's faculty and students. Forward-looking partnerships such as these create \"win-win\" opportunities for everyone involved, and help the local economy grow and prosper.\n\nMonroe Community College (MCC) also stands out with its significant workforce development initiatives.  In fact, earlier this year Vice President Joe Biden\u2014who was back in Rochester recently to announce the creation of a new manufacturing photonics hub\u2014presented the college as a model for developing meaningful collaborations with employers to create job-training programs that align with current employment opportunities.  MCC has taken a uniquely data driven approach to the development of tools and programs that work to address the most pressing workforce development needs in the greater Rochester area, and to provide diverse learners with clear paths to sustaining meaningful careers.\n\nFor instance, the MCC Corporate College program has designed and delivered more than 100 new noncredit courses and provided education and training to more than 2,000 individuals.  Additionally, the college has partnered with 128 employers, including CooperVision and Thermo Fisher Scientific, to deliver customized training to their employees.  The Corporate College takes an innovative approach in providing workforce learning and development solutions informed by current labor market data and expert analysis.\n\nThere is increased awareness, both locally and nationally, of a growing skills gap within industries.  Supporting middle-skill occupations has become a critical theme for many in the business community and within the workforce development community.  In response to this issue, MCC announced a new collaboration with JPMorgan Chase called the Middle-Skills Bridge Program. This program targets the disadvantaged and underrepresented populations within Rochester's urban center to provide access to skill-based careers.  Participants receive intensive developmental education to improve their literacy and math skills before transitioning into one of MCC's accelerated certificate programs.\n\nThere are many other good examples of cooperative workforce development programs in the New York Fed's District.  In Buffalo, the Overhead Electric Line Worker training program at Erie Community College (ECC) was created in conjunction with National Grid to address the critical shortage of overhead line workers and technicians.  To date, the program has graduated 132 students, including 42 who are currently employed at National Grid.\n\nAnother example is OnForce Solar, which sells and installs solar energy packages for commercial and residential customers.  In 2010, OnForce Solar CEO Charles Feit moved his rapidly growing company to a then unoccupied building in the Port Morris area of the Bronx.  After struggling to find skilled workers, OnForce Solar partnered with Bronx Community College to create a $7 million technology hub which will be paid for by the company.  The partnership was made possible by the Governor's Start-Up NY Program, which was launched in 2013 to spur job growth in distressed areas by designating tax-free zones at various colleges and universities.  OnForce Solar also developed and taught a newly designed technology course at Bronx Community College.\n\nAnother example is Stevens Institute of Technology in Hoboken, New Jersey.  When I visited Stevens in April, I learned how they are preparing their students to meet local workforce needs.  During discussions with university leaders, I heard about their exciting new partnership with NBC Universal.  By working together, a new Media/Broadcast minor was created to provide the necessary coursework to prepare students for employment at NBC Universal and similar companies.\n\nTo better understand the extent to which local workforce development programs are addressing skills gaps throughout Upstate New York, the New York Fed has engaged with community leaders from across the region.  Our first meeting took place here in Rochester in March 2014.  An important issue raised by many participants was the lack of information about available well-paying middle-skills career opportunities. To help address this concern, the New York Fed partnered with the Rochester Community Foundation, MCC, Finger Lakes Community College and Genesee Community College to launch a pilot video contest.\n\nThe purpose of the contest was to increase awareness about specific middle-skill occupations identified as in demand by analysis conducted by the Finger Lakes Economic Regional Council.  The contest challenged college students to create a 30-second video that identifies the skills required, expected wages and job demands for an occupational group within a targeted set of industries.  At an awards ceremony held in The Little Theatre here in downtown Rochester a panel of judges selected the winning video \"Not Just a Geek,\" submitted by students from Finger Lakes Community College.  The video focuses on the field of computer science. Local Rochester movie theaters will air the winning video for two weeks in September, and we will explore additional outlets for this video throughout the region as a public service announcement.\n\nThese success stories that I've highlighted today illustrate the potential for workforce development to help cities such as Rochester continue to reinvent themselves for today's economy.  We need to be vigilant in our focus on those in danger of being left behind. Too many individuals, especially in our urban centers, lack a high school diploma.  For example, the Rochester City School District has a dropout rate of 25 percent, and an alarmingly low graduation rate of just 50 percent.  Without a high school diploma, people are in danger of being left behind without the skills they will need to truly participate in the economy.  Succeeding in the international competition for jobs with a 50 percent graduation rate is like trying to win a boxing match with one hand tied behind your back.  We must do better.  While there are no easy answers, for the regional economy to thrive everyone needs to be an active participant.  We need to figure out ways to re-engage those who have become detached from the workforce, or who feel like they don't have the skills to compete in today's challenging economic environment.\n\nIn closing, Rochester is a metropolitan area in the midst of a process of transformation and reinvention.  While this process is not easy, Rochester possesses a unique set of assets that will help it succeed, and in many ways is on the cutting edge of adapting to these changes. Rochester is, in fact, becoming a leader in workforce development.  Reinvention like reform can be difficult, and requires a degree of boldness.  This sentiment was expressed by Rochester's social reformer, Susan B. Anthony, who said that \"Cautious, careful people, always casting about to preserve their reputation and social standing, can never bring about a reform.\"  Rochester is doing Susan B. Anthony proud, showing spirit and determination.\n\nThank you for your attention, I would be happy to take a few questions.\n\n__________________________________________________________\n\n1 Jaison Abel, Chelsea Cruz, Tony Davis, Richard Deitz, Eric Pajonk and Joseph Tracy assisted in preparing these remarks."
  },
  {
    "title": "Trends in Foreign Exchange Markets and the Challenges Ahead",
    "date": "July 14, 2015",
    "speaker": "1",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/pot150714",
    "content": "The ability of households, corporations, and sovereigns across the world to safely and efficiently exchange assets denominated in one currency for assets denominated in another is essential to a healthy and robust global economy. These transactions can occur for myriad reasons\u2014to support the flow of goods, services, and investment across national boundaries, to diversify the savings of retirees, or to hedge risks associated with manufacturing a particular type of product. These transactions all rely on a foreign exchange market that functions with integrity\u2014that is, one that allows a diverse set of buyers and sellers, supported by robust infrastructure, to confidently and effectively transact at prices that reflect available market information and in a manner that conforms to acceptable standards of behavior.\n\nIn my remarks today, I would like to expand on the essential role that the foreign exchange market plays and examine some of the ways the market\u2019s structure has changed in recent years. Then, amid the backdrop of a number of recent negative developments\u2014specifically, evidence of unethical and illegal behavior by some market participants\u2014I will discuss the critical role that implementation of and adherence to strong global industry standards, including best practices, can play in restoring and maintaining the integrity of the foreign exchange market. In doing so, I will highlight recent and ongoing efforts to help strengthen these standards through the Financial Stability Board and collaborative efforts by major central banks and market participants working within and across jurisdictions, often through local foreign exchange committees. I will conclude by setting an expectation for all market participants in foreign exchange to help support this work in order to reinforce the integrity of, and the public\u2019s trust in, this important market.\n\nThe Importance of the Foreign Exchange Market\n\nThe foreign exchange market is perhaps the largest, most globally integrated, and most active financial market in the world. The transactions that take place there are the lifeblood of a global economy that comprises many different national currencies. By enabling the transfer of funds and purchasing power from one currency to another, the foreign exchange market offers an important means for price discovery that facilitates international trade and investment activity.\n\nThe relative value of a currency, expressed in exchange rates, both drives and is driven by the costs of goods, services, and investment opportunities in each economy. Understanding relative prices helps businesses make decisions about the competitiveness of their goods and services, which is important for consumption and production choices. For example, the current and future value of an exchange rate can be an important factor for a corporation when deciding where to locate a new factory or where to source parts, or even where they want to sell their finished products. These decisions ground the composition of activity within an economy, and have a bearing on the distribution of jobs, investment, and growth across the global economy. This is a particularly important function given trade\u2019s increasing contribution to global growth. Indeed, between 2003 and 2013, the share of trade in global GDP increased by about 11 percentage points, to just over 59 percent.2\n\nThe FX market is a large and growing market. According to the latest Triennial Central Bank Survey of foreign exchange and derivatives market activity conducted by the Bank for International Settlements (BIS) in April 2013, total global average daily turnover across over-the-counter foreign exchange instruments\u2014including spot, forward, swap, and option transactions\u2014was estimated to be more than $5 trillion, an increase of nearly 60 percent since 2007.3 This trading volume dwarfs the U.S. fixed income market, where average daily turnover at the end of 2013 was about $815 billion.4\n\nWithin this large market, a broad range of foreign exchange products is traded each day by a diverse set of market participants for a wide variety of reasons. Derivatives are the largest component of global trading in the FX market, accounting for about 60 percent of turnover in 2013. They play an important role in helping transfer a wide variety of risks from entities that cannot or do not want to bear it to those that can and do\u2014including risks associated with hedging cross-border exposures or positions in other markets, such as fixed income\u2014or to provide a source of funding to help meet liquidity needs. The most actively traded derivative product, foreign-exchange swaps, accounted for about 40 percent of all trading activity in the global FX market in 2013, serving as a critically important cross-currency funding tool for a wide variety of market participants. For example, banks may have domestic currency liabilities but foreign currency assets, and thus may use the FX swap market to source foreign exchange. The spot market, which accounted for about 40 percent of trading activity in 2013, is used by private nonfinancial entities to trade goods and services or to invest in foreign businesses, while banks may use it to engage in cross-border lending and asset managers may use it to purchase financial assets or take positions based on their economic and financial market outlook.\n\nThe foreign exchange market is a truly global market and one of the few markets that trades around the clock. This gives it the unique ability to provide signals as to how market participants are interpreting or responding to developments taking place in other markets or in the real economy. During the global financial crisis, the foreign exchange market often was the first to reveal how market sentiment was evolving in response to significant events that occurred outside of trading hours in other markets. Such signals can be very useful to policymakers and market participants, particularly during periods of market stress.\n\nOf course, the foreign exchange market\u2019s ability to support price discovery and to enable the international flow of goods and capital requires a marketplace that is founded on integrity and capable of ensuring smooth and efficient interaction among market participants. This remains especially important as the structure of the market continues to evolve and adapts to new technologies and financial flows.\n\nChanges to Market Structure\n\nThe foreign exchange market is a dynamic market with a long history of change and innovation. Today, I would like to focus on two of the more significant recent changes in the market\u2019s structure: first, the broadening of participation, and second, how execution is taking place within the market.\n\nParticipation in the FX Market\n\nThe broadening of participation in the foreign exchange market is one reason why growth in FX trading volumes has far outpaced growth in global trade. The BIS Triennial Survey on foreign exchange market activity provides evidence of the degree to which this expanded participation is taking place.5 Traditionally, volumes in the foreign exchange market were dominated by what is known as the inter-dealer market\u2014trading between dealers. However, in the 2010 survey, the largest share of volume reported by dealer respondents was for transactions with \u201cother financial institutions\u201d\u2014a category that includes nonreporting banks;6 other financial institutions such as institutional investors, hedge funds, and proprietary trading firms; and official sector institutions. This shift continued through the 2013 survey, when \u201cother financial institutions\u201d accounted for just over half of reported volume, reinforcing evidence of a broadening in foreign exchange trading, with nondealers playing a greater role in the market.\n\nThe 2013 survey broke out the \u201cother financial institutions\u201d category for the first time. The data showed that nonreporting banks accounted for about 45 percent of the category\u2019s trading volume while institutional investors and hedge funds/proprietary trading firms each accounted for about 20 percent. In a market where daily trading volume exceeds $5 trillion, this represents significant activity and is consistent with a general theme of increased participation by nondealers in the FX market.\n\nExecution in the FX Market\n\nOne factor contributing to the expansion in participation by nondealers in the foreign exchange market has been the increased ease of entry into the market, attributable to an expansion in the number of execution platforms and services. In part, this has been supported by technological advancements, which, in some cases, have reduced trading costs, increased the speed with which transactions take place, and improved transparency. Electronic trading activity in foreign exchange markets, as well as in other markets, has played a growing role, and some reports suggest it may represent as much as 70 percent of daily turnover in the foreign exchange market, up from roughly 30 percent a decade ago.7\n\nIn addition to expanding entry to the market, technology is also changing how participants engage the market, through both single- and multi-dealer platforms. In the past, institutional customers could engage the market only by calling their dealing bank, but the marriage of technology and prime brokerage\u2014the bundling of investor services, such as trade execution, settlement, financing, and custody\u2014has enabled direct access to the interdealer market in ways not seen previously. Prime brokerage services have enabled an expansion in potential trading partners, allowing customers to trade in the name, and on the credit, of their prime broker. Altogether, this has served to transform what was once a two-tiered market\u2014interdealer and dealer-to-client\u2014into a market with much broader access. Moreover, as new trading platforms have come online, the profile of FX market participants, and thus the way FX is traded, has changed. New participants, such as retail and smaller institutions\u2014that are often engaged in high-frequency or high-speed trading\u2014could begin executing on their home or office computers, or could connect their trading algorithms directly to the platforms.\n\nThe expansion of both the universe of market participants and the infrastructure to support execution has brought many positive benefits to the market and global economy, but we should also be mindful of potential costs that might arise. In particular, it is important to consider the implications for the overall integrity of the market, which, as I noted earlier, relies on the ability of market participants to confidently and effectively transact at prices that reflect available market information.\n\nTechnology has helped ease entry to the market, but the capital investments needed to keep up have also increased. Indeed, operating in fractions of milliseconds has become an important component toward achieving faster execution. Will this hinder the entrance of new participants in the future, particularly those who may not have the extensive resources required to keep up?\n\nIn addition, while many market participants note the positive influence that technological changes have had on market functioning, including narrower bid-ask spreads,8 it is unclear how these changes may affect the broader price discovery process or liquidity of markets overall. Technology allows market participants to better connect across potentially fragmented execution options, but has the central price discovery mechanism emerged stronger, and is liquidity as resilient?\n\nFurther, dealers increasingly are internalizing customer flows\u2015that is, matching their clients\u2019 buy and sell orders in-house rather than executing them through the open market. But what does this do to the quality of pricing in the open market? And does reduction in potential open market trading have negative consequences for market functioning?  \n\nMoving Toward More Robust Practices in the FX Market\n\nThese changes in market structure and their potential implications for the functioning of the market are important to monitor, but market integrity does not rest solely on the ability to transact. It also requires that parties in the market behave in accordance with appropriate standards of behavior\u2014standards that help to ensure that parties treat each other fairly. This is an area where further work is clearly required to support, and in fact to rebuild, the integrity of the market. As this audience is well aware, the foreign exchange market has recently been rocked by broad, unethical misconduct, which is unacceptable, and this has shaken the public\u2019s trust and faith in the market.\n\nA recent series of investigations in the United States and abroad established that serious misconduct and collusion had occurred in the spot foreign exchange market. The investigations led to a string of regulatory actions and fines against some of the largest banks active in this market, and criminal pleas across multiple jurisdictions. These developments have resulted in damage to the integrity of the global FX market\u2014damage that will not easily be undone. The behaviors that triggered these criminal and regulatory actions illustrate that, for many, self-interest and the lure of near-term gains were put above the preservation of the market\u2019s integrity and long-term sustainability.9 The resulting loss of the public\u2019s faith and trust in this critical market comes with a cost: Let\u2019s recall that it is ultimately the public that stands to lose from an FX market unable to play its vital role in the global economy.\n\nThe FX market is considered by many to be relatively lightly regulated, particularly in the FX spot market. Regulatory treatment across jurisdictions varies.10 Regardless of who regulates in a given region, in the absence of a single centralized and comprehensive global regulator of this highly global market, collaborative efforts between the private and official sectors play an important role. These efforts help us to better understand the roots of the misconduct and the misalignment of incentives that contributed to weaknesses in trading structures and encouraged unethical and illegal activities. And they can also play an important role in elevating best practices in order to promote a sound, effective FX market going forward. In the remainder of my remarks, I\u2019ll discuss three examples of such work. First, the recommendations of the Financial Stability Board\u2019s Foreign Exchange Benchmarks Group. Second, the work of the various foreign exchange committees, including the New York Fed-sponsored Foreign Exchange Committee (FXC), to provide more detailed, globally harmonized guidance through an expanded Global Preamble to the existing regional codes of conduct. And third, the expansion of that work into the current international effort to develop and implement a single global code of conduct for the foreign exchange market and to enhance adherence to that code among all market participants.\n\nWork of the Financial Stability Board\u2019s Foreign Exchange Benchmarks Group (FXBG)\n\nGiven the global nature of the FX market, as well as the number of jurisdictions in which wrongdoing has been uncovered, efforts to strengthen the market must be global in nature as well. Recognizing this imperative, the Financial Stability Board (FSB), an international body that monitors and makes recommendations about the global financial system, established the Foreign Exchange Benchmarks Group (FXBG) in early 2014. The purpose of the FXBG was to review FX benchmarks and associated market practices, including potential misaligned incentives, and make recommendations for change. The FXBG, which consisted of representatives from more than twenty countries, engaged with a range of market participants to analyze the market structures and incentives as they related to trading around benchmark fixings. The group produced a series of recommendations to enhance the structures and behaviors around FX benchmark trading. I would like to focus on two particular aspects of these recommendations\u2014first, changes to the WM/Reuters calculation11 and second, changes aimed at strengthening market conduct.\n\nThe FXBG report highlighted the dominant use of the WM/Reuters (WMR) 4 p.m. London fixings by many different sets of market participants, including some not otherwise active in the foreign exchange market. The fixings, provided across many different currency pairs, were used in many different ways\u2014including for multicurrency portfolio valuation and for the valuation of key financial market indexes. In regard to the WMR 4 p.m. London fixings, the group identified important changes to strengthen the construction methodology and reduce the scope of potential manipulation. Specifically, it recommended that the length of time over which the fixing was calculated be extended. In addition, it recommended that this fixing incorporate price feeds and transaction data from a broader range of sources. These recommendations resulted in changes to the WMR calculation methodology, which were implemented in mid-February of this year.\n\nThe FXBG also identified a series of recommendations to strengthen market conduct and reduce the scope for manipulation and mistreatment of customer flow and information. For example, the recommendations encouraged greater clarity around fixing transactions through transparent pricing for such transactions and by establishing a clearer separation of fixing transactions from other types of activity. Further, the recommendations sought to strengthen the framework for the protection of information by providing greater detail around certain types of information that are not to be shared. Finally, the recommendations encouraged more detailed guidance within the various codes of conduct in the FX market as well as demonstration of greater compliance with such codes.\n\nIn February of this year, the co-chair of the FXBG, Guy Debelle, spoke at the FX Week Australia Conference about this work and addressed the status of implementation of the recommendations. He noted that while there had been some areas of progress, questions remained about the implementation in other areas\u2014for example, with regard to the recommendations related to more transparent and risk-appropriate pricing of fixing transactions.12 The FSB has since requested an update this summer on the status of implementation of the FXBG recommendations, and the various foreign exchange committees are working together, and with others, to assist in this effort.\n\nForeign Exchange Committee\n\nAdditional work to support the implementation of the FXBG recommendations has been an area of focus for the FXC. The FXC is a private sector group, made up of market professionals and sponsored by the New York Fed since 1978, that is intended to help provide guidance and leadership to the global FX market. In its earlier years, the Committee worked closely with comparable committees sponsored by central banks in other major jurisdictions, as well as with the Financial Markets Lawyers Group here in the United States, to improve standardization in the market, including through developing standardized documentation in the FX market, such as master agreements. Over the years, the Committee has evolved as the market has changed. For example, as entry to the FX market has expanded and as nondealer firms have come to play important roles in the market, the FXC expanded to include buy-side representatives. I believe that this has strengthened the FXC\u2019s ability to contribute on FX market issues, including the work now required to help strengthen the best practices landscape on a global basis. Before turning to these global efforts, I would like to briefly highlight a couple of recent changes to the Committee\u2019s Charter, which I believe will further support the FXC\u2019s ability to contribute in particular to this global work.13\n\nFirst, the revised Charter language places a more direct emphasis on the role of Committee members to help promote the efficiency and integrity of the market through, for example, the development and implementation of best practices. Second, the revised Charter better highlights the importance of incorporating an even broader set of perspectives and expertise directly on the FXC. Engaging a broader set of perspectives across operations, legal, and compliance professionals\u2014as well as individuals across buy-side, sell-side, and various market infrastructure firms\u2014will help the Committee to apply this more comprehensive perspective to its work on best practices. It will take some time for these changes to be fully implemented, but it is expected that the various steps that move us in this direction will also help us to engage even more effectively in the important work ahead.\n\nGlobal Best Practices Efforts\n\nThe FXC has been engaged in two global efforts with its counterparts abroad: development of the Global Preamble and work, now under way, to extend the Global Preamble into a single global code of best practices in the FX market.\n\nThe Global Preamble (\u201cPreamble\u201d) is a document that was developed collaboratively by the eight central-bank-sponsored foreign exchange committees to provide a common basis from which our individual codes of conduct for the FX market follow. The Preamble lays out key, shared principles that underpin our respective codes. The publication of a revised Global Preamble earlier this year was an important development that built upon a tradition of increasing engagement across the committees. The initial Global Preamble was published in 2013 and marked the first time the committees had come together to provide a single voice around best practices. For example, the document noted that market participants are expected to have systems and controls in place to:\n\nThe revised and expanded Global Preamble, published this past March, features even more substantive and detailed guidance on topics such as personal conduct, confidentiality and market conduct, and policies for execution practices.14 The Global Preamble provided an important opportunity to integrate the recommendations from the FSB FXBG report into best practices at a global level. For example, it includes language related to protection of information and confidentiality, as well as the enforcement of internal systems and controls involving both certain types of transactions and information.\n\nThe publication of the Global Preamble was a very important step in helping to provide a more globally harmonized and consistent framework for national codes of conduct and in integrating the FXBG recommendations, but it is not the final step. It is clear that further work is required both to strengthen best practices at a global level and to promote greater adherence to those practices. Recent developments indicate that market participants have either not been aware of existing best practices guidance or have made the conscious decision to violate such guidance in the hopes of making a short-term gain. The cost of these short-term gains has come at all of our expense and we must all be engaged to ensure that this does not happen again. Moving toward more globally harmonized guidance\u2014and consistent adherence to such guidance\u2014is an important step forward in maintaining the integrity of the market.\n\nIn recognition of the importance of this work, a new working group of the BIS Markets Committee has been formed to facilitate the establishment of a single global code of conduct and principles and to promote greater adherence to such guidance.15 This newly formed structure will deepen and broaden the already initiated public-private partnership and will engage an even wider set of financial centers in order to effectively move this work on best practices forward. The work will occur on a global scale and will engage a wide variety of market infrastructures and participants, including both the buy side and sell side. It will likely draw upon a variety of efforts, including the important work done in the U.K. under the Fair and Effective Markets Review. The FXC will be actively engaged in this effort along with its counterparts abroad, at the direction of the BIS Markets Committee FX Working Group.\n\nThe development of a single global code for the FX market is a significant effort, but developing a code is not enough. Codes of conduct and associated best practices are an important complement to regulation. They can support the integrity and function of the market by underpinning the smooth operation of the market and instill confidence that participants will treat each other fairly. But this is not possible, or sufficient, if best practices do not evolve as the market evolves, if they are not implemented effectively, or if they are not adhered to by market participants actively engaged in the market. Development of dynamic best practices is critical, as is the market\u2019s adherence.\n\nRecent headlines and events paint a picture of an FX market that does not always serve the public well. But you all have an opportunity to change this picture\u2014to support the work to strengthen the market. I encourage you all to make the most of this opportunity. As Guy Debelle noted in his speech in February, the failure to act on the FXBG recommendations may prompt authorities to conclude that further regulation is the only way to strengthen the integrity of the market.16 Similarly, the Governor of the Bank of England, Mark Carney, emphasized in his recent Mansion House speech that a failure to establish effective common standards that are adhered to would likely result in more restrictive regulation.17 Consider this message reiterated here today as well. I encourage you all to be engaged both at the individual and the firm level\u2014to share your perspective and contribute to the process to help strengthen best practices, and to support adherence to such standards in this critically important market.\n\nConclusion\n\nTo sum up, the foreign exchange market is one of the most vital markets in the world. Individuals, institutions, and the global financial system as a whole rely upon the ongoing effective functioning of this market. The market is constantly evolving, and it remains imperative that the industry work to strengthen the foundation of the market, and help to ensure that its integrity is upheld. Particularly in the wake of recent scandals, there is a role for industry participants to restore and maintain market integrity through support and development of best practices.\n\nYou all have a shared stake in this. As you move forward, always bear in mind the critical role that the FX market plays and think about whether your choices enhance or weaken the integrity of the market.\n\nI appreciate the work of those around the room to do so, as well as publications such as FX Week and others, for sharing their perspectives and providing continued coverage of these and other issues relevant to the market. Thank you.\n\n1 I would like to thank Robert Lerman and Jamie Pfeifer for their excellent assistance in the preparation of these remarks and colleagues in the global central bank community for numerous insightful comments and suggestions.\n\n2 World Bank Development Indicators; http://data.worldbank.org/data-catalog/world-development-indicators\n\n3 BIS 2013 Triennial Central Bank Survey. The Triennial Survey is coordinated by the BIS under the auspices of the Markets Committee (for the foreign exchange part) and the Committee on the Global Financial System (for the interest rate derivatives part). The latest survey of turnover took place in April 2013. Central banks and other authorities in fifty-three jurisdictions participated in the 2013 survey. They collected data from about 1,300 banks and other dealers in their jurisdictions and reported national aggregates to the BIS, which then calculated global aggregates. The survey, among other things, provides data on turnover, instruments, counterparties, and currencies, which are referenced in this speech; http://www.bis.org/publ/rpfx13fx.pdf\n\n4SIFMA US Bond Market Trading Volume; http://www.sifma.org/research/statistics.aspx\n\n5 BIS 2013 Triennial Central Bank Survey; http://www.bis.org/publ/rpfx13fx.pdf\n\n6 The anatomy of the Global FX Market through the lens of the 2013 Triennial Survey. A significant fraction of dealers\u2019 transactions with nondealer financial customers is with lower-tier banks. While these \u201cnonreporting banks\u201d tend to trade smaller amounts and/or only sporadically, in aggregate they account for roughly one quarter of global FX volumes. http://www.bis.org/publ/qtrpdf/r_qt1312e.pdf\n\n7 Euromoney, December 2013, Rise of electronic FX trading won\u2019t silence voice brokers. http://www.euromoney.com/Article/3286064/Rise-of-electronic-FX-trading-wont-silence-voice-brokers.html\n\n8 Not only is liquidity both challenging to define and measure, but the impact of technological change on liquidity is difficult to isolate. On a number of dimensions, technological change appears to have improved both the efficiency of price formation and the ability to transact in size without significantly affecting market prices. But recent \u201cflash\u201d events in various markets\u2014including rapid round-trips in prices on March 18, 2015, in the euro-dollar currency pair and on October 15, 2014, in the U.S. Treasury cash and futures markets\u2014have suggested the possibility that advancements in automated trading and changes in market structure may have improved liquidity in normal times but left markets prone to more frequent bouts of illiquidity during which price formation appears disconnected from fundamental information. Structural developments and the connection to liquidity and price discovery across markets warrant further study. See also recent comments by Lael Brainard, member of the Federal Reserve Board of Governors. Recent Changes in the Resilience of Market Liquidity. http://www.federalreserve.gov/newsevents/speech/brainard20150701a.htm\n\n9 See the U.K.\u2019s Fair and Effective Markets Review Final Report for related insightful discussion on fixed income, currency and commodities (FICC) markets. Available at: http://www.bankofengland.co.uk/markets/Documents/femrjun15.pdf\n\n10 In the United States, the CFTC has regulatory responsibility for most FX products.\n\n11 The WMR London fixing is now subject to regulatory oversight by the Financial Conduct Authority (FCA) in the U.K., in addition to the FSB initiatives. See the FCA\u2019s report Bringing additional benchmarks into the regulatory and supervisory regime, https://www.fca.org.uk/news/ps15-06-additional-benchmarks\n\n12 See http://www.bis.org/review/r150213c.htm\n\n13 See http://www.newyorkfed.org/fxc/FXC_Charter_2015.pdf\n\n14 See http://www.newyorkfed.org/fxc/2015/Global%20Preamble%20March30.pdf\n\n15 See: http://www.bis.org/press/p150511.htm\n\n16 See http://www.bis.org/review/r150213c.htm\n\n17 See http://www.bankofengland.co.uk/publications/Documents/speeches/2015/speech821.pdf"
  },
  {
    "title": "Remarks at the CPMI\u2019s 25th Anniversary Conference",
    "date": "Jun 30, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150630",
    "content": "We have three distinguished panelists in this opening session\u2014Claudio Borio, the head of the Monetary and Economic Department at the Bank for International Settlements (BIS), William Coen, the Secretary General of the Basel Committee on Banking Supervision (BCBS) and Masa Kono, who is currently the Vice-Minister of International Affairs at the Japan Financial Services Agency and who earlier chaired the International Organization of Securities Commissions (IOSCO) during the development of the Principles for Financial Market Infrastructures (PFMI).  They will offer their thoughts on how the role of the Committee on Payments and Market Infrastructure (CPMI) has changed and is likely to continue to evolve in its task of setting and helping implement global financial, operational and risk standards for the world\u2019s key financial market infrastructures (FMI).\n\nBefore I turn to our panelists, let me offer some brief comments on the evolution of the CPMI.  As I see it, there have been three broad complementary trends that have been important in influencing the evolution of the CPMI and have contributed to its increased importance over time.  As always, what I have to say represents my own views and not necessarily those of the Federal Open Market Committee or the Federal Reserve System.1\n\nThe first trend has been the development of a global financial system.  This has increased financial system interdependencies and, hence, the importance of harmonizing standards across national regulatory regimes.  It also has made it more important to avoid regulatory arbitrage and race to the bottom types of behavior that could weaken the resiliency and robustness of the global financial market infrastructure.\n\nThe second trend is the increasing importance of FMIs within the financial system.  As trading across a more complex array of instruments and products proliferates, and as more trades are centrally cleared, well-managed FMIs play an increasingly important role within the financial system.\n\nThe third trend stems directly from the first two.  With the global financial system becoming more prominent and FMIs playing a bigger role within this global financial system, it has become ever more essential that major FMIs operate safely.  When run well, they mitigate risk.  But, run poorly, they could be a source of contagion and risk propagation throughout the global financial system.  This means that the CPMI\u2019s work has become much more critical in ensuring a safe and sound global financial system.\n\nThe growing influence of the CPMI can be seen in its success in staying ahead of these trends.  It was the CPMI\u2019s analysis and standard-setting that led to the adoption of payment systems that provide \u201creal-time gross settlement with intraday finality,\u201d securities settlement systems that ensure \u201cdelivery versus payment,\u201d and foreign exchange settlement systems that ensure \u201cpayment versus payment.\u201d  This fundamental evolution of systemically important payment and settlement systems was instrumental in mitigating significant sources of systemic risk and laying a solid foundation to support the increasingly global financial system.\n\nIn parallel, it was the CPMI that first defined the concept and processes of \"central bank oversight of payment and settlement systems\" and implemented the associated principles for \"central bank cooperation.\"  This also supported many central banks and securities regulators in their efforts to gain explicit legal responsibility and power to apply standards aimed at promoting broader \"financial stability\" and containing \"systemic risk.\u201d  Title VIII of the Dodd-Frank Act in the United States is a good example of this.  This means that many authorities now have greater capacity and responsibility to apply and enforce the PFMI as requirements, where previously a number of regulators were constrained to treating earlier standards merely as \"recommendations.\"  Taken together, we have made considerable progress in terms of the global regulatory regime to reflect the growing importance of FMIs and central counterparties (CCPs) within the financial system.\n\nLet me briefly list a few of the accomplishments of the PFMI:\n\nAs I see it, great progress has been made, but there is more work to do in a number of areas:\n\nI am very fortunate to have had the opportunity to chair the Committee during the period in which the PFMI were created.  I recognize that this was just an initial step in the process, but it was an essential first step.  Subsequent CPMI committees, under the leadership of Paul Tucker and Benoit Coeure, have been working with the other Basel Committees, the Financial Stability Board (FSB), IOSCO and individual country regulators to continue to take this effort forward.\n\nWe have placed a lot of financial stability eggs in the FMI basket.  It is important that we monitor and oversee that basket carefully.\n\nI would now like to turn the floor over to our first panelist, Claudio Borio.  Claudio, the floor is yours, you have 10 minutes.\n\n1 Shari Bower, Caren Cox, Alex Merle-Huet, John Rutigliano, Johanna Schwab, Larry Sweet and Joseph Tracy assisted in preparing these remarks."
  },
  {
    "title": "Economic Research and Stress Testing",
    "date": "Jun 24, 2015",
    "speaker": "1",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/mca150624",
    "content": "Stress testing has become an important tool for bank supervision in the wake of the financial crisis of 2007-09.  A prominent example of stress testing is the quantitative assessment conducted by the Federal Reserve as part of its annual Comprehensive Capital Analysis and Review (CCAR) of large banking organizations operating in the United States.  The Federal Reserve uses its stress test to determine whether the banking organizations, given their current capitalization and future planned capital actions, would be likely to remain adequately capitalized under stressful macroeconomic scenarios.  The results of the quantitative assessment figure importantly in Federal Reserve policy decisions regarding whether to object to firms\u2019 plans for future capital distribution and retention\u2014for example, planned dividend payouts.  More generally, stress tests provide valuable information about the safety and soundness of individual firms, and, significantly, allow comparisons and aggregation across a range of firms.  For example, the stress tests conducted by the Federal Reserve under the terms of the Dodd-Frank Act\u2014the DFAST stress tests\u2014provide a very useful perspective on both individual firms and the banking system.  Stress tests are therefore used to gain insights applicable to both microprudential supervision of individual firms and macroprudential assessments of broader financial system vulnerabilities.\n\nGiven the now-central role of supervisory stress tests, it is appropriate to step back and assess how the science and intellectual framework underlying stress testing is evolving, and how economic research can ensure that these underpinnings are sufficiently robust to justify the continued confidence placed in stress tests by central banks and supervisors.  Stress testing is inherently challenging, for a number of reasons.  It requires specifying one or more macroeconomic scenarios that are stressful but not implausibly disastrous.  Scenarios must have certain elements of realism, but are certainly ahistorical, and may represent structural breaks in the processes that are being stressed.  Stress testing requires forecasting earnings and capital conditional on the nature of the scenario; not only is this more difficult than unconditional forecasting, but the objects of interest are the tails of the distribution\u2014the lower quantiles, which, almost by definition, are infrequently observed in historical data.  Stress tests rely on well-specified models of the processes that generate earnings for banks, and there are myriad ways to build such models; for example, they can be extremely disaggregated, built up from models of individual loans or securities, or they can be much more aggregated.  Supervisors and firms are, separately, both engaged in building these models; the supervisor has the benefit of having access to data from a panel of firms, while each firm mainly knows its own history of asset performance.\n\nThe complexity and difficulty of stress testing does not end there.  Two very important elements, bookends one might say, are the theory that lies behind stress testing, and the development and implementation of stress test models.  Both of these elements are crucial to using the output of stress tests in useful ways and to delivering outputs that reflect the risk of each bank\u2019s assets.  I\u2019ll have more to say on these points later in my remarks.\n\nHow can economic researchers help meet the daunting challenge of designing and implementing stress tests that will usefully reveal vulnerabilities in individual firms and in the financial system more broadly?  I\u2019ll suggest that there are various ways economic researchers can improve the science and practice of stress testing.  It seems clear to me that quantitative stress testing is an area in which the insights of economists are particularly valuable. Good stress testing practices should call upon the singular skills and knowledge of economists in econometric modeling, macroeconomic forecasting, banking theory, models of firm and household behavior, and many other areas of specialization.  The high demand for economists to work on stress tests at the Federal Reserve Bank of New York and throughout the Federal Reserve System during the last six years has clearly reflected these deep underlying needs.  \n\nObviously, these skills are critical for the practical implementation of stress testing\u2014calculating inputs to revenue and loss forecasts and evaluating the robustness of the models.  More broadly, these skills provide the logic for the intellectual framework that supports stress testing as a useful and current policy tool.  In what follows, I\u2019ll suggest several specific areas in which economic research is needed to continue to build the rigor and credibility of supervisory stress testing.\n\nAreas for Economic Research\n\nTheory\n\nStress testing cannot become a purely mechanical or statistical process. Instead, the design of stress tests must be informed and guided by sound economic theory, both in terms of identifying the goals of stress testing and determining the specifics of how the tests should be implemented. This need for economic theory is seen in many areas. Let me describe a few.\n\nProcyclicality: How should the severity of stress tests vary over the economic cycle?  A good case can be made for setting tough tests during boom periods, when vulnerabilities may be growing but hidden.  For example, although mortgage delinquency rates were low in 2004 and 2005, significant risks were building up in the mortgage market at that time.\n\nSome statistical models, however, may instead predict lower losses during good economic times, particularly if current loan or security performance is used as conditioning information in the model.  This raises an important question: should other aspects of the stress test, such as the severity of the macroeconomic scenarios, be adjusted to compensate for any such potential procyclicality?  If so, how, and by how much?  And does setting tougher tests during boom periods necessarily imply having weaker tests during periods of stress?  If it does, will having weaker tests during stress periods undermine the credibility of the stress testing regime?  Theory is needed to help guide thinking on these issues.  Such work could draw on the lessons learned from related research on the procyclicality of Basel II risk-based capital requirements.2\n\nFeedback Effects and Fire Sales: A second area in which further theoretical work can be focused is the feedback effects of stress at individual banks on other financial firms and markets.  This theme has been explored in many papers, such as Greenwood, Landier, and Thesmar (2015) and Duarte and Eisenbach (2013) and the sources cited in those papers.  The papers examine the role of spillovers in asset price declines among banks\u2014that is, situations in which the abrupt sale of assets by some banks causes other banks, holding concentrated positions in the asset sold, to experience significant declines in the value of their holdings, leading to further asset sales.  Such \u201cfire sales\u201d are emblematic of the complexity of the economics in the financial system, in which banks often hold similar assets and decisions by one firm to hold or sell an asset can affect the range of possible actions by other firms.\n\nTo date, most supervisory stress tests don\u2019t directly include feedback effects; instead, the macroeconomic scenario is itself intended to be stressful enough to include an assumption of difficult market conditions, consistent with negative feedback being already incorporated in the environment.  Whether this approach is sufficiently informative to policymakers, and whether it leads to a sufficient focus on managing the risk of exposure to fire sales, are questions that could benefit from further theoretical work by financial and macro economists.\n\nCombined Liquidity and Asset Stress: A third area meriting further exploration is the role of liquidity in stress tests.  The Federal Reserve conducts two types of stress tests: the CCAR, which stresses asset values and bank capital, and the Comprehensive Liquidity Analysis and Review, or CLAR, which focuses on stresses to funding and liquidity.  But as we saw in 2008, periods of financial instability are likely to involve a combination of stresses to capital and liquidity, with important feedback loops between the two.  This issue is, of course, related to the topic I just discussed\u2014Firms forced to sell assets in a fire sale because of liquidity problems may realize losses, reducing their capitalization and perhaps exacerbating liquidity problems.  A colleague and coauthor, Thomas Eisenbach, delivered our joint research on this topic at this conference last year.  Our research suggested one way that combined capital and liquidity stress tests, so-called dual stress tests, might be conducted.  But much more thought is needed here.\n\nLucas Critique: Another theoretical issue that could be explored further is the reliance on historical data to estimate econometric models that are then used by policymakers to project stressed capital ratios and to mandate additional capital retention or capital raising by firms subject to the stress test.  This procedure runs afoul of the Lucas Critique (Lucas 1976), which suggests that the relationships that are revealed by the use of historical data are likely to change if new policies are imposed based on the use of the estimated relationships.  While many papers question the empirical relevance of the Lucas Critique, it is nonetheless important to have a coherent theory of the policy process when stress testing is used to determine firms\u2019 minimum regulatory capital levels.  The problem might even be more severe when firms may be actively attempting to circumvent the intent of the policy.  Such a coherent theory might provide a better guide to policymakers on how to use the results of stress tests.\n\nEffects of Bank Capital on Financial Intermediation and the Real Economy:More broadly, additional work is needed to further our understanding of the relationship between bank capitalization and the provision of credit and other financial intermediation services to promote growth during a period of economic stress.  Stress testing as currently practiced by the Federal Reserve is oriented toward ensuring that banks have sufficient capital.  An understanding of the theoretical costs (and possible benefits) of different levels of bank capital, both for the individual firm and the financial system, will help ensure that we make the right trade-offs as a society.\n\nEmpirical Work\n\nAs I mentioned earlier, stress testing necessarily involves conditional forecasting of the tails of distributions of losses and revenues.  Many opportunities exist to develop new approaches and to incorporate existing insights from macroeconomic forecasting.  Two approaches that might be usefully applied in the stress testing context are Bayesian techniques and methods to incorporate structural breaks in the stochastic process being estimated.\n\nThe Federal Reserve has collected an unprecedented amount of granular cross-sectional data from the banks participating in the stress tests.  The data allow for the construction of structural models\u2014models that incorporate loan-by-loan or asset-by-asset projections of cash flows with valuable details on asset and loan characteristics.  These models may sidestep some of the concerns that arise with more aggregated modelling. For example, better information on borrower risk allows stress tests to be more responsive to shifts in bank risk-taking and other changes in asset composition.  This information also represents an opportunity for economists to better understand bank risks since, historically, many models of banks and their assets have not had such rich data to work with. Making use of these data to inform policy choices and monitor bank risk-taking, while ensuring the confidentiality and integrity of firm data, is both a challenge and an opportunity.\n\nThe design of macroeconomic stress scenarios is an area of interest in itself.  As the economy evolves over time, relevant potential scenarios are largely \u201cahistorical,\u201d in that they will contain constellations of asset price movements and macroeconomic conditions that might bear little resemblance to historical patterns.  Crafting such scenarios will nonetheless entail a great deal of empirical work to gauge the range of possibilities and to determine how probable such configurations of events might be.\n\nCombining ahistorical stress test scenarios and models developed with historical data presents a further empirical challenge. Since macroeconomic variables generally move together, it can be hard to identify or calibrate the importance of any single variable. Models calibrated using historical data may be challenged, therefore, to capture fully the impact of ahistorical movements in macroeconomic variables.  Finding ways to address this challenge is another area where the science of stress testing could be advanced.\n\nPerformance Testing and Model Validation\n\nPrecisely because stress tests are attempts to project unlikely outcomes\u2014those that occur under stressful macroeconomic conditions, the actual evolution of events generally won\u2019t closely follow the stress scenario, nor will bank losses necessarily accrue according to stressed loss estimates.  Notwithstanding that stress testing is a test of possible risks, not likely outcomes, the performance of the underlying models can and should be tested in various ways.  Here, too, economic theory and empirical work can be combined to suggest new ways to accomplish this important exercise.  How can stress testing model performance be measured and tested if severely adverse macroeconomic outcomes do not arise?  How can we estimate the precision of forecasts and quantify increases to firm and system stability that stress tests promise?\n\nA closely related dimension of stress testing that requires further investigation is the practice of model validation.  Models are validated in a number of ways\u2014for example, by checking model codes and data sources\u2014but economic models should also be validated in a larger sense by checking underlying assumptions and the efficiency of the model in measurement.  Such an undertaking requires a dialogue with the broader academic community of economists, which validates models by peer review and replication of results.  And indeed, the Federal Reserve sponsors just such a group of academic economists\u2014the Model Validation Council, some of whom are here today\u2014to provide expert and independent advice on stress test model validation.\n\nHow Economists Can Help\n\nNow that I\u2019ve outlined, surely in an incomplete way, a number of areas in which economists can usefully improve the intellectual framework of stress testing, the question arises, Which economists should be employed in those pursuits?  Here, I\u2019ll suggest that both academic economists and economists in central banks and other regulatory agencies, who work closely with their supervisory colleagues, are needed to make progress.\n\nFurthermore, I\u2019ll recommend that the central bank economists, like those at the Federal Reserve Bank of New York, be required as part of their career development  and evaluationto seek to publish papers in peer-reviewed scientific journals.  There is a strong long-run complementarity between research and policy analysis.  The skills needed to be successful in research and in policy analysis are largely the same.  It is vital that economists continue to invest in new knowledge and maintain their human capital.  The peer-review process is an important external signal that economists are obtaining these skills.  The best way, or should I say the most economical way, to build and retain a staff of highly qualified economists capable of making vital contributions to policy work is to encourage the economists to pursue research with the aim of publishing in peer-reviewed journals.  To this end, central bank economists should be given a significant amount of independent research time, with the appropriate accountability for their research output.  In the specific context of stress testing, this also means a commitment on the part of the Federal Reserve to make confidential data available for research purposes and to encourage collaboration between system economists and outside academics.\n\nCentral bank economists from research departments also bear a special responsibility to bring their full complement of knowledge, technical expertise, and inventiveness to important policy efforts such as stress testing.  At the New York Fed, this expectation ranks equally with the idea that economists must publish.  Effective policy analysis of the type necessary to improve stress tests requires a close collaboration between economists and key staff from other areas of the Federal Reserve, such as those charged with supervision and market monitoring.  This collaboration is facilitated by establishing and nurturing long-term relationships with colleagues outside of research departments.  In contrast with academic economists, an internal staff of central bank economists is in the best position to establish such relationships and to cultivate the necessary trust.  Academic economists have less incentive to develop relationships or to acquire institutional knowledge that is necessary to the analysis of specific, and sometimes acute, policy problems but that does not provide a general return in the broader market.\n\nAt the same time, academic economists are often expert in areas requiring a significant investment in innovative theoretical and empirical methods.  Their work, at a more general level, can be very useful for assessing the work of central bank economists and for suggesting promising new avenues of development.  Consequently, there are complementary roles to be played by central bank and academic economists in developing stress testing as a discipline.\n\nA Robust Intellectual Framework for Stress Testing\n\nStress testing is a relatively new supervisory discipline that requires the development of a robust intellectual framework to achieve its objective\u2014the forceful  and effective supervision of systemically risky financial firms. I\u2019ve suggested a number of areas in which work by research economists, both within central banks and in academia, can be used to build that framework over time.\n\nI found two clear lessons in the paper presented at this conference by Frame, Gerardi, and Willen (2015).  In that fascinating and important paper, the authors document how the stress tests of Fannie Mae and Freddie Mac, designed over a decade by the Office of Federal Housing Enterprise Oversight, OFHEO, failed in every sense.  By its governing law, OFHEO was required to fully disclose its stress testing model, and so published all stress scenarios, empirical specifications, and parameter estimates in the Federal Register.  The authors suggest that, from the introduction of the stress tests in 2002 through 2007 when the crisis hit, OFHEO never \u201cre-estimated its mortgage default or prepayment forecasting model, nor introduced new variables, despite well-documented changes in mortgage underwriting practices during this time\u201d (Frame, Gerardi, and Willen, p. 3).\n\nThe first lesson I draw is that full transparency in stress testing can be an enormous weakness; it can make tests less flexible and responsive, and give the firms subject to the test opportunities to circumvent the test.  The second lesson is that it is important to update stress testing models over time to incorporate changes in borrower behavior, lending standards, and other aspects of the economic environment, as well as improvements in techniques of the kind that I have addressed in these remarks.\n\nWhat I\u2019ve argued is that to build the robust intellectual framework that stress testing needs requires the sort of dynamism that economic research can bring to such inherently difficult problems.  Many commentators, including Schuermann (2013), warn against a sort of \u201cmodel monoculture,\u201d in which the regulator is forced to focus on a single model and all firms aim to manage to the model rather than to the real risks they face.  This is certainly a significant problem, and its dangers are seen in the failures of the OFHEO stress tests.  Thus far, my colleagues Bev Hirtle and Anna Kovner have examined this question empirically in posts in the New York Fed\u2019s Liberty Street Economics blog and have not found strong evidence of convergence between the Fed\u2019s and the banks\u2019 stress test estimates.  But the best method of averting this problem is exactly to have a robust intellectual debate that leads to innovations in stress testing, and that can allow the performance measurement of alternative approaches to stressing a bank\u2019s condition.\n\nConferences such as this one are a tonic against settling on a narrow modeling approach to the myriad difficulties of stress testing, and I hope that more economists, both in central banks and in academia, will pursue new solutions to the challenges of stress testing.\n\nReferences\n\nDuarte, F., and T. Eisenbach. 2013. Fire-Sale Spillovers and Systemic Risk. Federal Reserve Bank of New York Staff Reports, no. 645, October; revised February 2015.\n\nEisenbach, T., and J. McAndrews. 2014. \u201cDual Stress Testing and Run Vulnerability.\u201d Unpublished paper, Federal Reserve Bank of New York, March; revised June 2015.\n\nFrame, W. S., K. Gerardi, and P. S. Willen. 2015. The Failure of Supervisory Stress Testing: Fannie Mae, Freddie Mac, and OFHEO. Federal Reserve Bank of Atlanta Working Paper no. 2015-3, March.\n\nGreenwood, R., A. Landier, and D. Thesmar. Forthcoming. \u201cVulnerable Banks.\u201d Journal of Financial Economics.\n\nKashyap, A., and J. Stein. 2004. Cyclical Implications of the Basel II Capital Standards. Federal Reserve Bank of Chicago Economic Perspectives 28, no. 1 (First Quarter): 18-31.\n\nLucas, R. 1976. \"Econometric Policy Evaluation: A Critique.\" In Brunner, K., and A. Meltzer, eds., The Phillips Curve and Labor Markets. Carnegie-Rochester Conference Series on Public Policy, p. 19-46. New York: American Elsevier.\n\nRepullo, R., and J. Suarez. 2009. \u201cThe Procyclical Effects of Bank Capital Regulation.\u201d Working Paper, CEMFI, wp2012_1202.\n\nSchuermann, T. \u201cThe Fed's Stress Tests Add Risk to the Financial System.\u201d Wall Street Journal, March 19, 2013.\n\n1 The views expressed in this speech are those of the author and do not necessarily reflect the position of the Federal Reserve Bank of New York or of the Federal Reserve System. The author thanks Beverly Hirtle, Anna Kovner, and James Vickery for extensive discussions and assistance in preparing these remarks.\n\n2 For example, see Repullo and Suarez (2009) and Kashyap and Stein (2004)."
  },
  {
    "title": "The U.S. Economy and Financial System in an International Context",
    "date": "Jun 24, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/mus150624",
    "content": "It is a pleasure to have been invited to speak to the Institute of International Bankers today about the U.S. economy and financial system in an international context.  Developments in the U.S. have important implications for the rest of the world and vice-versa.\n\nI have two main messages today.\n\nFirst, the Federal Reserve has domestic objectives with respect to employment and inflation, the safety and soundness of supervised financial institutions, and the stability of the U.S. financial system. In the context of these domestic objectives, the Fed is mindful about the potential international implications of its policies.  This comes from a sense of a special responsibility given the international reserve currency status of the dollar and also because the international effects of Fed policies can spill back onto the U.S. economy and financial conditions. \n\nSecond, policies that make the U.S. economy and financial system strong and stable are most likely to generate positive spillovers to the rest of the world.  Federal Reserve transparency and clear communication about the evolution of the economic and financial landscape are critical for these positive spillovers to occur. \n\nIn my remarks I will review the U.S. economy; potential spillovers from U.S. monetary policy normalization; and U.S. financial system reforms in support of financial stability and economic growth.\n\nAs a reminder, my remarks reflect my own views and not necessarily those of the Federal Reserve Bank of New York or the Federal Reserve System.\n\nAs highlighted in the June FOMC statement and economic projections of FOMC members, the economy is expected to expand at roughly 2.0-2.5 percent per year over the next several years, in line with the average pace of the expansion experienced since the end of the Great Recession.  The Committee\u2019s assessment was that the upside and downside risks to U.S. growth are nearly balanced. \n\nDespite some softness in the first quarter, there are a number of reasons to expect a return to ongoing moderate growth going forward.  Consumers are benefiting from improved balance sheets, low debt service burdens, the positive wealth effects of higher house and equity prices, and nearly a percentage point increase to real disposable incomes due to lower energy prices. The labor market has continued to strengthen.  Workers are finally beginning to see at least modest real wage gains, and the U.S. unemployment rate has fallen to the lowest level since mid-2008.  The housing sector is now in much better balance.  The inventory-sales ratio for homes is near, or even slightly below, levels typically considered \u201cnormal,\u201d and there has been a significant drop in the fraction of households carrying mortgage balances in excess of the value of their homes.  Finally, business fixed investment outside of oil and gas seems likely to advance, reflecting high cash flows and a low cost of capital.\n\nThere are, however, also downside risks to the growth outlook.  Households could behave cautiously given the experience of the Great Recession and thus far appear to be saving a high fraction of the windfall from lower oil prices and from positive wealth effects.  Net exports have represented a notable headwind and are associated with weak domestic manufacturing activity.  These effects may continue to be felt well into 2016.  The fall in investment and employment in the oil producing sector have already been sharp and this could play out in activity over the next quarter or two, but the effects could also prove more extended.  Finally, the U.S. economy\u2019s productivity performance has been poor in recent quarters, raising questions about whether there has been a step down in the underlying trend.\n\nThe FOMC also highlighted that it expects inflation to rise gradually over the medium term from its recent low level toward 2 percent, as the labor market improves further and the transitory effects of earlier declines in energy and import prices dissipate.\n\nSome uncertainty also remains about the inflation outlook.  On the upside, recent Federal Reserve Bank of New York research suggests the economy should be near a point at which further declines in labor market slack would put greater upside pressure on wages.  Stronger wage growth could translate over time into upward pressure on inflation.  This tendency could be amplified if productivity growth remains lackluster.  However, there are also downside inflation risks.  A range of indicators points to some remaining cyclical weakness in the labor market. Healthy profit margins give U.S. firms scope for absorbing stronger wage gains without raising prices.  Also, the recent dip in productivity growth could prove temporary.  More generally, core PCE inflation has been running measurably below the Committee\u2019s 2 percent objective for some time; and the experience of other advanced economies demonstrates how difficult it can be to raise low inflation. \n\nIt is in this context that the Committee is considering the appropriate timing and pace for beginning to remove extraordinary accommodation.  The Committee stated in June that it will look at a wide range of indicators to make a data dependent evaluation, and that it will be appropriate to raise the federal funds rate \u201cwhen it has seen further improvement in the labor market and is reasonably confident that inflation will move back to its 2 percent objective over the medium term.\u201d2  Given the Committee\u2019s communication about data dependence, market participants seem to expect that economic conditions will warrant a first rate increase in the latter part of this year. \n\nProspects of U.S. monetary policy normalization have raised concerns about international spillovers particularly for emerging market economies (EME).  These concerns are understandable.\n\nLooking back at previous periods of Fed tightening, average EME economic performance has actually been strong.  For instance, industrial production growth has averaged between 7\u00bd to 10 percent in the 12 months following individual Fed tightening cycles, while export volumes have risen 10 to 15 percent.  These growth rates are comfortably above long-term averages.  A likely explanation for this favorable record is that Fed tightening has recently occurred during periods of strong U.S. economic performance.  The financial market performance of EMEs has been more varied, however.  For instance, average financial market performance was strong in the tightening cycle that began in 2004, but very weak in the 1994 tightening cycle, and more mixed in the 1999 cycle.  Of course, average performance hides considerable diversity across countries.  In the 1994 tightening cycle, for example, the economic and financial performance of emerging Asia was strong while Mexico slumped and then fell into a crisis, with contagion to Latin America more broadly.\n\nConcerns about EME economic and financial performance during Fed normalization also stem from the 2013 Taper Tantrum, when EMEs experienced sizeable weakening of their currencies, local currency and foreign currency bonds, and equity markets.  Other factors also played an important role ahead of the Taper Tantrum, including record capital inflows into emerging markets, stretched asset valuations, and weaknesses in some countries\u2019 domestic fundamentals.  Market stress was most severe for countries reliant on external financing and, in these countries, led to slower growth. \n\nThe impact of eventual Fed monetary policy normalization on EMEs will likely depend mostly on the underlying domestic economic fundamentals of individual countries and on the robustness of Fed communication.\n\nThe fundamental risk profile of EMEs has deteriorated modestly in recent years.  This reflects a combination of slowing trend GDP growth, deteriorating fiscal positions, and a build-up of domestic and external debt.  Commodity producers have experienced a more substantial deterioration in fundamentals.  Compared to conditions prevailing ahead of the Taper Tantrum, more recently capital inflows to EMEs have been more muted, valuations of emerging market assets are lower, and market pricing appears to be differentiating countries to a greater extent based on fundamentals.\n\nStill, many of the structural strengths that have enabled EMEs to weather recent periods of market strain remain largely in place; the most important of which is the presence of flexible and credible macroeconomic and monetary policy frameworks. A continued focus on implementing predictable policies, consistent with inflation and external sustainability objectives, will be important to help EMEs manage through potentially turbulent markets associated with the normalization of U.S. monetary policy.\n\nWhat accounts for the difference in EME performance across tightening cycles? Research suggests that anticipated Fed tightening moves have historically been followed by a minor pullback in private capital inflows, while unanticipated tightening moves have typically been followed by a pullback in private capital flows some four times as large.3 Research also suggests that the economic and financial performance of EMEs tends to be favorable when U.S. long-term yields rise because U.S. growth prospects are higher, as opposed to when U.S. yields rise because there is a monetary surprise not associated with higher U.S. growth prospects.4 This highlights the importance of transparency and clear messaging by the Fed about how it is evaluating the evolving economic landscape, to reduce the risk that policy adjustments might be associated with undue market volatility.   \n\nShifts in Fed monetary policy can also impact advanced economies and spill back to the U.S.  For instance, President Draghi highlighted that financial conditions associated with Fed exit discussions contributed to the ECB\u2019s decision to bring euro area interest rates down to their effective lower bound and strengthen forward guidance in 2014.5  Monetary policy actions by other central banks can also impact international markets, including U.S. bond and currency markets. There is growing evidence that unconventional monetary policy actions by the ECB have impacted U.S. and other markets.6\n\nFor all central banks, and the Fed in particular at this stage, it is important to clearly communicate assessments about the economy, the financial system and the stance of policy.\n\nLet me now add a few thoughts about ongoing financial reform efforts.  The complexity, severity and speed of the global financial crisis required a forceful and wide-ranging international regulatory response.  This has included higher capital and liquidity standards as well as stronger recovery and resolution regimes for supervised institutions, and greater transparency and standardization in derivatives markets.  These efforts will have a number of positive effects, and may lead to some changes in bank business models and strategy in the U.S. and internationally.\n\nIn the U.S., regulatory reforms have made the banking system much stronger than before the crisis.  In aggregate, Tier 1 risk-based capital ratios among U.S. bank holding companies have increased to 12.6 percent, an increase of almost 40 percent relative to pre-crisis levels, and the quality of capital has improved.  This progress is also evident in firms\u2019 forward-looking, post-stress capital positions as assessed under the CCAR process. In the latest exercise, firms had a significantly higher post-stress Tier 1 common ratio of 7.1 percent, compared to their starting position of 5.3 percent in the 2009 SCAP exercise. \n\nBank holding company balance sheets are also significantly more liquid, with liquid assets increasing from 30 percent of total assets at end-2006 to just over 40 percent as of the first quarter of 2015.  Core deposits now fund 47 percent of total assets, a more than 10 percentage point increase from pre-crisis levels.  A stronger U.S. banking system better protects against future shocks, provides a more solid foundation for growth, and therefore also enhances prospects for growth and financial stability abroad.\n\nI would like to briefly touch on two U.S.-specific financial regulatory issues with international implications, namely enhanced prudential standards for foreign banks - including intermediate holding company requirements for the largest institutions -, and issues surrounding correspondent banking, U.S. anti-money laundering rules, and \u201cde-risking\u201d.  Of these, the latter may be more relevant for emerging market economies and the former may be more relevant for advanced economies.\n\nThe adoption of Regulation YY, Enhanced Prudential Standards for Bank Holding Companies and Foreign Banking Organizations (FBOs) is a key element of U.S. regulatory reforms, and a significant change in supervision of FBOs.7  The largest FBOs with U.S. non-branch assets greater than $50 billion must hold their U.S. subsidiaries under an intermediate holding company (IHC), and meet various capital, leverage, liquidity, stress testing, risk management and corporate governance requirements.  These requirements respond to a mandate in the Dodd-Frank Act for enhanced standards for the largest domestic and foreign banks.  Firms have submitted their IHC implementation plans for review. The most significant requirements are expected to fall on the largest FBOs from advanced economies\u2014some of which have also adopted tighter local requirements for foreign banks\u2014and should contribute importantly to a safer and sounder U.S. and international financial system. The IIB has played a constructive role on this topic by offering comments on the original proposal and by providing assistance in organizing its members to discuss the implementation plan requirement with the Federal Reserve.\n\nCorrespondent banking relationships have also received heightened attention in the context of serious violations of anti-money laundering and know-your-customer standards by some banks, and substantial associated fines.  It is imperative to firmly deal with illegal, unsafe and unsound banking practices, including money laundering and transactions with U.S.-sanctioned countries.\n\nIt is also important to be on the look-out for potential unintended consequences and externalities, such as widespread de-risking where correspondent bank access is shut off to compliant counterparties and to legal flows, economic costs are increased, or flows migrate to avenues subject to less oversight or transparency.  The scope, scale, and impact of de-risking need to be better understood.  Dialogue between market participants and the official sector is ongoing.\n\nLet me conclude.  The U.S. economy and financial system have strengthened notably in recent years and in a mutually reinforcing way.  Monetary, supervisory and regulatory policy need to be tailored to domestic U.S. conditions.  In the context of its domestic objectives, the Fed is also mindful of the international effects of its policies, given the central place of the U.S. in the global financial system, and the potential for spillbacks to the U.S. economy and financial conditions.  Policies that make the U.S. economy and financial system strong and stable are most likely to generate positive spillovers to the rest of the world. Fed communication about the evolution of the economic and financial landscape is critical for these positive spillovers to occur. \n\nThank you for the opportunity to speak to you today.\n\n1 Idanna Appio, Gerard Dages, Matthew Higgins, David Hou, Siobhan Sanders and Kevin Stiroh assisted in preparing these remarks.\n\n2 See June 17, 2015 Federal Open Market Committee statement.\n\n3 \u201cInternational Capital Flows:  Reliable or Fickle?\u201d  World Economic Outlook,  April 2011, Chapter 4.\n\n4 See \u201cSpillovers from Unwinding Monetary Support in Advanced Economies,\u201d 2014 Spillover Report, Chapter 2.  See also, \u201cOn the Receiving End:  External Financial Conditions and Emerging Market Growth Before, During and After the Global Financial Crisis,\u201d World Economic Outlook, April 2013, Chapter 4.\n\n5 \u201cThe ECB\u2019s recent monetary policy measures: Effectiveness and challenges\u201d, Mario Draghi May 14, 2015.\n\n6 \u201cEvaluating Asset-Market Effects of Unconventional Monetary Policy:  A Cross-Country Comparison,\u201d Rogers, Scotti, and Wright, (March 2014); \u201cECB Unconventional Monetary Policy Actions:  Market Impact, International Spillovers and Transmission Channels,\u201d Fratzscher, Duca, and Straub (November 2014).\n\n7 Enhanced Prudential Standards for Bank Holding Companies and Foreign Banking Organizations, Federal Register, Vol. 79 No. 59, March 27, 2014."
  },
  {
    "title": "The U.S. Economic and Monetary Policy Outlook",
    "date": "Jun 5, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150605",
    "content": "Good morning.  It is a pleasure to be here in Minneapolis today and to have the chance to speak to all of you.  As chairman of the Economic Club of New York, I particularly appreciate the role that the Economic Club of Minneapolis has played in organizing this event. \n\nIn my remarks, I am going to focus on the economic outlook and the implications of that outlook for monetary policy.  Today, I come before you as the proverbial two-armed economist.  On one hand, the economy\u2019s forward momentum has slowed sharply during the first half of the year and inflation remains below the level the Federal Open Market Committee (FOMC) views as consistent with price stability.  On the other hand, I think it is also fair to say that we are still making progress towards our dual mandate objectives.  However, recent solid job gains and a further decline in the unemployment rate have occurred only because productivity growth has slowed markedly.  \n\nDuring the remainder of the year, I expect growth to pick up somewhat.  However, productivity growth will also likely rise.  So there remains some uncertainty about whether growth will be strong enough to lead to further improvement in the labor market. \n\nWith respect to inflation, as long as growth remains strong enough to lead to further improvement in labor market conditions\u2014and this is an important caveat\u2014I am becoming more confident that inflation will move up toward the FOMC\u2019s 2 percent objective over the medium term.  The firming of inflation that I anticipate reflects my expectation that resource utilization will increase and the fact that some of the factors that have pulled down inflation, such as lower oil and gas prices and a firmer dollar, have already stabilized or partially reversed. \n\nPutting this all together, I still think it is likely that conditions will be appropriate to begin monetary policy normalization later this year.  But the likelihood and timing will depend on the economic outlook, and that will be largely shaped by the incoming economic data. \n\nWhen the FOMC begins to raise short-term interest rates, this will occur in a very different environment than in the past.  Reserves in the banking system are very plentiful, reflecting the large increase in the Federal Reserve\u2019s balance sheet over the past few years.  But this circumstance should not adversely affect our ability to push the federal funds rate into a higher target range.  We have the appropriate tools to push up short-term interest rates.  However, lift-off may not go so smoothly in terms of the impact on financial asset prices.  After all, lift-off will represent a regime shift after more than six years at the zero lower bound.\n\nMore important for financial market asset prices than the precise timing of lift-off is the expected trajectory of short-term rates over the next few years following lift-off.  Most likely, this will be a shallow, upward path.  Because of the persistent headwinds associated with the recent financial crisis, the level of real short-term interest rates consistent with a neutral monetary policy seems considerably lower now than in the past.  And, if potential GDP growth is much lower\u2014due to slower labor force growth and productivity growth\u2014the long-run equilibrium real short-term rate is also likely to remain lower than normal in the future even after those headwinds fully dissipate.\n\nBut there must be considerable uncertainty about the path for short-term interest rates.  After all, the economic outlook is uncertain.  Moreover, the appropriate stance of monetary policy will be influenced by how financial market conditions respond to the Federal Reserve\u2019s actions.  All else equal, if financial conditions tighten sharply, then we are likely to proceed more slowly.  In contrast, if financial conditions were not to tighten at all or only very little, then\u2014assuming the economic outlook hadn\u2019t changed significantly\u2014we would likely have to move more quickly.  In the end, we will adjust the policy stance to support the financial market conditions that we deem are most consistent with our employment and inflation objectives.\n\nAs always, what I have to say today reflects my own views and not necessarily those of the FOMC or the Federal Reserve System.1\n\nThe Economic Outlook\n\nTurning first to the economic outlook, the real GDP growth rate appears to have slowed sharply during the first half of 2015.  Based on the revision we received last week, first-quarter real GDP fell by 0.7 percent at an annualized rate. Although most projections anticipate a pickup in growth to around 2 percent or slightly higher in the current quarter, there is little question that economic growth has slowed significantly from last year\u2019s second-half pace. \n\nWhat\u2019s going on?  Why has growth slowed and what does this portend for the remainder of the year?\n\nAs I see it, the contraction in GDP growth in the first quarter represents a mix of factors.  These include another unseasonably cold and snowy winter, a sharp contraction in oil and gas investment, a deterioration in the trade balance due\u2014in large part\u2014to the stronger dollar and sluggish foreign demand, and a slowdown in consumer spending growth after a very strong fourth quarter. \n\nAfter adjusting for weather effects, I think seasonal adjustment issues probably also played some role.  For example, real defense spending has declined eight times in the past nine years in the first quarter, suggesting there is a seasonal adjustment issue.  But I judge that this has had only a modest effect on measured real GDP growth.   \n\nBecause weather effects are by their nature temporary, the widely held expectation coming into the second quarter was that there would be a sharp rebound in growth similar to what took place last year. But current data suggests that the rebound has been relatively muted.  I think this is because some of the non-weather factors evident in the first quarter\u2014such as the drag from the sharp drop in oil and gas investment\u2014have persisted into the second quarter.  Also, real disposable income growth has slowed over the past three months as aggregate hours worked have grown more slowly and crude oil and gasoline prices have partially recovered.  This means that the fundamentals for consumer spending are not as strong as they were at the beginning of the year.\n\nNonetheless, my view is that growth will likely pick up further during the remainder of this year.  This judgment reflects several factors.  First, some of the forces that have been restraining growth are likely to fade later this year. For example, consider oil and gas investment.  The U.S. oil and gas rig count dropped precipitously during the first quarter, but the rate of decline has slowed during the current quarter.  Combined with the partial recovery in crude oil prices, this implies that oil and gas investment is likely to stabilize during the second half of the year. \n\nSecond, business fixed investment outside of oil and gas seems likely to advance, reflecting strong fundamentals.  For example, the cost of capital remains low and cash flows are high. \n\nThird, there is plenty of room for further gains in residential investment.  Housing starts have been running at an annual pace of only about one million so far this year.  This is low relative to both the rate of household formation that one would expect given underlying demographics and the rate of job formation.  Moreover, continued improvement in mortgage credit availability should support the demand for new housing.  Household credit worthiness is improving as the scars of the financial crisis heal, and underwriting standards may be relaxed somewhat in response to the excellent performance of recent mortgage vintages. \n\nFourth, household finances generally are in good shape with debt service burdens at historically low levels.  Nonetheless, household borrowing has been rising only very slowly, and the personal saving rate is somewhat elevated relative to what one would expect given the level of household net worth relative to income.  This suggests that if households become more confident about their finances, consumer spending should grow at least as fast as income growth over the remainder of the year.   \n\nBut, I can\u2019t be completely confident about this forecast.  After all, several times during this expansion we have been fooled by sharp rises in the growth rate that appeared to presage a sustained pickup, but that subsequently proved fleeting.  Moreover, faster consumption growth is not a given.  It will depend, in part, on the pace of employment and wage growth. A downside risk is that wage growth remains subdued, which would undercut consumer spending. And, the trade sector looks likely to remain a drag on growth over the remainder of the year.  Although the dollar has depreciated slightly on a broad trade-weighted basis recently, it still is more than 10 percent higher than it was a year ago. \n\nDespite the sharp slowdown in growth evident during the first half of the year, we have seen continued job gains and further falls in unemployment so far this year.  Consequently, we still seem to be making progress toward our objective of maximum employment in a context of price stability. \n\nToday\u2019s payroll and household employment reports indicate that this progress continued into May.  Even with a weak month in March, job gains this year have been averaging almost 220,000 per month.  The gain in May was even stronger at 280,000 and was widespread across industries.  Although the 12-month change in average hourly earnings is still low at 2.3 percent, it is a bit higher than we have seen in recent years.  At the same time, there is still some ways to go.  The unemployment rate has changed little in the past four months at about 5\u00bd percent, with the levels of part-time workers for economic reasons, and long-duration unemployed, remaining elevated.\n\nThis combination of slow output growth and continued job gains has meant that productivity growth has been unusually weak, with non-farm business productivity declining significantly during the past two quarters and rising by only 0.3 percent over the past year.  It also implies that the future path of productivity growth will be important in determining the outlook for employment growth and the prospects for further progress in U.S. labor market conditions. \n\nBecause it is unclear exactly why productivity growth has slowed recently, it is difficult to be confident about what it will do in the future.  One reading of the data is that some of the slowing seems likely to be persistent.  For instance, the weakness in capital spending evident during much of this economic expansion means that the contribution to productivity from capital deepening has dropped sharply in recent years.2  Also, the U.S. labor market appears to have become less dynamic\u2014perhaps due, in part, to an older workforce.  Less movement of workers across jobs could lead to a less efficient allocation of workers\u2019 skills, which would hurt productivity growth. \n\nThat said, it seems unlikely that productivity growth will remain as weak as it has been over the past year.  There is considerable evidence that technological progress continues at a healthy pace.  Just look at the advances that have occurred in health care, oil and gas extraction and the development of smartphones.  Moreover, because it takes time for technological advances to be adopted broadly throughout the economy, it seems unlikely that the productivity gains from recent innovations have yet been fully realized. \n\nBecause I am uncertain about the near-term trends of GDP growth and productivity growth, I am also uncertain about whether we will see further progress in the labor market over the remainder of the year.  There are many possible outcomes to consider.  For example, if real GDP growth were to pick up more than productivity growth, then employment growth would likely remain sufficiently firm to lead to further tightening of the U.S. labor market.  But, if the reverse occurs, then payroll gains could slow even as GDP growth strengthens.  \n\nIn contrast to my uncertainties about growth and the labor market, I am becoming more confident that inflation will return to our 2 percent objective over the medium term, as long as the labor market continues to improve\u2014an important caveat.  The reasons here are straightforward.\n\nFirst, a number of factors that threaten to keep inflation below our 2 percent objective appear to be transitory.  In this camp, I put the sharp decline in oil and gasoline prices that began in mid-2014, and the weakness we have seen in nonpetroleum import prices due to the strength in the dollar.  When the effects of these transitory influences wane, inflation will begin to move closer to our 2 percent objective for the personal consumption expenditures deflator. \n\nSecond, the tightening of the labor market may soon lead to some strengthening in the labor compensation trend.  Although the recent data are as a whole inconclusive, I find it noteworthy that the four-quarter change of the Employment Cost Index for all civilian workers, which I view as the most reliable indicator of labor cost trends, rose by 2.6 percent as of the first quarter of this year, up from around 2 percent in the first quarter of 2014.  Also, work done by my staff suggests that we are at that point in the labor market recovery where, in the past, we have typically seen a pickup in wage compensation.\n\nThird, the risk that inflation expectations, which are important in influencing inflation outcomes, might become unanchored to the downside seems to have diminished.  In particular, anxieties created by the decline in breakeven inflation compensation measures based on the relative yields of nominal Treasuries versus TIPs have lessened.  For example, the 5-year forward, 5-year inflation compensation measure has climbed by about 25 basis points from its low point in late January.3  \n\nImplications for Monetary Policy\n\nSo what are the implications of the economic outlook for U.S. monetary policy?  As the FOMC noted in its most recent statement in late April, the Committee is looking for two conditions to be satisfied for the normalization of monetary policy to start: \u201cfurther improvement in the labor market\u201d and that the Committee \u201cis reasonably confident\u201d that inflation will return to the FOMC\u2019s objective over the medium term.  I think these are reasonable criteria.\n\nI would note that these criteria are not independent.  All else equal, for example, further improvement in the labor market should make one more confident about the inflation outlook.  But improvement in the labor market, while necessary, is not a sufficient condition.  For example, if labor market improvement were not accompanied by a meaningful uptick in wage compensation and if inflation expectations also fell, then one likely would not be reasonably confident about inflation returning to 2 percent over the medium term. \n\nFor me, at present, the uncertainties rest more on the outlook of the labor market.  If the labor market continues to improve and inflation expectations remain well-anchored, then I would expect\u2014in the absence of some dark cloud gathering over the growth outlook\u2014to support a decision to begin normalizing monetary policy later this year.\n\nWhen the normalization process starts and we raise the target range for the federal funds rate, what should we anticipate?  I anticipate a smooth lift-off in terms of the ability of the FOMC to push the federal funds rate up into a higher range.  Less clear is what the financial market reaction will be.  Will it be more like the turbulent taper tantrum of 2013 in response to Chairman Bernanke\u2019s remarks that we might at some point begin to taper our asset purchases, or the benign response when the FOMC actually tapered in 2014?  Let me consider these two issues in turn. \n\nI am very confident that the Federal Reserve has the tools in place to ensure that the FOMC can successfully raise the federal funds rate into a new, higher target range when the time comes to do so.  This reflects several factors.  Most importantly, we have demonstrated that the interest rate paid on banks\u2019 reserve balances (IOER)\u2014which is our primary tool to raise the federal funds rate target\u2014and daily overnight reverse repo (ON RRP) operations\u2014which is a supplementary tool to help put a floor under money market rates\u2014have been effective in keeping the federal funds rate well within the FOMC\u2019s desired target range.  Moreover, in the unlikely event that the rates we initially selected for the IOER and ON RRP were insufficient to move the federal funds rate into the desired range, we could alter the level of these rates and/or the spread between these rates so as to move the federal funds rate into the desired range.  Finally, we also have other tools, such as the Term Deposit Facility and term reverse repo that could be used if needed to help achieve the targeted range for the federal funds rate.  While I don\u2019t expect that these tools will prove necessary, it is nice to have them available should we need to deal with unanticipated contingencies. \n\nHow will financial markets react to the onset of normalization?  My own view is that there likely will be some turbulence.  After all, lift-off will represent a regime change after more than six years at the zero lower bound.  Recognizing this, we have a responsibility to minimize the amount of potential turbulence by communicating clearly in order to reduce uncertainty about conditions surrounding lift-off and the likely aftermath of lift-off.  This means being clear about what factors are important in driving the timing of lift-off.  However, this does not mean providing advance notice about precisely when lift-off will occur because the timing should depend on the incoming economic news and how this influences the economic outlook.  Instead, if you pay attention to the incoming economic news and listen to our assessment about how the outlook is evolving, then I think you will be able to judge for yourself when lift-off is likely. \n\nWhat also matters for financial asset prices is the likely post-lift-off trajectory of short-term rates over the medium- to longer-term. In fact, this should be more important than the particular month in which the normalization process starts.  On this score, I think it is hard to be precise about the expected path of short-term rates.  That is because it depends on two important factors: (1) how the economic outlook evolves, which depends, in part, on how loose or tight monetary policy actually is at a given level of short-term rates, and (2) how financial conditions broadly react to changes in the level of short-term rates.\n\nMy own view is that the upward trajectory of short-term rates is likely to be relatively shallow.  This reflects several factors.  First, the lack of strong forward momentum in the economy despite the low level of short-term interest rates suggests that U.S. monetary policy is not as accommodative as one might think.  In particular, the lack of strong momentum suggests that the real equilibrium federal funds rate today is considerably lower than the 2 percent rate assumed in the standard Taylor Rule formulation.  Work done by my Federal Reserve colleagues, Thomas Laubach and John Williams, suggests that the so-called neutral real federal funds rate today may be close to zero.4  This presumably reflects still-persistent headwinds from the financial crisis, such as the constraints on mortgage credit availability to prospective borrowers with lower FICO scores.  Second, one might expect that it will still take additional time for these headwinds to fully subside.  This implies that the neutral short-term rate may be depressed for some time.  Third, my assessment is that the long-run equilibrium real federal funds rate is lower now than in the past, reflecting the likelihood that potential real GDP growth is lower due to slower growth of the labor force and more moderate productivity growth performance. \n\nAnother important factor that will affect the trajectory of short-term rates is how financial market conditions respond to a rise in short-term rates.  Monetary policy works on the economy through how it affects financial market conditions.  Economic conditions at any point in time warrant a particular set of financial market conditions so the FOMC can best achieve its objectives of maximum employment and price stability.  The FOMC chooses a policy stance to help support financial market conditions that will lead to economic outcomes consistent with its objectives. \n\nAn important aspect of current financial market conditions is the very low bond term premia around the globe.  If a small rise in short-term rates were to lead to an abrupt increase in term premia and bond yields, resulting in a significant tightening in financial market conditions, then the Federal Reserve would likely move more slowly\u2014all else equal.  As an example, consider the experience of the 1994-95 tightening cycle.  Bond yields rose sharply and the Federal Reserve tightened less than what was ultimately priced in by market participants.  Conversely, if term premia and bond yields were to remain low and the economic outlook suggested that financial conditions needed to be tighter and a rise in short-term rates did not generate this outcome, then the FOMC would likely need to raise short-term rates further than anticipated.  The 2004-07 tightening cycle might be a good example of this.  The FOMC ultimately pushed the federal funds rate up to a peak of 5.25 percent, in part, because the earlier rise in short-term rates was generally ineffective in tightening financial market conditions sufficiently over this period.5  \n\nThis means that there is uncertainty about the trajectory of short-term rates from two distinct sources: (1) the economic outlook and what setting of financial conditions this implies is appropriate, and (2) what setting of short rates is consistent with the financial market conditions that the FOMC is seeking to generate.  This also suggests that market participants should be cautious in interpreting the Summary of Economic Projection \u201cdot plots\u201d that show the FOMC participants\u2019 modal outlooks for the short-term rate trajectory.  If the participants were to provide confidence bands around their paths, they probably would be very wide because the economic outlook is uncertain and the linkage between the instrument of monetary policy\u2014the federal funds rate target range\u2014to financial market conditions is loose and variable.  \n\nIn conclusion, I believe that the FOMC is continuing to make progress towards our dual mandate objectives.  However, I have become somewhat more uncertain about the growth outlook given the lack of a sharp rebound in economic activity in recent months from the weak first quarter.  With respect to inflation, as long as we see further improvement in the labor market and anchored longer-term inflation expectations, I am somewhat less worried that inflation will stay too low.  Thus, I continue to expect that monetary policy normalization is likely to begin later this year.\n\nLonger-term, I expect that the trajectory of short-term interest rates after lift-off will likely be relatively shallow.  This is due, in part, to my reading that monetary policy today is not as accommodative as one might think judging just from the level of short-term rates.  But, the path will ultimately be determined by how the economic outlook evolves and how financial market conditions respond to monetary policy.  I expect that there will be many twists and turns in the road ahead.  As we make this journey, I will do my best to explain what I am seeing and how I think I might react as conditions change in the future. \n\nThank you so much for your kind attention.  I would be happy to take a few questions. \n\n1 Jonathan McCarthy, Richard Peach, Paolo Pesenti and Joseph Tracy assisted in preparing these remarks.\n\n2 For example, see Alan Blinder, \u201cThe Mystery of Declining Productivity Growth,\u201d Wall Street Journal, May 14, 2015.\n\n3The data on inflation compensation come from the Federal Reserve Board of Governors website at www.federalreserve.gov/econresdata/feds/2008/ and is based on Refet Gurkaynak, Brian Sack, and Jonathan Wright (2010), \u201cThe TIPS Yield Curve and Inflation Compensation,\u201d American Economic Journal: Macroeconomics 2(1), 70-92.\n\n5 With the benefit of hindsight, one could argue that the Federal Reserve should have raised short-term interest rates more aggressively over this period."
  },
  {
    "title": "Opening Remarks at the Mortgage Contract Design: Implications for Households, Monetary Policy, and Financial Stability Conference",
    "date": "May 21, 2015",
    "speaker": "1",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/mca150521",
    "content": "Good morning, and welcome to the Federal Reserve Bank of New York. \nToday is the second and final day of our conference on mortgage contract design.  We are hosting this conference, in association with the NYU Stern Center for Real Estate Finance Research, because we view mortgage design as an important policy issue, with implications for monetary policy, household finance and risk management, as well as for the structure and stability of the financial system. \n\nMortgage debt is, by far, the largest household financial liability.  According to New York Fed data2, mortgages and home equity lines of credit make up 73 percent of U.S.  household debt, amounting to $8.7 trillion in liabilities outstanding.  Mortgage design also varies in striking ways through time and across countries and even regions; for example, in terms of the sensitivity of mortgage rates to market rates, borrowers\u2019 ability to pay down or increase the loan balance, the ease with which loans can be modified, and the rights of junior lien holders.  Reflecting this international diversity, we are very happy to have panelists from the United Kingdom, Sweden and Denmark speaking today, as well as representatives from many foreign central banks and other international organizations in the audience. \n\nThis is also a particularly opportune time to think about mortgage contract design given the ongoing debate about housing finance reform in the U.S.  , and the future of the government sponsored enterprises Fannie Mae and Freddie Mac. \n\nBut debates about mortgage design are definitely not new! In fact, 40 years ago the Federal Reserve Bank of Boston hosted a well-known conference on \"new mortgage designs\"3, which included Franco Modigliani, later awarded the Nobel prize in economics, and current Federal Reserve vice chair Stanley Fischer.  An interesting contrast to today\u2014the main focus of the Boston conference was the design of mortgages to deal with a high and volatile inflation environment. \n\nThe financial crisis and its aftermath have brought mortgage contract design back into sharp focus.  In my remarks today I will focus on one aspect of mortgage design; namely how the prevalence of adjustable rate mortgages, or ARMs, may affect a number of aspects of economic performance, including the pass-through of monetary policy, the sharing of interest rate risk, and the use of resources spent on refinancing. \n\nThe federal funds rate dropped from 5-1/4 percent in August 2007 to the current 0-25 basis point range starting in December 2008.  Longer-term interest rates such as the yield on 10-year Treasury bonds also declined significantly, from about 5 percent in mid-2007 to a range between 2-3 percent in recent years.  As illustrated in the chart, however, the average interest rate paid on the total stock of outstanding mortgages in the U.S.  decreased relatively slowly and by a smaller amount over this period. \n\nThe source of the stickiness in mortgage interest rates is that the vast majority of outstanding mortgages in the U.S.  are long-term fixed-rate mortgages, whose pricing is tied to long-term interest rates, and which require borrowers to refinance to benefit from a decrease in market rates.  This refinancing process in earlier episodes has worked quite smoothly in transmitting lower market interest rates to the mortgage market\u2014in particular during the large refinancing wave in 2002-2003.  But during the crisis, many borrowers were unable to refinance either because their property was worth less than the outstanding mortgage balance, or because they didn\u2019t otherwise fulfill underwriting criteria that had also become much more stringent than during the boom. \n\nThese features surely limited the transmission of accommodative monetary policy through households\u2019 balance sheets.  Furthermore, borrowers that were able to refinance and benefit from lower interest rates were mostly those with high credit scores and relatively lower debt balances.  The Administration responded to this limited pass-through by introducing programs such as the Home Affordable Refinance Program, or HARP, to enable refinancing for borrowers with high-LTV loans backed by Fannie Mae or Freddie Mac, or facilitating streamline refinances of FHA loans.  While these programs eventually reached a large number of borrowers, their implementation was complex. \n\nAs a simple mortgage design counterfactual, had more borrowers had adjustable-rate mortgages, which are generally indexed to short-term interest rates, the pass-through of lower market interest rates would have been more direct.  As the Chart illustrates, the average interest rate on outstanding ARMs declined more rapidly than the rate on FRMs, even though in the U.S.  most ARMs only adjust after a rather long fixed-rate period (often 5 or more years) and then only do so infrequently (generally once or twice a year). \n\nCrucially, ARM interest rate resets reduced mortgage payments without requiring the borrower to refinance, thereby benefiting a broad range of borrowers, including those with little or no home equity and/or low credit scores.  Research conducted here at the New York Fed has shown that these lower interest payments resulted in large declines in these borrowers\u2019 default probabilities4.  And two papers presented in our academic sessions yesterday found evidence that these borrowers responded by increasing their consumption of durable goods5. \n\nAll this implies that a higher share of ARMs at the start of the financial crisis would likely have enhanced the effectiveness of monetary easing in reducing foreclosures and stimulating the macroeconomy.  More generally, the pass-through of monetary policy is likely to be stronger if a high share of mortgage debt has an adjustable interest rate, both in easing and tightening phases of the economic cycle.  6 As a result, the amplitude of interest rate adjustments by the central bank may not need to be quite as large to have the same economic effect.  This may be a particularly important consideration when the economy is at or close to the zero-lower bound on interest rates, as the U.S.  and many other economies are today. \n\nA related consideration is that refinancing to a lower interest rate requires significant resource costs, which would not be incurred if the borrower\u2019s interest rate adjusts automatically when market interest rates decline.  One estimate of the cost of refinancing a mortgage, which includes costs such as those on a property appraisal or title insurance, is $2,000 plus one percent of the loan amount.  7 Under this estimate, total refinancing transaction costs over 2008-2013 exceeded $100 billion.  8 Furthermore, the re-underwriting of existing loans leads to resource constraints in the mortgage origination industry during refinancing waves, frequently followed by lay-offs when the refinancing boom is complete.  9 Timing a mortgage refinancing optimally also requires time and attention from the borrower, and can lead to refinancing mistakes, particularly by less financially sophisticated households.  10\n\nBut do these considerations make ARMs preferable to FRMs, either from the point of view of monetary policymakers, or public policy more generally? Not necessarily.  FRMs have many advantages; for example they are simple for borrowers to understand, and clearly limit household exposure to interest rate volatility.  Consider too the incidence of interest rate adjustments: widespread reliance on ARMs may have unattractive distributional consequences for monetary policy, since it implies that a larger component of monetary transmission falls on a subset of highly indebted mortgage borrowers.  A risk-sharing argument may call for the effects of monetary policy to be more evenly spread across households.  On the other hand, monetary policy might have to adjust interest rates more dramatically in a world of widespread FRMs, which would affect some potential borrowers a great deal.  Furthermore, FRMs require an extensive financial-sector risk transfer system11, which may be costly, and may concentrate risks in systemically risky ways.  Thus, there are clearly many tradeoffs that need to be carefully considered.  Moreover, as academic research has emphasized, optimal mortgage choice depends on a borrower\u2019s characteristics and financial circumstances.  It therefore seems desirable that the mortgage finance system makes a range of different contracts available to borrowers, and be open to sensible innovations in contract design.  12\n\nAlthough I have focused on ARMs, interest rate adjustability is only one of many important aspects of mortgage design that will be considered in the discussions today.  Another important issue, for example, is how home price movements are shared between the borrower and lender.  Home price risk is already partially borne by lenders and other mortgage investors, since a fall in home prices increases mortgage defaults and foreclosures, and associated credit losses.  But a number of proposals have argued that mortgage balances should be explicitly indexed to movements in home prices in some way.  13\n\nI hope I have whetted your appetite for today\u2019s events. \n\nCharts\n\n_____________________________________________________\n\n1 The views expressed in this speech are those of the author and do not necessarily reflect the views of the Federal Reserve Bank of New York or of the Federal Reserve System. \n\n2 See the Federal Reserve Bank of New York Quarterly Report on Household Debt and Credit.\n\n3See New Mortgage Designs for an Inflationary Environment for the agenda and proceedings. \n\n4 See Tracy and Wright, 2012, Payment Changed and Default Risk: The Impact of Refinancing on Expected Credit Losses, Federal Reserve Bank of New York Staff Report No.  562; and Fuster and Willen, 2012, Payment Size, Negative Equity, and Mortgage Default Federal Reserve Bank of New York Staff Report No.  582.\n\n5 See Keys, Piskorski, Seru and Yao, 2015, Mortgage Rates, Household Balance Sheets, and the Real Economy, and Di Maggio, Kermani and Ramcharan, 2015, Monetary Pass-Through: Household Consumption and Voluntary Deleveraging.\n\n6 This is also an implication of the model presented in Auclert, 2015, Monetary Policy and the Redistribution Channel.\n\n7 See Agarwal, Driscoll and Laibson, 2013, \"Optimal Mortgage Refinancing: A Closed-Form Solution\", Journal of Money, Credit and Banking, Vol.  45, No.  4, pp.  591-622. \n\n8 According to data from the Home Mortgage Disclosure Act, there were 31.8 million refinancings of first-lien single-family mortgages over 2008-2013, with an average (median) loan amount of $212,000 ($174,000). \n\n9 For evidence on the importance of capacity constraints for time-varying margins in mortgage pricing, see Fuster, Goodman, Lucca, Madar, Molloy and Willen, 2012, The Rising Gap between Primary and Secondary Mortgage Rates, Federal Reserve Bank of New York Economic Policy Review, 19(2), pp.  17-39. \n\n10 This is documented for instance in another paper presented yesterday, by Andersen, Campbell, Meisner, Nielsen and Ramadorai (2015), \"Inattention and Inertia in Household Finance: Evidence from the Danish Mortgage Market\":\n\n11 For evidence that lenders are less willing to originate FRMs if mortgage securitization markets are illiquid or frozen, see Fuster and Vickery (2015), \"Securitization and the Fixed-Rate Mortgage\", Review of Financial Studies, 28(1), pp.  176-211.  Research presented in yesterday\u2019s academic sessions finds that a bank\u2019s access to external bond finance influences the composition of mortgages it originates: see Fo\u00e1, Gambacorta, Guiso and Mistrulli (2015), The Supply Side of Mortgage Finance.\n\n12 One proposal for such innovation that would have increased pass-through during the crisis is the \"automatic stabilizer mortgage\" of Eberly and Krishnamurthy, 2014; see /research/conference/2015/mortgage_design/Eberly_Janice_052015.pdf\n\n13 Kung, 2015, discusses the equilibrium implications of such \"shared appreciation mortgages\": /research/conference/2015/mortgage_design/Kung_Edward_housingstructural_052015.pdf"
  },
  {
    "title": "Observations on Community Banking Supervision in the Second District",
    "date": "May 19, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/cal150518",
    "content": "Welcome to the Federal Reserve Bank of New York.  We are pleased to continue our annual tradition of inviting community and regional bankers from across New York, northern New Jersey, southern Connecticut, and Puerto Rico to share perspectives on opportunities and challenges for smaller banks in the Second Federal Reserve District.\n\nCommunity banks\u2014which we define generally as institutions with total assets under $10 billion\u2014remain an important focus for the Federal Reserve System and for the Federal Reserve Bank of New York, and not simply because of our statutory responsibility to ensure that state member banks and bank holding companies are managed safely and soundly and treat consumers fairly.  Community banks also help to inform one of the Federal Reserve System\u2019s roles as our nation\u2019s central bank. \n\nFor me, it\u2019s quite simply the Federal Reserve\u2019s \u201cdual mandate\u201d that makes community banks an important area of focus for the Reserve Bank and the System.  As you know, the dual mandate expressed in a 1977 amendment to the Federal Reserve Act requires the central bank to promote maximum employment and price stability in the United States, commensurate with moderate long-term interest rates.  Yet it would be impossible for the Federal Reserve to promote price stability and maximum employment without understanding the demand and supply for credit across all parts of our country and all segments of our economy.  Consequently, under our dual mandate we must understand the important segment of the economy that community banks and other smaller firms serve, which generally comprises household lending, small business lending, and commercial real estate.\n\nIn my remarks today, I\u2019d like to offer three sets of observations on community banking supervision in the Second District.  First, I\u2019ll discuss the importance of community banking from our perspectives as both supervisors and central bankers.  Second, I\u2019ll update you on practical initiatives we have launched in our District to tailor our supervisory approach better to our sense of the actual risks that community banks present.  Finally, I\u2019ll share some observations on how community and larger regional banks (which we define generally as having $10 to $50 billion in assets) have performed in our District over the past two years. \n\nAs these observations reflect my personal experiences with community and regional bank supervision, I\u2019d like to stress that these views are my own and may not reflect the views of the Federal Reserve Bank of New York or the Federal Reserve System.1\n\nTo begin, when it comes to the importance of community banks, we know that it is because of you that more Americans are able to purchase homes for their families.  It\u2019s because of you that more entrepreneurs are able to pursue their ideas and create small businesses\u2014and those small businesses matter because historically small businesses have provided one of the largest sources of new jobs for our country\u2019s economy.  We know that your competitive advantage in local markets is that you know your local business conditions and your customers better than anyone else.  We know that other, larger firms may tend to overlook the customer base you serve best.\n\nWhen the Federal Reserve Bank of New York, as both a central bank and a supervisory authority, understands not just your firms\u2019 financial health, but importantly the health of your customers as well, we develop a deeper appreciation of how the economy is faring in your part of our District.  When Reserve Banks gather similar information from community banks across the country, we can foster powerful insight for the Federal Reserve System in achieving our dual mandate.\n\nOur chair, Janet Yellen, spoke at a conference of the Independent Community Bankers of America last year in great detail about the special role that community banks play in lending to Main Street: she said she believes that \u201ca healthy financial system relies on institutions of different sizes performing a variety of functions and serving different needs.\u201d2  Consequently, from the Federal Reserve\u2019s perspective, we need diversity in the size and scope of financial institutions to ensure that all participants in our economy can be served.\n\nBeyond the critical financial services that community banks provide to depositors and borrowers in your communities, community bankers in our District have been highly engaged in sharing perspectives with us on the economy and on business conditions outside of the supervisory process.  You do so by participating actively in this annual conference; by joining community outreach meetings that the New York Fed holds across the District; and, for some, by sharing perspectives with us through a more formal consultative body called the Community Depository Institutions Advisory Council (CDIAC).  President Dudley convenes the Second District\u2019s CDIAC twice per year to seek insights from leaders in community banks, credit unions, and thrifts.  CDIAC members offer their views about what\u2019s actually happening on Main Street regarding business conditions, the demand for credit, and market practices.  And yes, they share their concerns about supervisory practices, too.  Ultimately these views are reported to a national-level CDIAC body that advises Chair Yellen and other governors. \n\nRegardless of how you share insight with us, I know from my visits across our District with you and your staff, as well as with your firms\u2019 directors, that you are not a silent bunch.  We welcome your candor and honesty.  We need to hear your concerns so that we can better conduct our statutory mandates and minimize the burden on your businesses, consistent with your firms\u2019 individual risk profiles.\n\nThis leads to my second set of observations, which concerns how we tailor our supervisory programs to your firms and our best sense of the actual risks community banks present.  One of the themes I\u2019ve heard repeatedly from directors and senior leaders at community and regional banks in our District is the strong sense that you are struggling with the volume and weight of new regulations.  U.S. supervisory authorities and other stakeholders, including Congress and state legislatures, are still evaluating the lessons learned from the financial crisis and its aftermath.  It is indeed important to ensure that our laws and regulations reflect our best understanding of what can go wrong and how we can mitigate those risks from threatening the broader economy.\n\nStill, we understand that community banks do not generally pose a systemic threat to the stability of the U.S. financial system.  Consequently, the Federal Reserve and other supervisory agencies have long sought to differentiate and distinguish our supervisory programs for the largest firms versus those of our smaller community banks.  To illustrate these initiatives, one of our Governors, Daniel Tarullo, gave a speech to the Independent Community Bankers of America two weeks ago.3  In his remarks, he reviewed a number of changes we have made or are making to tailor our supervisory approaches for community banks.  I\u2019d like to share my observations on the experiences we have had in our District related to some of those changes that Governor Tarullo cited in his speech.\n\nOne of the important initiatives that Governor Tarullo mentioned concerns our conscious effort to limit the length of examinations and the period of time that community bank staff must devote to them so that we do not disrupt your businesses significantly.  Whenever I think about the amount of time that we spend onsite at community banks, I always remember Ben Franklin\u2019s adage that fish and visitors stink in three days.  I realize that Ben Franklin\u2019s timetable may be accelerated for bank examiners.  While I am relatively confident that we will not be able to reduce our full scope examinations to three days or less at a typical community bank in the near future, the New York Fed is undertaking several steps to reduce the time spent onsite. \n\nOne initiative includes doing more homework in advance of arriving at your front door to evaluate your firms\u2019 financial condition and performance with regard to capital adequacy, earnings, and liquidity.  We can then spend the time onsite asking more focused questions about the concerns we have rather than trying to update ourselves while we are onsite and then asking questions later, which could otherwise extend the duration of an onsite examination.\n\nIn addition, we\u2019re adopting a variety of automation tools to simplify the examinations process and make it more efficient.  Increasingly, we are using a secure online platform to facilitate the electronic receipt of your responses to our requests for information in advance of our arrival onsite.  Receiving critical data and information on the firm electronically should additionally reduce both the cost to community banks of shipping boxes of information to the Reserve Bank in advance of our onsite visits and the risk of losing confidential information en route.  These secure online platforms may furthermore enable us to share information more efficiently with other responsible supervisory agencies, reducing the need for a community bank to send similar information to two or more agencies and increasing our ability to collaborate with other agencies.\n\nOn a related note, Governor Tarullo mentioned that the Federal Reserve is experimenting with the use of electronic loan files to facilitate offsite reviews of a firm\u2019s loans.  In the New York District, we know that many community banks have not yet adopted the use themselves of digital loan files, and this is not a supervisory requirement for the time being.  Consequently, we at the New York Fed do not yet have much experience with conducting loan reviews for community banks offsite using electronic files.  Some of our fellow Reserve Banks have piloted such examinations in their Districts, and we\u2019ve heard encouraging results about how conducting at least part of our regular loan reviews offsite has reduced the stress and burden on community bank staff.  We remain eager to talk to any community bank in our District that may be interested for its own purposes in moving to digital loan files, as we would like to pilot an examination in which we conduct at least part of our loan review process offsite.\n\nBeyond the initiatives that Governor Tarullo mentioned, we have a massive effort underway in the Regional, Community, and Foreign Institutions Supervision and Consumer Compliance Function (RCFI) of the New York Fed to look at all of our internal processes with a fresh eye.  We are working to eliminate unnecessary steps, smooth out cumbersome internal processes, and increase efficiency so that we can conduct our examinations and share our findings with you more efficiently and effectively. \n\nBut what does all this mean practically?  Are we able to limit the length of examinations and thereby provide community bankers with feedback sooner and reduce the burden on their daily operations?  It\u2019s still early days for our efforts, but we have documented two pilot examinations using as many of the automation tools and business process improvements as possible.  I won\u2019t cite the names of the firms involved, and I want to stress that the pilot examinations were conducted at firms that did not have serious supervisory issues.\n\nThe measure of efficiency that we are monitoring is the number of days from the start of the examination at a community bank\u2014namely, the first day our examiners arrive onsite at your firms\u2014to the close of the onsite portion of the examination.  At one firm, our adoption of new automated tools and our own internal business process improvement efforts reduced the time spent onsite at the firm from 32 days in 2011 to 18 days in 2013.  That represents just over a 40% reduction in time spent onsite over just a two-year period.  But it\u2019s even more dramatic if we look back further to a period before we were implementing these new automated tools and process improvements.  In 2009, it took us 81 days from the start of the onsite examination to conclude all of our onsite work at that same firm, compared to just 18 days in 2013.  Now admittedly 2009 represented a difficult time in our nation\u2019s and region\u2019s economic history, so it may not be the best baseline of comparison.\n\nBut we found similarly material reductions in time spent onsite at a second firm: in 2012, we had spent 39 days onsite at the second firm, and after adopting these improvements, spent just 31 days onsite in 2014.  I would remind you that we conducted the two pilot examinations at community banks that were generally in sound condition.  The efficiencies we gain may depend greatly on the underlying condition and performance of the firm we are examining.  Consequently, I cannot predict how much time we\u2019ll be able to save at future examinations as more of the tools become available.  Still, the improvement in efficiency reflects our efforts to bring community bank supervision into the twenty-first century and transform what had been a highly manual process for decades into a more automated and risk-focused process.\n\nI should also note that some community banks don\u2019t want us to conduct all of our work offsite.  They don\u2019t want our examiners to reduce their firms to a data set that we process in an offsite supervisory model.  That\u2019s certainly not how community banks do business, as it is not how you treat your customers.  So the onsite portion of examinations will remain an important supervisory tradition: we simply want to have a better strategy for our time spent onsite so that our discussions will be more focused and meaningful for both the examiners and the bankers. \n\nGovernor Tarullo similarly mentioned in his remarks the Federal Reserve System\u2019s adoption of a new risk-focused supervision program with regard to our consumer compliance work.4  I\u2019d like to share our experiences in the Second District with adopting this approach. \n\nFrom my perspective, our consumer compliance examinations fit in well with our role as both a supervisory authority and a central bank: if consumers feel that banks do not treat them fairly, the Federal Reserve will not be able to foster public confidence in the banking system, no matter how much capital banks have.  Still, we\u2019re working hard to adjust our supervisory programs for consumer compliance matters so that they make sense for the scale and risk profiles of community banks.  Please allow me to mention just two examples.\n\nFirst, in years past, we usually included all lending areas and some deposit areas in our reviews of consumer protection matters.  By adjusting our scope to focus on the higher risk lending and deposit areas, we\u2019ve found efficiencies in terms of the numbers of examiners sent onsite and the number of weeks spent onsite.  In one case, we sent eight examiners for four weeks to a community bank under our former approach, yet more recently we were able to scale that back to about half the number of examiners and one week less onsite at that particular firm.  We\u2019re still developing experience with the new approach, and I want to emphasize, as always, that when risks are higher or problems have been identified, we will devote the appropriate time and resources to understand those challenges.\n\nAs a second example, the Federal Reserve System is currently testing an automated tool to help us analyze institutional risk factors from a consumer compliance perspective.  The tool helps us to look across many firms in our District simultaneously to identify potential outliers and new products that should draw more of our examiners\u2019 attention.  This tool and others should put us in a better position to focus our consumer reviews appropriately and in a more risk-sensitive way.\n\nSo far, I\u2019ve discussed some observations about why community banks matter to us as supervisors and central bankers, and I\u2019ve also discussed some of the practical efforts underway to tailor our supervision to the general lower risks that community banks pose to the economy.  Now I\u2019ll move on to my third set of observations, namely what we\u2019ve observed in community banks\u2019 performance in our District; I\u2019ll broaden this group to include regional banks ($10 to $50 billion in total assets), as they present similar stories overall. \n\nWith regard to the financial condition of community and regional banks in our District, it\u2019s been our sense that many have experienced gradual stabilization in their financial health over the past two years.  Challenges do remain in the District, as evidenced by the fact that some firms continue to have somewhat lower capital ratios.  Interestingly, capital ratios on average for our community and regional banks remain slightly below those of national peer group averages; the good news is that we\u2019ve seen few signs of deterioration in the solvency of supervised firms in our District over the past two years.  This more stable performance contrasts with a more volatile period prior to two years ago.\n\nThe key business for most community and many regional banks has historically been lending, and consequently credit risk is typically the most significant risk for such firms.  Over the past two years, we have found that indicators of credit risk as evidenced in the quality of assets on the balance sheets of regional and community banks in our District (such as weighted classification ratios of troubled loans to total lending, various measures of the ratio of the allowance for loan and lease losses related to loans, etc.) tend to compare slightly more favorably than those of peer banks nationwide.  This slightly stronger risk profile may explain why some Second District regional and community banks hold a little less capital.  To some degree, asset quality in the Second District may reflect the somewhat greater stability experienced in real estate values in our District, especially in the metropolitan area surrounding New York City, compared to other markets of the country where values fell precipitously\u2014such as Florida, Las Vegas, Phoenix, or Atlanta\u2014and for a prolonged period of time during the financial crisis.  However, we have to temper even that statement, as some individual communities in our District did experience worse shocks in housing or real estate prices during the crisis, including some that were more akin to some of the most troubled real estate markets in the country. \n\nEarnings levels for regional and community banks in the District have tended to remain positive and show some recent signs of greater stability, possibly reflecting the somewhat better quality assets underwritten and held in many firms\u2019 portfolios.\n\nIf we look to the other side of the balance sheet, we see that core deposits continue to fund the majority of assets for many Second District regional and community banks.  That\u2019s a healthy sign, as one independent study5 suggests that community banks that were more dependent on this traditionally sticky and usually well-priced sources of funding fared better than those that relied more on wholesale funding sources during the financial crisis. \n\nSo I\u2019ve shared with you why we view community banks as important to informing our work as supervisors and central bankers; I\u2019ve talked about how we are tailoring our supervisory approach to reflect the actual risks that community banks present to the economy, which generally are lower compared to that of larger firms; and I\u2019ve shared some observations that community and regional banks in our District are showing signs of stabilization over the past few years, though the story remains mixed.\n\nWhat does all of this mean?\n\nIt means that those of you who have been leading community and regional banking organizations in our District have steered your firms through one of the toughest financial crises in generations.  Moreover, you are still navigating well the fog-covered waters of continued economic challenges.\n\nYour accomplishments remind me of one of the observations that Will Rogers, the cowboy humorist of the 1920\u2019s and 30\u2019s, once said.  For those who may not be familiar with him, Will Rogers was an actual cowboy who gained fame for his lasso and rope tricks in vaudeville circuses.  But he was also a largely self-educated man who took a great interest in the events of the day and quickly became known for his witty and folksy observations on politics, business, international affairs, and culture.  He was once asked how it was that he could be so funny, all the time, when discussing current events.  His answer was that \u201cThere's no trick to being a humorist when you have the whole government working for you.\"  I should stress that I\u2019m quoting his view rather than my own. \n\nDespite his wry and witty daily commentary, Will Rogers was a keen observer of people and famously said that he never met a man he didn\u2019t like.  There\u2019s one observation from Will Rogers that I think is most appropriate today. He said once, \u201cThere are basically two types of people. People who accomplish things and people who claim to have accomplished things.  The first group is less crowded.\u201d\n\nSo, looking around this room, you count yourselves among that smaller group of people who have actually accomplished something.  Critically, you\u2019ve accomplished something important.  By steering your firms through the challenges of recent years, you continued to safeguard the hard-earned savings of consumers and businesses alike in your communities.  You provided credit and other financial services to them when other, larger firms might have otherwise overlooked them.  You can be proud of that accomplishment and of the impact that you have had on your communities.\n\nBut the message I want to leave you with is that your work is not finished.  We need community bankers to continue to demonstrate sound judgment and prudent business sense in your communities.  We need you to continue to provide credit and other services to businesses and consumers alike.  We need you to offer your services in a manner that is safe, prudent, and fair.  We need you to continue to maintain close ties to your neighbors and neighboring businesses so that you can leverage your special ability to understand and build sound business relationships with community members. \n\nThe Federal Reserve and other regulatory agencies at the state and federal levels will still be there to encourage you to maintain safe and sound operations.  We\u2019ll be especially active in doing so when things may appear to be going wrong. \n\nBut ultimately only you can ensure that your firms thrive, even when times get tough.  And when you manage your firms prudently, you can continue to play a vital role in serving the banking needs of those businesses and families who call your communities their home towns.  When you thrive, you can help your communities to thrive as well.\n\nI hope that you find our conference to be useful and informative.  Thank you for joining us today. \n\n1 Deborah Arndell, Jacqueline Fenton, Jordan Light, and Wilma Sabado provided input and advice for these remarks.\n\n2 See Tailored Supervision of Community Banks. Remarks by Janet Yellen at the Independent Community Bankers of America 2014 Washington Policy Summit, Washington, D.C., May 1, 2014.\n\n3 See Tailoring Community Bank Regulation and Supervision. Remarks by Daniel Tarullo at the Independent Community Bankers of America 2015 Washington Policy Summit, Washington, D.C., April 30, 2015.\n\n4 See Consumer Affairs Letter 13-19, Community Bank Risk-Focused Consumer Compliance Supervision Program, Board of Governors of the Federal Reserve System, November 18, 2013.\n\n5 See Financial Institutions: Causes and Consequences of Recent Bank Failures, United States Government Accountability Office, January 2013."
  },
  {
    "title": "The Global Implications of Diverging Monetary Policy Settings in Advanced Economies",
    "date": "May 12, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150512",
    "content": "But before I get to the implications for EMEs and what the Fed should do or not do to mitigate the impact, a few words on the timing of normalization.  To be as direct as possible: I don\u2019t know when this will occur.  The timing of lift-off will depend on how the economic outlook evolves.  Since the economic outlook is uncertain, this means the timing of liftoff must also be uncertain.  \n\nAt the same time, though, I can be clear about what conditions are needed for normalization to begin.  If the improvement in the U.S. labor market continues and the FOMC is \u201creasonably confident\u201d that inflation will move back to our 2 percent objective over the medium-term, then it would be appropriate to begin to normalize interest rates.  \n\nBecause the conditions necessary for liftoff are well-specified, market participants should be able to think right along with policymakers, adjusting their views about the prospects for normalization in response to the incoming data.  This implies that liftoff should not be a big surprise when it finally occurs, which should help mitigate the degree of market turbulence engendered by lift-off.  \n\nNevertheless, I think it would be na\u00efve not to expect some impact.  After more than six years at the zero lower bound, lift-off will signal a regime shift even though policy would only be slightly less accommodative after lift-off than it is before.  I expect that this will have implications for global capital flows, foreign exchange valuation and financial asset prices even if it is mostly anticipated when it occurs. \n\nWhich leads to the key question I want to address in the remainder of my remarks:  What should the Federal Reserve do to minimize the impact?\n\nLike other central banks, our monetary policy mandate has a domestic focus.  Our monetary policy actions, though, often have global implications that feed back into the U.S. economy and financial markets, and we need to always keep this in mind.  \n\nFrom one perspective, the unconventional nature of monetary policy around the world adds little that is fundamentally new to the challenges that face EMEs.  Today\u2019s monetary policies simply represent a way of easing that was necessitated by hitting the zero lower bound here and elsewhere.  Central bankers have managed differences across countries in cyclical positions and policy stances many times in the past. This time should not be fundamentally different.\n\nBut, from another perspective, we have less experience operating with unconventional monetary policy, we have been in this regime for a long time and this creates more potential uncertainties.  These uncertainties put a premium on clear communication among central bankers as well as between central bankers and market participants.  In my view, an important fact is that the large scale asset purchase programs undertaken in the United States and elsewhere have dramatically shrunk the size of bond risk premia globally.  This new set of monetary policies affects financial asset prices in a different way compared to changes in short-term interest rates, and we should be humble regarding what we claim to understand about this distinction.\n\nLooking ahead, it seems likely that markets will remain focused on those vulnerabilities that they might have ignored prior to the taper tantrum in 2013. The greater premium on strong fundamentals, policy coherence and predictability will likely remain.  Although we will undoubtedly experience further bumps in the road.  I think we can remain generally optimistic about the prospects for adjustment.  But for this to occur, it will be important for market participants to appropriately discriminate across countries, rather than treating EMEs as a single group.\n\nThe good news is that many EMEs generally appear to be better equipped today to handle the Fed's prospective exit from its exceptional policy accommodation than they were during past tightening cycles.  This reflects the fundamental reforms that EMEs have put in place over the past 15 years, as well as the hard lessons learned from past periods of market stress. Among the positives are:\n\nOf course, progress has not been uniform across EMEs, and more work remains to further strengthen institutional structures in some countries.  In particular, vulnerabilities remain in several important EMEs, and some have been hit by the sharp adverse turn in their terms of trade due to the recent fall in global commodity prices.  Still, the fundamental improvements I\u2019ve cited leave many EMEs better positioned than in the past to weather those times in the cycle when the external environment becomes more difficult.\n\nThe impact that changes in Fed policy can have beyond our borders has led to calls for us to do more to internalize those impacts, or even further, to internationally coordinate policymaking.  As I\u2019ve already noted, we are mindful of the global effects of Fed policy, given the central place of U.S. markets in the global financial system and the dollar\u2019s status as the global reserve currency.  Accordingly, we seek to conduct monetary policy transparently and based on clear principles.  Promoting growth and stability in the U.S., I believe, is the most important contribution we can make to growth and stability worldwide.\n\nThere is, of course, the argument that Fed policy has been too accommodative for too long, creating risks for financial stability worldwide.  Here, I think it\u2019s important to consider carefully the counterfactual.  Would countries beyond our borders really have been better off with a weaker U.S. economy\u2014an economy that might have required exceptional monetary policy accommodation for a much longer period of time?  The fundamental issue is whether U.S. monetary policy has helped support our dual objectives of maximum employment in the context of price stability, and whether this support is consistent with a healthy global economy.\n\nWhile explicit coordination looks neither feasible nor desirable, there may be more that central banks in general, and the Fed in particular, could do to be better global stewards.  As an example, I would emphasize the importance of effective Fed communication. It is clear, in retrospect, that our attempts in the spring of 2013 to provide guidance about the potential timing and pace of tapering confused market participants.  Market participants seemed to conflate the prospective tapering of asset purchases with monetary policy tightening, and pulled forward their expectations about the likely timing of liftoff and raised their expected paths for policy rates.  Lately, we seem to have done better: the tapering down of the Fed\u2019s asset purchase program went smoothly and market participants now seem to share the assessment embodied in the FOMC\u2019s March Summary of Economic Projections that lift-off is likely to begin sometime later this year. \n\nAs you know, we\u2019ve taken a number of steps in recent years to increase transparency and improve our communications.  This includes regular press conferences by the Fed chair following FOMC meetings; the publishing of growth, inflation and short-term rate forecasts of FOMC participants; and a concerted attempt to lay out the guideposts that the FOMC will look at to assess progress toward our mandate.  We also have explained in considerable detail what tools we will use and how we will likely use them to ensure to ensure a smooth lift-off. \n\nA second area we have focused on is doing a better job safeguarding financial stability. Simply put, we failed to act both early enough and decisively enough to stem the credit excesses that spawned the financial crisis and the Great Recession.  The U.S. was not alone in this shortcoming, but given our position in the global financial system, we especially should have done better.  We've taken important steps through new legislative mandates and a broader effort to rethink our regulatory and supervisory framework.  In particular, systemically important banking organizations must now hold amounts of capital and liquidity that are better aligned with their risk profiles.  Other changes have also been implemented, such as central clearing of standardized OTC derivatives contracts, that should make the global financial system more resilient and robust. \n\nAlthough this effort remains very much a work in progress, I think it will enable us to avoid repeating the mistakes of the past decade, and enable us to take a more proactive stance toward mitigating potential future vulnerabilities.  Of course, we at the Fed are not alone here. Since the recent financial crisis, central banks worldwide have been engaged in a broad rethinking of how to better fulfill their mandates.\n\nLet me close with a final thought.  The largest problems that countries create for others often emanate from getting policy wrong domestically. Recession or instability at home is often quickly exported abroad.  Equally important, growth and stability abroad makes all our jobs at home easier.  This illustrates the externalities in the work we all do, with more effective fulfillment of our domestic mandates helping to bring us collectively to a better place.\n\nThank you for your kind attention."
  },
  {
    "title": "Fostering Economic Growth in the Bronx",
    "date": "May 8, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150508",
    "content": "I am very pleased to have the opportunity to join you today at the 17th Annual Bronx Bankers Breakfast.  I would like to thank Bronx Borough President Ruben Diaz, Jr., the Business Initiative Corporation of New York and the Bronx Overall Economic Development Corporation for the opportunity to speak about the economic outlook for the Bronx.  This is my second visit to the Bronx in the past five months.  When I was here last December, I had the opportunity to hear from various community and business leaders about what they were seeing and the issues they were facing.  Such visits are an important part of the New York Fed\u2019s outreach efforts to keep apprised of key developments in the Second District, and to identify areas where we should be directing our attention.\n\nIn my remarks today, I will focus on the outlook for the Bronx, the important role that community banks play in the local economy, as well as specific challenges facing local small businesses.  It is important to recognize that small businesses play a vital role in any economy, so fostering economic and financial conditions that allow these businesses to flourish is important to the health of the local economy.  In light of recent developments, I am optimistic about the economic prospects for the Bronx and local small businesses.  I also believe that community banks and community development organizations have an important role to play in paving the way forward.\n\nAs always, my comments today reflect my own views and not necessarily those of the Federal Open Market Committee or the Federal Reserve System.1\n\nThe Economic Outlook for the Bronx\n\nTo appreciate where we are, we need to remember where we\u2019ve been.  Those of you who are long-time Bronxites know that starting in the 1950s, but especially during the 1970s, the Bronx endured a massive economic slump.  In that one decade, the 1970s, the borough\u2019s population fell by 20 percent\u2014and by even more in many well-established neighborhoods.  As people moved out in droves, buildings were abandoned, crime increased and jobs vanished\u2014all in a vicious cycle, creating an atmosphere of despair.  Yet, the borough persevered and conditions began to stabilize and then to even improve a bit in the 1980s.\n\nToday, while there is still much progress to be made, the Bronx is in dramatically better shape on many dimensions: its economy has been growing at a brisk pace, its population is on the rise, its housing stock is being rejuvenated and many businesses are thriving, creating strong job and income growth.  This is particularly evident in neighborhoods like Hunts Point and the area around Yankee Stadium, down to the Bronx Terminal Market and beyond.  Between 2007\u2014right before the last recession\u2014and last year, employment grew by 10 percent in New York City, making it one of the best performing areas in the nation.  In the Bronx, employment grew even faster, rising by more than 14 percent.\n\nWhile job creation in the Bronx has been quite broad-based, I would like to highlight two particular industries, each very different in nature, to illustrate the diversity of Bronx\u2019s economy.  Both health services and wholesale food distribution have been flourishing here.  These sectors, on average, pay relatively well and both have been contributing strongly to overall job creation and to the borough\u2019s economic resurgence.  By health services, I don\u2019t just mean hospitals and clinics serving the local population.  For example, Montefiore Medical Center is a nationally-ranked institution in a variety of specialties as well as a highly regarded teaching hospital.  Additionally, the Albert Einstein College of Medicine is a graduate medical school and clinical research facility.  And, of course, the Hunts Point Food Distribution Center houses institutions such as the Fulton Fish Market, which moved here from lower Manhattan about a decade ago. \n\nBut, of course, these aren\u2019t the only industries driving the Bronx economy.  Just last November I visited OnForce Solar, an installer of solar heating systems located in the Port Morris section of the South Bronx. There has also been a great deal of retail development over the past decade\u2014most notably, perhaps, the Bronx Terminal Market just south of Yankee Stadium.\n\nA little known fact is that, on average, jobs pay more in the Bronx than in any other of the five boroughs, except for Manhattan.  And my regional economists assure me that it\u2019s not just the Yankees that bring up the average, although they do make a difference.\n\nThis, of course, is not to say that all is well in the Bronx.  Its poverty rate and unemployment rate are both roughly twice the national average, and higher than in any of the other boroughs.  While crime has fallen dramatically over the past two decades, it also remains higher than in the rest of the city.  Debt is also burdensome for many Bronx residents.  Delinquency rates on household debt are relatively high, suggesting that many people are financially \u201cdistressed.\u201d\n\nAll this makes it especially important to maintain the economic momentum that is improving the quality of life in the Bronx.  Community banks have an important role to play in this process. Bank lending can help businesses\u2014especially new and small businesses\u2014expand and grow jobs, and help residents invest in improving their homes, neighborhoods and communities.  Lending to small businesses and entrepreneurs requires deep knowledge of local business conditions and potential borrowers, both of which community banks have a comparative advantage in acquiring.  Former Chairman Ben Bernanke in a 2012 interview summarized this point quite well.  He stated that \u201ccommunity banks have the capacity to respond with greater agility to lending requests than their national competitors; they have more detailed knowledge of the needs of their customers and closer ties to the communities they serve.\u201d2\n\nGiven this critical role played by community banks for localities such as the Bronx, it is important to ensure that the local banking sector remains vibrant.  The financial crisis offers important lessons for community banks in this regard.\n\nLessons for Community Banks from the Financial Crisis\n\nAmerica\u2019s banking system began with community banks, and today they continue to play a critical role in the financial system.  However, the number of commercial bank charters has declined by 50 percent since 1985, with the recent financial crisis contributing to this decline. A total of 417 banks and thrifts failed between 2006 through 2011.3  Many community banks, though, not only survived but also thrived during the crisis.  Why?  What sets those banks apart from others that failed, or that survived but did not thrive?  What were some common characteristics across the successful banks?  These characteristics are undoubtedly important and will be an essential element of success in the future.\n\nSome factors that one might think are important turn out not to be critical in determining performance.  For example, asset size was generally not a factor in performing well during, and following, the financial crisis. Community banks that thrived varied in asset size\u2014from below $50 million, to as large as $10 billion in assets.  Geography, though, did matter to a degree.  By definition, community banks are not geographically diversified, so those located in states that were most severely affected by the financial crisis and the recession faced the largest challenges.  However, there are examples of banks that performed well in Michigan despite the severe economic problems that Michigan experienced; and there are examples of banks that floundered in Texas despite the solid economic performance that Texas experienced.  Here in the Second District, while we had relatively modest declines in real estate values on average, some local areas saw house price declines as serious as in the worst hit states such as Arizona, California, Florida and Nevada.\n\nRecent research has identified several characteristics common to community banks that prospered during and following the financial crisis.4 First, thriving banks exercised a comparatively conservative growth strategy during good times, with a management culture that focused on long-term franchise value and not short-term profitability.  Successful banks had lower concentrations in commercial real estate lending generally; and much lower concentrations in construction and land development loans specifically.  While profitable during the boom, these loan categories suffered the greatest losses as real estate values declined and the recession set in.  As the boom progressed, the more conservative underwriting standards of successful banks led to declines in their market shares as other banks competed for business by relaxing their standards.  However, successful banks were able to gain back this market share and then some after the bust due to the relative strength of their balance sheets.  The successful community banks were patient and conservative regarding investments\u2014desiring reasonable, sustainable returns, not necessarily \u201cspectacular\u201d returns.  It seems that their managers devised their business plans heeding Friar Lawrence\u2019s advice to Romeo as he devised his courtship plan for Juliet: \u201cWisely and slow; they stumble that run fast.\u201d\n\nOther noteworthy characteristics also identified in this research were an engaged board of directors, talented staff who were familiar with the community, sound senior management oversight and thorough due diligence before offering a new product or service.  The studies further cited successful community banks as having a strong and localized customer service focus\u2014that is, avoiding the temptation to expand into new, less familiar areas and markets\u2014and high community visibility, with staff members heavily involved in community activities, which in turn, created customer relationships built on trust.5\n\nSo what did we learn from the experience of community banks with the financial crisis?  A foundation built on good risk management practices and intimate local knowledge helped the successful banks to thrive during one of this country\u2019s most difficult financial periods.  The banks that prosper in the future will likely have characteristics similar to those that outperformed during the financial crisis.  It bears repeating that community banks are critical in keeping local economies vibrant and growing.  Strong community banks are essential to the provision of credit to small businesses in their localities.\n\nImportance of Small Business Lending\n\nIt is often noted that small businesses contribute disproportionately to employment growth in their communities.  When you dig a little deeper into this stylized fact, you discover that it is new small businesses that are responsible for this growth.  Upon reflection, this makes sense given that, by definition, old small businesses are not growing.  If they had been growing fast, they would no longer be small.  A related fact is that the failure rate is quite high for new small businesses.  Taken together, this implies that it is important to provide an environment that is conducive to new business formation.  The more new businesses that are created, the more that have a chance of surviving and growing into larger, prosperous members of the local economy.\n\nOn earlier visits in the District, I heard several small business owners voice their concern over their ability to access credit.  Based on these conversations, I asked my research staff to investigate the degree to which they could substantiate with data whether Bronx small businesses seem credit-constrained relative to other boroughs or relative to other comparable counties across the country.  They first looked at the share of small business loan amounts made in each borough relative to the share of small businesses located in each borough, using data for 2013 (the latest available at the time).  If small business credit is equally available, then we would expect to see ratios of approximately one for each borough.  What the data show is that the ratio is well below one for the Bronx and Staten Island, with the Bronx being the lowest.  This is consistent with what I heard during my last visit.\n\nBroadening the lens of the analysis, my staff then compared the Bronx to a random sample of comparable low income counties that were located in urban areas, again using data for 2013.  They looked at the ratio of the volume of small business lending per small business.  The ratio for the Bronx was $9,900 as compared to a mean ratio of $10,400 across the sample of other counties.  While lower by $500, this difference is not large.  Taken together, the evidence suggests that while access to small business credit in the Bronx seems more constrained relative to Brooklyn, Manhattan and Queens, it is relatively consistent with what is typically available in lower income counties across the country.  Of course, this may simply indicate that small businesses in lower income areas of the country are generally constrained in their credit access.\n\nAnother way to investigate the question of credit constraints is to look for evidence that would reflect the consequences of these constraints.  For example, more constrained access to credit might result in a slower rate of new business formation.  My staff analyzed small business starts between 2010 and 2013.  For the Bronx, the number of small businesses per capita grew at a 12 percent rate over that period, double the average rate for the sample of 50 lower income counties.  This evidence can be viewed in multiple ways.  My take is that, in general, it is difficult to prove or disprove the presence of credit constraints with the available data, especially at the county level.  In the case of the Bronx, we found evidence both for and against the proposition.  In either case, we take seriously the feedback from local businesses that they perceive access to credit to be a problem.  The question then becomes what can be done to improve the situation going forward.\n\nNot surprisingly, most loans to small businesses tend to be small. Microloans\u2014defined $100,000 or smaller\u2014make up 90 percent of all loans to small businesses.  These loans tend to be labor intensive and costly to underwrite relative to the returns they generate.  This combined with the higher risk associated with these loans present challenges to banks.\n\nCommunity development financial institutions (CDFIs) can help fill this space.  CDFIs are specialized financial institutions that target their efforts to areas underserved by traditional financial institutions.  They provide a range of financial products including capital for investments to start-up or expanding businesses in low-income areas.  Most CDFIs tend to be nonprofit organizations, but some are regulated institutions such as community development banks and credit unions.  Examples of CDFIs operating in the Bronx include the Bronx Overall Economic Development Corporation, the Bethex Federal Credit Union and Spring Bank.  However, CDFIs tend to make loans smaller than $50,000.  A challenge, then, is bridging the gap between the maximum loan amount typically provided by a CDFI and the minimum loan amounts typically provided by a bank.  Since the CDFIs have the relationships with the small businesses, partnerships between banks and CDFIs that increase the lending capacity of the CDFIs could be helpful.  Possible avenues to achieving this include partnerships between CDFIs and banks, as well as assisting CDFIs to better access funding from the Federal Home Loan Bank (FHLB) system.\n\nI would like to touch on three additional issues that I think would assist small businesses to be successful: financial education, certification of community organizations that assist small businesses and greater transparency for small business lending.\n\nEstablishing a thriving small business takes more than a good idea and hard work.  While both of these are essential, there are many other factors that come into play.  It is important that people starting businesses have access to financial information that will assist them in navigating the difficult way forward.  This assistance can include how to develop a sound business plan, how to enhance their credit profile, how to avoid early pitfalls such as obtaining financing with punitive interest rates and how to cultivate a banking relationship.  These will all increase the likelihood that the small business will have access to the credit it needs over time to grow and thrive.  CDFIs have been an important source of this financial education to small businesses, and these efforts should be supported and expanded.\n\nIt is critical that small businesses also know that the organizations they work with are reputable and knowledgeable.  Unfortunately, there are individuals who try to take advantage of owners of new businesses by providing them with poor advice or overcharging them for credit. Researching the backgrounds of these service providers and lenders is difficult and time intensive, leaving small business owners too often uncertain as to who to deal with.  In some cases, this uncertainty can discourage a business owner from seeking assistance.\n\nI believe that we need a better system of certification for organizations that work with small businesses.  The certification will assure a business owner that the organization has been properly vetted and has the requisite skills to assist the owner.  This not only provides assurances to business owners, but saves them the time and resources required to do this due diligence on their own.\n\nFinally, in addition to certification, it would be helpful to have consistent standards and transparency requirements for organizations that lend to small businesses.  Such standards and requirements exist for lending to households, and I believe the same justification exists to extend these requirements to small businesses.  As a result, small business owners would have greater confidence that they fully understand the terms and conditions of their loan.  This, in conjunction with the access to more financial information and education, will help small business owners make better decisions about their use of credit.\n\nConclusion\n\nIn summary, economic conditions in the Bronx are improving but more progress is necessary.  Community banks will play a key role in spurring this progress, so it is essential that they remain financially sound and engaged.  The financial crisis provides many lessons for how banks can thrive even in turbulent economic conditions.  The vitality of the Bronx and other communities depends on the ability of entrepreneurs to establish and grow new businesses.  While access to credit is important, success depends on a wide range of factors, and we need to make sure new business owners have the help they need to prosper.\n\n1 Jason Bram, Christopher Calabia, Tony Davis, Jacqueline Fenton, Claire Kramer Mills, Don Morgan, James Orr, Joseph Tracy and Luis Uranga assisted in preparing these remarks.\n\n2 The Importance of Community Banking: A Conversation with Chairman Ben Bernanke, Community Banking Connections, Third Quarter 2012\n\n3 The Future of Community Banks: Lessons Learned from Banks That Thrived During the Recent Financial Crisis by  R. Alton Gilbert, Andrew P. Meyer, and James W. Fuchs all of the Federal Reserve Bank of St. Louis\n\n4 See United States Government Accountability Office, Financial Institutions: Causes and Consequences of Recent Community Bank Failures, Statement of Lawrance L. Evans, Jr., Director Financial Markets and Community Investment, June 13, 2013. Also see Gilbert et al. (2013).\n\n5 St. Louis Federal Reserve Study Shows Community Bank Model Can Thrive in Good Times and in Bad."
  },
  {
    "title": "Negative Nominal Central Bank Policy Rates: Where Is the Lower Bound?",
    "date": "May 8, 2015",
    "speaker": "1",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/mca150508",
    "content": "The Swiss National Bank (SNB), the European Central Bank (ECB), Danmarks Nationalbank (DNB), and the Swedish Riksbank recently have pushed short-term interest rates to levels below the \u201czero lower bound.\u201d The current extent and depth of negative policy rates is unprecedented; previously only Denmark had a modestly negative policy rate in 2012 through 2014. The actions of the four central banks have led a number of commentators to ask, Is the concept of a zero lower bound on interest rates valid? If not, what might be the lower bound, if any, on nominal interest rates? Indeed, some economists have suggested that with changes to the monetary system, we could in fact eliminate the lower bound to interest rates altogether.\n\nI\u2019ll first review the reasons given by the central banks for setting negative policy rates\u2014in all cases, the negative rates were seen as a means of advancing the banks\u2019 macroeconomic objectives in the current environment. But much of my talk will focus on the unique complications associated with negative nominal interest rates and the extent to which these complications constrain how low the rates can be set.\n\nAfter outlining these challenges, I\u2019ll suggest that the zero lower bound on policy interest rates is much like the low tide mark on a beach: Standing at that border between the land and the ocean, you can continue to lower your elevation by walking into the water, but with each additional step, you will need to push against the increasing resistance of the water. There is a distinct qualitative difference between positive and negative nominal interest rates, just as there is a distinct qualitative difference between the beach and the ocean. The zero lower bound is marked by this same qualitative difference: zero is a rate below which a central bank encounters the distinctive and increasing costs of a negative nominal rate, relative to a nonnegative rate of interest.\n\nPurpose\n\nIn September 2014, the ECB lowered its deposit rate to its current level of negative 0.2 percent. More recently, in late 2014 and early 2015, the SNB, DNB, and Riksbank reduced their policy rates to levels below zero, with the SNB and DNB setting their rates at negative 0.75 percent.2 These central banks established their negative rates for various reasons. Both the SNB and DNB established negative policy rates primarily to deter capital inflows and reduce the appreciation pressure on their currencies. In the case of the ECB and the Riksbank, negative policy rates were intended to provide additional monetary accommodation to ensure price stability over the medium term and a return of inflation to the central bank objective. Money market rates in the jurisdictions adopting negative deposit rates have also moved into negative territory, suggesting that the transmission of policy rates into market rates has continued.\n\nThe central banks implement their negative rate regimes in different ways, but in each case some of the bank reserves on deposit at the central bank are subject to negative rates. In other words, some commercial banks are charged periodically for (some of) their deposits at the central bank. In addition, some central banks conduct both overnight and term repo and reverse repo transactions at negative rates.\n\nIn addition to implementing the negative policy rates, each of these central banks has employed a variety of other tools to support its policy objectives, such as significant foreign exchange intervention for both the SNB and Danmarks Nationalbank and programs of asset purchases, or quantitative easing, for the ECB and, in a smaller-scale program, the Riksbank.\n\nIn an important sense, lowering interest rates to reduce capital inflows into a currency or to provide more accommodative financial conditions is a standard practice of central banking. Lower interest rates reduce the return to saving for households and reduce the \u201churdle rate\u201d to investment for businesses. Consequently, lower interest rates tend to support both consumption and investment, and thereby increased aggregate demand. If a central bank judges that demand is insufficient, and if the interest rate is already at zero, then lowering the interest rate necessarily means setting a negative rate.\n\nA key dimension of these issues is the distinction between the nominal interest rate and the real interest rate. The nominal interest rate measures the gross interest rate at which debtors remunerate creditors. The real interest rate measures the net interest rate at which debtors remunerate creditors\u2014that is, after subtracting the inflation that is expected to occur over the period during which the debt is outstanding. It is the real interest rate that is more important in stimulating or throttling consumption and investment decisions, as economic agents\u2019 income and expenses are affected by inflation more or less equally.\n\nThe relationship between the nominal interest rate (rN), the real interest rate (rr) and the rate of expected inflation (\u03a0e) is concisely expressed in the Fisher equation, or r_N=\u03c0_\u03f5+r_r. This relationship reveals that a negative real interest rate does not necessarily require fixing the nominal interest rate at negative levels. Instead, if expected inflation is positive, then for a sufficiently low but positive nominal interest rate, the real rate of interest will be negative.\n\nOne way to think of this is to liken prices and interest rates to the speed of travel for a person attempting to ascend a downward-moving escalator. The nominal interest rate can be thought of as the person\u2019s own effort to climb the steps; the rate of inflation can be thought of as the rate of speed of the escalator itself, descending against the stair climber. If the climber is ascending as fast as the escalator descends, she makes no vertical progress. This outcome can be likened to a real interest rate of zero\u2014the nominal rate of interest just offsets the inflation eroding the value of money. If the climber ascends more slowly than the escalator descends, the outcome is analogous to a negative real interest rate. If the escalator stops for some reason, then the only way to have a negative real interest rate is for the climber to descend by climbing down the escalator\u2014a negative nominal rate of interest.\n\nIt is not uncommon for countries to experience negative real interest rates. When nominal interest rates are positive, but real rates are negative, conditions are \u201cconventional\u201d in the sense that the debtor still pays positive gross amounts of interest to creditors. So the innovation in the negative nominal policy rates we see at Danmarks Nationalbank, the ECB, the Riksbank and the SNB is in the \u201cnominal\u201d aspect of their policy. It is unusual to set nominal policy rates at negative levels. When nominal rates are negative, creditors pay debtors interest, and debtors earn interest on their debt. That is, instead of your money working for you, you have to work for your money.\n\nTo explain why we are seeing these negative nominal rates, we can invoke the Fisher equation. In Denmark, Sweden, Switzerland and the euro area, rates of inflation, and expected inflation, had been falling and were near zero. Other things equal, the resulting real interest rates were too high for comfort. In an environment of low inflation, one policy to reduce real interest rates would be to boost expected inflation. However, there may be few or no easy ways to raise those expectations quickly; policies such as quantitative easing may take time to implement and have complications of their own. An alternative approach to reducing the real interest rate, the Fisher equation suggests, is for the central bank to set a negative nominal rate.\n\nIn addition to this straightforward influence of negative nominal rates on real rates, setting negative nominal rates may stimulate the economy in less predictable and clear ways. For example, setting a negative nominal policy rate\u2014a move that is, by nature, unconventional\u2014may surprise people and thereby send a strong signal of the central bank\u2019s intent to pursue its policy objective. Such a signaling channel may reinforce the effect of the negative rate and have an independent effect on boosting inflation expectations.\n\nLowering the policy rate into negative territory can also be useful in reducing the pressure on an appreciating currency. If a country\u2019s currency is facing such appreciation pressures at a time when \u201csubstitute\u201d currencies have policy rates at or near zero, then the country\u2019s central bank may choose to move its policy rates into negative territory to reduce the yields available to market participants who are holding the currency in anticipation of a gain on sale.\n\nComplications\n\nI\u2019ll now outline seven categories of complications associated with negative nominal policy rates. While some of these complications are already relevant in an environment of low real rates of interest, most arise only when nominal rates turn negative.\n\n1. Avoidance\n\nWhy do people say there is a lower bound on interest rates at zero? Our simple proposition is that people would not invest a dollar in an account or bond from which they they could expect to recoup only an amount less than a dollar so long as they could alternatively and costlessly put their money in currency\u2014an investment in which a dollar remains a dollar. If everyone could costlessly invest in currency rather than in activities bearing negative rates, then there wouldn\u2019t be any negative rate activity in which people would invest. Consequently, the negative interest rates in many European countries indicate that it is costly to invest in currency to earn a zero nominal rate of interest.\n\nWhy is this the case? First, currency is bulky and weighty. For example, a million U.S. dollars, made up solely of $100 bills, would form a stack measuring approximately 43 inches or 109 centimeters in height and weighing 22 pounds or about 10 kilos. Consequently, currency is inconvenient to use, especially for those who seek to make large investments or payments. Second, currency is subject to theft, requiring a big investment in security and insurance. Third, recounting currency every time it is moved or transferred between people entails time and expense. Finally, currency is subject to degradation, accident, fire, counterfeiting, and other mishaps.\n\nBecause currency is costly to invest in, then we could refine the proposition we stated earlier to say that a person would invest a dollar in an account or bond that promises to pay back less than a dollar so long as the person could not preserve more of his or her initial wealth by investing in currency, net of its costs. So one might suggest that it is the negative net return on currency that establishes the lower bound to interest rates\u2014zero is only a rough approximation. This formulation is sharper, certainly, but it may also be too blunt for the following reason. Notice that the costs of handling currency vary by the size of the investment one is considering. An ordinary person, with a few hundred or a few thousand dollars to invest, may find it perfectly convenient to invest in currency, and to store most of it in a safety-deposit box, one that the person may well have already rented to store important papers or other valuables. A large corporation, in contrast, likely would find dealing in currency extremely costly. So the proposition may be refined further to state that different economic agents will be more or less willing to invest in negative rate investments to the extent that diseconomies of scale make their costs of handling currency higher or lower than others\u2019.\n\nVaults introduce some additional considerations affecting the costs of holding currency. Often, the costs of holding currency securely, by having a safety deposit box or a vault, are fixed costs. Once one has a vault, or has rented a safety deposit box, the costs of storing additional currency in it, up to its capacity, is nil. This suggests that there is a dynamic element to the economics of avoiding negative interest rates: the longer the negative rates are expected to persist, and the lower they are, the more favorable are the returns to investing in a vault. Once the vault investment has been made, maintaining negative rates would likely become more difficult.\n\nAn even more far-reaching change that many have suggested would be the creation of a new institution to handle and store currency on behalf of others; this could dramatically reduce the costs of holding currency. The institution contemplated would have a single, highly trusted, party start a currency warehouse, which would consist of a large secure vault and excellent record-keeping and shipping facilities. Individuals could then deposit currency in the currency warehouse, receive receipts for their deposit, and then make payments with the warehouse receipts. Such an innovation could conceivably lower the cost of holding currency as an investment, and yield investors a return close to zero, but still slightly negative.\n\nBecause of these dynamic considerations involving innovative actions to avoid negative rates, we could add a corollary to our proposition. Specifically, we posit that different economic agents will be less willing to invest in negative rate investments over time to the extent that innovations reduce the costs of handling currency or make available other zero, or near-zero, interest rate economic arrangements.\n\nSome economists since Silvio Gesell\u2014notably, Willem Buiter, Marvin Goodfriend, Miles Kimball, and Ken Rogoff\u2014have suggested that currency be eliminated, taxed, made non-redeemable for deposits in banks, or made redeemable only in units that reflect an exchange rate that varies over time.3 These are all other ways of imposing negative nominal rates universally across the alternative means of payment people use. If such steps were implemented and widely adopted, these proponents claim, there would no longer be a zero bound on interest rates, primarily because currency would not offer a zero interest rate alternative investment as a way to avoid negative rates on electronic bank balances.\n\nThese ideas are clever, but complicated and permanent in their effects. Without going through the details of each proposal, let me discuss two of them: first, the proposal to eliminate currency, and second, the proposal to have currency taxed or to have interest collected from currency holders. By eliminating currency, the problem of avoiding the zero lower bound would be greatly diminished. In his paper, Ken Rogoff suggests that the use of currency, by allowing anonymity in trading, facilitates tax evasion and other criminal activity. He points out many benefits of currency, including seignorage, lack of reliance on electronic networks, transaction cost savings, and expanded civil liberties associated with additional privacy. If these aren\u2019t enough however, let me suggest another, very important benefit of currency that I explored in a paper with Charles Kahn and William Roberds.4\n\nThe anonymity afforded by currency transactions prevents a buyer from suffering from any actions taken after the transactions that could exploit the knowledge gained by the seller of the buyer\u2019s identity. For example, identity theft, or theft of credit or debit card information, is avoided through the use of currency. This is an economic benefit that is distinct from valuing privacy from a civil liberties point of view. If currency cannot be used in transactions, buyers are at a disadvantage, and many otherwise beneficial transactions (not related to buyers seeking to engage in tax evasion or otherwise illicit activity) would not take place.\n\nIt is important to consider whether the move to eliminate currency, or to alter radically how currency works, represents a degradation or an improvement in technology. Should society voluntarily abandon a widely used technology that has enormous benefits and features that are currently irreplaceable, such as the privacy that comes with an untraceable transaction? While some of those features are used by criminals to facilitate socially destructive activities, the vast majority of currency uses are legal and productive. Until there are equally secure electronic means of providing that anonymity, eliminating currency is not warranted.\n\nEconomists have proposed many clever ways to implement the taxation of currency, or, equivalently, the payment of interest on currency holdings. Some of the proposals entail decreasing the value of the currency by imposing a negative rate of interest. This can be likened to making currency out of ice. As you can imagine, such cold currency would slowly disappear as the ice turns into liquid water. (Other proposals would, in effect, attempt to raise or lower the temperature of the air surrounding the ice money.)\n\nOne might conjecture that the loss of purchasing power is the same whether a person holding a dollar for a period of a year sees the value of that dollar decline owing to inflation of 1 percent, or because he had to pay a penny of interest in an environment of stable prices. However, there is a subtle difference between a negative rate of interest charged on currency, and inflation decreasing the value of currency. With inflation, a dollar remains a dollar, but its purchasing power declines. In contrast, with negative interest rates, the dollar of currency is slowly whittled away as one makes interest payments, even though its purchasing power can remain unchanged (this would be the case if prices fell by the same rate as the negative interest rate). In other words, the value of the unit of account is unchanged when a negative interest rate is charged on currency. In addition, dollars would no longer be fungible, because each dollar would have a different amount of interest accrued on it.\n\nThe difference in those two situations is the subject of money illusion\u2014the behavioral tendency of people to think in nominal terms.5 To the extent that money illusion is operative, then imposing negative nominal interest rates will be perceived as more costly to people than engineering an increase in inflation of the same amount\u2014in both cases, the real wealth of the person\u2019s money holdings is the same, but in the case of inflation, the person holds the same number of dollars at the end of the period, whereas with negative nominal interest rates, some of the person\u2019s money holdings have been paid out as interest. Money illusion causes the payment of interest to be perceived as more costly, much as people resist nominal decreases in wages which manifests itself as downward wage rigidity.\n\n2. Legal and operational frictions\n\nLegal and operational challenges will also arise as money and capital markets adjust to negative rates. Many debt contracts feature floating interest rates; that is, the interest rate on the debt is modified periodically to reflect prevailing market interest rates. But when the contractual language does not contemplate the possibility of negative rates, complications will ensue. In that event, the parties must renegotiate, which is difficult when the parties are highly dispersed, and adjust the contractual language to address what happens when market rates are negative. Another first-order operational problem is how to collect interest from creditors: often debtors have few means of calculating interest payments due from creditors, few easy ways to collect the payment, and a limited ability to enforce negative interest payments from creditors. Given these realities, designing interest-bearing securities at negative yields will require careful planning.\n\nThis topic alone is worthy of a longer treatment. In fact, my colleague Ken Garbade and I wrote a piece on this topic, and I won\u2019t repeat the many considerations that enter into the design of securities at negative rates.6 I will point out that because it is so challenging to develop a practical way to collect periodic interest payments directly from holders, one possible work-around is for the issuer of a fixed-rate bond to set the coupon rate to zero, making the bond a single-payment security, and to sell the bond at a premium to its principal value. Alternatively, an issuer could sell a bond with a negative coupon rate by providing that, in the absence of timely payment of interest, the omitted interest payment will be deducted from the principal due at maturity. In this case the bond would be redeemed for less than par, depending on the number of unpaid coupons and the magnitude of the (negative) coupon rate. These alternatives have different tax implications, as discussed in a recent report by the Danish mortgage bankers.7\n\nAs one can imagine, these alternatives require a great deal of coordination and legal work to implement. One legal issue is whether, in the case in which bonds are to be redeemed for less than par, the bonds qualify to be used as collateral in various central bank or private arrangements that require collateral; another is whether the decrease in the par value of the bond might trigger a default that would require a writer of credit default swap protection to make payment to the holder of the swap. These and similar operational problems (including the difficulty of modifying security depositories and clearing and settlement systems to manage the calculations and transfers associated with negative rates) can presumably be solved in time. However, they represent expensive transition costs for those people and institutions that must deal with them as rates move from positive to negative.\n\n3. Economic frictions\n\nThere are many zero interest rate conventions in society: negative nominal rates, but not negative real rates, reverse the incentives to exploit these conventions. The problem is that the conventions evolved for a positive interest rate environment, and efforts to reverse the direction of these incentives can lead to bad economic outcomes for society. Furthermore, it is costly to change these conventions.\n\nIn many economic arrangements, including debt and tax payments, people can prepay debts or tax obligations, or make excessive payments on them, and earn a zero return during the prepayment period. For example, suppose that one holds a credit card under existing U.S. rules: one can withdraw funds from an account that is earning a negative rate, and pay one\u2019s debt to the credit card company in advance of when it is due, earning a zero return during the prepayment period. Similarly, one can make excessive tax payments to the taxing authority, and earn nothing during the period before one receives a refund, thereby avoiding negative deposit rates at banks. Such \u201czero nominal rate\u201d conventions abound in society, and the lower the negative rate, the more people will search for such ways to avoid the negative rates that might prevail elsewhere.8 Consequently, our proposition could now include this consideration: Different economic agents will be more or less willing to invest in negative rate investments to the extent that their costs of handling currency are lower or higher than others\u2019, and to the extent they have available to them zero interest rate economic arrangements. In addition, having talented individuals looking for these opportunities is a dead-weight loss to society. We would rather have them use their talents for more socially productive purposes.\n\nIn addition to the convention that all prepayments of debt carry a zero interest rate, creditors often have the option of deciding when to settle a debt, for example by choosing when to deposit a check once it is received. In an environment in which negative nominal rates prevail, one would want to collect debts slowly (at least from creditworthy counterparties).9 For example, if one were to receive a check from the U.S. government for a tax refund, one could simply put it in a safe place and earn zero interest on it during the time the check remained undeposited. (These practices could trigger further innovations, such as a check with a \u201cdeposit-by\u201d date embedded in it.) How strong these incentives are depends on the level of the negative rates. The lower the negative rate and the more persistent it is expected to be, the more attractive these practices would be. Consequently, these zero rate economic arrangements form another constraint that would prevent rates from going too far into negative territory.\n\nNotice that leaving the check undeposited, much like the hoarding of currency, is a negative outcome for society. In this case, the receiver of the check is able to impose the costs of earning negative deposit rates on the check writer. But this outcome turns on its head the reason that the convention of allowing the check receiver the option of deciding when to deposit a check was adopted in the first place. Under positive interest rates, the check receiver has an incentive to deposit the check at his or her earliest convenience. In other words, these conventions are incentive-compatible ways society has devised to enforce the payment of debt, taxes, and other obligations. By reversing those incentives, negative rates encourage the check receiver to deposit a check from a creditworthy source at his or her latest convenience. This may impose unexpected costs on the check writer, triggering unplanned overdrafts and associated charges, and, in this case, just as in the case of currency, encouraging investment in undeposited checks, rather than in some productive investment.\n\nOnce again, in these situations we should consider how innovations might alter the possibilities to avoid negative rates over time. For example, faced with potentially large repayments, many private contracts, such of those that allow prepayment or delayed deposit, might be renegotiated, introducing additional legal and operational frictions.\n\n4. Pass-through to market rates, and retail v. wholesale\n\nAnother practical challenge is that most if not all parties involved in negative interest rate policies\u2014central banks and commercial banks alike\u2014may wish to immunize ordinary retail bank depositors against experiencing negative interest rates. This is, in large part, a practical concern. As I pointed out earlier, the costs of avoiding negative interest rates by substituting currency for deposits is probably lower for retail depositors than for larger, business and institutional, depositors. Because retail depositors can avoid negative rates on deposits relatively easily, it makes sense not to impose negative rates on their deposits. In addition, many retail depositors may have a visceral negative reaction to being charged negative rates, and may lack a clear understanding of whether their bank is minimizing the costs of storing their deposits.\n\nRecognizing these difficulties, the central banks that have negative policy rates offer zero rates on many of their deposits from banks, imposing negative rates on the \u201cmarginal\u201d deposits. In this way, commercial banks can, in general, charge their retail depositors deposit rates of zero and earn zero at the central bank on at least a large portion of their reserve holdings.\n\nObservers report that retail depositors in Switzerland, Denmark, and Sweden do not face negative deposit rates. At the same time, many large business and institutional depositors do earn negative rates on their bank deposits. This state of affairs opens up new avenues, at least in theory, by which some can avoid negative rates: large business depositors could attempt to impersonate a host of retail depositors. While generally unrealistic, the possibility of such a ploy requires that some effort be expended to prevent that avoidance activity. One such effort might include frequent adjustments of the institutions or deposits subject to negative rates (as we have seen recently in Denmark and Switzerland). The complications of the negative rate policy only become greater once one realizes that it is a policy that is intended to be passed through to most deposit and market interest rates, but not to retail depositors.\n\n5. Effects of negative rates on the health of financial intermediaries\n\nA robust financial sector is important for many reasons: to direct savings into productive uses; to assist households to smooth consumption; to facilitate trading, payment, clearing, and settlement of financial assets; and to deliver insurance and pensions to people. The health of banks and many other financial institutions depends on earning a spread between what the institutions earn on their assets and what they pay on their liabilities. Negative rates can squeeze bank profits. If banks are earning negative rates on their loans while charging a zero rate to retail depositors, they lose money. If the goal of negative rates is to ease financial conditions and provide stimulus to the economy, then the effects of the policy on the health of financial intermediaries must be carefully assessed. Pension and insurance funds too have potential difficulties in operating successfully in a negative interest rate environment. They often provide liabilities\u2014that is, promises of future pension payments or insurance payments\u2014at nominally fixed rates. If they can only invest in negative yield instruments, their profits could be imperiled. Such possible profit squeezes could also prompt financial institutions to take on inappropriately risky assets to earn an apparently positive return. These concerns are present to some extent at very low rates, but they are magnified at negative rates of interest, a point made by Ben Bernanke in his 2004 speech on the topic.10\n\nA special case in the United States concerns the 2a-7 money market mutual funds, which are more prevalent in the United States than in Europe. Money market mutual funds are institutions that offer a floating rate of interest to shareholders that is intended to maintain the value of a share in the fund equal to par, or very close to par, at all times. With negative interest rates, and in the absence of a sponsor that is willing to subsidize shareholders in the fund, such a financial institution would not be able to return a dollar invested today to a shareholder the next day. In such circumstances, the fund must disband, as it has \u201cbroken the buck.\u201d Recent SEC reforms specify that prime institutional funds be offered only shares expressed as floating Net Asset Values in 2016, but retail and Treasury-only money funds will retain a fixed NAV share structure, and therefore will still be subject to this complication in an environment of negative nominal rates.11\n\n6. Signal of deflation\n\nAnother complication centers on the signaling effects I mentioned earlier. When implementing negative rates, central banks recognize that the signaling effects of their action may be unpredictable. The inference drawn by people could be a negative one. For instance, people could infer that the central bank itself has low expectations for inflation and is lowering nominal rates into negative territory as a way to \u201cratify\u201d the low expected inflation environment. Such an inference would complicate the central bank\u2019s effort to achieve its objective because it could encourage and entrench the public\u2019s expectations for deflation.12 That could complicate the potential exit from the negative rate regime.\n\n7. Public acceptance\n\nAs with all public policies, negative nominal rates must be acceptable to the public if they are to be a useful tool for central banks. Certainly, avoiding severely negative rates, especially for retail depositors, would tend to reduce perceived adverse effects on households. There is some anecdotal evidence that people in Switzerland, for example, on balance are not in favor of negative rates.13 But businesses and households may feel that they have been treated unfairly as they see others take advantage of various avoidance activities to which they don\u2019t have access. Others may suffer the theft or loss of a currency hoard, possibly resulting in feelings of regret after the fact, and place the blame on the negative rates. The hoarding of cash itself is an unproductive investment that drains resources from the financial sector of the economy, and consequently, may result in less efficient payments, difficulties in obtaining loans, and other problems.\n\nConclusion\n\nEven though nominal rates can become negative, zero is still an important benchmark: below that level of rates, society faces a distinctive set of complications and costs that can blunt the intended good effects of a negative nominal rate policy.\n\nSo given that, once one has waded into the ocean and implemented a negative nominal rate, how low can rates realistically go? Unfortunately, there is no simple answer. As I have noted in this talk, negative nominal rates introduce a number of legal, operational, and economic frictions associated with. These complications limit the pass-through of negative nominal policy rates to households and businesses. In addition, because the negative rates are costly in terms of resources, they limit the potential stimulus to aggregate demand. Negative nominal rates may also adversely affect the profitability of financial institutions and thus make financial conditions less accommodative than they would be otherwise.\n\nAddressing the complications of negative nominal interest rates includes redesigning debt securities; in some cases, redesigning financial institutions; adopting new social conventions for the timeliness of repayment of debt and payment of taxes; and adapting existing financial institutions for the calculation and payment of interest, the transfer and valuation of debt securities, and many other operations. These innovations will require considerable time, resources, and effort. A benefit-cost analysis thus must weigh the potential advantages of negative rates against the costs of pushing back the tide of all of these conventions and institutions that have proven useful under positive nominal interest rates. That calculation likely will differ across countries, across institutional environments, and across the expected levels and duration of negative rates.\n\n1 The views expressed in this speech are those of the author and do not necessarily reflect the views of the Federal Reserve Bank of New York or of the Federal Reserve System.\n\n2 The press releases announcing the interest rate decisions by the SNB, the ECB, and the Riksbank can be found at the links that follow: http://www.snb.ch/en/mmr/reference/pre_20150115/source/pre_20150115.en.pdf, http://www.ecb.europa.eu/press/pr/date/2014/html/pr140904.en.html, http://www.riksbank.se/en/Press-and-published/Press-Releases/2015/Riksbank-cuts-repo-rate-to-025-per-cent-and-buys-government-bonds-for-SEK-30-billion/\n\n3 Willem H. Buiter and Nikolaos Panigirtzoglou, \u201cOvercoming the Zero Bound on Nominal Interest Rates with Negative Interest on Currency: Gesell\u2019s Solution,\u201d Economic Journal 113, no. 490 (October 2003): 723\u201346; Kenneth Rogoff, \u201cCosts and Benefits of Phasing Out Paper Currency,\u201d paper presented at NBER Macroeconomics Annual Conference, April 11, 2014, Harvard University; Silvio Gesell, Die Natuerliche Wirtschaftsordnung (Rudolf Zitzman Verlag, 1916), available in English as The Natural Economic Order (London: Peter Owen Ltd., 1958); Marvin Goodfriend, \u201cOvercoming the Zero Bound on Interest Rate Policy,\u201d Journal of Money, Credit, and Banking 32, no. 4, part 2 (November 2000): 1007-35; Miles Kimball, \u201cHow and Why to Eliminate the Zero Lower Bound: A Reader\u2019s Guide,\u201d Confessions of a Supply-Side Liberal blog, September 20, 2013.\n\n4 Charles M. Kahn, James McAndrews, and William Roberds, \u201cMoney Is Privacy,\u201d International Economic Review 46, no. 2 (May 2005): 377-99.\n\n5 See Eldar Shafir, Peter Diamond, and Amos Tversky, \u201cMoney Illusion,\u201d Quarterly Journal of Economics 112, no. 2 (1997): 341-74, for evidence on money illusion.\n\n6 Kenneth Garbade and Jamie McAndrews, \"Interest-Bearing Securities When Interest Rates are Below Zero,\" Liberty Street Economics blog, May 4, 2015.\n\n7 \u201cNEGATIVE INTEREST RATES ON MORTGAGES\u201d Working Group on negative interest rates on mortgages, Business and Growth Ministry, Denmark https://www.evm.dk/~/media/oem/pdf/2015/15-04-28-negative-renter.ashx\n\n8 Many of these were reviewed in Kenneth Garbade and Jamie McAndrews, \u201cIf Interest Rates Go Negative . . . Or, Be Careful What You Wish For,\u201d Liberty Street Economics blog, August 29, 2012, and in John Cochrane, \u201cCancel Currency?\u201d The Grumpy Economist blog, December 30, 2014. A particularly interesting case is given in one of the models discussed in the Danish working group on mortgages referenced above. In one of the models for dealing with negative interest rates, a borrower who would be due, for example, $20 in interest payments today, has his principal balance reduced by $20, reducing the need for a later repayment of $20. But that presumes a 0 interest rate between now and the repayment date; an alternative would be to calculate the future value of $20 today compounded at the negative rate of interest.\n\n9 Because the strength of this incentive depends on creditworthiness, it is unlikely that the business of loan-sharking would change very much in a negative interest rate world. However, among trusted loan-sharks and their customers, one could imagine the comic possibilities of seeing loan-sharks\u2019 goons roughing up borrowers when the borrowers attempt to prepay their loans.\n\n10 Ben S. Bernanke and Vincent R. Reinhart, \u201cConducting Monetary Policy at Very Low Short-Term Interest Rates,\u201d paper presented at the International Center for Monetary and Banking Studies Lecture, Geneva, Switzerland. January 14, 2004\n\n11 See the Securities and Exchange Commission, \u201cSEC Adopts Money Market Fund Reform Rules: Rules Provide Structural and Operational Reform to Address Run Risks in Money Market Funds\u201d July 23, 2014 http://www.sec.gov/News/PressRelease/Detail/PressRelease/1370542347679 for a discussion of reforms that limited fixed NAV designs for money market mutual funds to retail and Treasury-only funds.\n\n12 A theoretical model that captures this idea is described in Jess Benhabib, Stephanie Schmitt-Grohe, and Martin Uribe, \u201cThe Perils of Taylor Rules,\u201d Journal of Economic Theory 96, (January/February 2001): 40-69.\n\n13 There have been a couple of informal polls by Swiss newspapers. For instance, in December 2014, after the SNB first announced negative rates (25 bps), the Tagesanzeiger (one of the biggest Swiss newspapers) asked readers whether the decision was a good one. Of the respondents, 47.7 percent said, \u201cYes, it\u2019s necessary to maintain the exchange rate\u201d [the floor was still in place then], while 52.3 percent said, \u201cNo, this policy punishes savers.\u201d http://www.tagesanzeiger.ch/wirtschaft/geld/Geldpolitik-Nationalbank-fuehrt-Negativzinsen-ein/story/26525077)"
  },
  {
    "title": "The U.S. Monetary Policy Outlook and its Global Implications",
    "date": "Apr 20, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150420",
    "content": "It is a pleasure to have the opportunity to speak with you here today.  In my remarks, I will assess the outlook for the U.S. economy and the progress that the Federal Reserve has made toward its dual mandate objectives of maximum employment in the context of price stability.   \n\nOver the past few years, the U.S. economy has made considerable progress toward achieving these goals.  Yet we still have further to go\u2014the unemployment rate is still too high and the inflation rate too low.  Because the economic outlook is uncertain, I can\u2019t tell you when normalization will occur.  The timing is data dependent.  We will have to see what unfolds. Whenever such a shift in policy occurs, we need to be mindful that it most likely will be accompanied by some degree of market stress and turbulence.  Moreover, the normalization of U.S. monetary policy could create significant challenges for those emerging market economies (EMEs) that have been the recipients of large capital inflows in recent years.  This leads to an important question: What can the Federal Reserve do to address these risks?   \n\nWhile tightening cycles by the Fed can pose challenges for EMEs, these need not be disruptive.  The combination of stronger U.S. growth, improved EME fundamentals and effective Fed communications can limit the stresses caused by the onset of tightening.  The experience will vary across EMEs, but EMEs as a group are better equipped today to handle the challenge than they were in the past. \n\nAs always, what I have to say today reflects my own views and not necessarily those of the Federal Open Market Committee (FOMC) or the Federal Reserve System.1\n\nThe U.S. Economic Outlook  \n\nSince the end of the Great Recession more than five years ago, the U.S. economy has grown at a disappointing 2.3 percent annualized rate.  Several times over that period, it appeared that growth was strengthening, but each time such hopes were subsequently unfulfilled.  We appear again to be at a similar junction.  Real GDP growth accelerated over the last two years, rising at a 2.7 percent annual rate.  However, the first quarter of 2015 is expected to be quite weak with growth only at around a 1\u00bd percent annualized rate.  What does this portend for growth going forward? \n\nDespite the weak performance of the first quarter, I believe that the growth prospects for the U.S. economy over the remainder of 2015 will improve.  I expect that the first quarter weakness will prove to be largely temporary.  The winter weather was quite severe in the eastern two-thirds of the United States and bottlenecks at the West Coast ports disrupted both sales and production.  \n\nMore important in assessing the growth potential of the U.S. are the improved underlying fundamentals.  The firming of growth in 2013 and 2014 reflected several important developments that, in my view, are likely to continue to support growth over the remainder of this year and into 2016.  Those developments include the fact that the household deleveraging process has largely run its course and the imbalances in the housing market have been largely worked off.  In addition, federal fiscal consolidation appears to be over for now, and employment and spending are again increasing at the state and local government level. \n\nMy outlook for 2015 as a whole is that economic growth will be close to the pace of the past two years, supported by continued solid fundamentals and accommodative financial conditions.  If I am correct, then this would lead to a further reduction of labor market slack, with the unemployment rate approaching 5 percent by the end of the year. \n\nAn important underpinning of this outlook is that, after a lull in the first quarter, household spending will move back toward the kind of growth path it was on over the second half of 2014, when real PCE grew at about a 3\u00be percent annual rate.  I expect stronger consumer spending to be supported by three factors: healthier household balance sheets, improved household income prospects and the benefit to purchasing power caused by the earlier declines in energy prices.  The fact that the personal saving rate is somewhat above what its longer-term relationship with household net worth also suggests that consumer spending could grow a bit quicker than income growth in the year ahead.   \n\nLet me elaborate on each of these three factors supporting household spending. \n\nWe have documented the steady improvement in household balance sheets in our Quarterly Report on Household Debt and Credit. Aggregate household credit declined from the fourth quarter of 2008 to the second quarter of 2013.  Since then it has increased by 6 percent.  The strongest and most broad based growth of consumer credit has been for purchases of motor vehicles.  In contrast, growth of mortgage debt remains relatively sluggish and is confined to those borrowers with relatively high credit scores.  However, as typically occurs as an economic expansion progresses, there are signs that credit standards are easing a bit, which should promote stronger growth of household borrowing going forward. \n\nAnother plus for consumer spending has been strong gains in nominal income.  Over the second half of 2014, hours worked in the nonfarm business sector rose at a 3.6 percent annual rate.  While wage growth has not yet picked up appreciably, this gain in hours worked resulted in a 4.7 percent annualized growth rate of labor compensation.  \n\nThe pace of improvement in the labor market slowed somewhat in the first quarter of 2015 from that of the second half of last year.  Nonfarm payroll employment increased in the first quarter by about 200,000 per month, but a gain of only 126,000 in March.  This was well below the pace of the fourth quarter.  Growth in hours worked also slowed, but because wage gains picked up somewhat, the growth rate of compensation in the first quarter looks to have been about as strong as it was during the second half of last year. \n\nMoreover, the level of slack in the labor market has diminished sufficiently so that one might expect firmer wage gains going forward.  The unemployment rate in March of 5.5 percent, for example, is at a level where, historically, we have seen a pickup in the pace of real wage gains.  If this happens again and unemployment continues to decline as I expect, then these wage gains will help support continued solid income growth even if the pace of employment growth remains slower than last year.  However, it will be important to determine whether the softness in the March labor market report was temporary, or if it foreshadows a more substantial slowing in the labor market than I currently anticipate.\n\nThe final factor supporting household spending is the decline in energy prices.  Recently, the benchmark West Texas Intermediate (WTI) oil price has been fluctuating in the neighborhood of $50 per barrel, about half the price in June of last year.  Since the U.S. is still a net importer of petroleum, this development has provided substantial benefits, with our oil import bill down by about a \u00bd percentage point of GDP.  That represents a significant boost to real disposable income for households.  The degree to which this energy dividend supports household spending will depend, though, on how much is spent versus saved. \n\nWhile I am relatively optimistic about the growth outlook for 2015, I also must acknowledge that there are some significant downside risks.  In particular, the roughly 15 percent appreciation of the exchange value of the dollar since mid-2014 is making U.S. exports more expensive and imports more competitive.  My staff\u2019s analysis concludes that an appreciation of this magnitude would, all else equal, reduce growth of real GDP by about 0.6 percentage point over this year. Some of the recent softness in indicators of manufacturing activity is likely a reflection of this development. \n\nAdditionally, the decline in energy prices, while helping to support household spending, will adversely impact business investment.  The support to growth from rapidly rising U.S. oil production almost certainly will fade due to the oil price decline.  Now, with prices sharply lower, U.S. oil exploration and drilling activity is falling off very sharply, and this will undoubtedly exert a meaningful drag on economic activity. \n\nTurning to the inflation outlook, the data continue to come in below the FOMC\u2019s objective of a 2 percent annualized rate for the personal consumption expenditures (PCE) deflator.  The twelve-month change of the total PCE deflator was just 0.3 percent in February, with the core PCE deflator at just 1.4 percent.  Despite these low readings, my expectation is that inflation will begin to firm later this year.  Importantly, most of the impact from the decline in energy prices that has weighed down overall inflation is likely over.  Although the appreciation of the dollar may cause some further softness in import prices, the continued decline in resource slack as the economy expands should push in the opposite direction.  We are already seeing some firming in rent inflation as rental vacancy rates have returned to more normal levels and employment and income growth have strengthened.  Longer-term household inflation expectations have been well maintained through this period of very low inflation as shown in our Survey of Consumer Expectations.  This should reinforce the effect of a higher level of overall resource utilization in slowly pushing inflation back towards the FOMC\u2019s 2 percent objective. \n\nMonetary Policy\n\nAs the FOMC has consistently communicated, decisions on monetary policy, such as the timing of lift-off will, depend on how the economic outlook evolves\u2014in particular with respect to the labor market and inflation.  As I have discussed, the labor market has improved substantially over the past few years and I expect to see inflation begin to firm later this year.  If this labor market improvement continues and the FOMC is reasonably confident that inflation will move back to our 2 percent objective over the medium term, then it would be appropriate to begin to normalize interest rates.  At their March meeting, the FOMC removed language from the statement that indicated that we would be patient in beginning the process of normalizing monetary policy.  But, as Chair Yellen remarked in her most recent press conference, removal of the word \u201cpatient\u201d from the statement does not indicate that we will now be \u201cimpatient\u201d to begin to normalize monetary policy.  Rather, the timing of normalization remains uncertain because how the economy evolves is also uncertain. \n\nWhen, hopefully, the data support a decision to lift off later this year, it does not mean that U.S. monetary policy will be tight.  Rather, we will simply be moving from an extremely accommodative monetary policy to one that is only slightly less so.  I would view this as a positive signal about the progress we have made in restoring the U.S. economy to health.  It is important to remember that near zero short-term interest rates and the large expansion of the Federal Reserve\u2019s balance sheet were designed to be a temporary extraordinary treatment to help the economy regain its vitality, and not a permanent palliative. \n\nI remain confident that when the FOMC decides to begin to remove policy accommodation that we have the requisite tools to support this decision.  We have tested numerous tools including overnight reverse repurchase operations, term reverse repurchase operations and term deposit facilities to ensure that, when the time comes, lift-off can be managed smoothly.  As the FOMC has communicated, the primary tool will be interest on excess reserves (IOER), with overnight reverse repurchases as a supplemental tool to be used as needed to help ensure a firm floor under short-term interest rates.  \n\nOnce normalization has begun, two important questions will be:  How fast will it proceed? And how high will short-term rates ultimately need to go?\n\nHow fast the normalization process will proceed depends mainly on two factors:  how the economy evolves and how financial market conditions respond to movements in the federal funds rate target.  If financial market conditions do not tighten much in response to higher short-term interest rates, we might have to move more quickly to achieve the appropriate restraint on financial market conditions.  In contrast, if financial conditions tighten unduly, then this will likely prompt us to go much more slowly or even to pause for a while.  Our intention will be to move short-term interest rates in a manner to generate the set of financial market conditions that we deem to be most consistent with achieving our employment and inflation objectives. \n\nThe question of how high short-term rates will ultimately need to go before we approach a neutral monetary stance is a difficult question, which is hard to pre-judge for a couple of reasons.  First, it depends on how financial market conditions evolve in response to our monetary policy adjustments.  Second, it depends on other factors, such as real potential GDP growth, which, in turn, depends on the growth rates of the labor force and of productivity.  My current thinking is that the long-run nominal federal funds rate consistent with 2 percent inflation is somewhat lower than in the past.  My point estimate is 3\u00bd percent, but I place considerable uncertainty on this estimate.  \n\nGlobal Implications of U.S. Monetary Policy Normalization \n\nLet me now turn to the implication of U.S. policy normalization for foreign economies.  While our monetary policy mandate has a domestic focus, our monetary policy actions have global implications that feed back into the U.S. economy and financial markets.  In some cases, these feedback effects can be disruptive.  An example is the market volatility that we saw in the spring and summer of 2013 during the so-called \u201ctaper tantrum.\u201d  EME financial markets were hit the hardest, with declines in equity prices, a widening in sovereign debt spreads and a sharp increase in foreign exchange rate volatility.  In the U.S., we saw a spike in Treasury yields, with the 10-year rate rising by more than 100 basis points from early May before peaking in early September. \n\nDespite the domestic focus of our policy mandate, we at the Fed take the potential international implications of our policies seriously.  In part, this is out of simple self-interest, since the international effects of Fed policies can spill back onto the U.S. economy and financial markets.  In part, too, it reflects a sense of special responsibility we have given the dollar\u2019s role as the international reserve currency.  We are and will remain attentive to the risk that the onset of Fed policy normalization could bring a new round of market pressures on EMEs.  Yet I think there are good reasons to think that this adjustment will prove manageable and not be very disruptive.     \n\nFirst, many EMEs appear to be better equipped today to handle the Fed's prospective exit from its exceptional policy accommodation than they were during past tightening cycles.  This reflects the fundamental reforms that EMEs have put in place over the past 15 years, as well as the hard lessons learned from past periods of market stress.  Among the positives are:\n\nTo be sure, progress has not been uniform across EMEs, and more work remains in some countries to further strengthen institutional structures.  Vulnerabilities remain in several important EMEs, and some have been hit by a sharp adverse turn in their terms of trade due to the recent fall in global commodity prices.  Still, the fundamental improvements I\u2019ve cited leave many EMEs better positioned than in the past to weather those times in the cycle when the external environment turns more challenging. \n\nSecond, during previous Fed tightening cycles EME economic performance has generally been good.  During the last three U.S. tightening cycles, EME industrial production growth has been between 7\u00bd and 10 percent over the 12-months from the start of Fed tightening, while EME export volumes have risen 10 to 15 percent.  The likely explanation for this favorable record is that Fed tightening generally occurs during periods of strong U.S. economic performance.  Recent research from the IMF bears out this hypothesis, finding that higher U.S. interest rates associated with stronger U.S. growth represent a net positive for EMEs.2\n\nFinancial performance of EMEs has been more diverse across Fed policy cycles.  The strongest contrast is between the tightening cycle that began in 2004, and the one beginning a decade earlier, in 1994.  EME asset prices strengthened considerably during the 2004 cycle, but weakened considerably during the earlier cycle.  Notably, the 1994 cycle was associated with a large increase in U.S. long-term bond yields, and appears to represent a case in which there was a considerable gap between what the Fed did in terms of monetary policy tightening relative to initial market expectations.  \n\nA similar gap was apparent during the taper tantrum in the spring of 2013, when our attempts to provide guidance about the potential tapering of asset purchases ended up confusing market participants, causing many to anticipate an earlier start and more rapid rollout of actual policy rate hikes.  These episodes are reminders of the importance of transparency and clear messaging in how the Fed is evaluating the evolving economic landscape, a point I\u2019ll return to shortly. \n\nThird, the stance of Fed policy will be far from the only factor affecting external financial conditions for EMEs.  Even as the FOMC considers the appropriate timing and pace of moving to a less accommodative policy stance, the ECB and the Bank of Japan are implementing additional easing measures.  As a result, external conditions will remain more supportive than would be indicated by a narrow focus on Fed policy alone. \n\nFinally, EME fundamentals are likely to be the most important determinant of how their financial conditions respond to Fed policy normalization.  This was one of the key lessons of the taper tantrum.  At first, market pressure was somewhat indiscriminant across countries.  Relatively quickly, however, market pressures turned more focused, tightening more severely for countries with clear fundamental vulnerabilities:  large current account deficits, a heavy reliance on portfolio inflows and high inflation rates.  Markets then responded favorably as EME authorities shifted toward clearer, more consistent policies focused on inflation objectives and external sustainability, and away from policies with conflicting and sometimes competing objectives.  A smooth adjustment to Fed normalization this cycle will be more likely if market participants retain this discriminating perspective. \n\nNone of this is to suggest that the road ahead will necessarily be an easy one.  Market participants may focus on vulnerabilities that they might have ignored prior to the taper tantrum in 2013, placing an added premium on strong fundamentals, policy coherence and predictability.  There will likely be no one right answer for EMEs in managing the trade-offs that come with the changed environment, and the adjustment could sometimes be difficult.\n\nWith respect to these risks, central banks in general, and the Fed in particular, play an important role.  We seek to be good global stewards.  As you know, we\u2019ve taken a number of steps to increase transparency and to improve the clarity of our communications.  This includes regular press conferences by the Fed chair following FOMC meetings; the publishing of growth, inflation and short-term rate forecasts of FOMC participants; and a concerted attempt to lay out the guideposts that the FOMC will look at to assess progress toward our mandate.  We are, though, still learning how to more effectively communicate, especially given our new and expanded set of policy instruments. \n\nA second area in which we can and must collectively do better is safeguarding global financial stability. Simply put, we failed to act both early enough and decisively enough to stem the credit excesses that spawned the financial crisis and the Great Recession.  While the U.S. was not alone in this shortcoming, given our position in the global financial system we especially should have done a better job.  We've taken important steps through new legislative mandates and a broader effort to rethink our regulatory and supervisory framework.  In particular, systemically important banking organizations must now hold higher amounts of capital and liquidity that are better aligned with their risk profiles and the official sector is making progress in ensuring no financial firm will be too-big-to-fail. \n\nAlthough this remains very much a work in progress, these efforts should help us to avoid repeating the mistakes of the recent past, and enable us to be more proactive in mitigating potential future vulnerabilities.  Of course, we at the Fed are not alone here.  Since the recent financial crisis, central banks worldwide have been engaged in a broad rethinking of how to better fulfill their mandates. \n\nLet me close with a final thought. The largest problems that countries create for others often emanate from getting policy wrong domestically.  Economic recession or financial instability at home is often quickly exported abroad.  Equally important, growth and stability abroad makes all our jobs at home easier.  This illustrates the externalities in the work we do, with more effective fulfillment of our domestic mandates helping to bring us collectively to a better place. \n\nThank you for your kind attention.\n\n1 Matthew Higgins, Richard Peach, Paolo Pesenti and Joseph Tracy assisted in preparing these remarks.\n\n2 See \u201cSpillovers from Unwinding Monetary Support in Advanced Economies,\u201d 2014 Spillover Report, Chapter 2. See also, \u201cOn the Receiving End: External Financial Conditions and Emerging Market Growth Before, During and After the Global Financial Crisis,\u201d World Economic Outlook, April 2013, Chapter 4."
  },
  {
    "title": "Money Markets and Monetary Policy Normalization",
    "date": "Apr 15, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/pot150415",
    "content": "It is a pleasure to speak again at the Money Marketeers. Much has happened with the implementation of monetary policy in the sixteen months since I last addressed this audience:\n\nAs always, these views are mine alone and do not necessarily reflect those of the New York Fed or the Federal Reserve System.1\n\nOngoing Refinements in the Federal Reserve's Approach to Policy Normalization\n\nWith the conclusion of the FOMC's asset purchase program last October and the ongoing reinvestment of principal repayments, the System Open Market Account's (SOMA) securities portfolio stands at $4.25 trillion. This portfolio is associated with some $2.9 trillion in excess reserve balance liabilities\u2014a level at which the Open Markets Trading Desk (the Desk) will be unable to move the effective federal funds rate up or down with small variations in the supply of reserves, as it did before the financial crisis.2 Against this backdrop, implementation of monetary policy will require a new operational approach to influence short-term interest rates when the FOMC determines it is time to start raising them.\n\nThe FOMC outlined its anticipated approach to policy normalization\u2014that is, raising the federal funds rate and other short-term interest rates to more normal levels, and reducing the Federal Reserve's securities holdings\u2014in a statement of Policy Normalization Principles and Plans published after the September 2014 FOMC meeting, with additional details provided in the March 2015 FOMC meeting minutes.3 In its September statement, the Committee noted its plans to reduce monetary policy accommodation by raising its target range for the federal funds rate. The Federal Reserve intends to move the federal funds rate into the target range primarily by adjusting the interest rate it pays on excess reserve balances (IOER), and will use an ON RRP facility and other supplementary tools, as needed, to help control the federal funds rate. The Committee noted that an ON RRP facility will be used only to the extent necessary and will be phased out once it is no longer needed to help control the federal funds rate.\n\nWith respect to the Fed's balance sheet, the Committee intends to reduce securities holdings in a gradual and predictable manner, primarily by ceasing to reinvest repayments of principal on securities held in the SOMA.4 In the longer run, the Committee intends that the Federal Reserve will hold no more securities than necessary to implement monetary policy efficiently and effectively, and that it will hold primarily Treasury securities.\n\nThe March 2015 minutes augment the September Principles and Plans with additional details about the FOMC's intended operational approach at the commencement of policy firming. Specifically, the Federal Reserve intends to target a range for the federal funds rate that is 25 basis points wide, and to set the IOER rate and the offering rate associated with an ON RRP facility equal to the top and bottom of the target range, respectively. It intends to allow aggregate capacity of the ON RRP facility to be temporarily elevated to support policy implementation. It can also adjust the IOER rate and parameters of the ON RRP facility, and to use other tools such as term operations, as necessary for appropriate monetary control based on policymakers' assessments of the efficacy and costs of their tools. The Committee expects that it will be appropriate to reduce the capacity of the ON RRP facility fairly soon after it commences policy firming.\n\nI'd like to explore some of these elements in more detail.\n\nFirst: IOER. The Federal Reserve began paying interest on reserve balances in October 2008; interest rates on required and excess reserve balances have both been \u00bc percent since mid-December 2008.5 The Federal Reserve intends to use adjustments to the IOER rate\u2014a rate it directly administers\u2014as the main tool for moving the fed funds rate and other short-term interest rates into its target range.\n\nThe IOER rate is essentially the rate of return earned by a bank on a riskless overnight deposit held at the Fed, thus representing the opportunity cost to a bank of using its funds in an alternative manner, such as making a loan or purchasing a security. In principle, no bank would want to deploy its funds in a way that earned less than what can be earned from its balances maintained at the Fed. Even though banks are the only institutions eligible to earn IOER, arbitrage should lift market rates up to the level of the IOER rate. In practice, however, with the large levels of excess reserves in the system, certain institutional aspects of money markets\u2014including bank-only access to IOER, credit limits imposed by cash lenders and other impediments to market competition, and the costs of balance sheet expansion associated with arbitrage activity\u2014appear to create frictions that have made IOER act more like a magnet that pulls up short-term interest rates than a firm floor beneath them.6\n\nSecond: An ON RRP facility. The FOMC will supplement the magnetic pull of changes in the IOER rate with an ON RRP facility to help control the federal funds rate.7 Under the facility, the Desk will offer general collateral reverse repurchase agreements at a specified offering rate to a broad set of counterparties\u2014including several types of nonbank financial institutions that are significant lenders in U.S. money markets.\n\nON RRPs, particularly if offered at full-allotment\u2014that is, fulfilled for any amount demanded at the designated rate\u2014are conceptually similar to IOER for banks in that they provide access to a risk-free overnight investment.8 An ON RRP facility can therefore help firm the floor beneath interest rates by widening the universe of counterparties that are unwilling to lend at rates below those available directly from the Fed. A facility can also help to alleviate some of the frictions that may curb the effectiveness of IOER in a system with large levels of excess reserves by enhancing market competition through a strengthening of large cash lenders' bargaining positions, and by reducing the amount of reserves held by banks and therefore associated balance sheet costs.\n\nThird: A 25 basis point target range for the federal funds rate bounded by the IOER and ON RRP rates. Framing the stance of policy in terms of the federal funds rate focuses monetary policy on a rate that is familiar to the public. Meanwhile, setting a target range, rather than a point target, is viewed as appropriate for providing some flexibility in interest rate control when the quantity of reserves remains elevated. As for the Fed's tools for policy implementation, setting the IOER and ON RRP rates at the upper and lower bounds of the target range is a straightforward arrangement at the start of policy firming.9 A spread of this size between the Federal Reserve's two administered-rate tools is expected to be narrow enough to provide sufficient interest rate control but wide enough to preserve a reasonable volume of trading in the federal funds market and to keep the Federal Reserve's footprint in the nonbank financial sector from growing too large. As suggested by operational guidance in the March minutes, policymakers may adjust either side of the spread between these two rates, as needed, once normalization is under way.\n\nFourth: Qualifications around the use and settings of an ON RRP facility. The FOMC intends to use an ON RRP facility only to the extent necessary and will phase it out when it is no longer needed to help control the federal funds rate. But what is necessary, and how can the facility be phased out?\n\nAs the minutes of recent FOMC meetings show, Committee participants differ in their answers to those questions, but all agree that demonstrating sufficient control over money market rates during the critical early stages of policy normalization is a priority. Against this backdrop, the Committee has noted that it plans to allow the aggregate capacity of the facility to be temporarily elevated to support policy implementation at liftoff, but also expects that it will be appropriate to reduce ON RRP capacity fairly soon after policy firming commences. While the $300 billion aggregate cap on ON RRP usage employed during exercise operations to date has generally provided sufficient capacity to establish a floor on the level of money market rates, it is difficult to know ex ante whether the same amount will be adequate once we move away from the zero lower bound. Providing capacity that market participants will judge sufficient to meet demand with a high degree of certainty can therefore enhance the confidence of policymakers and market participants that the facility will support short-term interest rates at the time of liftoff.\n\nIt is important to note that allowing for elevated capacity in an ON RRP facility is not the same as offering a fixed-rate, full-allotment facility. Through testing, we've learned that the fixed-rate and full-allotment features are not necessary for securing interest rate control. Moreover, by supplying a perfectly elastic quantity of a risk-free asset at a fixed-rate, a fixed-rate, full-allotment ON RRP facility might have undesirable effects on financial stability and the Federal Reserve's role in financial intermediation.10\n\nIn periods of financial stress, the availability of a fixed-rate, full-allotment facility could enable a rapid or unexpected expansion that exacerbates disruptive flight-to-quality flows by facilitating a run away from funding financial institutions and nonfinancial corporations. This dynamic could undermine financial stability. Separately, an ON RRP facility might affect the Federal Reserve's role in financial intermediation\u2014particularly if it were permanently in place\u2014by expanding the Federal Reserve's presence in short-term funding markets or potentially altering the structure and functioning of money markets in unanticipated ways.11 These risks are likely small given the sizable level of excess reserves currently in the system, which establishes the Federal Reserve's large footprint in money markets. However, the risks associated with offering a perfectly elastic supply of ON RRPs at a fixed rate could increase as the level of excess reserves declines over the course of normalization and an ON RRP facility becomes less important to support interest rate control.\n\nThese risks inform the Committee's desire to phase the facility out when it is no longer needed to control the federal funds rate. Indeed, money market rates should become more closely aligned with the IOER rate as the quantity of reserve balances in the system approaches greater levels of scarcity, likely reducing the need for supplementary support from an ON RRP facility. And since ON RRPs just swap one Federal Reserve liability for another\u2014reserves for reverse repos\u2014demand for RRPs should recede as the asset side of the Fed's balance sheet shrinks. There is, therefore, a natural \u201cglide path\u201d for the ON RRP facility to be phased out over time as the SOMA securities portfolio runs off and the size of the balance sheet is reduced to the smallest size needed for effective and efficient monetary policy implementation.\n\nThe pace at which the portfolio runs off will be influenced by a wide range of variables, including the FOMC's decisions about its securities portfolio, the future path of interest rates (which will affect the prepayment speed of the Fed's agency mortgage-backed securities portfolio), and currency growth. Under a set of baseline assumptions from the end of 2014, the level of reserves is projected to fall below $1 trillion in early 2019 and to reach its steady state in late 2020 (Figure 1).12\n\nIn the meantime, we can introduce features into the facility's design that would limit its size even as it supports interest rate control. Examples include managing the spread between the IOER rate and the ON RRP rate to influence demand for the facility, setting a cap on the facility's size through individual or aggregate limits, and establishing an auction mechanism to allocate usage. If needed, the Committee can adjust these levers to discourage usage and shrink the footprint of the facility. The Committee has already directed the Desk to include some of these features in its testing.\n\nFinally: The FOMC noted that it is prepared to adjust the details of its approach to policy normalization in light of economic and financial developments. Flexibility is a critical element of the Federal Reserve's approach to policy normalization. Policymakers have said that they will adjust the IOER rate and parameters of an ON RRP facility, and use other supplementary tools as necessary\u2014including term tools\u2014during the normalization process. In doing so, they will weigh the efficacy and costs of each of the tools in their arsenal to ensure that they are optimizing policy objectives while maintaining appropriate interest rate control.\n\nI'll now explain our confidence in and readiness to implement this approach.\n\nPreparedness to Implement Normalization\n\nExtensive testing of ON RRPs and other supplementary tools have provided policymakers with confidence that they will be able to maintain control over interest rates\u2014that is, that rates will move up with increases in the IOER rate\u2014during the normalization process.13\n\nAn important determinant of the effectiveness of an ON RRP facility is whether a sufficiently wide set of nonbank counterparties has access to it. The New York Fed currently executes RRPs with 163 counterparties comprising many of the major cash lenders in secured and unsecured money markets\u2014including money market funds that manage about 70 percent of the total U.S. money market fund assets under management and account for more than a quarter of total tri-party repo lending against government collateral.14 This provides a high degree of confidence that we are transacting with an adequate set of counterparties to achieve our policy execution objectives.15\n\nThroughout the testing regime, the Desk has varied the settings and design of the reverse repo operations, with operational results informing subsequent changes. We've operated at different times of the day, increased the maximum bid limit per counterparty, and introduced an aggregate cap of $300 billion and a single-price auction mechanism to allocate awards should the sum of submitted bids exceed the cap. We've also adjusted the offering rates and tested ON RRPs in conjunction with term RRPs at quarter-ends. These adjustments have allowed us to learn how ON RRPs might be used to support the monetary policy objectives of the FOMC.\n\nOur testing has demonstrated that ON RRP operations can set a soft floor on short-term interest rates. That is, while some trades may occur below the ON RRP offering rate, the volume-weighted averages of most money market rates have been above the ON RRP rate on nearly all days (Figure 2).\n\nData across a range of money markets provide evidence that changes in the ON RRP rate affected pricing for both unsecured and secured instruments and that the operations successfully set a floor on short-term interest rates. While market participants are aware of the success in producing a floor from such volume-weighted rates as the fed funds effective rate and GCF Repo Index\u00ae, the Desk has been also examining detailed transaction-level data for evidence that the ON RRP sets a floor on nearly all overnight money market transactions.\n\nA series of rate adjustments last November and December was particularly instructive in this examination. During the six-week test, the offering rate was temporarily lowered from 5 basis points to 3 basis points, then raised to 7 basis points and 10 basis points.16 The Fed's FR 2420 data on bank borrowing activity show that after each increase in the ON RRP offering rate, the distribution of fed funds trades shifted toward higher rates, with the vast majority of trades being executed at rates at or above the offering rate (Figure 3). The same patterns were observed in detailed data on brokered fed funds and Eurodollar trades, the latter of which encompasses a larger volume and wider set of lenders than fed funds, and also in secured markets. Examining in particular individual repo trades where money market funds and GSEs supply cash to counterparties over the tri-party platform, we saw repo rates shift higher and nearly all trading volume occur at or above the ON RRP rate. Thus, the rate on the ON RRP facility performed as a floor for nearly all overnight money market transactions, exactly as theory would predict for even small and temporary rate changes in the offering rate.\n\nAfter subsequently lowering the ON RRP offering rate back to its exercise baseline of 5 basis points in mid-December, secured rates declined. Interestingly however, average unsecured rates remained at somewhat elevated levels, even as a portion of the activity returned to lower rate levels (Figures 4 and 5).17 The drivers of this dynamic remain unclear and illustrate the complexity of money markets, but may partly reflect some lenders in unsecured markets gaining information about their relative bargaining power as a result of the ON RRP tests.18\n\nOverall, observations from testing and reports from market participants suggest that ON RRP operations generally work the way we have expected, with market participants evaluating the attractiveness of ON RRP investments relative to other opportunities available to them in the market. Indeed, take-up in the operations generally increases as the spread between alternative market rates and the ON RRP offering rate narrows, and aggregated usage patterns differ across counterparty types.19\n\nTake-up, particularly for prime money market funds, substantially increases around quarter- and year-ends, when cash investors' access to other short-term investments can become more limited. All else equal, the decline in the supply of short-term investment alternatives can create volatility in market rates, so the Federal Reserve's ability to provide investment capacity through ON RRPs at these times may be important for monetary control. Tellingly, the only time the $300 billion aggregate cap on ON RRP operations was reached was in the September 2014 quarter-end operation, soon after the cap's introduction surprised market participants, leaving them searching for investment options when less than two weeks remained before quarter-end. Money market rates softened over that period as lenders sought to protect themselves against the risk of not having their bids fully filled in the Fed's quarter-end operation. Indeed, requested bids in the September 30 operation exceeded the cap by about $100 billion, some bids were only partially filled, and ON RRPs were awarded at a stop-out rate of zero percent.\n\nIn December 2014 and March 2015, the early provision of additional investment capacity through term RRP operations spanning the quarter-end dates, on top of the $300 billion of capacity provided through ON RRPs, provided confidence to money market counterparties that sufficient investment opportunities would be available.20 Absorbing some investment demand in term operations ahead of those quarter ends likely kept demand for ON RRPs on the quarter-end dates below the cap and helped to keep money market rates above the ON RRP offering rate. Given an apparent high degree of substitutability between overnight and term RRPs, cumulative take-up in these operations helps us to assess variability in potential demand for safe investments around peak times and to evaluate how much capacity the Federal Reserve might need to provide in an ON RRP facility to satisfy demand sufficiently to maintain interest rate control (Figure 6).21\n\nWhile our testing suggests that the current parameters of ON RRP operations have worked successfully with IOER to control short-term interest rates, there are limits to what we can learn from testing. Importantly, we will likely not know the level of support that proximity to the zero lower bound has provided to money market rates until we start to move away from it. Demand for ON RRPs following liftoff could remain relatively steady. But it could conceivably be much greater than what we have seen at higher levels of interest rates or as regulatory and structural changes in money markets boost demand for safe assets, which I will discuss momentarily. Additionally, having some excess capacity, also known as headroom, in ON RRP operations over expected usage is important for the facility's effectiveness in helping to control rates. One might want such headroom\u2014which provides confidence to market participants that an ON RRP cap will not bind\u2014to be somewhat higher on average if take-up in ON RRP operations becomes more volatile. Given the importance of a successful liftoff to the Federal Reserve's credibility, the FOMC has indicated an intention to set ON RRP capacity at a temporarily elevated level when policy firming commences to support policy implementation.\n\nAs always, the Federal Reserve will monitor financial markets closely and make adjustments in its execution of monetary policy, as needed, to achieve its mandated objectives.\n\nChanges in Money Markets\n\nThe operational approach for policy normalization I described earlier refocuses the mechanism for implementing monetary policy back to money markets, after the post-crisis period in which policy has been driven by large-scale asset purchases. However, we will be operating in a complex, dynamic, and still-evolving market environment that looks much different from the money markets in which the Fed last operated actively to achieve its interest rate objectives. Still, these markets are no less important for the transmission of monetary policy or the broader U.S. financial system than they were before.\n\nIn recent years, money market trading dynamics have changed, reflecting the effects of Fed monetary policy as well as other factors. The expansion of the Federal Reserve's balance sheet and the introduction of payment of interest on reserves have significantly altered the motivation for many fed funds trades.22 With an abundant supply of reserves available, banks' need to borrow funds to meet their reserve requirements or to clear financial transactions has been dramatically reduced. Meanwhile, entities that have surplus cash but are not able to earn IOER, such as Federal Home Loan Banks, lend funds at sub-IOER levels to banks that borrow them for the purposes of depositing them at the Fed to earn IOER.\n\nAs a result, the size of the fed funds market has declined relative to pre-crisis levels and the nature of most fed funds activity has changed. Nevertheless, trading volumes remain reasonably robust. Since July 2014, the average overnight borrowing in the fed funds market that banks report to the Fed through our FR 2420 reporting form has been roughly $50 billion, with an average of about 300 transactions per day (Figure 7).23 Moreover, longer-term correlations between fed funds and other money market rates remain robust, with the fed funds rate remaining a suitable measure of banks' marginal borrowing costs.\n\nA variety of regulatory changes and other developments have also influenced motivations for participating in fed funds and other money markets. Liquidity and capital rules affect the management of bank balance sheets and the costs of many money market transactions, affecting banks' incentives to engage in short-term borrowing, arbitrage between different money market rates, and provide customers access to their balance sheets. Notably, regulatory changes affect different institutions in different ways. For example, changes to the calculation of FDIC deposit insurance assessment fees affect primarily domestic banks. The implementation of Basel III banking standards also varies by jurisdiction, so the rules for foreign bank branches operating in the United States are somewhat different than those for domestic institutions.24\n\nThe effects of regulatory requirements on money market dynamics can be seen especially around key financial reporting dates. As many market commentators have noted, some borrowers actively manage their balance sheets on quarter-end dates. The perceived costs associated with new regulatory requirements on capital and liquidity ratios may further incentivize such behavior, particularly by foreign institutions. Borrowers' responses appear to contribute to the period-end dynamics I described earlier, including declines in money market volumes, increased volatility in money market rates, and elevated participation in the RRP operations as cash investors face temporarily reduced investment options from private counterparties. Importantly, the increase in RRP take-up can be understood as a consequence, rather than a cause, of private market balance sheet reductions on quarter-end dates.\n\nThere have also been changes to the business models of many money market participants. Following the financial crisis, many financial institutions have sought to adjust their balance sheets to enhance their liquidity positions and reduce reliance on short-term wholesale funding. Cash lender business models have also adapted, with changes to some lenders' willingness to take credit risk. For example, Fannie Mae and Freddie Mac have not been active lenders in the fed funds market since 2011.\n\nRecent SEC money market fund reforms are beginning to change the landscape of the U.S. money fund industry and will likely influence investor use of prime funds relative to government funds or other investment options. Money fund reforms are one of many factors expected to increase demand for high-quality, short-term assets\u2014a trend that will have implications for the relative pricing across different money market instruments and flows to different investment options, including Fed RRPs.\n\nWe are also attentive to changes in money market infrastructure and technology. For example, the tri-party repo market has undergone significant changes in its settlement process and infrastructure since the crisis. Recent changes to the timing of settlement and maturity of tri-party repo trades have implications for market participants, such as making tri-party repo investments unattractive for lenders requiring morning return of funds.\n\nAll these factors contribute to changing dynamics in money markets, with some potentially resulting in greater demand for Federal Reserve liabilities.\n\nNew Data Collection on Money Markets\n\nIn addition to developing new tools and approaches to operate in this environment, the Fed is also improving tools that support daily implementation of monetary policy and analysis of money market conditions. In April of last year, the Fed launched the FR 2420 Report on Selected Money Market Rates, a mandatory daily collection of fed funds, Eurodollar, and CD transactions from around fifty domestic banks and one hundred U.S. branches of foreign banks.25 The goal of initiating this data collection was to better understand institutional behavior in money markets, and indeed, as indicated in observations shared with you this evening, our findings have already helped us analyze results of our operational tests to prepare for normalization.\n\nThese data also present an opportunity to make additional improvements in light of the recent international focus on identifying best practices for reference rates.26 Earlier this year, the Fed announced plans to improve the process for calculating the fed funds effective rate by transitioning the data source from data supplied by federal funds brokers to data reported directly by banks through FR 2420.27 The new data source includes more activity and transaction-level data, which will make the calculation process more robust.\n\nThe Fed also announced it would begin daily publication of a second, broader measure of unsecured bank borrowing activity based on transactions in both federal funds and Eurodollars. This rate, called the overnight bank funding rate, will provide increased transparency on broad overnight funding costs for U.S.-based banking offices.\n\nIn order to implement these changes, improve monitoring and analysis of unsecured money markets, and support supervisory objectives, the Fed recently proposed a number of enhancements to the FR 2420 data collection, which are intended to capture a larger share of fed fund and Eurodollar transactions.28 These enhancements would add about 30 new domestic institutions that are fed funds borrowers and lead to the collection of much more robust Eurodollar activity, including Eurodollar transactions from Caribbean branches that are managed and controlled by the U.S. offices of foreign banks. These proposed revisions are available for public comment until June 8, 2015, and implementation of the changes to the published rates will occur after revisions to the FR 2420 are complete, which is expected within a year.\n\nConclusion\n\nIn conclusion, although the Federal Reserve will be removing its policy accommodation in a much-changed money market environment, the Desk is ready to implement policy firming when the FOMC determines that economic and financial conditions warrant it. The minutes of the March FOMC meeting outline the Federal Reserve's intended operational approach, and our testing program gives us confidence that we have the necessary tools to enable a smooth liftoff. The minutes highlight that policymakers will be particularly careful at the start because demonstrating appropriate control over the federal funds rate and other short-term rates is a priority. This may entail elevated aggregate capacity in an ON RRP facility at liftoff because we don't know how much support we are currently getting from the zero lower bound, which creates some uncertainty about the demand for ON RRPs. However, the ON RRP will be used only to the extent necessary for monetary policy control because it has some potential financial stability and footprint costs associated with it. Moreover, the Federal Reserve has a number of backup tools should things work differently than expected, and policymakers will make changes as necessary as normalization proceeds.\n\nCharts\nData"
  },
  {
    "title": "Opening Remarks for the Chapter 9 and Alternatives for Distressed Municipalities and States Workshop",
    "date": "Apr 14, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150414",
    "content": "Good morning and welcome to the Federal Reserve Bank of New York.  I am especially happy to welcome this group, with its focus on the finances of state and local governments.  We at the New York Fed are committed to playing a role in ensuring the stability of this important sector.  To this end, we supported the outstanding work of the Volcker-Ravitch state fiscal crisis taskforce.  In addition, we conduct ongoing outreach activities with local officials and produce research on the subject of local fiscal conditions.  We do these things because we recognize the critical role of state and local governments and their fiscal health to the overall well-being of the economy and its citizens. \n\nIn my remarks today I will touch on the importance of the state and local public sector for the economy, its fiscal health and the need for proactive efforts to address the emerging fiscal stresses in the sector.  As always, what I have to say represents my own views and not necessarily those of the Federal Open Market Committee or the Federal Reserve System.1\n\nThe importance of state and local governments manifests itself in different ways, which are really different sides of the same coin.  First, the sector directly produces a very large amount of economic activity.  In 2014, state and local governments generated output valued at about $2 trillion.  This represents over 11 percent of total U.S. GDP and is more than 50 percent higher than the federal government's contribution.  And, even after years of retrenchment following the financial crisis, state and local governments employ almost 20 million individuals\u2014nearly one in seven American workers.  Clearly, a successful and stable state and local government sector is a vital contributor to overall output and employment.  \n\nOn the other side of the coin, we find the real effects of this activity: the provision of public safety, education, and health; as well as water, sewer and transportation services.  These are the core public services that our citizens need, and which are absolutely fundamental to support private sector economic activity.  So, as a central banker, I recognize the essential role that state and local governments play in the economy.  Without successful state and local governments, the Fed\u2019s dual mandate of maximum sustainable employment with stable prices would be much more difficult to attain. \n\nA final important dimension of the state and local sector\u2014and the one that is perhaps most obviously front and center for today\u2019s discussion\u2014is its debt.  The municipal bond market is very large, with outstanding issues totaling over $3.5 trillion.  Now this large dollar amount in and of itself is not a problem.  When governments invest in long-lived capital goods like water and sewer systems, as well as roads and bridges, it makes sense to finance these assets with debt.  Debt financing ensures that future residents, who benefit from the services these investments produce, are also required to help pay for them. This principle supports the efficient provision of these long-lived assets. \n\nUnfortunately, as the Volcker-Ravitch task force emphasized, issuing debt to finance infrastructure investments is not the only reason that states and localities borrow from the future.  Governments have also borrowed to cover operating deficits, and this kind of debt has a very different character than debt issued to finance infrastructure.  Let me take a moment to explain what I mean and why I think this distinction is important. \n\nWhen a jurisdiction borrows to invest in infrastructure, the cost of the debt to local residents\u2014and those considering locating in the jurisdiction\u2014is offset by the value of the services that the infrastructure provides.  This tradeoff is part of the \u201cfiscal surplus\u201d that a jurisdiction offers: the value of the services minus the tax price that residents have to pay.  A well-run capital budget will match these costs and benefits over the life of each project to ensure that the jurisdiction remains attractive to current and future residents.  That is, both current and future residents are willing to pay the tax cost of servicing this debt because of the benefits that they receive from the services supported by that debt. \n\nNow consider a different scenario\u2014one in which the jurisdiction is borrowing to pay for a current year operating deficit.  This kind of borrowing is inconsistent with running a balanced budget, which is in principle required in all but one state.  But, as people in this room are well aware, states and localities can often find ways to \u201cget around\u201d balanced budget requirements if they are determined to do so.  One example of this was New York City in the 1960s and early 1970s, where annual operating deficits were repeatedly financed with short-term debt, until the fiscal crisis exploded in 1974-1975. \n\nThe key distinction between these two types of borrowing is that in the former case an asset is producing services that help to offset the cost of the debt, but this is not so in the latter case.  Indeed, using debt to finance current operating deficits is equivalent to asking future taxpayers to help finance today\u2019s public services.  When this occurs, it means that the fiscal surplus offered by the jurisdiction in the future will be diminished by the value of these additional debts.  That is, in the future, the cost of servicing this debt will drive a wedge between the taxes paid by households and businesses, and the current services provided to them.  Of course, within the U.S., households and businesses can react to this wedge by choosing to locate elsewhere.  And because the tax base of any jurisdiction depends on the level of local economic activity, this out-migration can lead to ever-higher tax rates or ever-diminished services for those who still remain\u2014typically those with fewer opportunities or resources to relocate. \n\nToday, there are several ways that states and localities can borrow to cover operating deficits; and the relatively slow economic growth since the financial crisis has increased pressure on their budgets, making such measures more appealing.  One mechanism for doing this is to treat borrowed funds as revenues that can be used to balance the budget.  Another form is asset sales.  Here the jurisdiction receives cash today in exchange for a reduction in its future assets\u2014sometimes physical like an office building, sometimes financial like tobacco settlement funds\u2014and an increase in its future costs.  Finally, and perhaps most importantly, is the practice of pushing the cost of current employment services into the future. \n\nLet me elaborate on this last method.  Here I\u2019m referring to the underfunding of public employee pensions and other post-retirement benefits for current employees.  Both of these practices add to the indebtedness of the state and local governments with the employees playing the role of creditors.  To be clear, while unfunded promises to cover retiree health insurance are very common, unfunded pension liabilities are probably much larger in aggregate magnitude.  Estimates of unfunded pension liabilities range up to several trillion dollars.  While widespread, underfunding of public pensions is not universal.  Many states have found ways to keep their public pensions reasonably well funded, demonstrating that pushing today\u2019s costs into the future is not an inevitable outcome of a democratic government. \n\nNonetheless, we have seen evidence that high debt levels combined with diminished services provision can, in cases such as Detroit and Stockton, make the public sector finances unsustainable.  At a certain point, the debt service burden clashes with maintaining a sufficient ongoing provision of services to forestall people from voting with their feet.  This may occur well before the point that debt service capacity appears to be fully exhausted.  In other words, the prioritization of cash flows to debt service may not be sustainable beyond a certain point.  While these particular bankruptcy filings have captured a considerable amount of attention, and rightly so, they may foreshadow more widespread problems than what might be implied by current bond ratings.  We need to focus our attention today on addressing the underlying issues before any problems grow to the point where bankruptcy becomes the only viable option.  So, I am especially pleased to see that your agenda today focuses, in part, on helping cities and states avoid such levels of fiscal stress, where the risks of going past such a tipping point become significant. \n\nIn summary, state and local governments have enormous financial obligations, as well as critical service delivery responsibilities.  Managing their liabilities in such a way as to ensure that these vital services continue to be provided, and citizens view that they are getting appropriate value in exchange for their taxes is a daunting challenge.  I am happy to see such a distinguished group assembled here at the Bank to address this challenge.  Good luck in your work and I look forward to learning of the results of today\u2019s discussions. \n\n1 Andrew Haughwout and Joseph Tracy assisted in preparing these remarks."
  },
  {
    "title": "Challenges Posed by the Evolution of the Treasury Market",
    "date": "Apr 13, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/pot150413",
    "content": "Welcome to this year\u2019s primary dealer meeting, and thank you for joining us today. As primary dealers, you play an integral role as the Federal Reserve\u2019s counterparties in operations to implement monetary policy, as participants in U.S. Treasury auctions, and as important providers of information on market developments to support the Desk\u2019s monitoring of financial markets.2 Today\u2019s meeting provides us with a valuable opportunity to communicate our expectations for you as our counterparties and to strengthen our important relationship.\n\nToday, I\u2019ll discuss the market for U.S. Treasury securities, with a focus on how the market\u2019s structure has changed in recent years. As you all know, the U.S. Treasury market is one of the most important financial markets globally and is valued as a source of safety and liquidity. Indeed, both domestic and global investors, including private sector institutions, retail investors, and foreign central banks, hold Treasury securities at least in part for these reasons. A deep and liquid Treasury market also helps to underpin the U.S. dollar\u2019s status as the global reserve currency.\n\nI\u2019ll begin with an overview of the market\u2019s basic structure, including some historical perspective on how that structure has evolved over time. I\u2019ll then turn more specifically to the subject of electronic and automated trading\u2014a topic that has become increasingly important across many markets, including the market for U.S. Treasuries. I will then review the intraday volatility witnessed on October 15 of last year. As you all know, October 15 was a highly unusual day in the Treasury market, particularly given the very sharp round-trip in yields that took place mid-morning with no obvious immediate trigger. I will conclude with a few words on the updated best practice recommendations from the Treasury Market Practices Group (TMPG) in light of the changing market structure, and some observations on how you, as primary dealers, are expected to help promote the market\u2019s efficiency and integrity. As always, the views I express are mine alone and do not necessarily reflect those of the Federal Reserve Bank of New York or the Federal Reserve System.\n\nBackground\n\nThe Treasury market is the largest and most liquid sovereign debt market in the world. There are about $12.5 trillion in marketable securities outstanding, and primary dealers trade an average of around $500 billion every day with their clients and with other parties.3 Treasury securities play a variety of roles in the U.S. economy. They are, of course, the federal government\u2019s primary vehicle for financing the federal deficit and refinancing maturing debt. Global investors use Treasuries for investing and hedging purposes, and as benchmarks for pricing other types of assets. In addition, many in the public and private sectors use Treasury yields to glean information about expectations for the future course of the U.S. and global economy.\n\nTreasury securities originate in the primary market, where the Federal Reserve Bank of New York, in its capacity as fiscal agent for the U.S. Treasury, works with primary dealers to facilitate the auction process.4  Auctions are open to primary dealers, their customers, and direct bidders.\n\nHigher federal deficits in the wake of the financial crisis required Treasury to increase the amount of issuance for some time, but the deficit has now shrunk to a level closer to historical norms, bringing the required level of additional issuance, also known as \"net issuance,\" down in tandem.5  However, gross issuance, defined roughly as the sum of the issuance required to refinance maturing debt and the net issuance required to fund the existing deficit, continues to be very high by historical standards. For example, in 2014, the U.S. Treasury issued just over $630 billion on a net basis, whereas there was $7 trillion in total gross issuance taking place over the year.\n\nA deep and liquid secondary market, where traders buy and sell existing securities at an agreed-upon price, is a crucial attribute of the asset class, and primary dealers and other market participants also play an important role here. Strong liquidity in the secondary market facilitates smooth price discovery and ensures that investors can adjust their holdings of Treasury securities at minimal cost. The attractiveness of Treasury securities to investors, in turn, helps minimize the cost of issuance to the U.S. Treasury and facilitates the Federal Reserve\u2019s ability to implement monetary policy.  \n\nThe secondary market for Treasury securities operates on an over-the-counter basis\u2014that is, not on an exchange.6 Historically, secondary market trading has fallen into two categories: trades between dealers and customers, and trades between dealers. \"Dealer-to-customer\" trading consists of direct transactions between broker-dealers and end-investors, and trading activity tends to be dispersed across both the most recently issued securities, known as \"on-the-run\" issues, and seasoned securities, known as \"off-the-run\" issues. The outright purchases of Treasury securities that the Desk conducts to implement monetary policy would fall into the dealer-to-customer category.\n\nMuch of the trading between dealers, on the other hand, takes place on platforms that provide opportunities for market makers to trade anonymously with each other, with a broker sitting in the middle. Activity taking place over these platforms is often referred to as the \"interdealer\" market, since dealers have been its traditional participants. The vast majority of trading in the interdealer market has also tended to concentrate in on-the-run issues, given\u2014and likely contributing to\u2014their superior liquidity. This liquidity advantage is reflected in the tendency for on-the-run securities to trade at a slightly lower yield than might be predicted by a theoretical yield curve\u2014a concept often referred to as the \"on-the-run premium.\" \n\nThe interdealer Treasury market has undergone significant changes over its life and looks very different now than it did in recent decades. One obvious change is technological. As early as the mid-1970s, dealers would use brokerage screens as sources of aggregated information on the best bids and offers, but through the 1990s they continued to conduct transactions through voice channels. This practice began to change around the turn of the twenty-first century, when electronic means of transacting began to grow. Now, of course, nearly all trades are conducted electronically in the interdealer market, with transactions occurring via computer systems\n\nAnother important change in the interdealer Treasury market relates to the issue of access. Until 1992, only primary dealers, as designated by the Federal Reserve Bank of New York, had direct access to the interdealer brokerage platforms.7  Owing partly to the advent of direct bidding in Treasury auctions and the effects of the Salomon Brothers bidding scandal the year before, the interdealer brokers expanded access beyond primary dealers to all entities who were netting members of the Government Securities Clearing Corporation (now the Fixed Income Clearing Corporation, or FICC). Over time, other entities also gained effective access to the platforms through their prime brokers, who themselves had direct access. In more recent years, interdealer brokers have granted access to an even wider range of participants, including participants outside the FICC netting membership.\n\nA third change is the availability of close substitutes to on-the-run Treasuries, which, as noted above, account for the great majority of trading in interdealer markets. Historically, on-the-run Treasuries had a limited number of close substitutes as a highly liquid, credit-risk-free, dollar-denominated fixed-income instrument. Today, however, dealers and investors can transact in a variety of instruments that closely resemble the risk and liquidity properties of on-the-run Treasuries, including Libor-based interest rate swaps and overnight index swaps. Moreover, Treasury futures, which have existed for several decades, have become an increasingly widely used close substitute as well.   \n\nThroughout this history, the Treasury market has retained one of its most important attributes\u2014its superior liquidity. However, the concept of financial market liquidity is a notoriously difficult one to define. Many approaches to measuring liquidity seek to quantify the cost of transacting in a given size, and this is certainly one reasonable definition. Others, however, might argue that it is the ability to transact that matters most for liquidity, even if the \"cost\" goes up during periods of heightened volatility. Perhaps even more difficult than defining liquidity is answering the question of how an increasingly electronic, and often automated, market affects liquidity. As we will see, this is a particularly pertinent question when examining the events that took place in the Treasury market on October 15 of last year.\n\nElectronic and Automated Trading in the Treasury Market\n\nAs I noted earlier, electronic trading\u2014or the practice of executing transactions through computer systems\u2014has become an important feature of the modern Treasury market. While comprehensive data on the universe of secondary trading in the Treasury market is somewhat lacking, estimates suggest that electronic trading represents a greater share of activity than transactions conducted by voice, perhaps by a substantial margin. As noted above, the vast majority of interdealer market trading is conducted electronically, but a sizable proportion of trading in the dealer-to-customer market is now executed electronically as well.\n\nAutomated trading is a subset of electronic trading that relies on computer algorithms for trading decisions, execution, and booking. Market participants engage in automated trading for a variety of reasons, including cost savings and efficiency gains from the relatively faster speed at which computer algorithms can make and process certain types of decisions. For example, a dealer may decide that for orders under a certain size, it is more efficient and cost effective to have a system automatically provide a quote when a customer shows interest than to have a trader manually do so.  \n\nHigh-frequency trading (HFT) refers to a type of automated trading that relies primarily on speed to identify and act upon trading opportunities faster than other market participants. HFT is often associated with a high volume of order messages and rapid position turnover. Such trading typically requires a significant investment in technology and communications systems designed to reduce the amount of time necessary to transmit and process information. Although high-frequency trading has garnered much attention in the media, it is worth pointing out that distinguishing between \"automated trading\" and \"high-frequency trading\" is not clear cut. In fact, many features ascribed to high-frequency trading, such as minimizing the time between trading decisions and execution, also apply to automated trading more broadly.\n\nAutomated trading is conducted by a range of different firms, including broker-dealers and specialized proprietary trading firms that trade without client money. Firms specializing in automated trading generally participate in trading venues with \"protocols\" that allow for high-speed activity, most notably those operating with a Central Limit Order Book (or \"CLOB\"). CLOBs have long been a fixture of the futures, FX, and equity markets, and allow participating firms to place anonymous orders to buy or sell securities into a standing queue, and to rapidly execute such orders at any given moment in time.8  In the Treasury market, automated trading has become most pronounced in the Treasury futures market and the interdealer market for on-the-run securities, both of which operate with a CLOB protocol. In fact, proprietary automated trading firms are believed to account for over half of the volume transacted over the major interdealer trading platforms.\n\nIt is helpful to think of two basic types of automated trading strategies: those whose primary purpose is to earn a return by making markets, and those whose primary purpose is to generate excess returns\u2014what market participants sometimes call \"alpha-seeking\" strategies. A market-making algorithm might be designed to supply liquidity to a CLOB under a set of rules that depend on, for example, historical analysis of market and order book dynamics. An alpha-seeking strategy, on the other hand, might better describe a set of trading practices that is more likely to consume liquidity to produce excess returns. Examples of alpha-seeking strategies might be momentum detection, statistical arbitrage, and spread trading.9\n\nOne important difference between most automated trading firms and traditional broker-dealers is their balance sheet properties. Traditional broker-dealers generally carry net long or short positions in Treasury securities from one day to another, an activity that requires capital. Dealers hold Treasuries for a variety of reasons, including to support the liquidity needs of their customers, to hedge exposure in other fixed-income products, and to meet their obligations as primary dealers to participate in U.S. Treasury auctions and the Federal Reserve\u2019s open market operations. Many argue that the ability and willingness of dealers to deploy their balance sheets for holding Treasury securities and other fixed-income assets allows them to serve as shock absorbers, particularly during times of volatility.\n\nAutomated trading firms, on the other hand, typically do not end the day with significant long or short net exposure, despite the fact that they often conduct a substantial volume of gross transactions.10  As a result, automated trading firms do not face the same level of capital constraints under the traditional way of thinking about capital requirements.11However, for the same reason, they also may not be capable of serving as shock absorbers during periods of heightened volatility, as traditional market makers are thought to do. Thus, while the market may have come to rely on automated trading firms as suppliers of very-short-term intraday liquidity, market participants still rely on traditional market makers with balance sheet capacity to supply liquidity over longer-term horizons.\n\nElectronic trading, including automated and high-frequency trading, has likely had a number of benefits. For one, technological advances have supported market efficiency by increasing the pace at which price discovery is disseminated across financial markets. It may also have reduced transaction costs, both through the economies of scale that large technology investments produce, and perhaps through the maintenance of narrow bid-offer spreads that automated market-making arguably makes more likely. For example, automated market-making might allow an investor to instantaneously transact in a security at a visible price, with the market maker then able to immediately offset the risk by automatically hedging the exposure.\n\nElectronic and automated trading has also introduced risks to the Treasury market, as it has with other markets. For example, in the case of automated or high-frequency trading, firms must have sufficient internal controls to handle erroneous data and prevent malfunctioning algorithms. Considering that automated trading firms may hold limited amounts of capital given their minimal levels of net long or short exposure, some firms may be particularly vulnerable in the event of such an error. We have already seen some of these risks manifest themselves in foreign exchange and equity markets, where electronic trading is even more common. Further study is required to understand the particular nature of such risks in the Treasury market and the implications that may exist for other institutions, particularly since many automated trading firms are not direct netting members of FICC.  \n\nAutomated trading has also raised questions on issues related to fairness and market behavior. For example, there is likely some dispersion across firms with respect to the speed at which they can transact, which in turn could lead to dispersion in the quality of execution that market makers and end-investors are able to achieve. This is an important topic for examination and reflection, but it is also worth remembering that a varied level of technological access has long been a feature of competitive financial markets. For example, when the telegraph appeared in the first half of the nineteenth century, traders without immediate access cried foul when early users began leveraging the technology to minimize the time between trade decisions and execution.\n\nElectronic and algorithmic trading also has the potential to facilitate trading practices that are not helpful to market liquidity. For example, submitting a quote with the intent to cancel it before any reasonable probability of execution is detrimental to the quality of market liquidity and to the integrity of the market. Even if such acts are not intentionally misleading, they can still result in a false sense of market liquidity.\n\nFinally, firms employing high volume automated trading strategies could harm market liquidity if they do not manage those strategies carefully, particularly given the significant share of market activity they represent. As I will explain later, the Treasury Market Practices Group has updated its best practices to emphasize the importance of supporting market liquidity as well as avoiding automated trading strategies that create a false impression of market price, depth, or liquidity. In conjunction with those best practices, the TMPG also released a white paper on automated trading that reviews several categories of associated risk, including operational risk, potential systemic counterparty risk, market manipulation risk, and transmission risk.\n\nOctober 15\n\nLet me now turn to the unusual events of October 15. On that day, Treasury yields exhibited extreme volatility, with the benchmark ten-year yield trading in a range of about 35 basis points between the market open and close. This included a sharp decline in yields following the U.S. retail sales report at 8:30 ET that morning, and a highly unusual round-trip in yields just after 9:33 a.m. At that time, the ten-year yield fell about 15 basis points in a five-minute period, before nearly fully retracing that move in roughly the same increment of time. That very short \"event window\" was a remarkable occurrence in one of the world\u2019s most liquid markets, and likely reflected a unique dynamic on what was already an unusual day. Indeed, the net change on the session as a whole was less than 10 basis points\u2014a small fraction of the extraordinary intraday range that we are still discussing today (see the chart).\n\nHistorical examples of sharp intraday changes in U.S interest rates have tended to be associated with important economic events, such as major monetary policy announcements. There does not yet appear to be consensus by market participants around a single cause of the volatility on October 15. To be sure, a number of factors likely contributed, including concerns about the global macroeconomic outlook and the unwinding of positions by leveraged investors. Indeed, such concerns probably help explain why a modest surprise in U.S. retail sales could trigger such a strong reaction around 8:30. Publically available positioning data in the futures market does indicate that investors who take positions for purposes other than hedging had accumulated a large base of short positions in shorter-term interest rate futures contracts over the preceding months, and that that aggregate position unwound sharply in the weeks around October 15.\n\nYet these factors are less convincing as explanations of the round-trip in yields witnessed more than an hour after the data release. Activity in this event window also appears unconnected to any other piece of incoming information. As a result, many market participants and members of the official sector have questioned whether recent changes in the structure of the Treasury market can help explain the move, and some have focused on the potential role of electronic and automated trading.\n\nClearly automated trading likely played an important role in the speed of transmission of price movements from the Treasury market to other markets, since such technology allows investors to quickly identify and execute trades that are predicated on tight linkages between different markets. At the same time, some have suggested that firms engaging in automated trading may have \"unplugged\" their systems or carried out strategies that prompted or exacerbated the volatility. To be sure, the response of firms relying heavily on automated trading strategies to market volatility may be different than that of non-automated participants, given the ability of automated systems to rapidly adjust their risk exposure in response to evolving order book and market price dynamics. However, a wholesale retreat on October 15 is inconsistent with the extraordinarily high trading volumes observed throughout the day, and the continuous nature of trading that occurred even during the most volatile periods. Indeed, some past periods of very sharp changes in financial asset prices have been characterized by prices \"gapping\" from one point to another, with little trading in between. But this appears not to have been the case on October 15. Even so, it is possible that changes in the participation or behavior of firms employing automated strategies\u2014including broker-dealers and proprietary trading firms\u2014had an effect on market liquidity and price movements that day, even if there was no wholesale disengagement.\n\nOthers have suggested that the event window on October 15 is a byproduct of regulatory changes that have reduced traditional dealers\u2019 ability to serve as shock absorbers during periods of volatility by accommodating large net order flows. In particular, some market participants argue that recent regulatory changes have increased the cost that dealers face when expanding their balance sheets, leaving them less willing to do so for relatively low-margin businesses, such as making markets in Treasury securities. If true, it may help explain how an unwinding of large positions, as may have been observed in the sixty minutes after retail sales on October 15, could have had such a large impact on yields. But it is far from clear that such changes, on their own, can explain the round-trip in prices during the event window itself.\n\nThat said, it is possible that the dominance of electronic and automated trading and the changing composition of participants in the Treasury market have interacted with changes to dealer behavior\u2014whether the result of regulatory incentives or other reasons\u2014in a manner that makes unusual intraday price moves more probable. While it is precisely the intention of many recent regulatory initiatives to ensure that financial firms hold sufficient capital to support the size of their balance sheets and risk taking activities, there could be unintended consequences of these regulatory changes, including the possibility that sharp intraday price moves become more common.\n\nOctober 15 also raises questions about the nature of liquidity in the Treasury market today. As I mentioned earlier, market liquidity is a difficult concept to pin down, and if one asks how liquidity evolved on October 15, the answer will differ depending on the measure of market liquidity you have in mind. It is certainly the case that some frequently-cited metrics of liquidity, such as the quantity of orders available for execution in the CLOB at a given point in time, often referred to as \"market depth,\" showed significant signs of strain that morning. But volatility was also elevated, so a coincident reduction in market depth may be unsurprising. Indeed, an increase in volatility and reduction in depth can work in a self-reinforcing manner, in which reduced depth causes trades to have a greater price impact, while the resultant volatility causes market depth to shrink further. This dynamic has always existed in markets, but it is possible that automated trading serves to exacerbate it in certain situations. But even if a sharp reduction in market depth makes sense given an increase in volatility, a trade of reasonable size would have been more expensive for a customer to execute in the event window, and would have had a greater price impact, than in more normal conditions.  In this sense, liquidity was challenged, and frequent periods of strained liquidity would be undesirable for the most liquid sovereign debt market in the world. \n\nOthers might argue that liquidity on October 15 was reasonable, because the ability to transact, albeit in smaller than usual sizes, appears to have been there, even in the most volatile times. As previously noted, trading volumes were many times their normal levels during that morning, and trading took place on a continuous basis. If liquidity had really deteriorated so significantly, it may be unlikely that such extraordinary flows would have been possible. That being said, the simple ability to transact does not necessarily equate to strong liquidity, particularly if transacting is only realistic in a relatively small size, or if it is only possible to conduct a trade of reasonable size by \"paying\" a significant spread to the midpoint of the best bid and offer. \n\nRegardless of one\u2019s definition of liquidity, recurring periods of heightened and unexplained volatility \u2013 especially if prompted by little new information, as with the event window on October 15\u2014could prompt end-investors and market makers to question the superior liquidity of the Treasury market and perhaps hamper the critical roles the market serves.\n\nThe Treasury market serves as a liquid investment option for global investors, a ready source of collateral for other financial transactions, a benchmark for pricing other securities, an important component of the Federal Reserve\u2019s framework for implementing monetary policy, and a market for financing the government that determines borrowing costs to the taxpayer. Given these critical roles and the risks posed by periods of sharp volatility, understanding the manner in which the evolving market structure is affecting market liquidity, efficiency, and price dynamics is of the utmost importance, and something we plan to study further.\n\nBest Practices in the Treasury Market\n\nThe Treasury Market Practices Group (TMPG) recently released a consultative white paper that addresses the effects of ongoing changes in automated trading on the structure of the Treasury market. This study was well under way before October 15, but it includes some preliminary observations from the TMPG on that event as well.  The TMPG is a group of market professionals, sponsored by the New York Fed, committed to supporting the integrity and efficiency of the Treasury, agency debt, and agency mortgage-backed securities markets.  The group has released a wide range of best practices for these markets, including a fails charge that resulted in a dramatic decline in delivery fails in Treasury securities and agency MBS, and the recommendation to margin forward agency MBS trades, a practice that now covers most bi-lateral forward trades in that asset class. \n\nThe TMPG white paper on automated trading in the Treasury market includes an updated set of best practice recommendations that provide additional guidance for firms and trading venues involved with electronic and automated trading. Some of the changes to the best practices have to do with improving governance and back-office processes to keep pace with technological advancements. For example, the recommendations include maintaining better change control processes for designing, testing, and introducing trading technologies and algorithms. Additionally, they emphasize the importance of ensuring that risk management, clearing, and settlement processes are robust to challenges presented by the speed, sophistication, and potentially large gross trading volume associated with very rapid execution.\n\nThe updated best practices also emphasize the importance of avoiding automated trading strategies that create a false impression of market price, depth, or liquidity. While the possibility of such trading practices has always existed, electronic trading provides more efficient tools for this type of behavior, and might also give some participants the false impression that it is easier to hide such behavior.\n\nFinally, the enhanced best practice guidance recommends that market participants who represent a material share of daily trading consider the impact on market liquidity before making abrupt changes to automated systems or trading strategies. This last recommendation is an important addition to an existing best practice that calls for market participants to manage large positions with care. Whether a firm has a large position, or represents a sizeable share of market activity, it has the responsibility to help support market functioning and liquidity. Making significant changes to either such a position or trading activity could disrupt market functioning and liquidity if not done with care, and the TMPG calls for such positions and activity to be managed with particular vigilance. I would like to thank the TMPG for its continued excellent work in improving market practices.\n\nOnce the consultative period has concluded and the best practices are finalized, the TMPG calls for all participants in the Treasury, agency debt, and agency MBS markets to adopt these business practices. As primary dealers, you are, of course, also expected to implement these best practices. We also expect you to be good citizens of the Treasury market more broadly, and to be proactive in identifying worrying trends or suggesting further enhancements to these best practices as the market evolves further. You play a critical and central role in ensuring that the Treasury market remains a robust and efficient fixture of the global financial landscape.\n\nThank you.\n\n________________________________\n\n1 I would like to thank Michael McMorrow for his excellent assistance in the preparation of these remarks and colleagues in the Federal Reserve System for numerous insightful comments and suggestions.\n\n2 The \"Desk\" refers to the Federal Reserve Bank of New York\u2019s trading desk, which implements monetary policy on behalf of the Federal Reserve System, as directed by the Federal Open Market Committee.\n\n3 This figure is based on recent volume trends in the Federal Reserve\u2019s FR2004 database. This figure is not adjusted for double-counting issues that arise from primary dealers reporting transactions with other primary dealers. FR2004 also represents an incomplete picture of liquidity provision in the Treasury market, as it only captures activity conducted by primary dealers.\n\n4 At each Treasury auction, primary dealers are currently required to submit, at a minimum, their equally weighted share of the auction\u2019s total offering size to ensure coverage. This is known as the \u201cpro rata requirement.\u201d In the past, dealers were required to account for 1 percent of secondary trading, but this requirement no longer exists.\n\n5 The level of net marketable debt issuance is also affected by the Treasury\u2019s need to borrow for student loans and other credit programs. The Congressional Budget Office currently projects such additional borrowing to average $61 billion annually over the next ten years.\n\n6 Interestingly, Treasury bonds were traded on the New York Stock Exchange during the late 1910s and early 1920s, as the market grew with wartime financing needs. However, trading migrated to an over-the-counter market in the first half of the 1920s, in part because institutional investors, who were becoming an increasingly important part of the Treasury\u2019s investor base, found it a more efficient means of transferring risk.\n\n7 Although this was market practice through 1992, the Federal Reserve Bank of New York neither encouraged nor required this use of the primary dealer list.\n\n8 A CLOB protocol aggregates all executable bids and offers across participating liquidity providers in a single order book that is available to all market participants. In a liquid market, the continuous visibility of quotes and the interaction of multiple bids and offers are likely to enhance the price discovery process and market transparency. In contrast, a request-for-quote protocol, where a request for liquidity typically is submitted to only a limited set of providers, by its nature imposes a degree of market segmentation that may impede the price discovery process as compared with a CLOB protocol, but is arguably better suited to handle large block trades and illiquid securities.  \n\n9 Momentum detection is a strategy that attempts to predict short-run price changes based on patterns in real-time market data. Statistical arbitrage is a trading strategy that typically relies on identifying mean reversion from historical relative pricing relationships between correlated assets. Spread trading seeks to profit from a simultaneous purchase and sale of two closely related fixed-income assets.\n\n10 It is worth noting that the practice of trading with the intention of holding a position for a brief period of time is not new. For example, pit trading in the futures exchange featured traders who would look to earn spreads by holding positions for short periods of time and rarely overnight\u2014similar in many ways to the practices of modern automated trading firms.\n\n11 This raises the question of whether such firms are systematically capturing intraday exposures in their risk management systems. To the extent this remains a vulnerability, firms might consider near-term fixes they could put in place to insulate themselves from potential intraday losses."
  },
  {
    "title": "The National and Regional Economy",
    "date": "Apr 6, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150406",
    "content": "My meeting with you today is part of our continuing efforts to understand what is going on at the grassroots level of our economy.  We plan these trips so I can meet with a diverse array of stakeholders in the region.  This allows me to get a comprehensive picture of economic conditions in the region and a fuller understanding of the major issues and concerns.  This is our first regional trip for 2015 and the third time we have visited northern New Jersey in the past four years.\n\nI begin my day here at NJPAC and following this visit, I will take a tour of the Teachers Village, which is a new mixed-use community here in downtown Newark, attend a roundtable lunch meeting with members of the Statewide Hispanic Chamber of Commerce of New Jersey in Union City, and hear about the economic and community development activity in Jersey City from Mayor Steven Fulop.  I will then meet with nonprofit small business lenders to hear about lending conditions, and I\u2019ll end the day at Stevens Institute of Technology where I will learn how they have partnered with NBC Universal to create a new minor in media engineering to address a skills gap issue in the region.\n\nThese trips are one of the many ways in which we engage with people and businesses in our region.  We track the health of household balance sheets at the state and local level using data from the New York Fed\u2019s Consumer Credit Panel.  These data show debt balances and delinquency trends across all forms of consumer debt, including mortgages, student loans, auto loans and credit cards.  Later this month we will release a Regional Household Debt and Credit Snapshot that will provide an overview of the household debt trends in metropolitan areas within New Jersey.  We also conduct a biannual poll of small businesses to understand their credit needs and availability.  Based on the poll results, we have developed an ongoing series of clinics for small businesses to help them take the next step to access capital and identify new sources of funding.  We also get important input from our Small Business and Agricultural Advisory Council, whose members help us understand key economic and financial issues affecting regional businesses and communities.  This year we tapped two New Jersey business leaders to join the Advisory Council: Adenah Bayoh, co-founder of Kapwood, LLC, and Ranjini Poddar, founder of Artech Information Systems, LLC.\n\nLet me now review recent developments in the national and regional economy, and at the end of my talk, I will be happy to answer questions you may have about the economic outlook.  As always, what I have to say reflects my own views and not necessarily those of the Federal Reserve System or the Federal Open Market Committee (FOMC).1\n\nNational Economic Conditions\n\nAfter growing at just a 2 percent annual rate from 2010 through 2012, real GDP expanded more quickly in 2013 and 2014, rising at a 2.7 percent annual rate.  This was sufficient to push the unemployment rate down by more than two percentage points over this period.  This firming in growth reflected several important developments that, in my view, are likely to continue through 2015.  The data we follow suggest that the household deleveraging process has largely run its course and the imbalances in the housing market have been mostly worked off.  Federal fiscal consolidation appears to be over for now, and employment and spending are increasing at the state and local government level.\n\nThat said, economic performance in this cycle has been disappointing compared to historical patterns.  Even though household wealth relative to disposable income is nearly at its pre-financial crisis level and conditions in labor markets are substantially improved, consumer spending growth has been slower and the personal saving rate higher than what we would have expected based on past historical relationships.  Similarly, even with low mortgage rates, single-family housing construction has been surprisingly sluggish.  And, despite very accommodative financial conditions and record corporate profits, growth of business fixed investment has been tepid.\n\nLooking forward, my outlook for 2015 is that economic growth will be close to the pace of the past two years, supported by continued solid fundamentals and accommodative financial conditions.  If I am correct, then this would lead to a further reduction of labor market slack, with the unemployment rate approaching 5 percent by the second half of the year.\n\nAn important element of this forecast is continued strength in household spending.  This strength is supported by the restored health of household balance sheets, improved household income prospects and the benefit of significantly lower energy prices.  The data for the second half of 2014 reflect these positive forces: real personal consumption expenditures grew at a 3.2 annualized rate in the third quarter and a 4.4 percent rate in the fourth quarter.  This strength in consumption was accompanied by solid income growth, as real disposable income increased at a 3.6 percent annual rate in the fourth quarter, reflecting the stronger labor market.\n\nThe pace of improvement in the labor market has slowed in recent months from the strong pace at the end of last year. Nonfarm payroll employment increased in the first quarter by about 200,000 per month, well below the pace of the fourth quarter. This slowdown was broad-based, with job growth slowing in both the goods-producing and the service-providing sectors.\n\nThe unemployment rate was 5.5 percent in March: analysis by my staff suggests that the unemployment rate is nearing the point where we may begin to see a pickup in the pace of real wage gains. If this proves correct and unemployment continues to decline as I expect, then these stronger wage gains could help support solid income growth even if the pace of employment growth slows.  However, it will be important to monitor developments to determine whether the softness in the March labor market report evident on Friday foreshadows a more substantial slowing in the labor market than I currently anticipate.\n\nThe March labor market report is another indicator that the first quarter is likely to be quite weak.  Our current projection is that the economy will grow at about a 1 percent annual rate in the first quarter of 2015.  This softer performance is suggested by a wide range of recent indicators that have surprised to the downside over the past couple of months.  Examples of such indicators include retail sales, the ISM manufacturing index, manufacturing production and orders, and single-family housing starts.\n\nOverall, I view these downside surprises as reflecting temporary factors to a significant degree.  For example, some of the recent softness is likely due to yet another harsh winter in the Northeast and the Midwest.  My staff\u2019s analysis of a measure of both the amount of snow and the population affected indicates that January and February weather was 20 to 25 percent more severe than the five-year average.  Such large deviations appear to have meaningful negative impacts on a number of economic indicators.\n\nEven so, there are some downside risks to the growth outlook.  In particular, the steep decline in crude oil prices is likely to lead to a further sharp drop in U.S. oil and gas investment.  Additionally, the significant rise in the value of the dollar is likely to lead to weaker U.S. trade performance. \n\nLet me discuss each of these in more detail. Energy prices have declined sharply since mid-2014.  In recent weeks, the benchmark West Texas Intermediate (WTI) oil price has been hovering in a range of $45 to $50 per barrel, less than half the price in June of last year.  This creates both positives and negatives for the U.S. economy.  Starting with the positives, since the U.S. is still a net importer of petroleum, this development has provided substantial benefits, with our oil import bill down by about a \u00bd percentage point of GDP.  As I indicated earlier, that represents a significant boost to real disposable income for households.  How much this energy windfall boosts consumption will depend, though, on how much is spent versus saved.\n\nTurning to the negatives, the support to growth from rapidly rising U.S. oil production almost certainly will fade away.  U.S. oil production has been rising rapidly for several years, due largely to new technology that has expanded the amount of oil that can be recovered from existing wells and that has facilitated shale oil production by fracking.  Now, with prices dramatically lower, U.S. oil exploration and drilling activity is falling off very sharply. This will exert a meaningful drag on economic activity.\n\nAnother significant shock is the nearly 15 percent appreciation of the exchange value of the dollar since mid-2014.  Such an appreciation makes U.S. exports more expensive and imports more competitive.  My staff\u2019s analysis concludes that an appreciation of this magnitude would, all else equal, reduce real GDP growth by about 0.6 percentage point over this year.\n\nTurning to inflation, the data continue to come in below the FOMC\u2019s objective of a 2 percent annualized rate for the personal consumption expenditures (PCE) deflator.  The twelve-month change of the total PCE deflator was 0.3 percent in February, with the core PCE deflator at 1.4 percent.  Despite this, my expectation is that inflation will begin to firm later this year.  In particular, most of the impact from the decline in energy prices that has weighed down overall inflation is likely over.  Although the appreciation of the dollar is likely to cause some further softness in import prices, the continued decline in resource slack as the economy expands should push in the opposite direction.  In addition, longer-term household inflation expectations have been well maintained through this period of very low inflation, as indicated by our Survey of Consumer Expectations.  The combination of stable expectations and declining slack should push inflation slowly back towards the FOMC\u2019s objective.\n\nMonetary Policy\n\nAs the FOMC has consistently communicated, the timing of lift-off will depend on how the economic outlook evolves.  As I have discussed, the labor market has improved substantially and I expect to see inflation begin to firm later this year.  If this labor market improvement continues and the FOMC is reasonably confident that inflation will move back to our 2 percent objective over the medium-term, then it would be appropriate to begin to normalize interest rates.  At the March meeting, the FOMC removed language from the statement that indicated that we would be patient in beginning the process of normalizing monetary policy.  But, as Chair Yellen remarked in her most recent press conference, removal of \u201cpatient\u201d from the statement does not indicate that we will be \u201cimpatient\u201d to begin to normalize monetary policy.  Rather, the timing of normalization will be data dependent and remains uncertain because the future evolution of the economy cannot be fully anticipated.\n\nWhenever the data support a decision to lift off, I think it is important to recognize what this would signify.  It does not mean that monetary policy will be tight.  We will simply be moving from an extremely accommodative monetary policy to one that is slightly less so.  It also will be a positive signal about the progress we have made in restoring the economy to health.  In my view, it would be a cause for celebration, because it would signal that the FOMC believes that slightly higher short-term interest rates are consistent with its objectives of maximum employment and price stability.  Near-zero short-term interest rates and a larger Federal Reserve balance sheet were designed to be a temporary extraordinary treatment to help the economy regain its vitality, and not a permanent palliative.\n\nI remain confident that when the FOMC does decide to begin to remove policy accommodation that we have the requisite tools to effectively support this decision.  We have tested numerous tools including overnight reverse repurchase operations, term reverse repurchase operations, and term deposit facilities to ensure that, when the time comes, lift-off can be managed smoothly.  The primary tool will be interest on excess reserves (IOER), with overnight reverse repurchases as a supplemental tool to be used as needed to ensure a firm floor under short-term interest rates.\n\nFor financial markets, the likely path of short-term rates after lift-off is just as important as the timing of lift-off.  Here, I anticipate that the path will be relatively shallow.  Headwinds in the aftermath of the financial crisis are still in evidence, particularly the diminished availability and tougher terms for residential mortgage credit.\n\nHow fast the normalization process will proceed depends mainly on two factors: how the economy evolves and how financial market conditions respond to movements in the federal funds rate.  If financial market conditions do not tighten much in response to higher short-term interest rates, we might have to move more quickly.  After all, the point of raising short-term interest rates is to exert some restraint on financial market conditions.  In contrast, if financial conditions tighten unduly, then this will likely cause us to go much more slowly or even to pause for a while.  At the end of the day, we will move short-term interest rates to generate the set of financial market conditions that we deem is most consistent with our employment and inflation objectives.\n\nHow high will short-term rates ultimately need to go?  I think this issue is very difficult to judge for a number of reasons.  First, it depends on how financial market conditions evolve in response to our monetary policy adjustments.  Second, it depends on other factors, such as real potential GDP growth, which, in turn, depends on the growth rates of the labor force and of productivity.  My current thinking is that the long-run nominal federal funds rate consistent with 2 percent inflation is somewhat lower than in the past.  My point estimate is 3\u00bd percent, but I wouldn\u2019t bet the farm on this.  I have considerable uncertainty about this estimate.\n\nRegional Economic Conditions\n\nNow let\u2019s turn to the New Jersey economy.  One feature of the state\u2019s economy is its industrial diversity.  A sizeable number of jobs in the state are in the healthcare, professional and business services, wholesale and retail trade, and leisure and hospitality categories.  When we look at the northern part of the state, we see a greater concentration of jobs in finance, particularly in Hudson County. Also prominent are goods distribution jobs related to the ports, rail lines, trucking and warehousing.  Other large sectors include pharmaceuticals manufacturing and research and development, as well as private education.\n\nLooking at recent trends in northern New Jersey, the recovery in the economy in general\u2014and in employment in particular\u2014is lagging the nation and is not going as well as we would like.  The Garden State\u2019s economy lost a quarter of a million jobs during the recession, and employment didn\u2019t begin to recover until 2011, and even then it was slow getting started.  However, the latest annual employment revisions\u2014released just a few weeks ago\u2014show job gains in 2013 and 2014 were a bit stronger than previously reported.  Nevertheless, four years into the recovery, employment has recovered less than two-thirds of the job losses from the recession.  This contrasts notably with both New York State and the U.S. as a whole, where employment has far surpassed its earlier peaks.  Moreover, here in Essex County, there has yet to be any significant upturn in jobs, although neighboring Hudson County has seen a fairly strong rebound.\n\nThat\u2019s not to say that there aren\u2019t any strong industry sectors here in New Jersey: job growth has been quite robust in health services, transportation and warehousing, construction and a number of business service industries.  There has also been steady job creation in retail trade and leisure and hospitality, though these tend to be low-paying sectors.  On the other hand, employment remains depressed in other industries such as finance, publishing, telecommunications and manufacturing.\n\nSo why is New Jersey not keeping pace with New York in terms of job growth?  Well, much of the strength in New York State has been driven by New York City; other parts of the state have seen similar, if not weaker, job growth than New Jersey.  Of course, this raises the question: why has New York City\u2019s economy been so much stronger?  In fact, there is a body of research suggesting that the long-term drift of economic activity and jobs from cities to suburbs has subsided, and that there is a growing trend toward re-urbanization\u2014a preference for both people and businesses to locate in cities, like New York.\n\nYet there is also a strong tendency for persistent strength in an urban hub to gradually spill over into nearby areas.  With both commercial and residential rents, not to mention sales prices, high and rising in Manhattan, northern New Jersey has an opportunity to capitalize on its widening cost advantage by attracting companies and residents that value an urban location, but find New York City to be too pricey.  And if preferences are indeed in the midst of a long-term shift toward urbanization, this bodes particularly well for New Jersey\u2019s own cities.  With a major international airport and seaport, a 20-30 minute train ride from most of Manhattan\u2014but much cheaper rents\u2014as well as a number of universities and a solid infrastructure, Newark has strong potential to develop its prominence as a major local business, economic and cultural hub.\n\nConcluding Thoughts\n\nTo conclude, I would like to say a few words concerning proposals to reform the Federal Reserve System.  First, I concur with Chair Yellen that the Federal Reserve already is very transparent and accountable to Congress and to the public. I share her strong belief that the independence of the central bank to make appropriate policy decisions consistent with its legislated mandates is essential to a nation\u2019s economic well-being.\n\nWith regard to the structure of the Federal Reserve System and the role of the regional banks, including the New York Fed, I also agree with Chair Yellen that the system is working well, and I do not see a need for any substantive changes.  I believe that the System has been designed appropriately so that a wide range of regional views are represented.  At the same time, I believe that the Federal Reserve System\u2019s monetary policy responsibilities are allocated appropriately by the Federal Open Market Committee, with New York playing an important role to ensure that monetary policy is executed effectively even during periods of duress.  Of course, the Federal Reserve System and the New York Fed are not perfect institutions.  That is why we always must strive, in an open and transparent manner, to improve what we do and how we do it, for the benefit of the American people.\n\nThank you for your kind attention.  I would now be happy to take some questions.\n\n1 Jason Bram, Chelsea Cruz, Tony Davis, Jonathan McCarthy, James Orr, Richard Peach, Paolo Pesenti and Joseph Tracy assisted in preparing these remarks."
  },
  {
    "title": "The Importance of Addressing Cybersecurity Risks in the Financial Sector",
    "date": "Mar 24, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dah150324",
    "content": "Introduction\nI would like to thank Operational Risk & Regulation for inviting me to speak here today. I appreciate the opportunity to address this group and kick off what looks like a very interesting and comprehensive few days of dialogue around current and future risks facing the industry.\n\nAs always, my remarks today reflect my own views and not necessarily those of the Federal Reserve Bank of New York or the Federal Reserve System.\n\nI will begin my remarks with a high-level overview of the progress made in recent years in addressing some of the most significant risks facing the industry following the financial crisis.\n\nI will then go on to discuss one of the areas where I see some of the biggest challenges in the road ahead. As the industry continues to adapt to and implement necessary regulatory changes, it is also adapting to and leveraging technology changes: technology changes that offer both exciting opportunities and more complex risks than\u2014I think\u2014we are prepared for.\n\nProgress\nComing out of the financial crisis, we all knew that we needed to be better prepared for future crisis events, whatever their character, source or timing. We needed financial firms, and a financial system, that was better prepared to weather all storms.\n\nIn 2011, we developed the Framework for Supervision\u2014a framework designed to ensure we had firms and a system that were less complex, more resilient and better managed.\n\nCollectively, we have made a lot of progress since 2011\u2014and the industry is in much better condition relative to the pre-crisis period. But, as you all know, business does not stand still and this constant evolution results in new risks and new challenges.\n\nBefore turning to one of the biggest risks or challenges I see, I want to pause and recognize two things:\n\nWhat the Future Holds\nOne of the topics that I feel will compete for, and will deserve, a lot of attention in the foreseeable future is cybersecurity.\n\nI am often asked about my list of \"things that keep me awake at night,\" and I think it's fair to say that cybersecurity is at the top of that list\u2014as I\u2019m sure it is for many of you in this room.\n\nIn fact, I think cybersecurity is one of the topics that should be on everyone\u2019s list\u2014from the most senior managers and boards of directors, all the way down to line managers. Cybersecurity is not a topic or an issue just for the Information Technology staff or the CIO to address; it is a risk that isn\u2019t exclusive in who, what or where it targets.\n\nThe financial sector, in particular, is under unprecedented attack from a broad spectrum of intent and attack methods that are complex, widely distributed, and increasingly interconnected. These highly dynamic systems give rise to the \u201cnew normal\u201d\u2014system design and architecture that needs to support rapid and compartmentalized change.\n\nSo, where do we begin when we look at a risk of this magnitude? And, how do we get our arms around the many associated risks that surround it?\n\nLet me begin with what it is not. Cybersecurity is not an \u201cInformation Technology\u201d issue. It is not a risk that can be addressed by simply having a strong IT team in place. It is not a risk that just affects a firm\u2019s technology\u2014it affects the business itself, in every aspect\u2014the bottom line, reputation, processes, and so much more.\n\nHowever, information technology and cybersecurity are intrinsically linked. I\u2019d like to cover both of these issues in my remaining remarks and focus on several of the underlying issues that need to be addressed.\n\nInformation Technology and Legacy Issues\nThe first dimension is legacy: there is still a great deal of \"clean-up\" to do to fix longstanding technology and data issues that have built up over the years. The investments necessary are long-term and the fixes, in many cases, will take multiple years to execute. The range of issues include: systems or processes that are manual or not fully automated; asset management tools that are drastically insufficient; and business processes and models built without security requirements, to name but a few.\n\nAs firms address these challenges, they must also be flexible and agile enough to keep up with the changing environment and incorporate new developments as they arise. While a number of firms have sound programs in place to address these longstanding issues, strong project management and tenacity will be crucial to see them through. In addition, continued prioritization and commitment of resources, as well as support from the firm\u2019s senior management and board of directors, are critical. I see commitment to this basic \"blocking and tackling\" as essential to financial institutions\u2019 continuing to be competitive\u2014and relevant\u2014in the digital world.\n\nWhile the legacy issues need to be addressed in the near-term and quickly, we can\u2019t hold off on addressing the vast number of issues around cyber\u2014since cyber is upon us now.\n\nInformation Technology and Cybersecurity\nThe area where I will spend most of my time discussing today is cybersecurity. Suffice it to say that as I think about the kinds of risks that might cause the next crisis, cybersecurity is the one that worries me the most. While I will focus my remarks on the financial sector, my concern is not limited to the financial sector. This is much bigger than just banks or financial institutions; it includes many other sectors as well.\n\nAs it relates to the financial industry in particular, the interconnectedness of firms continues to pose a particular risk to financial stability; from trading systems to settlement activities, we are at risk of a major disruption to financial stability. During the last financial crisis, we began to get a glimpse into the challenges faced as a result of interconnectedness and systemic failures. Years later, we are still faced with some of the same challenges, with only a limited view into the true complexities behind how firms are linked, connected, and ultimately intertwined to form the fabric of the financial industry. While we have begun to address other areas of systemic risk, I feel the industry as a whole is just beginning to scratch the surface of the potential system-wide impact of a significant cyber-attack. This risk can be referred to as \u201csingle point of failure.\u201d What is this? These are areas that, despite all of the work that has already been carried out, are significantly more vulnerable than others. We need to identify where they are and focus our combined efforts on understanding their systemic impact and addressing them.\n\nI want to be very clear here. I don\u2019t think that this isn\u2019t a regular topic of conversation among directors, executives and managers\u2014in fact, based on discussions I\u2019ve had with many of you, I know that it\u2019s quite the opposite. There is a lot of discussion within firms about the topic\u2014and there\u2019s quite a bit of activity more broadly that suggests that many different people are talking about cyber. There are conferences on cybersecurity every week. Consultancy firms are working with the industry on how to protect against attacks. Law enforcement agencies are investigating and cracking down on attacks and those behind them. Everyone is talking about this! And, I think that\u2019s appropriate and necessary\u2014this is everyone\u2019s issue.\n\nAs we engage in discussions on the subject and flesh out our plans to address this risk, there are a number of topics that are key to keep in mind. Before I go through that list, I want to provide an overview on where we, at the Federal Reserve Bank of New York, are in our process.\n\nWhile cybersecurity has been on our agenda for quite some time, and we have been dedicating resources to assessing it in large complex firms and setting expectations for smaller firms, we have elevated our efforts in recent months and have formed a dedicated team focused on further strengthening our overall supervisory approach to cybersecurity. As I mentioned at the beginning, I think we've done a reasonable job in developing rules and regulations to ensure firms are prepared to withstand the other types of shocks we have experienced in the past. But, cyber adds an element to planning for the next crisis that goes beyond what additional capital and liquidity, for example, can provide to the system.\n\nThe newly-formed team, led by Roy Thetford, the former Information Security Officer for the Bank, will be working with our examination teams to establish a new risk-based cybersecurity assessment framework, based on best practices in the field, as well as exploring additional standards that might be set out for supervised institutions.\n\nIn addition, to further strengthen and build out our program, we will be collaborating with critical stakeholders, including experts in security and cybersecurity; financial institutions, including both banks and non-banks; critical third-party service providers; domestic regulatory bodies; enforcement agencies; and international supervisors. As we move forward with developing the framework and standards, we are reviewing current and emerging laws, regulations and guidance; further researching best practices; and identifying gaps in current assessment efforts. As we do this, we have identified a set of issues that are top of mind:\n\n1. This is not just an IT issue.\nAs I mentioned earlier, cyber isn\u2019t just an IT issue. I don\u2019t think I can say this enough. It is a business issue first and foremost and needs to be tackled as such. Cyber needs to be owned by the business leaders in the firm\u2014partnering with the experts of course. There needs to be a foundational shift in thinking at the top of the house: it needs to be a regular topic on the agenda for the board of directors; it needs to be at the top of the priority list for senior management of the firm; and it needs to be on the mind of every employee, to some extent. It needs to be part of everyone\u2019s vocabulary and recognized as a valid threat at every level.\n\n2. Good risk management is the foundation.\nGood risk management and good IT practices set the foundation for a solid program to address cyber-related risk. It\u2019s hard to imagine that a firm that doesn\u2019t manage its IT risk well is ever going to be able to manage cyber risk well. In fact, two areas that we recently reviewed that require attention include basic IT asset management and strengthening patch and vulnerability management practices. These are necessary hygiene steps and should be a fundamental for a sound cyber security defense program.\n\nAs part of good risk management, firms also need to start considering how to assess the costs of cyber and connect the pricing of cyber risk to the businesses. You must ask yourself \u201cwhat is my cyber exposure?\u201d And, you need to think about how you should price it, because until cyber is priced, it may not get the attention it needs.\n\n3. It's not just the banks.\nCyber isn\u2019t just about the banks\u2014it\u2019s about the entire financial sector, as well as the connections between the financial sector and other sectors like the utilities, retail, and others. We know that every area of the industry is interconnected; and it\u2019s not just financial firms. As the old saying goes, we are only as strong as the weakest link. In the financial system, that weak link could be a weak firm, a weak vendor, a weak point of vulnerability in a payments or clearing system, etc. A weakness in any of these areas exposes the entire system, because the interconnections mean that you are all linked to each other, to non-financial firms, and to every system that supports the operations and structure of the industry. The additional risk to keep in mind here is the growing number of unregulated firms operating in and competing in this arena. As the industry moves to overcome the risks associated with cybersecurity, you have to consider the additional vulnerabilities you are exposed to through non-regulated entities that will not be subject to the same guidance and standards. The big question lies in how you, as an industry, ensure that the \u2018industry as a whole\u2019 is safe, not just regulated entities.\n\n4. One size does not fit all.\nJust as firms are diverse in size, complexity and product offerings, so too are technologies, processes and systems. While some firms house all technology work internally, others outsource the entire function or a significant part of it to third-party vendors.\n\nIn addition to the variety of systems used and approaches to information security within firms, as I said earlier, we have an entire subsystem that supports the financial sector and ultimately connects every firm to some extent. In response to this, we are working under the assumption that there will not be a one-size-fits-all solution and the approach taken will need to be comprehensive and flexible enough to be adopted by all types of firms.\n\n5. We are in this together.\nCybersecurity is an area where I believe our interests are aligned and our shared goal is two-fold. In addition to wanting to see firms that are adequately protected against cyber-attacks and prepared to respond should they occur, we are equally as concerned with the overall safety and soundness of the financial system\u2014as a whole. No one firm or agency is going to come up with the one and only permanent solution or protection against cyber-attacks. I see how we approach cybersecurity similar to how we approached Y2K\u2014I\u2019m sure you all remember that.\n\nCybersecurity is a \u201cnew normal.\u201d It is going to become part of our vocabulary in nearly every exam we conduct, conversation we have with senior management, and conversation about the future of financial services.\n\nTo be successful, we have to agree that we have common goals; although we can approach them from different angles and think creatively about solutions, we should all be working toward understanding the threats we are facing. The threat landscape is shifting constantly, and we are all responsible for keeping up with the changes and adapting our controls accordingly. This includes firms, systems that support the industry, third party vendors, consultants, regulators, and law enforcement.\n\n6. We need to leverage best practices.\nLeveraging a common set of best practices across the industry will be an important first step in closing the gap on the current vulnerabilities. Unlike the approaches taken by other supervisors to address cybersecurity concerns, our initial focus in this area is on better understanding the vulnerabilities, how firms are addressing them, what progress has been made by firms and assessing where the industry stands as a whole. Yes, we want you to address the weaknesses, but this is a lot bigger than the weaknesses identified at one firm.\n\nWe will be looking to firms to leverage guidance around best practices to identify their weaknesses, and we want firms to bring forward other issues, concerns or vulnerabilities they encounter in doing so. We need to identify, as an industry, where the risks truly lie and what we are doing about them.\n\nThere has been a lot of work done in this area by experts, including the NIST, the FBIIC, FINRA, PRA, FFIEC, NCUA, etc.\u2014the list goes on. And, there are a number of sets of best practices already published. We are aware that firms have been looking for guidance on which approach to take or framework to adopt. As we review all published guidance, assess the broad volume of research that is already out there and come to consensus on an evaluation framework, we encourage firms to look at the fundamental commonalities across all best practices and build them into your ongoing/current activities.\n\n7. Assessing the threat.\nTo fully assess a threat or risk to a firm, we must first understand where the risk lies, who it affects, how it is defined, and what the associated costs are. In the case of assessing the risk and impact of cyber-attacks, I believe firms need to be cognizant that every business decision, every process, every change a firm makes ultimately has a cyber-related element to it. To add to the complexity of this, the firm\u2019s self-awareness must extend beyond the four walls of their company and must also take into account the impact critical service providers have on the firm. You can outsource the service, but not the risk.\n\nEveryone should be using threat intelligence as we go about our day-to-day activities\u2014using the potential of a cyber-attack as another filter through which we view every decision. As we think about the variables to be considered in the decision-making process, we must build in the potential for creating weaknesses, vulnerabilities or opportunities for cyber-attacks, and be aware of the associated costs.\n\nI fear that until we can assign financial consequences to cyber risks, and ensure staff are taking that into account when making decisions, we will not get the commitment needed from every level of the organization to adequately address the problem. As long as decisions are made and actions are taken without this type of assessment, we are going to see more and more of these weaknesses exposed. These vulnerabilities are not necessarily new, but the exposure to them is increasingly being made available to attackers. For instance, a weak patch management process comes with the risk that systems may take longer to patch (or not be patched at all!) resulting in a much larger target window of opportunity for attackers.\n\nAs we assess the potential impact, it is also important to remember that protecting against an attack is only half the solution\u2014particularly because, as my InfoSec colleagues like to say: \u201cIt\u2019s not a matter of IF we get hacked; it\u2019s a matter of WHEN.\u201d A strong cyber resiliency program is a good starting point to address this, but we also need to focus on limiting the impact following an attack by addressing the fundamental structure within the organization\u2014how safe is the system, how compartmentalized are the core areas of technology, and what your ability is to isolate the threat.\n\n8. Need to address communications.\nFinally, to successfully address this risk with a unified front, we must develop an approach to enhanced communications around cyber threats and events, and revisit supervisory guidance in this area. Silence and fear of sharing intelligence in this area could be detrimental to efforts to address the vulnerabilities systematically. We know that breaches have occurred and will continue to occur until the industry is better equipped to be ahead of the attackers, not playing catch up. Right now we are interested in learning from these breaches and using intelligence garnered to get ahead of game.\n\nThere is a lot to think about here. With all this in mind, I will end this part of my remarks with a reminder of what we see as the key components of any solution designed to address cybersecurity. It must:\n\nConclusion\nWe live in an ever-changing environment where speed and agility are of the essence. Demands from customers change, expectations from shareholders fluctuate and the regulatory landscape you work within will continue to evolve to keep pace. Constant change\u2014and commitment to evolution\u2014is not a choice. It is the only way to survive, stay competitive and stay safe in a complex and vulnerable world.\n\nAs it relates to cybersecurity, I believe we are at a pivotal moment: we know there is an issue; we will work with you on fully understanding the scope and breadth of the risk; we will be pragmatic and add value; we are looking at this holistically; and our goal is to come out with a set of next steps that will benefit all of us, including protecting the financial system and the U.S. economy as a whole.\n\nWe need to address cybersecurity before we see a catastrophic event, not analyze it afterwards.\n\nThank you."
  },
  {
    "title": "U.S. Macroeconomic and Regulatory Developments and Emerging Market Economies",
    "date": "Mar 9, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/mus150309",
    "content": "Thank you for the invitation to speak here today.  It has been a pleasure to attend this conference, and to have the opportunity to exchange views with many of you. \n\nMy remarks today will focus on the potential effects of the U.S. outlook and policy for emerging market economies.  I will make three main points.\n\nBefore I turn to the specifics, let me remind you that what I say today reflects my own views, and not necessarily those of the Federal Reserve Bank of New York or the Federal Reserve System.\n\nSince the end of the Great Recession almost six years ago, U.S. growth has averaged a somewhat disappointing 2.3 percent.  But growth has picked up recently, and the latest Blue Chip forecast is for growth to average slightly below 3 percent over the next year.\n\nThere are good reasons to think that a period of stronger growth can be sustained.\n\nOf course, there are important risks to the growth outlook including:  whether households behave cautiously relative to fundamentals given the experience of the Great Recession; the extent of the impact to the oil producing sector from lower oil prices, and the direction of the business cycle abroad.  The FOMC\u2019s view in its January statement was that the risks to U.S. growth are nearly balanced. \n\nThere are also risks in both directions to the inflation outlook.  Headline inflation has fallen quite low due to the drop in oil prices. These effects are likely to be transitory.  Measures of underlying inflation such as the core PCE deflator have been running somewhat short of the FOMC\u2019s 2 percent objective for some time.  Moreover, market-based measures of medium-term inflation compensation have fallen somewhat below the objective in recent months, even if survey measures of expectations have held essentially steady.\n\nThere are also upside risks to inflation.  The unemployment rate has declined and wage growth should firm as remaining slack diminishes.  Moreover, the U.S. economy\u2019s productivity performance has been relatively unimpressive in recent quarters.  If continued, this could also begin to push inflation higher. \n\nIt is in this context that the Committee has begun to consider the appropriate timing and pace for removing extraordinary accommodation.  The Committee stated in January that \u201cit can be patient in beginning to normalize the stance of monetary policy,\u201d and that the timing of any policy shift will be data dependent, based on an ongoing careful evaluation of progress towards the Committee\u2019s goals of maximum employment and 2 percent inflation.1\n\nEmerging market officials and market participants have expressed concerns that Fed liftoff might spark an undue tightening in global financial conditions, creating a new growth headwind for emerging market economies.  These concerns are understandable.  The Federal Funds rate has been near the zero lower bound for more than six years.  The Taper Tantrum in the spring and summer of 2013 provides a ready reminder of the potential for volatility around actual or perceived news concerning Fed policy.\n\nLike other central banks, the Fed\u2019s monetary policy mandate is defined in domestic terms.  Yet the Fed takes the potential international implications of its policies quite seriously.  In part, this comes from a sense of a special responsibility given the international reserve currency status of the dollar.  An outward-looking perspective is also warranted because the international effects of Fed policies can spill back onto the U.S. economy and financial conditions.   \n\nIt is of note that emerging market economic performance during previous Fed tightening cycles has generally been good.  During the last three U.S. tightening cycles, EME industrial production growth has come to between 7\u00bd and 10 percent over the 12 months from the start of Fed tightening, while EME export volumes have risen 10 to 15 percent.  A likely explanation for this favorable record is that Fed tightening generally occurs during periods of strong U.S. economic performance.  Recent research from the IMF bears out this hypothesis, finding that higher U.S. interest rates associated with stronger U.S. growth represent a net positive for EMEs.2\n\nFinancial performance of EMEs has been more diverse across Fed policy cycles.  The strongest contrast is between the tightening cycle that began in 2004, and the one beginning a decade earlier, in 1994.  EME asset prices strengthened considerably during the 2004 cycle, but weakened considerably during the earlier cycle.  Notably, the 1994 cycle was associated with a large increase in U.S. long-term bond yields, and appears to represent a case in which there was some distance between Fed policy and market expectations.  Other IMF research suggests that anticipated Fed tightening moves have historically been followed by only a minor pullback in private capital inflows, while unanticipated tightening has typically been followed by a pullback in private flows some four times as large.3  This evidence highlights the importance of transparency and clear messaging in how the Fed is evaluating the evolving economic landscape.\n\nThe FOMC has taken a number of steps in recent years to increase transparency and improve communications.  This includes press conferences by the Fed chair following FOMC meetings; the publishing of growth and inflation forecasts of FOMC participants; participants\u2019 projections of the Federal Funds rate at various horizons; and a concerted attempt to lay out the guideposts that the FOMC will look at to assess progress toward its mandate.  These steps are aimed at reducing the risk that Fed policy adjustment might be associated with undue market volatility.  \n\nThe stance of Fed policy will be far from the only thing affecting the global landscape facing EMEs.  As the FOMC considers the appropriate timing and pace of moving to a less accommodative policy stance, central banks in the Euro area and Japan are in the process of implementing additional easing measures.  Other important factors affecting the global terrain include China\u2019s slowing of credit growth without derailing economic growth, the behavior of oil and other commodity prices, and EMEs\u2019 own domestic fundamentals and growth dynamics.  Fed policy will be only one factor.\n\nEME fundamentals are likely to be an important determinant of how EME financial conditions respond to Fed policy normalization.  This was one of the key lessons from the Taper Tantrum.  At first, market pressure was somewhat indiscriminant and then later became more discerning with respect to EME fundamentals.  Financial conditions tightened, especially for countries with fundamental vulnerabilities including: large current account deficits, a heavy reliance on portfolio inflows, and high and above-target inflation rates.  Markets then responded favorably as EME authorities shifted toward clear, more consistent policies focused on inflation objectives and external sustainability, and away from policies with multiple and sometimes competing objectives.\n\nLet me now add a few thoughts about ongoing financial reform efforts.  The complexity, severity and speed of the global financial crisis required a forceful and wide-ranging international regulatory response.  This has included higher capital and liquidity standards, stronger recovery and resolution regimes for supervised institutions, and greater transparency and standardization in derivatives markets.  These efforts will have a number of positive effects, although they may lead to some changes in bank business models and strategy in the U.S. and internationally.\n\nIn the U.S., these efforts have made the banking system much stronger today than before the crisis.  In aggregate, Tier 1 risk-based capital ratios among U.S. bank holding companies have increased to just under 13 percent, an increase of almost 45 percent relative to pre-crisis levels, and the quality of capital has improved.  Bank holding company balance sheets are also significantly more liquid, with liquid assets increasing from 26 percent of total assets at end-2006 to 38 percent at end-2014.  Core deposits now fund 44 percent of total assets, a 10 percentage point increase from pre-crisis levels.  A stronger U.S. banking system better protects against future shocks, provides a more solid foundation for growth, and therefore also enhances prospects for growth and financial stability abroad. \n\nBasel III implementation has been proceeding on a comparable basis in advanced and emerging market countries.  The Financial Stability Board has been monitoring the unintended effects of reforms on EME banks and EMEs report no significant adverse effects.4  However, potential differences in reform implementation across jurisdictions could create challenges, particularly in countries where foreign banks are active.  This underscores the importance of continued home and host coordination.\n\nI would like to briefly touch on two U.S.-specific financial regulatory issues with international implications, namely enhanced prudential standards for foreign banks, including intermediate holding company requirements for the largest institutions, and issues surrounding correspondent banking, U.S. anti-money laundering rules, and \u201cde-risking\u201d.  Of these, the latter may have the most relevance for the EMEs broadly.\n\nThe adoption of enhanced prudential standards for foreign banking organizations (FBOs) is a key element of U.S. regulatory reforms, and a significant change in supervision of FBOs.5  The largest FBOs (with U.S. non-branch assets greater than $50 billion) must hold their U.S. subsidiaries under an intermediate holding company (IHC), and meet various capital, leverage, liquidity, stress testing, risk management and corporate governance requirements.  These requirements respond to a mandate in the Dodd-Frank Act for enhanced standards for the largest domestic and foreign banks.  The most significant requirements are expected to fall on the largest FBOs from advanced economies\u2014some of which have also adopted tighter local requirements for foreign banks\u2014and should contribute importantly to a safer and sounder U.S. and international financial system.\n\nCorrespondent banking relationships have also received heightened attention in the context of serious violations of anti-money laundering and know-your-customer standards by some banks, and substantial fines.  It is imperative to firmly deal with illegal, unsafe and unsound banking practices, including money laundering and transactions with U.S.-sanctioned countries.\n\nIt is also important to be on the look-out for potential unintended consequences and externalities, such as widespread de-risking where correspondent bank access is shut off to compliant counter parties and to legal flows, economic costs are excessively increased, or flows migrate to avenues subject to less oversight or transparency.  The scope, scale, and impact of de-risking need to be better understood.  Dialogue between market participants and the official sector is ongoing, both multilaterally and bilaterally.\n\nLet me conclude.  The U.S. economy and financial system have strengthened notably in recent years and in a mutually reinforcing way.  U.S. monetary and regulatory policy both need to be tailored to domestic conditions.  The Fed is also mindful of the international effects of its policies, given the central place of the U.S. in the global financial system, and the potential for spillbacks to the U.S. economy and financial system.  Effective communication with market participants and policymakers is important.  The opportunity for dialogue is what makes conferences such as this one valuable. \n\nThank you very much. \n\n1 See January 27-28, 2015 Federal Open Market Committee statement.\n\n2 See \u201cSpillovers from Unwinding Monetary Support in Advanced Economies,\u201d 2014 Spillover Report, Chapter 2.  See also, \u201cOn the Receiving End:  External Financial Conditions and Emerging Market Growth Before, During and After the Global Financial Crisis,\u201d World Economic Outlook, April 2013, Chapter 4.\n\n3 \u201cInternational Capital Flows:  Reliable or Fickle?\u201d World Economic Outlook, April 2011, Chapter 4.\n\n4 \u201cMonitoring the effects of agreed regulatory reforms on emerging market and developing economies\u201d, Financial Stability Board, November 12, 2014.\n\n5 Enhanced Prudential Standards for Bank Holding Companies and Foreign Banking Organizations, Federal Register, Vol. 79 No. 59, March 27, 2014."
  },
  {
    "title": "Opening Remarks at the Convening on Student Loan Data Conference",
    "date": "Mar 4, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150304",
    "content": "Good morning.  I\u2019m happy to welcome you to the New York Fed for this workshop that is intended to increase our understanding of student debt and how it affects individuals, their families and the economy.  I am delighted to see such widespread and growing interest in this important topic.  Making continued progress on understanding these issues will depend critically on efforts to identify and address existing data gaps that hamper its study.  I am particularly happy to welcome Deputy Secretary Sarah Bloom Raskin, who has spoken frequently and eloquently in the past about the need for improvements in student loan servicing and debt collection, the macroeconomic consequences of increased student debt, and the need for better data and analysis.  I look forward to her remarks today.\n\nBefore I make some specific comments on student debt, let me take a step back and say a few words on household finance more generally.  As always, what I say represents my own views and not necessarily those of the Federal Open Market Committee or the Federal Reserve System.1\n\nThere are several reasons the New York Fed has increased its focus on household finance.  First, the financial crisis made it obvious that an ability to understand and anticipate what is happening in the household sector is essential to gauging the strength and resiliency of the U.S. economy.  Second, our policy actions are intended to change the incentives facing households, so it is important to be able to gauge how our policies are transmitted into household financial decisions.  Good information on household borrowing, for example, allows us to see how monetary policy affects outcomes such as auto loan originations.  Third, better household finance research helps support our community outreach and development missions.\n\nA major challenge to achieving these goals is that household finances have traditionally been poorly documented.  We have lots of information about corporate sector debt and equity, but comparable basic facts about the household sector are much harder to come by.  For example, the lack of timely, comprehensive data made it more difficult to understand how vulnerable the household sector\u2019s financial position had become by 2007.\n\nI\u2019m happy to say that we\u2019ve made progress in beginning to close this data gap.  At the New York Fed, we\u2019ve been able to develop products that support a much better understanding of the household sector\u2019s borrowing behavior, ranging from loan-level mortgage information to credit card utilization and borrowing limits.  This has greatly improved our knowledge of household debt burdens, new borrowing activity, debt repayment as well as delinquencies.  We\u2019ve made a point of passing along these insights to the public through our Quarterly Report on Household Debt and Credit, various blog posts and interactive online maps of mortgage delinquencies.  It has required a substantial commitment of resources to obtain the data and extract the information from them, but I\u2019m convinced that it\u2019s been the right course of action.\n\nWhich brings me to the subject of today\u2019s workshop: student loans.\n\nAs you know, student debt is an increasingly important form of credit both for households and for the economy.  In 2010, aggregate outstanding student loan balances surpassed credit card indebtedness, and in 2013 eclipsed a trillion dollars.  During the historic household deleveraging that took place between 2008 and 2013, student debt bucked the trend, and was the only form of household credit that continued to increase each year.\n\nThere are many reasons for this growth, some of which are well-documented\u2014including increasing numbers of individuals who are pursuing post-secondary education, increasing durations in school and higher tuitions.  A less well-known contributor to the growing student debt balances was highlighted recently by a team of New York Fed economists.2  Using credit bureau data that track the quarterly balance and payment status of student loans, they have shown that the overall rate of repayment of outstanding student loans is very low, with many borrowers being delinquent on their loans.\n\nNow, it\u2019s probably fair to say that each form of household debt has distinctive features.  A researcher must understand these differences in order to understand the role that a particular kind of debt plays in household decision-making.  But student debt is perhaps the most distinctive form.  Let me explain what I mean.\n\nUnlike virtually all other forms of credit, student loans are generally not underwritten: they are frequently offered to young borrowers who have little or no credit history and little to no current income.  The amount of credit extended, on average, runs in the tens of thousands of dollars.  These loans are also not collateralized, nor are the interest rates risk-based.  However, lenders (now primarily the taxpayers), are given additional security in that student loans, unlike other forms of debt, are not dischargeable in bankruptcy.  This also means that delinquent student loans tend to remain on a borrower\u2019s credit record long after the borrower has stopped making payments, thus leading to very high measured rates of delinquency.  In addition, many special programs exist to allow borrowers to postpone repayment on their student loans to an extent not available for other kinds of household lending.  New York Fed economists have shown that for the 2009 cohort of graduates, only 17 percent of their original debt had been paid down after five years.3  More than 20 percent of high-balance student borrowers owe more now than when they graduated in 2009.  For the 2005 cohort of graduates, only 38 percent of their original student debt had been paid down, on average, nearly ten years after graduation.\n\nThese loans are used to finance human capital investment projects with returns that are highly uncertain.  It\u2019s true that virtually every study finds that the returns on college degrees are high, on average, relative to their cost.  But some people who take out student loans don\u2019t end up with these high average returns.  The net returns for some may, in fact, be negative.  For example, many who have pursued vocational training may be less remunerated in the market.  Similarly, some students attend certain for-profit universities with track records that indicate that their graduates have lower lifetime earnings than other types of educational institutions.  While others drop out before receiving a degree\u2014just 59 percent of the 2006 cohort had received their four-year degree by 2012.  Of course, uncertain returns are a feature of most investments, but for other loan types this uncertainty is generally managed more effectively through credit underwriting, collateralization and risk-based interest rates.\n\nWe are fairly confident in the aggregate statistics\u2014over a trillion dollars in loan balances outstanding, 43 million borrowers and the highest delinquency rates of any form of household debt.  But we know a lot less about the precise causes and consequences of the heterogeneity in the net returns to educational investments that I just described.  What we know so far, based on very imperfect data, suggests that this heterogeneity is likely to be very important.  We have gained an increasing understanding that how we finance post-secondary education has significant effects on a variety of critical economic outcomes, including economic growth and inequality.  For example, our research suggests that higher student debt and delinquencies reduce household formation and depress homeownership.\n\nBut there are many important questions still left unanswered.  What is the relationship between the amount and type of educational investment that people make and their outcomes?  What attributes are associated with borrowers who are more successful at repaying their student loans?  Are there particular types of degrees that are associated with better performance with respect to student debt repayment or with better living standards earlier in life?  What are the best interventions to help borrowers avoid the consequences of delinquency and default, and to limit any default costs to taxpayers?  Do borrowers who use programs like income-based repayment eventually succeed in paying off their debts?  How do income-based repayment programs affect important decisions such as labor supply, consumption and household formation?\n\nThese are important questions for the nation, as the human capital of our citizens is far and away our most important asset, and student loans are an important mechanism for financing needed investments in that asset.  But it is very hard to answer these questions with existing data.  We need to link information on borrower decisions about the kind and amount of education they receive to long-run outcomes for them and for the overall economy.\n\nSo I commend to you the work before you\u2014finding new ways to get the information that policymakers need to answer important questions about how we finance higher education.  I look forward to your insights and recommendations.\n\n1 Andrew Haughwout, Joseph Tracy and Wilbert van der Klaauw assisted in preparing these remarks.\n\n2 ,3 Payback Time? Measuring Progress on Student Debt Repayment"
  },
  {
    "title": "Remarks at the 2015 U.S. Monetary Policy Forum",
    "date": "Feb 27, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/dud150227",
    "content": "I think this is a timely topic because it is relevant to several questions that are particularly important in the current environment.  First, if one were to use a Taylor-type rule as a guide to assess the stance of monetary policy, what equilibrium real federal funds rate would one currently use in the formula?  Given the performance of the economy in recent years, I think it would be very hard to justify the typical assumption of a 2 percent rate.  \n\nSecond, what will this equilibrium real rate be in the future?  This is particularly germane right now given that short-term forward interest rates derived from the Treasury yield curve have come down sharply since late 2013.  For example, the 1-year forward rate, 9 years ahead has declined sharply over the past year, falling from around 5 percent in December 2013 to just under 3 percent currently.  What can explain such a large shift in forward rates at such a long time horizon?\n\nThird, when U.S. monetary policy is normalized, how fast should we raise short-term interest rates?  In other words, what is the appropriate path back to the long-run equilibrium real federal funds rate, shallow or steep?\n\nIn my view, the paper reaches five major conclusions\u2014conclusions that I find myself broadly in agreement with:\n\nTurning to the first issue of the relationship between real potential GDP growth and the equilibrium real short-term interest rate, the authors find, at best, only a very loose relationship.  I would have welcomed some further work here, more closely focused on the components of real potential GDP growth\u2014such as labor input and productivity\u2014and their potential links to the level and dynamics of the equilibrium real short-term rate.  First, I would look more closely at the demographic factors that influence the amount of labor input.  In my view, it seems plausible that when the labor force is rising rapidly, this might put upward pressure on r* by increasing the demand for capital needed to equip the new army of workers.  This might have been particularly relevant during the late 1970s when the labor supply in the U.S. was rising rapidly due to the influx of the baby boom generation into the workforce and the climb in female participation rates.  Second, the equilibrium real short-term rate might be influenced by the productivity growth rate.  If productivity growth were high, one might expect that the return on capital might also be elevated, putting upward pressure on real rates.  The late 1990s surge in productivity growth during the internet technology boom seems to be a good example of this type of phenomenon. \n\nIf the growth in labor input and productivity were positively related with the equilibrium real short-term rate, then in the current environment this would be consistent with a relatively low r*.  The potential labor force has grown very slowly in recent years (less than a \u00bd percent annual rate over the past five years), and productivity growth has been subdued\u2014running at only 1 to 1\u00bd percent annual rate on average over the past few years.  In sum, by focusing on the components rather than on the overall real potential GDP growth rate, one might find stronger and more persistent relationships with the equilibrium real short-term interest rate.  \n\nThe second issue that I want to briefly explore concerns the degree of uncertainty about the equilibrium real short-term rate and its implications for monetary policy.  The paper argues quite convincingly, I think, that when this uncertainty is high, then an inertial policy rule may be preferable\u2014that is, would lead to higher expected welfare. \n\nThat said, it is important not to overemphasize uncertainty to justify a policy of persistently low short-term interest rates.  There are also risks from too much policy inertia.  An inertial approach works well as long as inflation expectations stay well-anchored.  But, if a delay in monetary policy normalization or a very shallow trajectory in normalizing short-term interest rates were to cause inflation expectations to move meaningfully above our 2 percent inflation objective, then an inertial policy would likely become detrimental in achieving the FOMC\u2019s objectives. \n\nWhile simple policy rules provide useful benchmarks for policymakers, their very virtue\u2014their simplicity\u2014is also a significant shortcoming.  Policy rules, especially those with fixed values for r*, cannot capture all of the information that is relevant for policymaking.  In particular, such rules do not capture the fact that the linkage between the federal funds rate and both financial markets and global conditions can be very loose and shift over time.  This is a critical shortcoming because this looseness affects the stability of the relationship between monetary policy and economic outcomes.\n\nAs an example, one significant conundrum in financial markets currently is the recent decline of forward short-term rates at long time horizons to extremely low levels\u2014for example, the 1-year nominal rate, 9 years forward is about 3 percent currently.  My staff\u2019s analysis attributes this decline almost entirely to lower term premia.  In this case, the fact that market participants have set forward rates so low has presumably led to a more accommodative set of financial market conditions, such as the level of bond yields and the equity market\u2019s valuation, that are more supportive to economic growth.  If such compression in expected forward short-term rates were to persist even after the FOMC begins to raise short-term interest rates, then, all else equal, it would be appropriate to choose a more aggressive path of monetary policy normalization as compared to a scenario in which forward short-term rates rose significantly, pushing bond yields significantly higher. \n\nIn closing, I agree with the authors that it is very much premature to accept the hypothesis that we have entered a sustained period of secular stagnation.  That said, however, I do think that the real potential GDP growth rate will be lower over the medium term, held down by much slower growth of labor input and an anticipated continuation of lackluster productivity growth performance.  If I am correct, this does have implications for the longer-run value of r*.  My point estimate is that the longer-run value of the federal funds rate is 3\u00bd percent, well below its long-run historical level of 4\u00bc percent.  At the same time, I also have little confidence about the accuracy of this specific estimate.  So you see that I come out in a very similar place as the authors of this year\u2019s Monetary Policy Forum paper.  They suggest that the long-run equilibrium real federal funds rate might be in the range of 1 to 2 percent.  Add on 2 percent inflation, you end up in just about the same place as my current long-term 3\u00bd percent nominal federal funds rate point estimate.\n\nThank you for your kind attention.\n\n2015 U.S. Monetary Policy Forum\n\nThe Equilibrium Real Funds Rate: Past, Present and Future\n\n1 Jonathan McCarthy, Paolo Pesenti and Joseph Tracy assisted in preparing these remarks."
  },
  {
    "title": "Compliance \u2013 Some Thoughts About Reaching the Next Level1",
    "date": "Feb 9, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/bax020915",
    "content": "Let me begin by thanking Professor Sean Griffith, the director of the Corporate Law Center, and Robert Lyons, editor of the Fordham Journal of Corporate & Financial Law, for inviting me to participate in this symposium about corporate compliance and corporate governance.  Let me also thank Fordham Law School for hosting the symposium.  I would also like to recognize a colleague who is with us today.  He is Martin Grant, who is the New York Fed\u2019s chief ethics and compliance officer.  I have had the privilege of working with Martin for the last 25 years, and much of what I have learned about compliance I have learned from him.\n\nIn the space sometimes labeled compliance, we have come a very long way in a relatively short time.  In about 20 years, compliance has transformed from a nice idea to an important component of most major corporations.  This is especially true in the highly regulated industries, including the industry where I have made my career, financial services.  We could spend much time discussing how this transformation happened.  From my vantage point, it happened because of the combined effects of the Federal sentencing guidelines, the Delaware Chancery Court\u2019s Caremark decision,2 and the post-Enron legislation known as Sarbanes Oxley.  Of course, other events also fueled the transformation, and in the financial services industry, the worst financial crisis our country has seen since the Great Depression became a burning platform.\n\nWhile it is always important to look back at the road traveled, I am not going to spend any more time on that particular topic.  Instead, today I intend to look forward at where compliance is going, and to forecast for our future some things we should pay attention to now.  I will discuss five different items, and I predict that some of the greatest accomplishments for compliance are not in the recent past but in the not-too-distant future.  If we plan ahead, and if we can successfully adapt to changing circumstances in our respective industries and in the national and global economies, then 20 years from now you will listen to another keynote speaker remarking on further amazing progress for the compliance profession.  In short, we are on our way to another level.\n\nImportant Steps Toward the Next Level\n\nMost of my remarks today will be devoted to the things that I believe will get us to the next level.  Let me turn to them now.\n\n1. Ethics and Compliance/Values and Rules\n\nThe nomenclature that is used in compliance to describe the company officer responsible for compliance has changed, and the change in nomenclature is a clue to revealing a material, substantive change.  Twenty years ago, we called this officer the \u201ccompliance officer\u201d, and I emphasize the singular.  Over several years the title morphed, as compliance programs developed and compliance jobs multiplied, both with respect to subject matter expertise and the types of skill sets needed to make compliance programs \u201ctake\u201d.  Consequently, companies found that the compliance officer turned into the chief compliance officer, because in major companies, it took a village to get compliance done.  Compliance, you see, turned from singular to plural.\n\nMore recently the title has again changed.  In many companies today, the title is chief ethics and compliance officer, or CECO, reflecting a salutary trend on the part of many companies to integrate ethics and compliance.  Why is this happening?  In my view, it is happening in recognition of the fact that it is easier to have an effective compliance program in a company that nurtures a strong ethical culture.  In a recent speech, Daniel Tarullo, a governor of the Board of Governors of the Federal Reserve System, accurately observed that \u201cculture\u201d is a \u201csomewhat contested academic concept\u201d.  Yet, the evidence is growing that an ethical culture produces tangible benefits, including making compliance more effective.\n\nRecent studies attempting to assess the effectiveness of compliance programs have developed a measure called the \u201cPEI\u201d, or Program Effectiveness Index.  Early work with the PEI shows that companies combining their ethics and compliance programs tend to have better PEI scores.  The reason for the higher effectiveness measure seems to be something that I find perfectly rational.  Ethics programs, consisting of measures taken to inculcate organizational values, help to create a culture that is not only conducive to following rules that are embedded in law and regulation, but also conducive to compliance with company mores.  A strong ethical culture breeds a more compliant culture.\n\nOne of the very exciting areas in compliance today relates to how a company\u2019s strong ethical culture can impact corporate behavior.  One aspect of this behavioral change relates to the greater tendency of corporate constituents to follow the applicable rules when the culture is right.  Looking to the future, I envision we will see much more empirical research that shows the benefits of merging ethics with compliance, and placing both in the hands of a trusted corporate officer with a catchy new name\u2014the chief ethics and compliance officer.  As we move to the next level, ethics and compliance will increasingly become a part of a single program.\n\n2. Ethics and Compliance as a Tool for On-Boarding Risk\n\nThe last 20 years have demonstrated the benefit of ethics and compliance in identifying legal risk and taking operational measures to keep that identified legal risk within the organization\u2019s accepted risk appetite.  In most applications, though, compliance has been the vehicle that prompts the organization to reduce risk by constraining activity.  In the financial services industry, correspondent banking provides an illustrative case.\n\nCorrespondent banking is the business of effecting funds transfers for other financial institutions.  Because the U.S. dollar is the international medium of exchange, financial institutions throughout the world have a need to effect dollar-denominated transfers of funds.  Ethics and compliance professionals in U.S. banks have pointed out that this type of business presents several different legal risks:  money laundering, terrorist financing, and sanctions evasion are the most obvious and the most notorious.  There is no doubt that these compliance professionals are correct.  One consequence of their being right, however, is that U.S. correspondent banks decided to \u201cde-risk\u201d.  To execute on the de-risking mandate, many U.S. correspondents stopped providing correspondent banking services to those perceived to present such risk.\n\nAs a result, certain elements of the global financial services industry now find it increasingly difficult to transact business in dollars.  There is a concern by the U.S. correspondents transferring funds for Middle Eastern customers that the correspondents might unwittingly be providing services to a terrorist organization, or be enabling a person or affected sovereign to evade economic sanctions.  So, the correspondents close accounts for all banks in the Middle East.  Similarly, there is a concern by the U.S. correspondents transferring funds for Latin American customers that they might unwittingly be providing financial services to drug traffickers, a money laundering risk.  So, they close accounts for all banks located in Mexico, Venezuela and Colombia.  The de-risking exercise succeeds in its risk-reducing objective, but it succeeds in an overly broad manner by cutting services indiscriminately to so many.\n\nThe success of compliance over the last 20 years has conditioned business leaders to think about compliance as a pathway to terminate or constrain a risky business relationship.  However, it is possible to look at compliance in a very different way, as a two-way street and not a \u201cone-way\u201d street.  Let me explain what I mean.  A sound and effective compliance program can be used, appropriately in my view, as a tool that would permit on-boarding of what is seen as risky business.\n\nTo continue with the example of correspondent banking, if a U.S. correspondent had a sound and effective compliance program that was well tailored to identify and control the risks of money laundering, terrorist financing, and sanctions evasion, this correspondent might become sufficiently confident to on-board risk.  This means that instead of closing accounts for everyone in a specific geographic area, it would continue with some of these accounts, or even open new accounts.  Now, I do not want anyone to think I am saying that all correspondents can reasonably have such confidence now.  At this point in our journey, I concede the need to develop greater confidence that the identified risks can be controlled at a reasonable cost.  With that said, I believe that we will reach a place where ethics and compliance programs are sufficiently developed so organizations can make considered decisions to on-board risk and keep it within the accepted risk appetite by using effective controls.  I look forward to that time as we move to the next level.\n\n3. Developing the Methodology to Assess Effectiveness\n\nWhile we seem to be on the cusp of a number of promising indicators, like the PEI, the truth is that we are not there yet.  We simply do not have a tool that will give us an accurate and reliable measure of program effectiveness.  Instead, we have a situation where enforcers (including those agencies with civil enforcement authority, such as the banking agencies) tend to be result oriented.  When we see that a particular organization has experienced a major compliance failure, we tend to view the failure as evidence of the ineffectiveness of the ethics and compliance program.  We reason backward, \u201cif the program were effective, this would not have happened.\u201d  I think this is natural and understandable for the enforcement community, but it is not necessarily good policy.  To borrow an observation from Senator Ted Kennedy concerning the Federal sentencing guidelines, this creates \u201ca risk that companies without substantial compliance programs will get a free ride, and those with strong programs will not receive the credit that they deserve.\u201d4\n\nAlternatively, if there were a reliable and acceptable measure of program effectiveness, this kind of backward reasoning would be replaced by reliance on the effective measure.  Institutions could use the measure when making arguments for leniency, again assuming that the measure demonstrated that their programs were effective.  It might, of course, show just the opposite.  And there are other, perhaps even more important, benefits.  If an industry and its regulators came to have great confidence in a particular effectiveness measure, this might provide a foundation for building a program that could be used to on-board risk.  Put differently, a particular organization could have confidence that its ethics and compliance program would be protective because the program had been validated by a well-accepted measure of effectiveness.\n\nSome of the skeptics will say \u201cyou are dreaming\u201d.  When I hear them, I am reminded of the words of George Bernard Shaw, and specifically the reminder to dream things that never were and ask \u201cwhy not\u201d.5\n\n4. Adaptive Compliance \u2013 Adding Speed and Agility to Process and Procedure\n\nOver the past 20 years, as ethics and compliance has moved through infancy and into early childhood, we have become committed to the process and procedure that is emblematic of a program.  There is much about this progression that is good.  The building of compliance programs has produced real benefits,6 and these benefits have created the compliance profession.  There is a risk too.  The risk is that the process and procedure that is the substance of the compliance program will become a kind of iron cage, restraining innovation so that the organization cannot adapt to changing circumstances.  In short, the process and procedure can stifle speed and agility.\n\nOne place where this has occurred recently is in financial services.  Some institutions witnessed some malefactors violating the law and engaging in anti-competitive practices with respect to the setting of the Libor rate.  Those institutions responded to very specific rate fixing abuses, but they did not envision that the abuses with respect to Libor could also be occurring in other businesses, like foreign exchange.  Compliance, in this particular instance, was not adaptive.  Compliance professionals, in this instance, did not show the needed speed and agility.  They did not reason along the lines that \u201cif it is happening concerning Libor then it might be happening concerning foreign exchange.\u201d\n\nAs compliance becomes increasingly routinized and subject to what the consultants would call the \u201crepeatable process\u201d, the process can have a tendency to drive out creative thought.  As creativity dissipates, so does the ability to connect related occurrences.  In the next 20 years, we will need simultaneously to perform repeatable processes and to think innovatively.  We will need to continue to build the routines and repeatable processes.  Yet, we will also need to be sufficiently flexible to see around corners, to where new problems are emerging, and new risks to our franchises are developing.  This is what it will take to be successful at the next level.\n\n5. Attention at the Top \u2013 Developing Protocols for Escalation\n\nI commend Fordham for focusing this symposium on compliance and governance.  They are related and intertwined.  The four items discussed all relate to compliance.  My last item touches on governance.\n\nAs I speak with chief ethics and compliance officers, a regular topic of conversation is conflict with the business leaders who own the risk.  This is a little unsettling, because during the last 20 years we have been successful in establishing as a better practice the approval of the compliance program by the board of directors.  One might think that, if the board of directors approves the compliance program, then it should not be difficult for the chief ethics and compliance officer to get the business owners to pay close attention.\n\nThe devil here, as in so many other places, lies in the details.  It is usually the implementation of the compliance program that causes the conflict.  It is usually related to the cost of compliance, because the cost ordinarily affects how the business owner measures success, which is the size of the business\u2019 profit.  The chief ethics and compliance officer will not be able to resolve the conflict easily, because compliance is a cost to the business which can make compliance the adversary of the business owner.  The chief ethics and compliance officer will not want to bring a specific conflict issue to the attention of the board of directors.  While this might be very effective in resolving the specific conflict, it could absolutely destroy her ability to function effectively thereafter.  In a recent survey of chief ethics and compliance officers conducted by Price Waterhouse, the survey respondents identified as a problem their \u201cstruggle to gain the attention of the board of directors.\u201d7  Two specific issues were identified.  One related to fear on the part of the chief ethics and compliance officer to engage in action to resolve a conflict with a key business person\u2014a fear of losing one\u2019s job or her place in the corporate hierarchy.  The other problem concerned access to the board of directors.  It is one thing to go before the board of directors annually to have the compliance program approved.  It is quite another to go before the board of directors to do battle with a senior executive who is probably before the board of directors on a regular basis.\n\nConclusion\n\nThank you for listening.\n\n1 These remarks are personal and do not necessarily represent the views of the Federal Reserve Bank of New York, or any component of the Federal Reserve System.\n\n2 In re Caremark International Inc. Derivative Litigation, 698 A.2d 959 (Del.Ch. 1996)\n\n3 Ethics Resource Center, The Federal Sentencing Guidelines for Organizations at Twenty Years at 51 (2012).\n\n4 Remarks of the Honorable Edward M. Kennedy, U.S. Sentencing Commission, Symposium Proceedings: \u201cCorporate Crime in America: Strengthening the \u2018Good Citizen\u2019 Corporation,\u201d at 120 (1995).\n\n5 George Bernard Shaw, Back to Methuselah: In the Beginning, act 1, Selected Plays with Prefaces, vol. 2, at 7 (1949).\n\n6 A survey sponsored by the Ethics Resource Center from 2011 \u201cshows that employees in companies with effective, meaningful codes of conduct and programs . . . witness fewer incidents of misconduct, and are far more likely to report misconduct when observed.\u201d Ethics Resource Center, supra note 2, at 2.\n\n7 Price Waterhouse Coopers, \u201cWhat It Means to be a \u2018Chief\u2019 Compliance Officer: Today\u2019s Challenges, Tomorrow\u2019s Opportunities\u201d at 12 (2014)."
  },
  {
    "title": "Student Debt and Higher Education Financing: A Public Finance Perspective",
    "date": "Feb 5, 2015",
    "speaker": "James McAndrews",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/mca150205",
    "content": "Some of you may be wondering why the research director of a central bank is particularly interested in the way we as a nation pay for college. The answer, of course, is that we are gaining an increasing understanding that how we finance post-secondary education has important effects on a variety of critical economic outcomes, including economic growth and inequality. It\u2019s this realization, combined with the fact that the outstanding student debt balance has now surpassed $1 trillion, which has brought increased attention and discussion to the question of education finance.\n\nFirst, I\u2019d like to acknowledge the work and research of Meta Brown, Rajashri Chakrabarti, Andrew Haughwout, Donghoon Lee, Joelle Scally, and Wilbert Van der Klaauw in preparing these remarks.\n\nI\u2019m an economist, so I\u2019d like to start by discussing the economics of higher education finance as I see them.\n\nThe first thing to make clear is that the evidence strongly supports the view that a college degree, while expensive, is a worthwhile investment not only for the individual receiving the education but also for society as a whole.\n\nFor individuals, the expected benefit-cost ratio of a college degree is well over 1.0 and growing. Indeed, while more people are attending college over the last thirty years, college graduates on average earn 80 percent more than those without a college degree, and are far less likely to be unemployed, regardless of the phase of the business cycle. Of course both effort and what we might call academic acumen are likely to play a role in a prospective student attending a better college, and whether the student completes a degree, and so this figure may overstate the value of college itself to any particular prospective student. But careful work in economics has demonstrated that even after we control for talent, college is worth it for most, but not necessarily all, students.\n\nPart of the reason for the increasing importance of college is a result of what economists call skill-biased technological change. The idea is that the kinds of technologies that are increasingly influencing the workplace tend to favor people with more education. The personal computer, for example, is a great tool that enhances the productivity of people with lots of education, while it may actually be a substitute for unskilled labor. In addition to its effect on earnings, higher education improves one\u2019s quality of life by improving other outcomes, like health.\n\nEven when the large net benefit of college attendance is accurately perceived, there are significant financial constraints on many families\u2019 ability to finance a college education. After all, the costs of college are concentrated in a few years at the very beginning of a career, while the benefits are spread out over a long period that comes later. Borrowing is a natural solution to problems like these, but there is limited enforceability of uncollateralized debt contracts and the private sector may be willing to provide less than the optimal amount to support good educational outcomes.\n\nIn this environment, even optimal private debt contracts will not account for the second important part of the benefit of higher education: that which accrues to society as whole. Better-educated workers are higher paid and so pay more taxes, and they have a lower incidence of dependency on programs like unemployment compensation and welfare. There are positive spillovers from educated workers to others, raising aggregate productivity. Better-educated workers produce more innovation and are more civically engaged. In a democracy we are all better off when our fellow citizens understand the issues facing the country.\n\nOverall, a more skilled workforce is beneficial to us all. In addition, higher education is an important export industry in which the US holds a significant comparative advantage. This produces a better understanding among foreigners of the US and vice versa.\n\nAll of these social benefits mean that there is an appropriate role for the public sector in helping to finance higher education. The best policy would align the social and private benefits of attending college, and would find a way to relieve the liquidity and credit constraints that families face. Finally, the best policy would direct scarce educational resources toward those matches between student and institution that are likely to yield the best educational outcomes. The best matches avoid regrettable dropouts or degrees granted with little to show in the way of educational attainment or career prospects, or similar bad outcomes.\n\nIn considering what the proper public role should be, it\u2019s useful to think about an extreme case. In Europe, higher education has traditionally been essentially 100 percent publicly funded. This result is big subsidies for people\u2014mostly wealthy people\u2014who would have gladly paid for college if they had to. Making college free also means that there will likely be excess demand for the fixed number of seats at high quality institutions. Either this demand has to be rationed, or quality will have to fall. Neither choice is particularly attractive. In fact, excess demand and growing costs have put severe pressure on the European model for financing higher education, and European countries are now gradually moving away from the old system, introducing income-based tuition fees and loans to help restrain rising costs and expand access to higher education to more social groups.\n\nIn the US, we\u2019ve used a more complicated system that has several major elements. First, we have public universities whose tuitions are less than the full cost of providing the education, with the difference made up by state taxpayers. This can align the public and private benefits in the long run, but won\u2019t by itself mitigate the liquidity constraints that families face. Also, as I will discuss in more detail later, it puts public universities at the mercy of the business cycle.\n\nSecond, we offer Pell grants to families with limited means to pay for college. We also use the income tax system to reduce the cost of attending up to four years of college for people with incomes below a certain threshold. These subsidies, which operate like vouchers since they can be used at lots of different colleges and universities, serve to align private and social returns and relieve liquidity constraints. Because they are related to income, they also potentially have the additional important benefit of reducing inequality.\n\nThe final major element of our system is loans. These relieve the liquidity constraint, but they don\u2019t necessarily contribute to aligning the private and social returns to higher education.\n\nSince student loans are currently receiving a huge amount of attention, and since the New York Fed has been a leader in providing information about the sector, I\u2019d like to spend the rest of my time discussing what I see as the main issues with student debt and what to do about them.\n\nIssues with student debt\n\nStudent loans seem like a good part of the solution, but over the past decade our reliance on loans for funding higher education has increased and we are learning that they have many problems and implications we had not sufficiently understood or considered. As shown in Chart 1, between 2004 and 2014, the total student debt in the US tripled from $364 billion in 2004 to $1.16 trillion in 2014. Expressed in annual terms, this means student debt increased by an average of 13 percent per year. As shown in the chart, among the various types of household debt, student debt is unique. While balances on all forms of household debt\u2014including mortgages, credit cards, auto loans, and home equity lines of credit\u2014declined during and after the Great Recession, student debt has steadily risen. In 2010, student debt surpassed credit cards to become the second largest form of household debt after mortgages whereas prior to 2008, student debt was the smallest form of household debt.\n\nOur research indicates that this increase in aggregate debt was due to increases in both the number of borrowers as well as increases in the average balance per borrower. Between 2004 and 2014, the number of borrowers increased by 92 percent from 23 million borrowers to 43 million. In the same period, average debt per borrower increased by 74 percent, from about $15,000 to $27,000. With respect to the rise in the number of borrowers, we find that a steadily increasing share of young people are taking out student loans: in 2004, only about 27 percent of 25 year olds had student debt while 9 years later, in 2013, the proportion of 25 years olds with student debt had increased to about 45 percent.\n\nThere are several explanations for these increases. First, more people are attending college1. Second, students are staying in college longer and attending graduate school in greater numbers, and loans to finance graduate study have become more readily available. Third, competing non-education sources of credit such as home equity loans and credit card debt have imposed tighter underwriting standards, and generally have become less available since 2008. A fourth reason is the slow repayment rate on these loans, which I will discuss in more detail a little later. But another important reason for the increase in overall student debt, which I will discuss first, is the significant growth in the cost of a college education during the period2.\n\nFederal and State funding of subsidized higher education is heavily reliant on tax revenues and competes with other forms of public spending, and within education budgets competes with pre-school, elementary and secondary education spending. During the recession we saw severe revenue declines at the federal and state levels. Being highly credit constrained, with university subsidies being part of operating budgets which must be funded with current tax revenues, many states cut planned education funding while allowing public universities to increase tuition levels. This in turn contributed to a significant shift of education cost to students and parents.\n\nIn research conducted at the New York Fed, we found that since 2007 those states with the largest funding cuts also had the highest tuition increases, with an average annual tuition growth rate of 3.4 percent. As shown in Chart 2, this compares to an annual average tuition growth rate of 1.7 percent during the 2007-2010 period for all other states combined. That is, we observe an economically meaningful relationship between public funding and public institution tuition changes since 2007.\n\nHigher tuition has forced many students to take on larger student loans. Student debt and tuition increases were not limited to public institutions. Research conducted at the NYFed found that over the same period there was even larger tuition and student loan growth at for-profit institutions. [Chart 3] Despite larger average support through Pell grants, with tuition levels more than double those at public institutions, average net tuition and average loan sizes were considerably higher at for-profit educational institutions. In addition, a much larger proportion of students at for-profits took out subsidized direct loans. [Chart 4]\n\nReturning now to the surge in aggregate student debt, an increase in borrowing for college is not by itself a concern, given the high average lifetime payoff to college. In fact, in part the increase in debt reflects an arguably sensible increase in educational investment during a period of weak labor market opportunities. However, the growth in debt has important implications for the overall economy, and there are several worrisome aspects of the increase in student debt. Many of these problems have to do with the high rates of delinquency and default on student debt, and the generally low repayment rates on these loans.\n\nOver the past eight years there has been a considerable increase in payment difficulties for student loan borrowers. The most common measure of inability to meet the debt obligation is the proportion of borrowers 90 days or more past due on their payments. We refer to this as the \u201cmeasured delinquency rate.\u201d As of the fourth quarter of 2014, about 17 percent, or 7.3 million borrowers, were 90 days or more delinquent on their student loan payments; see the left panel of Chart 5. There was a strongly increasing trend in delinquency between 2004 and 2014, with measured delinquency rising from an overall rate of less than 10 percent in 2004 to 17 percent in 2014.\n\nThe measured delinquency rate on student debt is currently the highest of any consumer debt product, although for most of the last decade credit card delinquency was even higher. Nonetheless, the measured delinquency rate is somewhat misleading, and the effective delinquency rate as we define below, on student debt is even higher. As noted above, in 2014 the measured delinquency rate among the 43 million borrowers was 17 percent. But many of the remaining 83 percent in fact were not paying down their loan balances. While 37 percent did reduce their balance from the previous quarter by at least one dollar, 13 percent of borrowers had the same balance as the previous quarter. A full 33 percent of borrowers actually saw an increase in their balance. In other words, 46 percent of borrowers were neither delinquent nor paying down their loans.\n\nThose borrowers whose balances did not decline are likely not yet in the repayment cycle, meaning that they were either still in school, in deferral, or in a forbearance period delaying their regular payments. This group may also include some borrowers who participate in income-based repayment plans and make only small payments, which are often insufficient to cover the accumulated interest. In order to have a more accurate picture of the delinquency rate, we calculate the \u201ceffective delinquency rate\u201d by excluding this 46 percent of borrowers not in repayment; the result is shown in the right-hand panel of Chart 5. This effective delinquency rate is nearly double the measured delinquency rate, with almost one-third of borrowers in repayment being delinquent on their debt.\n\nIt is important to note that because of the unique character of student debt, an increasing delinquency rate defined either way does not necessarily imply that a greater percentage of new borrowers are falling behind on repayment. Borrowers who became delinquent in the past and remain so are included in the delinquency rate. Some may also default, which is defined as being more than 270 days past due in the case of federal loans. Because student debt is not generally dischargeable, even in bankruptcy, the delinquency rate may continue to increase even when the percentage of borrowers becoming newly delinquent remains constant.\n\nWe therefore also computed the proportion of borrowers in repayment who became newly delinquent on a quarterly basis. As shown in Chart 6 in 2005 about 6 percent of nondelinquent borrowers in repayment transitioned into delinquency each quarter, on average. By 2012, that rate had increased to almost 9 percent. This confirms that indeed there was an increasing trend of borrowers becoming newly delinquent over time.\n\nOur delinquency numbers may seem higher than those reported elsewhere. One reason for this is that our data allow a more comprehensive description of student debt delinquency and repayment rates than was previously possible. Our data come from consumer credit reports for a 5 percent random sample of the population\u2014that is for 12 million individuals aged 18 and older. Instead, existing knowledge of student federal loan defaults is based mainly on the three-year cohort default rates computed and released by the Department of Education each year. An institution\u2019s cohort default rate is calculated as the percentage of borrowers in a cohort who default before the end of the second fiscal years following the fiscal year in which the borrowers entered repayment.\n\nIn research that will be released later this month in a series of blog postings on our Liberty Street Economics blog, we use our data and a slightly different definition to compute comparable 3-year cohort default rates. Importantly, we find that three years out, we haven\u2019t seen the full picture of borrowers who will default. Our calculations indicate that the 3-year default rate for the 2009 cohort rises by more than a third by year 5. This is also true of earlier cohorts. The 2005 cohort had a 3-year default rate at 13 percent\u2014but this is only half of the defaults that we see nine years out. Taken together, these findings indicate that the student loan delinquency problem is much worse than currently understood.\n\nAnother way to look at borrower difficulty in loan repayment is to consider the state of repayment by the end of 2014 for all student loan borrowers we observe finishing their new loan accumulation, between 2005 and 2010. High rates of delinquency and default, and the high prevalence of participation in repayment-delaying programs such as deferments, forbearances and income based repayment, lead to a lower rate of balance reduction in the years after student loan borrowers leave school. In order to understand the magnitude of this delay, we investigate the extent of student loan repayment that recent school-leaving cohorts have achieved by 2014.\n\nFor the blog series, we calculated the outstanding balance of each of the 2005-2010 school-leaving cohorts as of the second quarter of the school-leaving year. For each cohort, we then recorded the share of the original student loan balance that remained as of the end of 2014. For example, for the 2010 cohort 91 percent of the original balance remained unpaid four and a half years later, at year-end 2014. This is typical of all the cohorts we examine, from 2005 forward.\n\nSo what accounts for the high default rates and low repayment rates of recent cohorts? Undoubtedly the weak labor market conditions for entering college graduates played an important role in explaining defaults and low loan repayment rates. As the youth unemployment rate continues to improve, we would expect repayment rates to gradually improve.\n\nHowever, while the available data limits deeper analysis of this issue, it seems reasonable to suspect that high college dropout rates contributed to loan repayment problems. As is well known, approximately 40 percent of college students drop out of college before finishing their degree. Among low-income students two-thirds don\u2019t complete their degree, with rates also varying across institutions and majors. While the average wage returns to college remain high, for the substantial share of student loan borrowers who drop out of college, the net returns are likely to be small or negative.\n\nReturns are also likely to be small for those who attended a set of for-profit institutions. Enrollment at those institutions surged during the recession. While our data don\u2019t allow us to investigate the returns for these groups of students, their especially low loan repayment rates (as reported elsewhere) are consistent with low post-college employment and earnings, suggesting that eventual returns to these educational investments may be low.\n\nThe increase in defaults and decline in repayment may also reflect a change in the composition of college entrants during the recession, where even those with relatively low, or even negative returns to college, enrolled in order to qualify for grants and loans as a source of income.\n\nThe individual and macroeconomic implications of growing student debt go well beyond the high default rates and may not have been sufficiently anticipated and understood. Our research suggests that the sharp buildup of student debt has contributed to large behavioral changes among the Millennial generation. First, among those with student debt, a growing share continues to live with their parents. For example, we see that states that have experienced sharper climbs in average student debt per graduate since the recession have also shown steeper growth in the rate at which 25 year olds live with their parents. Similarly, our research suggests that student debt has contributed to a decline in home and car purchasing. As shown in the next chart [Chart 7], the proportion of 30 year olds with a home mortgage and the share of 25 year olds with a car loan have dropped much faster among those with SL debt.\n\nMore serious econometric research indicates that the relationships between increased student debt and both higher coresidence with parents and lower home buying at age 30 are in fact causal and exist whether or not one controls for educational attainment. Holding other factors constant we find that in states with larger increases in student debt per graduate there was a greater decline in home buying by young individuals. Overall, the high level of existing debt and the apparent new norm for college financing, have important long-term implications for the housing market. With new cohorts continuing to leave college with high debt levels and entering the housing market at older ages, we can anticipate an overall persistently lower home ownership rate than in the pre-recession period.\n\nSo what is causing the withdrawal from home and car purchase markets? It is likely that rising student debt and an uncertain economic outlook have depressed demand. But most likely, declines in credit supply play an important role as well. Our analysis shows that average credit scores have fallen for student debt holders relative to those with no student debt. Clearly for the substantial and growing group of student loan borrows who are delinquent or have defaulted on their debt, access to credit is reduced through potentially long-lasting negative effects on credit scores. Better data is required to evaluate the extent to which the decline in car and home loan originations is concentrated among those delinquent on their student loans and those who dropped out of college, or whether it is more widespread among all those with student loans.\n\nThe fast growth of student debt and delinquencies, and the associated withdrawal of student loan borrowers from mortgage and other credit markets have led to a renewed policy debate about the viability and optimality of our higher education funding model. Some call for increased federal and state support for higher education to reverse the recent trend towards shifting the cost of higher education to students and parents. Others talk about a new debt bubble of uncollateralized loans provided to ill-prepared students who are unlikely to see any real returns to their investments, calling for better oversight and underwriting of loans. Yet others point to the persistent high returns to a college education and argue that the current situation represents primarily a repayment crisis rather than a debt crisis.\n\nIn my view, all these policy ideas deserve serious consideration. Some scholars argue that the current system turns reasonable levels of debt into crippling payment burdens that can prevent young workers from attaining financial independence and stability.3 They propose a single, simpler, income-based repayment system. Such a program would undoubtedly benefit many borrowers, allowing them to better smooth consumption. However, the very low cohort repayment rates we see, even ten years after entering repayment, suggest that realized labor market returns to these higher education investments appear to be lower than one would expect. While these returns may gradually increase as the labor market improves, for some the returns may in fact stay low, especially among college dropouts and those who attended some for-profit institutions.\n\nEven if the average returns to a college education remain large, or even grow, students generally have a larger amount of debt to pay off. As mentioned earlier, in response to reduced state and federal subsidies, educational institutions raised tuition, leaving students and their parents paying a greater share of the cost of higher education, thereby leaving students less of the surplus and a lower net return on their investment.\n\nThere are therefore reasons to be concerned about the viability of the current system (with various income-based repayment programs) as well as an alternative income-based repayment system. The high delinquency rate and very low repayment rates among recent cohorts have implications for the sustainability of higher education financing more generally. While there is considerable uncertainty about the ultimate amount, it appears likely that a significant portion of the outstanding federal student loans in income-based repayment-type programs will ultimately be charged off after 20 or 25 years.\n\nAnother potential threat to the sustainability of the current system, especially visible in the current low interest rate environment, represents the entry of private lenders engaged in cream skimming, providing loans that slightly undercut the administratively set interest rate on federal loans for those enrolled in high-return and low-risk programs towards business, medical and law degrees at top ranked institutions. There is a risk given the rapid growth of this industry that this could have a considerable impact on the average quality of loans held by the federal government.\n\nA primary policy challenge in higher education financing is to increase access to higher education to more people through grants and loans but in such a way that the private and social net returns remain positive. This requires a combination of financial support but with sufficient likelihood of success/ability to repay/for positive return.\n\nThe low returns to some students\u2019 experience with higher education, evidenced by high dropout and default rates, point to significant heterogeneity in outcomes for college students. An individual making the joint decision of whether to enter college and which college to enter faces a high degree of uncertainty regarding the future outcome of the educational experience. Tuition subsidies funded by state taxes and Pell grants funded by federal taxes work to distribute this risk over a wide pool of people. However, individuals with good college outcomes enjoy the private benefits that accrue to their higher-earning power. As a result, it is likely that the best type of financing arrangement would require at least some tuition payments from students.\n\nTo overcome the liquidity constraint faced by families whose members are entering college, it makes sense to have a loan program. Importantly, the financial system, whether private or public, should direct scarce resources to highly-valued investments. Given the wide heterogeneity of educational outcomes by type of student and type of institution, any loan program should take careful account of the expected quality of the match between the prospective student and the educational institution. This is a type of underwriting that could be employed much more extensively in the federal student loan program, to the benefit of both borrower and lender. In addition, by restricting the availability of loans to those matches that are likely to succeed, the social benefits will be achieved at lower cost.\n\nWhile there is currently little underwriting of student loans in terms of individual or family wealth \u2013 which is as it should be \u2013 better underwriting of loans may result in higher preparedness standards for students. Just as importantly, it will require evidence, provided by the institution, of sufficient success in graduating students of a specific preparedness level and placing them into viable jobs with sufficient income to permit repayment of the loans.\n\nThis unfortunately contrasts with the current student loan system. We see evidence of problems associated with the lack of careful underwriting standards for educational matches that are supported by student debt. For example, current performance for some degree programs and some universities are problematically weak, in terms of degree completion rates and loan repayment rates. There have been reports of some schools in cities with large minority populations and low-income residents who tried to build enrollment by encouraging academically under-qualified students to apply for loans that they would be unlikely to be able to repay, especially if they received a substandard education. These practices undermine our commitment to financing effective higher education matches, and it is important that they be addressed.\n\nConclusion\n\nNothing in the analyses I discussed with you undermines the strong case for completing a college degree for prospective students who match well with a particular college. Rather we see our evidence as suggesting that the way we as society finance those degrees\u2014with an increasing reliance on debt held by the students\u2014has costs to both borrowers and lenders that are only now becoming clear. Given the social benefits of an educated population, we see a strong case for some public role in financing college. Nonetheless, there are many private benefits, including higher lifetime earnings to be had by the successful college graduate. Therefore it is likely that the best system of finance also includes a tuition payment by the student.\n\nBecause many prospective students are credit and liquidity constrained, and because of the limited enforceability of debt, we outlined the case for a government-supported student loan program to support the payment of tuition. However, we see a case for stronger underwriting standards that would assess the likely quality and outcome of the education match between a prospective student and the educational institution, which would better deliver resources to high potential educational matches, and avoid encouraging poor ones.\n\nWe\u2019ve learned a lot over the past several years about how student loans are affecting individual borrowers, the taxpayers and the aggregate economy. We\u2019ve by no means answered all the relevant questions, and with over a trillion dollars in outstanding debt and the future of our workforce at stake, I consider these issues to be of first-order importance to the nation.\n\nWe at the New York Fed will continue to search for new facts to put on the table and push the debate forward.\n\nCharts"
  },
  {
    "title": "The Rewards of an Ethical Culture",
    "date": "Jan 20, 2015",
    "speaker": "Unknown",
    "url": "https://www.newyorkfed.org/newsevents/speeches/2015/bax012015",
    "content": "Let me begin by thanking Sir William Blair and the Bank of England for inviting me to participate in this Project and at this Conference1.  At the New York Fed, we have made ethical culture a priority for financial services.  We have done this not as a formal part of a supervisory program, but more as a call for reform.  In the short time that I have this afternoon, I will speak about the reasons why I believe reform is necessary, highlight some of the important practical features of a strong ethical culture, and conclude by setting out a few of the rewards that might result from it.\n\nBad behavior in the financial services industry prompted the New York Fed\u2019s call for a stronger ethical culture in banking.  My list of the most serious transgressions is probably not much different from anyone else\u2019s.  It includes the evasion of taxes and economic sanctions; conspiracy and market manipulation with respect to LIBOR and foreign exchange rates; and misselling financial products, including residential mortgages and insurance, to people who should not have acquired them.  This list is only illustrative.  It is not by any means exhaustive.\n\nThe traditional means to address bad behavior are enforcement actions against the bad actors and the organizations where they worked.2  This traditional response, in my view, is appropriate and I strongly support the actions that have been taken and that will continue to be taken.  All enforcement actions, though, are essentially retrospective.  Of course, we like to think that enforcement actions will not only punish but also deter. But I wonder if this hope is really a prospective strategy.  We would better serve the public good if we could do something\u2014anything\u2014more forward looking, and complementary to what our enforcement colleagues are doing to deter future bad behavior.\n\nEthical Culture\n\nThe new emphasis on an ethical culture within financial services firms arises from the policy interest in preventing some of the bad behavior that has been observed.  Now I use the phrase \u201csome of the bad behavior\u201d deliberately.  I fully embrace the goal of eliminating all bad behavior.  But we cannot let the goal of perfection become the enemy of progress.  We need to start making progress, so let us agree that perfection is probably not realistic.  Even an organization with the strongest ethical culture will have episodic bad behavior.  Although culture is no panacea, I believe that the ethical culture of an organization can improve the behavior of the people who work there.  Strengthening the ethical culture of financial services should therefore reduce the volume of bad behavior we have been seeing.\n\nSome of the skeptics say, \u201cProve it.\u201d  I confess that proof is hard to come by.  Yet, I am not alone in the fundamental belief that a strong ethical culture will lead to better behavior.  A 2010 Corporate Executive Board survey of more than 500,000 respondents shows a widespread view that corporations with strong ethical cultures experience less misconduct.3  This makes intuitive sense even in the absence of empirical proof.4  Further, the natural tendency to go with the intuitive is bolstered by the potential benefit of a reduction in enforcement actions against financial services firms, and by a healthy change in the public perception of the financial services industry.  And, of course, there is ready evidence for the contrapositive view.  Few would disagree with the following: The bad behavior that contributed to the Financial Crisis was evidence of a culture that was not strongly ethical.\n\nLet me also pose a challenge to those who are skeptical about the benefits of a strong ethical culture: If this is not a suitable method to prevent bad behavior by bankers, what alternative proposal do you advocate?  The status quo is not acceptable.  As a wise man once said, \u201cPlan beats no plan.\u201d\n\nThe Components of a Strong Ethical Culture\n\nSo what are the key components of a strong ethical culture?  It is said that lawyers love a metaphor, and this lawyer is no exception.  I like to think about ethical culture as if it were a package.  The culture that we will have is derivative of what we put into the package, and there are clear choices to be made.  The contents depend upon the type of organization, the kinds of people, and the nature of the skills needed to conduct the organization\u2019s activities.  Time will not permit me to cover this thoroughly, so let me cover a few items with a very broad brush.\n\nWhat Goes In\n\nFor starters, the conduct of the people in any organization will be strongly influenced by incentives.  Let me mention the \u201cbig three.\u201d  Bankers, like lawyers, want to do [1] quality work, [2] with people they like and respect, and [3] receive fair recognition in return.  I will touch on all three but will focus on two species of recognition: compensation and promotion.  Each should be tied to ethical considerations.  If the only consideration with respect to compensation and promotion is how much money the individual made for the firm, then that communicates a message that is inhospitable to a strong ethical culture.\n\nA second key component is what I call \u201ccharacter at the top.\u201d  The usual expression is \u201ctone at the top,\u201d and it refers to the message from the people who occupy the upper most positions in any organization (the board of directors and the \u201cC\u201d Suite).  My worry with the typical expression is that it tends to focus on words, rather than conduct. The implication is that if you sing the right notes in the right key then all will be fine.  I do not believe this.  Employees will be influenced by the actions of key management, and not merely by the songs they sing. If those actions are in harmony with stated mores, then the combination should foster a strong ethical culture.  But if the observed actions are not congruent with the words (or, worse, conflict with the words), then employees will follow suit: They may say the right things, but they will not behave the right way.  Worse still, they will sense that they work for a firm lacking in integrity.  This has long\u2010term, deleterious consequences.  Recall that one of the key attractions in working for a particular organization is association with people who are liked and respected.  Do people like and respect leaders who lack integrity?  Good luck attracting top talent in that kind of organization.\n\nA third key component in a strong ethical culture is values.  Most firms elaborate rules of proper behavior, often in well\u2010crafted codes of conduct.  In some large, complex organizations, the rules can be difficult and tedious, like the rules for conflicting interests and for avoiding trading on insider information.  In better run firms, the rules are built on a foundation of the shared and well\u2010understood values of the institution.  These values reflect a bank\u2019s public function as a financial intermediary and recognize the privileges that come with a banking charter.5  In other firms, however, compliance rules can be undermined by the values of the organization, resulting in an unhealthy dissonance.  For example, if there are elaborate rules for complying with the tax laws of a particular jurisdiction, but the organizational value is to facilitate flight capital, a mixed message may be sent that tax compliance rules are just technicalities.  Similarly, in the area of economic sanctions, if the sanction is perceived as something technical and implicating only a single currency, the bank might be sending an unintended message\u2014that we comply with the sanction only because it represents a mandatory but silly rule of a single sovereign issuing a specific currency, and not because the sanction seeks to address a problem that all should find abhorrent, like financing a jurisdiction engaged in genocide.6\n\nWhat to Leave Out\n\nThinking about culture like a package, there are some things that I would leave out.  Again, without being exhaustive, here are three examples.\n\nFirst, I would leave out any depiction of the persons that an organization does business with as \u201ccounterparties.\u201d  If you went to your doctor and overheard her refer to you in conversation with office personnel as a \u201ccounterparty,\u201d rather than as a \u201cpatient,\u201d would you worry?  I would.  Similarly, if you went to your personal lawyer and overheard him refer to you in conversation with his associate as a \u201ccounterparty,\u201d rather than as a \u201cclient,\u201d would you worry?  You should.  My point here is not that banking is a profession like medicine or law.  My point is about how you see your customer and the service provided to that customer.  A counterparty is not someone needing your help; \u201cit\u201d represents a profit opportunity\u2014something to be exploited.  Their loss is your gain.  A customer, by contrast, is someone to be served.  It is right to charge a fee to a customer, client, or patient, but the transaction is driven by the other person\u2019s needs.  Many financial services firms, however, refer to the people they do business with as counterparties.  This is no accident.  It characterizes the way in which the organization views the person it is facing in its businesses.  Viewing customers as profit opportunities is inconsistent with a strong ethical culture.  In my experience, firms that consider their operational model as service provider tend to have a better culture than those firms that consider their operational model as money maker.\n\nThe second item that I would leave out is a conception of a bank as a money making machine.  This is not to say that I would ignore profitability; that would be foolish and would destine a firm to a short life.  But a bank\u2019s goal should be to provide service to its customers through financial intermediation, as Mark Carney has explained so eloquently.7  Christine Lagarde sees this as a question of animating purpose\u2014of \u201ctelos\u201d\u2014and I agree.8  Similarly, the Archbishop of Canterbury, Justin Welby, has called for financial institutions to reset to the first principle of service, playing a role in the world that contributes to \u201chuman flourishing.\u201d9  If you don\u2019t believe me, listen to the Archbishop: It is possible to do good and do well at the same time.  And remember one of attributes that attracts the best and the brightest to an organization is the prospect of quality work.  Having a work force that feels they are contributing to the greater good should benefit the organization in its effort to recruit the best minds, but also in the effort to recruit those with the best hearts (who presumably will be less likely to become malefactors).\n\nThe last item that I will leave out is \u201cshort termism.\u201d  Permit me to describe the concept.  With increasing frequency, people working in a financial services firm have no loyalty to their employer because they do not intend to work there long.  Instead, the idea is to get some experience and a decent bonus and then move to the next employer\u2014or, if the bonus is large enough, to work for oneself.10  Given the specialization that tends to accompany various financial services, people with near\u2010term career horizons tend to develop loyalty to the special group of individuals with whom they transact business and who might provide the next job opportunity.  These specialized bankers or traders increasingly resemble independent contractors or freelancers\u2014careerists with no institutional loyalty.  In foreign exchange, for example, we saw people orchestrating a manipulative scheme across a network of individuals at many institutions.  This is all rational and understandable\u2014specialists need the long-term allegiance of their network to continue to ply their trade, and this allegiance is far more consequential than loyalty to the organization currently employing them.  So, when in conflict, career trumps institution.  Some of this is simply generational; there is more employment mobility now than thirty years ago.  But compensation plans bear some degree of responsibility as well.  Annual bonuses that reward immediate book value without reflecting tail risk to the organization reinforce short termism.  Changing the time horizon for compensation will be a significant feature of meaningful cultural reform.11\n\nConclusion\n\nThe principal benefit to a financial services firm in having a strong ethical culture is the avoidance of bad banker behavior.  Bad banker behavior often leads to enforcement actions that can carry significant monetary fines, that can inflict destructive damage to the organization\u2019s reputation, and in the worst case, that can cause the death of a franchise (recalling that all financial services firms depend upon public confidence to survive).  A strong ethical culture also attracts the best and the brightest personnel, who will seek out the bank as the place to build a career doing high quality work, for fair compensation, with people they like and respect.  As for those with whom the bank does business, they may come to see the organization as customer focused, looking to serve them well, and not turning them into the next \u201cprofit opportunity.\u201d  Finally, from the perspective of the supervisory community, an industry comprising personnel who have a strong ethical culture will be a safer and sounder industry, certainly safer and sounder than an industry full of miscreants.  This could be a powerful factor toward financial stability.  Thank you for your kind attention.\n\n1 These remarks are personal and do not necessarily represent the official position of the Federal Reserve Bank of New York, or any other component of the Federal Reserve System.\n\n2 To call enforcement traditional is not to say that it is static. Eric Holder, the Attorney General of the United States, recently recommended that Congress create new criminal liability for bank officers who were in a position to detect and deter illegal conduct, but failed to do so. That is, individual executives could be criminally liable for failings within their organization without specific bad intent. See Eric Holder, Remarks on Financial Fraud Prosecutions at NYU School of Law, September 17, 2014.\n\n3 See Corporate Executive Board, Research Reveals That Integrity Drives Corporate Performance: Companies With Weak Ethical Cultures Experience 10x More Misconduct Than Those With Strong Ones, Press Release, September 15, 2010. See also Anthony Salz, Salz Review: An Independent Review of Barclays\u2019 Business Practices, 189\u2010191 (App\u2019x C) (discussing the impact of culture on two archetypes of employee behaviors, and collecting sources).\n\n4 Somewhat tautologically, the proof of a good culture might be the absence of bad behavior. As Bill Dudley, the President of the Federal Reserve Bank of New York, has observed: \u201cHow will a firm know if it is making real progress [on culture]? Not having to plead guilty to felony charges or being assessed large fines is a good start.\u201d William C. Dudley, Enhancing Financial Stability by Improving Culture in the Financial Services Industry, Remarks at the Workshop on Reforming Culture and Behavior in the Financial Services Industry, October 20, 2014.\n\n5 Cf. E. Gerald Corrigan, Are Banks Special? Federal Reserve Bank of Minneapolis Annual Report, January 1983, (\u201c[T]he presence of the public safety net uniquely available to a particular class of institutions also implies that those institutions have unique public responsibilities and may therefore be subject to implicit codes of conduct or explicit regulations that do not fall on other institutions.\u201d).\n\n6 See Thomas C. Baxter, Jr., Reflections on the New Compliance Landscape, Remarks at \u201cThe New Compliance Landscape: Increasing Roles \u2013 Increasing Risks\u201d Conference, July 24, 2014.\n\n7 See Mark Carney, \u201cInclusive Capitalism: Creating a Sense of the Systemic,\u201d Address to the Conference on Inclusive Capitalism, May 24, 2014. \n\n8 Christine Lagarde, \u201cEconomic Inclusion and Financial Integrity,\u201d Address to the Conference on Inclusive Capitalism,\u201d May 27, 2014.\n\n9 The Archbishop offered these comments at an October 12, 2014 panel discussion that was part of the\n\nInternational Monetary Fund 2014 Annual Meetings. A video of that discussion is available at http://www.archbishopofcanterbury.org/articles.php/5426/archbishop\u2010to\u2010take\u2010part\u2010in\u2010imfworld\u2010bank\u2010panel\u2010onethics\u2010and\u2010finance. Notably, the Archbishop described his role at the conference as a \u201clion in a den of Daniels.\u201d\n\n10 Even the skeptics of cultural reform concede that there is \u201calmost universal accord that remuneration structures contributed to excessive risk\u2010taking in financial institutions and that excessive bonuses paid on anticipated accounting profit at the time of deal origination distorted decision\u2010making and resulted in asymmetric riskholding.\u201d Paradigm Risk Consulting, To boldly supervise . . . , February 2014.\n\n11 See Dudley, Enhancing Financial Stability by Improving Culture in the Financial Services Industry, supra n.4."
  }
]