{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # 纽约联储主席讲话数据爬取\n",
    "\n",
    "@author : zhangwubin / 01208663\n",
    "\n",
    "@date: Oct. 21, 2024 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the date range for scraping\n",
    "start_date = datetime(2006, 1, 1)\n",
    "end_date = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the most recent speech date from existing files\n",
    "def get_most_recent_speech_date():\n",
    "    all_speeches_file = '../data/fed_speeches/newyork_fed_speeches/newyork_fed_speeches_all.json'\n",
    "    \n",
    "    if os.path.exists(all_speeches_file):\n",
    "        with open(all_speeches_file, 'r', encoding='utf-8') as f:\n",
    "            speeches = json.load(f)\n",
    "            if speeches:  # Check if the file is not empty\n",
    "                last_speech = speeches[-1]\n",
    "                return datetime.strptime(last_speech['date'], '%B %d, %Y')\n",
    "    \n",
    "    return start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically downloads and sets up ChromeDriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the New York Fed speeches page\n",
    "URL = \"https://www.newyorkfed.org/newsevents/speeches/index\"\n",
    "driver.get(URL)\n",
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to parse the date\n",
    "def parse_date(date_string):\n",
    "    try:\n",
    "        return pd.to_datetime(date_string.strip()).to_pydatetime()\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return datetime.strptime(date_string.strip(), \"%b %d, %Y\")\n",
    "    except ValueError:\n",
    "        print(f\"Error parsing date: {date_string}\")\n",
    "        return None\n",
    "    \n",
    "parse_date(\"Oct. 12, 2023\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搜集所有的讲话数据信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_infos(last_names: Optional[List[str]] = None):\n",
    "    speech_urls = []\n",
    "    try:\n",
    "        driver.get(URL)\n",
    "        # Wait for the table to be present\n",
    "        table = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"newsTable\"))\n",
    "        )\n",
    "        \n",
    "        rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "        \n",
    "        for row in rows:\n",
    "            if \"yrHead\" in row.get_attribute(\"class\"):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                columns = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if len(columns) < 2: continue\n",
    "                date_div = columns[0].find_element(By.TAG_NAME, \"div\")\n",
    "                date = date_div.text.strip().split(\"==\")[0].strip()  # Extract date and remove any extra text\n",
    "                link_elem = row.find_element(By.TAG_NAME, \"a\")\n",
    "                href = link_elem.get_attribute(\"href\")\n",
    "                # Check if the speech is by one of the specified speakers\n",
    "                title = link_elem.text.strip()\n",
    "                if last_names:\n",
    "                    speaker_last_name = title.split(':')[0].strip()\n",
    "                    if speaker_last_name in last_names:\n",
    "                        speech_urls.append({\"url\": href, \"date\": date, \"title\": title})\n",
    "                else:\n",
    "                    speech_urls.append({\"url\": href, \"date\": date, \"title\": title})\n",
    "            except NoSuchElementException:\n",
    "                print(f\"No speech link found in row: {row.text}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"Collected {len(speech_urls)} speech links.\")\n",
    "        return speech_urls\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while collecting speech links: {str(e)}\")\n",
    "        return speech_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取最新的讲话信息\n",
    "# Williams and Dudley are the presidents of the New York Fed from 2020 to 2024\n",
    "most_recent_date = get_most_recent_speech_date()\n",
    "# most_recent_date = parse_date(most_recent_date)\n",
    "print(\"most_recent_date: {}\".format(most_recent_date))\n",
    "# last_names_to_include = [\"Williams\", \"Dudley\", \"Geithner\", \"Stewart\", \"Geithner\"]\n",
    "speech_infos = get_speech_infos()\n",
    "speech_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_speech_content(url):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        title = driver.find_element(By.CLASS_NAME, \"ts-article-title\").text.strip()\n",
    "        \n",
    "        # Wait for the content to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"container_12\"))\n",
    "        )\n",
    "        # Extract the \"Posted\" date\n",
    "        contact_info_elements = driver.find_elements(\n",
    "            By.XPATH, \"//body/div/div/div[@class='ts-contact-info']\"\n",
    "        )\n",
    "        if len(contact_info_elements) >=1:\n",
    "            # 日期\n",
    "            date_elem = contact_info_elements[0]\n",
    "            date_text = date_elem.text.strip()\n",
    "            posted_date = [line for line in date_text.split('\\n') if 'Posted' in line]\n",
    "            date = posted_date[0] if posted_date else date_text.split('\\n')[0]\n",
    "            # 演讲人\n",
    "            speaker_title = contact_info_elements[1].text\n",
    "            splits = speaker_title.split(',')\n",
    "            speaker = splits[0].strip() if len(splits) >0 else \"Unknown\"\n",
    "        else:\n",
    "            date = 'Unknown'\n",
    "            speaker = 'Unknown'\n",
    "\n",
    "        content_elem = driver.find_element(By.CLASS_NAME, \"ts-article-text\")\n",
    "        paragraphs = content_elem.find_elements(By.TAG_NAME, \"p\")\n",
    "        content = \"\\n\\n\".join([p.text for p in paragraphs if p.text.strip()])\n",
    "        \n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"date\": date,\n",
    "            \"speaker\": speaker,\n",
    "            \"url\": url,\n",
    "            \"content\": content.strip()\n",
    "        }\n",
    "    except TimeoutException as e:\n",
    "        print(f\"Timeout error extracting content from {url}: {str(e)}\")\n",
    "    except WebDriverException as e:\n",
    "        print(f\"WebDriver error extracting content from {url}: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error extracting content from {url}: {str(e)}\")\n",
    "\n",
    "test_url = \"https://www.newyorkfed.org/newsevents/speeches/2006/gei060405\"\n",
    "extract_speech_content(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_speeches(speeches, year=None):\n",
    "    folder_name = \"newyork_fed_speeches\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    if year is not None:\n",
    "        filename = f\"newyork_fed_speeches_{year}.json\"\n",
    "        file_path = os.path.join(folder_name, filename)\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(speeches, f, indent=2)\n",
    "        print(f\"Saved {len(speeches)} speeches for {year} to {file_path}\")\n",
    "    else:\n",
    "        filename = \"newyork_fed_speeches_all.json\"\n",
    "        file_path = os.path.join(folder_name, filename)\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(speeches, f, indent=2)\n",
    "        print(f\"Saved {len(speeches)} speeches to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main scraping process\n",
    "def scrape_speeches(start_date: datetime, speech_infos: list):\n",
    "    speeches = []\n",
    "    speeches_by_year = {}\n",
    "    current_year = None\n",
    "\n",
    "    for speech in speech_infos:\n",
    "        speech_date = parse_date(speech['date'])\n",
    "        if speech_date and speech_date >= start_date:\n",
    "            full_speech_data = extract_speech_content(speech['url'])\n",
    "            if full_speech_data:\n",
    "                full_speech_data['date'] = speech['date']  # Use the date from the index page\n",
    "                speeches.append(full_speech_data)\n",
    "                \n",
    "                year = speech_date.year\n",
    "                if year != current_year:\n",
    "                    if current_year:\n",
    "                        save_speeches(speeches_by_year[current_year], current_year)\n",
    "                    current_year = year\n",
    "                    speeches_by_year[year] = []\n",
    "                speeches_by_year[year].append(full_speech_data)\n",
    "                print(f\"Scraped speech: {speech['date']} - {full_speech_data['title']}\")\n",
    "        elif speech_date is None:\n",
    "            print(f\"Skipping speech due to invalid date: {speech_infos['url']}\")\n",
    "        else:\n",
    "            print(\"Reached speeches older than our start date, stop here\")\n",
    "            break\n",
    "    \n",
    "    # Save the last year's speeches if any are left\n",
    "    if current_year and speeches_by_year[current_year]:\n",
    "        save_speeches(speeches_by_year[current_year], current_year)\n",
    "\n",
    "    # Save all speeches\n",
    "    save_speeches(speeches)\n",
    "\n",
    "    return speeches, speeches_by_year\n",
    "\n",
    "speeches, speeches_by_year = scrape_speeches(most_recent_date, speech_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the browser\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FOMCTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
